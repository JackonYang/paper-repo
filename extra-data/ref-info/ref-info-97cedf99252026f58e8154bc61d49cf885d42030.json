{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145775792"
                        ],
                        "name": "Hassan Sajjad",
                        "slug": "Hassan-Sajjad",
                        "structuredName": {
                            "firstName": "Hassan",
                            "lastName": "Sajjad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hassan Sajjad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3457391"
                        ],
                        "name": "Svetlana Smekalova",
                        "slug": "Svetlana-Smekalova",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Smekalova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Svetlana Smekalova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145938140"
                        ],
                        "name": "Nadir Durrani",
                        "slug": "Nadir-Durrani",
                        "structuredName": {
                            "firstName": "Nadir",
                            "lastName": "Durrani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nadir Durrani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277248"
                        ],
                        "name": "Alexander M. Fraser",
                        "slug": "Alexander-M.-Fraser",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Fraser",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander M. Fraser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360495"
                        ],
                        "name": "Helmut Schmid",
                        "slug": "Helmut-Schmid",
                        "structuredName": {
                            "firstName": "Helmut",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helmut Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 75
                            }
                        ],
                        "text": "This interpolation is done for all iterations of all alignment models (See Sajjad et al. (2013) for details)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 707019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e039e1acca1b91e3dc417811ebbf56c060c6b02",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes QCRI-MES\u2019s submission on the English-Russian dataset to the Eighth Workshop on Statistical Machine Translation. We generate improved word alignment of the training data by incorporating an unsupervised transliteration mining module to GIZA++ and build a phrase-based machine translation system. For tuning, we use a variation of PRO which provides better weights by optimizing BLEU+1 at corpus-level. We transliterate out-of-vocabulary words in a postprocessing step by using a transliteration system built on the transliteration pairs extracted using an unsupervised transliteration mining system. For the Russian to English translation direction, we apply linguistically motivated pre-processing on the Russian side of the data."
            },
            "slug": "QCRI-MES-Submission-at-WMT13:-Using-Transliteration-Sajjad-Smekalova",
            "title": {
                "fragments": [],
                "text": "QCRI-MES Submission at WMT13: Using Transliteration Mining to Improve Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This paper describes QCRI-MES\u2019s submission on the English-Russian dataset to the Eighth Workshop on Statistical Machine Translation and generates improved word alignment of the training data by incorporating an unsupervised transliteration mining module to GIZA++ and builds a phrase-based machine translation system."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2539211"
                        ],
                        "name": "Alexandra Birch",
                        "slug": "Alexandra-Birch",
                        "structuredName": {
                            "firstName": "Alexandra",
                            "lastName": "Birch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandra Birch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1839533"
                        ],
                        "name": "Matthias Huck",
                        "slug": "Matthias-Huck",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Huck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthias Huck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145938140"
                        ],
                        "name": "Nadir Durrani",
                        "slug": "Nadir-Durrani",
                        "structuredName": {
                            "firstName": "Nadir",
                            "lastName": "Durrani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nadir Durrani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3444222"
                        ],
                        "name": "Nikolay Bogoychev",
                        "slug": "Nikolay-Bogoychev",
                        "structuredName": {
                            "firstName": "Nikolay",
                            "lastName": "Bogoychev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nikolay Bogoychev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 276
                            }
                        ],
                        "text": "For the English-to-German system we added an OSM model over [pos, morph] (source:pos, target:morph) and for the Germanto-English system we added an OSM model over [morph,pos] (source:morph, target:pos), a configuration that was found to work best in our previous experiments (Birch et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12222565,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "dd8a63a1ed6ab755e0a860f0086416af13dceaa2",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the University of Edinburgh\u2019s spoken language translation (SLT) and machine translation (MT) systems for the IWSLT 2014 evaluation campaign. In the SLT track, we participated in the German\u2194English and English\u2192French tasks. In the MT track, we participated in the German\u2194English, English\u2192French, Arabic\u2194English, Farsi\u2192English, Hebrew\u2192English, Spanish\u2194English, and Portuguese-Brazil\u2194English tasks. For our SLT submissions, we experimented with comparing operation sequence models with bilingual neural network language models. For our MT submissions, we explored using unsupervised transliteration for languages which have a different script than English, in particular for Arabic, Farsi, and Hebrew. We also investigated syntax-based translation and system combination."
            },
            "slug": "English-SLT-and-MT-system-description-for-the-IWSLT-Birch-Huck",
            "title": {
                "fragments": [],
                "text": "English SLT and MT system description for the IWSLT 2013 evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The University of Edinburgh\u2019s spoken language translation and machine translation systems for the IWSLT 2014 evaluation campaign are described and using unsupervised transliteration for languages which have a different script than English is explored."
            },
            "venue": {
                "fragments": [],
                "text": "IWSLT"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145938140"
                        ],
                        "name": "Nadir Durrani",
                        "slug": "Nadir-Durrani",
                        "structuredName": {
                            "firstName": "Nadir",
                            "lastName": "Durrani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nadir Durrani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259100"
                        ],
                        "name": "B. Haddow",
                        "slug": "B.-Haddow",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Haddow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Haddow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702066"
                        ],
                        "name": "Kenneth Heafield",
                        "slug": "Kenneth-Heafield",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Heafield",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Heafield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 363,
                                "start": 360
                            }
                        ],
                        "text": "We trained our systems with the following settings: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM)\n(Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "We also trained OSM models over cluster-ids (?)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "We also trained OSM models over POS and morph tags."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 57
                            }
                        ],
                        "text": "Our baseline systems are based on the setup described in (Durrani et al., 2013b) that we used for the Eighth Workshop on Statistical Machine Translation (Bojar et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "The lexically driven OSM model falls back to very small context sizes of two to three operations due to data sparsity."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 58
                            }
                        ],
                        "text": "Our baseline systems are based on the setup described in (Durrani et al., 2013b) that we used for the Eighth Workshop on Statistical Machine Translation (Bojar et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 45
                            }
                        ],
                        "text": "For the English-to-German system we added an OSM model over [pos, morph] (source:pos, target:morph) and for the Germanto-English system we added an OSM model over [morph,pos] (source:morph, target:pos), a configuration that was found to work best in our previous experiments (Birch et al., 2013)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "Table 2 shows gains from additionally using OSM models over POS/morph tags."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 168
                            }
                        ],
                        "text": "In order to create systems for the medical translation tasks, we used phrase-based Moses with exactly the same settings as for the news translation task, including the OSM (Durrani et al., 2011), and compound splitting Koehn and Knight (2003) for German source."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "Table 1 shows gains from adding target LM and OSM models over cluster-ids."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 145
                            }
                        ],
                        "text": "\u20262011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM)\n(Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9590996,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22ec0fb11ab16d0ad1c41be81648a82348364162",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We validated various novel and recently proposed methods for statistical machine translation on 10 language pairs, using large data resources. We saw gains from optimizing parameters, training with sparse features, the operation sequence model, and domain adaptation techniques. We also report on utilizing a huge language model trained on 126 billion tokens. The annual machine translation evaluation campaign for European languages organized around the ACL Workshop on Statistical Machine Translation offers the opportunity to test recent advancements in machine translation in large data condition across several diverse language pairs. Building on our own developments and external contributions to the Moses open source toolkit, we carried out extensive experiments that, by early indications, led to a strong showing in the evaluation campaign. We would like to stress especially two contributions: the use of the new operation sequence model (Section 3) within Moses, and \u2014 in a separate unconstraint track submission \u2014 the use of a huge language model trained on 126 billion tokens with a new training tool (Section 4). 1 Initial System Development We start with systems (Haddow and Koehn, 2012) that we developed for the 2012 Workshop on Statistical Machine Translation (Callison-Burch et al., 2012). The notable features of these systems are: \u2022 Moses phrase-based models with mostly default settings \u2022 training on all available parallel data, including the large UN parallel data, the FrenchEnglish 109 parallel data and the LDC Gigaword data \u2022 very large tuning set consisting of the test sets from 2008-2010, with a total of 7,567 sentences per language \u2022 German\u2013English with syntactic prereordering (Collins et al., 2005), compound splitting (Koehn and Knight, 2003) and use of factored representation for a POS target sequence model (Koehn and Hoang, 2007) \u2022 English\u2013German with morphological target sequence model Note that while our final 2012 systems included subsampling of training data with modified Moore-Lewis filtering (Axelrod et al., 2011), we did not use such filtering at the starting point of our development. We will report on such filtering in Section 2. Moreover, our system development initially used the WMT 2012 data condition, since it took place throughout 2012, and we switched to WMT 2013 training data at a later stage. In this section, we report cased BLEU scores (Papineni et al., 2001) on newstest2011. 1.1 Factored Backoff (German\u2013English) We have consistently used factored models in past WMT systems for the German\u2013English language pairs to include POS and morphological target sequence models. But we did not use the factored decomposition of translation options into multiple mapping steps, since this usually lead to much slower systems with usually worse results. A good place, however, for factored decomposition is the handling of rare and unknown source words which have more frequent morphological variants (Koehn and Haddow, 2012a). Here, we used only factored backoff for unknown words, giving gains in BLEU of +.12 for German\u2013English. 1.2 Tuning with k-best MIRA In preparation for training with sparse features, we moved away from MERT which is known to fall"
            },
            "slug": "Edinburgh\u2019s-Machine-Translation-Systems-for-Pairs-Durrani-Haddow",
            "title": {
                "fragments": [],
                "text": "Edinburgh\u2019s Machine Translation Systems for European Language Pairs"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The authors validated various novel and recently proposed methods for statistical machine translation on 10 language pairs, using large data resources, and saw gains from optimizing parameters, training with sparse features, the operation sequence model, and domain adaptation techniques."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143832874"
                        ],
                        "name": "Ondrej Bojar",
                        "slug": "Ondrej-Bojar",
                        "structuredName": {
                            "firstName": "Ondrej",
                            "lastName": "Bojar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ondrej Bojar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064348170"
                        ],
                        "name": "C. Buck",
                        "slug": "C.-Buck",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Buck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3359291"
                        ],
                        "name": "C. Federmann",
                        "slug": "C.-Federmann",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Federmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Federmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259100"
                        ],
                        "name": "B. Haddow",
                        "slug": "B.-Haddow",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Haddow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Haddow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696402"
                        ],
                        "name": "Christof Monz",
                        "slug": "Christof-Monz",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Monz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christof Monz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38842528"
                        ],
                        "name": "Matt Post",
                        "slug": "Matt-Post",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "Post",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matt Post"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737285"
                        ],
                        "name": "Radu Soricut",
                        "slug": "Radu-Soricut",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Soricut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radu Soricut"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702974"
                        ],
                        "name": "Lucia Specia",
                        "slug": "Lucia-Specia",
                        "structuredName": {
                            "firstName": "Lucia",
                            "lastName": "Specia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucia Specia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 81
                            }
                        ],
                        "text": ", 2013b) that we used for the Eighth Workshop on Statistical Machine Translation (Bojar et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 154
                            }
                        ],
                        "text": "Our baseline systems are based on the setup described in (Durrani et al., 2013b) that we used for the Eighth Workshop on Statistical Machine Translation (Bojar et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 37
                            }
                        ],
                        "text": "Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 97\u2013104, Baltimore, Maryland USA, June 26\u201327, 2014. c\u00a92014 Association for Computational Linguistics"
                    },
                    "intents": []
                }
            ],
            "corpusId": 1009868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7de66a09cd23f05859a95fa55616b515acab71e9",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the results of the WMT13 shared tasks, which included a translation task, a task for run-time estimation of machine translation quality, and an unofficial metrics task. This year, 143 machine translation systems were submitted to the ten translation tasks from 23 institutions. An additional 6 anonymized systems were included, and were then evaluated both automatically and manually, in our largest manual evaluation to date. The quality estimation task had four subtasks, with a total of 14 teams, submitting 55 entries."
            },
            "slug": "Findings-of-the-2013-Workshop-on-Statistical-Bojar-Buck",
            "title": {
                "fragments": [],
                "text": "Findings of the 2013 Workshop on Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The results of the WMT13 shared tasks, which included a translation task, a task for run-time estimation of machine translation quality, and an unofficial metrics task are presented."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145938140"
                        ],
                        "name": "Nadir Durrani",
                        "slug": "Nadir-Durrani",
                        "structuredName": {
                            "firstName": "Nadir",
                            "lastName": "Durrani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nadir Durrani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360495"
                        ],
                        "name": "Helmut Schmid",
                        "slug": "Helmut-Schmid",
                        "structuredName": {
                            "firstName": "Helmut",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helmut Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277248"
                        ],
                        "name": "Alexander M. Fraser",
                        "slug": "Alexander-M.-Fraser",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Fraser",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander M. Fraser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 71
                            }
                        ],
                        "text": "We explored the use of automatic word clusters in phrase-based models (Durrani et al., 2014a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 84
                            }
                        ],
                        "text": "This year we used an EM-based method to induce unsupervised transliteration models (Durrani et al., 2014b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14240696,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f79889beae12e29a38368210a8d106ab5b28f910",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the use of generalized representations (POS, morphological analysis and word clusters) in phrase-based models and the N-gram-based Operation Sequence Model (OSM). Our integration enables these models to learn richer lexical and reordering patterns, consider wider contextual information and generalize better in sparse data conditions. When interpolating generalized OSM models on the standard IWSLT and WMT tasks we observed improvements of up to +1.35 on the English-to-German task and +0.63 for the German-to-English task. Using automatically generated word classes in standard phrase-based models and the OSM models yields an average improvement of +0.80 across 8 language pairs on the IWSLT shared task."
            },
            "slug": "Investigating-the-Usefulness-of-Generalized-Word-in-Durrani-Koehn",
            "title": {
                "fragments": [],
                "text": "Investigating the Usefulness of Generalized Word Representations in SMT"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work investigates the use of generalized representations (POS, morphological analysis and word clusters) in phrase-based models and the N-gram-based Operation Sequence Model and finds that this integration enables these models to learn richer lexical and reordering patterns, consider wider contextual information and generalize better in sparse data conditions."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145287425"
                        ],
                        "name": "David Chiang",
                        "slug": "David-Chiang",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Chiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49337181"
                        ],
                        "name": "Wei Wang",
                        "slug": "Wei-Wang",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 147
                            }
                        ],
                        "text": "\u2026et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 112
                            }
                        ],
                        "text": ", 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3544821,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57b3f8df7020b67df71a96974adef8d5282ed396",
            "isKey": false,
            "numCitedBy": 212,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We use the Margin Infused Relaxed Algorithm of Crammer et al. to add a large number of new features to two machine translation systems: the Hiero hierarchical phrase-based translation system and our syntax-based translation system. On a large-scale Chinese-English translation task, we obtain statistically significant improvements of +1.5 Bleu and + 1.1 Bleu, respectively. We analyze the impact of the new features and the performance of the learning algorithm."
            },
            "slug": "11,001-New-Features-for-Statistical-Machine-Chiang-Knight",
            "title": {
                "fragments": [],
                "text": "11,001 New Features for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "On a large-scale Chinese-English translation task, the Margin Infused Relaxed Algorithm is used to add a large number of new features to two machine translation systems: the Hiero hierarchical phrase-based translation system and the syntax-basedtranslation system."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35307070"
                        ],
                        "name": "Markus Freitag",
                        "slug": "Markus-Freitag",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Freitag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700238"
                        ],
                        "name": "Stephan Peitz",
                        "slug": "Stephan-Peitz",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Peitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephan Peitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2046393"
                        ],
                        "name": "Joern Wuebker",
                        "slug": "Joern-Wuebker",
                        "structuredName": {
                            "firstName": "Joern",
                            "lastName": "Wuebker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joern Wuebker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1839533"
                        ],
                        "name": "Matthias Huck",
                        "slug": "Matthias-Huck",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Huck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthias Huck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082372"
                        ],
                        "name": "Rico Sennrich",
                        "slug": "Rico-Sennrich",
                        "structuredName": {
                            "firstName": "Rico",
                            "lastName": "Sennrich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rico Sennrich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145938140"
                        ],
                        "name": "Nadir Durrani",
                        "slug": "Nadir-Durrani",
                        "structuredName": {
                            "firstName": "Nadir",
                            "lastName": "Durrani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nadir Durrani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3456844"
                        ],
                        "name": "Maria Nadejde",
                        "slug": "Maria-Nadejde",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Nadejde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maria Nadejde"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144034785"
                        ],
                        "name": "Philip Williams",
                        "slug": "Philip-Williams",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Williams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244151"
                        ],
                        "name": "T. Herrmann",
                        "slug": "T.-Herrmann",
                        "structuredName": {
                            "firstName": "Teresa",
                            "lastName": "Herrmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Herrmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4006425"
                        ],
                        "name": "Eunah Cho",
                        "slug": "Eunah-Cho",
                        "structuredName": {
                            "firstName": "Eunah",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eunah Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 164
                            }
                        ],
                        "text": "Our GermanEnglish constrained systems were used for EUBridge system combination, a collaborative effort to improve the state-of-the-art in machine translation (See Freitag et al. (2014) for details)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16429074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56fcf886de43d431590c5617546f75c4c16f3ad4",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes one of the collaborative efforts within EU-BRIDGE to further advance the state of the art in machine translation between two European language pairs, German\u2192English and English\u2192German. Three research institutes involved in the EU-BRIDGE project combined their individual machine translation systems and participated with a joint setup in the shared translation task of the evaluation campaign at the ACL 2014 Eighth Workshop on Statistical Machine Translation (WMT 2014). We combined up to nine different machine translation engines via system combination. RWTH Aachen University, the University of Edinburgh, and Karlsruhe Institute of Technology developed several individual systems which serve as system combination input. We devoted special attention to building syntax-based systems and combining them with the phrasebased ones. The joint setups yield empirical gains of up to 1.6 points in BLEU and 1.0 points in TER on the WMT newstest2013 test set compared to the best single systems."
            },
            "slug": "EU-BRIDGE-MT:-Combined-Machine-Translation-Freitag-Peitz",
            "title": {
                "fragments": [],
                "text": "EU-BRIDGE MT: Combined Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Three research institutes involved in the EU-BRIDGE project combined their individual machine translation systems and participated with a joint setup in the shared translation task of the evaluation campaign at the ACL 2014 Eighth Workshop on Statistical Machine Translation."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2491610"
                        ],
                        "name": "I. Kucerova",
                        "slug": "I.-Kucerova",
                        "structuredName": {
                            "firstName": "Ivona",
                            "lastName": "Kucerova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kucerova"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 31
                            }
                        ],
                        "text": "We used syntactic-preordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) for German-to-English systems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11142668,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5b1146b7ca79322aab124fd63825b9c175c02cf",
            "isKey": false,
            "numCitedBy": 656,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for incorporating syntactic information in statistical machine translation systems. The first step of the method is to parse the source language string that is being translated. The second step is to apply a series of transformations to the parse tree, effectively reordering the surface string on the source language side of the translation system. The goal of this step is to recover an underlying word order that is closer to the target language word-order than the original string. The reordering approach is applied as a pre-processing step in both the training and decoding phases of a phrase-based statistical MT system. We describe experiments on translation from German to English, showing an improvement from 25.2% Bleu score for a baseline system to 26.8% Bleu score for the system with reordering, a statistically significant improvement."
            },
            "slug": "Clause-Restructuring-for-Statistical-Machine-Collins-Koehn",
            "title": {
                "fragments": [],
                "text": "Clause Restructuring for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The reordering approach is applied as a pre-processing step in both the training and decoding phases of a phrase-based statistical MT system, showing an improvement from 25.2% Bleu score for a baseline system to 26.8% Blee score for the system with reordering."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145938140"
                        ],
                        "name": "Nadir Durrani",
                        "slug": "Nadir-Durrani",
                        "structuredName": {
                            "firstName": "Nadir",
                            "lastName": "Durrani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nadir Durrani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145775792"
                        ],
                        "name": "Hassan Sajjad",
                        "slug": "Hassan-Sajjad",
                        "structuredName": {
                            "firstName": "Hassan",
                            "lastName": "Sajjad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hassan Sajjad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143620134"
                        ],
                        "name": "Hieu Hoang",
                        "slug": "Hieu-Hoang",
                        "structuredName": {
                            "firstName": "Hieu",
                            "lastName": "Hoang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hieu Hoang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 71
                            }
                        ],
                        "text": "We explored the use of automatic word clusters in phrase-based models (Durrani et al., 2014a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 84
                            }
                        ],
                        "text": "This year we used an EM-based method to induce unsupervised transliteration models (Durrani et al., 2014b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9407699,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa144b01862baa5de61d22fd3f922a3ddd54ac4d",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate three methods for integrating an unsupervised transliteration model into an end-to-end SMT system. We induce a transliteration model from parallel data and use it to translate OOV words. Our approach is fully unsupervised and language independent. In the methods to integrate transliterations, we observed improvements from 0.23-0.75 ( 0.41) BLEU points across 7 language pairs. We also show that our mined transliteration corpora provide better rule coverage and translation quality compared to the gold standard transliteration corpora."
            },
            "slug": "Integrating-an-Unsupervised-Transliteration-Model-Durrani-Sajjad",
            "title": {
                "fragments": [],
                "text": "Integrating an Unsupervised Transliteration Model into Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work induces a transliteration model from parallel data and uses it to translate OOV words and shows that the mined transliterations provide better rule coverage and translation quality compared to the gold standard transliterated corpora."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145938140"
                        ],
                        "name": "Nadir Durrani",
                        "slug": "Nadir-Durrani",
                        "structuredName": {
                            "firstName": "Nadir",
                            "lastName": "Durrani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nadir Durrani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145775792"
                        ],
                        "name": "Hassan Sajjad",
                        "slug": "Hassan-Sajjad",
                        "structuredName": {
                            "firstName": "Hassan",
                            "lastName": "Sajjad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hassan Sajjad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277248"
                        ],
                        "name": "Alexander M. Fraser",
                        "slug": "Alexander-M.-Fraser",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Fraser",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander M. Fraser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360495"
                        ],
                        "name": "Helmut Schmid",
                        "slug": "Helmut-Schmid",
                        "structuredName": {
                            "firstName": "Helmut",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helmut Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 93
                            }
                        ],
                        "text": "The transliteration module can be used to translate the 50K OOV words but previous research (Durrani et al., 2010; Nakov and Tiedemann, 2012) has shown that transliteration is useful for more than just translating OOV words when translating closely related language pairs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16076435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "272e4c36485ea073161fb9386aeaa22a2f610698",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach to integrate transliteration into Hindi-to-Urdu statistical machine translation. We propose two probabilistic models, based on conditional and joint probability formulations, that are novel solutions to the problem. Our models consider both transliteration and translation when translating a particular Hindi word given the context whereas in previous work transliteration is only used for translating OOV (out-of-vocabulary) words. We use transliteration as a tool for disambiguation of Hindi homonyms which can be both translated or transliterated or transliterated differently based on different contexts. We obtain final BLEU scores of 19.35 (conditional probability model) and 19.00 (joint probability model) as compared to 14.30 for a baseline phrase-based system and 16.25 for a system which transliterates OOV words in the baseline system. This indicates that transliteration is useful for more than only translating OOV words for language pairs like Hindi-Urdu."
            },
            "slug": "Hindi-to-Urdu-Machine-Translation-through-Durrani-Sajjad",
            "title": {
                "fragments": [],
                "text": "Hindi-to-Urdu Machine Translation through Transliteration"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A novel approach to integrate transliteration into Hindi-to-Urdu statistical machine translation by proposing two probabilistic models, based on conditional and joint probability formulations, that are novel solutions to the problem."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 286
                            }
                        ],
                        "text": "\u2026models were trained on text provided by the CommonCrawl foundation, which they converted to UTF-8 after stripping HTML. Languages were detected using the Compact Language Detection 23 and, except for Hindi where we lack tools, sentences were split with the Europarl sentence splitter (Koehn, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 164
                            }
                        ],
                        "text": "Languages were detected using the Compact Language Detection 23 and, except for Hindi where we lack tools, sentences were split with the Europarl sentence splitter (Koehn, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 38407095,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "694b3c58712deefb59502847ba1b52b192c413e5",
            "isKey": false,
            "numCitedBy": 3397,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We collected a corpus of parallel text in 11 languages from the proceedings of the European Parliament, which are published on the web. This corpus has found widespread use in the NLP community. Here, we focus on its acquisition and its application as training data for statistical machine translation (SMT). We trained SMT systems for 110 language pairs, which reveal interesting clues into the challenges ahead."
            },
            "slug": "Europarl:-A-Parallel-Corpus-for-Statistical-Machine-Koehn",
            "title": {
                "fragments": [],
                "text": "Europarl: A Parallel Corpus for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A corpus of parallel text in 11 languages from the proceedings of the European Parliament is collected and its acquisition and application as training data for statistical machine translation (SMT) is focused on."
            },
            "venue": {
                "fragments": [],
                "text": "MTSUMMIT"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145938140"
                        ],
                        "name": "Nadir Durrani",
                        "slug": "Nadir-Durrani",
                        "structuredName": {
                            "firstName": "Nadir",
                            "lastName": "Durrani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nadir Durrani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277248"
                        ],
                        "name": "Alexander M. Fraser",
                        "slug": "Alexander-M.-Fraser",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Fraser",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander M. Fraser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360495"
                        ],
                        "name": "Helmut Schmid",
                        "slug": "Helmut-Schmid",
                        "structuredName": {
                            "firstName": "Helmut",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helmut Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143620134"
                        ],
                        "name": "Hieu Hoang",
                        "slug": "Hieu-Hoang",
                        "structuredName": {
                            "firstName": "Hieu",
                            "lastName": "Hoang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hieu Hoang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 363,
                                "start": 360
                            }
                        ],
                        "text": "We trained our systems with the following settings: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM)\n(Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "We also trained OSM models over cluster-ids (?)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "We also trained OSM models over POS and morph tags."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "The lexically driven OSM model falls back to very small context sizes of two to three operations due to data sparsity."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 58
                            }
                        ],
                        "text": "Our baseline systems are based on the setup described in (Durrani et al., 2013b) that we used for the Eighth Workshop on Statistical Machine Translation (Bojar et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 45
                            }
                        ],
                        "text": "For the English-to-German system we added an OSM model over [pos, morph] (source:pos, target:morph) and for the Germanto-English system we added an OSM model over [morph,pos] (source:morph, target:pos), a configuration that was found to work best in our previous experiments (Birch et al., 2013)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "Table 2 shows gains from additionally using OSM models over POS/morph tags."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 168
                            }
                        ],
                        "text": "In order to create systems for the medical translation tasks, we used phrase-based Moses with exactly the same settings as for the news translation task, including the OSM (Durrani et al., 2011), and compound splitting Koehn and Knight (2003) for German source."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "Table 1 shows gains from adding target LM and OSM models over cluster-ids."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 145
                            }
                        ],
                        "text": "\u20262011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM)\n(Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5907276,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76232f8fa3377c7382220a196470d11cb30fb45c",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The phrase-based and N-gram-based SMT frameworks complement each other. While the former is better able to memorize, the latter provides a more principled model that captures dependencies across phrasal boundaries. Some work has been done to combine insights from these two frameworks. A recent successful attempt showed the advantage of using phrasebased search on top of an N-gram-based model. We probe this question in the reverse direction by investigating whether integrating N-gram-based translation and reordering models into a phrase-based decoder helps overcome the problematic phrasal independence assumption. A large scale evaluation over 8 language pairs shows that performance does significantly improve."
            },
            "slug": "Can-Markov-Models-Over-Minimal-Translation-Units-Durrani-Fraser",
            "title": {
                "fragments": [],
                "text": "Can Markov Models Over Minimal Translation Units Help Phrase-Based SMT?"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work investigates whether integrating N-gram-based translation and reordering models into a phrase-based decoder helps overcome the problematic phrasal independence assumption, and shows that performance does significantly improve."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802277"
                        ],
                        "name": "M. Utiyama",
                        "slug": "M.-Utiyama",
                        "structuredName": {
                            "firstName": "Masao",
                            "lastName": "Utiyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Utiyama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714134"
                        ],
                        "name": "H. Isahara",
                        "slug": "H.-Isahara",
                        "structuredName": {
                            "firstName": "Hitoshi",
                            "lastName": "Isahara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Isahara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 147
                            }
                        ],
                        "text": "\u2026p(u\u0304i|e\u0304i) and the phrase-table for English-Hindi p(e\u0304i|h\u0304i), we estimated a Urdu-Hindi phrase-table p(u\u0304i|h\u0304i) using the well-known convolution model (Utiyama and Isahara, 2007; Wu and Wang, 2007):\np(u\u0304i|h\u0304i) = \u2211 e\u0304i p(u\u0304i|e\u0304i)p(e\u0304i|h\u0304i)\nThe number of entries in the baseline Urdu-toHindi\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 187
                            }
                        ],
                        "text": "Given the phrase-table for Urdu-English p(\u016bi|\u0113i) and the phrase-table for English-Hindi p(\u0113i|h\u0304i), we estimated a Urdu-Hindi phrase-table p(\u016bi|h\u0304i) using the well-known convolution model (Utiyama and Isahara, 2007; Wu and Wang, 2007):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8030425,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe620306c0278e8c9ccd9519377ce26a70400aaf",
            "isKey": false,
            "numCitedBy": 179,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We compare two pivot strategies for phrase-based statistical machine translation (SMT), namely phrase translation and sentence translation. The phrase translation strategy means that we directly construct a phrase translation table (phrase-table) of the source and target language pair from two phrase-tables; one constructed from the source language and English and one constructed from English and the target language. We then use that phrase-table in a phrase-based SMT system. The sentence translation strategy means that we first translate a source language sentence into n English sentences and then translate these n sentences into target language sentences separately. Then, we select the highest scoring sentence from these target sentences. We conducted controlled experiments using the Europarl corpus to evaluate the performance of these pivot strategies as compared to directly trained SMT systems. The phrase translation strategy significantly outperformed the sentence translation strategy. Its relative performance was 0.92 to 0.97 compared to directly trained SMT systems."
            },
            "slug": "A-Comparison-of-Pivot-Methods-for-Phrase-Based-Utiyama-Isahara",
            "title": {
                "fragments": [],
                "text": "A Comparison of Pivot Methods for Phrase-Based Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The phrase translation strategy significantly outperformed the sentence translation strategy and its relative performance was 0.92 to 0.97 compared to directly trained SMT systems."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 77
                            }
                        ],
                        "text": "We used syntactic-preordering (Collins et al., 2005) and compound splitting (Koehn and Knight, 2003) for German-to-English systems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 31
                            }
                        ],
                        "text": ", 2005) and compound splitting (Koehn and Knight, 2003) for German-to-English systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 219
                            }
                        ],
                        "text": "In order to create systems for the medical translation tasks, we used phrase-based Moses with exactly the same settings as for the news translation task, including the OSM (Durrani et al., 2011), and compound splitting Koehn and Knight (2003) for German source."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14259080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cdaae7a8f0db8b280266606004f1c6f164a13f6d",
            "isKey": false,
            "numCitedBy": 368,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Compounded words are a challenge for NLP applications such as machine translation (MT). We introduce methods to learn splitting rules from monolingual and parallel corpora. We evaluate them against a gold standard and measure their impact on performance of statistical MT systems. Results show accuracy of 99.1% and performance gains for MT of 0.039 BLEU on a German-English noun phrase translation task."
            },
            "slug": "Empirical-Methods-for-Compound-Splitting-Koehn-Knight",
            "title": {
                "fragments": [],
                "text": "Empirical Methods for Compound Splitting"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Methods to learn splitting rules from monolingual and parallel corpora are introduced and evaluated against a gold standard and their impact on performance of statistical MT systems is measured."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683562"
                        ],
                        "name": "Preslav Nakov",
                        "slug": "Preslav-Nakov",
                        "structuredName": {
                            "firstName": "Preslav",
                            "lastName": "Nakov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Preslav Nakov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143675545"
                        ],
                        "name": "J. Tiedemann",
                        "slug": "J.-Tiedemann",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Tiedemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tiedemann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 115
                            }
                        ],
                        "text": "The transliteration module can be used to translate the 50K OOV words but previous research (Durrani et al., 2010; Nakov and Tiedemann, 2012) has shown that transliteration is useful for more than just translating OOV words when translating closely related language pairs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7447330,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c522f0d51aa2c03cedd279d05af24751e8740c39",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose several techniques for improving statistical machine translation between closely-related languages with scarce resources. We use character-level translation trained on n-gram-character-aligned bitexts and tuned using word-level BLEU, which we further augment with character-based transliteration at the word level and combine with a word-level translation model. The evaluation on Macedonian-Bulgarian movie subtitles shows an improvement of 2.84 BLEU points over a phrase-based word-level baseline."
            },
            "slug": "Combining-Word-Level-and-Character-Level-Models-for-Nakov-Tiedemann",
            "title": {
                "fragments": [],
                "text": "Combining Word-Level and Character-Level Models for Machine Translation Between Closely-Related Languages"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work uses character-level translation trained on n-gram-character-aligned bitexts and tuned using word-level BLEU to augment with character-based transliteration at the word level and combine with a word- level translation model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145938140"
                        ],
                        "name": "Nadir Durrani",
                        "slug": "Nadir-Durrani",
                        "structuredName": {
                            "firstName": "Nadir",
                            "lastName": "Durrani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nadir Durrani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360495"
                        ],
                        "name": "Helmut Schmid",
                        "slug": "Helmut-Schmid",
                        "structuredName": {
                            "firstName": "Helmut",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helmut Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277248"
                        ],
                        "name": "Alexander M. Fraser",
                        "slug": "Alexander-M.-Fraser",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Fraser",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander M. Fraser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 173
                            }
                        ],
                        "text": "In order to create systems for the medical translation tasks, we used phrase-based Moses with exactly the same settings as for the news translation task, including the OSM (Durrani et al., 2011), and compound splitting Koehn and Knight (2003) for German source."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 453090,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "019e706ff091a69bdbe348e782fe5ea2998d93b9",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel machine translation model which models translation by a linear sequence of operations. In contrast to the \"N-gram\" model, this sequence includes not only translation but also reordering operations. Key ideas of our model are (i) a new reordering approach which better restricts the position to which a word or phrase can be moved, and is able to handle short and long distance re-orderings in a unified way, and (ii) a joint sequence model for the translation and reordering probabilities which is more flexible than standard phrase-based MT. We observe statistically significant improvements in BLEU over Moses for German-to-English and Spanish-to-English tasks, and comparable results for a French-to-English task."
            },
            "slug": "A-Joint-Sequence-Translation-Model-with-Integrated-Durrani-Schmid",
            "title": {
                "fragments": [],
                "text": "A Joint Sequence Translation Model with Integrated Reordering"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel machine translation model which models translation by a linear sequence of operations which includes not only translation but also reordering operations, and a joint sequence model for the translation and reordering probabilities which is more flexible than standard phrase-based MT."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40354707"
                        ],
                        "name": "Hua Wu",
                        "slug": "Hua-Wu",
                        "structuredName": {
                            "firstName": "Hua",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hua Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144270731"
                        ],
                        "name": "Haifeng Wang",
                        "slug": "Haifeng-Wang",
                        "structuredName": {
                            "firstName": "Haifeng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haifeng Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 198
                            }
                        ],
                        "text": "Given the phrase-table for Urdu-English p(u\u0304i|e\u0304i) and the phrase-table for English-Hindi p(e\u0304i|h\u0304i), we estimated a Urdu-Hindi phrase-table p(u\u0304i|h\u0304i) using the well-known convolution model (Utiyama and Isahara, 2007; Wu and Wang, 2007):\np(u\u0304i|h\u0304i) = \u2211 e\u0304i p(u\u0304i|e\u0304i)p(e\u0304i|h\u0304i)\nThe number of entries in the baseline Urdu-toHindi phrase-table were approximately 254K."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 142
                            }
                        ],
                        "text": "\u2026for English-Hindi p(e\u0304i|h\u0304i), we estimated a Urdu-Hindi phrase-table p(u\u0304i|h\u0304i) using the well-known convolution model (Utiyama and Isahara, 2007; Wu and Wang, 2007):\np(u\u0304i|h\u0304i) = \u2211 e\u0304i p(u\u0304i|e\u0304i)p(e\u0304i|h\u0304i)\nThe number of entries in the baseline Urdu-toHindi phrase-table were approximately\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 187
                            }
                        ],
                        "text": "Given the phrase-table for Urdu-English p(\u016bi|\u0113i) and the phrase-table for English-Hindi p(\u0113i|h\u0304i), we estimated a Urdu-Hindi phrase-table p(\u016bi|h\u0304i) using the well-known convolution model (Utiyama and Isahara, 2007; Wu and Wang, 2007):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3681367,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "8942ce07381f2021ef5c91fd2d16c065b0315a17",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a novel method for phrase-based statistical machine translation based on the use of a pivot language. To translate between languages Ls and Lt with limited bilingual resources, we bring in a third language, L p, called the pivot language. For the language pairs Ls\u00a0\u2212\u00a0L p and L p\u00a0\u2212\u00a0Lt, there exist large bilingual corpora. Using only Ls\u00a0\u2212\u00a0L p and L p\u00a0\u2212\u00a0Lt bilingual corpora, we can build a translation model for Ls\u00a0\u2212\u00a0Lt. The advantage of this method lies in the fact that we can perform translation between Ls and Lt even if there is no bilingual corpus available for this language pair. Using BLEU as a metric, our pivot language approach significantly outperforms the standard model trained on a small bilingual corpus. Moreover, with a small Ls\u00a0\u2212\u00a0Lt bilingual corpus available, our method can further improve translation quality by using the additional Ls\u00a0\u2212\u00a0L p and L p\u00a0\u2212\u00a0Lt bilingual corpora."
            },
            "slug": "Pivot-language-approach-for-phrase-based-machine-Wu-Wang",
            "title": {
                "fragments": [],
                "text": "Pivot language approach for phrase-based statistical machine translation"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper proposes a novel method for phrase-based statistical machine translation based on the use of a pivot language, using BLEU as a metric, that significantly outperforms the standard model trained on a small bilingual corpus."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143832874"
                        ],
                        "name": "Ondrej Bojar",
                        "slug": "Ondrej-Bojar",
                        "structuredName": {
                            "firstName": "Ondrej",
                            "lastName": "Bojar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ondrej Bojar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2941179"
                        ],
                        "name": "Vojtech Diatka",
                        "slug": "Vojtech-Diatka",
                        "structuredName": {
                            "firstName": "Vojtech",
                            "lastName": "Diatka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vojtech Diatka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3269260"
                        ],
                        "name": "P. Rychl\u00fd",
                        "slug": "P.-Rychl\u00fd",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Rychl\u00fd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Rychl\u00fd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788237"
                        ],
                        "name": "P. Stran\u00e1k",
                        "slug": "P.-Stran\u00e1k",
                        "structuredName": {
                            "firstName": "Pavel",
                            "lastName": "Stran\u00e1k",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Stran\u00e1k"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081043"
                        ],
                        "name": "V\u00edt Suchomel",
                        "slug": "V\u00edt-Suchomel",
                        "structuredName": {
                            "firstName": "V\u00edt",
                            "lastName": "Suchomel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V\u00edt Suchomel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2211536"
                        ],
                        "name": "A. Tamchyna",
                        "slug": "A.-Tamchyna",
                        "structuredName": {
                            "firstName": "Ales",
                            "lastName": "Tamchyna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tamchyna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771298"
                        ],
                        "name": "Daniel Zeman",
                        "slug": "Daniel-Zeman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Zeman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Zeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 142
                            }
                        ],
                        "text": "Interpolation: We trained two phrase translation tables p(u\u0304i|e\u0304i) and p(e\u0304i|h\u0304i), from UrduEnglish (Indic corpus) and Hindi-English (HindEnCorp (Bojar et al., 2014)) bilingual corpora."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6561801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2744d46b583e3131fe4d52457cac487d0ebdf39",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present HindEnCorp, a parallel corpus of Hindi and English, and HindMonoCorp, a monolingual corpus of Hindi in their release version 0.5. Both corpora were collected from web sources and preprocessed primarily for the training of statistical machine translation systems. HindEnCorp consists of 274k parallel sentences (3.9 million Hindi and 3.8 million English tokens). HindMonoCorp amounts to 787 million tokens in 44 million sentences. Both the corpora are freely available for non-commercial research and their preliminary release has been used by numerous participants of the WMT 2014 shared translation task."
            },
            "slug": "HindEnCorp-Hindi-English-and-Hindi-only-Corpus-for-Bojar-Diatka",
            "title": {
                "fragments": [],
                "text": "HindEnCorp - Hindi-English and Hindi-only Corpus for Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Both the corpora are freely available for non-commercial research and their preliminary release has been used by numerous participants of the WMT 2014 shared translation task."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145938140"
                        ],
                        "name": "Nadir Durrani",
                        "slug": "Nadir-Durrani",
                        "structuredName": {
                            "firstName": "Nadir",
                            "lastName": "Durrani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nadir Durrani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277248"
                        ],
                        "name": "Alexander M. Fraser",
                        "slug": "Alexander-M.-Fraser",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Fraser",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander M. Fraser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360495"
                        ],
                        "name": "Helmut Schmid",
                        "slug": "Helmut-Schmid",
                        "structuredName": {
                            "firstName": "Helmut",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helmut Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 363,
                                "start": 360
                            }
                        ],
                        "text": "We trained our systems with the following settings: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM)\n(Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "We also trained OSM models over cluster-ids (?)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "We also trained OSM models over POS and morph tags."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "The lexically driven OSM model falls back to very small context sizes of two to three operations due to data sparsity."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 58
                            }
                        ],
                        "text": "Our baseline systems are based on the setup described in (Durrani et al., 2013b) that we used for the Eighth Workshop on Statistical Machine Translation (Bojar et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 45
                            }
                        ],
                        "text": "For the English-to-German system we added an OSM model over [pos, morph] (source:pos, target:morph) and for the Germanto-English system we added an OSM model over [morph,pos] (source:morph, target:pos), a configuration that was found to work best in our previous experiments (Birch et al., 2013)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "Table 2 shows gains from additionally using OSM models over POS/morph tags."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In order to create systems for the medical translation tasks, we used phrase-based Moses with exactly the same settings as for the news translation task, including the OSM (Durrani et al., 2011), and compound splitting Koehn and Knight (2003) for German source."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "Table 1 shows gains from adding target LM and OSM models over cluster-ids."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 145
                            }
                        ],
                        "text": "\u20262011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM)\n(Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8555345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9657cc862298e102413220743a8046ea5ec8c63",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "N-gram-based models co-exist with their phrase-based counterparts as an alternative SMT framework. Both techniques have pros and cons. While the N-gram-based framework provides a better model that captures both source and target contexts and avoids spurious phrasal segmentation, the ability to memorize and produce larger translation units gives an edge to the phrase-based systems during decoding, in terms of better search performance and superior selection of translation units. In this paper we combine N-grambased modeling with phrase-based decoding, and obtain the benefits of both approaches. Our experiments show that using this combination not only improves the search accuracy of the N-gram model but that it also improves the BLEU scores. Our system outperforms state-of-the-art phrase-based systems (Moses and Phrasal) and N-gram-based systems by a significant margin on German, French and Spanish to English translation tasks."
            },
            "slug": "Model-With-Minimal-Translation-Units,-But-Decode-Durrani-Fraser",
            "title": {
                "fragments": [],
                "text": "Model With Minimal Translation Units, But Decode With Phrases"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper combines N-grambased modeling with phrase-based decoding, and obtains the benefits of both approaches, and shows that using this combination not only improves the search accuracy of the N- gram model but that it also improves the BLEU scores."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152378023"
                        ],
                        "name": "Hieu T. Hoang",
                        "slug": "Hieu-T.-Hoang",
                        "structuredName": {
                            "firstName": "Hieu",
                            "lastName": "Hoang",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hieu T. Hoang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2539211"
                        ],
                        "name": "Alexandra Birch",
                        "slug": "Alexandra-Birch",
                        "structuredName": {
                            "firstName": "Alexandra",
                            "lastName": "Birch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandra Birch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102811815"
                        ],
                        "name": "Marcello Federico",
                        "slug": "Marcello-Federico",
                        "structuredName": {
                            "firstName": "Marcello",
                            "lastName": "Federico",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcello Federico"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895952"
                        ],
                        "name": "N. Bertoldi",
                        "slug": "N.-Bertoldi",
                        "structuredName": {
                            "firstName": "Nicola",
                            "lastName": "Bertoldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Bertoldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46898156"
                        ],
                        "name": "Brooke Cowan",
                        "slug": "Brooke-Cowan",
                        "structuredName": {
                            "firstName": "Brooke",
                            "lastName": "Cowan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brooke Cowan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2529583"
                        ],
                        "name": "Wade Shen",
                        "slug": "Wade-Shen",
                        "structuredName": {
                            "firstName": "Wade",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wade Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055137469"
                        ],
                        "name": "C. Moran",
                        "slug": "C.-Moran",
                        "structuredName": {
                            "firstName": "Christine",
                            "lastName": "Moran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Moran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983801"
                        ],
                        "name": "R. Zens",
                        "slug": "R.-Zens",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745899"
                        ],
                        "name": "Chris Dyer",
                        "slug": "Chris-Dyer",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Dyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Dyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143832874"
                        ],
                        "name": "Ondrej Bojar",
                        "slug": "Ondrej-Bojar",
                        "structuredName": {
                            "firstName": "Ondrej",
                            "lastName": "Bojar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ondrej Bojar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057195055"
                        ],
                        "name": "Alexandra Constantin",
                        "slug": "Alexandra-Constantin",
                        "structuredName": {
                            "firstName": "Alexandra",
                            "lastName": "Constantin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandra Constantin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082901914"
                        ],
                        "name": "Evan Herbst",
                        "slug": "Evan-Herbst",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Herbst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Evan Herbst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 83
                            }
                        ],
                        "text": "In order to create systems for the medical translation tasks, we used phrase-based Moses with exactly the same settings as for the news translation task, including the OSM (Durrani et al., 2011), and compound splitting Koehn and Knight (2003) for German source."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 128
                            }
                        ],
                        "text": "The inclusion of such an additional factor is trivial given the factored model implementation (Koehn and Hoang, 2007) of Moses (Koehn et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 794019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ee2eab4c298c1824a9fb8799ad8eed21be38d21",
            "isKey": false,
            "numCitedBy": 5929,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an open-source toolkit for statistical machine translation whose novel contributions are (a) support for linguistically motivated factors, (b) confusion network decoding, and (c) efficient data formats for translation models and language models. In addition to the SMT decoder, the toolkit also includes a wide variety of tools for training, tuning and applying the system to many translation tasks."
            },
            "slug": "Moses:-Open-Source-Toolkit-for-Statistical-Machine-Koehn-Hoang",
            "title": {
                "fragments": [],
                "text": "Moses: Open Source Toolkit for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An open-source toolkit for statistical machine translation whose novel contributions are support for linguistically motivated factors, confusion network decoding, and efficient data formats for translation models and language models."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1947267"
                        ],
                        "name": "Michel Galley",
                        "slug": "Michel-Galley",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Galley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michel Galley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 142
                            }
                        ],
                        "text": "\u2026an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM)\n(Durrani et al., 2013a) with 4 count-based supportive features,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 51
                            }
                        ],
                        "text": "Table 8: Hierarchical lexicalized reordering model (Galley and Manning, 2008)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 113
                            }
                        ],
                        "text": "Hierarchical lexicalized reordering model: We explored the use of the hierarchical lexicalized reordering model (Galley and Manning, 2008) in two variants: using the same orientations as our traditional model (monotone, discontinuous, swap), and one that distinguishes the discontinuous orientations\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 112
                            }
                        ],
                        "text": "Hierarchical lexicalized reordering model: We explored the use of the hierarchical lexicalized reordering model (Galley and Manning, 2008) in two variants: using the same orientations as our traditional model (monotone, discontinuous, swap), and one that distinguishes the discontinuous orientations to the left and right."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 305,
                                "start": 279
                            }
                        ],
                        "text": "We trained our systems with the following settings: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM) (Durrani et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2479536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efe0cf9a64f0e580a530cc16b79cfac5f4e61aca",
            "isKey": true,
            "numCitedBy": 358,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "While phrase-based statistical machine translation systems currently deliver state-of-the-art performance, they remain weak on word order changes. Current phrase reordering models can properly handle swaps between adjacent phrases, but they typically lack the ability to perform the kind of long-distance re-orderings possible with syntax-based systems. In this paper, we present a novel hierarchical phrase reordering model aimed at improving non-local reorderings, which seamlessly integrates with a standard phrase-based system with little loss of computational efficiency. We show that this model can successfully handle the key examples often used to motivate syntax-based systems, such as the rotation of a prepositional phrase around a noun phrase. We contrast our model with reordering models commonly used in phrase-based systems, and show that our approach provides statistically significant BLEU point gains for two language pairs: Chinese-English (+0.53 on MT05 and +0.71 on MT08) and Arabic-English (+0.55 on MT05)."
            },
            "slug": "A-Simple-and-Effective-Hierarchical-Phrase-Model-Galley-Manning",
            "title": {
                "fragments": [],
                "text": "A Simple and Effective Hierarchical Phrase Reordering Model"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel hierarchical phrase reordering model aimed at improving non-local reorderings, which seamlessly integrates with a standard phrase-based system with little loss of computational efficiency is presented."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143620134"
                        ],
                        "name": "Hieu Hoang",
                        "slug": "Hieu-Hoang",
                        "structuredName": {
                            "firstName": "Hieu",
                            "lastName": "Hoang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hieu Hoang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 94
                            }
                        ],
                        "text": "The inclusion of such an additional factor is trivial given the factored model implementation (Koehn and Hoang, 2007) of Moses (Koehn et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 87
                            }
                        ],
                        "text": "We used POS and morphological tags as additional factors in phrase translation models (Koehn and Hoang, 2007) for GermanEnglish language pairs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 95
                            }
                        ],
                        "text": "The inclusion of such an additional factor is trivial given the factored model implementation (Koehn and Hoang, 2007) of Moses (Koehn et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2330566,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "659f1f754954d093e684ead4842832052f7bf748",
            "isKey": false,
            "numCitedBy": 642,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an extension of phrase-based statistical machine translation models that enables the straight-forward integration of additional annotation at the word-level \u2014 may it be linguistic markup or automatically generated word classes. In a number of experiments we show that factored translation models lead to better translation performance, both in terms of automatic scores, as well as more grammatical coherence."
            },
            "slug": "Factored-Translation-Models-Koehn-Hoang",
            "title": {
                "fragments": [],
                "text": "Factored Translation Models"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "In a number of experiments, it is shown that factored translation models lead to better translation performance, both in terms of automatic scores, as well as more grammatical coherence."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2868598"
                        ],
                        "name": "Amittai Axelrod",
                        "slug": "Amittai-Axelrod",
                        "structuredName": {
                            "firstName": "Amittai",
                            "lastName": "Axelrod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amittai Axelrod"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137069"
                        ],
                        "name": "Xiaodong He",
                        "slug": "Xiaodong-He",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800422"
                        ],
                        "name": "Jianfeng Gao",
                        "slug": "Jianfeng-Gao",
                        "structuredName": {
                            "firstName": "Jianfeng",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianfeng Gao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 70
                            }
                        ],
                        "text": "We also experimented with modified MooreLewis (Moore and Lewis, 2010; Axelrod et al., 2011) data selection, using the EMEA corpus as the in-domain corpus (for the language model required in MML) and selecting from all the out-ofdomain data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10766958,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "396aabd694da04cdb846cb724ca9f866f345cbd5",
            "isKey": false,
            "numCitedBy": 526,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore efficient domain adaptation for the task of statistical machine translation based on extracting sentences from a large general-domain parallel corpus that are most relevant to the target domain. These sentences may be selected with simple cross-entropy based methods, of which we present three. As these sentences are not themselves identical to the in-domain data, we call them pseudo in-domain subcorpora. These subcorpora -- 1% the size of the original -- can then used to train small domain-adapted Statistical Machine Translation (SMT) systems which outperform systems trained on the entire corpus. Performance is further improved when we use these domain-adapted models in combination with a true in-domain model. The results show that more training data is not always better, and that best results are attained via proper domain-relevant data selection, as well as combining in- and general-domain systems during decoding."
            },
            "slug": "Domain-Adaptation-via-Pseudo-In-Domain-Data-Axelrod-He",
            "title": {
                "fragments": [],
                "text": "Domain Adaptation via Pseudo In-Domain Data Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The results show that more training data is not always better, and that best results are attained via proper domain-relevant data selection, as well as combining in- and general-domain systems during decoding."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768480"
                        ],
                        "name": "Liang Huang",
                        "slug": "Liang-Huang",
                        "structuredName": {
                            "firstName": "Liang",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145287425"
                        ],
                        "name": "David Chiang",
                        "slug": "David-Chiang",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Chiang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 149
                            }
                        ],
                        "text": "\u2026distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 158
                            }
                        ],
                        "text": ", 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 690,
                                "start": 678
                            }
                        ],
                        "text": "We trained our systems with the following settings: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM)\n(Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3510512,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebbd9e5fbc9c663d9dd60a08e1c3a09b15e65278",
            "isKey": false,
            "numCitedBy": 324,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Efficient decoding has been a fundamental problem in machine translation, especially with an integrated language model which is essential for achieving good translation quality. We develop faster approaches for this problem based on k-best parsing algorithms and demonstrate their effectiveness on both phrase-based and syntax-based MT systems. In both cases, our methods achieve significant speed improvements, often by more than a factor of ten, over the conventional beam-search method at the same levels of search error and translation accuracy."
            },
            "slug": "Forest-Rescoring:-Faster-Decoding-with-Integrated-Huang-Chiang",
            "title": {
                "fragments": [],
                "text": "Forest Rescoring: Faster Decoding with Integrated Language Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work develops faster approaches for efficient decoding based on k-best parsing algorithms and demonstrates their effectiveness on both phrase-based and syntax-based MT systems."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9567965"
                        ],
                        "name": "Shankar Kumar",
                        "slug": "Shankar-Kumar",
                        "structuredName": {
                            "firstName": "Shankar",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shankar Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716907"
                        ],
                        "name": "W. Byrne",
                        "slug": "W.-Byrne",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Byrne",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Byrne"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 120
                            }
                        ],
                        "text": ", 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 150
                            }
                        ],
                        "text": "\u2026Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11706155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2a68774f92d1e894cbbbef2c819e4592990eb4b",
            "isKey": false,
            "numCitedBy": 354,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation. This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance. We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings, word-to-word alignments from an MT system, and syntactic structure from parse-trees of source and target language sentences. We report the performance of the MBR decoders on a Chinese-to-English translation task. Our results show that MBR decoding can be used to tune statistical MT performance for specific loss functions."
            },
            "slug": "Minimum-Bayes-Risk-Decoding-for-Statistical-Machine-Kumar-Byrne",
            "title": {
                "fragments": [],
                "text": "Minimum Bayes-Risk Decoding for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The results show that MBR decoding can be used to tune statistical MT performance for specific loss functions, and a hierarchy of loss functions that incorporate different levels of linguistic information from word strings, word-to-word alignments from an MT system, and syntactic structure from parse-trees of source and target language sentences."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143767423"
                        ],
                        "name": "Robert C. Moore",
                        "slug": "Robert-C.-Moore",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Moore",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert C. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119117298"
                        ],
                        "name": "W. Lewis",
                        "slug": "W.-Lewis",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lewis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 47
                            }
                        ],
                        "text": "We also experimented with modified MooreLewis (Moore and Lewis, 2010; Axelrod et al., 2011) data selection, using the EMEA corpus as the in-domain corpus (for the language model required in MML) and selecting from all the out-ofdomain data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8170227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0482eeefa01c4cbf585f572c1fd4ed930ee222d2",
            "isKey": false,
            "numCitedBy": 547,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of selecting non-domain-specific language model training data to build auxiliary language models for use in tasks such as machine translation. Our approach is based on comparing the cross-entropy, according to domain-specific and non-domain-specifc language models, for each sentence of the text source used to produce the latter language model. We show that this produces better language models, trained on less data, than both random data selection and two other previously proposed methods."
            },
            "slug": "Intelligent-Selection-of-Language-Model-Training-Moore-Lewis",
            "title": {
                "fragments": [],
                "text": "Intelligent Selection of Language Model Training Data"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work addresses the problem of selecting non-domain-specific language model training data to build auxiliary language models for use in tasks such as machine translation by comparing the cross-entropy, according to domain-specific and non- domain-specifc language models, for each sentence of the text source used to produce the latter language model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518416"
                        ],
                        "name": "Holger Schwenk",
                        "slug": "Holger-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Holger Schwenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 144
                            }
                        ],
                        "text": "We trained domain-specific language models separately and then linearly interpolated them using SRILM with weights optimized on the tuning set (Schwenk and Koehn, 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10426366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08d207e48b990265cfd1693b68574c193b080cd5",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents methods to combine large language models trained from diverse text sources and applies them to a state-ofart French\u2013English and Arabic\u2013English machine translation system. We show gains of over 2 BLEU points over a strong baseline by using continuous space language models in re-ranking."
            },
            "slug": "Large-and-Diverse-Language-Models-for-Statistical-Schwenk-Koehn",
            "title": {
                "fragments": [],
                "text": "Large and Diverse Language Models for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "Methods to combine large language models trained from diverse text sources and applies them to a state-ofart French\u2013English and Arabic\u2013English machine translation system are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNLP"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38842528"
                        ],
                        "name": "Matt Post",
                        "slug": "Matt-Post",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "Post",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matt Post"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057788"
                        ],
                        "name": "M. Osborne",
                        "slug": "M.-Osborne",
                        "structuredName": {
                            "firstName": "Miles",
                            "lastName": "Osborne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Osborne"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 76
                            }
                        ],
                        "text": "We made use of the Urdu-English segment of the Indic multi-parallel corpus (Post et al., 2012) which contains roughly 87K sentence pairs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17338596,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fe6e965ecdeb0fd3e4d38a93f6010a317b843d1",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work has established the efficacy of Amazon's Mechanical Turk for constructing parallel corpora for machine translation research. We apply this to building a collection of parallel corpora between English and six languages from the Indian subcontinent: Bengali, Hindi, Malayalam, Tamil, Telugu, and Urdu. These languages are low-resource, under-studied, and exhibit linguistic phenomena that are difficult for machine translation. We conduct a variety of baseline experiments and analysis, and release the data to the community."
            },
            "slug": "Constructing-Parallel-Corpora-for-Six-Indian-via-Post-Callison-Burch",
            "title": {
                "fragments": [],
                "text": "Constructing Parallel Corpora for Six Indian Languages via Crowdsourcing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A collection of parallel corpora between English and six languages from the Indian subcontinent, which are low-resource, under-studied, and exhibit linguistic phenomena that are difficult for machine translation research are built."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@NAACL-HLT"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064348170"
                        ],
                        "name": "C. Buck",
                        "slug": "C.-Buck",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Buck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702066"
                        ],
                        "name": "Kenneth Heafield",
                        "slug": "Kenneth-Heafield",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Heafield",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Heafield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31965747"
                        ],
                        "name": "B. V. Ooyen",
                        "slug": "B.-V.-Ooyen",
                        "structuredName": {
                            "firstName": "Bas",
                            "lastName": "Ooyen",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. V. Ooyen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 80
                            }
                        ],
                        "text": "A full description of the pipeline, including a public data release, appears in Buck et al. (2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9709731,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e4fb17fff38a7834af5b4eaafcbbde02bf00975",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We contribute 5-gram counts and language models trained on the Common Crawl corpus, a collection over 9 billion web pages. This release improves upon the Google n-gram counts in two key ways: the inclusion of low-count entries and deduplication to reduce boilerplate. By preserving singletons, we were able to use Kneser-Ney smoothing to build large language models. This paper describes how the corpus was processed with emphasis on the problems that arise in working with data at this scale. Our unpruned Kneser-Ney English $5$-gram language model, built on 975 billion deduplicated tokens, contains over 500 billion unique n-grams. We show gains of 0.5-1.4 BLEU by using large language models to translate into various languages."
            },
            "slug": "N-gram-Counts-and-Language-Models-from-the-Common-Buck-Heafield",
            "title": {
                "fragments": [],
                "text": "N-gram Counts and Language Models from the Common Crawl"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This release improves upon the Google n-gram counts in two key ways: the inclusion of low-count entries and deduplication to reduce boilerplate, and the use of Kneser-Ney smoothing to build large language models."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145706651"
                        ],
                        "name": "Paul Baker",
                        "slug": "Paul-Baker",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144566715"
                        ],
                        "name": "Andrew Hardie",
                        "slug": "Andrew-Hardie",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Hardie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Hardie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2344182"
                        ],
                        "name": "Tony McEnery",
                        "slug": "Tony-McEnery",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "McEnery",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tony McEnery"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145435830"
                        ],
                        "name": "H. Cunningham",
                        "slug": "H.-Cunningham",
                        "structuredName": {
                            "firstName": "Hamish",
                            "lastName": "Cunningham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Cunningham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718590"
                        ],
                        "name": "R. Gaizauskas",
                        "slug": "R.-Gaizauskas",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gaizauskas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gaizauskas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15949005,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "37a56c59fce2b86689322b081f63e7f824a25b20",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes developments to date on the EMILLE Project (Enabling Minority Language Engineering) being carried out at the Universities of Lancaster and Sheffield. EMILLE was established to construct a 67 million word corpus of South Asian languages. In addition to undertaking this corpus construction, the project has had to address a number of related issues in the context of establishing a language engineering (LE) environment for South Asian language processing, such as translating 8-bit language data into Unicode and producing a number of basic LE tools. The development of tools on EMILLE has contributed to the on-going development of the LE architecture GATE."
            },
            "slug": "EMILLE,-A-67-Million-Word-Corpus-of-Indic-Data-and-Baker-Hardie",
            "title": {
                "fragments": [],
                "text": "EMILLE, A 67-Million Word Corpus of Indic Languages: Data Collection, Mark-up and Harmonisation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The paper describes developments to date on the EMILLE Project (Enabling Minority Language Engineering) being carried out at the Universities of Lancaster and Sheffield."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145938140"
                        ],
                        "name": "Nadir Durrani",
                        "slug": "Nadir-Durrani",
                        "structuredName": {
                            "firstName": "Nadir",
                            "lastName": "Durrani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nadir Durrani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 143
                            }
                        ],
                        "text": "Detailed results on Urdu-toHindi baseline and improvements obtained from\nusing transliteration and triangulated phrase-tables are presented in Durrani and Koehn (2014)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15541532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01bf10be5fd4d3d60dd3e2ce531f9eb3f959079c",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we improve Urdu\u2192Hindi English machine translation through triangulation and transliteration. First we built an Urdu\u2192Hindi SMT system by inducing triangulated and transliterated phrase-tables from Urdu\u2013English and Hindi\u2013English phrase translation models. We then use it to translate the Urdu part of the Urdu-English parallel data into Hindi, thus creating an artificial Hindi-English parallel data. Our phrase-translation strategies give an improvement of up to +3.35 BLEU points over a baseline Urdu\u2192Hindi system. The synthesized data improve Hindi\u2192English system by +0.35 and English\u2192Hindi system by +1.0 BLEU points."
            },
            "slug": "Improving-machine-translation-via-triangulation-and-Durrani-Koehn",
            "title": {
                "fragments": [],
                "text": "Improving machine translation via triangulation and transliteration"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This paper built an Urdu\u2192Hindi SMT system by inducing triangulated and transliterated phrase-tables from Urdu\u2013English and Hindi\u2013English phrase translation models and uses it to translate the Urdu part of theUrdu-English parallel data into Hindi, thus creating an artificial Hindi- English parallel data."
            },
            "venue": {
                "fragments": [],
                "text": "EAMT"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685771"
                        ],
                        "name": "P. Blunsom",
                        "slug": "P.-Blunsom",
                        "structuredName": {
                            "firstName": "Phil",
                            "lastName": "Blunsom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Blunsom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057788"
                        ],
                        "name": "M. Osborne",
                        "slug": "M.-Osborne",
                        "structuredName": {
                            "firstName": "Miles",
                            "lastName": "Osborne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Osborne"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 150
                            }
                        ],
                        "text": "\u2026sequence model (OSM)\n(Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 112
                            }
                        ],
                        "text": ", 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12277873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bef0b80cbe5ba692aecba09a4557bbe1e02b0e8a",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We advance the state-of-the-art for discriminatively trained machine translation systems by presenting novel probabilistic inference and search methods for synchronous grammars. By approximating the intractable space of all candidate translations produced by intersecting an ngram language model with a synchronous grammar, we are able to train and decode models incorporating millions of sparse, heterogeneous features. Further, we demonstrate the power of the discriminative training paradigm by extracting structured syntactic features, and achieving increases in translation performance."
            },
            "slug": "Probabilistic-Inference-for-Machine-Translation-Blunsom-Osborne",
            "title": {
                "fragments": [],
                "text": "Probabilistic Inference for Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The power of the discriminative training paradigm is demonstrated by extracting structured syntactic features, and achieving increases in translation performance, by approximating the intractable space of all candidate translations produced by intersecting an ngram language model with a synchronous grammar."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 45
                            }
                        ],
                        "text": "We computed the clusters with GIZA++\u2019s mkcls (Och, 1999) on the source and target side of the parallel training corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11533588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e7560f48806d56612349c2ab0086ad0cff986f4",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In statistical natural language processing we always face the problem of sparse data. One way to reduce this problem is to group words into equivalence classes which is a standard method in statistical language modeling. In this paper we describe a method to determine bilingual word classes suitable for statistical machine translation. We develop an optimization criterion based on a maximum-likelihood approach and describe a clustering algorithm. We will show that the usage of the bilingual word classes we get can improve statistical machine translation."
            },
            "slug": "An-Efficient-Method-for-Determining-Bilingual-Word-Och",
            "title": {
                "fragments": [],
                "text": "An Efficient Method for Determining Bilingual Word Classes"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A method to determine bilingual word classes suitable for statistical machine translation is described, an optimization criterion based on a maximum-likelihood approach is developed and a clustering algorithm is described."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702066"
                        ],
                        "name": "Kenneth Heafield",
                        "slug": "Kenneth-Heafield",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Heafield",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Heafield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1837145"
                        ],
                        "name": "Ivan Pouzyrevsky",
                        "slug": "Ivan-Pouzyrevsky",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Pouzyrevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivan Pouzyrevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144797264"
                        ],
                        "name": "J. Clark",
                        "slug": "J.-Clark",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 67
                            }
                        ],
                        "text": "We built unpruned modified Kneser-Ney language models using lmplz (Heafield et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2561041,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "774e560a2cadcb84f4b1def7b152e5398b062efb",
            "isKey": false,
            "numCitedBy": 557,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an efficient algorithm to estimate large modified Kneser-Ney models including interpolation. Streaming and sorting enables the algorithm to scale to much larger models by using a fixed amount of RAM and variable amount of disk. Using one machine with 140 GB RAM for 2.8 days, we built an unpruned model on 126 billion tokens. Machine translation experiments with this model show improvement of 0.8 BLEU point over constrained systems for the 2013 Workshop on Machine Translation task in three language pairs. Our algorithm is also faster for small models: we estimated a model on 302 million tokens using 7.7% of the RAM and 14.0% of the wall time taken by SRILM. The code is open source as part of KenLM."
            },
            "slug": "Scalable-Modified-Kneser-Ney-Language-Model-Heafield-Pouzyrevsky",
            "title": {
                "fragments": [],
                "text": "Scalable Modified Kneser-Ney Language Model Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "An efficient algorithm to estimate large modified Kneser-Ney models including interpolation using Streaming and sorting enables the algorithm to scale to much larger models by using a fixed amount of RAM and variable amount of disk."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755162"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259100"
                        ],
                        "name": "B. Haddow",
                        "slug": "B.-Haddow",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Haddow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Haddow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 273
                            }
                        ],
                        "text": "\u2026limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 317,
                                "start": 293
                            }
                        ],
                        "text": ", 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1675316,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "6f0fc52cdb399dd47efb03639db13b821fb839b1",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "PCT No. PCT/JP90/01270 Sec. 371 Date Apr. 1, 1992 Sec. 102(e) Date Apr. 1, 1992 PCT Filed Oct. 2, 1990 PCT Pub. No. WO91/04751 PCT Pub. Date Apr. 18, 1991.A drug for preventing the absorption of food materials dissolved during digestion, a drug for preventing obesity, a drug for treating hyperlipemia, a drug for treating diabetes mellitus, and a drug for preventing constipation, wherein the flocculant and other auxiliary additives at request, are coated with the aquatic enteric material."
            },
            "slug": "Edinburgh\u2019s-Submission-to-all-Tracks-of-the-WMT-and-Koehn-Haddow",
            "title": {
                "fragments": [],
                "text": "Edinburgh\u2019s Submission to all Tracks of the WMT 2009 Shared Task with Reordering and Speed Improvements to Moses"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A drug for preventing the absorption of food materials dissolved during digestion, adrug for preventing obesity, a drug for treating hyperlipemia, aDrug for treating diabetes mellitus, and a drugFor preventing constipation, wherein the flocculant and other auxiliary additives at request, are coated with the aquatic enteric material."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@EACL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737616"
                        ],
                        "name": "D. Litman",
                        "slug": "D.-Litman",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Litman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Litman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32057282"
                        ],
                        "name": "J. Hirschberg",
                        "slug": "J.-Hirschberg",
                        "structuredName": {
                            "firstName": "Julia",
                            "lastName": "Hirschberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hirschberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730911"
                        ],
                        "name": "M. Swerts",
                        "slug": "M.-Swerts",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Swerts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swerts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123937952"
                        ],
                        "name": "Scott Miller",
                        "slug": "Scott-Miller",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744313"
                        ],
                        "name": "L. Ramshaw",
                        "slug": "L.-Ramshaw",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Ramshaw",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ramshaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732071"
                        ],
                        "name": "R. Weischedel",
                        "slug": "R.-Weischedel",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Weischedel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weischedel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115666502"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207783692,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "566eb7be43b8a2b2daff82b03711098a84859b2a",
            "isKey": false,
            "numCitedBy": 2173,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Association-for-Computational-Linguistics-Litman-Hirschberg",
            "title": {
                "fragments": [],
                "text": "Association for Computational Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702066"
                        ],
                        "name": "Kenneth Heafield",
                        "slug": "Kenneth-Heafield",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Heafield",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Heafield"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 209
                            }
                        ],
                        "text": "We trained our systems with the following settings: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM) (Durrani et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 142
                            }
                        ],
                        "text": "\u2026length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 65
                            }
                        ],
                        "text": "We therefore created a filter that operates directly on files in KenLM trie binary format, preserving only n-grams whose words all appear in the target side vocabulary of at least one source sentence."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 205
                            }
                        ],
                        "text": "We trained our systems with the following settings: a maximum sentence length of 80, growdiag-final-and symmetrization of GIZA++ alignments, an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, hierarchical lexicalized reordering (Galley and Manning, 2008), a lexicallydriven 5-gram operation sequence model (OSM)\n(Durrani et al., 2013a) with 4 count-based supportive features, sparse domain indicator, phrase length, and count bin features (Blunsom and Osborne, 2008; Chiang et al., 2009), a distortion limit of 6, maximum phrase-length of 5, 100-best translation options, Minimum Bayes Risk decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), with a stack-size of 1000 during tuning and 5000 during test and the noreordering-over-punctuation heuristic (Koehn and Haddow, 2009)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8313873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "883d1d06d857a85a0e64bb19f0b17d56f2cc9d7b",
            "isKey": false,
            "numCitedBy": 1173,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present KenLM, a library that implements two data structures for efficient language model queries, reducing both time and memory costs. The Probing data structure uses linear probing hash tables and is designed for speed. Compared with the widely-used SRILM, our Probing model is 2.4 times as fast while using 57% of the memory. The Trie data structure is a trie with bit-level packing, sorted records, interpolation search, and optional quantization aimed at lower memory consumption. Trie simultaneously uses less memory than the smallest lossless baseline and less CPU than the fastest baseline. Our code is open-source, thread-safe, and integrated into the Moses, cdec, and Joshua translation systems. This paper describes the several performance techniques used and presents benchmarks against alternative implementations."
            },
            "slug": "KenLM:-Faster-and-Smaller-Language-Model-Queries-Heafield",
            "title": {
                "fragments": [],
                "text": "KenLM: Faster and Smaller Language Model Queries"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "KenLM is a library that implements two data structures for efficient language model queries, reducing both time and memory costs and is integrated into the Moses, cdec, and Joshua translation systems."
            },
            "venue": {
                "fragments": [],
                "text": "WMT@EMNLP"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745899"
                        ],
                        "name": "Chris Dyer",
                        "slug": "Chris-Dyer",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Dyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Dyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2730654"
                        ],
                        "name": "Victor Chahuneau",
                        "slug": "Victor-Chahuneau",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Chahuneau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Chahuneau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144365875"
                        ],
                        "name": "Noah A. Smith",
                        "slug": "Noah-A.-Smith",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noah A. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 86
                            }
                        ],
                        "text": "Fast align: In preliminary experiments, we compared the fast word alignment method by Dyer et al. (2013) against our traditional use of GIZA++. Results are quite mixed (Table 7), ranging from a gain of +.35 for Russian-English to a loss of \u2013.19 for Czech-English."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 50
                            }
                        ],
                        "text": "Table 7: Comparison of fast word alignment method (Dyer et al., 2013) against GIZA++ (WMT 2013 data condition, test on newstest2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8476273,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b5e31257f01aba987f16e175a3e49e00a5bd3bb",
            "isKey": false,
            "numCitedBy": 819,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple log-linear reparameterization of IBM Model 2 that overcomes problems arising from Model 1\u2019s strong assumptions and Model 2\u2019s overparameterization. Efficient inference, likelihood evaluation, and parameter estimation algorithms are provided. Training the model is consistently ten times faster than Model 4. On three large-scale translation tasks, systems built using our alignment model outperform IBM Model 4. An open-source implementation of the alignment model described in this paper is available from http://github.com/clab/fast align ."
            },
            "slug": "A-Simple,-Fast,-and-Effective-Reparameterization-of-Dyer-Chahuneau",
            "title": {
                "fragments": [],
                "text": "A Simple, Fast, and Effective Reparameterization of IBM Model 2"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A simple log-linear reparameterization of IBM Model 2 that overcomes problems arising from Model 1\u2019's strong assumptions and Model 2\u2019s overparameterization is presented."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49604675"
                        ],
                        "name": "Philipp Koehn",
                        "slug": "Philipp-Koehn",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Koehn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Koehn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102811815"
                        ],
                        "name": "Marcello Federico",
                        "slug": "Marcello-Federico",
                        "structuredName": {
                            "firstName": "Marcello",
                            "lastName": "Federico",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcello Federico"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2529583"
                        ],
                        "name": "Wade Shen",
                        "slug": "Wade-Shen",
                        "structuredName": {
                            "firstName": "Wade",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wade Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895952"
                        ],
                        "name": "N. Bertoldi",
                        "slug": "N.-Bertoldi",
                        "structuredName": {
                            "firstName": "Nicola",
                            "lastName": "Bertoldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Bertoldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143832874"
                        ],
                        "name": "Ondrej Bojar",
                        "slug": "Ondrej-Bojar",
                        "structuredName": {
                            "firstName": "Ondrej",
                            "lastName": "Bojar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ondrej Bojar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46898156"
                        ],
                        "name": "Brooke Cowan",
                        "slug": "Brooke-Cowan",
                        "structuredName": {
                            "firstName": "Brooke",
                            "lastName": "Cowan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brooke Cowan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745899"
                        ],
                        "name": "Chris Dyer",
                        "slug": "Chris-Dyer",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Dyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Dyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152378023"
                        ],
                        "name": "Hieu T. Hoang",
                        "slug": "Hieu-T.-Hoang",
                        "structuredName": {
                            "firstName": "Hieu",
                            "lastName": "Hoang",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hieu T. Hoang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983801"
                        ],
                        "name": "R. Zens",
                        "slug": "R.-Zens",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057195055"
                        ],
                        "name": "Alexandra Constantin",
                        "slug": "Alexandra-Constantin",
                        "structuredName": {
                            "firstName": "Alexandra",
                            "lastName": "Constantin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandra Constantin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082901914"
                        ],
                        "name": "Evan Herbst",
                        "slug": "Evan-Herbst",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Herbst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Evan Herbst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055137469"
                        ],
                        "name": "C. Moran",
                        "slug": "C.-Moran",
                        "structuredName": {
                            "firstName": "Christine",
                            "lastName": "Moran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Moran"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61651780,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99e8d34817ae10d7304521e89c5fbf908b9d856b",
            "isKey": false,
            "numCitedBy": 543,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Open-Source-Toolkit-for-Statistical-Machine-Models-Koehn-Federico",
            "title": {
                "fragments": [],
                "text": "Open Source Toolkit for Statistical Machine Translation: Factored Translation Models and Lattice Decoding"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "001 New Features for Statistical Machine Translation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "inburgh SLT and MT system description for the IWSLT 2013 evaluation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 10 th International Workshop on Spoken Language Translation"
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 142
                            }
                        ],
                        "text": "Interpolation: We trained two phrase translation tables p(u\u0304i|e\u0304i) and p(e\u0304i|h\u0304i), from UrduEnglish (Indic corpus) and Hindi-English (HindEnCorp (Bojar et al., 2014)) bilingual corpora."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 142
                            }
                        ],
                        "text": "Interpolation: We trained two phrase translation tables p(\u016bi|\u0113i) and p(\u0113i|h\u0304i), from UrduEnglish (Indic corpus) and Hindi-English (HindEnCorp (Bojar et al., 2014)) bilingual corpora."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "HindiEnglish and Hindi-only Corpus for Machine"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 276
                            }
                        ],
                        "text": "For the English-to-German system we added an OSM model over [pos, morph] (source:pos, target:morph) and for the Germanto-English system we added an OSM model over [morph,pos] (source:morph, target:pos), a configuration that was found to work best in our previous experiments (Birch et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "inburgh SLT and MT system description for the IWSLT 2013 evaluation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 10 th International Workshop on Spoken Language Translation"
            },
            "year": 2013
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 31
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 43,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Edinburgh\u2019s-Phrase-based-Machine-Translation-for-Durrani-Haddow/97cedf99252026f58e8154bc61d49cf885d42030?sort=total-citations"
}