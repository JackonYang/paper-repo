{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144003169"
                        ],
                        "name": "Claire Grover",
                        "slug": "Claire-Grover",
                        "structuredName": {
                            "firstName": "Claire",
                            "lastName": "Grover",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claire Grover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1876168"
                        ],
                        "name": "A. Lascarides",
                        "slug": "A.-Lascarides",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Lascarides",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lascarides"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 18
                            }
                        ],
                        "text": "Recently, though, Grover and Lascarides (2001) have demonstrated that a useful system can be built recovering full logical forms for around 30% of sentences from a sample of the Medline corpus, using a modified version of the ANLT full grammar but backing off to PoS tags for unknown words."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Recently, though,  Grover and Lascarides (2001)  have demonstrated that a useful system can be built recovering full logical forms for around 30% of sentences from a sample of the Medline corpus, using a modified version of the ANLT full grammar but backing off to PoS tags for unknown words."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14746127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f13393e0b73efc49fcece2dc7fd6ca1234ea4361",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the use of XML tokenisation, tagging and mark-up tools to prepare a corpus for parsing. Our techniques are generally applicable but here we focus on parsing Medline abstracts with the ANLT wide-coverage grammar. Hand-crafted grammars inevitably lack coverage but many coverage failures are due to inadequacies of their lexicons. We describe a method of gaining a degree of robustness by interfacing POS tag information with the existing lexicon. We also show that XML tools provide a sophisticated approach to pre-processing, helping to ameliorate the 'messiness' in real language data and improve parse performance."
            },
            "slug": "XML-Based-Data-Preparation-for-Robust-Deep-Parsing-Grover-Lascarides",
            "title": {
                "fragments": [],
                "text": "XML-Based Data Preparation for Robust Deep Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A method of gaining a degree of robustness by interfacing POS tag information with the existing lexicon is described and it is shown that XML tools provide a sophisticated approach to pre-processing, helping to ameliorate the 'messiness' in real language data and improve parse performance."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145693410"
                        ],
                        "name": "Ted Briscoe",
                        "slug": "Ted-Briscoe",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Briscoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Briscoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708726"
                        ],
                        "name": "John A. Carroll",
                        "slug": "John-A.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John A. Carroll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074471847"
                        ],
                        "name": "Jonathan Graham",
                        "slug": "Jonathan-Graham",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Graham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Graham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15379653"
                        ],
                        "name": "Ann A. Copestake",
                        "slug": "Ann-A.-Copestake",
                        "structuredName": {
                            "firstName": "Ann",
                            "lastName": "Copestake",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ann A. Copestake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 121
                            }
                        ],
                        "text": "Measured in this way our results appear broadly competitive with those produced by state-of-the-art statistical parsers (Briscoe et al., 2002a)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 147
                            }
                        ],
                        "text": "\u2026tasks that we want to use the RADISP system for, such as parsing of highly-ranked documents relevant to queries in open-domain questionanswering (Briscoe et al., 2002b), it is useful to be able\nto output an underspecified semantic representation, in our case robust minimal recursion semantics\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 145
                            }
                        ],
                        "text": "Our system achieves a F -score of 76.5% on a manually constructed test suite of 500 sentences from the Susanne corpus (see Carroll et al., 1998; Briscoe et al.,\n2002a for further details)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15951704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb5b13c348c973cd17e94ae0b21a9fa8c05f64fc",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe extensions to a scheme for evaluating parse selection accuracy based on named grammatical relations between lemmatised lexical heads. The scheme is intended to directly reflect the task of recovering grammatical and logical relations, rather than more arbitrary details of tree topology. There is a manually annotated test suite of 500 sentences which has been used by several groups to perform evaluations. We are developing software to create larger test suites automatically from existing treebanks. We are considering alternative relational annotations which draw a clearer distinction between grammatical and logical relations in order to overcome limitations of the current proposal."
            },
            "slug": "Relational-evaluation-schemes-Briscoe-Carroll",
            "title": {
                "fragments": [],
                "text": "Relational evaluation schemes"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "Extensions to a scheme for evaluating parse selection accuracy based on named grammatical relations between lemmatised lexical heads are described, considering alternative relational annotations which draw a clearer distinction between grammatical and logical relations in order to overcome limitations of the current proposal."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8184544"
                        ],
                        "name": "C. D. Marcken",
                        "slug": "C.-D.-Marcken",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Marcken",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Marcken"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 851638,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18dde31c2716b0bf10a35f334ed24af4e4e37fa5",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a rapid and robust parsing system currently used to learn from large bodies of unedited text. The system contains a multivalued part-of-speech disambiguator and a novel parser employing bottom-up recognition to find the constituent phrases of larger structures that might be too difficult to analyze. The results of applying the disambiguator and parser to large sections of the Lancaster/Oslo-Bergen corpus are presented."
            },
            "slug": "Parsing-the-LOB-Corpus-Marcken",
            "title": {
                "fragments": [],
                "text": "Parsing the LOB Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A rapid and robust parsing system currently used to learn from large bodies of unedited text, which contains a multivalued part-of-speech disambiguator and a novel parser employing bottom-up recognition to find the constituent phrases of larger structures that might be too difficult to analyze."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708726"
                        ],
                        "name": "John A. Carroll",
                        "slug": "John-A.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John A. Carroll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145702640"
                        ],
                        "name": "Guido Minnen",
                        "slug": "Guido-Minnen",
                        "structuredName": {
                            "firstName": "Guido",
                            "lastName": "Minnen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guido Minnen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145693410"
                        ],
                        "name": "Ted Briscoe",
                        "slug": "Ted-Briscoe",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Briscoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Briscoe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 123
                            }
                        ],
                        "text": "Our system achieves a F -score of 76.5% on a manually constructed test suite of 500 sentences from the Susanne corpus (see Carroll et al., 1998; Briscoe et al.,\n2002a for further details)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 203
                            }
                        ],
                        "text": "We originally proposed transforming trees to sets of named grammatical relations (GRs) of the type illustrated in Figure 2 above as a technique for facilitating fine-grained cross-system evaluation (see Carroll et al., 1998 where a detailed specification of the representation is also given)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 180
                            }
                        ],
                        "text": "The GR representation stays deliberately close to surface syntax, although it does encode some logical / underlying relations via extra parameters on specific named relations (see Carroll et al., 1998 for details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "497c12316650452a676d602aa51619f9892323bf",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Research into the automatic acquisition of lexical information from corpora is starting to produce large-scale computational lexicons containing data on the relative frequencies of subcategorisation alternatives for individual verbal predicates. However, the empirical question of whether this type of frequency information can in practice improve the accuracy of a statistical parser has not yet been answered. In this paper we describe an experiment with a wide-coverage statistical grammar and parser for English and subcategorisation frequencies acquired from ten million words of text which shows that this information can significantly improve parse accuracy."
            },
            "slug": "Can-Subcategorisation-Probabilities-Help-a-Parser-Carroll-Minnen",
            "title": {
                "fragments": [],
                "text": "Can Subcategorisation Probabilities Help a Statistical Parser"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An experiment with a wide-coverage statistical grammar and parser for English and subcategorisation frequencies acquired from ten million words of text shows that this information can significantly improve parse accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "VLC@COLING/ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59702881,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99328d4b34d1ac02252258a9437b8b2c1acdb92c",
            "isKey": false,
            "numCitedBy": 773,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we first present a dependency-based method for parser evaluation. We then use the method to evaluate a broad-coverage parser, called MINIPAR, with the SUSANNE corpus. The method allows us to evaluate not only the overall performance of the parser, but also its performance with respect to different grammatical relationships and phenomena. The evaluation results show that MINIPAR is able to cover about 79% of the dependency relationships in the SUSANNE corpus with about 89% precision."
            },
            "slug": "Dependency-Based-Evaluation-of-Minipar-Lin",
            "title": {
                "fragments": [],
                "text": "Dependency-Based Evaluation of Minipar"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A dependency-based method for parser evaluation is presented and a broad-coverage parser, called MINIPAR, is evaluated with the SUSANNE corpus."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34730654"
                        ],
                        "name": "J. Caroll",
                        "slug": "J.-Caroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Caroll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Caroll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145693410"
                        ],
                        "name": "Ted Briscoe",
                        "slug": "Ted-Briscoe",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Briscoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Briscoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143661868"
                        ],
                        "name": "A. Sanfilippo",
                        "slug": "A.-Sanfilippo",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Sanfilippo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sanfilippo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our system achieves a F -score of 76.5% on a manually constructed test suite of 500 sentences from the Susanne corpus (see  Carroll et al., 1998;  Briscoe et al., raw text"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We have argued elsewhere that an evaluation scheme measuring recovery of grammatical relations between lexical heads has a number of advantages over one measuring tree similarity ( Carroll, Briscoe and Sanfilippo, 1998 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "However, reliance on lexical information leads to domain dependence so our broad approach is to attempt to seed the RADISP system with such information acquired from automatic parses obtained without it, as with our approach to subcategorisation ( Carroll, Minnen and Briscoe, 1998;  Korhonen, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The GR representation stays deliberately close to surface syntax, although it does encode some logical / underlying relations via extra parameters on specific named relations (see  Carroll et al., 1998  for details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We originally proposed transforming trees to sets of named grammatical relations (GRs) of the type illustrated in Figure 2 above as a technique for facilitating fine-grained cross-system evaluation (see  Carroll et al., 1998  where a detailed specification of the representation is also given)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7042755,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1bfc525e48e3dab1087b7308da3ba462d6fc382c",
            "isKey": false,
            "numCitedBy": 290,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a critical overview of the state-of-the-art in parser evaluation methodologies and metrics. A discussion of their relative strengths and weaknesses motivates a new\u2014and we claim more informative and generally applicable\u2014technique of measuring parser accuracy, based on the use of grammatical relations. We conclude with some preliminary results of experiments in which we use this new scheme to evaluate a robust parser of English."
            },
            "slug": "Parser-evaluation:-a-survey-and-a-new-proposal-Caroll-Briscoe",
            "title": {
                "fragments": [],
                "text": "Parser evaluation: a survey and a new proposal"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new\u2014and reportedly more informative and generally applicable\u2014technique of measuring parser accuracy, based on the use of grammatical relations, is claimed to be applicable to parser accuracy evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145693410"
                        ],
                        "name": "Ted Briscoe",
                        "slug": "Ted-Briscoe",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Briscoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Briscoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708726"
                        ],
                        "name": "John A. Carroll",
                        "slug": "John-A.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John A. Carroll"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 165
                            }
                        ],
                        "text": "The manually-developed wide-coverage tag sequence grammar utilised in this version of the parser consists of about 400 unification-based phrase structure rules (see Briscoe and Carroll, 1995 for further details)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13505514,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "802d281c4a2cd213248a2d9ada71c55b52752d4a",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach to robust domain-independent syntactic parsing of unrestricted naturally-occurring (English) input. The technique involves parsing sequences of part-of-speech and punctuation labels using a unification-based grammar coupled with a probabilistic LR parser. We describe the coverage of several corpora using this grammar and report the results of a parsing experiment using probabilities derived from bracketed training data. We report the first substantial experiments to assess the contribution of punctuation to deriving an accurate syntactic analysis, by parsing identical texts both with and without naturally-occurring punctuation marks."
            },
            "slug": "Developing-and-Evaluating-a-Probabilistic-LR-Parser-Briscoe-Carroll",
            "title": {
                "fragments": [],
                "text": "Developing and Evaluating a Probabilistic LR Parser of Part-of-Speech and Punctuation Labels"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The first substantial experiments to assess the contribution of punctuation to deriving an accurate syntactic analysis are reported, by parsing identical texts both with and without naturally-occurring punctuation marks."
            },
            "venue": {
                "fragments": [],
                "text": "IWPT"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37590811"
                        ],
                        "name": "B. Kiefer",
                        "slug": "B.-Kiefer",
                        "structuredName": {
                            "firstName": "Bernd",
                            "lastName": "Kiefer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kiefer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35698498"
                        ],
                        "name": "Hans-Ulrich Krieger",
                        "slug": "Hans-Ulrich-Krieger",
                        "structuredName": {
                            "firstName": "Hans-Ulrich",
                            "lastName": "Krieger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hans-Ulrich Krieger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708726"
                        ],
                        "name": "John A. Carroll",
                        "slug": "John-A.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John A. Carroll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145804005"
                        ],
                        "name": "Robert Malouf",
                        "slug": "Robert-Malouf",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Malouf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Malouf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The criteria are partial parse probability and a preference for longer but nonlexical partial parse combinations (Kiefer et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5260380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74e9402f31fb4d72e8174aff27341220081f1543",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes new and improved techniques which help a unification-based parser to process input efficiently and robustly. In combination these methods result in a speed-up in parsing time of more than an order of magnitude. The methods are correct in the sense that none of them rule out legal rule applications."
            },
            "slug": "A-Bag-of-Useful-Techniques-for-Efficient-and-Robust-Kiefer-Krieger",
            "title": {
                "fragments": [],
                "text": "A Bag of Useful Techniques for Efficient and Robust Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "New and improved techniques which help a unification-based parser to process input efficiently and robustly are described, resulting in a speed-up in parsing time of more than an order of magnitude."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145561618"
                        ],
                        "name": "A. Yeh",
                        "slug": "A.-Yeh",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Yeh",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yeh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 72
                            }
                        ],
                        "text": "The system has also been used in experiments in information extraction (Yeh, 2000) and as a component of an open-domain questionanswering (Briscoe, Copestake and Teufel, 2002b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2960680,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a725cfeda249eff372ae1262c1764d2b6cfa54c1",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Grammatical relationships (GRs) form an important level of natural language processing, but different sets of GRs are useful for different purposes. Therefore, one may often only have time to obtain a small training corpus with the desired GR annotations. To boost the performance from using such a small training corpus on a transformation rule learner, we use existing systems that find related types of annotations."
            },
            "slug": "Using-Existing-Systems-to-Supplement-Small-Amounts-Yeh",
            "title": {
                "fragments": [],
                "text": "Using Existing Systems to Supplement Small Amounts of Annotated Grammatical Relations Training Data"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work uses existing systems that find related types of annotations to boost the performance from using a small training corpus on a transformation rule learner."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35551590"
                        ],
                        "name": "Steven P. Abney",
                        "slug": "Steven-P.-Abney",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Abney",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven P. Abney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 313,
                                "start": 274
                            }
                        ],
                        "text": "The alternative approach to robust parsing, favoured by most commercial and academic information extraction systems, is to use (cascaded) finitestate transducers, often augmented with heuristics such as the longest match preference, to construct partial phrasallevel parses (e.g. Appelt et al., 1995; Abney, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 286
                            }
                        ],
                        "text": "\u2026approach to robust parsing, favoured by most commercial and academic information extraction systems, is to use (cascaded) finitestate transducers, often augmented with heuristics such as the longest match preference, to construct partial phrasallevel parses (e.g. Appelt et al., 1995; Abney, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15439037,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "217b6c4febec11de7dcd50aaaa5b084821567611",
            "isKey": false,
            "numCitedBy": 274,
            "numCiting": 106,
            "paperAbstract": {
                "fragments": [],
                "text": "The initial impetus for the current popularity of statistical methods in computational linguistics was provided in large part by the papers on part-of-speech tagging by Church (1988), DeRose (1988), and Garside (1987b). In contradiction to common wisdom, these taggers showed that it was indeed possible to carve part-of-speech disambiguation out of the apparently monolithic problem of natural language understanding, and solve it with impressive accuracy."
            },
            "slug": "Part-of-Speech-Tagging-and-Partial-Parsing-Abney",
            "title": {
                "fragments": [],
                "text": "Part-of-Speech Tagging and Partial Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "The initial impetus for the current popularity of statistical methods in computational linguistics was provided in large part by the papers on part-of-speech tagging by Church, DeRose, and Garside, which showed that it was indeed possible to carve part- of-speech disambiguation out of the apparently monolithic problem of natural language understanding, and solve it with impressive accuracy."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145693410"
                        ],
                        "name": "Ted Briscoe",
                        "slug": "Ted-Briscoe",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Briscoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Briscoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708726"
                        ],
                        "name": "John A. Carroll",
                        "slug": "John-A.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John A. Carroll"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, very little work has been undertaken with the ANLT full grammar since the initial experiment parsing dictionary definitions ( Briscoe and Carroll, 1993 ) because this grammar requires accurate subcategorisation information for all lexical items to function effectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The lattice of lemma+affix tag forms is passed to a modified version of the probabilistic generalised LR parser ( Briscoe and Carroll, 1993;  Inui et al., 1997), augmented with limited lexical information encoding the probability of some phrasal verb combinations (i.e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 134
                            }
                        ],
                        "text": "However, very little work has been undertaken with the ANLT full grammar since the initial experiment parsing dictionary definitions (Briscoe and Carroll, 1993) because this grammar requires accurate subcategorisation information for all lexical items to function effectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 113
                            }
                        ],
                        "text": "The lattice of lemma+affix tag forms is passed to a modified version of the probabilistic generalised LR parser (Briscoe and Carroll, 1993; Inui et al., 1997), augmented with limited lexical information encoding the probability\nof some phrasal verb combinations (i.e. verb plus preposition/particle)\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2220955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ad8e98574a275930bf04a477ce3532fd13c503c",
            "isKey": false,
            "numCitedBy": 283,
            "numCiting": 106,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe work toward the construction of a very wide-coverage probabilistic parsing system for natural language (NL), based on LR parsing techniques. The system is intended to rank the large number of syntactic analyses produced by NL grammars according to the frequency of occurrence of the individual rules deployed in each analysis. We discuss a fully automatic procedure for constructing an LR parse table from a unification-based grammar formalism, and consider the suitability of alternative LALR(1) parse table construction methods for large grammars. The parse table is used as the basis for two parsers; a user-driven interactive system that provides a computationally tractable and labor-efficient method of supervised training of the statistical information required to drive the probabilistic parser. The latter is constructed by associating probabilities with the LR parse table directly. This technique is superior to parsers based on probabilistic lexical tagging or probabilistic context-free grammar because it allows for a more context-dependent probabilistic language model, as well as use of a more linguistically adequate grammar formalism. We compare the performance of an optimized variant of Tomita's (1987) generalized LR parsing algorithm to an (efficiently indexed and optimized) chart parser. We report promising results of a pilot study training on 150 noun definitions from the Longman Dictionary of Contemporary English (LDOCE) and retesting on these plus a further 55 definitions. Finally, we discuss limitations of the current system and possible extensions to deal with lexical (syntactic and semantic) frequency of occurrence."
            },
            "slug": "Generalized-Probabilistic-LR-Parsing-of-Natural-Briscoe-Carroll",
            "title": {
                "fragments": [],
                "text": "Generalized Probabilistic LR Parsing of Natural Language (Corpora) with Unification-Based Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "The construction of a very wide-coverage probabilistic parsing system for natural language (NL) based on LR parsing techniques, intended to rank the large number of syntactic analyses produced by NL grammars according to the frequency of occurrence of the individual rules deployed in each analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082871039"
                        ],
                        "name": "Eirik Hektoen",
                        "slug": "Eirik-Hektoen",
                        "structuredName": {
                            "firstName": "Eirik",
                            "lastName": "Hektoen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eirik Hektoen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 140
                            }
                        ],
                        "text": "The lattice of lemma+affix tag forms is passed to a modified version of the probabilistic generalised LR parser (Briscoe and Carroll, 1993; Inui et al., 1997), augmented with limited lexical information encoding the probability\nof some phrasal verb combinations (i.e. verb plus preposition/particle)\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61105171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e078ed9ec47381b5f9b64b3d63e0b8af99c8029e",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new technique for selecting the correct parse of ambiguous sentences based on a probabilistic analysis, of lexical cooccurrences in semantic forms. The method is called \u201cSemco\u201d (for semantic cooccurrence analysis) and is specifically targeted at the differential distribution of such cooccurrences in correct and incorrect parses. It uses Bayesian Estimation for the cooccurrence probabilities to achieve higher accuracy for sparse data than the more common Maximum Likelihood Estimation would. It has been tested on the Wall Street Journal corpus (in the PENN Treebank) and shown to find the correct parse of 60.9% of parseable sentences of 6-20 words."
            },
            "slug": "Probabilistic-Parse-Selection-based-on-Semantic-Hektoen",
            "title": {
                "fragments": [],
                "text": "Probabilistic Parse Selection based on Semantic Cooccurrences"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper presents a new technique for selecting the correct parse of ambiguous sentences based on a probabilistic analysis, of lexical cooccurrences in semantic forms called Semco, which uses Bayesian Estimation for the cooccurrence probabilities to achieve higher accuracy for sparse data than the more common Maximum Likelihood Estimation would."
            },
            "venue": {
                "fragments": [],
                "text": "IWPT"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145702640"
                        ],
                        "name": "Guido Minnen",
                        "slug": "Guido-Minnen",
                        "structuredName": {
                            "firstName": "Guido",
                            "lastName": "Minnen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guido Minnen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708726"
                        ],
                        "name": "John A. Carroll",
                        "slug": "John-A.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John A. Carroll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35096557"
                        ],
                        "name": "Darren Pearce",
                        "slug": "Darren-Pearce",
                        "structuredName": {
                            "firstName": "Darren",
                            "lastName": "Pearce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Darren Pearce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 34553826,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "e979925b15861153a0e9ce8ace39a28d319e613d",
            "isKey": false,
            "numCitedBy": 386,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe two newly developed computational tools for morphological processing: a program for analysis of English inflectional morphology, and a morphological generator, automatically derived from the analyser. The tools are fast, being based on finite-state techniques, have wide coverage, incorporating data from various corpora and machine readable dictionaries, and are robust, in that they are able to deal effectively with unknown words. The tools are freely available. We evaluate the accuracy and speed of both tools and discuss a number of practical applications in which they have been put to use."
            },
            "slug": "Applied-morphological-processing-of-English-Minnen-Carroll",
            "title": {
                "fragments": [],
                "text": "Applied morphological processing of English"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "Two newly developed computational tools for morphological processing are described: a program for analysis of English inflectional morphology, and a morphological generator, automatically derived from the analyser, which are fast, being based on finite-state techniques, and robust, in that they are able to deal effectively with unknown words."
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Engineering"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732071"
                        ],
                        "name": "R. Weischedel",
                        "slug": "R.-Weischedel",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Weischedel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weischedel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227843"
                        ],
                        "name": "M. Meteer",
                        "slug": "M.-Meteer",
                        "structuredName": {
                            "firstName": "Marie",
                            "lastName": "Meteer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Meteer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744313"
                        ],
                        "name": "L. Ramshaw",
                        "slug": "L.-Ramshaw",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Ramshaw",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ramshaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2452408"
                        ],
                        "name": "Jeff Palmucci",
                        "slug": "Jeff-Palmucci",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Palmucci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Palmucci"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6838726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a94da952fb8ffc77881028081e90efb494f1c5d",
            "isKey": false,
            "numCitedBy": 329,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "From spring 1990 through fall 1991, we performed a battery of small experiments to test the effectiveness of supplementing knowledge-based techniques with probabilistic models. This paper reports our experiments in predicting parts of speech of highly ambiguous words, predicting the intended interpretation of an utterance when more than one interpretation satisfies all known syntactic and semantic constraints, and learning caseframe informationfor verbsfrom example uses.From these experiments, we are convinced that probabilistic models based on annotated corpora can effectively reduce the ambiguity in processing text and can be used to acquire lexical informationfrom a corpus, by supplementing knowledge-based techniques.Based on the results of those experiments, we have constructed a new natural language system (PLUM) for extracting data from text, e.g., newswire text."
            },
            "slug": "Coping-with-Ambiguity-and-Unknown-Words-through-Weischedel-Meteer",
            "title": {
                "fragments": [],
                "text": "Coping with Ambiguity and Unknown Words through Probabilistic Models"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A new natural language system (PLUM) is constructed for extracting data from text, e.g., newswire text, based on results of experiments in predicting parts of speech of highly ambiguous words, predicting the intended interpretation of an utterance when more than one interpretation satisfies all known syntactic and semantic constraints."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 77
                            }
                        ],
                        "text": "Similar relation-based schemes have been employed by others (e.g. Lin, 1998; Collins, 1999; Srinivas, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 183
                            }
                        ],
                        "text": "However, a great deal of this progress has been achieved with systems based on lexicalised probabilistic models of parse selection optimised on the Wall Street Journal treebank (e.g. Collins, 1999; Charniak, 2000)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7901127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fc44ff7f37ec5585310666c183c65e0a0bb2446",
            "isKey": false,
            "numCitedBy": 2062,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes three statistical models for natural language parsing. The models extend methods from probabilistic context-free grammars to lexicalized grammars, leading to approaches in which a parse tree is represented as the sequence of decisions corresponding to a head-centered, top-down derivation of the tree. Independence assumptions then lead to parameters that encode the X-bar schema, subcategorization, ordering of complements, placement of adjuncts, bigram lexical dependencies, wh-movement, and preferences for close attachment. All of these preferences are expressed by probabilities conditioned on lexical heads. The models are evaluated on the Penn Wall Street Journal Treebank, showing that their accuracy is competitive with other models in the literature. To gain a better understanding of the models, we also give results on different constituent types, as well as a breakdown of precision/recall results in recovering various types of dependencies. We analyze various characteristics of the models through experiments on parsing accuracy, by collecting frequencies of various structures in the treebank, and through linguistically motivated examples. Finally, we compare the models to others that have been applied to parsing the treebank, aiming to give some explanation of the difference in performance of the various models."
            },
            "slug": "Head-Driven-Statistical-Models-for-Natural-Language-Collins",
            "title": {
                "fragments": [],
                "text": "Head-Driven Statistical Models for Natural Language Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "Three statistical models for natural language parsing are described, leading to approaches in which a parse tree is represented as the sequence of decisions corresponding to a head-centered, top-down derivation of the tree."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767737"
                        ],
                        "name": "D. Elworthy",
                        "slug": "D.-Elworthy",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Elworthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Elworthy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 99
                            }
                        ],
                        "text": "As the Forward-Backward algorithm (FBA) has been implemented in addition to the Viterbi algorithm (Elworthy, 1994), the tagger can trade-off precision against recall by returning all but the most improbable tags up to some relative threshold ranked according to the posterior probabilities found\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 93
                            }
                        ],
                        "text": "This is done using a first-order (\u2018bigram\u2019) hidden markov model (HMM) tagger implemented in C (Elworthy, 1994) and trained on the manually-corrected tagged versions of the Susanne, LOB and (subset of) BNC corpora."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 98
                            }
                        ],
                        "text": "As the Forward-Backward algorithm (FBA) has been implemented in addition to the Viterbi algorithm (Elworthy, 1994), the tagger can trade-off precision against recall by returning all but the most improbable tags up to some relative threshold ranked according to the posterior probabilities found using the FBA."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1900253,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "5301d28e78992a588ee5699c305ebb949dc83613",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In part of speech tagging by Hidden Markov Model, a statistical model is used to assign grammatical categories to words in a text. Early work in the field relied on a corpus which had been tagged by a human annotator to train the model. More recently, Cutting et al. (1992) suggest that training can be achieved with a minimal lexicon and a limited amount of a priori information about probabilities, by using an Baum-Welch re-estimation to automatically refine the model. In this paper, I report two experiments designed to determine how much manual training information is needed. The first experiment suggests that initial biasing of either lexical or transition probabilities is essential to achieve a good accuracy. The second experiment reveals that there are three distinct patterns of Baum-Welch reestimation. In two of the patterns, the re-estimation ultimately reduces the accuracy of the tagging rather than improving it. The pattern which is applicable can be predicted from the quality of the initial model and the similarity between the tagged training corpus (if any) and the corpus to be tagged. Heuristics for deciding how to use re-estimation in an effective manner are given. The conclusions are broadly in agreement with those of Merialdo (1994), but give greater detail about the contributions of different parts of the model."
            },
            "slug": "Does-Baum-Welch-Re-estimation-Help-Taggers-Elworthy",
            "title": {
                "fragments": [],
                "text": "Does Baum-Welch Re-estimation Help Taggers?"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Two experiments designed to determine how much manual training information is needed for speech tagging by Hidden Markov Model suggest that initial biasing of either lexical or transition probabilities is essential to achieve a good accuracy and reveal three distinct patterns of Baum-Welch reestimation."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2949607"
                        ],
                        "name": "S. Oepen",
                        "slug": "S.-Oepen",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Oepen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Oepen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708726"
                        ],
                        "name": "John A. Carroll",
                        "slug": "John-A.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John A. Carroll"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 90
                            }
                        ],
                        "text": "This process backtracks occasionally when unification fails during the unpacking process (Oepen and Carroll, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14652639,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "63c12c1142f2cad9fe03182cc14756a58be0990e",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel approach to 'packing' of local ambiguity in parsing with a wide-coverage HPSG grammar, and provide an empirical assessment of the interaction between various packing and parsing strategies. We present a linear-time, bidirectional subsumption test for typed feature structures and demonstrate that (a) subsumption- and equivalence-based packing is applicable to large HPSG grammars and (b) average parse complexity can be greatly reduced in bottom-up chart parsing with comprehensive HPSG implementations."
            },
            "slug": "Ambiguity-Packing-in-Constraint-based-Parsing-Oepen-Carroll",
            "title": {
                "fragments": [],
                "text": "Ambiguity Packing in Constraint-based Parsing Practical Results"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A linear-time, bidirectional subsumption test for typed feature structures is presented and it is demonstrated that (a) subsumption- and equivalence-based packing is applicable to large HPSG grammars and (b) average parse complexity can be greatly reduced in bottom-up chart parsing with comprehensive H PSG implementations."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 198
                            }
                        ],
                        "text": "However, a great deal of this progress has been achieved with systems based on lexicalised probabilistic models of parse selection optimised on the Wall Street Journal treebank (e.g. Collins, 1999; Charniak, 2000)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 538122,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76d5e3fa888bee872b7adb7fa810089aa8ab1d58",
            "isKey": false,
            "numCitedBy": 1855,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new parser for parsing down to Penn tree-bank style parse trees that achieves 90.1% average precision/recall for sentences of length 40 and less, and 89.5% for sentences of length 100 and less when trained and tested on the previously established [5, 9, 10, 15, 17] \"standard\" sections of the Wall Street Journal treebank. This represents a 13% decrease in error rate over the best single-parser results on this corpus [9]. The major technical innovation is the use of a \"maximum-entropy-inspired\" model for conditioning and smoothing that let us successfully to test and combine many different conditioning events. We also present some partial results showing the effects of different conditioning information, including a surprising 2% improvement due to guessing the lexical head's pre-terminal before guessing the lexical head."
            },
            "slug": "A-Maximum-Entropy-Inspired-Parser-Charniak",
            "title": {
                "fragments": [],
                "text": "A Maximum-Entropy-Inspired Parser"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A new parser for parsing down to Penn tree-bank style parse trees that achieves 90.1% average precision/recall for sentences of length 40 and less and 89.5% when trained and tested on the previously established sections of the Wall Street Journal treebank is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708726"
                        ],
                        "name": "John A. Carroll",
                        "slug": "John-A.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John A. Carroll"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 76
                            }
                        ],
                        "text": "The parser takes average time roughly quadratic in the length of the input (Carroll, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8413372,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "345ec40aebfe8c03c54953887e4aea3e7499eda8",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper demonstrates that exponential complexities with respect to grammar size and input length have little impact on the performance of three unification-based parsing algorithms, using a wide-coverage grammar. The results imply that the study and optimisation of unification-based parsing must rely on empirical data until complexity theory can more accurately predict the practical behaviour of such parsers1."
            },
            "slug": "Relating-Complexity-to-Practical-Performance-in-Carroll",
            "title": {
                "fragments": [],
                "text": "Relating Complexity to Practical Performance in Parsing with Wide-Coverage Unification Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "It is demonstrated that exponential complexities with respect to grammar size and input length have little impact on the performance of three unification-based parsing algorithms, using a wide-coverage grammar, demonstrating that complexity theory can more accurately predict the practical behaviour of such parsers."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708726"
                        ],
                        "name": "John A. Carroll",
                        "slug": "John-A.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John A. Carroll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145586618"
                        ],
                        "name": "Diana McCarthy",
                        "slug": "Diana-McCarthy",
                        "structuredName": {
                            "firstName": "Diana",
                            "lastName": "McCarthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diana McCarthy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 118
                            }
                        ],
                        "text": "To date, the resulting annotated corpora have been used to develop systems for word sense disambiguation (Carroll and McCarthy, 2000; Lambeau, 2001), anaphora resolution (Preiss, 2002), acquiring verb subcategorisations (Korhonen, 2002) and acquiring selectional preferences (McCarthy and Korhonen,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6759706,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "8cd3b56be8fcdc29caf4dd1930a2c1b4dbbb924f",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The selectional preferences of verbal predicates are an importantcomponent of a computational lexicon. They have frequently been citedas being useful for WSD, alongside other sources ofknowledge. We evaluate automatically acquired selectional preferenceson the level playing field provided by SENSEVAL to examine towhat extent they help in WSD."
            },
            "slug": "Word-Sense-Disambiguation-Using-Automatically-Carroll-McCarthy",
            "title": {
                "fragments": [],
                "text": "Word Sense Disambiguation Using Automatically Acquired Verbal Preferences"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Humanit."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144003169"
                        ],
                        "name": "Claire Grover",
                        "slug": "Claire-Grover",
                        "structuredName": {
                            "firstName": "Claire",
                            "lastName": "Grover",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claire Grover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144210097"
                        ],
                        "name": "C. Matheson",
                        "slug": "C.-Matheson",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Matheson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Matheson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847246"
                        ],
                        "name": "Andrei Mikheev",
                        "slug": "Andrei-Mikheev",
                        "structuredName": {
                            "firstName": "Andrei",
                            "lastName": "Mikheev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrei Mikheev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085030"
                        ],
                        "name": "M. Moens",
                        "slug": "M.-Moens",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Moens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Moens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 90
                            }
                        ],
                        "text": "It can be easily replaced with other more developed tools (e.g. the Edinburgh TTT system, Grover et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 252573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "082dd9f93c88993b866aa55ed06eda4ace7f36c8",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe LT TTT, a recently developed software system which provides tools to perform text tokenisation and mark-up. The system includes ready-made components to segment text into paragraphs, sentences, words and other kinds of token but, crucially, it also allows users to tailor rule-sets to produce mark-up appropriate for particular applications. We present three case studies of our use of LT TTT: named-entity recognition (MUC-7), citation recognition and mark-up and the preparation of a corpus in the medical domain. We conclude with a discussion of the use of browsers to visualise marked-up text."
            },
            "slug": "LT-TTT-A-Flexible-Tokenisation-Tool-Grover-Matheson",
            "title": {
                "fragments": [],
                "text": "LT TTT - A Flexible Tokenisation Tool"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "LT TTT, a recently developed software system which provides tools to perform text tokenisation and mark-up, is described and three case studies of the use are presented: named-entity recognition (MUC-7), citation recognition and Mark-up and the preparation of a corpus in the medical domain."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3040648"
                        ],
                        "name": "Kentaro Inui",
                        "slug": "Kentaro-Inui",
                        "structuredName": {
                            "firstName": "Kentaro",
                            "lastName": "Inui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kentaro Inui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779078"
                        ],
                        "name": "V. Sornlertlamvanich",
                        "slug": "V.-Sornlertlamvanich",
                        "structuredName": {
                            "firstName": "Virach",
                            "lastName": "Sornlertlamvanich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sornlertlamvanich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911717"
                        ],
                        "name": "Hozumi Tanaka",
                        "slug": "Hozumi-Tanaka",
                        "structuredName": {
                            "firstName": "Hozumi",
                            "lastName": "Tanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hozumi Tanaka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37090109"
                        ],
                        "name": "T. Tokunaga",
                        "slug": "T.-Tokunaga",
                        "structuredName": {
                            "firstName": "Takenobu",
                            "lastName": "Tokunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tokunaga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 140
                            }
                        ],
                        "text": "The lattice of lemma+affix tag forms is passed to a modified version of the probabilistic generalised LR parser (Briscoe and Carroll, 1993; Inui et al., 1997), augmented with limited lexical information encoding the probability\nof some phrasal verb combinations (i.e. verb plus preposition/particle)\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 111
                            }
                        ],
                        "text": "The lattice of lemma+affixtag forms is passed to a modified version of the probabilistic generalised LR parser (Briscoe and Carroll, 1993; Inui et al., 1997), augmented with limited lexical information encoding the probability of some phrasal verb combinations (i."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10918665,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b1d9f9a645065c75c1032c498d1f2a892c057f9",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new formalization of probabilistic GLR language modeling for statistical parsing. Our model inherits its essential features from Briscoe and Carroll\u2019s generalized probabilistic LR model, which obtains context-sensitivity by assigning a probability to each LR parsing action according to its left and right context. Briscoe and Carroll\u2019s model, however, has a drawback in that it is not formalized in any probabilistically well-founded way, which may degrade its parsing performance. Our formulation overcomes this drawback with a few significant refinements, while maintaining all the advantages of Briscoe and Carroll\u2019s modeling."
            },
            "slug": "A-New-Formalization-of-Probabilistic-GLR-Parsing-Inui-Sornlertlamvanich",
            "title": {
                "fragments": [],
                "text": "A New Formalization of Probabilistic GLR Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper presents a new formalization of probabilistic GLR language modeling for statistical parsing with a few significant refinements, while maintaining all the advantages of Briscoe and Carroll\u2019s modeling."
            },
            "venue": {
                "fragments": [],
                "text": "IWPT"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15379653"
                        ],
                        "name": "Ann A. Copestake",
                        "slug": "Ann-A.-Copestake",
                        "structuredName": {
                            "firstName": "Ann",
                            "lastName": "Copestake",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ann A. Copestake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3209288"
                        ],
                        "name": "D. Flickinger",
                        "slug": "D.-Flickinger",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Flickinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Flickinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144741427"
                        ],
                        "name": "C. Pollard",
                        "slug": "C.-Pollard",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Pollard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Pollard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2393013"
                        ],
                        "name": "I. Sag",
                        "slug": "I.-Sag",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Sag",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Sag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 275
                            }
                        ],
                        "text": "\u2026the RADISP system for, such as parsing of highly-ranked documents relevant to queries in open-domain questionanswering (Briscoe et al., 2002b), it is useful to be able\nto output an underspecified semantic representation, in our case robust minimal recursion semantics (MRS, Copestake et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5271395,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "e867a965033a074e4074875e0916ce1ca42f3bf6",
            "isKey": false,
            "numCitedBy": 1202,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "Minimal recursion semantics (MRS) is a framework for computational semantics that is suitable for parsing and generation and that can be implemented in typed feature structure formalisms. We discuss why, in general, a semantic representation with minimal structure is desirable and illustrate how a descriptively adequate representation with a nonrecursive structure may be achieved. MRS enables a simple formulation of the grammatical constraints on lexical and phrasal semantics, including the principles of semantic composition. We have integrated MRS with a broad-coverage HPSG grammar."
            },
            "slug": "Minimal-Recursion-Semantics:-An-Introduction-Copestake-Flickinger",
            "title": {
                "fragments": [],
                "text": "Minimal Recursion Semantics: An Introduction"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work has integrated MRS with a broad-coverage HPSG grammar and discusses why, in general, a semantic representation with minimal structure is desirable and how a descriptively adequate representation with a nonrecursive structure may be achieved."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523372"
                        ],
                        "name": "S. Clark",
                        "slug": "S.-Clark",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35258592"
                        ],
                        "name": "David J. Weir",
                        "slug": "David-J.-Weir",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Weir",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Weir"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 273
                            }
                        ],
                        "text": "\u2026corpora have been used to develop systems for word sense disambiguation (Carroll and McCarthy, 2000; Lambeau, 2001), anaphora resolution (Preiss, 2002), acquiring verb subcategorisations (Korhonen, 2002) and acquiring selectional preferences (McCarthy and Korhonen, 1998; Clark and Weir, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 326,
                                "start": 275
                            }
                        ],
                        "text": "To date, the resulting annotated corpora have been used to develop systems for word sense disambiguation (Carroll and McCarthy, 2000; Lambeau, 2001), anaphora resolution (Preiss, 2002), acquiring verb subcategorisations (Korhonen, 2002) and acquiring selectional preferences (McCarthy and Korhonen, 1998; Clark and Weir, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2454033,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "266f957b08b96fd65fc93c01f3dc3ad017b5e6e2",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This article concerns the estimation of a particular kind of probability, namely, the probability of a noun sense appearing as a particular argument of a predicate. In order to overcome the accompanying sparse-data problem, the proposal here is to define the probabilities in terms of senses from a semantic hierarchy and exploit the fact that the senses can be grouped into classes consisting of semantically similar senses. There is a particular focus on the problem of how to determine a suitable class for a given sense, or, alternatively, how to determine a suitable level of generalization in the hierarchy. A procedure is developed that uses a chi-square test to determine a suitable level of generalization. In order to test the performance of the estimation method, a pseudo-disambiguation task is used, together with two alternative estimation methods. Each method uses a different generalization procedure; the first alternative uses the minimum description length principle, and the second uses Resnik's measure of selectional preference. In addition, the performance of our method is investigated using both the standard Pearson chi-square statistic and the log-likelihood chi-square statistic."
            },
            "slug": "Class-Based-Probability-Estimation-Using-a-Semantic-Clark-Weir",
            "title": {
                "fragments": [],
                "text": "Class-Based Probability Estimation Using a Semantic Hierarchy"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "This article concerns the estimation of a particular kind of probability, namely, the probability of a noun sense appearing as a particular argument of a predicate, and a procedure is developed that uses a chi-square test to determine a suitable level of generalization."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145586618"
                        ],
                        "name": "Diana McCarthy",
                        "slug": "Diana-McCarthy",
                        "structuredName": {
                            "firstName": "Diana",
                            "lastName": "McCarthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diana McCarthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145762466"
                        ],
                        "name": "A. Korhonen",
                        "slug": "A.-Korhonen",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Korhonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Korhonen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2693349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fabb90d6482e614bce42e2ed936b133a508c958",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for automatically identifying verbal participation in diathesis alternations. Automatically acquired subcategorization frames are compared to a hand-crafted classification for selecting candidate verbs. The minimum description length principle is then used to produce a model and cost for storing the head noun instances from a training corpus at the relevant argument slots. Alternating subcategorization frames are identified where the data from corresponding argument slots in the respective frames can be combined to produce a cheaper model than that produced if the data is encoded separately."
            },
            "slug": "Detecting-Verbal-Participation-in-Diathesis-McCarthy-Korhonen",
            "title": {
                "fragments": [],
                "text": "Detecting Verbal Participation in Diathesis Alternations"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A method for automatically identifying verbal participation in diathesis alternations and a hand-crafted classification for selecting candidate verbs are presented."
            },
            "venue": {
                "fragments": [],
                "text": "COLING-ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219077"
                        ],
                        "name": "J. Levine",
                        "slug": "J.-Levine",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Levine",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Levine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144780054"
                        ],
                        "name": "Tony Mason",
                        "slug": "Tony-Mason",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Mason",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tony Mason"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115530319"
                        ],
                        "name": "Doug Brown",
                        "slug": "Doug-Brown",
                        "structuredName": {
                            "firstName": "Doug",
                            "lastName": "Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Doug Brown"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59849813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89cecf56e13442c9af78c564ed425c9dbe7fc460",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This book shows you how to use two Unix utilities, lex and yacc, in program development. These tools help programmers build compilers and interpreters, but they also have a wider range of applications. The second edition contains completely revised tutorial sections for novice users and reference sections for advanced users. This edition is twice the size of the first and has an expanded index. The following material has been added: Each utility is explained in a chapter that covers basic usage and simple, stand-alone applicationsHow to implement a full SQL grammar, with full sample codeMajor MS-DOS and Unix versions of lex and yacc are explored in depth, including AT&T lex and yacc, Berkeley yacc, Berkeley/GNU Flex, GNU Bison, MKS lex and yacc, and Abraxas PCYACC"
            },
            "slug": "Lex-&-yacc,-2nd-edition-Levine-Mason",
            "title": {
                "fragments": [],
                "text": "Lex & yacc, 2nd edition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The second edition of this book contains completely revised tutorial sections for novice users and reference sections for advanced users, and is twice the size of the first and has an expanded index."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15379653"
                        ],
                        "name": "Ann A. Copestake",
                        "slug": "Ann-A.-Copestake",
                        "structuredName": {
                            "firstName": "Ann",
                            "lastName": "Copestake",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ann A. Copestake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1876168"
                        ],
                        "name": "A. Lascarides",
                        "slug": "A.-Lascarides",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Lascarides",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lascarides"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3209288"
                        ],
                        "name": "D. Flickinger",
                        "slug": "D.-Flickinger",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Flickinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Flickinger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8626751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e006247c9584f39593bed908827cca40b74cdf66",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a framework for formalizing semantic construction within grammars expressed in typed feature structure logics, including HPSG. The approach provides an alternative to the lambda calculus; it maintains much of the desirable flexibility of unification-based approaches to composition, while constraining the allowable operations in order to capture basic generalizations and improve maintainability."
            },
            "slug": "An-Algebra-for-Semantic-Construction-in-Grammars-Copestake-Lascarides",
            "title": {
                "fragments": [],
                "text": "An Algebra for Semantic Construction in Constraint-based Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A framework for formalizing semantic construction within grammars expressed in typed feature structure logics, including HPSG is developed, which maintains much of the desirable flexibility of unification-based approaches to composition, while constraining the allowable operations in order to capture basic generalizations and improve maintainability."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143623142"
                        ],
                        "name": "T. Parsons",
                        "slug": "T.-Parsons",
                        "structuredName": {
                            "firstName": "Terence",
                            "lastName": "Parsons",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Parsons"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 64
                            }
                        ],
                        "text": "In robust MRS the arguments of predicates are represented using Parsons\u2019 (1990) event-based scheme: instead of, for example, give(e,x,y,z), Robust MRS uses give(e), arg1(e,x), arg2(e,y), arg3(e,z)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60646629,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "8ff703240303808d2d54b0d7723550820d17a7ca",
            "isKey": false,
            "numCitedBy": 1690,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This extended investigation of the semantics of event (and state) sentences in their various forms is a major contribution to the semantics of natural language, simultaneously encompassing important issues in linguistics, philosophy, and logic. It develops the view that the logical forms of simple English sentences typically contain quantification over events or states and shows how this view can account for a wide variety of semantic phenomena.Focusing on the structure of meaning in English sentences at a \"subatomic\" level - that is, a level below the one most theories accept as basic or \"atomic\" - Parsons asserts that the semantics of simple English sentences require logical forms somewhat more complex than is normally assumed in natural language semantics. His articulation of underlying event theory explains a wide variety of apparently diverse semantic characteristics of natural language, and his development of the theory shows the importance of seeing the distinction between events and states.Parsons demonstrates that verbs, also, indicate kinds of actions rather than specific, individual actions. Verb phrases, too, he argues, depend on modifiers to make their function and meaning in a sentence specific. An appendix gives many of the details needed to formalize the theory discussed in the body of the text and provides a series of templates that permit the generation of atomic formulas of English.Terence Parsons is Professor of Philosophy and Dean of Humanities at the University of California, Irvine."
            },
            "slug": "Events-in-the-Semantics-of-English:-A-Study-in-Parsons",
            "title": {
                "fragments": [],
                "text": "Events in the Semantics of English: A Study in Subatomic Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Focusing on the structure of meaning in English sentences at a \"subatomic\" level - that is, a level below the one most theories accept as basic or \"atomic\" - Parsons asserts that the semantics of simple English sentences require logical forms somewhat more complex than is normally assumed in natural language semantics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 121
                            }
                        ],
                        "text": "Measured in this way our results appear broadly competitive with those produced by state-of-the-art statistical parsers (Briscoe et al., 2002a)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 147
                            }
                        ],
                        "text": "\u2026tasks that we want to use the RADISP system for, such as parsing of highly-ranked documents relevant to queries in open-domain questionanswering (Briscoe et al., 2002b), it is useful to be able\nto output an underspecified semantic representation, in our case robust minimal recursion semantics\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 145
                            }
                        ],
                        "text": "Our system achieves a F -score of 76.5% on a manually constructed test suite of 500 sentences from the Susanne corpus (see Carroll et al., 1998; Briscoe et al.,\n2002a for further details)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "CSTIT MPhil, Language Practical 2, Computer Laboratory, University of Cambridge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 123
                            }
                        ],
                        "text": "Our system achieves a F -score of 76.5% on a manually constructed test suite of 500 sentences from the Susanne corpus (see Carroll et al., 1998; Briscoe et al.,\n2002a for further details)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 203
                            }
                        ],
                        "text": "We originally proposed transforming trees to sets of named grammatical relations (GRs) of the type illustrated in Figure 2 above as a technique for facilitating fine-grained cross-system evaluation (see Carroll et al., 1998 where a detailed specification of the representation is also given)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 180
                            }
                        ],
                        "text": "The GR representation stays deliberately close to surface syntax, although it does encode some logical / underlying relations via extra parameters on specific named relations (see Carroll et al., 1998 for details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Briscoe(1998)\u2018Can subcategorisationprobabilitieshelp a statisticalparser?\u2019,Proceedingsof the ACL SIGDAT 6th Workshop on Very LargeCorpora (WVLC\u201998),Montreal,pp.118\u2013126"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 96
                            }
                        ],
                        "text": "As the Forward-Backward algorithm (FBA) hasbeen implementedin addition to the Viterbi algorithm (Elworthy, 1994),thetaggercantrade-of precisionagainstrecall by returningall but the most improbabletagsup to some relative thresholdranked accordingto the posteriorprobabilities found usingthe FBA."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 99
                            }
                        ],
                        "text": "As the Forward-Backward algorithm (FBA) has been implemented in addition to the Viterbi algorithm (Elworthy, 1994), the tagger can trade-off precision against recall by returning all but the most improbable tags up to some relative threshold ranked according to the posterior probabilities found\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 87
                            }
                        ],
                        "text": "This is done usingafirst-order(\u2018bigram\u2019) hiddenmarkov model(HMM) taggerimplementedin C (Elworthy, 1994)andtrainedon the manually-correctedtaggedversionsof the Susanne, LOB and (subsetof) BNC corpora."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 93
                            }
                        ],
                        "text": "This is done using a first-order (\u2018bigram\u2019) hidden markov model (HMM) tagger implemented in C (Elworthy, 1994) and trained on the manually-corrected tagged versions of the Susanne, LOB and (subset of) BNC corpora."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1994)\u2018DoesBaum-Welchre-estimationhelp taggers?\u2019,Proceedingsof the4thACLConferenceonApplied NLP, Stuttgart,Germany, pp.53\u201358"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 121
                            }
                        ],
                        "text": "Measured in this way our results appear broadly competitive with those produced by state-of-the-art statistical parsers (Briscoe et al., 2002a)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 147
                            }
                        ],
                        "text": "\u2026tasks that we want to use the RADISP system for, such as parsing of highly-ranked documents relevant to queries in open-domain questionanswering (Briscoe et al., 2002b), it is useful to be able\nto output an underspecified semantic representation, in our case robust minimal recursion semantics\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 145
                            }
                        ],
                        "text": "Our system achieves a F -score of 76.5% on a manually constructed test suite of 500 sentences from the Susanne corpus (see Carroll et al., 1998; Briscoe et al.,\n2002a for further details)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Relational evaluation schemes\u2019, Proceedings of the Workshop at LREC\u201902 on Beyond PARSEVAL: Towards Improved Evaluation Measures for Parsing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144003169"
                        ],
                        "name": "Claire Grover",
                        "slug": "Claire-Grover",
                        "structuredName": {
                            "firstName": "Claire",
                            "lastName": "Grover",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claire Grover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145693410"
                        ],
                        "name": "Ted Briscoe",
                        "slug": "Ted-Briscoe",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Briscoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Briscoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708726"
                        ],
                        "name": "John A. Carroll",
                        "slug": "John-A.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John A. Carroll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713574"
                        ],
                        "name": "B. Boguraev",
                        "slug": "B.-Boguraev",
                        "structuredName": {
                            "firstName": "Branimir",
                            "lastName": "Boguraev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boguraev"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, it does not map easily to a logical form or predicate-argument structure, and the tag sequence grammar, unlike the ANLT full grammar ( Grover, Carroll and Briscoe, 1993 ) is not able to construct a logical form deterministically from the derivation because of the intermediate level of analysis achieved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 56796940,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "290175a4a8e54e9256a97a4529e85ed5f1900837",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Alvey-natural-language-tools-grammar-(2nd-Grover-Briscoe",
            "title": {
                "fragments": [],
                "text": "The Alvey natural language tools grammar (2nd Release)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708726"
                        ],
                        "name": "John A. Carroll",
                        "slug": "John-A.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John A. Carroll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145693410"
                        ],
                        "name": "Ted Briscoe",
                        "slug": "Ted-Briscoe",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Briscoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Briscoe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1627677,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "233c1331055925ad08f72b39816e4ce37512e7bd",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "A parsing system returning analyses in the form of sets of grammatical relations can obtain high precision if it hypothesises a particular grammatical relation only when it is certain that the relation is correct. We operationalise this technique -in a statistical parser using a manually-developed wide-coverage grammar of English - by only returning relations that form part of all analyses licensed by the grammar. We observe an increase in precision from 75% to over 90% (at the cost of a reduction in recall) on a test corpus of naturally-occurring text."
            },
            "slug": "High-Precision-Extraction-of-Grammatical-Relations-Carroll-Briscoe",
            "title": {
                "fragments": [],
                "text": "High Precision Extraction of Grammatical Relations"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work operationalises this technique -in a statistical parser using a manually-developed wide-coverage grammar of English - by only returning relations that form part of all analyses licensed by the grammar."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J.CarrollandR.Malouf (1999)\u2018A bagof usefultechniquesfor efficientandrobustparsing\u2019, Proceedingsof the37thAnnualMeetingof theAssociation for ComputationalLinguistics,Universityof Maryland,pp.473\u2013480"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 149
                            }
                        ],
                        "text": "\u2026annotated corpora have been used to develop systems for word sense disambiguation (Carroll and McCarthy, 2000; Lambeau, 2001), anaphora resolution (Preiss, 2002), acquiring verb subcategorisations (Korhonen, 2002) and acquiring selectional preferences (McCarthy and Korhonen, 1998; Clark and Weir,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 170
                            }
                        ],
                        "text": "To date, the resulting annotated corpora have been used to develop systems for word sense disambiguation (Carroll and McCarthy, 2000; Lambeau, 2001), anaphora resolution (Preiss, 2002), acquiring verb subcategorisations (Korhonen, 2002) and acquiring selectional preferences (McCarthy and Korhonen, 1998; Clark and Weir, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Anaphora resolution with memory-based learning"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 5th Annual CLUK Research Colloquium,"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 284,
                                "start": 265
                            }
                        ],
                        "text": "\u2026approach to robust parsing, favoured by most commercial and academic information extraction systems, is to use (cascaded) finitestate transducers, often augmented with heuristics such as the longest match preference, to construct partial phrasallevel parses (e.g. Appelt et al., 1995; Abney, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The SRI FASTUS system, MUC-6 test results and analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 6th Message Understanding Conference,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Detecting verbal participation in diathesisalternations\u2019,Proceedingsof the36thAnnualMeetingof theAssociationfor ComputationalLinguistics,vol"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 273
                            }
                        ],
                        "text": "\u2026corpora have been used to develop systems for word sense disambiguation (Carroll and McCarthy, 2000; Lambeau, 2001), anaphora resolution (Preiss, 2002), acquiring verb subcategorisations (Korhonen, 2002) and acquiring selectional preferences (McCarthy and Korhonen, 1998; Clark and Weir, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2001)\u2018Class-basedprobability estimation using a semantichierarchy"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedingsof the 2nd Conferenceof the North AmericanChapterof the Associationof ComputationalLinguistics,Carnegie Mellon University,"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 175
                            }
                        ],
                        "text": "Factoring of derivations into sets of bilexical dependencies can also, in principle, support reranking of derivations using a lexicalised discriminative model (Hektoen, 1997; Collins, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminative rerankingfor natural languageparsing\u2019,Proceedingsof the17thInternational Conferenceon MachineLearning(ICML2000),Morgan Kaufmann,SanMateo,CA"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 72
                            }
                        ],
                        "text": "The system has also been used in experiments in information extraction (Yeh, 2000) and as a component of an open-domain questionanswering (Briscoe, Copestake and Teufel, 2002b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 64
                            }
                        ],
                        "text": "Thesystemhasalso beenusedin experimentsin informationextraction (Yeh, 2000) and as a componentof an open-domainquestionanswering(Briscoe,Copestak e and Teufel, 2002b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Using existing systemsto supplement smallamountsof annotatedgrammaticalrelationstraining data\u2019,Proceedingsof the38thAnnualMeetingof the Associationfor ComputationalLinguistics,HongKong, pp.126\u2013132"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An algebrafor semanticconstructionin constraint-based grammars\u2019,Proceedingsof the 39th AnnualMeetingof theAssociationfor"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sag and C. Pollard (1999) Minimal Recursion Semantics: An introduction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic parse selection based on"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 134
                            }
                        ],
                        "text": "However, very little work has been undertaken with the ANLT full grammar since the initial experiment parsing dictionary definitions (Briscoe and Carroll, 1993) because this grammar requires accurate subcategorisation information for all lexical items to function effectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 113
                            }
                        ],
                        "text": "The lattice of lemma+affix tag forms is passed to a modified version of the probabilistic generalised LR parser (Briscoe and Carroll, 1993; Inui et al., 1997), augmented with limited lexical information encoding the probability\nof some phrasal verb combinations (i.e. verb plus preposition/particle)\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalised probabilistic LR parsing of natural language (corpora) with unification-based grammars', Computational Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": "Generalised probabilistic LR parsing of natural language (corpora) with unification-based grammars', Computational Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 77
                            }
                        ],
                        "text": "Similar relation-based schemes have been employed by others (e.g. Lin, 1998; Collins, 1999; Srinivas, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 183
                            }
                        ],
                        "text": "However, a great deal of this progress has been achieved with systems based on lexicalised probabilistic models of parse selection optimised on the Wall Street Journal treebank (e.g. Collins, 1999; Charniak, 2000)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1999)Head-drivenstatisticalmodelsfor natural languageparsing, PhDDissertation,Computerand InformationScience,Universityof Pennsylvania"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 64
                            }
                        ],
                        "text": "In robust MRS the arguments of predicates are represented using Parsons\u2019 (1990) event-based scheme: instead of, for example, give(e,x,y,z), Robust MRS uses give(e), arg1(e,x), arg2(e,y), arg3(e,z)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Events in the semantics of English, MIT Press: Cambridge, MA"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 66
                            }
                        ],
                        "text": "Similar relation-based schemes have been employed by others (e.g. Lin, 1998; Collins, 1999; Srinivas, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dependency-basedevaluation of MINIPAR\u2019, Proceedingsof theWorkshopat LREC\u201998on The Evaluationof ParsingSystems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u2018 A lightweight dependency analyzer"
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Engineering"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 275
                            }
                        ],
                        "text": "\u2026the RADISP system for, such as parsing of highly-ranked documents relevant to queries in open-domain questionanswering (Briscoe et al., 2002b), it is useful to be able\nto output an underspecified semantic representation, in our case robust minimal recursion semantics (MRS, Copestake et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Minimal Recursion Semantics: An introduction, <http://www-csli.stanford.edu/ \u0303aac/papers/ newmrs.pdf>"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 134
                            }
                        ],
                        "text": "However, very little work has been undertaken with the ANLT full grammar since the initial experiment parsing dictionary definitions (Briscoe and Carroll, 1993) because this grammar requires accurate subcategorisation information for all lexical items to function effectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 113
                            }
                        ],
                        "text": "The lattice of lemma+affix tag forms is passed to a modified version of the probabilistic generalised LR parser (Briscoe and Carroll, 1993; Inui et al., 1997), augmented with limited lexical information encoding the probability\nof some phrasal verb combinations (i.e. verb plus preposition/particle)\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalisedprobabilistic LR parsingof natural language(corpora)with unification-basedgrammars\u2019, ComputationalLinguistics,vol.19.1,25\u201360"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J.Carroll andE. Briscoe(1993)TheAlvey natural language tools grammar (4th release),Computer Laboratory, CambridgeUniversity, UK, TechnicalReport 284"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u2018 Anaphora resolution with memory - based learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 175
                            }
                        ],
                        "text": "Factoring of derivations into sets of bilexical dependencies can also, in principle, support reranking of derivations using a lexicalised discriminative model (Hektoen, 1997; Collins, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 161
                            }
                        ],
                        "text": "Factoring of derivations into sets of bilexical dependencies can also, in principle, support reran king of derivations using a lexicalised discriminative mode l (Hektoen, 1997; Collins, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminative reranking for natural"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 69
                            }
                        ],
                        "text": "The tagger has been augmented with a statistical unknown word model (Piano, 1996; Weischedel et al., 1993) and achieves around 97% per word accuracy when tested on similar data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adaptation of Acquilex tagger to unknown words -release 2"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 105
                            }
                        ],
                        "text": "To date, the resulting annotated corpora have been used to develop systems for word sense disambiguation (Carroll and McCarthy, 2000; Lambeau, 2001), anaphora resolution (Preiss , 2002), acquiring verb subcategorisations (Korhonen, 2002 ) and acquiring selectional preferences (McCarthy and Korhonen, 1998; Clark and Weir, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 106
                            }
                        ],
                        "text": "To date, the resulting annotated corpora have been used to develop systems for word sense disambiguation (Carroll and McCarthy, 2000; Lambeau, 2001), anaphora resolution (Preiss, 2002), acquiring verb subcategorisations (Korhonen, 2002) and acquiring selectional preferences (McCarthy and Korhonen,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Word sense disambiguation using automatically acquired verbal preferences\u2019,Computers and the Humanities, vol.31.1\u20132"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 66
                            }
                        ],
                        "text": "The parsertakesaveragetimeroughlyquadraticin thelengthof theinput (Carroll, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 76
                            }
                        ],
                        "text": "The parser takes average time roughly quadratic in the length of the input (Carroll, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1994)\u2018Relatingcomplexity to practicalperformancein parsingwith wide-coverageunificationgrammars\u2019, Proceedingsof the 32ndAnnualMeetingof the Associationfor ComputationalLinguistics,Las"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 284,
                                "start": 265
                            }
                        ],
                        "text": "\u2026approach to robust parsing, favoured by most commercial and academic information extraction systems, is to use (cascaded) finitestate transducers, often augmented with heuristics such as the longest match preference, to construct partial phrasallevel parses (e.g. Appelt et al., 1995; Abney, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The SRI FASTUS system, MUC-6 test results and analysis\u2019,Proceedingsof the 6th Message Understanding"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 72
                            }
                        ],
                        "text": "At 90% precision, the system achieves 45% recall on the same test data (Carroll and Briscoe, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 271
                            }
                        ],
                        "text": "\u2026it possible to compute the transderivational support for a particular relation and thus compute a weighting which takes account both of the probability of derivations yielding a specific relation and the proportion of such derivations in the set produced by the parser (Carroll and Briscoe, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "High precision extraction of grammaticalrelations\u2019, Proceedingsof the 7th ACL/SIGPARSEInternationalWorkshopon Parsing Technologies(IWPT\u201901),Beijing, China"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 189
                            }
                        ],
                        "text": "\u2026corpora have been used to develop systems for word sense disambiguation (Carroll and McCarthy, 2000; Lambeau, 2001), anaphora resolution (Preiss, 2002), acquiring verb subcategorisations (Korhonen, 2002) and acquiring selectional preferences (McCarthy and Korhonen, 1998; Clark and Weir, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 220
                            }
                        ],
                        "text": "To date, the resulting annotated corpora have been used to develop systems for word sense disambiguation (Carroll and McCarthy, 2000; Lambeau, 2001), anaphora resolution (Preiss, 2002), acquiring verb subcategorisations (Korhonen, 2002) and acquiring selectional preferences (McCarthy and Korhonen, 1998; Clark and Weir, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 282
                            }
                        ],
                        "text": "However, reliance on lexical information leads to domain dependence so our broad approach is to attempt to seed the RADISP system with such information acquired from automatic parses obtained without it, as with our approach to subcategorisation (Carroll, Minnen and Briscoe, 1998; Korhonen, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Subcategorisation acquisition, PhD Dissertation, Computer Laboratory, University of Cambridge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Does BaumWelch reestimation help taggers ?"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 134
                            }
                        ],
                        "text": "To date, the resulting annotated corpora have been used to develop systems for word sense disambiguation (Carroll and McCarthy, 2000; Lambeau, 2001), anaphora resolution (Preiss, 2002), acquiring verb subcategorisations (Korhonen, 2002) and acquiring selectional preferences (McCarthy and Korhonen,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Verb sense disambiguation from argument relations, MPhil dissertation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 106
                            }
                        ],
                        "text": "To date, the resulting annotated corpora have been used to develop systems for word sense disambiguation (Carroll and McCarthy, 2000; Lambeau, 2001), anaphora resolution (Preiss, 2002), acquiring verb subcategorisations (Korhonen, 2002) and acquiring selectional preferences (McCarthy and Korhonen,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Word sensedisambiguation using automaticallyacquiredverbal preferences\u2019,Computer"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 69
                            }
                        ],
                        "text": "The tagger has been augmented with a statistical unknown word model (Piano, 1996; Weischedel et al., 1993) and achieves around 97% per word accuracy when tested on similar data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adaptation of Acquilex tagger to unknown words \u2014 release 2, University of Cambridge Computer Laboratory, unpublished memo"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pearce(2001)\u2018Applied morphological processingof English"
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Engineering,"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 162
                            }
                        ],
                        "text": "The system has also been used in experiments in information extraction (Yeh, 2000) and as a component of an open-domain questionanswering (Briscoe, Copestake and Teufel, 2002b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "CSTIT MPhil, Language Practical 2, ComputerLaboratory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 90
                            }
                        ],
                        "text": "This process backtracks occasionally when unification fails during the unpacking process (Oepen and Carroll, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ambiguity packing in constraint-basedparsing\u2014 practicalresults\u2019,Proceedingsof the1stConferenceof theNorth AmericanChapter of the Associationfor ComputationalLinguistics, Seattle,WA, pp.162\u2013169"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 165
                            }
                        ],
                        "text": "The manually-developed wide-coverage tag sequence grammar utilised in this version of the parser consists of about 400 unification-based phrase structure rules (see Briscoe and Carroll, 1995 for further details)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Developing and Evaluating a Probabilistic LR Parser of Part-of-Speech and Punctuation Labels\u2019,Proceedings of the 4th International Workshop on Parsing Technologies (IWPT\u201995)"
            },
            "venue": {
                "fragments": [],
                "text": "Prague / Karlovy Vary, Czech Republic,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 92
                            }
                        ],
                        "text": "Similar relation-based schemes have been employed by others (e.g. Lin, 1998; Collins, 1999; Srinivas, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 47
                            }
                        ],
                        "text": "There is evidence from the results reported by Srinivas (2000) that Susanne data, drawn from a variety of genres, constitutes a harder test than the more homogeneous Wall Street Journal."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A lightweight dependency analyzer"
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Engineering,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 284,
                                "start": 265
                            }
                        ],
                        "text": "\u2026approach to robust parsing, favoured by most commercial and academic information extraction systems, is to use (cascaded) finitestate transducers, often augmented with heuristics such as the longest match preference, to construct partial phrasallevel parses (e.g. Appelt et al., 1995; Abney, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The SRI FASTUS system, MUC-6 test results and analysis\u2019,Proceedings of the 6th Message Understanding"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "XML-based data preparationfor robustdeepparsing\u2019,Proceedingsof the 39th Annual Meetingof the Associationfor Computational Linguistics,Toulouse,France,pp.252\u2013259"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 82
                            }
                        ],
                        "text": "The tagger has been augmented with a statistical unknown word model (Piano, 1996; Weischedel et al., 1993) and achieves around 97% per word accuracy when tested on similar data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "andJ.Palmucci(1993)\u2018Coping with ambiguityandunknown words throughprobabilisticmodels\u2019, Computational Linguistics,vol.19.2,359\u2013382"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 90
                            }
                        ],
                        "text": "It can be easily replaced with other more developed tools (e.g. the Edinburgh TTT system, Grover et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "LT TTT \u2013 A flexible tokenisation"
            },
            "venue": {
                "fragments": [],
                "text": "tool\u2019,Proceedings of the 2nd International Conference on Language Resources and Evaluation,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 189
                            }
                        ],
                        "text": "\u2026corpora have been used to develop systems for word sense disambiguation (Carroll and McCarthy, 2000; Lambeau, 2001), anaphora resolution (Preiss, 2002), acquiring verb subcategorisations (Korhonen, 2002) and acquiring selectional preferences (McCarthy and Korhonen, 1998; Clark and Weir, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 282
                            }
                        ],
                        "text": "However, reliance on lexical information leads to domain dependence so our broad approach is to attempt to seed the RADISP system with such information acquired from automatic parses obtained without it, as with our approach to subcategorisation (Carroll, Minnen and Briscoe, 1998; Korhonen, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Subcategorisation acquisition, PhD Dissertation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "TanakaandT. Tokunaga (1997)\u2018A new formalizationof probabilisticGLR parsing"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedingsof the 5th InternationalWorkshopon ParsingTechnologies(IWPT\u201997),MIT,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 105
                            }
                        ],
                        "text": "To date, the resulting annotated corpora have been used to develop systems for word sense disambiguation (Carroll and McCarthy, 2000; Lambeau, 2001), anaphora resolution (Preiss, 2002), acquiring verb subcategorisations (Korhonen, 2002) and acquiring selectional preferences (McCarthy and Korhonen, 1998; Clark and Weir, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 134
                            }
                        ],
                        "text": "To date, the resulting annotated corpora have been used to develop systems for word sense disambiguation (Carroll and McCarthy, 2000; Lambeau, 2001), anaphora resolution (Preiss, 2002), acquiring verb subcategorisations (Korhonen, 2002) and acquiring selectional preferences (McCarthy and Korhonen,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Verb sense disambiguation from argument relations, MPhil dissertation, Dept. of Engineering, University of Cambridge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 18,
            "methodology": 44,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 76,
        "totalPages": 8
    },
    "page_url": "https://www.semanticscholar.org/paper/Robust-Accurate-Statistical-Annotation-of-General-Briscoe-Carroll/d8fe99b6dc76dc342fe9fb47740fee40381fa13d?sort=total-citations"
}