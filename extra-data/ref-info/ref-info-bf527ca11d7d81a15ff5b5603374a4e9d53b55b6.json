{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 144
                            }
                        ],
                        "text": "\u2026on a variety of examples with most emphasis on the Bayes Point Machine\nSection For the clutter problem in one dimension EP was in well behaved cases times more accurate than its nearest competitor Laplace s method both in estimating the posterior mean and the normalizing constant p D In\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16462148,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19908640236767427ebf0524dc3a4bb09d65145e",
            "isKey": false,
            "numCitedBy": 1774,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, researchers have demonstrated that \"loopy belief propagation\" -- the use of Pearl's polytree algorithm in a Bayesian network with loops -- can perform well in the context of error-correcting codes. The most dramatic instance of this is the near Shannon-limit performance of \"Turbo Codes\" -- codes whose decoding algorithm is equivalent to loopy belief propagation in a chain-structured Bayesian network. \n \nIn this paper we ask: is there something special about the error-correcting code context, or does loopy propagation work as an approximate inference scheme in a more general setting? We compare the marginals computed using loopy propagation to the exact ones in four Bayesian network architectures, including two real-world networks: ALARM and QMR. We find that the loopy beliefs often converge and when they do, they give a good approximation to the correct marginals. However, on the QMR network, the loopy beliefs oscillated and had no obvious relationship to the correct posteriors. We present some initial investigations into the cause of these oscillations, and show that some simple methods of preventing them lead to the wrong results."
            },
            "slug": "Loopy-Belief-Propagation-for-Approximate-Inference:-Murphy-Weiss",
            "title": {
                "fragments": [],
                "text": "Loopy Belief Propagation for Approximate Inference: An Empirical Study"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper compares the marginals computed using loopy propagation to the exact ones in four Bayesian network architectures, including two real-world networks: ALARM and QMR, and finds that the loopy beliefs often converge and when they do, they give a good approximation to the correct marginals."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3198578"
                        ],
                        "name": "J. Yedidia",
                        "slug": "J.-Yedidia",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Yedidia",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yedidia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15300022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2799fd1254689eec52f86daf3668a5aac3ea943",
            "isKey": false,
            "numCitedBy": 1127,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Belief propagation (BP) was only supposed to work for treelike networks but works surprisingly well in many applications involving networks with loops, including turbo codes. However, there has been little understanding of the algorithm or the nature of the solutions it finds for general graphs. \n \nWe show that BP can only converge to a stationary point of an approximate free energy, known as the Bethe free energy in statistical physics. This result characterizes BP fixed-points and makes connections with variational approaches to approximate inference. \n \nMore importantly, our analysis lets us build on the progress made in statistical physics since Bethe's approximation was introduced in 1935. Kikuchi and others have shown how to construct more accurate free energy approximations, of which Bethe's approximation is the simplest. Exploiting the insights from our analysis, we derive generalized belief propagation (GBP) versions of these Kikuchi approximations. These new message passing algorithms can be significantly more accurate than ordinary BP, at an adjustable increase in complexity. We illustrate such a new GBP algorithm on a grid Markov network and show that it gives much more accurate marginal probabilities than those found using ordinary BP."
            },
            "slug": "Generalized-Belief-Propagation-Yedidia-Freeman",
            "title": {
                "fragments": [],
                "text": "Generalized Belief Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown that BP can only converge to a stationary point of an approximate free energy, known as the Bethe free energy in statistical physics, and generalized belief propagation (GBP) versions of these Kikuchi approximations are derived."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728216"
                        ],
                        "name": "A. Storkey",
                        "slug": "A.-Storkey",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Storkey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Storkey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8169493,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f80f8356c104e605e7cc87aba59103526707bb7d",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Dynamic trees are mixtures of tree structured belief networks. They solve some of the problems of fixed tree networks at the cost of making exact inference intractable. For this reason approximate methods such as sampling or mean field approaches have been used. However, mean field approximations assume a factorised distribution over node states. Such a distribution seems unlikely in the posterior, as nodes are highly correlated in the prior. Here a structured variational approach is used, where the posterior distribution over the non-evidential nodes is itself approximated by a dynamic tree. It turns out that this form can be used tractably and efficiently. The result is a set of update rules which can propagate information through the network to obtain both a full variational approximation, and the relevant marginals. \n \nThe propagation rules are more efficient than the mean field approach and give noticeable quantitative and qualitative improvement in the inference. The marginals calculated give better approximations to the posterior than loopy propagation on a small toy problem."
            },
            "slug": "Dynamic-Trees:-A-Structured-Variational-Method-Storkey",
            "title": {
                "fragments": [],
                "text": "Dynamic Trees: A Structured Variational Method Giving Efficient Propagation Rules"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A structured variational approach is used, where the posterior distribution over the non-evidential nodes is itself approximated by a dynamic tree, and the marginals calculated give better approximations to the posterior than loopy propagation on a small toy problem."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73775381"
                        ],
                        "name": "U. Lerner",
                        "slug": "U.-Lerner",
                        "structuredName": {
                            "firstName": "Uri",
                            "lastName": "Lerner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Lerner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838674"
                        ],
                        "name": "Dragomir Anguelov",
                        "slug": "Dragomir-Anguelov",
                        "structuredName": {
                            "firstName": "Dragomir",
                            "lastName": "Anguelov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dragomir Anguelov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 75
                            }
                        ],
                        "text": "Iterative refinement has previously been used in conjunction with sampling (Koller et al., 1999) and extended Kalman filtering (Shachter, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7824624,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "63e664998d8947e34a4cfc401562a172458a7053",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The clique tree algorithm is the standard method for doing inference in Bayesian networks. It works by manipulating clique potentials - distributions over the variables in a clique. While this approach works well for many networks, it is limited by the need to maintain an exact representation of the clique potentials. This paper presents a new unified approach that combines approximate inference and the clique tree algorithm, thereby circumventing this limitation. Many known approximate inference algorithms can be viewed as instances of this approach. The algorithm essentially does clique tree propagation, using approximate inference to estimate the densities in each clique. In many settings, the computation of the approximate clique potential can be done easily using statistical importance sampling. Iterations are used to gradually improve the quality of the estimation."
            },
            "slug": "A-General-Algorithm-for-Approximate-Inference-and-Koller-Lerner",
            "title": {
                "fragments": [],
                "text": "A General Algorithm for Approximate Inference and Its Application to Hybrid Bayes Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new unified approach is presented that combines approximate inference and the clique tree algorithm, thereby circumventing the need to maintain an exact representation of the cliques potentials."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681881"
                        ],
                        "name": "Xavier Boyen",
                        "slug": "Xavier-Boyen",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Boyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xavier Boyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5271129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9e7c948ec2d8ff655f9f51b4ddeb8b221eef8df",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Inference is a key component in learning probabilistic models from partially observable data. When learning temporal models, each of the many inference phases requires a traversal over an entire long data sequence; furthermore, the data structures manipulated are exponentially large, making this process computationally expensive. In [2], we describe an approximate inference algorithm for monitoring stochastic processes, and prove bounds on its approximation error. In this paper, we apply this algorithm as an approximate forward propagation step in an EM algorithm for learning temporal Bayesian networks. We provide a related approximation for the backward step, and prove error bounds for the combined algorithm. We show empirically that, for a real-life domain, EM using our inference algorithm is much faster than EM using exact inference, with almost no degradation in quality of the learned model. We extend our analysis to the online learning task, showing a bound on the error resulting from restricting attention to a small window of observations. We present an online EM learning algorithm for dynamic systems, and show that it learns much faster than standard offline EM."
            },
            "slug": "Approximate-Learning-of-Dynamic-Models-Boyen-Koller",
            "title": {
                "fragments": [],
                "text": "Approximate Learning of Dynamic Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown empirically that, for a real-life domain, EM using the authors' inference algorithm is much faster than EM using exact inference, with almost no degradation in quality of the learned model."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681881"
                        ],
                        "name": "Xavier Boyen",
                        "slug": "Xavier-Boyen",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Boyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xavier Boyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5556701,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92aea50331c19fe9716d3a9a02e26704afe24d88",
            "isKey": false,
            "numCitedBy": 617,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The monitoring and control of any dynamic system depends crucially on the ability to reason about its current status and its future trajectory. In the case of a stochastic system, these tasks typically involve the use of a belief state--a probability distribution over the state of the process at a given point in time. Unfortunately, the state spaces of complex processes are very large, making an explicit representation of a belief state intractable. Even in dynamic Bayesian networks (DBNs), where the process itself can be represented compactly, the representation of the belief state is intractable. We investigate the idea of maintaining a compact approximation to the true belief state, and analyze the conditions under which the errors due to the approximations taken over the lifetime of the process do not accumulate to make our answers completely irrelevant. We show that the error in a belief state contracts exponentially as the process evolves. Thus, even with multiple approximations, the error in our process remains bounded indefinitely. We show how the additional structure of a DBN can be used to design our approximation scheme, improving its performance significantly. We demonstrate the applicability of our ideas in the context of a monitoring task, showing that orders of magnitude faster inference can be achieved with only a small degradation in accuracy."
            },
            "slug": "Tractable-Inference-for-Complex-Stochastic-Boyen-Koller",
            "title": {
                "fragments": [],
                "text": "Tractable Inference for Complex Stochastic Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work investigates the idea of maintaining a compact approximation to the true belief state, and analyzes the conditions under which the errors due to the approximations taken over the lifetime of the process do not accumulate to make the authors' answers completely irrelevant."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786990"
                        ],
                        "name": "H. Attias",
                        "slug": "H.-Attias",
                        "structuredName": {
                            "firstName": "Hagai",
                            "lastName": "Attias",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Attias"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026where key groundwork for this thesis was performed\nIt has been a pleasure to exchange ideas with everyone at the Vision and Modeling group at the MIT Media Lab especially Martin Szummer Flavia Sparacino Ali Rahimi and Yuan Qi Thanks to Sumit Basu for providing his code for the billiard algorithm"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13371224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b4f8e1b4d781e3b47b72724d2e0c50fad87e464",
            "isKey": false,
            "numCitedBy": 633,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Current methods for learning graphical models with latent variables and a fixed structure estimate optimal values for the model parameters. Whereas this approach usually produces overfitting and suboptimal generalization performance, carrying out the Bayesian program of computing the full posterior distributions over the parameters remains a difficult problem. Moreover, learning the structure of models with latent variables, for which the Bayesian approach is crucial, is yet a harder problem. In this paper I present the Variational Bayes framework, which provides a solution to these problems. This approach approximates full posterior distributions over model parameters and structures, as well as latent variables, in an analytical manner without resorting to sampling methods. Unlike in the Laplace approximation, these posteriors are generally non-Gaussian and no Hessian needs to be computed. The resulting algorithm generalizes the standard Expectation Maximization algorithm, and its convergence is guaranteed. I demonstrate that this algorithm can be applied to a large class of models in several domains, including unsupervised clustering and blind source separation."
            },
            "slug": "Inferring-Parameters-and-Structure-of-Latent-Models-Attias",
            "title": {
                "fragments": [],
                "text": "Inferring Parameters and Structure of Latent Variable Models by Variational Bayes"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Variational Bayes framework is presented, which approximates full posterior distributions over model parameters and structures, as well as latent variables, in an analytical manner without resorting to sampling methods, and can be applied to a large class of models in several domains."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7607258"
                        ],
                        "name": "P. Saama",
                        "slug": "P.-Saama",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Saama",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Saama"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 54
                            }
                        ],
                        "text": "ADF has been independently proposed in the statistics (Lauritzen, 1992; Bernardo & Giron, 1988; Stephens, 1997), artificial intelligence (Boyen & Koller, 1998b; Opper & Winther, 1999; Barber & Sollich, 1999; Frey et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 63
                            }
                        ],
                        "text": "ADF was applied to this problem by Bernardo & Giron (1988) and Stephens (1997). Break the joint distribution p(D, w) into n + 1 terms as given by (3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 55
                            }
                        ],
                        "text": "It is an extension to assumed-density filtering (ADF), (Maybeck, 1982; Lauritzen, 1992; Bernardo & Giron, 1988; Stephens, 1997; Boyen & Koller, 1998b; Barber & Sollich, 1999; Opper & Winther, 1999; Frey et al., 2000) a one-pass, sequential method for computing an approximate posterior distribution."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 28
                            }
                        ],
                        "text": "Bernardo & Giron (1988) and Stephens (1997) show that this algorithm performs better than simpler rules like Directed Decision and Probabilistic Teacher."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117077842,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a2f66d35b75e5fa9f35c2c3c32b54ce4fec0d8be",
            "isKey": true,
            "numCitedBy": 121,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "MAXIMUM LIKELIHOOD AND BAYESIAN METHODS FOR MIXTURES OF NORMAL DISTRIBUTIONS. Peter M. Saama. UCLA Office of Academic Computing. November, 1997. A. ABSTRACT Data were waiting times between eruptions of the Old Faithful geyser in Yellowstone National Park, Wyoming, USA. The sample histogram showed evidence of bimodality. Forthwith, a twocomponent normal mixture model was fitted to the data. The Gauss-Newton algorithm was used to obtain the maximum likelihood estimate of the nuisance parameters in the mixture model. An alternative method which uses the Gibbs Sampler to obtain parameter estimates as well as 100(1FUHGLEOH EDQGV IRU WKH SDUDPHWHUV ZDV LPSOHPHQWHG DQG LV SUHVHQWHG B. INTRODUCTION Because of overdispersion and heterogeneity in the population, a mixture of distributions is often used to model the quantitative response. Such distributions are often considered appropriate models for thought to consist of a number of relatively distinct sub-populations (c). In situations where the number of components is unknown, mixture densities of the form ( ) \u2211 = k"
            },
            "slug": "MAXIMUM-LIKELIHOOD-AND-BAYESIAN-METHODS-FOR-OF-Saama",
            "title": {
                "fragments": [],
                "text": "MAXIMUM LIKELIHOOD AND BAYESIAN METHODS FOR MIXTURES OF NORMAL DISTRIBUTIONS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 114
                            }
                        ],
                        "text": "For example, we might replace the exact one-step posterior with a Gaussian having the same mean and same variance (Maybeck, 1982; Lauritzen, 1992; Barber & Sollich, 1999; Opper & Winther, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 54
                            }
                        ],
                        "text": "ADF has been independently proposed in the statistics (Lauritzen, 1992; Bernardo & Giron, 1988; Stephens, 1997), arti cial intelligence (Boyen & Koller, 1998b; Opper & Winther, 1999; Barber & Sollich, 1999; Frey et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 53
                            }
                        ],
                        "text": "It is an extension to assumed-density ltering (ADF), (Maybeck, 1982; Lauritzen, 1992; Bernardo & Giron, 1988; Stephens, 1997; Boyen & Koller, 1998b; Barber & Sollich, 1999; Opper & Winther, 1999; Frey et al., 2000) a one-pass, sequential method for computing an approximate posterior distribution."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17051088,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a87f270ac2c8420db2669e5e12abb6aff0755115",
            "isKey": false,
            "numCitedBy": 493,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A scheme is presented for modeling and local computation of exact probabilities, means, and variances for mixed qualitative and quantitative variables. The models assume that the conditional distribution of the quantitative variables, given the qualitative, is multivariate Gaussian. The computational architecture is set up by forming a tree of belief universes, and the calculations are then performed by local message passing between universes. The asymmetry between the quantitative and qualitative variables sets some additional limitations for the specification and propagation structure. Approximate methods when these are not appropriately fulfilled are sketched. It has earlier been shown how to exploit the local structure in the specification of a discrete probability model for fast and efficient computation, thereby paving the way for exploiting probability-based models as parts of realistic systems for planning and decision support. The purpose of this article is to extend this computational s..."
            },
            "slug": "Propagation-of-Probabilities,-Means,-and-Variances-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Propagation of Probabilities, Means, and Variances in Mixed Graphical Association Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The purpose of this article is to extend the local structure in the specification of a discrete probability model for fast and efficient computation, thereby paving the way for exploiting probability-based models as parts of realistic systems for planning and decision support."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724252"
                        ],
                        "name": "O. Winther",
                        "slug": "O.-Winther",
                        "structuredName": {
                            "firstName": "Ole",
                            "lastName": "Winther",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Winther"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14115671,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05db3fb6ab9550fb5a5cfaa57e56e8ad78e0a31b",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 93,
            "paperAbstract": {
                "fragments": [],
                "text": "The subject of this thesis is the derivation and study of Bayesian mean eld learning algorithms for feed-forward neural networks and Gaussian processes. In Bayes learning our posterior beliefs { based upon our a priori knowledge and past observations { are expressed as probabilities. Making predictions on new observations requires averaging over this posterior probability distribution. Mean eld techniques developed within the statistical physics of disordered systems are employed here to compute these averages. The resulting Bayesian algorithms are expressed as an extensive set of non-linear mean eld equations which may be solved by iteration. Two di erent formalisms are used to derive the mean eld equations, the cavity method and a saddle-point method. In the latter the mean eld equations are derived from the saddle-point of a variational mean eld free energy. Two di erent mean eld free energies are studied, a naive and the so-called TAP mean eld free energy. The cavity method and TAP saddle-point method give equivalent mean eld equations, although the derivation di ers. The naive and TAP approach give similar results in simulations, but the latter has the advantage that it may be analyzed theoretically, and one may derive estimators of the generalization error from the mean eld theory. The aims of this work are twofold. Firstly, to gain theoretical into insight how Bayes algorithm infers a rule given by a neural network. Besides deriving algorithms, the mean eld techniques may be used to derive the expected generalization error of the algorithms for learning scenarios in the thermodynamic limit. The results found show ne agreement between the average case analysis and simulations for learning scenarios in the simple perceptron and in the committee machine. Also Bayesian online and query algorithms are derived and studied theoretically. The second aim is to derive mean eld algorithms for use on real data. The mean eld algorithm is derived for Gaussian processes. This choice is very exible because, depending on the speci cation of the covariance function, di erent models may be tested. For example, one choice corresponds to the simple perceptron. The mean eld algorithms are tested on three small benchmark data sets for various covariance functions and the performances are found to be similar to the state of the art. Preface This thesis summarizes the results of my doctoral research. The work has been carried out at the Computational Neural Network Center, connect, The Niels Bohr Institute, University of Copenhagen and at Theoretical Physics, University of Lund. The thesis consists of two parts, an essay and a collection of reprinted papers. The rst part, as well as serving as an introduction to the reprinted paper, contains new results building upon the results of the papers. I wish to thank both my advisor, Benny Lautrup and my supervisor in Lund, Carsten Peterson for their guidance. I wish to thank everybody at connect and in the group in Lund for providing me with good places to do research. It has been a pleasure to work with my collaborators S ren Halkj r, Benny Lautrup, Manfred Opper, Sara S. Solla and Jian-Bo Zhang. A special thanks to Manfred Opper for his guidance and generosity in sharing his great insight into the eld. This work has been supported by the Danish Natural Science Council and the Danish Technical Research Council through connect. Most importantly, I wish to thank Mette and Rebecca for their love and inspiration. O.W. Copenhagen, Denmark May 1998 i"
            },
            "slug": "Bayesian-Mean-Field-Algorithms-for-Neural-Networks-Winther",
            "title": {
                "fragments": [],
                "text": "Bayesian Mean Field Algorithms for Neural Networks and Gaussian Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The derivation and study of Bayesian mean eld learning algorithms for feed-forward neural networks and Gaussian processes is carried out to gain theoretical into insight how Bayes algorithm infers a rule given by a neural network."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145617808"
                        ],
                        "name": "D. Barber",
                        "slug": "D.-Barber",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Barber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Barber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2613576"
                        ],
                        "name": "Peter Sollich",
                        "slug": "Peter-Sollich",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Sollich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Sollich"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30271192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b216e31e338a25beddf9b50f1671e39567be5baa",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Layered Sigmoid Belief Networks are directed graphical models in which the local conditional probabilities are parameterised by weighted sums of parental states. Learning and inference in such networks are generally intractable, and approximations need to be considered. Progress in learning these networks has been made by using variational procedures. We demonstrate, however, that variational procedures can be inappropriate for the equally important issue of inference - that is, calculating marginals of the network. We introduce an alternative procedure, based on assuming that the weighted input to a node is approximately Gaussian distributed. Our approach goes beyond previous Gaussian field assumptions in that we take into account correlations between parents of nodes. This procedure is specialized for calculating marginals and is significantly faster and simpler than the variational procedure."
            },
            "slug": "Gaussian-Fields-for-Approximate-Inference-in-Belief-Barber-Sollich",
            "title": {
                "fragments": [],
                "text": "Gaussian Fields for Approximate Inference in Layered Sigmoid Belief Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work introduces an alternative procedure, based on assuming that the weighted input to a node is approximately Gaussian distributed, which is specialized for calculating marginals and is significantly faster and simpler than the variational procedure."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3085659"
                        ],
                        "name": "H. Kushner",
                        "slug": "H.-Kushner",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Kushner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kushner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2410839"
                        ],
                        "name": "A. Budhiraja",
                        "slug": "A.-Budhiraja",
                        "structuredName": {
                            "firstName": "Amarjit",
                            "lastName": "Budhiraja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Budhiraja"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206479613,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "5ba10d0f146eb3b7862965d66afd8e43d26de5a9",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "An effective form of the Gaussian or moment approximation method for approximating optimal nonlinear filters with a diffusion signal process and discrete-time observations is presented. Various computational simplifications reduce the dimensionality of the numerical integrations that need to be done. This process, combined with an iterative Gaussian quadrature method, makes the filter effective for real-time use. The advantages are illustrated by a model that captures the general flavour of modeling the highly uncertain behavior of a ship near obstacles such as a shore line into which it cannot go, and must manoeuvre away in some unknown fashion. The observations are of very poor quality, yet the filter behaves well and is quite stable. The procedure does not rely on linearization, but attempts to compute the conditional moments directly by approximating the integrations used by the optimal filter."
            },
            "slug": "A-nonlinear-filtering-algorithm-based-on-an-of-the-Kushner-Budhiraja",
            "title": {
                "fragments": [],
                "text": "A nonlinear filtering algorithm based on an approximation of the conditional distribution"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An effective form of the Gaussian or moment approximation method for approximating optimal nonlinear filters with a diffusion signal process and discrete-time observations is presented and attempts to compute the conditional moments directly by approximating the integrations used by the optimal filter."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Autom. Control."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "79735252"
                        ],
                        "name": "Rong Chen",
                        "slug": "Rong-Chen",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50740237"
                        ],
                        "name": "Jun S. Liu",
                        "slug": "Jun-S.-Liu",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Liu",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun S. Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 121295804,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d84cd3bf37f677433db97b75123211854346639e",
            "isKey": false,
            "numCitedBy": 649,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "In treating dynamic systems, sequential Monte Carlo methods use discrete samples to represent a complicated probability distribution and use rejection sampling, importance sampling and weighted resampling to complete the on\u2010line \u2018filtering\u2019 task. We propose a special sequential Monte Carlo method, the mixture Kalman filter, which uses a random mixture of the Gaussian distributions to approximate a target distribution. It is designed for on\u2010line estimation and prediction of conditional and partial conditional dynamic linear models, which are themselves a class of widely used non\u2010linear systems and also serve to approximate many others. Compared with a few available filtering methods including Monte Carlo methods, the gain in efficiency that is provided by the mixture Kalman filter can be very substantial. Another contribution of the paper is the formulation of many non\u2010linear systems into conditional or partial conditional linear form, to which the mixture Kalman filter can be applied. Examples in target tracking and digital communications are given to demonstrate the procedures proposed."
            },
            "slug": "Mixture-Kalman-filters-Chen-Liu",
            "title": {
                "fragments": [],
                "text": "Mixture Kalman filters"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "79735252"
                        ],
                        "name": "Rong Chen",
                        "slug": "Rong-Chen",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50740237"
                        ],
                        "name": "Jun S. Liu",
                        "slug": "Jun-S.-Liu",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Liu",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun S. Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 48
                            }
                        ],
                        "text": "For background on Bayesian model selection, see MacKay (1995); Kass & Raftery (1993); Minka (2000a)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 48
                            }
                        ],
                        "text": "For background on Bayesian model selection, see MacKay (1995); Kass & Raftery (1993); Minka (2000a). A popular approach to model selection for the SVM is to minimize R2 M2 , where R is the radius of the smallest ball containing the training set (measured in the mapped feature space) and M is the margin (Cristianini et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7087401,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ab7c242cb7b23735bb7c91bb299391fce97dec21",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In treating dynamic systems, sequential Monte Carlo methods use discrete samples to represent a complicated probability distribution and use rejection sampling, importance sampling and weighted resampling to complete the on-lin\u00e8\u00aeltering' task. We propose a special sequential Monte Carlo method, the mixture Kalman \u00aelter, which uses a random mixture of the Gaussian distributions to approximate a target distribution. It is designed for on-line estimation and prediction of conditional and partial conditional dynamic linear models, which are themselves a class of widely used non-linear systems and also serve to approximate many others. Compared with a few available \u00aeltering methods including Monte Carlo methods, the gain in ef\u00aeciency that is provided by the mixture Kalman \u00aelter can be very substantial. Another contribution of the paper is the formulation of many non-linear systems into conditional or partial conditional linear form, to which the mixture Kalman \u00aelter can be applied. Examples in target tracking and digital communications are given to demonstrate the procedures proposed."
            },
            "slug": "Mixture-Kalman-\u00aelters-Chen-Liu",
            "title": {
                "fragments": [],
                "text": "Mixture Kalman \u00aelters"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14332165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ce9da2d2182a2fbc4b460bdb56d3c34110b3e39",
            "isKey": false,
            "numCitedBy": 896,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian probability theory provides a unifying framework for data modelling. In this framework the overall aims are to find models that are well-matched to the data, and to use these models to make optimal predictions. Neural network learning is interpreted as an inference of the most probable parameters for the model, given the training data. The search in model space (i.e., the space of architectures, noise models, preprocessings, regularizers and weight decay constants) can then also be treated as an inference problem, in which we infer the relative probability of alternative models, given the data. This review describes practical techniques based on Gaussian approximations for implementation of these powerful methods for controlling, comparing and using adaptive networks."
            },
            "slug": "Probable-networks-and-plausible-predictions-a-of-Mackay",
            "title": {
                "fragments": [],
                "text": "Probable networks and plausible predictions - a review of practical Bayesian methods for supervised neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Practical techniques based on Gaussian approximations for implementation of these powerful methods for controlling, comparing and using adaptive networks are described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145617808"
                        ],
                        "name": "D. Barber",
                        "slug": "D.-Barber",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Barber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Barber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792884"
                        ],
                        "name": "Charles M. Bishop",
                        "slug": "Charles-M.-Bishop",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles M. Bishop"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026where key groundwork for this thesis was performed\nIt has been a pleasure to exchange ideas with everyone at the Vision and Modeling group at the MIT Media Lab especially Martin Szummer Flavia Sparacino Ali Rahimi and Yuan Qi Thanks to Sumit Basu for providing his code for the billiard algorithm"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18903411,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "278600ebe6f56c6e1363788f464b9138bbdef35f",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian treatments of learning in neural networks are typically based either on local Gaussian approximations to a mode of the posterior weight distribution, or on Markov chain Monte Carlo simulations. A third approach, called ensemble learning, was introduced by Hinton and van Camp (1993). It aims to approximate the posterior distribution by minimizing the Kullback-Leibler divergence between the true posterior and a parametric approximating distribution. However, the derivation of a deterministic algorithm relied on the use of a Gaussian approximating distribution with a diagonal covariance matrix and so was unable to capture the posterior correlations between parameters. In this paper, we show how the ensemble learning approach can be extended to full-covariance Gaussian distributions while remaining computationally tractable. We also extend the framework to deal with hyperparameters, leading to a simple re-estimation procedure. Initial results from a standard benchmark problem are encouraging."
            },
            "slug": "Ensemble-Learning-for-Multi-Layer-Networks-Barber-Bishop",
            "title": {
                "fragments": [],
                "text": "Ensemble Learning for Multi-Layer Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper shows how the ensemble learning approach can be extended to full-covariance Gaussian distributions while remaining computationally tractable, and extends the framework to deal with hyperparameters, leading to a simple re-estimation procedure."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773821"
                        ],
                        "name": "Matthew J. Beal",
                        "slug": "Matthew-J.-Beal",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Beal",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew J. Beal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026where key groundwork for this thesis was performed\nIt has been a pleasure to exchange ideas with everyone at the Vision and Modeling group at the MIT Media Lab especially Martin Szummer Flavia Sparacino Ali Rahimi and Yuan Qi Thanks to Sumit Basu for providing his code for the billiard algorithm"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3219667,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f46dd0b2dc85fe72c2c145749343feee264390e8",
            "isKey": false,
            "numCitedBy": 456,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm that infers the model structure of a mixture of factor analysers using an efficient and deterministic variational approximation to full Bayesian integration over model parameters. This procedure can automatically determine the optimal number of components and the local dimensionality of each component (i.e. the number of factors in each factor analyser). Alternatively it can be used to infer posterior distributions over number of components and dimensionalities. Since all parameters are integrated out the method is not prone to overfitting. Using a stochastic procedure for adding components it is possible to perform the variational optimisation incrementally and to avoid local maxima. Results show that the method works very well in practice and correctly infers the number and dimensionality of nontrivial synthetic examples. \n \nBy importance sampling from the variational approximation we show how to obtain unbiased estimates of the true evidence, the exact predictive density, and the KL divergence between the variational posterior and the true posterior, not only in this model but for variational approximations in general."
            },
            "slug": "Variational-Inference-for-Bayesian-Mixtures-of-Ghahramani-Beal",
            "title": {
                "fragments": [],
                "text": "Variational Inference for Bayesian Mixtures of Factor Analysers"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An algorithm is presented that infers the model structure of a mixture of factor analysers using an efficient and deterministic variational approximation to full Bayesian integration over model parameters and shows how to obtain unbiased estimates of the true evidence, the exact predictive density, and the KL divergence between the variational posterior and the true posterior."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3198578"
                        ],
                        "name": "J. Yedidia",
                        "slug": "J.-Yedidia",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Yedidia",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yedidia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 141225804,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "91699ea4bec60d4d47ca3db8c8d1e035d069d9e4",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "I try to clarify the relationships between different ways of deriving or correcting mean field theory, and present \u201dtranslations\u201d between the language of physicists and that of computer scientists. The connecting thread between the different methods described here is the Gibbs free energy. After introducing the inference problem we are interested in analyzing, I will define the Gibbs free energy, and describe how to derive a mean field approximation to it using a variational approach. I will then explain how one might re-derive and correct the mean field and TAP free energies using high temperature expansions with constrained one-node beliefs. I will explore the relationships between the high-temperature expansion approach, the Bethe approximation, and the belief propagation algorithm, and point out in particular the equivalence of the Bethe approximation and belief propagation. Finally, I will describe Kikuchi approximations to the Gibbs Free energy and advertise new belief propagation algorithms that efficiently compute beliefs equivalent to those obtained from the Kikuchi free energy. To appear as a chapter in \u201cAdvanced Mean Field Methods Theory and Practice\u201d, eds. D. Saad and M. Opper, MIT Press, 2000. This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Information Technology Center America; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Information Technology Center America. All rights reserved. Copyright c Mitsubishi Electric Information Technology Center America, 2000 201 Broadway, Cambridge, Massachusetts 02139 Publication History:\u2013 1. First printing, TR-2000-27, June 2000 ! \" # %$& ' () * ,+ .-0/ 1 2 314#57698#5 4;:= A@CB#DEB#DE5 F < F G 4,69H 3IB J#KL6MDE314 NPORQTS UWV)XYS'ZL[7Q]\\_^`NAabUdcec QT^]fgQ]hiXjcWZL^]UlkmfnQTS \\o^T\\9cdZLQTUdhpO VTS Ud[ Vrq1\\jQsat\\_\\9Ovu7Ulw,\\_^]\\_O Q atZxf7V)hLkyu7\\9^TUdzCUeO {nhp^|Xjh ^T^]\\9XjQTUdO {i}|\\9ZpO\u007f~ \\9cduvQTS \\9hp^]fp\u0080 \u0081 S \\\"\u0082y\\MXj\\_})q'\\9^0\u0083M\u0084p\u0084 \u0084 \u0085\u0086Ns\u0087 \u0088nathp^]\u00897V\u008aS h [ih O!\u008b]\u008cyu7z ZpO Xj\\Mun\u008d\u008e\\MZLO\u007f\u008f#Ue\\9cduR\u008d\u008e\\_QTS h7u V]\u0090\u008eVT\u0091 X_X_\\_\\9u \\9u O UWXj\\_cdf UeO q ^]UeO { UeO {\u0092Q]hp{p\\_QTS \\9^A[ SCfCVTUWXjUWVsQYV\u0093ZpO u Xjhp}|[ \u0091 QT\\_^rV]XjUd\\_O QTUWV\u008aQ]V9\u0094 abS h0O h atZ u Zxf7V hLk\u0095QT\\9O0athp^]\u0089|hpO0[ ^T\\MXjUWV\u008a\\9cef\u0096Q]S \\rVTZp}\u0096\\\u0097[ ^]hpq cd\\_}\u0098V9\u0094 q \u00917Q\u0086Xjhp}|\\\u0097QTh)QTS \\MV\u008a\\\u0093[ ^]hpq cd\\_}\u0098V abUlQ]S%u7Uew1\\9^T\\9O Qn['\\9^]VT['\\MX\u0099Q]Uez \\9V9\u0094y}|\\jQ]S h7u V_\u0094\u0093O Zp}\u0096\\MViZpO u O hLQYZ Q]Ueh O V_\u0080\u0093\u0088Chp}|\\\u009ahpk QTS UWV\u0086XYS Zp[7QT\\9^bUdVtQ]S \\_^]\\jkmh ^T\\ru7\\9zphLQ]\\9u\u0092QTh|[ ^]\\9VT\\_O QTUdO {\u0096QT^YZLO'V\u008acWZ Q]Ueh O Vtq'\\_Qsa \\9\\_O0QTS \\ cdZpO {p\u0091 Zp{p\\0hLkyQ]S \\\"[ SCf7V\u008aUWXjUWVsQ\u0098ZLO'uvQ]S \\\"cdZpO {p\u0091 Zp{p\\0hLk\u0086Q]S \\\u008eXjhp}|[ \u0091 QT\\_^oV]XjUd\\_O Q]UdV\u008aQ9\u0094 ZLceQTS h \u0091 {pSvN`Zp}\u009bV\u008a\u0091 ^]\\oQ]S Z Q\u0096}\u009cfRhp^]Ud{pUdO ZLc QT^YZLUdO UeO {nZpV)Zg[ SCf7VTUdX_UdV\u008aQ)abUdcec VTS h a QTS ^]hp\u0091 { SI\u0080 N abUecdc hpO cef\u009cX_h zp\\9^#}|\\_QTS h7u V?Q]S Z Q N#S Zxzp\\t[1\\_^YV\u008ah O ZLcdcefr\u0091'V\u008a\\Mu \u0094pVTh\u0097Q]S UWV XYS ZL[7Q]\\_^ u7hC\\9V\u007fO hpQ\u009aZ QTQT\\_}|[7Q\u009aQTh\u009dq1\\\u009eZ!QTS h ^Th \u0091 {pS\u009fVT\u0091 ^Tz \\_f.hpk UeQ]V\u009aV\u008a\u0091 q is\\9X\u0099QM\u0080)\u00a2b\\MZpu7\\9^]V UeO QT\\9^T\\MVsQ]\\9uRUdOv}|hp^]\\oq Z XY\u0089 { ^Th \u0091 O u hpORQ]S \\0V\u008aQ]ZLQTUWVsQ]UdX9ZLc [ SCfCVTUWX_V`hpkyu7UWV\u008ah ^]u7\\9^T\\Mu V\u008af7V\u008aQT\\_}\u0098V \u00a3m[ Zp^\u008aQ]UdX_\u0091 cWZL^]cef\u00a4abUeQTS\u009e^]\\_{ ZL^Yu\u00a5QTh\u009aQTS \\nQT\\MXYS O UW\u00a6 \u0091 \\nhpk)Zxzp\\9^]Zp{pUdO {Rh zp\\_^ u7UdVThp^Yu7\\9^ \u0091 V\u008aUdO {rQ]S \\\u0086^]\\_[ cdUWX_Z\u0093}|\\jQTS hCu'\u00a7 }|Ue{ S Q ZLcWV\u008ahra ZLO Q QTh`X_hpO VT\u0091 ceQ ^]\\jkm\\_^]\\_O'Xj\\9V \u00a3s\u00839\u0084 \u00a7\u0099\u0094)\u00a3 L\u00a9 \u00a7\u0099\u0094\u0097ZpO u\u009f\u00a3Ea \u0083M\u00a7\u0099\u0094\u0097abS Udce\\RQ]S h VT\\vUdO Q]\\_^]\\9V\u008aQT\\Mu;UdO QTS \\\u009aXjh }\u0096[ \u00917QT\\9^iVTX_Ue\\9O Xj\\ ceUeQT\\9^]ZLQT\u0091 ^]\\\u0098hpO\u007f{ ^]Zp[ S UWX_ZLc }\u0096h7u7\\9cdV\u009c}|Ue{ S Q\u009cX_hpO VT\u0091 ceQ\u009c^]\\jkm\\_^]\\_O'Xj\\9V\u0092\u00a3* La \u00a7\u0099\u0094t\u00a3s\u0083p\u0083M\u00a7`ZLO'u \u00a3 \u00abL\u00a7j\u0080 \u0081 S \\\u0086X_hpO O \\9X\u0099Q]UeO {\u0097Q]S ^]\\9Zpu\u0096q1\\jQsat\\_\\9O)Q]S \\\u0086u7Uew1\\9^T\\9O Q=}\u0096\\_QTS h7u V u7\\9V]Xj^]Ueq1\\9u\u0096S \\9^T\\ UdV QTS \\r\u00ac\u0093Udq q V km^T\\9\\y\\_O \\_^]{pfp\u0080C\u008cbk\u0095Q]\\_^tUeO Q]^Th7u7\u0091 X_UeO {`QTS \\\u0097UdO7km\\_^]\\_O'Xj\\y[ ^Th q ce\\9}\u009fa \\yZp^T\\ UeO QT\\9^T\\MVsQ]\\9u\u0092UeO ZLO ZpcefC\u00ad_UdO {'\u0094 N=abUdcdcIu7\\j~ O \\yQ]S \\`\u00ac\u0093Ueq q'V km^]\\_\\\u0093\\_O \\_^]{pfp\u0094CZLO'u\u0092u7\\MVTX_^TUdq'\\ S h a\u009dQTh\u008eu7\\9^TUdzp\\\u0096Z\u0092}|\\MZLOn~ \\_cWunZp[ [ ^]hx\u00ae7Ue}\u0098Z Q]Ueh O\"QTh\"UeQA\u0091'V\u008aUdO {\"Z\u0092z ZL^]UWZ QTUdhpO'ZLc?ZL[7 [ ^Th ZpXYSI\u0080MNIabUdcecCQ]S \\_O\u0096\\j\u00ae7[ cWZLUdO\u009cS h avhpO \\t}|Ue{ S Q#^]\\j Pu7\\_^]Udzp\\ ZpO u\u009cX_hp^]^T\\MX\u0099Q QTS \\ }|\\9ZpO ~ \\_cWu)ZpO u\u0096\u0081 \u008c\u0097\u0087gkm^]\\_\\ \\_O \\_^]{pUd\\9V \u0091 V\u008aUdO {AS Ud{pS\u009cQT\\_}|[1\\_^YZ Q]\u0091 ^T\\ \\_\u00aeC['ZLO VTUeh O V abUlQ]S\u0096X_hpO7 VsQ]^]ZpUeO \\Mu\u007fhpO \\j \u00b0O h7u7\\\u0092q1\\_cdUe\\_kEV_\u0080 N\u009cabUecdc \\j\u00ae7[ cdhp^]\\\u0098QTS \\\"^]\\_cWZ Q]Ueh O V\u008aS Ue[ V\u009cq'\\_Qsa \\9\\_O\u009aQTS \\ S Ue{ S7 QT\\_}|[1\\_^YZ Q]\u0091 ^T\\i\\j\u00ae7[ ZLO'V\u008aUdhpO\u00b1Zp[ [ ^]h ZpXYS \u0094 QTS \\R2t\\jQ]S \\nZp[ [ ^]hx\u00aeCUd}\u0098Z Q]Ueh OI\u0094 ZLO'u QTS \\Aq1\\_cdUe\\_k#[ ^]hp['ZL{ ZLQTUdhpO\u0092Zpce{ hp^]UlQ]S }\"\u00947ZLO u\u0092['h UeO Qbhp\u00917QbUdO0['ZL^TQTUWXj\u0091 cWZL^tQTS \\\u0093\\M\u00a6 \u0091 Uez ZLcd\\_O X_\\bhLk1QTS \\y2t\\_QTS \\yZp[ [ ^]hx\u00ae7Ue}\u0098Z Q]Ueh O)ZpO u|q'\\9ceUd\\jk [ ^]hp['ZL{ ZLQTUdhpOI\u0080 \u008f#UdO ZLcdcef \u0094pN#abUecdc u7\\9V]Xj^]Ueq1\\o3AUd\u0089 \u0091'XYS U ZL[ [ ^Thx\u00ae7Ud}\u0098Z QTUdhpO'V\u0093QTh\"QTS \\0\u00ac\u0093Ueq q V\u009c\u008f ^T\\9\\\u0098\\_O \\9^T{ fnZLO'u Z u7zp\\9^\u008a QTUWV\u008a\\0O \\_a q1\\_cdUe\\_k\u0086[ ^]hp[ Zp{ Z Q]Ueh O Zpce{ hp^]UlQ]S }\u0098VrQ]S Z Q\u0096\\j\u03bcoXjUd\\_O QTcdfRXjhp}|[ \u0091 QT\\\u0092q1\\_cdUd\\jkEV \\9\u00a6 \u0091 UdzxZpce\\9O QtQ]h|QTS h V\u008a\\Ah q7Q]ZpUeO \\Mu0km^Th } QTS \\`3AUd\u0089C\u0091 XYS U,km^]\\_\\A\\_O \\_^]{pfp\u0080 \u00b6A\u00b7\u0095 \u008e11o \u00bbs1\u20444*1\u20444 \u00b6r1\u20442]3\u20444*? AYA#\u00c2jAYA\u0099A\u0099A\u0099AjAYA\u0099AjA9AEsCxEEAE\u008aEME E\u0099II1'1\u20442YI\u0099\u00bb AE"
            },
            "slug": "An-Idiosyncratic-Journey-Beyond-Mean-Field-Theory-Yedidia",
            "title": {
                "fragments": [],
                "text": "An Idiosyncratic Journey Beyond Mean Field Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2228643"
                        ],
                        "name": "Relu Patrascu",
                        "slug": "Relu-Patrascu",
                        "structuredName": {
                            "firstName": "Relu",
                            "lastName": "Patrascu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Relu Patrascu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057604686"
                        ],
                        "name": "Jodi Moran",
                        "slug": "Jodi-Moran",
                        "structuredName": {
                            "firstName": "Jodi",
                            "lastName": "Moran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jodi Moran"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3185986,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e4768e4a4d452befe71ad0c0ce66291f3d377819",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "An important class of problems can be cast as inference in noisy-OR Bayesian networks, where the binary state of each variable is a logical OR of noisy versions of the states of the variable's parents. For example, in medical diagnosis, the presence of a symptom can be expressed as a noisy-OR of the diseases that may cause the symptom - on some occasions, a disease may fail to activate the symptom. Inference in richly-connected noisy-OR networks is intractable, but approximate methods (e.g., variational techniques) are showing increasing promise as practical solutions. One problem with most approximations is that they tend to concentrate on a relatively small number of modes in the true posterior, ignoring other plausible configurations of the hidden variables. We introduce a new sequential variational method for bipartite noisy-OR networks, that favors including all modes of the true posterior and models the posterior distribution as a tree. We compare this method with other approximations using an ensemble of networks with network statistics that are comparable to the QMR-DT medical diagnostic network."
            },
            "slug": "Sequentially-Fitting-\"Inclusive\"-Trees-for-in-Frey-Patrascu",
            "title": {
                "fragments": [],
                "text": "Sequentially Fitting \"Inclusive\" Trees for Inference in Noisy-OR Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A new sequential variational method is introduced for bipartite noisy-OR networks, that favors including all modes of the true posterior and models the posterior distribution as a tree."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145617808"
                        ],
                        "name": "D. Barber",
                        "slug": "D.-Barber",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Barber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Barber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783429"
                        ],
                        "name": "W. Wiegerinck",
                        "slug": "W.-Wiegerinck",
                        "structuredName": {
                            "firstName": "Wim",
                            "lastName": "Wiegerinck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wiegerinck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16049210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eee1c6295c7778a966261424c9d48ff78fb072be",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphical models provide a broad probabilistic framework with applications in speech recognition (Hidden Markov Models), medical diagnosis (Belief networks) and artificial intelligence (Boltzmann Machines). However, the computing time is typically exponential in the number of nodes in the graph. Within the variational framework for approximating these models, we present two classes of distributions, decimatable Boltzmann Machines and Tractable Belief Networks that go beyond the standard factorized approach. We give generalised mean-field equations for both these directed and undirected approximations. Simulation results on a small benchmark problem suggest using these richer approximations compares favorably against others previously reported in the literature."
            },
            "slug": "Tractable-Variational-Structures-for-Approximating-Barber-Wiegerinck",
            "title": {
                "fragments": [],
                "text": "Tractable Variational Structures for Approximating Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work presents two classes of distributions, decimatable Boltzmann Machines and Tractable Belief Networks that go beyond the standard factorized approach, and gives generalised mean-field equations for both these directed and undirected approximations."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1889982"
                        ],
                        "name": "F. Kschischang",
                        "slug": "F.-Kschischang",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Kschischang",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kschischang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143681410"
                        ],
                        "name": "H. Loeliger",
                        "slug": "H.-Loeliger",
                        "structuredName": {
                            "firstName": "Hans-Andrea",
                            "lastName": "Loeliger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Loeliger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1520,
                                "start": 50
                            }
                        ],
                        "text": "In fact, it is the form used in in factor graphs (Kschischang et al., 2000). All of the nodes that participate in a conditional probability table p(Xjpa(X)) send messages to each other based on their partial belief states. This algorithm applies generally to any decomposition into terms t(x), not just that given by (4.18). For example, equivalence also holds for undirected networks, if the terms ti are the clique potentials-compare to the equations in Yedidia et al. (2000). See section 4.2 for an example with an undirected network. The remaining difference between belief propagation and EP is that belief propagation does not specify the order in which messages are sent. In the EP algorithm above, each node must exchange messages with all of its parents at each step. However, we can relax this condition by considering a simple variation of EP, where we do not minimize KLdivergence completely at each step, but only partially. Specifically, we only update one of the tik functions each time. With this variation, we can pass messages in any order. This reordering will not change the result at convergence. This equivalence shows that there is a close connection between Boyen & Koller's algorithm and loopy belief propagation. Boyen & Koller's algorithm for dynamic Bayesian networks is simply one pass of loopy belief propagation where each term ti is the product of multiple conditional probability tables-all of the tables for a given timeslice. This equivalence was also noticed by Murphy & Weiss (2000), though described in terms of modifications to the graph."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 48
                            }
                        ],
                        "text": "For background on Bayesian model selection, see MacKay (1995); Kass & Raftery (1993); Minka (2000a). A popular approach to model selection for the SVM is to minimize , where R is the radius of the smallest ball containing the training set (measured in the mapped feature space) and M is the margin (Cristianini et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 49
                            }
                        ],
                        "text": "In fact, it is the form used in in factor graphs (Kschischang et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 48
                            }
                        ],
                        "text": "For background on Bayesian model selection, see MacKay (1995); Kass & Raftery (1993); Minka (2000a)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 478,
                                "start": 50
                            }
                        ],
                        "text": "In fact, it is the form used in in factor graphs (Kschischang et al., 2000). All of the nodes that participate in a conditional probability table p(Xjpa(X)) send messages to each other based on their partial belief states. This algorithm applies generally to any decomposition into terms t(x), not just that given by (4.18). For example, equivalence also holds for undirected networks, if the terms ti are the clique potentials-compare to the equations in Yedidia et al. (2000). See section 4."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14394619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08c370eb9ba13bfb836349e7f3ea428be4697818",
            "isKey": true,
            "numCitedBy": 4132,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms that must deal with complicated global functions of many variables often exploit the manner in which the given functions factor as a product of \"local\" functions, each of which depends on a subset of the variables. Such a factorization can be visualized with a bipartite graph that we call a factor graph, In this tutorial paper, we present a generic message-passing algorithm, the sum-product algorithm, that operates in a factor graph. Following a single, simple computational rule, the sum-product algorithm computes-either exactly or approximately-various marginal functions derived from the global function. A wide variety of algorithms developed in artificial intelligence, signal processing, and digital communications can be derived as specific instances of the sum-product algorithm, including the forward/backward algorithm, the Viterbi algorithm, the iterative \"turbo\" decoding algorithm, Pearl's (1988) belief propagation algorithm for Bayesian networks, the Kalman filter, and certain fast Fourier transform (FFT) algorithms."
            },
            "slug": "Factor-graphs-and-the-sum-product-algorithm-Kschischang-Frey",
            "title": {
                "fragments": [],
                "text": "Factor graphs and the sum-product algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A generic message-passing algorithm, the sum-product algorithm, that operates in a factor graph, that computes-either exactly or approximately-various marginal functions derived from the global function."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103816063"
                        ],
                        "name": "Ole WintherWe",
                        "slug": "Ole-WintherWe",
                        "structuredName": {
                            "firstName": "Ole",
                            "lastName": "WintherWe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ole WintherWe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11494535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d39f9fca08678ab835f588b8237da9257ccceb2",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a TAP mean eld approach to models with quadratic interactions which does not assume a speciic randomness of the couplings but rather adapts to the concrete data. The method is based on an extra set of mean eld equations for the Onsager correction term to the naive mean eld result. We present applications for the Hoppeld model and for a Bayesian classiier. 1.1 Introduction Mean eld (MF) methods provide eecient approximations which are able to cope with the increasing complexity of modern probabilistic data models. They replace the intractable task of computing high dimensional sums and integrals by the tractable problem of solving a system of nonlinear equations. The TAP (21) MF approach represents a principled way for correcting the deeciencies of simple MF methods which are based on the crude approximation of replacing the intractable distribution by a fac-torized one, thereby neglecting important correlations between variables. In contrast, the TAP method takes into account nontrivial dependencies by estimating the reaction of all other random variables when a single variable is deleted from the system (8). The method has its origin in the statistical physics of amorphous systems, where it was developed by Thouless, Anderson and Palmer (TAP) to treat the Sherrington-Kirkpatrick (SK) model of disordered magnetic materials (19). Under the assumption that the couplings (or interactions) between random variables are themselves drawn at random from certain classes of distributions, the TAP equations provide an exact result in the 'thermodynamic limit' of innnitely many variables. The 'Onsager correction' to the simple or 'naive' MF theory will explicitly depend on the distribution of these couplings. Two models with the same connectivities but diierent distributions for the couplings, like e.g. the SK model and the Hoppeld model (5) have diierent expressions for the TAP corrections (see e.g. (8), chapter XIII). In order to use the TAP method as a good approximation for practical applications to real data, the lack of knowledge of the underlying"
            },
            "slug": "Adaptive-Tap-Equations-WintherWe",
            "title": {
                "fragments": [],
                "text": "Adaptive Tap Equations"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A TAP mean eld approach to models with quadratic interactions which does not assume a speciic randomness of the couplings but rather adapts to the concrete data, a principled way for correcting the deeciencies of simple MF methods which are based on the crude approximation of replacing the intractable distribution by a fac-torized one."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60985485,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6daf578847accea9775b21bb2ecb07b9e49c6656",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Online learning is discussed from the viewpoint of Bayesian statistical inference. By replacing the true posterior distribution with a simpler parametric distribution, one can define an online algorithm by a repetition of two steps: An update of the approximate posterior, when a new example arrives, and an optimal projection into the parametric family. Choosing this family to be Gaussian, we show that the algorithm achieves asymptotic efficiency. An application to learning in single layer neural networks is given."
            },
            "slug": "A-Bayesian-approach-to-on-line-learning-Opper",
            "title": {
                "fragments": [],
                "text": "A Bayesian approach to on-line learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Choosing this family to be Gaussian, it is shown that the algorithm achieves asymptotic efficiency and an application to learning in single layer neural networks is given."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058177533"
                        ],
                        "name": "Simon Tong",
                        "slug": "Simon-Tong",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Tong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Tong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8223567,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "06a154b63c9e49840ded076ebe9e9915ea672e99",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the notion of restricted Bayes optimal classifiers . These classifiers attempt to combine the flexibility of the generative approach to classification with the high accuracy associated with discriminative learning. They first create a model of the joint distribution over class labels and features. Instead of choosing the decision boundary induced directly from the model, they restrict the allowable types of decision boundaries and learn the one that minimizes the probability of misclassification relative to the estimated joint distribution. In this paper, we investigate two particular instantiations of this approach. The first uses a non-parametric density estimator \u2014 Parzen Windows with Gaussian kernels \u2014 and hyperplane decision boundaries. We show that the resulting classifier is asymptotically equivalent to a maximal margin hyperplane classifier, a highly successful discriminative classifier. We therefore provide an alternative justification for maximal margin hyperplane classifiers. The second instantiation uses a mixture of Gaussians as the estimated density; in experiments on real-world data, we show that this approach allows data with missing values to be handled in a principled manner, leading to improved performance over regular discriminative approaches."
            },
            "slug": "Restricted-Bayes-Optimal-Classifiers-Tong-Koller",
            "title": {
                "fragments": [],
                "text": "Restricted Bayes Optimal Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper investigates two particular instantiations of the notion of restricted Bayes optimal classifiers, and shows that the first uses a non-parametric density estimator \u2014 Parzen Windows with Gaussian kernels \u2014 and hyperplane decision boundaries and is asymptotically equivalent to a maximal margin hyperplane classifier, a highly successful discriminative classifier."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9512569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef7a83d4d17020cb7ef3bcadfbd9c9d5863c2f28",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The Factored Frontier (FF) algorithm is a simple approximate inference algorithm for Dynamic Bayesian Networks (DBNs). It is very similar to the fully factorized version of the Boyen-Koller (BK) algorithm, but instead of doing an exact update at every step followed by marginalisation (projection), it always works with factored distributions. Hence it can be applied to models for which the exact update step is intractable. We show that FF is equivalent to (one iteration of) loopy belief propagation (LBP) on the original DBN, and that BK is equivalent (to one iteration of) LBP on a DBN where we cluster some of the nodes. We then show empirically that by iterating more than once, LBP can improve on the accuracy of both FF and BK. We compare these algorithms on two real-world DBNs: the first is a model of a water treatment plant, and the second is a coupled HMM, used to model freeway traffic."
            },
            "slug": "The-Factored-Frontier-Algorithm-for-Approximate-in-Murphy-Weiss",
            "title": {
                "fragments": [],
                "text": "The Factored Frontier Algorithm for Approximate Inference in DBNs"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that FF is equivalent to loopy belief propagation (LBP) on the original DBN, and that BK is equivalent (to one iteration of) LBP on a DBN where the authors cluster some of the nodes, and empirically that by iterating more than once, LBP can improve on the accuracy of both FF and BK."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13026917,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "ee606afe92d1998d516f1e2599ddf8a386880d2a",
            "isKey": false,
            "numCitedBy": 584,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider a logistic regression model with a Gaussian prior distribution over the parameters. We show that an accurate variational transformation can be used to obtain a closed form approximation to the posterior distribution of the parameters thereby yielding an approximate posterior predictive model. This approach is readily extended to binary graphical model with complete observations. For graphical models with incomplete observations we utilize an additional variational transformation and again obtain a closed form approximation to the posterior. Finally, we show that the dual of the regression problem gives a latent variable density model, the variational formulation of which leads to exactly solvable EM updates."
            },
            "slug": "Bayesian-parameter-estimation-via-variational-Jaakkola-Jordan",
            "title": {
                "fragments": [],
                "text": "Bayesian parameter estimation via variational methods"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "It is shown that an accurate variational transformation can be used to obtain a closed form approximation to the posterior distribution of the parameters thereby yielding an approximate posterior predictive model."
            },
            "venue": {
                "fragments": [],
                "text": "Stat. Comput."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792269"
                        ],
                        "name": "H. Kappen",
                        "slug": "H.-Kappen",
                        "structuredName": {
                            "firstName": "Hilbert",
                            "lastName": "Kappen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kappen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783429"
                        ],
                        "name": "W. Wiegerinck",
                        "slug": "W.-Wiegerinck",
                        "structuredName": {
                            "firstName": "Wim",
                            "lastName": "Wiegerinck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wiegerinck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2726798,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d922611468cd4ee520aa4afb538825cf62f098a",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we derive a second order mean field theory for directed graphical probability models. By using an information theoretic argument it is shown how this can be done in the absense of a partition function. This method is a direct generalisation of the well-known TAP approximation for Boltzmann Machines. In a numerical example, it is shown that the method greatly improves the first order mean field approximation. For a restricted class of graphical models, so-called single overlap graphs, the second order method has comparable complexity to the first order method. For sigmoid belief networks, the method is shown to be particularly fast and effective."
            },
            "slug": "Second-Order-Approximations-for-Probability-Models-Kappen-Wiegerinck",
            "title": {
                "fragments": [],
                "text": "Second Order Approximations for Probability Models"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A second order mean field theory for directed graphical probability models for Boltzmann Machines is derived by using an information theoretic argument how this can be done in the absense of a partition function."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50318312"
                        ],
                        "name": "A. Buhot",
                        "slug": "A.-Buhot",
                        "structuredName": {
                            "firstName": "Arnaud",
                            "lastName": "Buhot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Buhot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145764383"
                        ],
                        "name": "J. Moreno",
                        "slug": "J.-Moreno",
                        "structuredName": {
                            "firstName": "Jes\u00fas M.",
                            "lastName": "Moreno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Moreno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153945"
                        ],
                        "name": "M. B. Gordon",
                        "slug": "M.-B.-Gordon",
                        "structuredName": {
                            "firstName": "Mirta",
                            "lastName": "Gordon",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. B. Gordon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 139
                            }
                        ],
                        "text": "Bayesian averaging of linear classifiers has been proven both theoretically and empirically optimal in terms of generalization performance (Watkin, 1993; Bouten et al., 1995; Buhot et al., 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15229238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31b53003aba9b94e9d5238a4d867da840931c0de",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We study numerically the properties of the Bayesian perceptron through a gradient descent on the optimal cost function. The theoretical distribution of stabilities is deduced. It predicts that the optimal generalizer lies close to the boundary of the space of ~error-free! solutions. The numerical simulations are in good agreement with the theoretical distribution. The extrapolation of the generalization error to infinite input space size agrees with the theoretical results. Finite size corrections are negative and exhibit two different scaling regimes, depending on the training set size. The variance of the generalization error vanishes for N!\u2018 confirming the property of self-averaging. @S1063-651X~97!15406-X#"
            },
            "slug": "Finite-size-scaling-of-the-Bayesian-perceptron-Buhot-Moreno",
            "title": {
                "fragments": [],
                "text": "Finite size scaling of the Bayesian perceptron"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The theoretical distribution of stabilities is deduced and it predicts that the optimal generalizer lies close to the boundary of the space of ~error-free! solutions, confirming the property of self-averaging."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122944385,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b5571a1cf9d3f640883812358498f64c1655d5a",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Mean field methods provide computationally efficient approximations to posterior probability distributions for graphical models. Simple mean field methods make a completely factorized approximation to the posterior, which is unlikely to be accurate when the posterior is multimodal. Indeed, if the posterior is multi-modal, only one of the modes can be captured. To improve the mean field approximation in such cases, we employ mixture models as posterior approximations, where each mixture component is a factorized distribution. We describe efficient methods for optimizing the Parameters in these models."
            },
            "slug": "Improving-the-Mean-Field-Approximation-Via-the-Use-Jaakkola-Jordan",
            "title": {
                "fragments": [],
                "text": "Improving the Mean Field Approximation Via the Use of Mixture Distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work employs mixture models as posterior approximations, where each mixture component is a factorized distribution, and describes efficient methods for optimizing the Parameters in these models."
            },
            "venue": {
                "fragments": [],
                "text": "Learning in Graphical Models"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2454055"
                        ],
                        "name": "A. Gelfand",
                        "slug": "A.-Gelfand",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Gelfand",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gelfand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109352679"
                        ],
                        "name": "Adrian F. M. Smith",
                        "slug": "Adrian-F.-M.-Smith",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Smith",
                            "middleNames": [
                                "F.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adrian F. M. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53446269,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d990deca66c9afefbe042f95e41ada0c7227877",
            "isKey": false,
            "numCitedBy": 7053,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Stochastic substitution, the Gibbs sampler, and the sampling-importance-resampling algorithm can be viewed as three alternative sampling- (or Monte Carlo-) based approaches to the calculation of numerical estimates of marginal probability distributions. The three approaches will be reviewed, compared, and contrasted in relation to various joint probability structures frequently encountered in applications. In particular, the relevance of the approaches to calculating Bayesian posterior densities for a variety of structured models will be discussed and illustrated."
            },
            "slug": "Sampling-Based-Approaches-to-Calculating-Marginal-Gelfand-Smith",
            "title": {
                "fragments": [],
                "text": "Sampling-Based Approaches to Calculating Marginal Densities"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "Stochastic substitution, the Gibbs sampler, and the sampling-importance-resampling algorithm can be viewed as three alternative sampling- (or Monte Carlo-) based approaches to the calculation of numerical estimates of marginal probability distributions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46197721"
                        ],
                        "name": "Ernest Fokou",
                        "slug": "Ernest-Fokou",
                        "structuredName": {
                            "firstName": "Ernest",
                            "lastName": "Fokou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ernest Fokou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080535259"
                        ],
                        "name": "Bernhard SchottkyNeural",
                        "slug": "Bernhard-SchottkyNeural",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "SchottkyNeural",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bernhard SchottkyNeural"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067401521"
                        ],
                        "name": "Swedenwinther Lund",
                        "slug": "Swedenwinther-Lund",
                        "structuredName": {
                            "firstName": "Swedenwinther",
                            "lastName": "Lund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Swedenwinther Lund"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11273776,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e02e893fb1289100438d628995d9323fb9841cd",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We present three simple approximations for the calculation of the posterior mean in Gaussian Process classiication. The rst two methods are related to mean eld ideas known in Statistical Physics. The third approach is based on Bayesian online approach which was motivated by recent results in the Statistical Mechanics of Neural Networks. We present simulation results showing: 1. that the mean eld Bayesian evidence may be used for hyperparameter tuning and 2. that the online approach may achieve a low training error fast."
            },
            "slug": "Eecient-Approaches-to-Gaussian-Process-Fokou-Opper",
            "title": {
                "fragments": [],
                "text": "Eecient Approaches to Gaussian Process Classiication"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "Three simple approximations for the calculation of the posterior mean in Gaussian Process classiication are presented, based on Bayesian online approach which was motivated by recent results in the Statistical Mechanics of Neural Networks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932960"
                        ],
                        "name": "Ross D. Shachter",
                        "slug": "Ross-D.-Shachter",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Shachter",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross D. Shachter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 38
                            }
                        ],
                        "text": ", 1999) and extended Kalman filtering (Shachter, 1990)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14752744,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76ebf0a48d0d8251e3b3eeb812895f35c3011f2a",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-linear-approximation-method-for-probabilistic-Shachter",
            "title": {
                "fragments": [],
                "text": "A linear approximation method for probabilistic inference"
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11595354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b0d62ffdcebed5da55bd48242ed62ba25d7fd87",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a variational approximation method for efficient inference in large-scale probabilistic models. Variational methods are deterministic procedures that provide approximations to marginal and conditional probabilities of interest. They provide alternatives to approximate inference methods based on stochastic sampling or search. We describe a variational approach to the problem of diagnostic inference in the \"Quick Medical Reference\" (QMR) network. The QMR network is a large-scale probabilistic graphical model built on statistical and expert knowledge. Exact probabilistic inference is infeasible in this model for all but a small set of cases. We evaluate our variational inference algorithm on a large set of diagnostic test cases, comparing the algorithm to a state-of-the-art stochastic sampling method."
            },
            "slug": "Variational-Probabilistic-Inference-and-the-QMR-DT-Jaakkola-Jordan",
            "title": {
                "fragments": [],
                "text": "Variational Probabilistic Inference and the QMR-DT Network"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This work describes a variational approximation method for efficient inference in large-scale probabilistic models and evaluates the algorithm on a large set of diagnostic test cases, comparing the algorithm to a state-of-the-art stochastic sampling method."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2880651"
                        ],
                        "name": "S. R. Waterhouse",
                        "slug": "S.-R.-Waterhouse",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Waterhouse",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. R. Waterhouse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40268570"
                        ],
                        "name": "A. J. Robinson",
                        "slug": "A.-J.-Robinson",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Robinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Robinson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026where key groundwork for this thesis was performed\nIt has been a pleasure to exchange ideas with everyone at the Vision and Modeling group at the MIT Media Lab especially Martin Szummer Flavia Sparacino Ali Rahimi and Yuan Qi Thanks to Sumit Basu for providing his code for the billiard algorithm"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14217319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aba6e4081a1e8fc3edbe4fc3112616737486b559",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a Bayesian framework for inferring the parameters of a mixture of experts model based on ensemble learning by variational free energy minimisation. The Bayesian approach avoids the over-fitting and noise level under-estimation problems of traditional maximum likelihood inference. We demonstrate these methods on artificial problems and sunspot time series prediction."
            },
            "slug": "Bayesian-Methods-for-Mixtures-of-Experts-Waterhouse-Mackay",
            "title": {
                "fragments": [],
                "text": "Bayesian Methods for Mixtures of Experts"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A Bayesian framework for inferring the parameters of a mixture of experts model based on ensemble learning by variational free energy minimisation is presented and these methods are demonstrated on artificial problems and sunspot time series prediction."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3234984"
                        ],
                        "name": "R. Herbrich",
                        "slug": "R.-Herbrich",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Herbrich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Herbrich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686971"
                        ],
                        "name": "T. Graepel",
                        "slug": "T.-Graepel",
                        "structuredName": {
                            "firstName": "Thore",
                            "lastName": "Graepel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Graepel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1249662,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "008363aa3040e593090a5bf6248ad2ae2f91da7f",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a bound on the generalisation error of linear classifiers in terms of a refined margin quantity on the training set. The result is obtained in a PAC-Bayesian framework and is based on geometrical arguments in the space of linear classifiers. The new bound constitutes an exponential improvement of the so far tightest margin bound by Shawe-Taylor et al. [8] and scales logarithmically in the inverse margin. Even in the case of less training examples than input dimensions sufficiently large margins lead to non-trivial bound values and - for maximum margins - to a vanishing complexity term. Furthermore, the classical margin is too coarse a measure for the essential quantity that controls the generalisation error: the volume ratio between the whole hypothesis space and the subset of consistent hypotheses. The practical relevance of the result lies in the fact that the well-known support vector machine is optimal w.r.t. the new bound only if the feature vectors are all of the same length. As a consequence we recommend to use SVMs on normalised feature vectors only - a recommendation that is well supported by our numerical experiments on two benchmark data sets."
            },
            "slug": "A-PAC-Bayesian-margin-bound-for-linear-classifiers-Herbrich-Graepel",
            "title": {
                "fragments": [],
                "text": "A PAC-Bayesian margin bound for linear classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A bound on the generalisation error of linear classifiers in terms of a refined margin quantity on the training set is presented in a PAC-Bayesian framework and is based on geometrical arguments in the space oflinear classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724252"
                        ],
                        "name": "O. Winther",
                        "slug": "O.-Winther",
                        "structuredName": {
                            "firstName": "Ole",
                            "lastName": "Winther",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Winther"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10063289,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4323cf65589bc509aea260ccaa4ef32a94b2f7e",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive a mean-field algorithm for binary classification with gaussian processes that is based on the TAP approach originally proposed in statistical physics of disordered systems. The theory also yields an approximate leave-one-out estimator for the generalization error, which is computed with no extra computational cost. We show that from the TAP approach, it is possible to derive both a simpler naive mean-field theory and support vector machines (SVMs) as limiting cases. For both mean-field algorithms and support vector machines, simulation results for three small benchmark data sets are presented. They show that one may get state-of-the-art performance by using the leave-one-out estimator for model selection and the built-in leave-one-out estimators are extremely precise when compared to the exact leave-one-out estimate. The second result is taken as strong support for the internal consistency of the mean-field approach."
            },
            "slug": "Gaussian-Processes-for-Classification:-Mean-Field-Opper-Winther",
            "title": {
                "fragments": [],
                "text": "Gaussian Processes for Classification: Mean-Field Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A mean-field algorithm for binary classification with gaussian processes that is based on the TAP approach originally proposed in statistical physics of disordered systems is derived and an approximate leave-one-out estimator for the generalization error is computed."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686671"
                        ],
                        "name": "L. Csat\u00f3",
                        "slug": "L.-Csat\u00f3",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Csat\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Csat\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2547567"
                        ],
                        "name": "E. Fokoue",
                        "slug": "E.-Fokoue",
                        "structuredName": {
                            "firstName": "Ernest",
                            "lastName": "Fokoue",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fokoue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2174937"
                        ],
                        "name": "B. Schottky",
                        "slug": "B.-Schottky",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Schottky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schottky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724252"
                        ],
                        "name": "O. Winther",
                        "slug": "O.-Winther",
                        "structuredName": {
                            "firstName": "Ole",
                            "lastName": "Winther",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Winther"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 57
                            }
                        ],
                        "text": "ADF was previously applied to the Bayes Point Machine by Csato et al. (1999). Divide the joint distribution p(D, w) into n terms, one for each data point."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 37
                            }
                        ],
                        "text": "It is the same algorithm obtained by Csato et al. (1999), except they expressed it in terms of kernel inner products, which makes it more complex."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7562841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6f7fb3b0922810c54b6419d9aba612669aba14f",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We present three simple approximations for the calculation of the posterior mean in Gaussian Process classification. The first two methods are related to mean field ideas known in Statistical Physics. The third approach is based on Bayesian online approach which was motivated by recent results in the Statistical Mechanics of Neural Networks. We present simulation results showing: 1. that the mean field Bayesian evidence may be used for hyperparameter tuning and 2. that the online approach may achieve a low training error fast."
            },
            "slug": "Efficient-Approaches-to-Gaussian-Process-Csat\u00f3-Fokoue",
            "title": {
                "fragments": [],
                "text": "Efficient Approaches to Gaussian Process Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "Three simple approximations for the calculation of the posterior mean in Gaussian Process classification are presented, based on Bayesian online approach which was motivated by recent results in the Statistical Mechanics of Neural Networks."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6518359,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8871254256b95f52fe6a2c0edeee0fa706c1117",
            "isKey": false,
            "numCitedBy": 370,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Until recently, artificial intelligence researchers have frowned upon the application of probability propagation in Bayesian belief networks that have cycles. The probability propagation algorithm is only exact in networks that are cycle-free. However, it has recently been discovered that the two best error-correcting decoding algorithms are actually performing probability propagation in belief networks with cycles."
            },
            "slug": "A-Revolution:-Belief-Propagation-in-Graphs-with-Frey-Mackay",
            "title": {
                "fragments": [],
                "text": "A Revolution: Belief Propagation in Graphs with Cycles"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "Until recently, artificial intelligence researchers have frowned upon the application of probability propagation in Bayesian belief networks that have cycles, but it has recently been discovered that the two best error-correcting decoding algorithms are actually performing probability propagation with cycles."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3234984"
                        ],
                        "name": "R. Herbrich",
                        "slug": "R.-Herbrich",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Herbrich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Herbrich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686971"
                        ],
                        "name": "T. Graepel",
                        "slug": "T.-Graepel",
                        "structuredName": {
                            "firstName": "Thore",
                            "lastName": "Graepel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Graepel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069725698"
                        ],
                        "name": "Icg Campbell",
                        "slug": "Icg-Campbell",
                        "structuredName": {
                            "firstName": "Icg",
                            "lastName": "Campbell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Icg Campbell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026Machines on several standard datasets in addition to having a comparable training time Expectation Propagation can also be used to choose an appropriate feature set for classi cation via Bayesian model selection\nThesis Supervisor Rosalind Picard Title Associate Professor of Media Arts and Sciences"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14059040,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "64f72adbe8280f92bae8de867d96b02846b76e7f",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "From a Bayesian perspective Support Vector Machines choose the hypothesis corresponding to the largest possible hypersphere that can be inscribed in version space, i.e. in the space of all consistent hypotheses given a training set. Those boundaries of version space which are tangent to the hypersphere define the support vectors. An alternative and potentially better approach is to construct the hypothesis using the whole of version space. This is achieved by using a Bayes Point Machine which finds the midpoint of the region of intersection of all hyperplanes bisecting version space into two halves of equal volume (the Bayes point). It is known that the center of mass of version space approximates the Bayes point [Watkin, 1993]. We suggest estimating the center of mass by averaging over the trajectory of a billiard ball bouncing in version space. Experimental results are presented indicating that Bayes Point Machines consistently outperform Support Vector Machines."
            },
            "slug": "Bayes-Point-Machines:-Estimating-the-Bayes-Point-in-Herbrich-Graepel",
            "title": {
                "fragments": [],
                "text": "Bayes Point Machines: Estimating the Bayes Point in Kernel Space"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Estimating the center of mass of version space by averaging over the trajectory of a billiard ball bouncing in version space is suggested, indicating that Bayes Point Machines consistently outperform Support Vector Machines."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32536207"
                        ],
                        "name": "D. Camp",
                        "slug": "D.-Camp",
                        "structuredName": {
                            "firstName": "Drew",
                            "lastName": "Camp",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Camp"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026where key groundwork for this thesis was performed\nIt has been a pleasure to exchange ideas with everyone at the Vision and Modeling group at the MIT Media Lab especially Martin Szummer Flavia Sparacino Ali Rahimi and Yuan Qi Thanks to Sumit Basu for providing his code for the billiard algorithm"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9346534,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25c9f33aceac6dcff357727cbe2faf145b01d13c",
            "isKey": false,
            "numCitedBy": 934,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Supervised neural networks generalize well if there is much less information in the weights than there is in the output vectors of the training cases. So during learning, it is important to keep the weights simple by penalizing the amount of information they contain. The amount of information in a weight can be controlled by adding Gaussian noise and the noise level can be adapted during learning to optimize the trade-o between the expected squared error of the network and the amount of information in the weights. We describe a method of computing the derivatives of the expected squared error and of the amount of information in the noisy weights in a network that contains a layer of non-linear hidden units. Provided the output units are linear, the exact derivatives can be computed e ciently without time-consuming Monte Carlo simulations. The idea of minimizing the amount of information that is required to communicate the weights of a neural network leads to a number of interesting schemes for encoding the weights."
            },
            "slug": "Keeping-the-neural-networks-simple-by-minimizing-of-Hinton-Camp",
            "title": {
                "fragments": [],
                "text": "Keeping the neural networks simple by minimizing the description length of the weights"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A method of computing the derivatives of the expected squared error and of the amount of information in the noisy weights in a network that contains a layer of non-linear hidden units without time-consuming Monte Carlo simulations is described."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3472959"
                        ],
                        "name": "C. Rasmussen",
                        "slug": "C.-Rasmussen",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Rasmussen",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rasmussen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 113
                            }
                        ],
                        "text": "hidden Markov models? Is any deterministic method effective for nonparametric models such as Dirichlet processes (Rasmussen, 1999)? Second, can we anticipate how EP will perform? Can EP provide an estimate of its error? (The experiments in this paper always used the ADF initialization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1001953,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "5079ea296646fbbb0c1ceb8bbadf86c698c842ef",
            "isKey": false,
            "numCitedBy": 1247,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In a Bayesian mixture model it is not necessary a priori to limit the number of components to be finite. In this paper an infinite Gaussian mixture model is presented which neatly sidesteps the difficult problem of finding the \"right\" number of mixture components. Inference in the model is done using an efficient parameter-free Markov Chain that relies entirely on Gibbs sampling."
            },
            "slug": "The-Infinite-Gaussian-Mixture-Model-Rasmussen",
            "title": {
                "fragments": [],
                "text": "The Infinite Gaussian Mixture Model"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This paper presents an infinite Gaussian mixture model which neatly sidesteps the difficult problem of finding the \"right\" number of mixture components and uses an efficient parameter-free Markov Chain that relies entirely on Gibbs sampling."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8966205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d4ebfd71c8c69e30c3dd1b24d0332cab5de9137",
            "isKey": false,
            "numCitedBy": 537,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "A central issue in principal component analysis (PCA) is choosing the number of principal components to be retained. By interpreting PCA as density estimation, we show how to use Bayesian model selection to estimate the true dimensionality of the data. The resulting estimate is simple to compute yet guaranteed to pick the correct dimensionality, given enough data. The estimate involves an integral over the Steifel manifold of k-frames, which is difficult to compute exactly. But after choosing an appropriate parameterization and applying Laplace's method, an accurate and practical estimator is obtained. In simulations, it is convincingly better than cross-validation and other proposed algorithms, plus it runs much faster."
            },
            "slug": "Automatic-Choice-of-Dimensionality-for-PCA-Minka",
            "title": {
                "fragments": [],
                "text": "Automatic Choice of Dimensionality for PCA"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "By interpreting PCA as density estimation, it is shown how to use Bayesian model selection to estimate the true dimensionality of the data, and the resulting estimate is simple to compute yet guaranteed to pick the correct dimensionality, given enough data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064612704"
                        ],
                        "name": "David Saad",
                        "slug": "David-Saad",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Saad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Saad"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 149
                            }
                        ],
                        "text": "\u2026method e ective for nonparametric models such as Dirichlet processes Rasmussen &\nSecond can we anticipate how EP will perform& Can EP provide an estimate of its error& The experiments in this paper always used the ADF initialization Are the xed points of EP unique or does initialization matter&\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026where key groundwork for this thesis was performed\nIt has been a pleasure to exchange ideas with everyone at the Vision and Modeling group at the MIT Media Lab especially Martin Szummer Flavia Sparacino Ali Rahimi and Yuan Qi Thanks to Sumit Basu for providing his code for the billiard algorithm"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 143
                            }
                        ],
                        "text": "\u2026For example some variants of ADF do not use the exponential family Cowell et al approximate a mixture posterior with a smaller mixture after processing each data point see also the generalized pseudo Bayes algorithms in Murphy Frey et al approximate the discrete posterior with an arbitrary\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 125183395,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "22f464167e25d0e38cf38b035fce6ba9fee7a643",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Introduction, Inference, Some Models from Statistical Physics, The Gibbs Free Energy, Mean Field Theory: The Variational Approach, Correcting Mean Field Theory, The Bethe Approximation, Belief Propagation, Kikuchi Approximations and Generalized Belief Propagation, Acknowledgments, References"
            },
            "slug": "An-Idiosyncratic-Journey-Beyond-Mean-Field-Theory-Opper-Saad",
            "title": {
                "fragments": [],
                "text": "An Idiosyncratic Journey Beyond Mean Field Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680574"
                        ],
                        "name": "M. Seeger",
                        "slug": "M.-Seeger",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Seeger",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Seeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1408,
                                "start": 1400
                            }
                        ],
                        "text": "This chapter describes recursive approximation techniques that try to minimize the KL divergence between the true posterior and the approximation Assumed density ltering is a fast sequential method for this purpose Expectation Propagation is introduced as an extension of assumed density ltering to batch situations It has higher accuracy than assumed density ltering and other comparable methods for approximate inference\nAssumed density ltering\nThis section reviews the idea of assumed density ltering ADF to lay groundwork for Expectation Propagation Assumed density ltering is a general technique for computing approximate posteriors in Bayesian networks and other statistical models ADF has been in dependently proposed in the statistics Lauritzen Bernardo Giron Stephens arti cial intelligence Boyen Koller b Opper Winther Barber Sol lich Frey et al and control literature Kushner Budhiraja Maybeck Assumed density ltering is the name used in control other names include on line Bayesian learning moment matching and weak marginalization ADF applies when we have postulated a joint distribution p D where D has been observed and is hidden We would like to know the posterior over p jD as well as the probability of the observed data or evidence for the model p D The former is useful for estimation while the latter is useful for model selection\nFor example suppose we have observations from a Gaussian distribution embedded in a sea of unrelated clutter so that the observation density is a mixture of two Gaussians\np xj w N x I wN x I N x m V\nj Vj exp\nx m TV x m\nThe rst component contains the parameter of interest while the other component describes clutter The constant w is the known ratio of clutter Let the d dimensional vector have a Gaussian prior distribution\np N Id The joint distribution of and n independent observations D fx xng is therefore\np D p Y i p xij\nt t t t t\nqnew\np q\nFigure Assumed density ltering computes an exact one step posterior p and then approximates it to get qnew\nTo apply ADF we rst factor the joint distribution p D into a product of simple terms\np D Y i ti\nThere are many ways to do this As a rule of thumb fewer terms are better since it entails fewer approximations However we need each term to be simple enough to propagate expectations through In the mixture example we can use the factoring into n terms implied by\nt p\nti p xij For a general Bayesian network we would use the factoring into conditional probability tables Q nodes Y p Y jpa Y where pa Y is the parents of node Y in the graph\nThe second step is to choose a parametric approximating distribution It is essential that the distribution be in the exponential family so that only a xed number of expectations the su cient statistics need to be propagated Usually the nature and domain of constrains the distribution enough that there is no choice left to make In the clutter problem a spherical Gaussian distribution is appropriate The approximate posterior is therefore\nq N m v I Finally we sequence through and incorporate the terms ti into the approximate poste\nrior At each step we move from an old q to a new q as shown in gure For notational simplicity we drop the dependence of q on i Initialize with q Incor porating the prior term is trivial with no approximation needed To incorporate the next term ti take the exact posterior\np ti q R\nti q d\nand minimize the KL divergence D p jjqnew subject to the constraint that qnew is a Gaussian distribution Zeroing the gradient with respect to m v gives the conditions\nmnew\nZ p d\nvnew d m new T mnew\nZ p T d\nor in other words expectation constraints\nEqnew E p Eqnew T E p T\nWe see that the spherical Gaussian distribution is characterized by the expectations E E T For other members of the exponential family we will get constraints on di erent expectations as illustrated in section\nTo compute these expectations it is helpful to exploit the following relations\nZ m v Z t q d\nZ\nt\nv d exp\nv m T m d\nrm logZ m v Z\nZ\nm v\nt\nv d exp\nv m T m d\nE p v m v\nE p m v rm logZ m v E p T E p TE p v d v rTmrm rv logZ m v\nThese relations are a property of the Gaussian distribution and hold for any t In the clutter problem we have\nZ m v w N x m v I wN x I r\nw N x m v I w N x m v I wN x I\nrm logZ m v rx m v\nrv logZ m v rd v\nr x m T x m\nv\nrTmrm rv logZ m v rd v r r x m T x m v\nAn estimate of the probability of the data p D is a trivial byproduct of ADF Sim ply accumulate the normalization factors Zi m v produced by each update to get an overall normalization for the posterior This normalizer estimates p D because p D p jD p D\nThe nal ADF algorithm is\nInitialize m v the prior Initialize s the scale factor\nFor each data point xi update m v s according to\nmnew m v ri xi m v\nvnew v ri v v ri ri v\nxi m T xi m\nd v\nsnew s Zi m v\nThis algorithm can be understood in an intuitive way for each data point we compute its probability r of not being clutter make a soft update to our estimate of m and change our con dence in the estimate v However it is clear that this algorithm will depend on\nthe order in which data is processed because the clutter probability depends on the current estimate of\nThis algorithm was derived using a spherical Gaussian approximating distribution If we use a richer set of distributions like diagonal or full covariance Gaussians we can get a better result since more expectations will be preserved Unlike tting models to data there is no over tting problem when tting approximations to posteriors The only penalty is computational cost\nFigure shows the output of this algorithm using three random orderings of the same data Synthetic data was generated using w and No theory is available for how ADF varies with ordering but some empirical observations can be made The error increases whenever similar data points are processed together Processing the data in sorted order is especially bad This is because the algorithm overcommits to one part of input space only to realize that there is also data somewhere else The approximate mean and especially the variance will su er because of this So one approach to improve ADF is to nd an ordering that best re ects the natural variation in the data if this can be quanti ed somehow Another approach is to modify ADF to eliminate the dependence on ordering which is described in the next section\n\u22121 0 1 2 3 4 5 \u03b8\np( \u03b8,\nD )\nExact ADF\nFigure The approximate posterior resulting from ADF using three di erent orderings of the same data The posterior is scaled by the evidence estimate p D\nt t t t t\nq\nt t t t t\nqnew\nq\nt t t\nqnew\nt t t\nt t\nt t\nq\nFigure An alternative view of ADF as approximating each term and then computing qnew exactly EP re nes each term in the context of all other terms\nExpectation Propagation\nThis section describes the Expectation Propagation algorithm and demonstrates its use on the clutter problem Expectation Propagation is based on a novel interpretation of assumed density ltering Normally we think of ADF as treating each observation term ti exactly and then approximating the posterior that includes ti But we can also think of it as rst approximating ti with some !ti and then using an exact posterior with !ti gure This interpretation is always possible because we can de ne the approximate term !ti to be the ratio of the new posterior to the old posterior times a constant\n!t Z qnew\nq\nMultiplying this approximate term by q gives qnew as desired An important property is that if the approximate posterior is Gaussian i e an exponentiated quadratic in then the equivalent term approximation which is a ratio of these will also be an exponentiated quadratic If the approximate posterior is any distribution in the exponential family then the term approximations will have the same functional form as that distribution\nThe algorithm of the previous section can thus be interpreted as sequentially comput ing a Gaussian approximation !ti to every observation term ti then combining these approximations analytically to get a Gaussian posterior on Under this perspective the approximations do not have any required order the ordering only determined how wemade the approximations We are free to go back and re ne the approximations in any order From this idea we get Expectation Propagation\nConsider how this new interpretation applies to the previous section From the ratio of spherical Gaussians we get the following term approximation\nZi m v\nZ ti q d\n!ti Zi m v qnew\nq\nZi m v\nv vnew\nd exp\nvnew mnew T mnew\nexp v m T m\nNow de ne mi vi according to\nv i v new\nv\nmi vi v new mnew viv m m vi v v m new m\nto get the simpli cation\n!ti Zi m v\nvi v vi d exp\nvi mi T mi\nexp\nvi v mi m T mi m\nZi m v\nN mi m vi v I N mi viI\nBy construction multiplying q by this approximation gives exactly the ADF update with the proper scale factor The N notation is here used formally as shorthand not to imply a proper density The approximation is an exponentiated quadratic in which has the form of a Gaussian with mean mi and variance viI times a scale factor What makes this approximation di erent from a Gaussian is that the variance vi may be negative or in nite which for !ti is perfectly ne negative variance corresponds to a function that curves upward and in nite variance corresponds to a constant\nFigure illustrates ti and !ti for the clutter problem The exact term ti p xij is a Gaussian in raised by a constant The approximate term !ti is an expo nentiated quadratic The current posterior q determines where the approximation will be accurate When q is narrow i e v is small then !ti is accurate only in a narrow range of values determined bym When v is large then !ti tries to approximate ti more broadly and m is less important\nm v m v\n!t t q\nm v m v\nm v m v\nFigure The approximate term !t as a function of plotted versus the exact term t and the current posterior q The current posterior controls where the approximation will be accurate\nSo far we have just rewritten the ADF updates in a di erent way To get EP we re ne the term variables mi vi based on all of the other approximations The general EP algorithm is\nInitialize the term approximations !ti\nCompute the posterior for from the product of !ti\nqnew\nQ i !ti R Q\ni !ti d\nUntil all !ti converge\na Choose a !ti to re ne b Remove !ti from the posterior to get an old posterior q by dividing and normalizing\nq q new !ti\nFor notational simplicity we drop the dependence of q on i However qnew is not a function of i\nc Compute the posterior qnew and normalizing factor Zi from q and ti via ADF\nd Set\n!ti Zi qnew\nq\nUse the normalizing constant of qnew from as an approximation to p D\np D Z Y\ni\n!ti d\nAt convergence the result will be independent of processing order as desired In this algorithm we have used division to remove !ti from the posterior Step b can also be performed without division by accumulating all terms except for !ti\nq Y j i !tj\nbut division is usually more e cient\nThe clutter problem\nFor the clutter problem of the previous section the EP algorithm is\nThe term approximations have the form\n!ti si exp vi\nmi T mi\nInitialize the prior term to itself\nv\nm\ns v d\nInitialize the data terms to\nvi mi\nsi\nmnew m v new v\nUntil all mi vi si converge changes are less than\nloop i n\na Remove !ti from the posterior to get an old posterior\nv v new\nv i m v v new\nmnew v v i mi mnew v v i mnew mi\nb Recompute mnew v new Zi from m v this is the same as ADF\nri w N xi m v I\nw N xi m v I wN xi I\nmnew m v ri xi m v\nvnew v ri v v ri ri v\nxi m T xi m\nd v\nZi w N xi m v I wN xi I\nc Update !ti\nv i v new\nv\nri v ri ri xi m T xi m d v\nv\nmi m vi v v m\nnew m\nm vi v ri xi m v\nsi Zi\nvi d N mi m vi v I\nCompute the normalizing constant\nB mnew Tmnew vnew\nX i mTi mi vi\np D Z Y\ni\n!ti d\nvnew d exp B\nnY i si\nBecause the term approximations start at the result after one pass through the data is identical to ADF On later passes the re nement may sometimes fail due to a negative value for v This happens when many of the vi are negative and we wish to re ne a term with positive vi In the subtraction step we subtract a positive value from v new and are left with something negative From this Zi does not exist and the algorithm fails Another problem is that the term approximations may oscillate without ever converging This tends to occur in conjunction with negative vi s which suggests a simple work around force all vi by relaxing some of the expectation constraints Whenever a vi would become negative make it large instead and set vnew v because v new v v\ni This trick does provide convergence but leads to inaccurate posteriors since we are e ectively ignoring some of the data When EP does converge with negative vi s the result is always better than having forced vi So a better solution would be to use a re nement algorithm with better convergence properties see the discussion at the end of section\nResults and comparisons\nThis section evaluates ADF and EP on the clutter problem and compares them to four other algorithms for approximate inference Laplace s method variational Bayes importance sampling speci cally likelihood weighted sampling and Gibbs sampling\nIn Laplace s method we rst run EM to get a MAP estimate of Then we construct a Gaussian approximation to the posterior by using the curvature of the posterior at This curvature is Minka c\nH r T log p jD\nI X i riI X i ri ri xi xi T\nri w N x I\nw N x I wN x I\nThe Gaussian approximation and normalizing constant are\np jD N H p D p D d j Hj\nFor variational Bayes we lower bound the joint distribution by bounding each data term Minka c\np xij w N x I\nqi\nqi wN x I qi qi\nThe variational parameters qij are optimized to give the tightest bound Given the bounds the posterior for is Gaussian\nKj X i qij\n\"xj\nKj X i qijxi\nSj X i qij xi \"xj xi \"xj T\nV\nK I\nI\nm V K \"x\np jD N m V\np D d K K d\nN \"x I K exp tr S\nd K K d\nN \"x I K exp tr S\nY i w qi qi w qi qi\nFor importance sampling or more speci cally likelihood weighted sampling we draw samples f Sg from p and approximate the integrals via\np D S SX i p Dj i\nE jD PS\ni ip Dj i PS i p Dj i\nFor Gibbs sampling we introduce hidden variables ci which indicate whether xi is clutter or not Given a choice for we sample ci from a Bernoulli distribution with mean ri Then given ci we form an exact Gaussian posterior for and sample a new The average of the s that arise from this process is our estimate of the posterior mean\nThe three deterministic algorithms EP Laplace and VB all obtain approximate pos teriors close to the true one The sampling algorithms only estimate speci c integrals To compare the algorithms quantitatively we compute the absolute di erence between the es timated and exact evidence and the estimated and exact posterior mean Figure shows the results on a typical run with data size n and n It plots the accuracy vs cost of the algorithms on the two integrals Accuracy is measured by absolute di erence from the true integral Cost is measured by the number of oating point operations FLOPS in Matlab via Matlab s flops function This is better than using CPU time because FLOPS ignores interpretation overhead\nThe exact shape of these curves especially the EP curve should not be taken too seriously since the convergence properties of EP including whether it converges at all can be substantially a ected by the particular dataset and data ordering The Laplace curve is generated by applying to intermediate values of even though the gradient may not be zero\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u221223\n10 \u221222\n10 \u221221\n10 \u221220\n10 \u221219\n10 \u221218\n10 \u221217\nEP\nVB\nLaplace\nImportance\nEvidence\nFLOPS\nE rr\nor\n10 3\n10 4\n10 5\n10 6\n10 7\n10 \u2212205\n10 \u2212204\n10 \u2212203\n10 \u2212202\n10 \u2212201\n10 \u2212200\n10 \u2212199\nEP\nVB\nLaplace\nImportance\nEvidence\nFLOPS\nE rr\nor\nData size n n\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u22126\n10 \u22125\n10 \u22124\n10 \u22123\n10 \u22122\n10 \u22121\n10 0\nEP\nLaplace VB\nImportance\nGibbs\nPosterior mean\nFLOPS\nE rr\nor\n10 3\n10 4\n10 5\n10 6\n10 7\n10 \u22126\n10 \u22125\n10 \u22124\n10 \u22123\n10 \u22122\n10 \u22121\n10 0\nEP\nLaplace\nVB\nImportance\nGibbs\nPosterior mean\nFLOPS\nE rr\nor\nn n\nFigure Cost vs accuracy curves for expectation propagation EP Laplace s method variational Bayes VB importance sampling and Gibbs sampling on the clutter problem with w and Each x is one iteration of EP ADF is the rst x\nADF is equivalent to the rst iteration of EP the rst x on the curve It performs sig ni cantly worse than variational Bayes and Laplace s method which are o#ine algorithms Yet by re ning the ADF approximations we move from last place to rst The worth of an algorithm is not always what it seems\nIt is interesting to see how the di erent properties of the algorithms manifest themselves EP Laplace and VB all try to approximate the posterior with a Gaussian and their performance depends on how well this assumption holds With more data the posterior becomes more Gaussian so they all improve Sampling methods by contrast assume very little about the posterior and consequently cannot exploit the fact that it is becoming more Gaussian\nHowever this disadvantage turns into an advantage when the posterior has a complex shape Figure shows a run with n where the true posterior has three distinct modes EP crashes on this data due to negative variances Restricted EP which forces all vi does converge but to a poor result that captures only a single mode Laplace s method and variational Bayes are even worse For all three algorithms the error in the posterior mean increases with more iterations as they focus on a single mode Sampling methods by contrast are only slightly challenged by this posterior\n\u22126 \u22124 \u22122 0 2 4 6 0\n1\n2\n3\n4\n5\n6\n7\n8 x 10\n\u221226\ntheta\np( th\net a,\nD )\nExact EP VB Laplace\n\u221210 \u22125 0 5 10 0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\ntheta\np( th\net a\n| D )\nExact Gibbs\na b\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u22122\n10 \u22121\n10 0\n10 1\nEP\nLaplace\nVB\nImportance\nGibbs\nPosterior mean\nFLOPS\nE rr\nor\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u221227\n10 \u221226\n10 \u221225\n10 \u221224\nEP\nVB\nLaplace\nImportance\nEvidence\nFLOPS\nE rr\nor\nc d\nFigure A complex posterior in the clutter problem a Exact posterior vs approx imations obtained by Restricted EP Laplace s method and variational Bayes b Exact posterior vs approximation obtained by Gibbs sampling and complete conditional density averaging Gelfand Smith c d Cost vs accuracy EP only converged when restricted to positive vi\nAnother example Mixture weights\nThis section demonstrates how the structure of ADF and EP are preserved with a di er ent approximating distribution a Dirichlet distribution Let the probabilistic model be a mixture of K known densities p x pK x with unknown mixing weights w\np xjw X k wkpk x\nX k wk\np w p D w p w Y i p xijw\nWe want to compute the posterior p wjD and the evidence p D ADF was applied to this problem by Bernardo Giron and Stephens\nBreak the joint distribution p D w into n terms as given by The parameter vector w must lie in the simplex P k wk so a Dirichlet distribution is an appropriate approximation to the posterior The approximate posterior will have the form\nq w $ P\nk ak Q k $ ak Y k wak k\nADF\nFor ADF we sequence through and incorporate the terms ti into the approximate posterior The prior is a Dirichlet distribution so we initialize with that To incorporate a data term ti w take the exact posterior\np w ti w q w R\nw ti w q w dw\nand minimize the KL divergence D p w jjqnew w subject to the constraint that qnew w is a Dirichlet distribution Zeroing the gradient with respect to anewk gives the conditions k K\n% anewk % X j anewj Z w p w log wk dw\nwhere % a d log $ a\nda\nAs usual these are expectation constraints\nEqnew log wk E p log wk k K\nThe Dirichlet distribution is characterized by the expectations E log wk How do we solve for anew& Given the values E p log wk Newton s method is very e ec tive and EM like algorithms are also possible Minka b To compute the expectations use integration by parts to nd\nZ a Z w t w q w dw\nE p log wk % ak % X j aj rak logZ a\nThis is a property of the Dirichlet distribution valid for any t w In the mixture weight problem we have\nt w X k pk x wk Z a X k pk x Eq wk\nP k pk x akP\nk ak\nrak logZ a pk x P j aj P j pj x aj P j aj\nZ a\npk x P j pj x aj\nP j aj\nSo the nal ADF algorithm is\nInitialize a the prior Initialize s the scale factor\nFor each data point xi in turn solve the equations k K\n% anewk % X j anewj % ak % X j aj pk xi P j pj xi aj\nP j aj\nto get anew Update s via\nsnew s Zi a s P\nj pj xi ajP j aj\nBernardo Giron and Stephens show that this algorithm performs better than simpler rules like Directed Decision and Probabilistic Teacher With a little extra work we can get an EP algorithm that is even better\nEP\nDivide the new posterior by the old to get a term approximation parameterized by b\n!t Z qnew\nq Z $ P k a new k Q\nk $ a new k\nQ k $ ak\n$ P\nk ak Y k wbkk\nwhere bk a new k ak\nThe EP algorithm is\nThe term approximations have the form\n!ti si Y k wbikk\nInitialize the prior term to itself\nb\ns\nInitialize the data terms to\nbi\nsi\nanewk Pn i bik\nUntil all bi si converge\nloop i n\na Remove !ti from the posterior to get an old posterior\na anew bi\nb Recompute anew from a by solving k K\n% anewk % X j anewj % ak % X j aj pk xi P j pj xi aj\nP j aj\nc Update !ti\nbi a new a si Zi a $ P k a new k Q\nk $ a new k\nQ k $ ak\n$ P\nk ak\nCompute the normalizing constant\np D Q k $ a new k\n$ P\nk a new k nY i si\nA simpler method\nThe complexity of this algorithm results from preserving the expectations E log wk Cow ell et al suggest instead preserving only the rst two moments of the posterior dis tribution i e the expectations E wk P k E w k Preserving these expectations will not minimize KL divergence but allows a closed form update Their proposed ADF update is\nmk E p wk\nak Zi a P j aj\npk xi P j pj xi aj\nP\nj aj\nm k E p w k\nak ak Zi a P j aj P j aj\npk xi P j pj xi aj\nP\nj aj\nanewk\nP k mk m k P k m k m k\nmk\nThis update can be incorporated into EP by replacing The bene t of this change is determined empirically in the next section\n0 0.2 0.4 0.6 0.8 1 0\n2\n4\n6 x 10\n\u221247\nw\np( D\n,w )\nExact Laplace VB\n0 0.2 0.4 0.6 0.8 1 0\n2\n4\n6 x 10\n\u221247\nw\np( D\n,w )\nExact EP\n10 3\n10 4\n10 5\n10 6\n10 \u221249\n10 \u221248\n10 \u221247\n10 \u221246\nEP\nVB\nLaplace\nEvidence\nFLOPS E\nrr or\nEP2\na b\nFigure a Exact posterior vs approximations scaled by evidence p D The varia tional Bayes approximation is a lower bound while the others are not The approximation from EP is very similar to EP b Cost vs accuracy in approximating p D ADF is the rst x on the EP curve EP uses the fast update of Cowell et al\nResults and comparisons\nEP is compared against Laplace s method and variational Bayes For Laplace s method we use a softmax parameterization of w MacKay which makes the approximate posterior a logistic normal distribution the result of passing a Gaussian random variable through the logistic function Aitchison Shen For variational Bayes we use a Jensen bound as before to get a Dirichlet approximation Minka c\nFigure shows a typical example with w n The component densities were two closely spaced Gaussians\np x N p x N\nThe accuracy of the three methods at estimating p D can be seen immediately from the di erent posterior approximations EP using either the exact update or the fast update is the most accurate Even ADF the rst iteration of EP is very accurate The success of the fast update illustrates that it is sometimes good to consider criteria other than KL divergence"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4543,
                                "start": 4535
                            }
                        ],
                        "text": "This chapter describes prior work in approximate Bayesian inference The outline is\nNumerical quadrature\nMonte Carlo methods importance sampling Gibbs sampling\nLaplace s method\nVariational bound on the integral using Jensen s inequality\nVariational bound on the integrand variational Bayes\nStatistical physics methods\nSequential ltering\nThe classical approach to numerical integration is quadrature Davis Rabinowitz In this deterministic approach the integrand is evaluated at several locations knots and a function is constructed that interpolates these values The interpolant is chosen from a simple family that can be integrated analytically e g polynomials or splines The integral of the interpolant approximates the desired integral and with enough knots the approximation can be made arbitrarily accurate By using a set of prede ned knots x xn the interpolation and integration procedure can be compiled down to a simple summation of weighted function values\nI\nZ A f x dx\nI nX i wif xi\nwhere the weights wi are known This method is excellent with integrands that are simple i e that are easy to interpolate In one dimension quadrature is nearly unbeatable But in high dimensions it is infeasible because of the vast number of knots required to get a good interpolant of a complex function In Bayesian inference problems the integrands are mostly zero except in small regions i e they are sparse which makes the situation even worse most of the knots will be wasted Newer deterministic techniques try to avoid these problems by exploiting more properties of the integrand than just its value at given points Another approach is nondeterminism\nNondeterministic i e Monte Carlo methods do not try to interpolate or otherwise approximate the integrand at all they merely appeal to the law of large numbers In the simplest approach we sample knots uniformly in the region of integration A The expected value E f x under such a sampling must be the desired integral I divided by the area of A Hence the estimate\nI jAj n nX i f xi\nwill converge to the true value given enough samples and this happens independent of dimensionality and independent of the complexity of f Thus while Monte Carlo is rather ine cient in low dimensions requiring thousands of knots when quadrature would only need around it is often the only feasible method in high dimensions In Bayesian inference problems the sparsity of the integrand can be addressed by the technique of importance sampling Instead of sampling uniformly in A we sample from a proposal distribution p x that matches the shape of jf j as well as possible Then the estimate\nI\nn nX i f xi p xi\nalso converges to I and much faster than would Importance sampling also has the advantage of working for in nite regions A Various enhancements to the basic importance sampling procedure are possible Ventura With importance sampling the di culties of numerical integration are replaced by the di culties of sampling from a complex distribu tion Good proposal distributions may be hard to sample from In this case one can apply Markov Chain Monte Carlo methods Neal Liu such as Metropolis sampling and Gibbs sampling In these methods we generate samples that are approximately from p x and then apply as before For these methods careful monitoring and restarting is required to ensure that the samples adequately represent p x The Billiard algorithm for Bayes Point Machines discussed in chapter is a particularly clever Markov Chain Monte Carlo algorithm\nTo learn about a function we can compute its value at a large number of knots but we could also compute a large number of derivatives at a single knot This is the basic idea of Taylor expansion By nite di erences a given number of knots translates into an equivalent number of derivatives so theoretically this approach has no advantage over quadrature But for Bayesian inference problems it has certain conceptual advantages Since the integrand is sparse it makes sense to focus on one area where the action is Interpolation is also simpler since we just match derivatives The most popular application of this idea in statistics is Laplace s method Kass Raftery where we expand log f about its mode\nlog f x log f x gT x x x x TA x x\ng\nd log f x\ndx\nx x\nH d log f x\ndxdxT\nx x\nBecause x is the mode g and we get\nf x f x exp x x TH x x\nI\nZ A f x dx f x rows H j Hj\nw p( D\n,w )\nExact Laplace\nw\np( D\n,w )\nExact Bound\na b\nw\np( D\n,w )\nExact EP\nc\nFigure Deterministic methods for integration try to approximate the integrand a Laplace s method uses a Gaussian that has the correct curvature at the mode It produces approximations that are too local b In one type of variational bound the integrand is bounded everywhere It produces approximations that are too inaccurate c The proposed method Expectation Propagation tries to minimize KL divergence a global measure of deviation It produces the most accurate integrals\nWhat Laplace s method does is approximate f by a scaled Gaussian density that matches the value rst derivative and second derivatives of f at x Figure shows an example The drawback of this method is that it is di cult to use higher order derivatives resulting in an approximation that is limited in its accuracy and scope\nVariational bounding is a deterministic approach more global than Laplace s method We start by introducing an arbitrary function q x\nI\nZ x q x f x q x dx\nJensen s inequality for convex functions says that in the case of logarithm\nlog Z x q x g x dx Z x q x logg x dx\nif Z x q x dx\nCombining and gives the following bound on I\nI exp Z x q x log f x q x dx\nThis of course requires that f x is positive a condition that is satis ed for most but not all integrals in Bayesian inference We are free to choose q x to get the tightest bound which corresponds to maximizing the right hand side of Note that this is equivalent to minimizing the reversed KL divergence\nD q jj f Z x q x log q x f x dx\nover q subject to the constraint If q x is unconstrained the maximum is achieved at q x f x and the bound matches the original integral To achieve a simpli cation in the integral we must constrain q x in some way Typically q x is constrained to be Gaussian Hinton van Camp Barber Bishop Seeger but mixture distributions have also been suggested Jaakkola Jordan c Having a lower bound is useful since it provides a rm guarantee about the true value of the integral something none of the other methods can do However it tends to be very computational and is feasible in a limited number of cases Jensen s inequality takes advantage of the fact that log f x is often easy to integrate when f x is not But this is not always true For example in a mixture problem such as discussed in chapter f is a product of sums which does not simplify under a logarithm And in chapter the likelihood is a step function which reaches zero The step function could be softened into a sigmoid to make the Jensen bound well de ned but we could not expect a good t to result\nA less accurate but simpler way to obtain a variational bound is to bound the integrand and then integrate the bound\nf x g x for all x I Z x g x dx\nFigure shows an example Unlike the previous variational method this approach can be used in mixture problems This approach was used explicitly by Jaakkola Jordan a b and implicitly by Waterhouse et al Attias Ghahramani Beal under the name variational Bayes The implicit approach introduces hidden variables to de ne a bound Start by writing f x in terms of h x y\nf x\nZ y h x y dy\nApply the Jensen bound to get\nI Z x y h x y dydx\nexp Z x y q x y log h x y q x y dydx\nAt this point we constrain q x y to factor into separate functions for x and for y\nq x y qx x qy y\nwith no other constraints on functional form The qx and qy functions are iteratively optimized to maximize the value of the bound To see that this is equivalent to note that for any qy we can solve analytically for the optimal qx which is\nqx x g x R\nx g x dx\nwhere g x exp Z y qy y log h x y qy y dy\nWhen we substitute this qx the bound becomes\nI Z x g x dx\nRegardless of which approach we use implicit or explicit we can optimize the bound via the EM algorithm This is described in Minka c\nBesides variational bounds there are other integration techniques that are inspired by mean eld statistical physics Most of these are extensions of TAP such as the cavity method Opper Winther a Bethe approximation Yedidia and Plefka ex pansion Kappen Wiegerinck So far they have been applied to regular structures such as the Boltzmann machine and rarely to general probabilistic models where it is less obvious how to apply them An exception to this is the paper by Opper Winther c The algorithm they derive is new and accurate yet coincides with the framework proposed in this thesis It will be interesting to see what other algorithms come out of this mean eld line of research\nFor approximating an integral we thus nd ourselves in the following position We have methods that work well for simple functions in low dimensions quadrature and complex functions in high dimensions Monte Carlo We have methods that are simple and fast but inaccurate Laplace s method variational Bayes We have methods that apply in special cases Jensen bound TAP What is missing is a general and accurate deterministic method in high dimensions at least for simple functions That is what this thesis provides\nThe approach taken by this thesis continues the path started by the extended Kalman lter EKF The EKF is a sequential method developed for inference in dynamical systems with nonlinear dynamics It is not a general method for integration But there are several variations on the EKF Maybeck that have promise One is sequential Monte Carlo a family of nondeterministic techniques Liu Chen Carpenter et al Another is the assumed density lter a general deterministic method that approximately minimizes the KL divergence D f jj g between f x and its approximation g x as shown in gure The next chapter discusses the assumed density lter and its extension to Expectation Propagation"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1274,
                                "start": 1266
                            }
                        ],
                        "text": "This thesis has developed a family of algorithms for approximate inference based on ex tending assumed density ltering ADF to use iterative re nement This extension removes all order dependence from ADF and increases its accuracy The family includes loopy be lief propagation in Bayesian networks and extends it to allow approximate messages for reduced computation as well as more elaborate messages for increased accuracy For in ference in the Bayes Point Machine it includes the algorithm of Opper Winther c and provides an alternative to the costly billiard algorithm\nThe accuracy of the Expectation Propagation family was demonstrated on a variety of examples with most emphasis on the Bayes Point Machine\nSection For the clutter problem in one dimension EP was in well behaved cases times more accurate than its nearest competitor Laplace s method both in estimating the posterior mean and the normalizing constant p D In other cases when the true posterior was strongly multimodal EP did not converge at all while Restricted EP and other deterministic methods lagged behind Monte Carlo The computational cost of EP is slightly higher than Laplace s method but much less than Monte Carlo\nSection For marginalizing the mixing weight in a mixture density of two Gaussians EP was again times more accurate than Laplace s method its nearest competitor With modi cations inspired by Cowell et al EP is also faster than Laplace s method In this problem the posterior is always unimodal in fact log convex which may explain why EP always converged\nSection On a toy dataset where the Bayes Point Machine is very di erent from the Support Vector Machine EP delivers high accuracy at a fraction of the cost of its competitor the billiard algorithm The accuracy of EP degrades when points are clustered together but even then it still beats the billiard algorithm with respect to cost On separable problems the posterior is unimodal and EP seems to always converge\nSection EP is also accurate in situations that the billiard algorithm cannot handle namely when there is label noise This was demonstrated on a toy dataset more de tailed experiments showing that EP achieves theoretical bounds are given by Winther since his algorithm is equivalent to EP\nSection On benchmark datasets with around points and - features EP achieves test set error rates consistent with the billiard algorithm Beating the SVM on out\nof datasets EP realizes in practice the theoretical gains expected with a Bayesian approach\nMany opportunities for future work are available both within the framework of EP as well as beyond it First how e ective is EP for other statistical models& For example is it useful for inference in coupled hidden Markov models sigmoid belief networks Barber Sollich and dynamic trees Storkey & Is EP e ective for Bayesian parameter estimation of classi cation models beyond linear classi ers e g hidden Markov models& Is any deterministic method e ective for nonparametric models such as Dirichlet processes Rasmussen &\nSecond can we anticipate how EP will perform& Can EP provide an estimate of its error& The experiments in this paper always used the ADF initialization Are the xed points of EP unique or does initialization matter& What causes EP to diverge& Can it be made to always converge& Can EP be made to give reasonable approximations to multimodal posteriors&\nCan EP be made to run faster especially for the Bayes Point Machine& This thesis compared EP to the original quadratic programming implementation of the Support Vector Machine But much faster specialized algorithms for the SVM are now available due to intense research Can we exploit special properties of the Bayes Point Machine to speed up EP& For example can we represent the A matrix in a sparse fashion& Can we identify the terms that need to be re ned& Having an error estimate for EP could facilitate this\nIs it optimal to minimize KL divergence at each step or should we use some other criterion& The modi ed update inspired by Cowell et al shows that we may obtain computational speedups with other criteria But improvements in accuracy may also be possible if we replace the greedy KL criterion with something that incorporates lookahead For example if we know the posterior has heavy tails and we are approximating it with a Gaussian then we may choose to use a Gaussian with in ated variance to better account for the tails\nThe entire di erence between EP and ADF is that EP makes better choices for the approximate terms !ti But both algorithms base their choices on the old posterior q x which is assumed to be accurate If the true posterior is multimodal then q x cannot possibly be accurate Could we propagate additional information about q x to use in choosing !ti&\nCan iterative re nement be applied to other ltering algorithms& For example some variants of ADF do not use the exponential family Cowell et al approximate a mixture posterior with a smaller mixture after processing each data point see also the generalized pseudo Bayes algorithms in Murphy Frey et al approximate the discrete posterior with an arbitrary tree structured distribution Conventional EP is not practical with these kinds of approximations because the equivalent terms !ti x qnew x q x do not simplify\nYedidia et al give a generalization of belief propagation that is di erent from the generalization a orded by EP Their algorithm propagates exact marginals and pairwise marginals which gives it high accuracy but also limits its practicality Can it be extended to allow approximate messages as in EP& Is there a common parent of their algorithm and EP&\nBayesian inference is a fertile area for developing numerical integration algorithms espe cially deterministic ones because of the rich problem structure and prior knowledge about the functions being integrated There is also relatively little research on it compared to\noptimization for example Many researchers are swayed enough by this imbalance to use inferior techniques such as maximum likelihood estimation because they only involve op timization As argued in this thesis it doesn t have to be that way And I anticipate that there are even better integration algorithms out there waiting for someone to discover them"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1362,
                                "start": 1354
                            }
                        ],
                        "text": "One of the major obstacles to using Bayesian methods for pattern recognition has been its computational expense This thesis presents an approximation technique that can per form Bayesian inference faster and more accurately than previously possible This method Expectation Propagation uni es and generalizes two previous techniques assumed density ltering an extension of the Kalman lter and loopy belief propagation an ex tension of belief propagation in Bayesian networks The uni cation shows how both of these algorithms can be viewed as approximating the true posterior distribution with a simpler distribution which is close in the sense of KL divergence Expectation Propagation exploits the best of both algorithms the generality of assumed density ltering and the accuracy of loopy belief propagation\nLoopy belief propagation because it propagates exact belief states is useful for lim ited types of belief networks such as purely discrete networks Expectation Propagation approximates the belief states with expectations such as means and variances giving it much wider scope Expectation Propagation also extends belief propagation in the op posite direction propagating richer belief states which incorporate correlations between variables\nThis framework is demonstrated in a variety of statistical models using synthetic and real world data On Gaussian mixture problems Expectation Propagation is found for the same amount of computation to be convincingly better than rival approximation techniques Monte Carlo Laplace s method and variational Bayes For pattern recognition Expecta tion Propagation provides an algorithm for training Bayes Point Machine classi ers that is faster and more accurate than any previously known The resulting classi ers outperform Support Vector Machines on several standard datasets in addition to having a comparable training time Expectation Propagation can also be used to choose an appropriate feature set for classi cation via Bayesian model selection\nThesis Supervisor Rosalind Picard Title Associate Professor of Media Arts and Sciences"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 46
                            }
                        ],
                        "text": "Typically, q(x) is constrained to be Gaussian (Hinton & van Camp, 1993; Barber & Bishop, 1997; Seeger, 1999) but mixture distributions have also been suggested (Jaakkola & Jordan, 1999c)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 766,
                                "start": 758
                            }
                        ],
                        "text": "Classi cation using the Bayes Point\nThis chapter applies Expectation Propagation to inference in the Bayes Point Machine The Bayes Point Machine is a Bayesian approach to linear classi cation that competes with the popular but non Bayesian Support Vector Machine SVM Bayesian averaging of linear classi ers has been proven both theoretically and empirically optimal in terms of generalization performance Watkin Bouten et al Buhot et al But an e cient algorithm has remained elusive The Bayes Point Machine approximates the Bayesian average by choosing one average classi er the Bayes Point Watkin Rujan Herbrich et al Computing the Bayes Point is a simpler but still very di cult task\nThis chapter shows that Expectation Propagation using a full covariance Gaussian ap proximation to the posterior provides an accurate estimate of the Bayes Point an ap proximation to the full Bayesian average The algorithm turns out to be identical to what Opper Winther c derived by statistical physics methods However EP uses a dif ferent optimization scheme that is faster and does not require a stepsize parameter EP also provides an estimate of the evidence p D which is useful for feature selection but not provided by Opper Winther\nThe Bayes Point Machine\nThe Bayes Point Machine BPM is a Bayesian approach to linear classi cation A linear classi er classi es a point x according to y sign wTx for some parameter vector w the two classes are y Given a training set D f x y xn yn g the likelihood for w can be written\np Djw Y i p yijxi w Y i ) yiw Txi\n) z\nif z if z\nThis is a slight abuse of notation since p Djw is only a distribution for y not x This likelihood is if w is a perfect separator and otherwise A simple way to achieve linear separation is to progressively enlarge the set of features e g by computing squares and third powers until the data is separable in the new feature space This has the e ect of producing a nonlinear decision boundary in the original measurement space Feature expansion can be implemented e ciently using the kernel trick where we rewrite the algorithm in terms\nx1\nx2\nx1\nx2\na b\nFigure Two di erent classi cation data sets with label information removed The Bayes Point Machine assumes that without labels we cannot infer where the boundary lies In b one might be inclined to think that the horizontal axis determines the decision But the horizontal axis could easily be something irrelevant like the time of day the datum was collected Only domain knowledge can determine the validity of the assumption\nof inner products and perform the feature expansion implicitly via the inner product This technique will be described more fully later\nBecause it is conditional on xi this model assumes that the distribution of the x s is unrelated to the true decision boundary That is if we were given the x s without any labels we would have no information about where the boundary lies The validity of this assumption must come from domain knowledge it cannot be determined from the data itself see gure The Support Vector Machine SVM for example does not seem to make this assumption Tong Koller show that the SVM follows from assuming that the x s follow a Gaussian mixture distribution in each class In addition some workers have used the SVM with unlabeled data Bennett Demiriz while the BPM by design cannot The advantage of assuming independence in the BPM is that we avoid stronger assumptions about the nature of the dependence and thus obtain a more general algorithm Experiments show it is quite robust section\nA re nement to the basic model is to admit the possibility of errors in labeling or measurement A labeling error rate of can be modeled using Opper Winther b\np yjx w ) ywTx ) ywTx ) ywTx\nUnder this model the likelihood p Djw for a given w will be r n r where r is the number of errors on the training set Only the number of errors is important not where they are This way of modeling errors can automatically reject outliers because it doesn t care how far an error is from the boundary Other approaches based on adding slack to the boundary only allow errors near the boundary and are sensitive to outliers These approaches can be simulated by using a smooth likelihood function such as\np yjx w ywTx where is the cumulative distribution function for a Gaussian The tails of this function fall like exp x so it provides quadratic slack The logistic function could also be\nused it falls like exp x providing linear slack By changing ) to one of these smooth functions the labeling error model can be combined with slack with no computational di culties However this chapter focuses on without slack\nTo complete our Bayesian model we need to specify a prior on w Since the magnitude of w is irrelevant for classi cation some authors have restricted w to the unit sphere in d dimensions and have given w a uniform distribution on the sphere Rujan This distribution is nice because it is fair to all decision boundaries but it is not very convenient to work with A more general non informative prior is an average over spheres Let r kwk be the magnitude of w Given r let w be uniformly distributed on the sphere of radius r This prior is non informative for any r It is also non informative if r is unknown with distribution p r For example p r could be uniform from to allowing w to live in the unit ball instead of on the unit sphere By choosing p r appropriately we can also give w a spherical Gaussian distribution\np w N I\nIt is a property of the spherical Gaussian distribution that conditional on any r w is uniformly distributed on the sphere of radius r so no particular decision boundary is favored by this prior\nGiven this model the optimal way to classify a new data point x is to use the predictive distribution for y given the training data\np yjx D Z w p yjx w p wjD dw\nHowever this requires solving an integral each time A practical substitute is to use a single value ofw which approximates the predictive distribution as well as possible Watkin and Rujan have de ned the Bayes point as the single best w However this point is di cult to nd Thus following Rujan we use the posterior mean for w E wjD Following convention we will be sloppy and also call this the Bayes point Our strategy will be to make a Gaussian approximation to the posterior and use its mean as the estimated Bayes point Of course if we really wanted to we could also use EP to solve the integral for each test point The normalizing constant of the posterior is also useful because as an estimate of p D it allows us to choose among di erent models see section\nTraining via ADF\nStart with the ADF updates ADF was previously applied to the Bayes Point Machine by Csato et al Divide the joint distribution p D w into n terms one for each data point Since y and x always appear multiplied together the formulas will drop y and assume that xi is already scaled by yi Let the approximate posterior have the form\nq w N mw Vw\nFrom minimizing the KL divergence we get the expectation constraints\nEqnew w E p w\nEqnew ww T E p ww T\nTo compute these expectations use the following relations obtained from integration by parts\nZ mw Vw\nZ w t w q w dw\nE p w mw Vwrm logZ mw Vw E p ww\nT E p w E p w T Vw Vw rmrTm rv logZ mw Vw Vw These hold for any t w For the Bayes Point Machine we have combining yx into x\nt w ) wTx z Z z N z dz\nz mTwxp xTVwx\nZ mw Vw z\np xTVwx\nN z z\nrm logZ mw Vw x rv logZ mw Vw mTwx\nxTVwx xxT\nrmrTm rv logZ mw Vw xxT mTwx\nxTVwx xxT\nmw Vw x\nTx\nxTVwx xxT\nThe ADF algorithm is thus\nInitialize mw Vw I the prior Initialize s the scale factor\nFor each data point xi update mw Vw s according to\nmneww mw Vw ixi\nVneww Vw Vwxi ix\nT i m new w\nxTi Vwxi\nVwxi\nT\nsnew s Zi mw Vw\nThe nal mw is the estimate of w used for classi cation Note that this algorithm does not require matrix inversion It is the same algorithm obtained by Csato et al except they expressed it in terms of kernel inner products which makes it more complex\nTraining via EP\nNow we turn the ADF algorithm into an EP algorithm By dividing two consecutive Gaus sian posteriors we nd that the term approximations are also Gaussian parameterized by mi and Vi\n!t w Z qnew w\nq w\nZ\nN mi mw Vi Vw N w mi Vi\nwhere V i V new w\nV w mi Vi V new w\nmneww ViV w mw mw Vi Vw V w m new w mw\nTo simplify this combine it with the ADF updates to get mi Vi directly from mw Vw\nVi\nix T i m new w xTi Vwxi xix T i\nVw\nmi mw Vi Vw ixi\nThe matrix ixTi m new w\nxT i Vwxi\nxix T i has one nonzero eigenvalue which means Vi will have one nite\neigenvalue in the direction of xi This makes sense because term i only constrains the projection of w along xi This special structure allows us to represent Vi with a scalar vi\nV i v i xix T i\nxTi Vixi vi\nFrom we know that\nxTi Vixi xTi Vwxi\nixTi m new w\nxTi Vwxi\nwhich means the update for vi is\nvi x T i Vwxi\nix T i m new w\nAnother consequence of this special structure is that instead of the full vector mi we only need the projection mTi xi which can be stored as a scalar mi\nNow we can write an e cient EP algorithm\nExcept for the prior the term approximations have the form\n!ti w si exp vi wTxi mi\nInitialize them to\nvi mi\nsi\nmneww V new w I the prior\nUntil all mi vi si converge changes are less than\nloop i n\na Remove !ti from the posterior to get an old posterior\nVw V new w v i xixTi Vneww V new w xi vi xTi Vneww xi Vneww xi T mw m new w VwV i m new w mi\nmneww Vwxi v i x T i m new w mi\nThese expressions involving Vw can be computed e ciently\nVwxi V new w xi\nvi\nvi xTi Vneww xi\nxTi Vwxi\nxTi V new w xi\nvi\nb Recompute mneww V new w Zi from mw Vw as in ADF c Update !ti\nvi x T i Vwxi\nixTi m new w\nmi x T i mw vi x T i Vwxi i\nsi Zi jVi Vwj\njVij exp\nmi mw T Vi Vw mi mw\nZi q v i x T i Vwxi exp xTi Vwxi\nxTi m new w\ni\nCompute the normalizing constant\nB mneww T Vneww\nmneww X i m i vi\np D jVneww j exp B nY i si\nThis algorithm processes each data point in O d time Assuming the number of iterations is constant which seems to be true in practice computing the Bayes point therefore takes O nd time Computing the normalizing constant at the end requires O d time\nEP with kernels\nTo use the kernel trick we need to rewrite EP in terms of inner products Following the notation of Opper Winther c de ne\ni x T i V ni wxi V ni w is the Vw when term i is left out\nCij x T i xj\n* diag v vn hi x T i m new w\nh ni i x T i m ni w\nFrom the de nition of qnew w as the product of approximate terms !ti w we know that\nVneww\nI X i xix T i vi\nI X* XT\nmneww V new w X j mjxj vj\nxTi m new w\nX j xTi V new w xj mj vj\nFrom the matrix inversion lemma we therefore have\nC * * * XTVneww X* XTVneww X * * C * *\nC *\nIn this way we can compute xTi V new w xj for any i j using only C and * The EP algorithm becomes\nInitialize vi mi si Initialize hi i Cii\nUntil all mi vi si converge\nloop i n\na Remove !ti from the posterior to get an old posterior\nh ni i hi iv i hi mi\nb Recompute part of the new posterior as in ADF\nz h ni ip i\nZi z i\np i\nN z z\nhi h ni i i i\nc Set\nvi i\nihi\nmi h ni i vi i i hi vi i\nsi Zi q v i i exp\ni i hi\nd Now that * is updated nish recomputing the new posterior\nA C *\nFor all i\nhi X j Aij mj vj\nfrom\ni\nAii vi\nfrom\nCompute the normalizing constant\nB X ij Aij mimj vivj\nX i m i vi\np D j*j\njC *j exp B\nnY i si\nThe determinant expression in follows from\njVneww j I X* XT I XTX*\nI C* j*jjC *j\nIn step it would appear that we need to invert a matrix taking O n time for each data point However since only one vi changes each time A can be updated incrementally in O n time Initialize A C and then update with\nAnew C * +*\nA aia T i\naii\nwhere\nvnewi voldi\nAssuming a constant number of iterations the algorithm thus runs in O n time plus the time to compute the inner product matrix C This is a great improvement over O nd if the dimensionality is very large e g if the feature set is arti cially expanded\nTo show the equivalence with Opper Winther s algorithm we make the following observations\nAt convergence will hold for all i so that X j mjxj vj X j hjxj vj X j jxj\nmneww X j mjxj vj\nI X\nj\nxjx T j\nvj\nAmneww X\nj\njxj\nmneww X j jxj\nhi X j j x T i xj\nX j Cij j\nThis is the equation Opper Winther use instead of\nThe update for i can be written\ni\nvi v i C * ii vi vi v i h C * i ii vi h C *\ni ii\nC * ii vi\nThis is the update Opper Winther use instead of\nEP computes a normalizing constant for the posterior while Opper Winther do not\nAll other updates are identical to those in Opper Winther c though carried out in a di erent order Reordering the updates does not matter as long as both algorithms converge\nThe input to the algorithm is simply the matrix C which can be computed using an arbitrary inner product function C xi xj instead of x T i xj However in that case we need to keep yi and xi separate Cij yiyjC xi xj\nUsing a nonlinear inner product function is an e cient way to use an expanded feature space since we don t have to represent each expanded data point We only have to compute the inner product between two expanded data points which is a scalar function of the original data\nThe output of the algorithm is the i which implicitly represent m new w through\nWith these we classify a new data point according to\nf x sign xTmneww sign X i iyiC x xi\nResults on synthetic data\nFigure a demonstrates the Bayes point classi er vs the SVM classi er on training points Besides the two dimensions shown here each point had a third dimension set at\nThis provides a bias coe cient w so that the decision boundary doesn t have to pass through Each classi er is set to zero label noise and zero slack The Bayes point classi er approximates a vote between all linear separators ranging from an angle of to The Bayes point chooses an angle in the middle of this range SVM chooses the decision boundary to maximize margin the distance to the nearest data point This makes it ignore the topmost data point In fact the Bayes point and SVM would coincide if that point were removed Adding the point reduces the set of linear separators and Bayesian inference must take this into account\nFigure plots the situation in parameter space For viewing convenience we restrictw to the unit sphere The exact Bayes point was computed by likelihood weighted sampling i e sampling a random w on the sphere and discarding those which are not separators EP provides an accurate estimate of the posterior mean mw and posterior covariance Vw Compare\nExact Vw\nEP Vw\nFigure b plots cost vs error for EP versus three other algorithms for estimating the Bayes point the billiard algorithm of Herbrich et al the TAP algorithm of Opper Winther c and the mean eld MF algorithm of Opper Winther c The error is measured by Euclidean distance to the exact solution found by importance sampling The error in using the SVM solution is also plotted for reference Its unusually long running time is due to Matlab s quadprog solver TAP and MF were slower to converge than EP even with a large initial step size of As expected EP and TAP converge to the same solution\nThe billiard algorithm is a Monte Carlo method that bounces a ball inside the region de ned by hyperplane constraints It must be initialized with a linear separator and the SVM was used for that purpose Since there are many other ways one could initialize the billiard which may be much cheaper the initialization step was not counted against the billiard s FLOP count otherwise the billiard curve would be right of the SVM point The error axis must also be interpreted carefully While it is tempting to use the lower envelope of the curve as the measure of error it is actually more accurate to use the upper envelope since this is all that the algorithm can consistently achieve as samples accumulate Nevertheless it is clear that EP is much faster and more accurate\nLaplace s method and variational Bayes do not work at all on this problem Laplace fails because the derivatives of the likelihood are not informative they are either zero or in nity Variational Bayes fails for because no Gaussian can lower bound the likelihood Gaussians never reach zero Even with a Gaussian bound must be quite narrow so we can t expect competitive performance\nHerbrich Graepel point out that the SVM is sensitive to scaling an input vector i e if we replace x by x then the solution will change They argue theoretically and empirically that data vectors should therefore be normalized to unit length before SVM training This is quite a shock since no mention of this was made in the original SVM papers If the data in gure including the bias dimension is normalized before training then the SVM solution tilts slightly toward the BPM solution supporting Herbrich Graepel s suggestion The Bayes Point Machine by contrast does not require any normalization because the data likelihood is correctly invariant to scaling an input vector The solution found by EP is also invariant\nSVM Bayes\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u22124\n10 \u22123\n10 \u22122\n10 \u22121\n10 0\nEP\nBilliard\nSVM\nMF\nTAP\nFLOPS\nE rr\nor\nFigure left Bayes point machine vs Support Vector Machine on a simple data set The Bayes point more closely approximates a vote between all linear separators of the data right Cost vs error in estimating the posterior mean ADF is the rst x on the EP curve\nFigure left The same problem viewed in parameter space the unit sphere Each data point imposes a linear constraint giving an odd shaped region on the sphere The Bayes point is the centroid of the region The EP estimate is indistinguishable from the exact Bayes point on this plot right The Gaussian posterior approximation obtained by EP rendered as a one standard deviation isoprobability ellipsoid\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u22122\n10 \u22121\n10 0\nEP\nBilliard\nSVM\nMF\nTAP\nFLOPS\nE rr\nor\nFigure Cost vs error for the point problem with one point replicated times\nThe linear classi cation problem is special in that some points can have large in uence on the solution while adjacent points have zero in uence This is because the constraints imposed by the latter points may be redundant given the constraints already imposed by other points This property allows the support vector machine to focus on a small number of points the support vectors when nding its solution Unfortunately this property can cause havoc with EP EP uses Gaussians to smooth out the hard constraints and cannot always recognize when a point is redundant and should be ignored The result is that clusters of points can degrade the EP estimate Figure shows what happens to gure b when the point at is replicated times As expected the cluster of points counts more than it should making the EP boundary move slightly away from it The accuracy of EP TAP and MF degrades signi cantly while SVM and Billiard are unchanged On the bright side the error cannot be made arbitrarily high using more than replications or replicating the other points does not degrade the accuracy any further One work around for this behavior would be to reduce the dataset in advance e g to just the support vectors This idea has not been tested yet\nFigure compares the EP solution to the exact posterior mean when noisy labels are allowed Theoretically this integral is harder since we have to consider the entire parameter space not just perfect separators EP can handle it with no additional cost The solution comes out vertical because it is a compromise between the small set of perfect separators at and the larger set of boundaries between and which have one error There is also a set of boundaries past which also have one error On this dataset a similar result can be achieved with the SVM if we set the slack parameter C though this would not necessarily be true on another dataset Winther has given extensive evaluations of EP with and on synthetic datasets showing that it achieves the theoretical performance of Bayesian averaging Those experiments are not repeated here\nFigure demonstrates EP with a nonlinear kernel contrasting it to the SVM solution\n\u22121 \u22120.5 0 0.5 1 1.5 2 \u22121\n\u22120.5\n0\n0.5\n1\n1.5\n2\nExactEP\nFigure The EP solution has good agreement with the exact posterior mean when noisy labels are allowed\nwith the same kernel The kernel was Gaussian\nC xi xj exp\nxi xj T xi xj\nwith width parameter and The feature expansion equivalent to this kernel has an in nite number of features The SVM is quite sensitive to the choice of as well as the idiosyncrasies of the dataset This is related to the sparsity of the SVM solution when the boundary depends on only a few data points i e a few Gaussian kernels small changes in those kernels have a larger e ect on the boundary Similar results obtain if we use a polynomial kernel\nC xi xj x T i xj\np\nFor large p the boundaries are almost identical to those for a wide Gaussian kernel\nBPM SVM\nBPM SVM\nnarrow Gaussian kernel wide Gaussian kernel\nFigure Classi cation boundaries resulting from Support Vector Machine training vs Bayes Point Machine training with EP Both used a Gaussian kernel with the same width parameter left Narrow width The SVM tends to put extra bumps and kinks in the boundary right Wider width The SVM chooses an unusual solution in order to maximize margin in the expanded space The BPM boundary is non sparse all i but smoother It is hardly a ected by changing the kernel width Billiard gives results similar to EP\nResults on real data\nFor higher dimensional problems it is more di cult to compute the exact Bayes point and make cost vs accuracy comparisons So instead we ll measure cost vs test performance on benchmark problems\nFigure compares EP Billiard and SVM on discriminating handwritten digit from Each data point xi is an binary image dimensions The dataset was randomly split times into a small training set of points and a test set of points All algorithms were linear and set for zero noise Billiard was run for iterations which is far more computation than EP or SVM used Nevertheless EP is best\nFigures and show the same type of comparison on four datasets from the UCI repository Blake Merz Each dataset was randomly split times into a training set and test set in the ratio , , In each trial the features were normalized to have zero mean and unit variance in the training set The classi ers used zero label noise and a Gaussian kernel with Billiard was run for iterations The thyroid dataset was made into a binary classi cation problem by merging the di erent classes into normal vs abnormal Except for sonar EP and Billiard beat the SVM a majority of the time and in all cases EP performed similarly to Billiard However the running time for Billiard is signi cantly higher since it must be initialized at the SVM solution Figure shows cost vs test error curves on some typical runs The SVM using quadprog is particularly slow on thyroid The unusual success of the SVM on sonar was also reported by Herbrich et al and may be related to the di erent assumptions made by the SVM see section\nTo give an idea of the actual running time in Matlab gure plots the training time vs training set size for trials As expected the time scales as n Extrapolating from this it would take an hour for data points and weeks for data points Finding a way to speed up EP similar to the way that quadratic programming can be sped up for the SVM will be essential for large data sets\n30 40 50 60 70 80 35\n40\n45\n50\n55\n60\n65\n70\nSVM\nE P\nTest errors\n30 40 50 60 70 35\n40\n45\n50\n55\n60\n65\n70\nBilliard\nE P\nTest errors\nFigure Test error of SVM vs EP left and Billiard vs EP right on digit classi cation over random train'test splits Each point is test error for SVM'Billiard test error for EP Points under the line correspond to trials where EP had a lower test error EP beat SVM times and beat Billiard times despite being the fastest of all three algorithms of this dataset\nHeart features training points\n0.15 0.2 0.25 0.3\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\n0.26\n0.28\n0.3\n0.32\nSVM\nE P\nTest errors\n0.15 0.2 0.25 0.3\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\n0.26\n0.28\n0.3\n0.32\nBilliard\nE P\nTest errors\nThyroid features training points\n\u22120.05 0 0.05 0.1 0.15 \u22120.05\n0\n0.05\n0.1\n0.15\nSVM\nE P\nTest errors\n\u22120.05 0 0.05 0.1 0.15 \u22120.05\n0\n0.05\n0.1\n0.15\nBilliard\nE P\nTest errors\nFigure Test error rates over train'test splits Each point is test error for SVM'Billiard test error for EP Points under the line correspond to trials where EP had a lower test error For running times see gure\nIonosphere features training points\n0.05 0.1 0.15 0.2\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\nSVM\nE P\nTest errors\n0.05 0.1 0.15 0.2 0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\nBilliard\nE P\nTest errors\nSonar features training points\n0.05 0.1 0.15 0.2\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\nSVM\nE P\nTest errors\n0.05 0.1 0.15 0.2\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\nBilliard\nE P\nTest errors\nFigure Test error rates over train'test splits Each point is test error for SVM'Billiard test error for EP for one trial Points under the line correspond to tri als where EP had a lower test error For running times see gure\nHeart Thyroid\n10 7\n10 8\n10 9\n0.21\n0.22\n0.23\n0.24\n0.25\n0.26\n0.27\n0.28\n0.29\n0.3\nEP\nBilliard\nSVM\nFLOPS\nT es\nt e rr\nor\n10 7\n10 8\n10 9\n10 10\n0\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\nFLOPS\nT es\nt e rr\nor\nSVM\nEP Billiard\nIonosphere Sonar\n10 7\n10 8\n10 9\n10 10\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\nFLOPS\nT es\nt e rr\nor\nSVM\nEP\nBilliard\n10 6\n10 7\n10 8\n10 9\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\n0.26\n0.28\n0.3\nFLOPS\nT es\nt e rr\nor\nSVM EP\nBilliard\nFigure Cost vs test error on a typical trial for each dataset\n0 200 400 600 800 0\n5\n10\n15\n20\n25\nTraining set size\nT ra\nin in\ng tim\ne (m\nin s)\nFigure Actual training time in Matlab for EP with kernels for di erent dataset sizes It nearly perfectly follows n growth The time to compute the inner product matrix is not included\nModel selection\nThis section reports results on Bayesian model selection using the estimated evidence p D This is a unique feature of EP because the billiard algorithm cannot provide an estimate of p D By maximizing the evidence we can select the appropriate feature set feature kernel or noise parameter For background on Bayesian model selection see MacKay Kass Raftery Minka a A popular approach to model selection for the SVM is to minimize R\nM where R is the radius of the smallest ball containing the training\nset measured in the mapped feature space and M is the margin Cristianini et al Another approach is to minimize the span bound given by thresholding the s Chapelle Vapnik Chapelle et al\nS X\nsupport vectors i\n) i h C sv i ii\nThese three criteria evidence margin and span can lead to quite di erent results Figure shows a synthetic training set classi ed according to distance from the origin i e the true decision boundary is a circle Three di erent decision boundaries result from training an SVM with three di erent kernels the decision boundaries from EP are nearly identical All of these boundaries achieve zero error so we need to invoke some other rule besides training error to select among them Over all Gaussian kernels the margin criterion is minimized by taking This produces a decision boundary with spurious kinks and bumps The span bound is minimized by an even narrower kernel where the bound is By contrast the best Gaussian kernel according to evidence has providing a much smoother and more realistic boundary The quadratic kernel which is the closest to the true boundary has even greater evidence yet less margin\nIn the noise free case the Bayesian evidence p D has a natural interpretation It is the fraction of perfect separators out of all representable classi ers If a particular set of features has a large percentage of perfect separators then we intuitively should have more faith in that feature set This is what Bayesian model selection does and in choosing the Bayes point we follow the same basic argument Maximizing the margin does not necessarily behave this way\nThe next example repeats the feature selection experiment of Weston et al Chapelle et al Synthetic data with six features was created by rst sampling y with equal probability and then setting\nx N y x N y x N y x N x N x N\nWith probability features x -x were swapped with features x -x Thus all six features are relevant to some degree To these six relevant features are appended irrelevant features with distribution N The test is to see whether we can reject the irrelevant features In Chapelle et al the algorithm was forced to keep only two features Here we use a more rigorous test features are added one by one starting with the relevant ones\nGaussian Gaussian\nKernel R M span log p D\nquadratic\nQuadratic\nFigure A dataset classi ed with three di erent kernels The margin criterion R M prefers the solution while the Bayesian evidence p D prefers the quadratic solution The span bound prefers a Gaussian with tiny not shown The true boundary is a circle\n0 5 10 15 20 10\n15\n20\n25\n30 35 M ar gi n bo un d\nNumber of features 0 5 10 15 20\n0\n1\n2\n3\n4\n5\n6\n7\nS pa\nn bo\nun d\nNumber of features\n0 5 10 15 20 \u221215\n\u221214\n\u221213\n\u221212\n\u221211\n\u221210\n\u22129\n\u22128\n\u22127\nE P\ne vi\nde nc\ne\nNumber of features\nFigure Feature selection curves for the margin bound span bound and Bayesian evidence The Bayesian evidence has a clear peak at six the correct answer The other criteria which are to be minimized do not perform as well The margin bound has only a local minimum at six and the span bound only a local minimum at ve\nand the algorithm must decide when to stop Figure shows the curves for the margin bound span bound and Bayesian evidence Both the SVM and BPM used a linear kernel with zero slack The Bayesian evidence is clearly a better measure of relevance\nFigure a Conventional billiard algorithms allow the ball to escape They project the collision point onto the surface of the sphere but preserve the rebound velocity dashed line b The new algorithm works inside the sphere using the sphere s surface as an additional wall\nA better billiard algorithm\nA major drawback of current billiard algorithms is that they do not really operate on the sphere The billiard ball always follows a straight line trajectory until it hits a wall at which point it is projected back onto the sphere gure a Unfortunately this means the ball can sometimes leave the sphere without ever hitting a wall On the point problem in gure this happens on , of the bounces Rujan recovers from this by restarting the billiard at its initial point with a random velocity Unfortunately this introduces severe bias in the estimate by overcounting the initial point Herbrich et al have a better solution leave the ball where it is but choose a new random velocity This has less bias but doesn t resemble a billiard anymore\nThe problem of escaping billiard balls can be avoided entirely if we simply rede ne the pool Remember that the unit sphere was an arbitrary choice we can use any prior distribution that assigns equal probability to all w vectors of a given length So let s use the inside of the unit sphere as shown in gure b The sphere s surface is an additional wall that prevents escape The new algorithm is\nDetermine the next collision From position w and velocity v compute the ight time to each wall and take the minimum The distance from wall xi is\ndi wTxiq xTi xi\nand the velocity normal to xi is\nvi vTxiq xTi xi\nso the ight time is\ni\ndivi if vi otherwise\nThe ight time to the surface of the sphere satis es\nw v T w v\nq wTv vTv wTw wTv\nvTv\nwhich is always positive and nite\nUpdate the position of the ball the total distance traveled s and the center of mass estimate m\nwnew w v min\nz kwnew wk mnew s\ns z m\nz\ns z\nwnew w\nsnew s z\nUpdate the velocity If xi was hit\nvnew v vi xiq xTi xi\nIf the surface of the sphere was hit\nvnew v wnew wnew Tv\nThe length of v is unchanged by these updates so if we initialize vTv it will stay that way throughout the algorithm\nThe algorithm can also be made use a kernel inner product as in Herbrich et al With this algorithm we can run one billiard trajectory without ever restarting However that is not a good idea because the pool is not perfectly ergodic By periodically randomiz ing the velocity of the ball we can achieve a more ergodic sampling Periodic randomization is important in all Markov chain Monte Carlo schemes including Gibbs sampling For the billiard randomization at every bounces seems to work well\nFigure compares the three algorithms on the point problem of section Each was run for iterations using a comparable number of ops Because of its bias Rujan s algorithm is never more accurate than in Euclidean distance to the true value Herbrich s algorithm does better but also seems to level o at The new algorithm with randomization every bounces converges nicely These characteristics are typical and hold across many di erent runs on this dataset\n10 2\n10 4\n10 6\n10 \u22123\n10 \u22122\n10 \u22121\n10 0\nRujan\nHerbrich\nNew\nFLOPS\nE rr\nor\nFigure Cost vs error of conventional billiard algorithms vs the new algorithm"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2249,
                                "start": 2241
                            }
                        ],
                        "text": "The dominant computational task in Bayesian inference is numerical integration New methods for fast and accurate integration are therefore very important and can have great impact This dissertation presents a new deterministic approximation framework Expecta tion Propagation which achieves higher accuracy than existing integration algorithms with similar computational cost\nThe general scenario of Bayesian inference is that there is some observed data and some unobserved quantity of interest Inferences about the unknown x are based on its posterior distribution given the observed D\np xjD p x D p D\np x D R\nx p x D dx\nFor example we may want to know the posterior mean and variance of the unknown which are integrals over the posterior\nE xjD Z x xp xjD dx\nR x xp x D dxR x p x D dx\nE x jD Z x x p xjD dx\nR x x\np x D dxR x p x D dx\nvar xjD E x jD E xjD\nIn real situations there are many unknowns not just the one we are interested in In Bayesian inference these must be marginalized out of the joint distribution which involves yet more integrals\np xjD R y z p x y z D R x y z p x y z D\nThus numerical integration goes hand in hand with practical Bayesian inference Numerical integration algorithms can be principally divided into deterministic vs non deterministic methods Deterministic methods try to approximate the integrand with some thing whose integral is known exactly They work from properties of the integrand like its maxima and curvature Nondeterministic methods sample the integrand at random points to get a stochastic estimate of the integral This approach is more general since it works for almost any integrand but it also requires a great deal more computation than deterministic approximation\nThe proposed method Expectation Propagation is a deterministic approximation method It is an extension to assumed density ltering ADF Maybeck Lauritzen Bernardo Giron Stephens Boyen Koller b Barber Sollich Opper Winther Frey et al a one pass sequential method for comput ing an approximate posterior distribution In ADF observations are processed one by one updating the posterior distribution which is then approximated before processing the next observation For example we might replace the exact one step posterior with a Gaussian having the same mean and same variance Maybeck Lauritzen Barber Sol lich Opper Winther Or we might replace a posterior over many variables with one that renders the variables independent Boyen Koller b or approximates them as Markovian Frey et al In each case the approximate posterior is found by minimizing KL divergence which amounts to preserving a speci c set of posterior expecta tions Note that the statistical model in question need not be a time series model and the processing order of observations need not correspond with time of arrival The weakness of ADF stems from its sequential nature information that is discarded early on may turn out to be important later Even if ADF is augmented with a backward pass Boyen Koller a this information cannot be recovered ADF is also sensitive to observation ordering which is undesirable in a batch context\nExpectation Propagation EP extends ADF to incorporate iterative re nement of the approximations by making additional passes The information from later observations re nes the choices made earlier so that the most important information is retained When the re nement converges the resulting posterior is independent of ordering and more accurate Iterative re nement has previously been used in conjunction with sampling Koller et al and extended Kalman ltering Shachter Expectation Propagation di ers by applying this idea to the deterministic approximation of general distributions not just Gaussian distributions as in Shachter EP is more expensive than ADF by only a constant factor the number of re nement passes typically or As shown in chapter the accuracy of EP is signi cantly better than ADF as well as rival approximation methods Monte Carlo Laplace s method and variational Bayes\nThinking in this framework has a number of bene ts For example in belief networks with loops it is known that approximate marginal distributions can be obtained by iterating the belief propagation recursions a process known as loopy belief propagation Frey MacKay Murphy et al As described in chapter it turns out that this heuristic procedure is a special case of Expectation Propagation where the approximate posterior is a completely disconnected network with no other constraints on functional form In other words loopy belief propagation is a direct generalization of the ADF algorithm of Boyen Koller b\nExpectation Propagation can therefore be seen as a way of generalizing loopy belief propagation to less restrictive approximations that are not completely disconnected and to useful constraints on functional form such as multivariate Gaussian Partially disconnected approximations are useful for improving accuracy just as in variational methods Jordan et al while constraints on functional form are useful for reducing computation Instead of propagating exact belief states which may be intractable EP only needs to propagate expectations relevant to the chosen approximating distribution e g means and variances Hence the name Expectation Propagation\nExpectation Propagation also has connections to statistical physics techniques Yedidia et al have shown that belief propagation tries to minimize an approximate free en ergy on discrete networks This is known as the TAP approach in statistical physics Opper\nWinther a have generalized the TAP approach to networks with mixed continuous and discrete nodes via the cavity method and applied it to Gaussian process classi ers Opper Winther c Chapter shows that Opper Winther s algorithm which has excellent performance is a special case of Expectation Propagation where the posterior approximation is Gaussian In this sense Expectation Propagation as a generalization of belief propagation parallels the cavity method as a generalization of TAP\nExpectation Propagation as a general framework for approximate Bayesian inference can be applied to many real world tasks Chapter demonstrates its use for the general task of discriminating objects into classes Classi cation via Bayesian averaging has long been popular in the theoretical community but di cult to implement in a computationally competitive way An excellent example of this is the Bayes Point Machine Rujan Herbrich et al With Expectation Propagation the advantages of Bayesian averaging can be achieved at less expense than previously possible\nIn short\nChapter reviews the prior work in approximate Bayesian inference excluding ADF Chapter reviews ADF and introduces Expectation Propagation Both are illustrated on simple statistical models\nChapter addresses belief networks describing how loopy belief propagation is a special case of Expectation Propagation and how belief propagation may be extended\nChapter applies Expectation Propagation to the Bayes Point Machine classi er Chapter summarizes the results and o ers suggestions for future work on Expecta tion Propagation"
                    },
                    "intents": []
                }
            ],
            "corpusId": 1001206,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69ef4c14c7cf129747a018861fa688aa8a5769b7",
            "isKey": true,
            "numCitedBy": 128,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a variational Bayesian method for model selection over families of kernels classifiers like Support Vector machines or Gaussian processes. The algorithm needs no user interaction and is able to adapt a large number of kernel parameters to given data without having to sacrifice training cases for validation. This opens the possibility to use sophisticated families of kernels in situations where the small \"standard kernel\" classes are clearly inappropriate. We relate the method to other work done on Gaussian processes and clarify the relation between Support Vector machines and certain Gaussian process models."
            },
            "slug": "Bayesian-Model-Selection-for-Support-Vector-and-Seeger",
            "title": {
                "fragments": [],
                "text": "Bayesian Model Selection for Support Vector Machines, Gaussian Processes and Other Kernel Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A variational Bayesian method for model selection over families of kernels classifiers like Support Vector machines or Gaussian processes that needs no user interaction and is able to adapt a large number of kernel parameters to given data without having to sacrifice training cases for validation."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50740317"
                        ],
                        "name": "J. Atchison",
                        "slug": "J.-Atchison",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Atchison",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Atchison"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46494993"
                        ],
                        "name": "S. Shen",
                        "slug": "S.-Shen",
                        "structuredName": {
                            "firstName": "Shir",
                            "lastName": "Shen",
                            "middleNames": [
                                "Ming"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123168591,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "100021b7eff067512397a09c4995375a7643b8ba",
            "isKey": false,
            "numCitedBy": 413,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY The logistic transformation applied to a ^-dimensional normal distribution produces a distribution over the d-dimensional simplex which can sensibly be termed a logistic-norma l distribution. Such distributions, implicitly used in a number of recent applications, are here given a formal identity and some useful properties are recorded. A main aim is to extend the area of application from the restricted role as a substitute for the Dirichlet conjugate prior class in the analysis of multinomial and contingency table data to the direct statistical description and analysis of compositional and probabilistic data."
            },
            "slug": "Logistic-normal-distributions:Some-properties-and-Atchison-Shen",
            "title": {
                "fragments": [],
                "text": "Logistic-normal distributions:Some properties and uses"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122933719"
                        ],
                        "name": "Bouten",
                        "slug": "Bouten",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Bouten",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bouten"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29967289"
                        ],
                        "name": "Schietse",
                        "slug": "Schietse",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Schietse",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Schietse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30060814"
                        ],
                        "name": "Van den Broeck C",
                        "slug": "Van-den-Broeck-C",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Van den Broeck C",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Van den Broeck C"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 33020596,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd9dc0b77fe2e7e1c6ca9db247d4e4ed2d3c1f80",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a streamlined formalism which reduces the calculation of the generalization error for a perceptron, trained on random examples generated by a teacher perceptron, to a matter of simple algebra. The method is valid whenever the student perceptron can be identified as the unique minimum of a specific cost function. The asymptotic generalization error is calculated explicitly for a broad class of cost functions, and a specific cost function is singled out that leads to a generalization error extremely close to the one of the Bayes classifier."
            },
            "slug": "Gradient-descent-learning-in-perceptrons:-A-review-Bouten-Schietse",
            "title": {
                "fragments": [],
                "text": "Gradient descent learning in perceptrons: A review of its possibilities."
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A streamlined formalism is presented which reduces the calculation of the generalization error for a perceptron, trained on random examples generated by a teacher perceptrons, to a matter of simple algebra."
            },
            "venue": {
                "fragments": [],
                "text": "Physical review. E, Statistical physics, plasmas, fluids, and related interdisciplinary topics"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724252"
                        ],
                        "name": "O. Winther",
                        "slug": "O.-Winther",
                        "structuredName": {
                            "firstName": "Ole",
                            "lastName": "Winther",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Winther"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 73584892,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3fc168e5c34b965af75a846ec7c777f323b0807",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "In this chapter, we elaborate on the well-known relationship between Gaussian processes (GP) and Support Vector Machines (SVM). Secondly, we present approximate solutions for two computational problems arising in GP and SVM. The first one is the calculation of the posterior mean for GP classifiers using a `naive' mean field approach. The second one is a leave-one-out estimator for the generalization error of SVM based on a linear response method. Simulation results on a benchmark dataset show similar performances for the GP mean field algorithm and the SVM algorithm. The approximate leave-one-out estimator is found to be in very good agreement with the exact leave-one-out error."
            },
            "slug": "Gaussian-processes-and-SVM:-Mean-field-results-and-Opper-Winther",
            "title": {
                "fragments": [],
                "text": "Gaussian processes and SVM: Mean field results and leave-one-out"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This chapter elaborates on the well-known relationship between Gaussian processes (GP) and Support Vector Machines (SVM) and presents approximate solutions for two computational problems arising in GP and SVM."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69052801"
                        ],
                        "name": "T. Watkin",
                        "slug": "T.-Watkin",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Watkin",
                            "middleNames": [
                                "L.",
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Watkin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3401,
                                "start": 3390
                            }
                        ],
                        "text": "This chapter describes prior work in approximate Bayesian inference The outline is\nNumerical quadrature\nMonte Carlo methods importance sampling Gibbs sampling\nLaplace s method\nVariational bound on the integral using Jensen s inequality\nVariational bound on the integrand variational Bayes\nStatistical physics methods\nSequential ltering\nThe classical approach to numerical integration is quadrature Davis Rabinowitz In this deterministic approach the integrand is evaluated at several locations knots and a function is constructed that interpolates these values The interpolant is chosen from a simple family that can be integrated analytically e g polynomials or splines The integral of the interpolant approximates the desired integral and with enough knots the approximation can be made arbitrarily accurate By using a set of prede ned knots x xn the interpolation and integration procedure can be compiled down to a simple summation of weighted function values\nI\nZ A f x dx\nI nX i wif xi\nwhere the weights wi are known This method is excellent with integrands that are simple i e that are easy to interpolate In one dimension quadrature is nearly unbeatable But in high dimensions it is infeasible because of the vast number of knots required to get a good interpolant of a complex function In Bayesian inference problems the integrands are mostly zero except in small regions i e they are sparse which makes the situation even worse most of the knots will be wasted Newer deterministic techniques try to avoid these problems by exploiting more properties of the integrand than just its value at given points Another approach is nondeterminism\nNondeterministic i e Monte Carlo methods do not try to interpolate or otherwise approximate the integrand at all they merely appeal to the law of large numbers In the simplest approach we sample knots uniformly in the region of integration A The expected value E f x under such a sampling must be the desired integral I divided by the area of A Hence the estimate\nI jAj n nX i f xi\nwill converge to the true value given enough samples and this happens independent of dimensionality and independent of the complexity of f Thus while Monte Carlo is rather ine cient in low dimensions requiring thousands of knots when quadrature would only need around it is often the only feasible method in high dimensions In Bayesian inference problems the sparsity of the integrand can be addressed by the technique of importance sampling Instead of sampling uniformly in A we sample from a proposal distribution p x that matches the shape of jf j as well as possible Then the estimate\nI\nn nX i f xi p xi\nalso converges to I and much faster than would Importance sampling also has the advantage of working for in nite regions A Various enhancements to the basic importance sampling procedure are possible Ventura With importance sampling the di culties of numerical integration are replaced by the di culties of sampling from a complex distribu tion Good proposal distributions may be hard to sample from In this case one can apply Markov Chain Monte Carlo methods Neal Liu such as Metropolis sampling and Gibbs sampling In these methods we generate samples that are approximately from p x and then apply as before For these methods careful monitoring and restarting is required to ensure that the samples adequately represent p x The Billiard algorithm for Bayes Point Machines discussed in chapter is a particularly clever Markov Chain Monte Carlo algorithm\nTo learn about a function we can compute its value at a large number of knots but we could also compute a large number of derivatives at a single knot This is the basic idea of Taylor expansion By nite di erences a given number of knots translates into an equivalent number of derivatives so theoretically this approach has no advantage over quadrature But for Bayesian inference problems it has certain conceptual advantages Since the integrand is sparse it makes sense to focus on one area where the action is Interpolation is also simpler since we just match derivatives The most popular application of this idea in statistics is Laplace s method Kass Raftery where we expand log f about its mode\nlog f x log f x gT x x x x TA x x\ng\nd log f x\ndx\nx x\nH d log f x\ndxdxT\nx x\nBecause x is the mode g and we get\nf x f x exp x x TH x x\nI\nZ A f x dx f x rows H j Hj\nw p( D\n,w )\nExact Laplace\nw\np( D\n,w )\nExact Bound\na b\nw\np( D\n,w )\nExact EP\nc\nFigure Deterministic methods for integration try to approximate the integrand a Laplace s method uses a Gaussian that has the correct curvature at the mode It produces approximations that are too local b In one type of variational bound the integrand is bounded everywhere It produces approximations that are too inaccurate c The proposed method Expectation Propagation tries to minimize KL divergence a global measure of deviation It produces the most accurate integrals\nWhat Laplace s method does is approximate f by a scaled Gaussian density that matches the value rst derivative and second derivatives of f at x Figure shows an example The drawback of this method is that it is di cult to use higher order derivatives resulting in an approximation that is limited in its accuracy and scope\nVariational bounding is a deterministic approach more global than Laplace s method We start by introducing an arbitrary function q x\nI\nZ x q x f x q x dx\nJensen s inequality for convex functions says that in the case of logarithm\nlog Z x q x g x dx Z x q x logg x dx\nif Z x q x dx\nCombining and gives the following bound on I\nI exp Z x q x log f x q x dx\nThis of course requires that f x is positive a condition that is satis ed for most but not all integrals in Bayesian inference We are free to choose q x to get the tightest bound which corresponds to maximizing the right hand side of Note that this is equivalent to minimizing the reversed KL divergence\nD q jj f Z x q x log q x f x dx\nover q subject to the constraint If q x is unconstrained the maximum is achieved at q x f x and the bound matches the original integral To achieve a simpli cation in the integral we must constrain q x in some way Typically q x is constrained to be Gaussian Hinton van Camp Barber Bishop Seeger but mixture distributions have also been suggested Jaakkola Jordan c Having a lower bound is useful since it provides a rm guarantee about the true value of the integral something none of the other methods can do However it tends to be very computational and is feasible in a limited number of cases Jensen s inequality takes advantage of the fact that log f x is often easy to integrate when f x is not But this is not always true For example in a mixture problem such as discussed in chapter f is a product of sums which does not simplify under a logarithm And in chapter the likelihood is a step function which reaches zero The step function could be softened into a sigmoid to make the Jensen bound well de ned but we could not expect a good t to result\nA less accurate but simpler way to obtain a variational bound is to bound the integrand and then integrate the bound\nf x g x for all x I Z x g x dx\nFigure shows an example Unlike the previous variational method this approach can be used in mixture problems This approach was used explicitly by Jaakkola Jordan a b and implicitly by Waterhouse et al Attias Ghahramani Beal under the name variational Bayes The implicit approach introduces hidden variables to de ne a bound Start by writing f x in terms of h x y\nf x\nZ y h x y dy\nApply the Jensen bound to get\nI Z x y h x y dydx\nexp Z x y q x y log h x y q x y dydx\nAt this point we constrain q x y to factor into separate functions for x and for y\nq x y qx x qy y\nwith no other constraints on functional form The qx and qy functions are iteratively optimized to maximize the value of the bound To see that this is equivalent to note that for any qy we can solve analytically for the optimal qx which is\nqx x g x R\nx g x dx\nwhere g x exp Z y qy y log h x y qy y dy\nWhen we substitute this qx the bound becomes\nI Z x g x dx\nRegardless of which approach we use implicit or explicit we can optimize the bound via the EM algorithm This is described in Minka c\nBesides variational bounds there are other integration techniques that are inspired by mean eld statistical physics Most of these are extensions of TAP such as the cavity method Opper Winther a Bethe approximation Yedidia and Plefka ex pansion Kappen Wiegerinck So far they have been applied to regular structures such as the Boltzmann machine and rarely to general probabilistic models where it is less obvious how to apply them An exception to this is the paper by Opper Winther c The algorithm they derive is new and accurate yet coincides with the framework proposed in this thesis It will be interesting to see what other algorithms come out of this mean eld line of research\nFor approximating an integral we thus nd ourselves in the following position We have methods that work well for simple functions in low dimensions quadrature and complex functions in high dimensions Monte Carlo We have methods that are simple and fast but inaccurate Laplace s method variational Bayes We have methods that apply in special cases Jensen bound TAP What is missing is a general and accurate deterministic method in high dimensions at least for simple functions That is what this thesis provides\nThe approach taken by this thesis continues the path started by the extended Kalman lter EKF The EKF is a sequential method developed for inference in dynamical systems with nonlinear dynamics It is not a general method for integration But there are several variations on the EKF Maybeck that have promise One is sequential Monte Carlo a family of nondeterministic techniques Liu Chen Carpenter et al Another is the assumed density lter a general deterministic method that approximately minimizes the KL divergence D f jj g between f x and its approximation g x as shown in gure The next chapter discusses the assumed density lter and its extension to Expectation Propagation"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 457,
                                "start": 446
                            }
                        ],
                        "text": "This thesis has developed a family of algorithms for approximate inference based on ex tending assumed density ltering ADF to use iterative re nement This extension removes all order dependence from ADF and increases its accuracy The family includes loopy be lief propagation in Bayesian networks and extends it to allow approximate messages for reduced computation as well as more elaborate messages for increased accuracy For in ference in the Bayes Point Machine it includes the algorithm of Opper Winther c and provides an alternative to the costly billiard algorithm\nThe accuracy of the Expectation Propagation family was demonstrated on a variety of examples with most emphasis on the Bayes Point Machine\nSection For the clutter problem in one dimension EP was in well behaved cases times more accurate than its nearest competitor Laplace s method both in estimating the posterior mean and the normalizing constant p D In other cases when the true posterior was strongly multimodal EP did not converge at all while Restricted EP and other deterministic methods lagged behind Monte Carlo The computational cost of EP is slightly higher than Laplace s method but much less than Monte Carlo\nSection For marginalizing the mixing weight in a mixture density of two Gaussians EP was again times more accurate than Laplace s method its nearest competitor With modi cations inspired by Cowell et al EP is also faster than Laplace s method In this problem the posterior is always unimodal in fact log convex which may explain why EP always converged\nSection On a toy dataset where the Bayes Point Machine is very di erent from the Support Vector Machine EP delivers high accuracy at a fraction of the cost of its competitor the billiard algorithm The accuracy of EP degrades when points are clustered together but even then it still beats the billiard algorithm with respect to cost On separable problems the posterior is unimodal and EP seems to always converge\nSection EP is also accurate in situations that the billiard algorithm cannot handle namely when there is label noise This was demonstrated on a toy dataset more de tailed experiments showing that EP achieves theoretical bounds are given by Winther since his algorithm is equivalent to EP\nSection On benchmark datasets with around points and - features EP achieves test set error rates consistent with the billiard algorithm Beating the SVM on out\nof datasets EP realizes in practice the theoretical gains expected with a Bayesian approach\nMany opportunities for future work are available both within the framework of EP as well as beyond it First how e ective is EP for other statistical models& For example is it useful for inference in coupled hidden Markov models sigmoid belief networks Barber Sollich and dynamic trees Storkey & Is EP e ective for Bayesian parameter estimation of classi cation models beyond linear classi ers e g hidden Markov models& Is any deterministic method e ective for nonparametric models such as Dirichlet processes Rasmussen &\nSecond can we anticipate how EP will perform& Can EP provide an estimate of its error& The experiments in this paper always used the ADF initialization Are the xed points of EP unique or does initialization matter& What causes EP to diverge& Can it be made to always converge& Can EP be made to give reasonable approximations to multimodal posteriors&\nCan EP be made to run faster especially for the Bayes Point Machine& This thesis compared EP to the original quadratic programming implementation of the Support Vector Machine But much faster specialized algorithms for the SVM are now available due to intense research Can we exploit special properties of the Bayes Point Machine to speed up EP& For example can we represent the A matrix in a sparse fashion& Can we identify the terms that need to be re ned& Having an error estimate for EP could facilitate this\nIs it optimal to minimize KL divergence at each step or should we use some other criterion& The modi ed update inspired by Cowell et al shows that we may obtain computational speedups with other criteria But improvements in accuracy may also be possible if we replace the greedy KL criterion with something that incorporates lookahead For example if we know the posterior has heavy tails and we are approximating it with a Gaussian then we may choose to use a Gaussian with in ated variance to better account for the tails\nThe entire di erence between EP and ADF is that EP makes better choices for the approximate terms !ti But both algorithms base their choices on the old posterior q x which is assumed to be accurate If the true posterior is multimodal then q x cannot possibly be accurate Could we propagate additional information about q x to use in choosing !ti&\nCan iterative re nement be applied to other ltering algorithms& For example some variants of ADF do not use the exponential family Cowell et al approximate a mixture posterior with a smaller mixture after processing each data point see also the generalized pseudo Bayes algorithms in Murphy Frey et al approximate the discrete posterior with an arbitrary tree structured distribution Conventional EP is not practical with these kinds of approximations because the equivalent terms !ti x qnew x q x do not simplify\nYedidia et al give a generalization of belief propagation that is di erent from the generalization a orded by EP Their algorithm propagates exact marginals and pairwise marginals which gives it high accuracy but also limits its practicality Can it be extended to allow approximate messages as in EP& Is there a common parent of their algorithm and EP&\nBayesian inference is a fertile area for developing numerical integration algorithms espe cially deterministic ones because of the rich problem structure and prior knowledge about the functions being integrated There is also relatively little research on it compared to\noptimization for example Many researchers are swayed enough by this imbalance to use inferior techniques such as maximum likelihood estimation because they only involve op timization As argued in this thesis it doesn t have to be that way And I anticipate that there are even better integration algorithms out there waiting for someone to discover them"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1656,
                                "start": 1645
                            }
                        ],
                        "text": "One of the major obstacles to using Bayesian methods for pattern recognition has been its computational expense This thesis presents an approximation technique that can per form Bayesian inference faster and more accurately than previously possible This method Expectation Propagation uni es and generalizes two previous techniques assumed density ltering an extension of the Kalman lter and loopy belief propagation an ex tension of belief propagation in Bayesian networks The uni cation shows how both of these algorithms can be viewed as approximating the true posterior distribution with a simpler distribution which is close in the sense of KL divergence Expectation Propagation exploits the best of both algorithms the generality of assumed density ltering and the accuracy of loopy belief propagation\nLoopy belief propagation because it propagates exact belief states is useful for lim ited types of belief networks such as purely discrete networks Expectation Propagation approximates the belief states with expectations such as means and variances giving it much wider scope Expectation Propagation also extends belief propagation in the op posite direction propagating richer belief states which incorporate correlations between variables\nThis framework is demonstrated in a variety of statistical models using synthetic and real world data On Gaussian mixture problems Expectation Propagation is found for the same amount of computation to be convincingly better than rival approximation techniques Monte Carlo Laplace s method and variational Bayes For pattern recognition Expecta tion Propagation provides an algorithm for training Bayes Point Machine classi ers that is faster and more accurate than any previously known The resulting classi ers outperform Support Vector Machines on several standard datasets in addition to having a comparable training time Expectation Propagation can also be used to choose an appropriate feature set for classi cation via Bayesian model selection\nThesis Supervisor Rosalind Picard Title Associate Professor of Media Arts and Sciences"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 467,
                                "start": 456
                            }
                        ],
                        "text": "Introduction\nMethods of numerical integration\nExpectation Propagation\nAssumed density ltering Expectation Propagation\nThe clutter problem Results and comparisons\nAnother example Mixture weights ADF EP A simpler method Results and comparisons\nDisconnected approximations of belief networks\nBelief propagation Extensions to belief propagation\nGrouping terms Partially disconnected approximations Combining both extensions Future work\nClassi cation using the Bayes Point\nThe Bayes Point Machine Training via ADF Training via EP EP with kernels Results on synthetic data Results on real data Model selection A better billiard algorithm\nSummary and future work"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 138
                            }
                        ],
                        "text": "Bayesian averaging of linear classi ers has been proven both theoretically and empirically optimal in terms of generalization performance (Watkin, 1993; Bouten et al., 1995; Buhot et al., 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 2
                            }
                        ],
                        "text": "& Winther (2000a) have generalized the TAP approach to networks with mixed continuous and discrete nodes via the cavity method, and applied it to Gaussian process classi ers (Opper & Winther, 2000c)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 79
                            }
                        ],
                        "text": "For inference in the Bayes Point Machine, it includes the algorithm of Opper & Winther (2000c) and provides an alternative to the costly billiard algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 24
                            }
                        ],
                        "text": "Classi cation using the Bayes Point\nThis chapter applies Expectation Propagation to inference in the Bayes Point Machine The Bayes Point Machine is a Bayesian approach to linear classi cation that competes with the popular but non Bayesian Support Vector Machine SVM Bayesian averaging of linear classi ers has been proven both theoretically and empirically optimal in terms of generalization performance Watkin Bouten et al Buhot et al But an e cient algorithm has remained elusive The Bayes Point Machine approximates the Bayesian average by choosing one average classi er the Bayes Point Watkin Rujan Herbrich et al Computing the Bayes Point is a simpler but still very di cult task\nThis chapter shows that Expectation Propagation using a full covariance Gaussian ap proximation to the posterior provides an accurate estimate of the Bayes Point an ap proximation to the full Bayesian average The algorithm turns out to be identical to what Opper Winther c derived by statistical physics methods However EP uses a dif ferent optimization scheme that is faster and does not require a stepsize parameter EP also provides an estimate of the evidence p D which is useful for feature selection but not provided by Opper Winther\nThe Bayes Point Machine\nThe Bayes Point Machine BPM is a Bayesian approach to linear classi cation A linear classi er classi es a point x according to y sign wTx for some parameter vector w the two classes are y Given a training set D f x y xn yn g the likelihood for w can be written\np Djw Y i p yijxi w Y i ) yiw Txi\n) z\nif z if z\nThis is a slight abuse of notation since p Djw is only a distribution for y not x This likelihood is if w is a perfect separator and otherwise A simple way to achieve linear separation is to progressively enlarge the set of features e g by computing squares and third powers until the data is separable in the new feature space This has the e ect of producing a nonlinear decision boundary in the original measurement space Feature expansion can be implemented e ciently using the kernel trick where we rewrite the algorithm in terms\nx1\nx2\nx1\nx2\na b\nFigure Two di erent classi cation data sets with label information removed The Bayes Point Machine assumes that without labels we cannot infer where the boundary lies In b one might be inclined to think that the horizontal axis determines the decision But the horizontal axis could easily be something irrelevant like the time of day the datum was collected Only domain knowledge can determine the validity of the assumption\nof inner products and perform the feature expansion implicitly via the inner product This technique will be described more fully later\nBecause it is conditional on xi this model assumes that the distribution of the x s is unrelated to the true decision boundary That is if we were given the x s without any labels we would have no information about where the boundary lies The validity of this assumption must come from domain knowledge it cannot be determined from the data itself see gure The Support Vector Machine SVM for example does not seem to make this assumption Tong Koller show that the SVM follows from assuming that the x s follow a Gaussian mixture distribution in each class In addition some workers have used the SVM with unlabeled data Bennett Demiriz while the BPM by design cannot The advantage of assuming independence in the BPM is that we avoid stronger assumptions about the nature of the dependence and thus obtain a more general algorithm Experiments show it is quite robust section\nA re nement to the basic model is to admit the possibility of errors in labeling or measurement A labeling error rate of can be modeled using Opper Winther b\np yjx w ) ywTx ) ywTx ) ywTx\nUnder this model the likelihood p Djw for a given w will be r n r where r is the number of errors on the training set Only the number of errors is important not where they are This way of modeling errors can automatically reject outliers because it doesn t care how far an error is from the boundary Other approaches based on adding slack to the boundary only allow errors near the boundary and are sensitive to outliers These approaches can be simulated by using a smooth likelihood function such as\np yjx w ywTx where is the cumulative distribution function for a Gaussian The tails of this function fall like exp x so it provides quadratic slack The logistic function could also be\nused it falls like exp x providing linear slack By changing ) to one of these smooth functions the labeling error model can be combined with slack with no computational di culties However this chapter focuses on without slack\nTo complete our Bayesian model we need to specify a prior on w Since the magnitude of w is irrelevant for classi cation some authors have restricted w to the unit sphere in d dimensions and have given w a uniform distribution on the sphere Rujan This distribution is nice because it is fair to all decision boundaries but it is not very convenient to work with A more general non informative prior is an average over spheres Let r kwk be the magnitude of w Given r let w be uniformly distributed on the sphere of radius r This prior is non informative for any r It is also non informative if r is unknown with distribution p r For example p r could be uniform from to allowing w to live in the unit ball instead of on the unit sphere By choosing p r appropriately we can also give w a spherical Gaussian distribution\np w N I\nIt is a property of the spherical Gaussian distribution that conditional on any r w is uniformly distributed on the sphere of radius r so no particular decision boundary is favored by this prior\nGiven this model the optimal way to classify a new data point x is to use the predictive distribution for y given the training data\np yjx D Z w p yjx w p wjD dw\nHowever this requires solving an integral each time A practical substitute is to use a single value ofw which approximates the predictive distribution as well as possible Watkin and Rujan have de ned the Bayes point as the single best w However this point is di cult to nd Thus following Rujan we use the posterior mean for w E wjD Following convention we will be sloppy and also call this the Bayes point Our strategy will be to make a Gaussian approximation to the posterior and use its mean as the estimated Bayes point Of course if we really wanted to we could also use EP to solve the integral for each test point The normalizing constant of the posterior is also useful because as an estimate of p D it allows us to choose among di erent models see section\nTraining via ADF\nStart with the ADF updates ADF was previously applied to the Bayes Point Machine by Csato et al Divide the joint distribution p D w into n terms one for each data point Since y and x always appear multiplied together the formulas will drop y and assume that xi is already scaled by yi Let the approximate posterior have the form\nq w N mw Vw\nFrom minimizing the KL divergence we get the expectation constraints\nEqnew w E p w\nEqnew ww T E p ww T\nTo compute these expectations use the following relations obtained from integration by parts\nZ mw Vw\nZ w t w q w dw\nE p w mw Vwrm logZ mw Vw E p ww\nT E p w E p w T Vw Vw rmrTm rv logZ mw Vw Vw These hold for any t w For the Bayes Point Machine we have combining yx into x\nt w ) wTx z Z z N z dz\nz mTwxp xTVwx\nZ mw Vw z\np xTVwx\nN z z\nrm logZ mw Vw x rv logZ mw Vw mTwx\nxTVwx xxT\nrmrTm rv logZ mw Vw xxT mTwx\nxTVwx xxT\nmw Vw x\nTx\nxTVwx xxT\nThe ADF algorithm is thus\nInitialize mw Vw I the prior Initialize s the scale factor\nFor each data point xi update mw Vw s according to\nmneww mw Vw ixi\nVneww Vw Vwxi ix\nT i m new w\nxTi Vwxi\nVwxi\nT\nsnew s Zi mw Vw\nThe nal mw is the estimate of w used for classi cation Note that this algorithm does not require matrix inversion It is the same algorithm obtained by Csato et al except they expressed it in terms of kernel inner products which makes it more complex\nTraining via EP\nNow we turn the ADF algorithm into an EP algorithm By dividing two consecutive Gaus sian posteriors we nd that the term approximations are also Gaussian parameterized by mi and Vi\n!t w Z qnew w\nq w\nZ\nN mi mw Vi Vw N w mi Vi\nwhere V i V new w\nV w mi Vi V new w\nmneww ViV w mw mw Vi Vw V w m new w mw\nTo simplify this combine it with the ADF updates to get mi Vi directly from mw Vw\nVi\nix T i m new w xTi Vwxi xix T i\nVw\nmi mw Vi Vw ixi\nThe matrix ixTi m new w\nxT i Vwxi\nxix T i has one nonzero eigenvalue which means Vi will have one nite\neigenvalue in the direction of xi This makes sense because term i only constrains the projection of w along xi This special structure allows us to represent Vi with a scalar vi\nV i v i xix T i\nxTi Vixi vi\nFrom we know that\nxTi Vixi xTi Vwxi\nixTi m new w\nxTi Vwxi\nwhich means the update for vi is\nvi x T i Vwxi\nix T i m new w\nAnother consequence of this special structure is that instead of the full vector mi we only need the projection mTi xi which can be stored as a scalar mi\nNow we can write an e cient EP algorithm\nExcept for the prior the term approximations have the form\n!ti w si exp vi wTxi mi\nInitialize them to\nvi mi\nsi\nmneww V new w I the prior\nUntil all mi vi si converge changes are less than\nloop i n\na Remove !ti from the posterior to get an old posterior\nVw V new w v i xixTi Vneww V new w xi vi xTi Vneww xi Vneww xi T mw m new w VwV i m new w mi\nmneww Vwxi v i x T i m new w mi\nThese expressions involving Vw can be computed e ciently\nVwxi V new w xi\nvi\nvi xTi Vneww xi\nxTi Vwxi\nxTi V new w xi\nvi\nb Recompute mneww V new w Zi from mw Vw as in ADF c Update !ti\nvi x T i Vwxi\nixTi m new w\nmi x T i mw vi x T i Vwxi i\nsi Zi jVi Vwj\njVij exp\nmi mw T Vi Vw mi mw\nZi q v i x T i Vwxi exp xTi Vwxi\nxTi m new w\ni\nCompute the normalizing constant\nB mneww T Vneww\nmneww X i m i vi\np D jVneww j exp B nY i si\nThis algorithm processes each data point in O d time Assuming the number of iterations is constant which seems to be true in practice computing the Bayes point therefore takes O nd time Computing the normalizing constant at the end requires O d time\nEP with kernels\nTo use the kernel trick we need to rewrite EP in terms of inner products Following the notation of Opper Winther c de ne\ni x T i V ni wxi V ni w is the Vw when term i is left out\nCij x T i xj\n* diag v vn hi x T i m new w\nh ni i x T i m ni w\nFrom the de nition of qnew w as the product of approximate terms !ti w we know that\nVneww\nI X i xix T i vi\nI X* XT\nmneww V new w X j mjxj vj\nxTi m new w\nX j xTi V new w xj mj vj\nFrom the matrix inversion lemma we therefore have\nC * * * XTVneww X* XTVneww X * * C * *\nC *\nIn this way we can compute xTi V new w xj for any i j using only C and * The EP algorithm becomes\nInitialize vi mi si Initialize hi i Cii\nUntil all mi vi si converge\nloop i n\na Remove !ti from the posterior to get an old posterior\nh ni i hi iv i hi mi\nb Recompute part of the new posterior as in ADF\nz h ni ip i\nZi z i\np i\nN z z\nhi h ni i i i\nc Set\nvi i\nihi\nmi h ni i vi i i hi vi i\nsi Zi q v i i exp\ni i hi\nd Now that * is updated nish recomputing the new posterior\nA C *\nFor all i\nhi X j Aij mj vj\nfrom\ni\nAii vi\nfrom\nCompute the normalizing constant\nB X ij Aij mimj vivj\nX i m i vi\np D j*j\njC *j exp B\nnY i si\nThe determinant expression in follows from\njVneww j I X* XT I XTX*\nI C* j*jjC *j\nIn step it would appear that we need to invert a matrix taking O n time for each data point However since only one vi changes each time A can be updated incrementally in O n time Initialize A C and then update with\nAnew C * +*\nA aia T i\naii\nwhere\nvnewi voldi\nAssuming a constant number of iterations the algorithm thus runs in O n time plus the time to compute the inner product matrix C This is a great improvement over O nd if the dimensionality is very large e g if the feature set is arti cially expanded\nTo show the equivalence with Opper Winther s algorithm we make the following observations\nAt convergence will hold for all i so that X j mjxj vj X j hjxj vj X j jxj\nmneww X j mjxj vj\nI X\nj\nxjx T j\nvj\nAmneww X\nj\njxj\nmneww X j jxj\nhi X j j x T i xj\nX j Cij j\nThis is the equation Opper Winther use instead of\nThe update for i can be written\ni\nvi v i C * ii vi vi v i h C * i ii vi h C *\ni ii\nC * ii vi\nThis is the update Opper Winther use instead of\nEP computes a normalizing constant for the posterior while Opper Winther do not\nAll other updates are identical to those in Opper Winther c though carried out in a di erent order Reordering the updates does not matter as long as both algorithms converge\nThe input to the algorithm is simply the matrix C which can be computed using an arbitrary inner product function C xi xj instead of x T i xj However in that case we need to keep yi and xi separate Cij yiyjC xi xj\nUsing a nonlinear inner product function is an e cient way to use an expanded feature space since we don t have to represent each expanded data point We only have to compute the inner product between two expanded data points which is a scalar function of the original data\nThe output of the algorithm is the i which implicitly represent m new w through\nWith these we classify a new data point according to\nf x sign xTmneww sign X i iyiC x xi\nResults on synthetic data\nFigure a demonstrates the Bayes point classi er vs the SVM classi er on training points Besides the two dimensions shown here each point had a third dimension set at\nThis provides a bias coe cient w so that the decision boundary doesn t have to pass through Each classi er is set to zero label noise and zero slack The Bayes point classi er approximates a vote between all linear separators ranging from an angle of to The Bayes point chooses an angle in the middle of this range SVM chooses the decision boundary to maximize margin the distance to the nearest data point This makes it ignore the topmost data point In fact the Bayes point and SVM would coincide if that point were removed Adding the point reduces the set of linear separators and Bayesian inference must take this into account\nFigure plots the situation in parameter space For viewing convenience we restrictw to the unit sphere The exact Bayes point was computed by likelihood weighted sampling i e sampling a random w on the sphere and discarding those which are not separators EP provides an accurate estimate of the posterior mean mw and posterior covariance Vw Compare\nExact Vw\nEP Vw\nFigure b plots cost vs error for EP versus three other algorithms for estimating the Bayes point the billiard algorithm of Herbrich et al the TAP algorithm of Opper Winther c and the mean eld MF algorithm of Opper Winther c The error is measured by Euclidean distance to the exact solution found by importance sampling The error in using the SVM solution is also plotted for reference Its unusually long running time is due to Matlab s quadprog solver TAP and MF were slower to converge than EP even with a large initial step size of As expected EP and TAP converge to the same solution\nThe billiard algorithm is a Monte Carlo method that bounces a ball inside the region de ned by hyperplane constraints It must be initialized with a linear separator and the SVM was used for that purpose Since there are many other ways one could initialize the billiard which may be much cheaper the initialization step was not counted against the billiard s FLOP count otherwise the billiard curve would be right of the SVM point The error axis must also be interpreted carefully While it is tempting to use the lower envelope of the curve as the measure of error it is actually more accurate to use the upper envelope since this is all that the algorithm can consistently achieve as samples accumulate Nevertheless it is clear that EP is much faster and more accurate\nLaplace s method and variational Bayes do not work at all on this problem Laplace fails because the derivatives of the likelihood are not informative they are either zero or in nity Variational Bayes fails for because no Gaussian can lower bound the likelihood Gaussians never reach zero Even with a Gaussian bound must be quite narrow so we can t expect competitive performance\nHerbrich Graepel point out that the SVM is sensitive to scaling an input vector i e if we replace x by x then the solution will change They argue theoretically and empirically that data vectors should therefore be normalized to unit length before SVM training This is quite a shock since no mention of this was made in the original SVM papers If the data in gure including the bias dimension is normalized before training then the SVM solution tilts slightly toward the BPM solution supporting Herbrich Graepel s suggestion The Bayes Point Machine by contrast does not require any normalization because the data likelihood is correctly invariant to scaling an input vector The solution found by EP is also invariant\nSVM Bayes\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u22124\n10 \u22123\n10 \u22122\n10 \u22121\n10 0\nEP\nBilliard\nSVM\nMF\nTAP\nFLOPS\nE rr\nor\nFigure left Bayes point machine vs Support Vector Machine on a simple data set The Bayes point more closely approximates a vote between all linear separators of the data right Cost vs error in estimating the posterior mean ADF is the rst x on the EP curve\nFigure left The same problem viewed in parameter space the unit sphere Each data point imposes a linear constraint giving an odd shaped region on the sphere The Bayes point is the centroid of the region The EP estimate is indistinguishable from the exact Bayes point on this plot right The Gaussian posterior approximation obtained by EP rendered as a one standard deviation isoprobability ellipsoid\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u22122\n10 \u22121\n10 0\nEP\nBilliard\nSVM\nMF\nTAP\nFLOPS\nE rr\nor\nFigure Cost vs error for the point problem with one point replicated times\nThe linear classi cation problem is special in that some points can have large in uence on the solution while adjacent points have zero in uence This is because the constraints imposed by the latter points may be redundant given the constraints already imposed by other points This property allows the support vector machine to focus on a small number of points the support vectors when nding its solution Unfortunately this property can cause havoc with EP EP uses Gaussians to smooth out the hard constraints and cannot always recognize when a point is redundant and should be ignored The result is that clusters of points can degrade the EP estimate Figure shows what happens to gure b when the point at is replicated times As expected the cluster of points counts more than it should making the EP boundary move slightly away from it The accuracy of EP TAP and MF degrades signi cantly while SVM and Billiard are unchanged On the bright side the error cannot be made arbitrarily high using more than replications or replicating the other points does not degrade the accuracy any further One work around for this behavior would be to reduce the dataset in advance e g to just the support vectors This idea has not been tested yet\nFigure compares the EP solution to the exact posterior mean when noisy labels are allowed Theoretically this integral is harder since we have to consider the entire parameter space not just perfect separators EP can handle it with no additional cost The solution comes out vertical because it is a compromise between the small set of perfect separators at and the larger set of boundaries between and which have one error There is also a set of boundaries past which also have one error On this dataset a similar result can be achieved with the SVM if we set the slack parameter C though this would not necessarily be true on another dataset Winther has given extensive evaluations of EP with and on synthetic datasets showing that it achieves the theoretical performance of Bayesian averaging Those experiments are not repeated here\nFigure demonstrates EP with a nonlinear kernel contrasting it to the SVM solution\n\u22121 \u22120.5 0 0.5 1 1.5 2 \u22121\n\u22120.5\n0\n0.5\n1\n1.5\n2\nExactEP\nFigure The EP solution has good agreement with the exact posterior mean when noisy labels are allowed\nwith the same kernel The kernel was Gaussian\nC xi xj exp\nxi xj T xi xj\nwith width parameter and The feature expansion equivalent to this kernel has an in nite number of features The SVM is quite sensitive to the choice of as well as the idiosyncrasies of the dataset This is related to the sparsity of the SVM solution when the boundary depends on only a few data points i e a few Gaussian kernels small changes in those kernels have a larger e ect on the boundary Similar results obtain if we use a polynomial kernel\nC xi xj x T i xj\np\nFor large p the boundaries are almost identical to those for a wide Gaussian kernel\nBPM SVM\nBPM SVM\nnarrow Gaussian kernel wide Gaussian kernel\nFigure Classi cation boundaries resulting from Support Vector Machine training vs Bayes Point Machine training with EP Both used a Gaussian kernel with the same width parameter left Narrow width The SVM tends to put extra bumps and kinks in the boundary right Wider width The SVM chooses an unusual solution in order to maximize margin in the expanded space The BPM boundary is non sparse all i but smoother It is hardly a ected by changing the kernel width Billiard gives results similar to EP\nResults on real data\nFor higher dimensional problems it is more di cult to compute the exact Bayes point and make cost vs accuracy comparisons So instead we ll measure cost vs test performance on benchmark problems\nFigure compares EP Billiard and SVM on discriminating handwritten digit from Each data point xi is an binary image dimensions The dataset was randomly split times into a small training set of points and a test set of points All algorithms were linear and set for zero noise Billiard was run for iterations which is far more computation than EP or SVM used Nevertheless EP is best\nFigures and show the same type of comparison on four datasets from the UCI repository Blake Merz Each dataset was randomly split times into a training set and test set in the ratio , , In each trial the features were normalized to have zero mean and unit variance in the training set The classi ers used zero label noise and a Gaussian kernel with Billiard was run for iterations The thyroid dataset was made into a binary classi cation problem by merging the di erent classes into normal vs abnormal Except for sonar EP and Billiard beat the SVM a majority of the time and in all cases EP performed similarly to Billiard However the running time for Billiard is signi cantly higher since it must be initialized at the SVM solution Figure shows cost vs test error curves on some typical runs The SVM using quadprog is particularly slow on thyroid The unusual success of the SVM on sonar was also reported by Herbrich et al and may be related to the di erent assumptions made by the SVM see section\nTo give an idea of the actual running time in Matlab gure plots the training time vs training set size for trials As expected the time scales as n Extrapolating from this it would take an hour for data points and weeks for data points Finding a way to speed up EP similar to the way that quadratic programming can be sped up for the SVM will be essential for large data sets\n30 40 50 60 70 80 35\n40\n45\n50\n55\n60\n65\n70\nSVM\nE P\nTest errors\n30 40 50 60 70 35\n40\n45\n50\n55\n60\n65\n70\nBilliard\nE P\nTest errors\nFigure Test error of SVM vs EP left and Billiard vs EP right on digit classi cation over random train'test splits Each point is test error for SVM'Billiard test error for EP Points under the line correspond to trials where EP had a lower test error EP beat SVM times and beat Billiard times despite being the fastest of all three algorithms of this dataset\nHeart features training points\n0.15 0.2 0.25 0.3\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\n0.26\n0.28\n0.3\n0.32\nSVM\nE P\nTest errors\n0.15 0.2 0.25 0.3\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\n0.26\n0.28\n0.3\n0.32\nBilliard\nE P\nTest errors\nThyroid features training points\n\u22120.05 0 0.05 0.1 0.15 \u22120.05\n0\n0.05\n0.1\n0.15\nSVM\nE P\nTest errors\n\u22120.05 0 0.05 0.1 0.15 \u22120.05\n0\n0.05\n0.1\n0.15\nBilliard\nE P\nTest errors\nFigure Test error rates over train'test splits Each point is test error for SVM'Billiard test error for EP Points under the line correspond to trials where EP had a lower test error For running times see gure\nIonosphere features training points\n0.05 0.1 0.15 0.2\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\nSVM\nE P\nTest errors\n0.05 0.1 0.15 0.2 0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\nBilliard\nE P\nTest errors\nSonar features training points\n0.05 0.1 0.15 0.2\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\nSVM\nE P\nTest errors\n0.05 0.1 0.15 0.2\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\nBilliard\nE P\nTest errors\nFigure Test error rates over train'test splits Each point is test error for SVM'Billiard test error for EP for one trial Points under the line correspond to tri als where EP had a lower test error For running times see gure\nHeart Thyroid\n10 7\n10 8\n10 9\n0.21\n0.22\n0.23\n0.24\n0.25\n0.26\n0.27\n0.28\n0.29\n0.3\nEP\nBilliard\nSVM\nFLOPS\nT es\nt e rr\nor\n10 7\n10 8\n10 9\n10 10\n0\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\nFLOPS\nT es\nt e rr\nor\nSVM\nEP Billiard\nIonosphere Sonar\n10 7\n10 8\n10 9\n10 10\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\nFLOPS\nT es\nt e rr\nor\nSVM\nEP\nBilliard\n10 6\n10 7\n10 8\n10 9\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\n0.26\n0.28\n0.3\nFLOPS\nT es\nt e rr\nor\nSVM EP\nBilliard\nFigure Cost vs test error on a typical trial for each dataset\n0 200 400 600 800 0\n5\n10\n15\n20\n25\nTraining set size\nT ra\nin in\ng tim\ne (m\nin s)\nFigure Actual training time in Matlab for EP with kernels for di erent dataset sizes It nearly perfectly follows n growth The time to compute the inner product matrix is not included\nModel selection\nThis section reports results on Bayesian model selection using the estimated evidence p D This is a unique feature of EP because the billiard algorithm cannot provide an estimate of p D By maximizing the evidence we can select the appropriate feature set feature kernel or noise parameter For background on Bayesian model selection see MacKay Kass Raftery Minka a A popular approach to model selection for the SVM is to minimize R\nM where R is the radius of the smallest ball containing the training\nset measured in the mapped feature space and M is the margin Cristianini et al Another approach is to minimize the span bound given by thresholding the s Chapelle Vapnik Chapelle et al\nS X\nsupport vectors i\n) i h C sv i ii\nThese three criteria evidence margin and span can lead to quite di erent results Figure shows a synthetic training set classi ed according to distance from the origin i e the true decision boundary is a circle Three di erent decision boundaries result from training an SVM with three di erent kernels the decision boundaries from EP are nearly identical All of these boundaries achieve zero error so we need to invoke some other rule besides training error to select among them Over all Gaussian kernels the margin criterion is minimized by taking This produces a decision boundary with spurious kinks and bumps The span bound is minimized by an even narrower kernel where the bound is By contrast the best Gaussian kernel according to evidence has providing a much smoother and more realistic boundary The quadratic kernel which is the closest to the true boundary has even greater evidence yet less margin\nIn the noise free case the Bayesian evidence p D has a natural interpretation It is the fraction of perfect separators out of all representable classi ers If a particular set of features has a large percentage of perfect separators then we intuitively should have more faith in that feature set This is what Bayesian model selection does and in choosing the Bayes point we follow the same basic argument Maximizing the margin does not necessarily behave this way\nThe next example repeats the feature selection experiment of Weston et al Chapelle et al Synthetic data with six features was created by rst sampling y with equal probability and then setting\nx N y x N y x N y x N x N x N\nWith probability features x -x were swapped with features x -x Thus all six features are relevant to some degree To these six relevant features are appended irrelevant features with distribution N The test is to see whether we can reject the irrelevant features In Chapelle et al the algorithm was forced to keep only two features Here we use a more rigorous test features are added one by one starting with the relevant ones\nGaussian Gaussian\nKernel R M span log p D\nquadratic\nQuadratic\nFigure A dataset classi ed with three di erent kernels The margin criterion R M prefers the solution while the Bayesian evidence p D prefers the quadratic solution The span bound prefers a Gaussian with tiny not shown The true boundary is a circle\n0 5 10 15 20 10\n15\n20\n25\n30 35 M ar gi n bo un d\nNumber of features 0 5 10 15 20\n0\n1\n2\n3\n4\n5\n6\n7\nS pa\nn bo\nun d\nNumber of features\n0 5 10 15 20 \u221215\n\u221214\n\u221213\n\u221212\n\u221211\n\u221210\n\u22129\n\u22128\n\u22127\nE P\ne vi\nde nc\ne\nNumber of features\nFigure Feature selection curves for the margin bound span bound and Bayesian evidence The Bayesian evidence has a clear peak at six the correct answer The other criteria which are to be minimized do not perform as well The margin bound has only a local minimum at six and the span bound only a local minimum at ve\nand the algorithm must decide when to stop Figure shows the curves for the margin bound span bound and Bayesian evidence Both the SVM and BPM used a linear kernel with zero slack The Bayesian evidence is clearly a better measure of relevance\nFigure a Conventional billiard algorithms allow the ball to escape They project the collision point onto the surface of the sphere but preserve the rebound velocity dashed line b The new algorithm works inside the sphere using the sphere s surface as an additional wall\nA better billiard algorithm\nA major drawback of current billiard algorithms is that they do not really operate on the sphere The billiard ball always follows a straight line trajectory until it hits a wall at which point it is projected back onto the sphere gure a Unfortunately this means the ball can sometimes leave the sphere without ever hitting a wall On the point problem in gure this happens on , of the bounces Rujan recovers from this by restarting the billiard at its initial point with a random velocity Unfortunately this introduces severe bias in the estimate by overcounting the initial point Herbrich et al have a better solution leave the ball where it is but choose a new random velocity This has less bias but doesn t resemble a billiard anymore\nThe problem of escaping billiard balls can be avoided entirely if we simply rede ne the pool Remember that the unit sphere was an arbitrary choice we can use any prior distribution that assigns equal probability to all w vectors of a given length So let s use the inside of the unit sphere as shown in gure b The sphere s surface is an additional wall that prevents escape The new algorithm is\nDetermine the next collision From position w and velocity v compute the ight time to each wall and take the minimum The distance from wall xi is\ndi wTxiq xTi xi\nand the velocity normal to xi is\nvi vTxiq xTi xi\nso the ight time is\ni\ndivi if vi otherwise\nThe ight time to the surface of the sphere satis es\nw v T w v\nq wTv vTv wTw wTv\nvTv\nwhich is always positive and nite\nUpdate the position of the ball the total distance traveled s and the center of mass estimate m\nwnew w v min\nz kwnew wk mnew s\ns z m\nz\ns z\nwnew w\nsnew s z\nUpdate the velocity If xi was hit\nvnew v vi xiq xTi xi\nIf the surface of the sphere was hit\nvnew v wnew wnew Tv\nThe length of v is unchanged by these updates so if we initialize vTv it will stay that way throughout the algorithm\nThe algorithm can also be made use a kernel inner product as in Herbrich et al With this algorithm we can run one billiard trajectory without ever restarting However that is not a good idea because the pool is not perfectly ergodic By periodically randomiz ing the velocity of the ball we can achieve a more ergodic sampling Periodic randomization is important in all Markov chain Monte Carlo schemes including Gibbs sampling For the billiard randomization at every bounces seems to work well\nFigure compares the three algorithms on the point problem of section Each was run for iterations using a comparable number of ops Because of its bias Rujan s algorithm is never more accurate than in Euclidean distance to the true value Herbrich s algorithm does better but also seems to level o at The new algorithm with randomization every bounces converges nicely These characteristics are typical and hold across many di erent runs on this dataset\n10 2\n10 4\n10 6\n10 \u22123\n10 \u22122\n10 \u22121\n10 0\nRujan\nHerbrich\nNew\nFLOPS\nE rr\nor\nFigure Cost vs error of conventional billiard algorithms vs the new algorithm"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6413,
                                "start": 6402
                            }
                        ],
                        "text": "The dominant computational task in Bayesian inference is numerical integration New methods for fast and accurate integration are therefore very important and can have great impact This dissertation presents a new deterministic approximation framework Expecta tion Propagation which achieves higher accuracy than existing integration algorithms with similar computational cost\nThe general scenario of Bayesian inference is that there is some observed data and some unobserved quantity of interest Inferences about the unknown x are based on its posterior distribution given the observed D\np xjD p x D p D\np x D R\nx p x D dx\nFor example we may want to know the posterior mean and variance of the unknown which are integrals over the posterior\nE xjD Z x xp xjD dx\nR x xp x D dxR x p x D dx\nE x jD Z x x p xjD dx\nR x x\np x D dxR x p x D dx\nvar xjD E x jD E xjD\nIn real situations there are many unknowns not just the one we are interested in In Bayesian inference these must be marginalized out of the joint distribution which involves yet more integrals\np xjD R y z p x y z D R x y z p x y z D\nThus numerical integration goes hand in hand with practical Bayesian inference Numerical integration algorithms can be principally divided into deterministic vs non deterministic methods Deterministic methods try to approximate the integrand with some thing whose integral is known exactly They work from properties of the integrand like its maxima and curvature Nondeterministic methods sample the integrand at random points to get a stochastic estimate of the integral This approach is more general since it works for almost any integrand but it also requires a great deal more computation than deterministic approximation\nThe proposed method Expectation Propagation is a deterministic approximation method It is an extension to assumed density ltering ADF Maybeck Lauritzen Bernardo Giron Stephens Boyen Koller b Barber Sollich Opper Winther Frey et al a one pass sequential method for comput ing an approximate posterior distribution In ADF observations are processed one by one updating the posterior distribution which is then approximated before processing the next observation For example we might replace the exact one step posterior with a Gaussian having the same mean and same variance Maybeck Lauritzen Barber Sol lich Opper Winther Or we might replace a posterior over many variables with one that renders the variables independent Boyen Koller b or approximates them as Markovian Frey et al In each case the approximate posterior is found by minimizing KL divergence which amounts to preserving a speci c set of posterior expecta tions Note that the statistical model in question need not be a time series model and the processing order of observations need not correspond with time of arrival The weakness of ADF stems from its sequential nature information that is discarded early on may turn out to be important later Even if ADF is augmented with a backward pass Boyen Koller a this information cannot be recovered ADF is also sensitive to observation ordering which is undesirable in a batch context\nExpectation Propagation EP extends ADF to incorporate iterative re nement of the approximations by making additional passes The information from later observations re nes the choices made earlier so that the most important information is retained When the re nement converges the resulting posterior is independent of ordering and more accurate Iterative re nement has previously been used in conjunction with sampling Koller et al and extended Kalman ltering Shachter Expectation Propagation di ers by applying this idea to the deterministic approximation of general distributions not just Gaussian distributions as in Shachter EP is more expensive than ADF by only a constant factor the number of re nement passes typically or As shown in chapter the accuracy of EP is signi cantly better than ADF as well as rival approximation methods Monte Carlo Laplace s method and variational Bayes\nThinking in this framework has a number of bene ts For example in belief networks with loops it is known that approximate marginal distributions can be obtained by iterating the belief propagation recursions a process known as loopy belief propagation Frey MacKay Murphy et al As described in chapter it turns out that this heuristic procedure is a special case of Expectation Propagation where the approximate posterior is a completely disconnected network with no other constraints on functional form In other words loopy belief propagation is a direct generalization of the ADF algorithm of Boyen Koller b\nExpectation Propagation can therefore be seen as a way of generalizing loopy belief propagation to less restrictive approximations that are not completely disconnected and to useful constraints on functional form such as multivariate Gaussian Partially disconnected approximations are useful for improving accuracy just as in variational methods Jordan et al while constraints on functional form are useful for reducing computation Instead of propagating exact belief states which may be intractable EP only needs to propagate expectations relevant to the chosen approximating distribution e g means and variances Hence the name Expectation Propagation\nExpectation Propagation also has connections to statistical physics techniques Yedidia et al have shown that belief propagation tries to minimize an approximate free en ergy on discrete networks This is known as the TAP approach in statistical physics Opper\nWinther a have generalized the TAP approach to networks with mixed continuous and discrete nodes via the cavity method and applied it to Gaussian process classi ers Opper Winther c Chapter shows that Opper Winther s algorithm which has excellent performance is a special case of Expectation Propagation where the posterior approximation is Gaussian In this sense Expectation Propagation as a generalization of belief propagation parallels the cavity method as a generalization of TAP\nExpectation Propagation as a general framework for approximate Bayesian inference can be applied to many real world tasks Chapter demonstrates its use for the general task of discriminating objects into classes Classi cation via Bayesian averaging has long been popular in the theoretical community but di cult to implement in a computationally competitive way An excellent example of this is the Bayes Point Machine Rujan Herbrich et al With Expectation Propagation the advantages of Bayesian averaging can be achieved at less expense than previously possible\nIn short\nChapter reviews the prior work in approximate Bayesian inference excluding ADF Chapter reviews ADF and introduces Expectation Propagation Both are illustrated on simple statistical models\nChapter addresses belief networks describing how loopy belief propagation is a special case of Expectation Propagation and how belief propagation may be extended\nChapter applies Expectation Propagation to the Bayes Point Machine classi er Chapter summarizes the results and o ers suggestions for future work on Expecta tion Propagation"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 111
                            }
                        ],
                        "text": "The Bayes Point Machine approximates the Bayesian average by choosing one `average' classi er, the Bayes Point (Watkin, 1993; Rujan, 1997; Herbrich et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 119672672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3afa60b6a9f0e49bb58a533afa2be282b304c053",
            "isKey": true,
            "numCitedBy": 59,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce optimal learning with a neural network, which we define as minimising the expectation generalisation error. We find that the optimally-trained spherical perceptron may learn a linearly-separable rule as well as any possible network. We sketch an algorithm to generate optimal learning, and simulation results support our conclusions. Optimal learning of a well-known, significant unlearnable problem, the mismatched weight problem, gives better asymptotic learning than conventional techniques, and may be simulated enormously more easily. Unlike many other learning schemes, optimal learning extends to more general networks learning more complex rules."
            },
            "slug": "Optimal-Learning-with-a-Neural-Network-Watkin",
            "title": {
                "fragments": [],
                "text": "Optimal Learning with a Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is found that the optimally-trained spherical perceptron may learn a linearly-separable rule as well as any possible network, and simulation results support these conclusions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34631309"
                        ],
                        "name": "R. Cowell",
                        "slug": "R.-Cowell",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Cowell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cowell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714284"
                        ],
                        "name": "P. Sebastiani",
                        "slug": "P.-Sebastiani",
                        "structuredName": {
                            "firstName": "Paola",
                            "lastName": "Sebastiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sebastiani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1471,
                                "start": 125
                            }
                        ],
                        "text": "Is it optimal to minimize KL-divergence at each step, or should we use some other criterion? The modified update inspired by Cowell et al. (1996) shows that we may obtain computational speedups with other criteria. But improvements in accuracy may also be possible, if we replace the greedy KL criterion with something that incorporates lookahead. For example, if we know the posterior has heavy tails and we are approximating it with a Gaussian, then we may choose to use a Gaussian with inflated variance, to better account for the tails. The entire difference between EP and ADF is that EP makes better choices for the approximate terms ti. But both algorithms base their choices on the 'old' posterior q(x), which is assumed to be accurate. If the true posterior is multimodal, then q(x) cannot possibly be accurate. Could we propagate additional information about q(x) to use in choosing Ii? Can iterative refinement be applied to other filtering algorithms? For example, some variants of ADF do not use the exponential family. Cowell et al. (1996) approximate a mixture posterior with a smaller mixture after processing each data point; see also the \"generalized pseudo-Bayes\" algorithms in Murphy (1998). Frey et al. (2000) approximate the discrete posterior with an arbitrary tree-structured distribution. Conventional EP is not practical with these kinds of approximations because the equivalent terms t,(x)= q new(x)/q(x) do not simplify. Yedidia et al. (2000) give a generalization of belief propagation that is different from the generalization afforded by EP."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 125
                            }
                        ],
                        "text": "Is it optimal to minimize KL-divergence at each step, or should we use some other criterion? The modified update inspired by Cowell et al. (1996) shows that we may obtain computational speedups with other criteria."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1054,
                                "start": 125
                            }
                        ],
                        "text": "Is it optimal to minimize KL-divergence at each step, or should we use some other criterion? The modified update inspired by Cowell et al. (1996) shows that we may obtain computational speedups with other criteria. But improvements in accuracy may also be possible, if we replace the greedy KL criterion with something that incorporates lookahead. For example, if we know the posterior has heavy tails and we are approximating it with a Gaussian, then we may choose to use a Gaussian with inflated variance, to better account for the tails. The entire difference between EP and ADF is that EP makes better choices for the approximate terms ti. But both algorithms base their choices on the 'old' posterior q(x), which is assumed to be accurate. If the true posterior is multimodal, then q(x) cannot possibly be accurate. Could we propagate additional information about q(x) to use in choosing Ii? Can iterative refinement be applied to other filtering algorithms? For example, some variants of ADF do not use the exponential family. Cowell et al. (1996) approximate a mixture posterior with a smaller mixture after processing each data point; see also the \"generalized pseudo-Bayes\" algorithms in Murphy (1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 897,
                                "start": 31
                            }
                        ],
                        "text": "With modifications inspired by Cowell et al. (1996), EP is also faster than Laplace's method. In this problem, the posterior is always unimodal (in fact log-convex), which may explain why EP always converged. Section 5.5 On a toy dataset where the Bayes Point Machine is very different from the Support Vector Machine, EP delivers high accuracy at a fraction of the cost of its competitor, the billiard algorithm. The accuracy of EP degrades when points are clustered together, but even then it still beats the billiard algorithm with respect to cost. On separable problems, the posterior is unimodal and EP seems to always converge. Section 5.5 EP is also accurate in situations that the billiard algorithm cannot handle, namely when there is label noise. This was demonstrated on a toy dataset; more detailed experiments, showing that EP achieves theoretical bounds, are given by Winther (1998), since his algorithm is equivalent to EP."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 31
                            }
                        ],
                        "text": "With modifications inspired by Cowell et al. (1996), EP is also faster than Laplace's method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1231,
                                "start": 125
                            }
                        ],
                        "text": "Is it optimal to minimize KL-divergence at each step, or should we use some other criterion? The modified update inspired by Cowell et al. (1996) shows that we may obtain computational speedups with other criteria. But improvements in accuracy may also be possible, if we replace the greedy KL criterion with something that incorporates lookahead. For example, if we know the posterior has heavy tails and we are approximating it with a Gaussian, then we may choose to use a Gaussian with inflated variance, to better account for the tails. The entire difference between EP and ADF is that EP makes better choices for the approximate terms ti. But both algorithms base their choices on the 'old' posterior q(x), which is assumed to be accurate. If the true posterior is multimodal, then q(x) cannot possibly be accurate. Could we propagate additional information about q(x) to use in choosing Ii? Can iterative refinement be applied to other filtering algorithms? For example, some variants of ADF do not use the exponential family. Cowell et al. (1996) approximate a mixture posterior with a smaller mixture after processing each data point; see also the \"generalized pseudo-Bayes\" algorithms in Murphy (1998). Frey et al. (2000) approximate the discrete posterior with an arbitrary tree-structured distribution."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Cowell et al. (1996) suggest instead preserving only the first two moments of the posterior distribution, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1211,
                                "start": 125
                            }
                        ],
                        "text": "Is it optimal to minimize KL-divergence at each step, or should we use some other criterion? The modified update inspired by Cowell et al. (1996) shows that we may obtain computational speedups with other criteria. But improvements in accuracy may also be possible, if we replace the greedy KL criterion with something that incorporates lookahead. For example, if we know the posterior has heavy tails and we are approximating it with a Gaussian, then we may choose to use a Gaussian with inflated variance, to better account for the tails. The entire difference between EP and ADF is that EP makes better choices for the approximate terms ti. But both algorithms base their choices on the 'old' posterior q(x), which is assumed to be accurate. If the true posterior is multimodal, then q(x) cannot possibly be accurate. Could we propagate additional information about q(x) to use in choosing Ii? Can iterative refinement be applied to other filtering algorithms? For example, some variants of ADF do not use the exponential family. Cowell et al. (1996) approximate a mixture posterior with a smaller mixture after processing each data point; see also the \"generalized pseudo-Bayes\" algorithms in Murphy (1998). Frey et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 115606926,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "3930376440ffd434b15c727c898790b0c1a36079",
            "isKey": true,
            "numCitedBy": 30,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This invention relates to an improved golf ball retriever of the type which may be lowered directly over the ball. The retriever has a telescopic handle for reaching into water hazards and the like. The handle is pivotally connected to a body member which has a pair of lower forwardly extending curved arms and a retaining ring pivotally connected at its rear to the body member at a point above the plane of the curved arms. Thus the retaining ring normally slopes forwardly downward and rests on the ends of the curved arms. The ring is slightly larger in diameter than a golf ball and when the retriever is lowered over a golf ball, the ring pivots slightly upward to increase the effective size of the opening between it and the curved arms to allow the ball to pass therethrough. When it has, the ring drops down past the outside of the ball, and the retriever is then lifted upwards with the ball engaged by the ring and the curved arms. The body member has an upper curved holding finger which prevents the ball from being dislodged and to which the handle is pivotally connected. This structure provides the advantage that the ball may be released simply by resting the body member on the ground and pulling forward on the handle. This automatically pivots the body portion about the ball and the retaining ring to release the ball. In other embodiments, the retaining ring may be rectangular or triangular with the body portion having arms to match."
            },
            "slug": "A-comparison-of-sequential-learning-methods-for-Cowell-Dawid",
            "title": {
                "fragments": [],
                "text": "A comparison of sequential learning methods for incomplete data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703039"
                        ],
                        "name": "Paat Rusmevichientong",
                        "slug": "Paat-Rusmevichientong",
                        "structuredName": {
                            "firstName": "Paat",
                            "lastName": "Rusmevichientong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paat Rusmevichientong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731282"
                        ],
                        "name": "Benjamin Van Roy",
                        "slug": "Benjamin-Van-Roy",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Van Roy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Van Roy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1289,
                                "start": 95
                            }
                        ],
                        "text": "Typically, q(x) is constrained to be Gaussian (Hinton & van Camp, 1993; Barber & Bishop, 1997; Seeger, 1999) but mixture distributions have also been suggested (Jaakkola & Jordan, 1999c). Having a lower bound is useful since it provides a rm guarantee about the true value of the integral|something none of the other methods can do. However it tends to be very computational and is feasible in a limited number of cases. Jensen's inequality takes advantage of the fact that log(f(x)) is often easy to integrate when f(x) is not. But this is not always true. For example, in a mixture problem such as discussed in chapter 3, f is a product of sums, which does not simplify under a logarithm. And in chapter 5, the likelihood is a step function which reaches zero. The step function could be softened into a sigmoid to make the Jensen bound well-de ned, but we could not expect a good t to result. A less accurate but simpler way to obtain a variational bound is to bound the integrand and then integrate the bound: f(x) g(x) for all x (2.15) I Zx g(x)dx (2.16) Figure 2-1 shows an example. Unlike the previous variational method, this approach can be used in mixture problems. This approach was used explicitly by Jaakkola & Jordan (1999a; 1999b) and implicitly by Waterhouse et al. (1995); Attias (1999); Ghahramani & Beal (1999), under the name \\variational Bayes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 63
                            }
                        ],
                        "text": "ADF was applied to this problem by Bernardo & Giron (1988) and Stephens (1997). Break the joint distribution p(D;w) into n+1 terms as given by (3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2749292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efa3492756d36303370d40c1de80fc790b3451d7",
            "isKey": true,
            "numCitedBy": 18,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We provide an analysis of the turbo decoding algorithm (TDA) in a setting involving Gaussian densities. In this context, we are able to show that the algorithm converges and that - somewhat surprisingly - though the density generated by the TDA may differ significantly from the desired posterior density, the means of these two densities coincide."
            },
            "slug": "An-Analysis-of-Turbo-Decoding-with-Gaussian-Rusmevichientong-Roy",
            "title": {
                "fragments": [],
                "text": "An Analysis of Turbo Decoding with Gaussian Densities"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is shown that the turbo decoding algorithm converges and that - somewhat surprisingly - though the density generated by the TDA may differ significantly from the desired posterior density, the means of these two densities coincide."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145728220"
                        ],
                        "name": "K. Bennett",
                        "slug": "K.-Bennett",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Bennett",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bennett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932893"
                        ],
                        "name": "A. Demiriz",
                        "slug": "A.-Demiriz",
                        "structuredName": {
                            "firstName": "Ayhan",
                            "lastName": "Demiriz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Demiriz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7635678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8198e70878c907e1bd05e7a3fa4280d8c338df60",
            "isKey": false,
            "numCitedBy": 873,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a semi-supervised support vector machine (S3VM) method. Given a training set of labeled data and a working set of unlabeled data, S3VM constructs a support vector machine using both the training and working sets. We use S3VM to solve the transduction problem using overall risk minimization (ORM) posed by Vapnik. The transduction problem is to estimate the value of a classification function at the given points in the working set. This contrasts with the standard inductive learning problem of estimating the classification function at all possible values and then using the fixed function to deduce the classes of the working set data. We propose a general S3VM model that minimizes both the misclassification error and the function capacity based on all the available data. We show how the S3VM model for 1-norm linear support vector machines can be converted to a mixed-integer program and then solved exactly using integer programming. Results of S3VM and the standard 1-norm support vector machine approach are compared on ten data sets. Our computational results support the statistical learning theory results showing that incorporating working data improves generalization when insufficient training information is available. In every case, S3VM either improved or showed no significant difference in generalization compared to the traditional approach."
            },
            "slug": "Semi-Supervised-Support-Vector-Machines-Bennett-Demiriz",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A general S3VM model is proposed that minimizes both the misclassification error and the function capacity based on all the available data that can be converted to a mixed-integer program and then solved exactly using integer programming."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145990261"
                        ],
                        "name": "C. Campbell",
                        "slug": "C.-Campbell",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Campbell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Campbell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1012625,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8feebb6e160539e3d114ce0b1c851b6f938aa4a9",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The kernel-parameter is one of the few tunable parameters in Support Vector machines, controlling the complexity of the resulting hypothesis. Its choice amounts to model selection and its value is usually found by means of a validation set. We present an algorithm which can automatically perform model selection with little additional computational cost and with no need of a validation set. In this procedure model selection and learning are not separate, but kernels are dynamically adjusted during the learning process to find the kernel parameter which provides the best possible upper bound on the generalisation error. Theoretical results motivating the approach and experimental results confirming its validity are presented."
            },
            "slug": "Dynamically-Adapting-Kernels-in-Support-Vector-Cristianini-Campbell",
            "title": {
                "fragments": [],
                "text": "Dynamically Adapting Kernels in Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "In this procedure model selection and learning are not separate, but kernels are dynamically adjusted during the learning process to find the kernel parameter which provides the best possible upper bound on the generalisation error."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2824202"
                        ],
                        "name": "L. Bauwens",
                        "slug": "L.-Bauwens",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Bauwens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bauwens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1968901"
                        ],
                        "name": "M. Lubrano",
                        "slug": "M.-Lubrano",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Lubrano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lubrano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143969056"
                        ],
                        "name": "J. Richard",
                        "slug": "J.-Richard",
                        "structuredName": {
                            "firstName": "Jean-Fran\u00e7ois",
                            "lastName": "Richard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Richard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64081377,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "271d99612211715659ca68f145117bd9ad16e75c",
            "isKey": false,
            "numCitedBy": 945,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Want to get experience? Want to get any ideas to create new things in your life? Read methods of numerical integration now! By reading this book as soon as possible, you can renew the situation to get the inspirations. Yeah, this way will lead you to always think more and more. In this case, this book will be always right for you. When you can observe more about the book, you will know why you need this."
            },
            "slug": "Methods-of-Numerical-Integration-Bauwens-Lubrano",
            "title": {
                "fragments": [],
                "text": "Methods of Numerical Integration"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Methods of numerical integration will lead you to always think more and more, and this book will be always right for you."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153292035"
                        ],
                        "name": "Sayan Mukherjee",
                        "slug": "Sayan-Mukherjee",
                        "structuredName": {
                            "firstName": "Sayan",
                            "lastName": "Mukherjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sayan Mukherjee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2860274,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46ba0c8afc9339221076f2b2e497e2a6d9ce6248",
            "isKey": false,
            "numCitedBy": 1131,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a method of feature selection for Support Vector Machines. The method is based upon finding those features which minimize bounds on the leave-one-out error. This search can be efficiently performed via gradient descent. The resulting algorithms are shown to be superior to some standard feature selection algorithms on both toy data and real-life problems of face recognition, pedestrian detection and analyzing DNA microarray data."
            },
            "slug": "Feature-Selection-for-SVMs-Weston-Mukherjee",
            "title": {
                "fragments": [],
                "text": "Feature Selection for SVMs"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The resulting algorithms are shown to be superior to some standard feature selection algorithms on both toy data and real-life problems of face recognition, pedestrian detection and analyzing DNA microarray data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 793899,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbc78c2669eb595c988ab69a6dd4cbabc2421043",
            "isKey": false,
            "numCitedBy": 398,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "New functionals for parameter (model) selection of Support Vector Machines are introduced based on the concepts of the span of support vectors and rescaling of the feature space. It is shown that using these functionals, one can both predict the best choice of parameters of the model and the relative quality of performance for any value of parameter."
            },
            "slug": "Model-Selection-for-Support-Vector-Machines-Chapelle-Vapnik",
            "title": {
                "fragments": [],
                "text": "Model Selection for Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "New functionals for parameter (model) selection of Support Vector Machines are introduced based on the concepts of the span of support vectors and rescaling of the feature space and it is shown that using these functionals one can both predict the best choice of parameters of the model and the relative quality of performance for any value of parameter."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145298005"
                        ],
                        "name": "Catherine Blake",
                        "slug": "Catherine-Blake",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catherine Blake"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62622768,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e068be31ded63600aea068eacd12931efd2a1029",
            "isKey": false,
            "numCitedBy": 13446,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "UCI-Repository-of-machine-learning-databases-Blake",
            "title": {
                "fragments": [],
                "text": "UCI Repository of machine learning databases"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1227,
                                "start": 124
                            }
                        ],
                        "text": "Is it optimal to minimize KL-divergence at each step, or should we use some other criterion? The modi ed update inspired by Cowell et al. (1996) shows that we may obtain computational speedups with other criteria. But improvements in accuracy may also be possible, if we replace the greedy KL criterion with something that incorporates lookahead. For example, if we know the posterior has heavy tails and we are approximating it with a Gaussian, then we may choose to use a Gaussian with in ated variance, to better account for the tails. The entire di erence between EP and ADF is that EP makes better choices for the approximate terms ~ti. But both algorithms base their choices on the `old' posterior q(x), which is assumed to be accurate. If the true posterior is multimodal, then q(x) cannot possibly be accurate. Could we propagate additional information about q(x) to use in choosing ~ti? Can iterative re nement be applied to other ltering algorithms? For example, some variants of ADF do not use the exponential family. Cowell et al. (1996) approximate a mixture posterior with a smaller mixture after processing each data point; see also the \\generalized pseudo-Bayes\" algorithms in Murphy (1998). Frey et al. (2000) approximate the discrete posterior with an arbitrary tree-structured distribution."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1469,
                                "start": 124
                            }
                        ],
                        "text": "Is it optimal to minimize KL-divergence at each step, or should we use some other criterion? The modi ed update inspired by Cowell et al. (1996) shows that we may obtain computational speedups with other criteria. But improvements in accuracy may also be possible, if we replace the greedy KL criterion with something that incorporates lookahead. For example, if we know the posterior has heavy tails and we are approximating it with a Gaussian, then we may choose to use a Gaussian with in ated variance, to better account for the tails. The entire di erence between EP and ADF is that EP makes better choices for the approximate terms ~ti. But both algorithms base their choices on the `old' posterior q(x), which is assumed to be accurate. If the true posterior is multimodal, then q(x) cannot possibly be accurate. Could we propagate additional information about q(x) to use in choosing ~ti? Can iterative re nement be applied to other ltering algorithms? For example, some variants of ADF do not use the exponential family. Cowell et al. (1996) approximate a mixture posterior with a smaller mixture after processing each data point; see also the \\generalized pseudo-Bayes\" algorithms in Murphy (1998). Frey et al. (2000) approximate the discrete posterior with an arbitrary tree-structured distribution. Conventional EP is not practical with these kinds of approximations because the equivalent terms ~ ti(x) = qnew(x)=q(x) do not simplify. Yedidia et al. (2000) give a generalization of belief propagation that is di erent from the generalization a orded by EP."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 30
                            }
                        ],
                        "text": "With modi cations inspired by Cowell et al. (1996), EP is also faster than Laplace's method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Cowell et al. (1996) suggest instead preserving only the rst two moments of the posterior distribution, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 895,
                                "start": 30
                            }
                        ],
                        "text": "With modi cations inspired by Cowell et al. (1996), EP is also faster than Laplace's method. In this problem, the posterior is always unimodal (in fact log-convex), which may explain why EP always converged. Section 5.5 On a toy dataset where the Bayes Point Machine is very di erent from the Support Vector Machine, EP delivers high accuracy at a fraction of the cost of its competitor, the billiard algorithm. The accuracy of EP degrades when points are clustered together, but even then it still beats the billiard algorithm with respect to cost. On separable problems, the posterior is unimodal and EP seems to always converge. Section 5.5 EP is also accurate in situations that the billiard algorithm cannot handle, namely when there is label noise. This was demonstrated on a toy dataset; more detailed experiments, showing that EP achieves theoretical bounds, are given by Winther (1998), since his algorithm is equivalent to EP."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 124
                            }
                        ],
                        "text": "Is it optimal to minimize KL-divergence at each step, or should we use some other criterion? The modi ed update inspired by Cowell et al. (1996) shows that we may obtain computational speedups with other criteria."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1207,
                                "start": 124
                            }
                        ],
                        "text": "Is it optimal to minimize KL-divergence at each step, or should we use some other criterion? The modi ed update inspired by Cowell et al. (1996) shows that we may obtain computational speedups with other criteria. But improvements in accuracy may also be possible, if we replace the greedy KL criterion with something that incorporates lookahead. For example, if we know the posterior has heavy tails and we are approximating it with a Gaussian, then we may choose to use a Gaussian with in ated variance, to better account for the tails. The entire di erence between EP and ADF is that EP makes better choices for the approximate terms ~ti. But both algorithms base their choices on the `old' posterior q(x), which is assumed to be accurate. If the true posterior is multimodal, then q(x) cannot possibly be accurate. Could we propagate additional information about q(x) to use in choosing ~ti? Can iterative re nement be applied to other ltering algorithms? For example, some variants of ADF do not use the exponential family. Cowell et al. (1996) approximate a mixture posterior with a smaller mixture after processing each data point; see also the \\generalized pseudo-Bayes\" algorithms in Murphy (1998). Frey et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1050,
                                "start": 124
                            }
                        ],
                        "text": "Is it optimal to minimize KL-divergence at each step, or should we use some other criterion? The modi ed update inspired by Cowell et al. (1996) shows that we may obtain computational speedups with other criteria. But improvements in accuracy may also be possible, if we replace the greedy KL criterion with something that incorporates lookahead. For example, if we know the posterior has heavy tails and we are approximating it with a Gaussian, then we may choose to use a Gaussian with in ated variance, to better account for the tails. The entire di erence between EP and ADF is that EP makes better choices for the approximate terms ~ti. But both algorithms base their choices on the `old' posterior q(x), which is assumed to be accurate. If the true posterior is multimodal, then q(x) cannot possibly be accurate. Could we propagate additional information about q(x) to use in choosing ~ti? Can iterative re nement be applied to other ltering algorithms? For example, some variants of ADF do not use the exponential family. Cowell et al. (1996) approximate a mixture posterior with a smaller mixture after processing each data point; see also the \\generalized pseudo-Bayes\" algorithms in Murphy (1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A comparison of sequential learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3409,
                                "start": 3390
                            }
                        ],
                        "text": "This chapter describes prior work in approximate Bayesian inference The outline is\nNumerical quadrature\nMonte Carlo methods importance sampling Gibbs sampling\nLaplace s method\nVariational bound on the integral using Jensen s inequality\nVariational bound on the integrand variational Bayes\nStatistical physics methods\nSequential ltering\nThe classical approach to numerical integration is quadrature Davis Rabinowitz In this deterministic approach the integrand is evaluated at several locations knots and a function is constructed that interpolates these values The interpolant is chosen from a simple family that can be integrated analytically e g polynomials or splines The integral of the interpolant approximates the desired integral and with enough knots the approximation can be made arbitrarily accurate By using a set of prede ned knots x xn the interpolation and integration procedure can be compiled down to a simple summation of weighted function values\nI\nZ A f x dx\nI nX i wif xi\nwhere the weights wi are known This method is excellent with integrands that are simple i e that are easy to interpolate In one dimension quadrature is nearly unbeatable But in high dimensions it is infeasible because of the vast number of knots required to get a good interpolant of a complex function In Bayesian inference problems the integrands are mostly zero except in small regions i e they are sparse which makes the situation even worse most of the knots will be wasted Newer deterministic techniques try to avoid these problems by exploiting more properties of the integrand than just its value at given points Another approach is nondeterminism\nNondeterministic i e Monte Carlo methods do not try to interpolate or otherwise approximate the integrand at all they merely appeal to the law of large numbers In the simplest approach we sample knots uniformly in the region of integration A The expected value E f x under such a sampling must be the desired integral I divided by the area of A Hence the estimate\nI jAj n nX i f xi\nwill converge to the true value given enough samples and this happens independent of dimensionality and independent of the complexity of f Thus while Monte Carlo is rather ine cient in low dimensions requiring thousands of knots when quadrature would only need around it is often the only feasible method in high dimensions In Bayesian inference problems the sparsity of the integrand can be addressed by the technique of importance sampling Instead of sampling uniformly in A we sample from a proposal distribution p x that matches the shape of jf j as well as possible Then the estimate\nI\nn nX i f xi p xi\nalso converges to I and much faster than would Importance sampling also has the advantage of working for in nite regions A Various enhancements to the basic importance sampling procedure are possible Ventura With importance sampling the di culties of numerical integration are replaced by the di culties of sampling from a complex distribu tion Good proposal distributions may be hard to sample from In this case one can apply Markov Chain Monte Carlo methods Neal Liu such as Metropolis sampling and Gibbs sampling In these methods we generate samples that are approximately from p x and then apply as before For these methods careful monitoring and restarting is required to ensure that the samples adequately represent p x The Billiard algorithm for Bayes Point Machines discussed in chapter is a particularly clever Markov Chain Monte Carlo algorithm\nTo learn about a function we can compute its value at a large number of knots but we could also compute a large number of derivatives at a single knot This is the basic idea of Taylor expansion By nite di erences a given number of knots translates into an equivalent number of derivatives so theoretically this approach has no advantage over quadrature But for Bayesian inference problems it has certain conceptual advantages Since the integrand is sparse it makes sense to focus on one area where the action is Interpolation is also simpler since we just match derivatives The most popular application of this idea in statistics is Laplace s method Kass Raftery where we expand log f about its mode\nlog f x log f x gT x x x x TA x x\ng\nd log f x\ndx\nx x\nH d log f x\ndxdxT\nx x\nBecause x is the mode g and we get\nf x f x exp x x TH x x\nI\nZ A f x dx f x rows H j Hj\nw p( D\n,w )\nExact Laplace\nw\np( D\n,w )\nExact Bound\na b\nw\np( D\n,w )\nExact EP\nc\nFigure Deterministic methods for integration try to approximate the integrand a Laplace s method uses a Gaussian that has the correct curvature at the mode It produces approximations that are too local b In one type of variational bound the integrand is bounded everywhere It produces approximations that are too inaccurate c The proposed method Expectation Propagation tries to minimize KL divergence a global measure of deviation It produces the most accurate integrals\nWhat Laplace s method does is approximate f by a scaled Gaussian density that matches the value rst derivative and second derivatives of f at x Figure shows an example The drawback of this method is that it is di cult to use higher order derivatives resulting in an approximation that is limited in its accuracy and scope\nVariational bounding is a deterministic approach more global than Laplace s method We start by introducing an arbitrary function q x\nI\nZ x q x f x q x dx\nJensen s inequality for convex functions says that in the case of logarithm\nlog Z x q x g x dx Z x q x logg x dx\nif Z x q x dx\nCombining and gives the following bound on I\nI exp Z x q x log f x q x dx\nThis of course requires that f x is positive a condition that is satis ed for most but not all integrals in Bayesian inference We are free to choose q x to get the tightest bound which corresponds to maximizing the right hand side of Note that this is equivalent to minimizing the reversed KL divergence\nD q jj f Z x q x log q x f x dx\nover q subject to the constraint If q x is unconstrained the maximum is achieved at q x f x and the bound matches the original integral To achieve a simpli cation in the integral we must constrain q x in some way Typically q x is constrained to be Gaussian Hinton van Camp Barber Bishop Seeger but mixture distributions have also been suggested Jaakkola Jordan c Having a lower bound is useful since it provides a rm guarantee about the true value of the integral something none of the other methods can do However it tends to be very computational and is feasible in a limited number of cases Jensen s inequality takes advantage of the fact that log f x is often easy to integrate when f x is not But this is not always true For example in a mixture problem such as discussed in chapter f is a product of sums which does not simplify under a logarithm And in chapter the likelihood is a step function which reaches zero The step function could be softened into a sigmoid to make the Jensen bound well de ned but we could not expect a good t to result\nA less accurate but simpler way to obtain a variational bound is to bound the integrand and then integrate the bound\nf x g x for all x I Z x g x dx\nFigure shows an example Unlike the previous variational method this approach can be used in mixture problems This approach was used explicitly by Jaakkola Jordan a b and implicitly by Waterhouse et al Attias Ghahramani Beal under the name variational Bayes The implicit approach introduces hidden variables to de ne a bound Start by writing f x in terms of h x y\nf x\nZ y h x y dy\nApply the Jensen bound to get\nI Z x y h x y dydx\nexp Z x y q x y log h x y q x y dydx\nAt this point we constrain q x y to factor into separate functions for x and for y\nq x y qx x qy y\nwith no other constraints on functional form The qx and qy functions are iteratively optimized to maximize the value of the bound To see that this is equivalent to note that for any qy we can solve analytically for the optimal qx which is\nqx x g x R\nx g x dx\nwhere g x exp Z y qy y log h x y qy y dy\nWhen we substitute this qx the bound becomes\nI Z x g x dx\nRegardless of which approach we use implicit or explicit we can optimize the bound via the EM algorithm This is described in Minka c\nBesides variational bounds there are other integration techniques that are inspired by mean eld statistical physics Most of these are extensions of TAP such as the cavity method Opper Winther a Bethe approximation Yedidia and Plefka ex pansion Kappen Wiegerinck So far they have been applied to regular structures such as the Boltzmann machine and rarely to general probabilistic models where it is less obvious how to apply them An exception to this is the paper by Opper Winther c The algorithm they derive is new and accurate yet coincides with the framework proposed in this thesis It will be interesting to see what other algorithms come out of this mean eld line of research\nFor approximating an integral we thus nd ourselves in the following position We have methods that work well for simple functions in low dimensions quadrature and complex functions in high dimensions Monte Carlo We have methods that are simple and fast but inaccurate Laplace s method variational Bayes We have methods that apply in special cases Jensen bound TAP What is missing is a general and accurate deterministic method in high dimensions at least for simple functions That is what this thesis provides\nThe approach taken by this thesis continues the path started by the extended Kalman lter EKF The EKF is a sequential method developed for inference in dynamical systems with nonlinear dynamics It is not a general method for integration But there are several variations on the EKF Maybeck that have promise One is sequential Monte Carlo a family of nondeterministic techniques Liu Chen Carpenter et al Another is the assumed density lter a general deterministic method that approximately minimizes the KL divergence D f jj g between f x and its approximation g x as shown in gure The next chapter discusses the assumed density lter and its extension to Expectation Propagation"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 465,
                                "start": 446
                            }
                        ],
                        "text": "This thesis has developed a family of algorithms for approximate inference based on ex tending assumed density ltering ADF to use iterative re nement This extension removes all order dependence from ADF and increases its accuracy The family includes loopy be lief propagation in Bayesian networks and extends it to allow approximate messages for reduced computation as well as more elaborate messages for increased accuracy For in ference in the Bayes Point Machine it includes the algorithm of Opper Winther c and provides an alternative to the costly billiard algorithm\nThe accuracy of the Expectation Propagation family was demonstrated on a variety of examples with most emphasis on the Bayes Point Machine\nSection For the clutter problem in one dimension EP was in well behaved cases times more accurate than its nearest competitor Laplace s method both in estimating the posterior mean and the normalizing constant p D In other cases when the true posterior was strongly multimodal EP did not converge at all while Restricted EP and other deterministic methods lagged behind Monte Carlo The computational cost of EP is slightly higher than Laplace s method but much less than Monte Carlo\nSection For marginalizing the mixing weight in a mixture density of two Gaussians EP was again times more accurate than Laplace s method its nearest competitor With modi cations inspired by Cowell et al EP is also faster than Laplace s method In this problem the posterior is always unimodal in fact log convex which may explain why EP always converged\nSection On a toy dataset where the Bayes Point Machine is very di erent from the Support Vector Machine EP delivers high accuracy at a fraction of the cost of its competitor the billiard algorithm The accuracy of EP degrades when points are clustered together but even then it still beats the billiard algorithm with respect to cost On separable problems the posterior is unimodal and EP seems to always converge\nSection EP is also accurate in situations that the billiard algorithm cannot handle namely when there is label noise This was demonstrated on a toy dataset more de tailed experiments showing that EP achieves theoretical bounds are given by Winther since his algorithm is equivalent to EP\nSection On benchmark datasets with around points and - features EP achieves test set error rates consistent with the billiard algorithm Beating the SVM on out\nof datasets EP realizes in practice the theoretical gains expected with a Bayesian approach\nMany opportunities for future work are available both within the framework of EP as well as beyond it First how e ective is EP for other statistical models& For example is it useful for inference in coupled hidden Markov models sigmoid belief networks Barber Sollich and dynamic trees Storkey & Is EP e ective for Bayesian parameter estimation of classi cation models beyond linear classi ers e g hidden Markov models& Is any deterministic method e ective for nonparametric models such as Dirichlet processes Rasmussen &\nSecond can we anticipate how EP will perform& Can EP provide an estimate of its error& The experiments in this paper always used the ADF initialization Are the xed points of EP unique or does initialization matter& What causes EP to diverge& Can it be made to always converge& Can EP be made to give reasonable approximations to multimodal posteriors&\nCan EP be made to run faster especially for the Bayes Point Machine& This thesis compared EP to the original quadratic programming implementation of the Support Vector Machine But much faster specialized algorithms for the SVM are now available due to intense research Can we exploit special properties of the Bayes Point Machine to speed up EP& For example can we represent the A matrix in a sparse fashion& Can we identify the terms that need to be re ned& Having an error estimate for EP could facilitate this\nIs it optimal to minimize KL divergence at each step or should we use some other criterion& The modi ed update inspired by Cowell et al shows that we may obtain computational speedups with other criteria But improvements in accuracy may also be possible if we replace the greedy KL criterion with something that incorporates lookahead For example if we know the posterior has heavy tails and we are approximating it with a Gaussian then we may choose to use a Gaussian with in ated variance to better account for the tails\nThe entire di erence between EP and ADF is that EP makes better choices for the approximate terms !ti But both algorithms base their choices on the old posterior q x which is assumed to be accurate If the true posterior is multimodal then q x cannot possibly be accurate Could we propagate additional information about q x to use in choosing !ti&\nCan iterative re nement be applied to other ltering algorithms& For example some variants of ADF do not use the exponential family Cowell et al approximate a mixture posterior with a smaller mixture after processing each data point see also the generalized pseudo Bayes algorithms in Murphy Frey et al approximate the discrete posterior with an arbitrary tree structured distribution Conventional EP is not practical with these kinds of approximations because the equivalent terms !ti x qnew x q x do not simplify\nYedidia et al give a generalization of belief propagation that is di erent from the generalization a orded by EP Their algorithm propagates exact marginals and pairwise marginals which gives it high accuracy but also limits its practicality Can it be extended to allow approximate messages as in EP& Is there a common parent of their algorithm and EP&\nBayesian inference is a fertile area for developing numerical integration algorithms espe cially deterministic ones because of the rich problem structure and prior knowledge about the functions being integrated There is also relatively little research on it compared to\noptimization for example Many researchers are swayed enough by this imbalance to use inferior techniques such as maximum likelihood estimation because they only involve op timization As argued in this thesis it doesn t have to be that way And I anticipate that there are even better integration algorithms out there waiting for someone to discover them"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2125,
                                "start": 180
                            }
                        ],
                        "text": "Since the magnitude of w is irrelevant for classi cation, some authors have restricted w to the unit sphere in d dimensions, and have given w a uniform distribution on the sphere (Rujan, 1997). This distribution is nice because it is fair to all decision boundaries, but it is not very convenient to work with. A more general non-informative prior is an average over spheres. Let r = kwk be the magnitude of w. Given r, let w be uniformly distributed on the sphere of radius r. This prior is non-informative for any r. It is also non-informative if r is unknown with distribution p(r). For example, p(r) could be uniform from 0 to 1, allowing w to live in the unit ball instead of on the unit sphere. By choosing p(r) appropriately, we can also give w a spherical Gaussian distribution: p(w) N (0; I) (5.6) It is a property of the spherical Gaussian distribution that, conditional on any r, w is uniformly distributed on the sphere of radius r, so no particular decision boundary is favored by this prior. Given this model, the optimal way to classify a new data point x is to use the predictive distribution for y given the training data: p(yjx; D) = Zw p(yjx;w)p(wjD)dw (5.7) However, this requires solving an integral each time. A practical substitute is to use a single value ofw which approximates the predictive distribution as well as possible. Watkin (1993) and Rujan (1997) have de ned the `Bayes point' as the single best w. However, this point is di cult to nd. Thus, following Rujan (1997), we use the posterior mean for w, E[wjD]. Following convention, we will be sloppy and also call this the `Bayes point'. Our strategy will be to make a Gaussian approximation to the posterior and use its mean as the estimated Bayes point. Of course, if we really wanted to, we could also use EP to solve the integral (5.7) for each test point. The normalizing constant of the posterior is also useful because, as an estimate of p(D), it allows us to choose among di erent models (see section 5.7). 5.2 Training via ADF Start with the ADF updates. ADF was previously applied to the Bayes Point Machine by Csato et al. (1999). Divide the joint distribution p(D;w) into n terms, one for each data point."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1664,
                                "start": 1645
                            }
                        ],
                        "text": "One of the major obstacles to using Bayesian methods for pattern recognition has been its computational expense This thesis presents an approximation technique that can per form Bayesian inference faster and more accurately than previously possible This method Expectation Propagation uni es and generalizes two previous techniques assumed density ltering an extension of the Kalman lter and loopy belief propagation an ex tension of belief propagation in Bayesian networks The uni cation shows how both of these algorithms can be viewed as approximating the true posterior distribution with a simpler distribution which is close in the sense of KL divergence Expectation Propagation exploits the best of both algorithms the generality of assumed density ltering and the accuracy of loopy belief propagation\nLoopy belief propagation because it propagates exact belief states is useful for lim ited types of belief networks such as purely discrete networks Expectation Propagation approximates the belief states with expectations such as means and variances giving it much wider scope Expectation Propagation also extends belief propagation in the op posite direction propagating richer belief states which incorporate correlations between variables\nThis framework is demonstrated in a variety of statistical models using synthetic and real world data On Gaussian mixture problems Expectation Propagation is found for the same amount of computation to be convincingly better than rival approximation techniques Monte Carlo Laplace s method and variational Bayes For pattern recognition Expecta tion Propagation provides an algorithm for training Bayes Point Machine classi ers that is faster and more accurate than any previously known The resulting classi ers outperform Support Vector Machines on several standard datasets in addition to having a comparable training time Expectation Propagation can also be used to choose an appropriate feature set for classi cation via Bayesian model selection\nThesis Supervisor Rosalind Picard Title Associate Professor of Media Arts and Sciences"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 179
                            }
                        ],
                        "text": "Since the magnitude of w is irrelevant for classi cation, some authors have restricted w to the unit sphere in d dimensions, and have given w a uniform distribution on the sphere (Rujan, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 491,
                                "start": 472
                            }
                        ],
                        "text": "Introduction\nMethods of numerical integration\nExpectation Propagation\nAssumed density ltering Expectation Propagation\nThe clutter problem Results and comparisons\nAnother example Mixture weights ADF EP A simpler method Results and comparisons\nDisconnected approximations of belief networks\nBelief propagation Extensions to belief propagation\nGrouping terms Partially disconnected approximations Combining both extensions Future work\nClassi cation using the Bayes Point\nThe Bayes Point Machine Training via ADF Training via EP EP with kernels Results on synthetic data Results on real data Model selection A better billiard algorithm\nSummary and future work"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 0
                            }
                        ],
                        "text": "Rujan (1997) recovers from this by restarting the billiard at its initial point, with a random velocity. Unfortunately, this introduces severe bias in the estimate, by overcounting the initial point. Herbrich et al. (1999) have a better solution: leave the ball where it is, but choose a new random velocity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 101
                            }
                        ],
                        "text": "Classi cation using the Bayes Point\nThis chapter applies Expectation Propagation to inference in the Bayes Point Machine The Bayes Point Machine is a Bayesian approach to linear classi cation that competes with the popular but non Bayesian Support Vector Machine SVM Bayesian averaging of linear classi ers has been proven both theoretically and empirically optimal in terms of generalization performance Watkin Bouten et al Buhot et al But an e cient algorithm has remained elusive The Bayes Point Machine approximates the Bayesian average by choosing one average classi er the Bayes Point Watkin Rujan Herbrich et al Computing the Bayes Point is a simpler but still very di cult task\nThis chapter shows that Expectation Propagation using a full covariance Gaussian ap proximation to the posterior provides an accurate estimate of the Bayes Point an ap proximation to the full Bayesian average The algorithm turns out to be identical to what Opper Winther c derived by statistical physics methods However EP uses a dif ferent optimization scheme that is faster and does not require a stepsize parameter EP also provides an estimate of the evidence p D which is useful for feature selection but not provided by Opper Winther\nThe Bayes Point Machine\nThe Bayes Point Machine BPM is a Bayesian approach to linear classi cation A linear classi er classi es a point x according to y sign wTx for some parameter vector w the two classes are y Given a training set D f x y xn yn g the likelihood for w can be written\np Djw Y i p yijxi w Y i ) yiw Txi\n) z\nif z if z\nThis is a slight abuse of notation since p Djw is only a distribution for y not x This likelihood is if w is a perfect separator and otherwise A simple way to achieve linear separation is to progressively enlarge the set of features e g by computing squares and third powers until the data is separable in the new feature space This has the e ect of producing a nonlinear decision boundary in the original measurement space Feature expansion can be implemented e ciently using the kernel trick where we rewrite the algorithm in terms\nx1\nx2\nx1\nx2\na b\nFigure Two di erent classi cation data sets with label information removed The Bayes Point Machine assumes that without labels we cannot infer where the boundary lies In b one might be inclined to think that the horizontal axis determines the decision But the horizontal axis could easily be something irrelevant like the time of day the datum was collected Only domain knowledge can determine the validity of the assumption\nof inner products and perform the feature expansion implicitly via the inner product This technique will be described more fully later\nBecause it is conditional on xi this model assumes that the distribution of the x s is unrelated to the true decision boundary That is if we were given the x s without any labels we would have no information about where the boundary lies The validity of this assumption must come from domain knowledge it cannot be determined from the data itself see gure The Support Vector Machine SVM for example does not seem to make this assumption Tong Koller show that the SVM follows from assuming that the x s follow a Gaussian mixture distribution in each class In addition some workers have used the SVM with unlabeled data Bennett Demiriz while the BPM by design cannot The advantage of assuming independence in the BPM is that we avoid stronger assumptions about the nature of the dependence and thus obtain a more general algorithm Experiments show it is quite robust section\nA re nement to the basic model is to admit the possibility of errors in labeling or measurement A labeling error rate of can be modeled using Opper Winther b\np yjx w ) ywTx ) ywTx ) ywTx\nUnder this model the likelihood p Djw for a given w will be r n r where r is the number of errors on the training set Only the number of errors is important not where they are This way of modeling errors can automatically reject outliers because it doesn t care how far an error is from the boundary Other approaches based on adding slack to the boundary only allow errors near the boundary and are sensitive to outliers These approaches can be simulated by using a smooth likelihood function such as\np yjx w ywTx where is the cumulative distribution function for a Gaussian The tails of this function fall like exp x so it provides quadratic slack The logistic function could also be\nused it falls like exp x providing linear slack By changing ) to one of these smooth functions the labeling error model can be combined with slack with no computational di culties However this chapter focuses on without slack\nTo complete our Bayesian model we need to specify a prior on w Since the magnitude of w is irrelevant for classi cation some authors have restricted w to the unit sphere in d dimensions and have given w a uniform distribution on the sphere Rujan This distribution is nice because it is fair to all decision boundaries but it is not very convenient to work with A more general non informative prior is an average over spheres Let r kwk be the magnitude of w Given r let w be uniformly distributed on the sphere of radius r This prior is non informative for any r It is also non informative if r is unknown with distribution p r For example p r could be uniform from to allowing w to live in the unit ball instead of on the unit sphere By choosing p r appropriately we can also give w a spherical Gaussian distribution\np w N I\nIt is a property of the spherical Gaussian distribution that conditional on any r w is uniformly distributed on the sphere of radius r so no particular decision boundary is favored by this prior\nGiven this model the optimal way to classify a new data point x is to use the predictive distribution for y given the training data\np yjx D Z w p yjx w p wjD dw\nHowever this requires solving an integral each time A practical substitute is to use a single value ofw which approximates the predictive distribution as well as possible Watkin and Rujan have de ned the Bayes point as the single best w However this point is di cult to nd Thus following Rujan we use the posterior mean for w E wjD Following convention we will be sloppy and also call this the Bayes point Our strategy will be to make a Gaussian approximation to the posterior and use its mean as the estimated Bayes point Of course if we really wanted to we could also use EP to solve the integral for each test point The normalizing constant of the posterior is also useful because as an estimate of p D it allows us to choose among di erent models see section\nTraining via ADF\nStart with the ADF updates ADF was previously applied to the Bayes Point Machine by Csato et al Divide the joint distribution p D w into n terms one for each data point Since y and x always appear multiplied together the formulas will drop y and assume that xi is already scaled by yi Let the approximate posterior have the form\nq w N mw Vw\nFrom minimizing the KL divergence we get the expectation constraints\nEqnew w E p w\nEqnew ww T E p ww T\nTo compute these expectations use the following relations obtained from integration by parts\nZ mw Vw\nZ w t w q w dw\nE p w mw Vwrm logZ mw Vw E p ww\nT E p w E p w T Vw Vw rmrTm rv logZ mw Vw Vw These hold for any t w For the Bayes Point Machine we have combining yx into x\nt w ) wTx z Z z N z dz\nz mTwxp xTVwx\nZ mw Vw z\np xTVwx\nN z z\nrm logZ mw Vw x rv logZ mw Vw mTwx\nxTVwx xxT\nrmrTm rv logZ mw Vw xxT mTwx\nxTVwx xxT\nmw Vw x\nTx\nxTVwx xxT\nThe ADF algorithm is thus\nInitialize mw Vw I the prior Initialize s the scale factor\nFor each data point xi update mw Vw s according to\nmneww mw Vw ixi\nVneww Vw Vwxi ix\nT i m new w\nxTi Vwxi\nVwxi\nT\nsnew s Zi mw Vw\nThe nal mw is the estimate of w used for classi cation Note that this algorithm does not require matrix inversion It is the same algorithm obtained by Csato et al except they expressed it in terms of kernel inner products which makes it more complex\nTraining via EP\nNow we turn the ADF algorithm into an EP algorithm By dividing two consecutive Gaus sian posteriors we nd that the term approximations are also Gaussian parameterized by mi and Vi\n!t w Z qnew w\nq w\nZ\nN mi mw Vi Vw N w mi Vi\nwhere V i V new w\nV w mi Vi V new w\nmneww ViV w mw mw Vi Vw V w m new w mw\nTo simplify this combine it with the ADF updates to get mi Vi directly from mw Vw\nVi\nix T i m new w xTi Vwxi xix T i\nVw\nmi mw Vi Vw ixi\nThe matrix ixTi m new w\nxT i Vwxi\nxix T i has one nonzero eigenvalue which means Vi will have one nite\neigenvalue in the direction of xi This makes sense because term i only constrains the projection of w along xi This special structure allows us to represent Vi with a scalar vi\nV i v i xix T i\nxTi Vixi vi\nFrom we know that\nxTi Vixi xTi Vwxi\nixTi m new w\nxTi Vwxi\nwhich means the update for vi is\nvi x T i Vwxi\nix T i m new w\nAnother consequence of this special structure is that instead of the full vector mi we only need the projection mTi xi which can be stored as a scalar mi\nNow we can write an e cient EP algorithm\nExcept for the prior the term approximations have the form\n!ti w si exp vi wTxi mi\nInitialize them to\nvi mi\nsi\nmneww V new w I the prior\nUntil all mi vi si converge changes are less than\nloop i n\na Remove !ti from the posterior to get an old posterior\nVw V new w v i xixTi Vneww V new w xi vi xTi Vneww xi Vneww xi T mw m new w VwV i m new w mi\nmneww Vwxi v i x T i m new w mi\nThese expressions involving Vw can be computed e ciently\nVwxi V new w xi\nvi\nvi xTi Vneww xi\nxTi Vwxi\nxTi V new w xi\nvi\nb Recompute mneww V new w Zi from mw Vw as in ADF c Update !ti\nvi x T i Vwxi\nixTi m new w\nmi x T i mw vi x T i Vwxi i\nsi Zi jVi Vwj\njVij exp\nmi mw T Vi Vw mi mw\nZi q v i x T i Vwxi exp xTi Vwxi\nxTi m new w\ni\nCompute the normalizing constant\nB mneww T Vneww\nmneww X i m i vi\np D jVneww j exp B nY i si\nThis algorithm processes each data point in O d time Assuming the number of iterations is constant which seems to be true in practice computing the Bayes point therefore takes O nd time Computing the normalizing constant at the end requires O d time\nEP with kernels\nTo use the kernel trick we need to rewrite EP in terms of inner products Following the notation of Opper Winther c de ne\ni x T i V ni wxi V ni w is the Vw when term i is left out\nCij x T i xj\n* diag v vn hi x T i m new w\nh ni i x T i m ni w\nFrom the de nition of qnew w as the product of approximate terms !ti w we know that\nVneww\nI X i xix T i vi\nI X* XT\nmneww V new w X j mjxj vj\nxTi m new w\nX j xTi V new w xj mj vj\nFrom the matrix inversion lemma we therefore have\nC * * * XTVneww X* XTVneww X * * C * *\nC *\nIn this way we can compute xTi V new w xj for any i j using only C and * The EP algorithm becomes\nInitialize vi mi si Initialize hi i Cii\nUntil all mi vi si converge\nloop i n\na Remove !ti from the posterior to get an old posterior\nh ni i hi iv i hi mi\nb Recompute part of the new posterior as in ADF\nz h ni ip i\nZi z i\np i\nN z z\nhi h ni i i i\nc Set\nvi i\nihi\nmi h ni i vi i i hi vi i\nsi Zi q v i i exp\ni i hi\nd Now that * is updated nish recomputing the new posterior\nA C *\nFor all i\nhi X j Aij mj vj\nfrom\ni\nAii vi\nfrom\nCompute the normalizing constant\nB X ij Aij mimj vivj\nX i m i vi\np D j*j\njC *j exp B\nnY i si\nThe determinant expression in follows from\njVneww j I X* XT I XTX*\nI C* j*jjC *j\nIn step it would appear that we need to invert a matrix taking O n time for each data point However since only one vi changes each time A can be updated incrementally in O n time Initialize A C and then update with\nAnew C * +*\nA aia T i\naii\nwhere\nvnewi voldi\nAssuming a constant number of iterations the algorithm thus runs in O n time plus the time to compute the inner product matrix C This is a great improvement over O nd if the dimensionality is very large e g if the feature set is arti cially expanded\nTo show the equivalence with Opper Winther s algorithm we make the following observations\nAt convergence will hold for all i so that X j mjxj vj X j hjxj vj X j jxj\nmneww X j mjxj vj\nI X\nj\nxjx T j\nvj\nAmneww X\nj\njxj\nmneww X j jxj\nhi X j j x T i xj\nX j Cij j\nThis is the equation Opper Winther use instead of\nThe update for i can be written\ni\nvi v i C * ii vi vi v i h C * i ii vi h C *\ni ii\nC * ii vi\nThis is the update Opper Winther use instead of\nEP computes a normalizing constant for the posterior while Opper Winther do not\nAll other updates are identical to those in Opper Winther c though carried out in a di erent order Reordering the updates does not matter as long as both algorithms converge\nThe input to the algorithm is simply the matrix C which can be computed using an arbitrary inner product function C xi xj instead of x T i xj However in that case we need to keep yi and xi separate Cij yiyjC xi xj\nUsing a nonlinear inner product function is an e cient way to use an expanded feature space since we don t have to represent each expanded data point We only have to compute the inner product between two expanded data points which is a scalar function of the original data\nThe output of the algorithm is the i which implicitly represent m new w through\nWith these we classify a new data point according to\nf x sign xTmneww sign X i iyiC x xi\nResults on synthetic data\nFigure a demonstrates the Bayes point classi er vs the SVM classi er on training points Besides the two dimensions shown here each point had a third dimension set at\nThis provides a bias coe cient w so that the decision boundary doesn t have to pass through Each classi er is set to zero label noise and zero slack The Bayes point classi er approximates a vote between all linear separators ranging from an angle of to The Bayes point chooses an angle in the middle of this range SVM chooses the decision boundary to maximize margin the distance to the nearest data point This makes it ignore the topmost data point In fact the Bayes point and SVM would coincide if that point were removed Adding the point reduces the set of linear separators and Bayesian inference must take this into account\nFigure plots the situation in parameter space For viewing convenience we restrictw to the unit sphere The exact Bayes point was computed by likelihood weighted sampling i e sampling a random w on the sphere and discarding those which are not separators EP provides an accurate estimate of the posterior mean mw and posterior covariance Vw Compare\nExact Vw\nEP Vw\nFigure b plots cost vs error for EP versus three other algorithms for estimating the Bayes point the billiard algorithm of Herbrich et al the TAP algorithm of Opper Winther c and the mean eld MF algorithm of Opper Winther c The error is measured by Euclidean distance to the exact solution found by importance sampling The error in using the SVM solution is also plotted for reference Its unusually long running time is due to Matlab s quadprog solver TAP and MF were slower to converge than EP even with a large initial step size of As expected EP and TAP converge to the same solution\nThe billiard algorithm is a Monte Carlo method that bounces a ball inside the region de ned by hyperplane constraints It must be initialized with a linear separator and the SVM was used for that purpose Since there are many other ways one could initialize the billiard which may be much cheaper the initialization step was not counted against the billiard s FLOP count otherwise the billiard curve would be right of the SVM point The error axis must also be interpreted carefully While it is tempting to use the lower envelope of the curve as the measure of error it is actually more accurate to use the upper envelope since this is all that the algorithm can consistently achieve as samples accumulate Nevertheless it is clear that EP is much faster and more accurate\nLaplace s method and variational Bayes do not work at all on this problem Laplace fails because the derivatives of the likelihood are not informative they are either zero or in nity Variational Bayes fails for because no Gaussian can lower bound the likelihood Gaussians never reach zero Even with a Gaussian bound must be quite narrow so we can t expect competitive performance\nHerbrich Graepel point out that the SVM is sensitive to scaling an input vector i e if we replace x by x then the solution will change They argue theoretically and empirically that data vectors should therefore be normalized to unit length before SVM training This is quite a shock since no mention of this was made in the original SVM papers If the data in gure including the bias dimension is normalized before training then the SVM solution tilts slightly toward the BPM solution supporting Herbrich Graepel s suggestion The Bayes Point Machine by contrast does not require any normalization because the data likelihood is correctly invariant to scaling an input vector The solution found by EP is also invariant\nSVM Bayes\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u22124\n10 \u22123\n10 \u22122\n10 \u22121\n10 0\nEP\nBilliard\nSVM\nMF\nTAP\nFLOPS\nE rr\nor\nFigure left Bayes point machine vs Support Vector Machine on a simple data set The Bayes point more closely approximates a vote between all linear separators of the data right Cost vs error in estimating the posterior mean ADF is the rst x on the EP curve\nFigure left The same problem viewed in parameter space the unit sphere Each data point imposes a linear constraint giving an odd shaped region on the sphere The Bayes point is the centroid of the region The EP estimate is indistinguishable from the exact Bayes point on this plot right The Gaussian posterior approximation obtained by EP rendered as a one standard deviation isoprobability ellipsoid\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u22122\n10 \u22121\n10 0\nEP\nBilliard\nSVM\nMF\nTAP\nFLOPS\nE rr\nor\nFigure Cost vs error for the point problem with one point replicated times\nThe linear classi cation problem is special in that some points can have large in uence on the solution while adjacent points have zero in uence This is because the constraints imposed by the latter points may be redundant given the constraints already imposed by other points This property allows the support vector machine to focus on a small number of points the support vectors when nding its solution Unfortunately this property can cause havoc with EP EP uses Gaussians to smooth out the hard constraints and cannot always recognize when a point is redundant and should be ignored The result is that clusters of points can degrade the EP estimate Figure shows what happens to gure b when the point at is replicated times As expected the cluster of points counts more than it should making the EP boundary move slightly away from it The accuracy of EP TAP and MF degrades signi cantly while SVM and Billiard are unchanged On the bright side the error cannot be made arbitrarily high using more than replications or replicating the other points does not degrade the accuracy any further One work around for this behavior would be to reduce the dataset in advance e g to just the support vectors This idea has not been tested yet\nFigure compares the EP solution to the exact posterior mean when noisy labels are allowed Theoretically this integral is harder since we have to consider the entire parameter space not just perfect separators EP can handle it with no additional cost The solution comes out vertical because it is a compromise between the small set of perfect separators at and the larger set of boundaries between and which have one error There is also a set of boundaries past which also have one error On this dataset a similar result can be achieved with the SVM if we set the slack parameter C though this would not necessarily be true on another dataset Winther has given extensive evaluations of EP with and on synthetic datasets showing that it achieves the theoretical performance of Bayesian averaging Those experiments are not repeated here\nFigure demonstrates EP with a nonlinear kernel contrasting it to the SVM solution\n\u22121 \u22120.5 0 0.5 1 1.5 2 \u22121\n\u22120.5\n0\n0.5\n1\n1.5\n2\nExactEP\nFigure The EP solution has good agreement with the exact posterior mean when noisy labels are allowed\nwith the same kernel The kernel was Gaussian\nC xi xj exp\nxi xj T xi xj\nwith width parameter and The feature expansion equivalent to this kernel has an in nite number of features The SVM is quite sensitive to the choice of as well as the idiosyncrasies of the dataset This is related to the sparsity of the SVM solution when the boundary depends on only a few data points i e a few Gaussian kernels small changes in those kernels have a larger e ect on the boundary Similar results obtain if we use a polynomial kernel\nC xi xj x T i xj\np\nFor large p the boundaries are almost identical to those for a wide Gaussian kernel\nBPM SVM\nBPM SVM\nnarrow Gaussian kernel wide Gaussian kernel\nFigure Classi cation boundaries resulting from Support Vector Machine training vs Bayes Point Machine training with EP Both used a Gaussian kernel with the same width parameter left Narrow width The SVM tends to put extra bumps and kinks in the boundary right Wider width The SVM chooses an unusual solution in order to maximize margin in the expanded space The BPM boundary is non sparse all i but smoother It is hardly a ected by changing the kernel width Billiard gives results similar to EP\nResults on real data\nFor higher dimensional problems it is more di cult to compute the exact Bayes point and make cost vs accuracy comparisons So instead we ll measure cost vs test performance on benchmark problems\nFigure compares EP Billiard and SVM on discriminating handwritten digit from Each data point xi is an binary image dimensions The dataset was randomly split times into a small training set of points and a test set of points All algorithms were linear and set for zero noise Billiard was run for iterations which is far more computation than EP or SVM used Nevertheless EP is best\nFigures and show the same type of comparison on four datasets from the UCI repository Blake Merz Each dataset was randomly split times into a training set and test set in the ratio , , In each trial the features were normalized to have zero mean and unit variance in the training set The classi ers used zero label noise and a Gaussian kernel with Billiard was run for iterations The thyroid dataset was made into a binary classi cation problem by merging the di erent classes into normal vs abnormal Except for sonar EP and Billiard beat the SVM a majority of the time and in all cases EP performed similarly to Billiard However the running time for Billiard is signi cantly higher since it must be initialized at the SVM solution Figure shows cost vs test error curves on some typical runs The SVM using quadprog is particularly slow on thyroid The unusual success of the SVM on sonar was also reported by Herbrich et al and may be related to the di erent assumptions made by the SVM see section\nTo give an idea of the actual running time in Matlab gure plots the training time vs training set size for trials As expected the time scales as n Extrapolating from this it would take an hour for data points and weeks for data points Finding a way to speed up EP similar to the way that quadratic programming can be sped up for the SVM will be essential for large data sets\n30 40 50 60 70 80 35\n40\n45\n50\n55\n60\n65\n70\nSVM\nE P\nTest errors\n30 40 50 60 70 35\n40\n45\n50\n55\n60\n65\n70\nBilliard\nE P\nTest errors\nFigure Test error of SVM vs EP left and Billiard vs EP right on digit classi cation over random train'test splits Each point is test error for SVM'Billiard test error for EP Points under the line correspond to trials where EP had a lower test error EP beat SVM times and beat Billiard times despite being the fastest of all three algorithms of this dataset\nHeart features training points\n0.15 0.2 0.25 0.3\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\n0.26\n0.28\n0.3\n0.32\nSVM\nE P\nTest errors\n0.15 0.2 0.25 0.3\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\n0.26\n0.28\n0.3\n0.32\nBilliard\nE P\nTest errors\nThyroid features training points\n\u22120.05 0 0.05 0.1 0.15 \u22120.05\n0\n0.05\n0.1\n0.15\nSVM\nE P\nTest errors\n\u22120.05 0 0.05 0.1 0.15 \u22120.05\n0\n0.05\n0.1\n0.15\nBilliard\nE P\nTest errors\nFigure Test error rates over train'test splits Each point is test error for SVM'Billiard test error for EP Points under the line correspond to trials where EP had a lower test error For running times see gure\nIonosphere features training points\n0.05 0.1 0.15 0.2\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\nSVM\nE P\nTest errors\n0.05 0.1 0.15 0.2 0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\nBilliard\nE P\nTest errors\nSonar features training points\n0.05 0.1 0.15 0.2\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\nSVM\nE P\nTest errors\n0.05 0.1 0.15 0.2\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\nBilliard\nE P\nTest errors\nFigure Test error rates over train'test splits Each point is test error for SVM'Billiard test error for EP for one trial Points under the line correspond to tri als where EP had a lower test error For running times see gure\nHeart Thyroid\n10 7\n10 8\n10 9\n0.21\n0.22\n0.23\n0.24\n0.25\n0.26\n0.27\n0.28\n0.29\n0.3\nEP\nBilliard\nSVM\nFLOPS\nT es\nt e rr\nor\n10 7\n10 8\n10 9\n10 10\n0\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\nFLOPS\nT es\nt e rr\nor\nSVM\nEP Billiard\nIonosphere Sonar\n10 7\n10 8\n10 9\n10 10\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\nFLOPS\nT es\nt e rr\nor\nSVM\nEP\nBilliard\n10 6\n10 7\n10 8\n10 9\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\n0.26\n0.28\n0.3\nFLOPS\nT es\nt e rr\nor\nSVM EP\nBilliard\nFigure Cost vs test error on a typical trial for each dataset\n0 200 400 600 800 0\n5\n10\n15\n20\n25\nTraining set size\nT ra\nin in\ng tim\ne (m\nin s)\nFigure Actual training time in Matlab for EP with kernels for di erent dataset sizes It nearly perfectly follows n growth The time to compute the inner product matrix is not included\nModel selection\nThis section reports results on Bayesian model selection using the estimated evidence p D This is a unique feature of EP because the billiard algorithm cannot provide an estimate of p D By maximizing the evidence we can select the appropriate feature set feature kernel or noise parameter For background on Bayesian model selection see MacKay Kass Raftery Minka a A popular approach to model selection for the SVM is to minimize R\nM where R is the radius of the smallest ball containing the training\nset measured in the mapped feature space and M is the margin Cristianini et al Another approach is to minimize the span bound given by thresholding the s Chapelle Vapnik Chapelle et al\nS X\nsupport vectors i\n) i h C sv i ii\nThese three criteria evidence margin and span can lead to quite di erent results Figure shows a synthetic training set classi ed according to distance from the origin i e the true decision boundary is a circle Three di erent decision boundaries result from training an SVM with three di erent kernels the decision boundaries from EP are nearly identical All of these boundaries achieve zero error so we need to invoke some other rule besides training error to select among them Over all Gaussian kernels the margin criterion is minimized by taking This produces a decision boundary with spurious kinks and bumps The span bound is minimized by an even narrower kernel where the bound is By contrast the best Gaussian kernel according to evidence has providing a much smoother and more realistic boundary The quadratic kernel which is the closest to the true boundary has even greater evidence yet less margin\nIn the noise free case the Bayesian evidence p D has a natural interpretation It is the fraction of perfect separators out of all representable classi ers If a particular set of features has a large percentage of perfect separators then we intuitively should have more faith in that feature set This is what Bayesian model selection does and in choosing the Bayes point we follow the same basic argument Maximizing the margin does not necessarily behave this way\nThe next example repeats the feature selection experiment of Weston et al Chapelle et al Synthetic data with six features was created by rst sampling y with equal probability and then setting\nx N y x N y x N y x N x N x N\nWith probability features x -x were swapped with features x -x Thus all six features are relevant to some degree To these six relevant features are appended irrelevant features with distribution N The test is to see whether we can reject the irrelevant features In Chapelle et al the algorithm was forced to keep only two features Here we use a more rigorous test features are added one by one starting with the relevant ones\nGaussian Gaussian\nKernel R M span log p D\nquadratic\nQuadratic\nFigure A dataset classi ed with three di erent kernels The margin criterion R M prefers the solution while the Bayesian evidence p D prefers the quadratic solution The span bound prefers a Gaussian with tiny not shown The true boundary is a circle\n0 5 10 15 20 10\n15\n20\n25\n30 35 M ar gi n bo un d\nNumber of features 0 5 10 15 20\n0\n1\n2\n3\n4\n5\n6\n7\nS pa\nn bo\nun d\nNumber of features\n0 5 10 15 20 \u221215\n\u221214\n\u221213\n\u221212\n\u221211\n\u221210\n\u22129\n\u22128\n\u22127\nE P\ne vi\nde nc\ne\nNumber of features\nFigure Feature selection curves for the margin bound span bound and Bayesian evidence The Bayesian evidence has a clear peak at six the correct answer The other criteria which are to be minimized do not perform as well The margin bound has only a local minimum at six and the span bound only a local minimum at ve\nand the algorithm must decide when to stop Figure shows the curves for the margin bound span bound and Bayesian evidence Both the SVM and BPM used a linear kernel with zero slack The Bayesian evidence is clearly a better measure of relevance\nFigure a Conventional billiard algorithms allow the ball to escape They project the collision point onto the surface of the sphere but preserve the rebound velocity dashed line b The new algorithm works inside the sphere using the sphere s surface as an additional wall\nA better billiard algorithm\nA major drawback of current billiard algorithms is that they do not really operate on the sphere The billiard ball always follows a straight line trajectory until it hits a wall at which point it is projected back onto the sphere gure a Unfortunately this means the ball can sometimes leave the sphere without ever hitting a wall On the point problem in gure this happens on , of the bounces Rujan recovers from this by restarting the billiard at its initial point with a random velocity Unfortunately this introduces severe bias in the estimate by overcounting the initial point Herbrich et al have a better solution leave the ball where it is but choose a new random velocity This has less bias but doesn t resemble a billiard anymore\nThe problem of escaping billiard balls can be avoided entirely if we simply rede ne the pool Remember that the unit sphere was an arbitrary choice we can use any prior distribution that assigns equal probability to all w vectors of a given length So let s use the inside of the unit sphere as shown in gure b The sphere s surface is an additional wall that prevents escape The new algorithm is\nDetermine the next collision From position w and velocity v compute the ight time to each wall and take the minimum The distance from wall xi is\ndi wTxiq xTi xi\nand the velocity normal to xi is\nvi vTxiq xTi xi\nso the ight time is\ni\ndivi if vi otherwise\nThe ight time to the surface of the sphere satis es\nw v T w v\nq wTv vTv wTw wTv\nvTv\nwhich is always positive and nite\nUpdate the position of the ball the total distance traveled s and the center of mass estimate m\nwnew w v min\nz kwnew wk mnew s\ns z m\nz\ns z\nwnew w\nsnew s z\nUpdate the velocity If xi was hit\nvnew v vi xiq xTi xi\nIf the surface of the sphere was hit\nvnew v wnew wnew Tv\nThe length of v is unchanged by these updates so if we initialize vTv it will stay that way throughout the algorithm\nThe algorithm can also be made use a kernel inner product as in Herbrich et al With this algorithm we can run one billiard trajectory without ever restarting However that is not a good idea because the pool is not perfectly ergodic By periodically randomiz ing the velocity of the ball we can achieve a more ergodic sampling Periodic randomization is important in all Markov chain Monte Carlo schemes including Gibbs sampling For the billiard randomization at every bounces seems to work well\nFigure compares the three algorithms on the point problem of section Each was run for iterations using a comparable number of ops Because of its bias Rujan s algorithm is never more accurate than in Euclidean distance to the true value Herbrich s algorithm does better but also seems to level o at The new algorithm with randomization every bounces converges nicely These characteristics are typical and hold across many di erent runs on this dataset\n10 2\n10 4\n10 6\n10 \u22123\n10 \u22122\n10 \u22121\n10 0\nRujan\nHerbrich\nNew\nFLOPS\nE rr\nor\nFigure Cost vs error of conventional billiard algorithms vs the new algorithm"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Rujan (1997) recovers from this by restarting the billiard at its initial point, with a random velocity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6421,
                                "start": 6402
                            }
                        ],
                        "text": "The dominant computational task in Bayesian inference is numerical integration New methods for fast and accurate integration are therefore very important and can have great impact This dissertation presents a new deterministic approximation framework Expecta tion Propagation which achieves higher accuracy than existing integration algorithms with similar computational cost\nThe general scenario of Bayesian inference is that there is some observed data and some unobserved quantity of interest Inferences about the unknown x are based on its posterior distribution given the observed D\np xjD p x D p D\np x D R\nx p x D dx\nFor example we may want to know the posterior mean and variance of the unknown which are integrals over the posterior\nE xjD Z x xp xjD dx\nR x xp x D dxR x p x D dx\nE x jD Z x x p xjD dx\nR x x\np x D dxR x p x D dx\nvar xjD E x jD E xjD\nIn real situations there are many unknowns not just the one we are interested in In Bayesian inference these must be marginalized out of the joint distribution which involves yet more integrals\np xjD R y z p x y z D R x y z p x y z D\nThus numerical integration goes hand in hand with practical Bayesian inference Numerical integration algorithms can be principally divided into deterministic vs non deterministic methods Deterministic methods try to approximate the integrand with some thing whose integral is known exactly They work from properties of the integrand like its maxima and curvature Nondeterministic methods sample the integrand at random points to get a stochastic estimate of the integral This approach is more general since it works for almost any integrand but it also requires a great deal more computation than deterministic approximation\nThe proposed method Expectation Propagation is a deterministic approximation method It is an extension to assumed density ltering ADF Maybeck Lauritzen Bernardo Giron Stephens Boyen Koller b Barber Sollich Opper Winther Frey et al a one pass sequential method for comput ing an approximate posterior distribution In ADF observations are processed one by one updating the posterior distribution which is then approximated before processing the next observation For example we might replace the exact one step posterior with a Gaussian having the same mean and same variance Maybeck Lauritzen Barber Sol lich Opper Winther Or we might replace a posterior over many variables with one that renders the variables independent Boyen Koller b or approximates them as Markovian Frey et al In each case the approximate posterior is found by minimizing KL divergence which amounts to preserving a speci c set of posterior expecta tions Note that the statistical model in question need not be a time series model and the processing order of observations need not correspond with time of arrival The weakness of ADF stems from its sequential nature information that is discarded early on may turn out to be important later Even if ADF is augmented with a backward pass Boyen Koller a this information cannot be recovered ADF is also sensitive to observation ordering which is undesirable in a batch context\nExpectation Propagation EP extends ADF to incorporate iterative re nement of the approximations by making additional passes The information from later observations re nes the choices made earlier so that the most important information is retained When the re nement converges the resulting posterior is independent of ordering and more accurate Iterative re nement has previously been used in conjunction with sampling Koller et al and extended Kalman ltering Shachter Expectation Propagation di ers by applying this idea to the deterministic approximation of general distributions not just Gaussian distributions as in Shachter EP is more expensive than ADF by only a constant factor the number of re nement passes typically or As shown in chapter the accuracy of EP is signi cantly better than ADF as well as rival approximation methods Monte Carlo Laplace s method and variational Bayes\nThinking in this framework has a number of bene ts For example in belief networks with loops it is known that approximate marginal distributions can be obtained by iterating the belief propagation recursions a process known as loopy belief propagation Frey MacKay Murphy et al As described in chapter it turns out that this heuristic procedure is a special case of Expectation Propagation where the approximate posterior is a completely disconnected network with no other constraints on functional form In other words loopy belief propagation is a direct generalization of the ADF algorithm of Boyen Koller b\nExpectation Propagation can therefore be seen as a way of generalizing loopy belief propagation to less restrictive approximations that are not completely disconnected and to useful constraints on functional form such as multivariate Gaussian Partially disconnected approximations are useful for improving accuracy just as in variational methods Jordan et al while constraints on functional form are useful for reducing computation Instead of propagating exact belief states which may be intractable EP only needs to propagate expectations relevant to the chosen approximating distribution e g means and variances Hence the name Expectation Propagation\nExpectation Propagation also has connections to statistical physics techniques Yedidia et al have shown that belief propagation tries to minimize an approximate free en ergy on discrete networks This is known as the TAP approach in statistical physics Opper\nWinther a have generalized the TAP approach to networks with mixed continuous and discrete nodes via the cavity method and applied it to Gaussian process classi ers Opper Winther c Chapter shows that Opper Winther s algorithm which has excellent performance is a special case of Expectation Propagation where the posterior approximation is Gaussian In this sense Expectation Propagation as a generalization of belief propagation parallels the cavity method as a generalization of TAP\nExpectation Propagation as a general framework for approximate Bayesian inference can be applied to many real world tasks Chapter demonstrates its use for the general task of discriminating objects into classes Classi cation via Bayesian averaging has long been popular in the theoretical community but di cult to implement in a computationally competitive way An excellent example of this is the Bayes Point Machine Rujan Herbrich et al With Expectation Propagation the advantages of Bayesian averaging can be achieved at less expense than previously possible\nIn short\nChapter reviews the prior work in approximate Bayesian inference excluding ADF Chapter reviews ADF and introduces Expectation Propagation Both are illustrated on simple statistical models\nChapter addresses belief networks describing how loopy belief propagation is a special case of Expectation Propagation and how belief propagation may be extended\nChapter applies Expectation Propagation to the Bayes Point Machine classi er Chapter summarizes the results and o ers suggestions for future work on Expecta tion Propagation"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1366,
                                "start": 180
                            }
                        ],
                        "text": "Since the magnitude of w is irrelevant for classi cation, some authors have restricted w to the unit sphere in d dimensions, and have given w a uniform distribution on the sphere (Rujan, 1997). This distribution is nice because it is fair to all decision boundaries, but it is not very convenient to work with. A more general non-informative prior is an average over spheres. Let r = kwk be the magnitude of w. Given r, let w be uniformly distributed on the sphere of radius r. This prior is non-informative for any r. It is also non-informative if r is unknown with distribution p(r). For example, p(r) could be uniform from 0 to 1, allowing w to live in the unit ball instead of on the unit sphere. By choosing p(r) appropriately, we can also give w a spherical Gaussian distribution: p(w) N (0; I) (5.6) It is a property of the spherical Gaussian distribution that, conditional on any r, w is uniformly distributed on the sphere of radius r, so no particular decision boundary is favored by this prior. Given this model, the optimal way to classify a new data point x is to use the predictive distribution for y given the training data: p(yjx; D) = Zw p(yjx;w)p(wjD)dw (5.7) However, this requires solving an integral each time. A practical substitute is to use a single value ofw which approximates the predictive distribution as well as possible. Watkin (1993) and Rujan (1997) have de ned the `Bayes point' as the single best w."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 111
                            }
                        ],
                        "text": "The Bayes Point Machine approximates the Bayesian average by choosing one `average' classi er, the Bayes Point (Watkin, 1993; Rujan, 1997; Herbrich et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1502,
                                "start": 180
                            }
                        ],
                        "text": "Since the magnitude of w is irrelevant for classi cation, some authors have restricted w to the unit sphere in d dimensions, and have given w a uniform distribution on the sphere (Rujan, 1997). This distribution is nice because it is fair to all decision boundaries, but it is not very convenient to work with. A more general non-informative prior is an average over spheres. Let r = kwk be the magnitude of w. Given r, let w be uniformly distributed on the sphere of radius r. This prior is non-informative for any r. It is also non-informative if r is unknown with distribution p(r). For example, p(r) could be uniform from 0 to 1, allowing w to live in the unit ball instead of on the unit sphere. By choosing p(r) appropriately, we can also give w a spherical Gaussian distribution: p(w) N (0; I) (5.6) It is a property of the spherical Gaussian distribution that, conditional on any r, w is uniformly distributed on the sphere of radius r, so no particular decision boundary is favored by this prior. Given this model, the optimal way to classify a new data point x is to use the predictive distribution for y given the training data: p(yjx; D) = Zw p(yjx;w)p(wjD)dw (5.7) However, this requires solving an integral each time. A practical substitute is to use a single value ofw which approximates the predictive distribution as well as possible. Watkin (1993) and Rujan (1997) have de ned the `Bayes point' as the single best w. However, this point is di cult to nd. Thus, following Rujan (1997), we use the posterior mean for w, E[wjD]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 56
                            }
                        ],
                        "text": "An excellent example of this is the Bayes Point Machine (Rujan, 1997; Herbrich et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perceptron learning by playing billiards"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1942,
                                "start": 204
                            }
                        ],
                        "text": "A popular approach to model selection for the SVM is to minimize R2 M2 , where R is the radius of the smallest ball containing the training set (measured in the mapped feature space) and M is the margin (Cristianini et al., 1998). Another approach is to minimize the span bound given by thresholding the 's (Chapelle & Vapnik, 1999; Chapelle et al., 2000): S = X support vectors i ( i hC 1 sv iii) (5.93) These three criteria, evidence, margin, and span, can lead to quite di erent results. Figure 5-12 shows a synthetic training set classi ed according to distance from the origin, i.e. the true decision boundary is a circle. Three di erent decision boundaries result from training an SVM with three di erent kernels (the decision boundaries from EP are nearly identical). All of these boundaries achieve zero error so we need to invoke some other rule besides training error to select among them. Over all Gaussian kernels, the margin criterion is minimized by taking = 0:1. This produces a decision boundary with spurious kinks and bumps. The span bound is minimized by an even narrower kernel: = 0:011, where the bound is 0. By contrast, the best Gaussian kernel according to evidence has = 0:9, providing a much smoother and more realistic boundary. The quadratic kernel, which is the closest to the true boundary, has even greater evidence yet less margin. In the noise-free case, the Bayesian evidence p(D) has a natural interpretation. It is the fraction of perfect separators out of all representable classi ers. If a particular set of features has a large percentage of perfect separators, then we intuitively should have more faith in that feature set. This is what Bayesian model selection does, and in choosing the Bayes point we follow the same basic argument. Maximizing the margin does not necessarily behave this way. The next example repeats the feature selection experiment of Weston et al. (2000); Chapelle et al. (2000). Synthetic data with six features was created by rst sampling y = 1 with equal probability and then setting x1 = N (y; 1) (5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1918,
                                "start": 204
                            }
                        ],
                        "text": "A popular approach to model selection for the SVM is to minimize R2 M2 , where R is the radius of the smallest ball containing the training set (measured in the mapped feature space) and M is the margin (Cristianini et al., 1998). Another approach is to minimize the span bound given by thresholding the 's (Chapelle & Vapnik, 1999; Chapelle et al., 2000): S = X support vectors i ( i hC 1 sv iii) (5.93) These three criteria, evidence, margin, and span, can lead to quite di erent results. Figure 5-12 shows a synthetic training set classi ed according to distance from the origin, i.e. the true decision boundary is a circle. Three di erent decision boundaries result from training an SVM with three di erent kernels (the decision boundaries from EP are nearly identical). All of these boundaries achieve zero error so we need to invoke some other rule besides training error to select among them. Over all Gaussian kernels, the margin criterion is minimized by taking = 0:1. This produces a decision boundary with spurious kinks and bumps. The span bound is minimized by an even narrower kernel: = 0:011, where the bound is 0. By contrast, the best Gaussian kernel according to evidence has = 0:9, providing a much smoother and more realistic boundary. The quadratic kernel, which is the closest to the true boundary, has even greater evidence yet less margin. In the noise-free case, the Bayesian evidence p(D) has a natural interpretation. It is the fraction of perfect separators out of all representable classi ers. If a particular set of features has a large percentage of perfect separators, then we intuitively should have more faith in that feature set. This is what Bayesian model selection does, and in choosing the Bayes point we follow the same basic argument. Maximizing the margin does not necessarily behave this way. The next example repeats the feature selection experiment of Weston et al. (2000); Chapelle et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 203
                            }
                        ],
                        "text": "A popular approach to model selection for the SVM is to minimize R2 M2 , where R is the radius of the smallest ball containing the training set (measured in the mapped feature space) and M is the margin (Cristianini et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2491,
                                "start": 204
                            }
                        ],
                        "text": "A popular approach to model selection for the SVM is to minimize R2 M2 , where R is the radius of the smallest ball containing the training set (measured in the mapped feature space) and M is the margin (Cristianini et al., 1998). Another approach is to minimize the span bound given by thresholding the 's (Chapelle & Vapnik, 1999; Chapelle et al., 2000): S = X support vectors i ( i hC 1 sv iii) (5.93) These three criteria, evidence, margin, and span, can lead to quite di erent results. Figure 5-12 shows a synthetic training set classi ed according to distance from the origin, i.e. the true decision boundary is a circle. Three di erent decision boundaries result from training an SVM with three di erent kernels (the decision boundaries from EP are nearly identical). All of these boundaries achieve zero error so we need to invoke some other rule besides training error to select among them. Over all Gaussian kernels, the margin criterion is minimized by taking = 0:1. This produces a decision boundary with spurious kinks and bumps. The span bound is minimized by an even narrower kernel: = 0:011, where the bound is 0. By contrast, the best Gaussian kernel according to evidence has = 0:9, providing a much smoother and more realistic boundary. The quadratic kernel, which is the closest to the true boundary, has even greater evidence yet less margin. In the noise-free case, the Bayesian evidence p(D) has a natural interpretation. It is the fraction of perfect separators out of all representable classi ers. If a particular set of features has a large percentage of perfect separators, then we intuitively should have more faith in that feature set. This is what Bayesian model selection does, and in choosing the Bayes point we follow the same basic argument. Maximizing the margin does not necessarily behave this way. The next example repeats the feature selection experiment of Weston et al. (2000); Chapelle et al. (2000). Synthetic data with six features was created by rst sampling y = 1 with equal probability and then setting x1 = N (y; 1) (5.94) x2 = N (2y; 1) (5.95) x3 = N (3y; 1) (5.96) x4 = N (0; 1) (5.97) x5 = N (0; 1) (5.98) x6 = N (0; 1) (5.99) With probability 0.3, features x1{x3 were swapped with features x4{x6. Thus all six features are relevant to some degree. To these six relevant features are appended 14 irrelevant features with distribution N (0; 20). The test is to see whether we can reject the 14 irrelevant features. In Chapelle et al. (2000), the algorithm was forced to keep only two features."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamically adapting kernels"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Winther (1998) has given extensive evaluations of EP with = 0 and > 0 on synthetic datasets, showing that it achieves the theoretical performance of Bayesian averaging."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 37
                            }
                        ],
                        "text": "(1999), the TAP algorithm of Opper & Winther (2000c), and the mean- eld (MF) algorithm of Opper & Winther (2000c)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 429,
                                "start": 33
                            }
                        ],
                        "text": "85) This is the equation Opper & Winther use instead of (5.73). The update (5.74) for i can be written i = 1 vi v2 i [(C+ ) 1]ii 1 vi! 1 (5.86) = (vi v2 i h(C+ ) 1iii)(vi h(C+ ) 1iii) 1 (5.87) = 1 [(C+ ) 1]ii vi (5.88) This is the update Opper & Winther use instead of (5.74). EP computes a normalizing constant for the posterior, while Opper & Winther do not. All other updates are identical to those in Opper & Winther (2000c), though carried out in a di erent order."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1691,
                                "start": 37
                            }
                        ],
                        "text": "(1999), the TAP algorithm of Opper & Winther (2000c), and the mean- eld (MF) algorithm of Opper & Winther (2000c). The error is measured by Euclidean distance to the exact solution found by importance sampling. The error in using the SVM solution is also plotted for reference. Its unusually long running time is due to Matlab's quadprog solver. TAP and MF were slower to converge than EP, even with a large initial step size of 0:5. As expected, EP and TAP converge to the same solution. The billiard algorithm is a Monte Carlo method that bounces a ball inside the region de ned by hyperplane constraints. It must be initialized with a linear separator and the SVM was used for that purpose. Since there are many other ways one could initialize the billiard, which may be much cheaper, the initialization step was not counted against the billiard's FLOP count (otherwise the billiard curve would be right of the SVM point). The error axis must also be interpreted carefully. While it is tempting to use the lower envelope of the curve as the measure of error, it is actually more accurate to use the upper envelope, since this is all that the algorithm can consistently achieve as samples accumulate. Nevertheless it is clear that EP is much faster and more accurate. Laplace's method and variational Bayes do not work at all on this problem. Laplace fails because the derivatives of the likelihood are not informative: they are either zero or in nity. Variational Bayes fails for = 0 because no Gaussian can lower bound the likelihood (Gaussians never reach zero). Even with > 0, a Gaussian bound must be quite narrow so we can't expect competitive performance. Herbrich & Graepel (2000) point out that the SVM is sensitive to scaling an input vector, i."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 34
                            }
                        ],
                        "text": "Following the notation of Opper & Winther (2000c), de ne i = xTi Vni wxi (Vni w is the Vw when term i is left out) (5."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 37
                            }
                        ],
                        "text": "(1999), the TAP algorithm of Opper & Winther (2000c), and the mean- eld (MF) algorithm of Opper & Winther (2000c). The error is measured by Euclidean distance to the exact solution found by importance sampling."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian mean eld algorithms for neural networks and Gaussian"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2117,
                                "start": 196
                            }
                        ],
                        "text": "It is an extension to assumed-density ltering (ADF), (Maybeck, 1982; Lauritzen, 1992; Bernardo & Giron, 1988; Stephens, 1997; Boyen & Koller, 1998b; Barber & Sollich, 1999; Opper & Winther, 1999; Frey et al., 2000) a one-pass, sequential method for computing an approximate posterior distribution. In ADF, observations are processed one by one, updating the posterior distribution which is then approximated before processing the next observation. For example, we might replace the exact one-step posterior with a Gaussian having the same mean and same variance (Maybeck, 1982; Lauritzen, 1992; Barber & Sollich, 1999; Opper & Winther, 1999). Or we might replace a posterior over many variables with one that renders the variables independent (Boyen & Koller, 1998b) or approximates them as Markovian (Frey et al., 2000). In each case, the approximate posterior is found by minimizing KL-divergence, which amounts to preserving a speci c set of posterior expectations. Note that the statistical model in question need not be a time series model, and the processing order of observations need not correspond with time of arrival. The weakness of ADF stems from its sequential nature: information that is discarded early on may turn out to be important later. Even if ADF is augmented with a backward pass (Boyen & Koller, 1998a), this information cannot be recovered. ADF is also sensitive to observation ordering, which is undesirable in a batch context. Expectation Propagation (EP) extends ADF to incorporate iterative re nement of the approximations, by making additional passes. The information from later observations renes the choices made earlier, so that the most important information is retained. When the re nement converges, the resulting posterior is independent of ordering and more accurate. Iterative re nement has previously been used in conjunction with sampling (Koller et al., 1999) and extended Kalman ltering (Shachter, 1990). Expectation Propagation di ers by applying this idea to the deterministic approximation of general distributions, not just Gaussian distributions as in Shachter (1990). EP is more expensive than ADF by only a constant factor|the number of re nement passes (typically 4 or 5)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 74
                            }
                        ],
                        "text": "Partially disconnected approximations have previously been used in ADF by Frey et al. (2000) and in the context of variational bounds by Ghahramani & Jordan (1997), Barber & Wiegerinck (1998), and references therein."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3816,
                                "start": 196
                            }
                        ],
                        "text": "It is an extension to assumed-density ltering (ADF), (Maybeck, 1982; Lauritzen, 1992; Bernardo & Giron, 1988; Stephens, 1997; Boyen & Koller, 1998b; Barber & Sollich, 1999; Opper & Winther, 1999; Frey et al., 2000) a one-pass, sequential method for computing an approximate posterior distribution. In ADF, observations are processed one by one, updating the posterior distribution which is then approximated before processing the next observation. For example, we might replace the exact one-step posterior with a Gaussian having the same mean and same variance (Maybeck, 1982; Lauritzen, 1992; Barber & Sollich, 1999; Opper & Winther, 1999). Or we might replace a posterior over many variables with one that renders the variables independent (Boyen & Koller, 1998b) or approximates them as Markovian (Frey et al., 2000). In each case, the approximate posterior is found by minimizing KL-divergence, which amounts to preserving a speci c set of posterior expectations. Note that the statistical model in question need not be a time series model, and the processing order of observations need not correspond with time of arrival. The weakness of ADF stems from its sequential nature: information that is discarded early on may turn out to be important later. Even if ADF is augmented with a backward pass (Boyen & Koller, 1998a), this information cannot be recovered. ADF is also sensitive to observation ordering, which is undesirable in a batch context. Expectation Propagation (EP) extends ADF to incorporate iterative re nement of the approximations, by making additional passes. The information from later observations renes the choices made earlier, so that the most important information is retained. When the re nement converges, the resulting posterior is independent of ordering and more accurate. Iterative re nement has previously been used in conjunction with sampling (Koller et al., 1999) and extended Kalman ltering (Shachter, 1990). Expectation Propagation di ers by applying this idea to the deterministic approximation of general distributions, not just Gaussian distributions as in Shachter (1990). EP is more expensive than ADF by only a constant factor|the number of re nement passes (typically 4 or 5). As shown in chapter 3, the accuracy of EP is signi cantly better than ADF as well as rival approximation methods: Monte Carlo, Laplace's method, and variational Bayes. Thinking in this framework has a number of bene ts. For example, in belief networks with loops it is known that approximate marginal distributions can be obtained by iterating the belief propagation recursions, a process known as loopy belief propagation (Frey & MacKay, 1997; Murphy et al., 1999). As described in chapter 4, it turns out that this heuristic procedure is a special case of Expectation Propagation, where the approximate posterior is a completely disconnected network with no other constraints on functional form. In other words, loopy belief propagation is a direct generalization of the ADF algorithm of Boyen & Koller (1998b). Expectation Propagation can therefore be seen as a way of generalizing loopy belief propagation|to less restrictive approximations that are not completely disconnected and to useful constraints on functional form such as multivariate Gaussian. Partially disconnected approximations are useful for improving accuracy, just as in variational methods (Jordan et al., 1999), while constraints on functional form are useful for reducing computation. Instead of propagating exact belief states, which may be intractable, EP only needs to propagate expectations relevant to the chosen approximating distribution (e.g. means and variances). Hence the name \\Expectation Propagation.\" Expectation Propagation also has connections to statistical physics techniques. Yedidia et al. (2000) have shown that belief propagation tries to minimize an approximate free energy on discrete networks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 158
                            }
                        ],
                        "text": "Or we might replace a posterior over many variables with one that renders the variables independent (Boyen & Koller, 1998b) or approximates them as Markovian (Frey et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 136
                            }
                        ],
                        "text": "ADF has been independently proposed in the statistics (Lauritzen, 1992; Bernardo & Giron, 1988; Stephens, 1997), arti cial intelligence (Boyen & Koller, 1998b; Opper & Winther, 1999; Barber & Sollich, 1999; Frey et al., 2000), and control literature (Kushner & Budhiraja, 2000; Maybeck, 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2485,
                                "start": 2476
                            }
                        ],
                        "text": "The dominant computational task in Bayesian inference is numerical integration New methods for fast and accurate integration are therefore very important and can have great impact This dissertation presents a new deterministic approximation framework Expecta tion Propagation which achieves higher accuracy than existing integration algorithms with similar computational cost\nThe general scenario of Bayesian inference is that there is some observed data and some unobserved quantity of interest Inferences about the unknown x are based on its posterior distribution given the observed D\np xjD p x D p D\np x D R\nx p x D dx\nFor example we may want to know the posterior mean and variance of the unknown which are integrals over the posterior\nE xjD Z x xp xjD dx\nR x xp x D dxR x p x D dx\nE x jD Z x x p xjD dx\nR x x\np x D dxR x p x D dx\nvar xjD E x jD E xjD\nIn real situations there are many unknowns not just the one we are interested in In Bayesian inference these must be marginalized out of the joint distribution which involves yet more integrals\np xjD R y z p x y z D R x y z p x y z D\nThus numerical integration goes hand in hand with practical Bayesian inference Numerical integration algorithms can be principally divided into deterministic vs non deterministic methods Deterministic methods try to approximate the integrand with some thing whose integral is known exactly They work from properties of the integrand like its maxima and curvature Nondeterministic methods sample the integrand at random points to get a stochastic estimate of the integral This approach is more general since it works for almost any integrand but it also requires a great deal more computation than deterministic approximation\nThe proposed method Expectation Propagation is a deterministic approximation method It is an extension to assumed density ltering ADF Maybeck Lauritzen Bernardo Giron Stephens Boyen Koller b Barber Sollich Opper Winther Frey et al a one pass sequential method for comput ing an approximate posterior distribution In ADF observations are processed one by one updating the posterior distribution which is then approximated before processing the next observation For example we might replace the exact one step posterior with a Gaussian having the same mean and same variance Maybeck Lauritzen Barber Sol lich Opper Winther Or we might replace a posterior over many variables with one that renders the variables independent Boyen Koller b or approximates them as Markovian Frey et al In each case the approximate posterior is found by minimizing KL divergence which amounts to preserving a speci c set of posterior expecta tions Note that the statistical model in question need not be a time series model and the processing order of observations need not correspond with time of arrival The weakness of ADF stems from its sequential nature information that is discarded early on may turn out to be important later Even if ADF is augmented with a backward pass Boyen Koller a this information cannot be recovered ADF is also sensitive to observation ordering which is undesirable in a batch context\nExpectation Propagation EP extends ADF to incorporate iterative re nement of the approximations by making additional passes The information from later observations re nes the choices made earlier so that the most important information is retained When the re nement converges the resulting posterior is independent of ordering and more accurate Iterative re nement has previously been used in conjunction with sampling Koller et al and extended Kalman ltering Shachter Expectation Propagation di ers by applying this idea to the deterministic approximation of general distributions not just Gaussian distributions as in Shachter EP is more expensive than ADF by only a constant factor the number of re nement passes typically or As shown in chapter the accuracy of EP is signi cantly better than ADF as well as rival approximation methods Monte Carlo Laplace s method and variational Bayes\nThinking in this framework has a number of bene ts For example in belief networks with loops it is known that approximate marginal distributions can be obtained by iterating the belief propagation recursions a process known as loopy belief propagation Frey MacKay Murphy et al As described in chapter it turns out that this heuristic procedure is a special case of Expectation Propagation where the approximate posterior is a completely disconnected network with no other constraints on functional form In other words loopy belief propagation is a direct generalization of the ADF algorithm of Boyen Koller b\nExpectation Propagation can therefore be seen as a way of generalizing loopy belief propagation to less restrictive approximations that are not completely disconnected and to useful constraints on functional form such as multivariate Gaussian Partially disconnected approximations are useful for improving accuracy just as in variational methods Jordan et al while constraints on functional form are useful for reducing computation Instead of propagating exact belief states which may be intractable EP only needs to propagate expectations relevant to the chosen approximating distribution e g means and variances Hence the name Expectation Propagation\nExpectation Propagation also has connections to statistical physics techniques Yedidia et al have shown that belief propagation tries to minimize an approximate free en ergy on discrete networks This is known as the TAP approach in statistical physics Opper\nWinther a have generalized the TAP approach to networks with mixed continuous and discrete nodes via the cavity method and applied it to Gaussian process classi ers Opper Winther c Chapter shows that Opper Winther s algorithm which has excellent performance is a special case of Expectation Propagation where the posterior approximation is Gaussian In this sense Expectation Propagation as a generalization of belief propagation parallels the cavity method as a generalization of TAP\nExpectation Propagation as a general framework for approximate Bayesian inference can be applied to many real world tasks Chapter demonstrates its use for the general task of discriminating objects into classes Classi cation via Bayesian averaging has long been popular in the theoretical community but di cult to implement in a computationally competitive way An excellent example of this is the Bayes Point Machine Rujan Herbrich et al With Expectation Propagation the advantages of Bayesian averaging can be achieved at less expense than previously possible\nIn short\nChapter reviews the prior work in approximate Bayesian inference excluding ADF Chapter reviews ADF and introduces Expectation Propagation Both are illustrated on simple statistical models\nChapter addresses belief networks describing how loopy belief propagation is a special case of Expectation Propagation and how belief propagation may be extended\nChapter applies Expectation Propagation to the Bayes Point Machine classi er Chapter summarizes the results and o ers suggestions for future work on Expecta tion Propagation"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 53
                            }
                        ],
                        "text": "It is an extension to assumed-density ltering (ADF), (Maybeck, 1982; Lauritzen, 1992; Bernardo & Giron, 1988; Stephens, 1997; Boyen & Koller, 1998b; Barber & Sollich, 1999; Opper & Winther, 1999; Frey et al., 2000) a one-pass, sequential method for computing an approximate posterior distribution."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3038,
                                "start": 196
                            }
                        ],
                        "text": "It is an extension to assumed-density ltering (ADF), (Maybeck, 1982; Lauritzen, 1992; Bernardo & Giron, 1988; Stephens, 1997; Boyen & Koller, 1998b; Barber & Sollich, 1999; Opper & Winther, 1999; Frey et al., 2000) a one-pass, sequential method for computing an approximate posterior distribution. In ADF, observations are processed one by one, updating the posterior distribution which is then approximated before processing the next observation. For example, we might replace the exact one-step posterior with a Gaussian having the same mean and same variance (Maybeck, 1982; Lauritzen, 1992; Barber & Sollich, 1999; Opper & Winther, 1999). Or we might replace a posterior over many variables with one that renders the variables independent (Boyen & Koller, 1998b) or approximates them as Markovian (Frey et al., 2000). In each case, the approximate posterior is found by minimizing KL-divergence, which amounts to preserving a speci c set of posterior expectations. Note that the statistical model in question need not be a time series model, and the processing order of observations need not correspond with time of arrival. The weakness of ADF stems from its sequential nature: information that is discarded early on may turn out to be important later. Even if ADF is augmented with a backward pass (Boyen & Koller, 1998a), this information cannot be recovered. ADF is also sensitive to observation ordering, which is undesirable in a batch context. Expectation Propagation (EP) extends ADF to incorporate iterative re nement of the approximations, by making additional passes. The information from later observations renes the choices made earlier, so that the most important information is retained. When the re nement converges, the resulting posterior is independent of ordering and more accurate. Iterative re nement has previously been used in conjunction with sampling (Koller et al., 1999) and extended Kalman ltering (Shachter, 1990). Expectation Propagation di ers by applying this idea to the deterministic approximation of general distributions, not just Gaussian distributions as in Shachter (1990). EP is more expensive than ADF by only a constant factor|the number of re nement passes (typically 4 or 5). As shown in chapter 3, the accuracy of EP is signi cantly better than ADF as well as rival approximation methods: Monte Carlo, Laplace's method, and variational Bayes. Thinking in this framework has a number of bene ts. For example, in belief networks with loops it is known that approximate marginal distributions can be obtained by iterating the belief propagation recursions, a process known as loopy belief propagation (Frey & MacKay, 1997; Murphy et al., 1999). As described in chapter 4, it turns out that this heuristic procedure is a special case of Expectation Propagation, where the approximate posterior is a completely disconnected network with no other constraints on functional form. In other words, loopy belief propagation is a direct generalization of the ADF algorithm of Boyen & Koller (1998b). Expectation Propagation can therefore be seen as a way of generalizing loopy belief propagation|to less restrictive approximations that are not completely disconnected and to useful constraints on functional form such as multivariate Gaussian."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sequentially tting inclusive"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 695,
                                "start": 13
                            }
                        ],
                        "text": "For example, Yedidia et al. (2000) have shown that clustering nodes in a belief network can encourage belief propagation to converge (as well as improve its accuracy). Clustering corresponds to an approximating density that is partially disconnected, such as q(x) = q(x1; x2)q(x3; x4). As described in section 4.2.1, we can also cluster some of the terms ti(x) to get fewer approximations. Or we can use a Markov chain approximation, as described in section 4.2.2. A second way to improve convergence is to devise a better iteration scheme. Analogous to belief propagation, EP can be derived by minimizing a free energy-like objective. The expression is similar to that of Yedidia et al. (2000) but involving expectation constraints."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 109
                            }
                        ],
                        "text": "Most of these are extensions of TAP, such as the cavity method (Opper & Winther, 2000a), Bethe approximation (Yedidia, 2000), and Plefka expansion (Kappen & Wiegerinck, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 13
                            }
                        ],
                        "text": "For example, Yedidia et al. (2000) have shown that clustering nodes in a belief network can encourage belief propagation to converge (as well as improve its accuracy)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An idiosyncratic journey beyond mean eld theory (Technical"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1408,
                                "start": 1400
                            }
                        ],
                        "text": "This chapter describes recursive approximation techniques that try to minimize the KL divergence between the true posterior and the approximation Assumed density ltering is a fast sequential method for this purpose Expectation Propagation is introduced as an extension of assumed density ltering to batch situations It has higher accuracy than assumed density ltering and other comparable methods for approximate inference\nAssumed density ltering\nThis section reviews the idea of assumed density ltering ADF to lay groundwork for Expectation Propagation Assumed density ltering is a general technique for computing approximate posteriors in Bayesian networks and other statistical models ADF has been in dependently proposed in the statistics Lauritzen Bernardo Giron Stephens arti cial intelligence Boyen Koller b Opper Winther Barber Sol lich Frey et al and control literature Kushner Budhiraja Maybeck Assumed density ltering is the name used in control other names include on line Bayesian learning moment matching and weak marginalization ADF applies when we have postulated a joint distribution p D where D has been observed and is hidden We would like to know the posterior over p jD as well as the probability of the observed data or evidence for the model p D The former is useful for estimation while the latter is useful for model selection\nFor example suppose we have observations from a Gaussian distribution embedded in a sea of unrelated clutter so that the observation density is a mixture of two Gaussians\np xj w N x I wN x I N x m V\nj Vj exp\nx m TV x m\nThe rst component contains the parameter of interest while the other component describes clutter The constant w is the known ratio of clutter Let the d dimensional vector have a Gaussian prior distribution\np N Id The joint distribution of and n independent observations D fx xng is therefore\np D p Y i p xij\nt t t t t\nqnew\np q\nFigure Assumed density ltering computes an exact one step posterior p and then approximates it to get qnew\nTo apply ADF we rst factor the joint distribution p D into a product of simple terms\np D Y i ti\nThere are many ways to do this As a rule of thumb fewer terms are better since it entails fewer approximations However we need each term to be simple enough to propagate expectations through In the mixture example we can use the factoring into n terms implied by\nt p\nti p xij For a general Bayesian network we would use the factoring into conditional probability tables Q nodes Y p Y jpa Y where pa Y is the parents of node Y in the graph\nThe second step is to choose a parametric approximating distribution It is essential that the distribution be in the exponential family so that only a xed number of expectations the su cient statistics need to be propagated Usually the nature and domain of constrains the distribution enough that there is no choice left to make In the clutter problem a spherical Gaussian distribution is appropriate The approximate posterior is therefore\nq N m v I Finally we sequence through and incorporate the terms ti into the approximate poste\nrior At each step we move from an old q to a new q as shown in gure For notational simplicity we drop the dependence of q on i Initialize with q Incor porating the prior term is trivial with no approximation needed To incorporate the next term ti take the exact posterior\np ti q R\nti q d\nand minimize the KL divergence D p jjqnew subject to the constraint that qnew is a Gaussian distribution Zeroing the gradient with respect to m v gives the conditions\nmnew\nZ p d\nvnew d m new T mnew\nZ p T d\nor in other words expectation constraints\nEqnew E p Eqnew T E p T\nWe see that the spherical Gaussian distribution is characterized by the expectations E E T For other members of the exponential family we will get constraints on di erent expectations as illustrated in section\nTo compute these expectations it is helpful to exploit the following relations\nZ m v Z t q d\nZ\nt\nv d exp\nv m T m d\nrm logZ m v Z\nZ\nm v\nt\nv d exp\nv m T m d\nE p v m v\nE p m v rm logZ m v E p T E p TE p v d v rTmrm rv logZ m v\nThese relations are a property of the Gaussian distribution and hold for any t In the clutter problem we have\nZ m v w N x m v I wN x I r\nw N x m v I w N x m v I wN x I\nrm logZ m v rx m v\nrv logZ m v rd v\nr x m T x m\nv\nrTmrm rv logZ m v rd v r r x m T x m v\nAn estimate of the probability of the data p D is a trivial byproduct of ADF Sim ply accumulate the normalization factors Zi m v produced by each update to get an overall normalization for the posterior This normalizer estimates p D because p D p jD p D\nThe nal ADF algorithm is\nInitialize m v the prior Initialize s the scale factor\nFor each data point xi update m v s according to\nmnew m v ri xi m v\nvnew v ri v v ri ri v\nxi m T xi m\nd v\nsnew s Zi m v\nThis algorithm can be understood in an intuitive way for each data point we compute its probability r of not being clutter make a soft update to our estimate of m and change our con dence in the estimate v However it is clear that this algorithm will depend on\nthe order in which data is processed because the clutter probability depends on the current estimate of\nThis algorithm was derived using a spherical Gaussian approximating distribution If we use a richer set of distributions like diagonal or full covariance Gaussians we can get a better result since more expectations will be preserved Unlike tting models to data there is no over tting problem when tting approximations to posteriors The only penalty is computational cost\nFigure shows the output of this algorithm using three random orderings of the same data Synthetic data was generated using w and No theory is available for how ADF varies with ordering but some empirical observations can be made The error increases whenever similar data points are processed together Processing the data in sorted order is especially bad This is because the algorithm overcommits to one part of input space only to realize that there is also data somewhere else The approximate mean and especially the variance will su er because of this So one approach to improve ADF is to nd an ordering that best re ects the natural variation in the data if this can be quanti ed somehow Another approach is to modify ADF to eliminate the dependence on ordering which is described in the next section\n\u22121 0 1 2 3 4 5 \u03b8\np( \u03b8,\nD )\nExact ADF\nFigure The approximate posterior resulting from ADF using three di erent orderings of the same data The posterior is scaled by the evidence estimate p D\nt t t t t\nq\nt t t t t\nqnew\nq\nt t t\nqnew\nt t t\nt t\nt t\nq\nFigure An alternative view of ADF as approximating each term and then computing qnew exactly EP re nes each term in the context of all other terms\nExpectation Propagation\nThis section describes the Expectation Propagation algorithm and demonstrates its use on the clutter problem Expectation Propagation is based on a novel interpretation of assumed density ltering Normally we think of ADF as treating each observation term ti exactly and then approximating the posterior that includes ti But we can also think of it as rst approximating ti with some !ti and then using an exact posterior with !ti gure This interpretation is always possible because we can de ne the approximate term !ti to be the ratio of the new posterior to the old posterior times a constant\n!t Z qnew\nq\nMultiplying this approximate term by q gives qnew as desired An important property is that if the approximate posterior is Gaussian i e an exponentiated quadratic in then the equivalent term approximation which is a ratio of these will also be an exponentiated quadratic If the approximate posterior is any distribution in the exponential family then the term approximations will have the same functional form as that distribution\nThe algorithm of the previous section can thus be interpreted as sequentially comput ing a Gaussian approximation !ti to every observation term ti then combining these approximations analytically to get a Gaussian posterior on Under this perspective the approximations do not have any required order the ordering only determined how wemade the approximations We are free to go back and re ne the approximations in any order From this idea we get Expectation Propagation\nConsider how this new interpretation applies to the previous section From the ratio of spherical Gaussians we get the following term approximation\nZi m v\nZ ti q d\n!ti Zi m v qnew\nq\nZi m v\nv vnew\nd exp\nvnew mnew T mnew\nexp v m T m\nNow de ne mi vi according to\nv i v new\nv\nmi vi v new mnew viv m m vi v v m new m\nto get the simpli cation\n!ti Zi m v\nvi v vi d exp\nvi mi T mi\nexp\nvi v mi m T mi m\nZi m v\nN mi m vi v I N mi viI\nBy construction multiplying q by this approximation gives exactly the ADF update with the proper scale factor The N notation is here used formally as shorthand not to imply a proper density The approximation is an exponentiated quadratic in which has the form of a Gaussian with mean mi and variance viI times a scale factor What makes this approximation di erent from a Gaussian is that the variance vi may be negative or in nite which for !ti is perfectly ne negative variance corresponds to a function that curves upward and in nite variance corresponds to a constant\nFigure illustrates ti and !ti for the clutter problem The exact term ti p xij is a Gaussian in raised by a constant The approximate term !ti is an expo nentiated quadratic The current posterior q determines where the approximation will be accurate When q is narrow i e v is small then !ti is accurate only in a narrow range of values determined bym When v is large then !ti tries to approximate ti more broadly and m is less important\nm v m v\n!t t q\nm v m v\nm v m v\nFigure The approximate term !t as a function of plotted versus the exact term t and the current posterior q The current posterior controls where the approximation will be accurate\nSo far we have just rewritten the ADF updates in a di erent way To get EP we re ne the term variables mi vi based on all of the other approximations The general EP algorithm is\nInitialize the term approximations !ti\nCompute the posterior for from the product of !ti\nqnew\nQ i !ti R Q\ni !ti d\nUntil all !ti converge\na Choose a !ti to re ne b Remove !ti from the posterior to get an old posterior q by dividing and normalizing\nq q new !ti\nFor notational simplicity we drop the dependence of q on i However qnew is not a function of i\nc Compute the posterior qnew and normalizing factor Zi from q and ti via ADF\nd Set\n!ti Zi qnew\nq\nUse the normalizing constant of qnew from as an approximation to p D\np D Z Y\ni\n!ti d\nAt convergence the result will be independent of processing order as desired In this algorithm we have used division to remove !ti from the posterior Step b can also be performed without division by accumulating all terms except for !ti\nq Y j i !tj\nbut division is usually more e cient\nThe clutter problem\nFor the clutter problem of the previous section the EP algorithm is\nThe term approximations have the form\n!ti si exp vi\nmi T mi\nInitialize the prior term to itself\nv\nm\ns v d\nInitialize the data terms to\nvi mi\nsi\nmnew m v new v\nUntil all mi vi si converge changes are less than\nloop i n\na Remove !ti from the posterior to get an old posterior\nv v new\nv i m v v new\nmnew v v i mi mnew v v i mnew mi\nb Recompute mnew v new Zi from m v this is the same as ADF\nri w N xi m v I\nw N xi m v I wN xi I\nmnew m v ri xi m v\nvnew v ri v v ri ri v\nxi m T xi m\nd v\nZi w N xi m v I wN xi I\nc Update !ti\nv i v new\nv\nri v ri ri xi m T xi m d v\nv\nmi m vi v v m\nnew m\nm vi v ri xi m v\nsi Zi\nvi d N mi m vi v I\nCompute the normalizing constant\nB mnew Tmnew vnew\nX i mTi mi vi\np D Z Y\ni\n!ti d\nvnew d exp B\nnY i si\nBecause the term approximations start at the result after one pass through the data is identical to ADF On later passes the re nement may sometimes fail due to a negative value for v This happens when many of the vi are negative and we wish to re ne a term with positive vi In the subtraction step we subtract a positive value from v new and are left with something negative From this Zi does not exist and the algorithm fails Another problem is that the term approximations may oscillate without ever converging This tends to occur in conjunction with negative vi s which suggests a simple work around force all vi by relaxing some of the expectation constraints Whenever a vi would become negative make it large instead and set vnew v because v new v v\ni This trick does provide convergence but leads to inaccurate posteriors since we are e ectively ignoring some of the data When EP does converge with negative vi s the result is always better than having forced vi So a better solution would be to use a re nement algorithm with better convergence properties see the discussion at the end of section\nResults and comparisons\nThis section evaluates ADF and EP on the clutter problem and compares them to four other algorithms for approximate inference Laplace s method variational Bayes importance sampling speci cally likelihood weighted sampling and Gibbs sampling\nIn Laplace s method we rst run EM to get a MAP estimate of Then we construct a Gaussian approximation to the posterior by using the curvature of the posterior at This curvature is Minka c\nH r T log p jD\nI X i riI X i ri ri xi xi T\nri w N x I\nw N x I wN x I\nThe Gaussian approximation and normalizing constant are\np jD N H p D p D d j Hj\nFor variational Bayes we lower bound the joint distribution by bounding each data term Minka c\np xij w N x I\nqi\nqi wN x I qi qi\nThe variational parameters qij are optimized to give the tightest bound Given the bounds the posterior for is Gaussian\nKj X i qij\n\"xj\nKj X i qijxi\nSj X i qij xi \"xj xi \"xj T\nV\nK I\nI\nm V K \"x\np jD N m V\np D d K K d\nN \"x I K exp tr S\nd K K d\nN \"x I K exp tr S\nY i w qi qi w qi qi\nFor importance sampling or more speci cally likelihood weighted sampling we draw samples f Sg from p and approximate the integrals via\np D S SX i p Dj i\nE jD PS\ni ip Dj i PS i p Dj i\nFor Gibbs sampling we introduce hidden variables ci which indicate whether xi is clutter or not Given a choice for we sample ci from a Bernoulli distribution with mean ri Then given ci we form an exact Gaussian posterior for and sample a new The average of the s that arise from this process is our estimate of the posterior mean\nThe three deterministic algorithms EP Laplace and VB all obtain approximate pos teriors close to the true one The sampling algorithms only estimate speci c integrals To compare the algorithms quantitatively we compute the absolute di erence between the es timated and exact evidence and the estimated and exact posterior mean Figure shows the results on a typical run with data size n and n It plots the accuracy vs cost of the algorithms on the two integrals Accuracy is measured by absolute di erence from the true integral Cost is measured by the number of oating point operations FLOPS in Matlab via Matlab s flops function This is better than using CPU time because FLOPS ignores interpretation overhead\nThe exact shape of these curves especially the EP curve should not be taken too seriously since the convergence properties of EP including whether it converges at all can be substantially a ected by the particular dataset and data ordering The Laplace curve is generated by applying to intermediate values of even though the gradient may not be zero\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u221223\n10 \u221222\n10 \u221221\n10 \u221220\n10 \u221219\n10 \u221218\n10 \u221217\nEP\nVB\nLaplace\nImportance\nEvidence\nFLOPS\nE rr\nor\n10 3\n10 4\n10 5\n10 6\n10 7\n10 \u2212205\n10 \u2212204\n10 \u2212203\n10 \u2212202\n10 \u2212201\n10 \u2212200\n10 \u2212199\nEP\nVB\nLaplace\nImportance\nEvidence\nFLOPS\nE rr\nor\nData size n n\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u22126\n10 \u22125\n10 \u22124\n10 \u22123\n10 \u22122\n10 \u22121\n10 0\nEP\nLaplace VB\nImportance\nGibbs\nPosterior mean\nFLOPS\nE rr\nor\n10 3\n10 4\n10 5\n10 6\n10 7\n10 \u22126\n10 \u22125\n10 \u22124\n10 \u22123\n10 \u22122\n10 \u22121\n10 0\nEP\nLaplace\nVB\nImportance\nGibbs\nPosterior mean\nFLOPS\nE rr\nor\nn n\nFigure Cost vs accuracy curves for expectation propagation EP Laplace s method variational Bayes VB importance sampling and Gibbs sampling on the clutter problem with w and Each x is one iteration of EP ADF is the rst x\nADF is equivalent to the rst iteration of EP the rst x on the curve It performs sig ni cantly worse than variational Bayes and Laplace s method which are o#ine algorithms Yet by re ning the ADF approximations we move from last place to rst The worth of an algorithm is not always what it seems\nIt is interesting to see how the di erent properties of the algorithms manifest themselves EP Laplace and VB all try to approximate the posterior with a Gaussian and their performance depends on how well this assumption holds With more data the posterior becomes more Gaussian so they all improve Sampling methods by contrast assume very little about the posterior and consequently cannot exploit the fact that it is becoming more Gaussian\nHowever this disadvantage turns into an advantage when the posterior has a complex shape Figure shows a run with n where the true posterior has three distinct modes EP crashes on this data due to negative variances Restricted EP which forces all vi does converge but to a poor result that captures only a single mode Laplace s method and variational Bayes are even worse For all three algorithms the error in the posterior mean increases with more iterations as they focus on a single mode Sampling methods by contrast are only slightly challenged by this posterior\n\u22126 \u22124 \u22122 0 2 4 6 0\n1\n2\n3\n4\n5\n6\n7\n8 x 10\n\u221226\ntheta\np( th\net a,\nD )\nExact EP VB Laplace\n\u221210 \u22125 0 5 10 0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\ntheta\np( th\net a\n| D )\nExact Gibbs\na b\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u22122\n10 \u22121\n10 0\n10 1\nEP\nLaplace\nVB\nImportance\nGibbs\nPosterior mean\nFLOPS\nE rr\nor\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u221227\n10 \u221226\n10 \u221225\n10 \u221224\nEP\nVB\nLaplace\nImportance\nEvidence\nFLOPS\nE rr\nor\nc d\nFigure A complex posterior in the clutter problem a Exact posterior vs approx imations obtained by Restricted EP Laplace s method and variational Bayes b Exact posterior vs approximation obtained by Gibbs sampling and complete conditional density averaging Gelfand Smith c d Cost vs accuracy EP only converged when restricted to positive vi\nAnother example Mixture weights\nThis section demonstrates how the structure of ADF and EP are preserved with a di er ent approximating distribution a Dirichlet distribution Let the probabilistic model be a mixture of K known densities p x pK x with unknown mixing weights w\np xjw X k wkpk x\nX k wk\np w p D w p w Y i p xijw\nWe want to compute the posterior p wjD and the evidence p D ADF was applied to this problem by Bernardo Giron and Stephens\nBreak the joint distribution p D w into n terms as given by The parameter vector w must lie in the simplex P k wk so a Dirichlet distribution is an appropriate approximation to the posterior The approximate posterior will have the form\nq w $ P\nk ak Q k $ ak Y k wak k\nADF\nFor ADF we sequence through and incorporate the terms ti into the approximate posterior The prior is a Dirichlet distribution so we initialize with that To incorporate a data term ti w take the exact posterior\np w ti w q w R\nw ti w q w dw\nand minimize the KL divergence D p w jjqnew w subject to the constraint that qnew w is a Dirichlet distribution Zeroing the gradient with respect to anewk gives the conditions k K\n% anewk % X j anewj Z w p w log wk dw\nwhere % a d log $ a\nda\nAs usual these are expectation constraints\nEqnew log wk E p log wk k K\nThe Dirichlet distribution is characterized by the expectations E log wk How do we solve for anew& Given the values E p log wk Newton s method is very e ec tive and EM like algorithms are also possible Minka b To compute the expectations use integration by parts to nd\nZ a Z w t w q w dw\nE p log wk % ak % X j aj rak logZ a\nThis is a property of the Dirichlet distribution valid for any t w In the mixture weight problem we have\nt w X k pk x wk Z a X k pk x Eq wk\nP k pk x akP\nk ak\nrak logZ a pk x P j aj P j pj x aj P j aj\nZ a\npk x P j pj x aj\nP j aj\nSo the nal ADF algorithm is\nInitialize a the prior Initialize s the scale factor\nFor each data point xi in turn solve the equations k K\n% anewk % X j anewj % ak % X j aj pk xi P j pj xi aj\nP j aj\nto get anew Update s via\nsnew s Zi a s P\nj pj xi ajP j aj\nBernardo Giron and Stephens show that this algorithm performs better than simpler rules like Directed Decision and Probabilistic Teacher With a little extra work we can get an EP algorithm that is even better\nEP\nDivide the new posterior by the old to get a term approximation parameterized by b\n!t Z qnew\nq Z $ P k a new k Q\nk $ a new k\nQ k $ ak\n$ P\nk ak Y k wbkk\nwhere bk a new k ak\nThe EP algorithm is\nThe term approximations have the form\n!ti si Y k wbikk\nInitialize the prior term to itself\nb\ns\nInitialize the data terms to\nbi\nsi\nanewk Pn i bik\nUntil all bi si converge\nloop i n\na Remove !ti from the posterior to get an old posterior\na anew bi\nb Recompute anew from a by solving k K\n% anewk % X j anewj % ak % X j aj pk xi P j pj xi aj\nP j aj\nc Update !ti\nbi a new a si Zi a $ P k a new k Q\nk $ a new k\nQ k $ ak\n$ P\nk ak\nCompute the normalizing constant\np D Q k $ a new k\n$ P\nk a new k nY i si\nA simpler method\nThe complexity of this algorithm results from preserving the expectations E log wk Cow ell et al suggest instead preserving only the rst two moments of the posterior dis tribution i e the expectations E wk P k E w k Preserving these expectations will not minimize KL divergence but allows a closed form update Their proposed ADF update is\nmk E p wk\nak Zi a P j aj\npk xi P j pj xi aj\nP\nj aj\nm k E p w k\nak ak Zi a P j aj P j aj\npk xi P j pj xi aj\nP\nj aj\nanewk\nP k mk m k P k m k m k\nmk\nThis update can be incorporated into EP by replacing The bene t of this change is determined empirically in the next section\n0 0.2 0.4 0.6 0.8 1 0\n2\n4\n6 x 10\n\u221247\nw\np( D\n,w )\nExact Laplace VB\n0 0.2 0.4 0.6 0.8 1 0\n2\n4\n6 x 10\n\u221247\nw\np( D\n,w )\nExact EP\n10 3\n10 4\n10 5\n10 6\n10 \u221249\n10 \u221248\n10 \u221247\n10 \u221246\nEP\nVB\nLaplace\nEvidence\nFLOPS E\nrr or\nEP2\na b\nFigure a Exact posterior vs approximations scaled by evidence p D The varia tional Bayes approximation is a lower bound while the others are not The approximation from EP is very similar to EP b Cost vs accuracy in approximating p D ADF is the rst x on the EP curve EP uses the fast update of Cowell et al\nResults and comparisons\nEP is compared against Laplace s method and variational Bayes For Laplace s method we use a softmax parameterization of w MacKay which makes the approximate posterior a logistic normal distribution the result of passing a Gaussian random variable through the logistic function Aitchison Shen For variational Bayes we use a Jensen bound as before to get a Dirichlet approximation Minka c\nFigure shows a typical example with w n The component densities were two closely spaced Gaussians\np x N p x N\nThe accuracy of the three methods at estimating p D can be seen immediately from the di erent posterior approximations EP using either the exact update or the fast update is the most accurate Even ADF the rst iteration of EP is very accurate The success of the fast update illustrates that it is sometimes good to consider criteria other than KL divergence"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4543,
                                "start": 4535
                            }
                        ],
                        "text": "This chapter describes prior work in approximate Bayesian inference The outline is\nNumerical quadrature\nMonte Carlo methods importance sampling Gibbs sampling\nLaplace s method\nVariational bound on the integral using Jensen s inequality\nVariational bound on the integrand variational Bayes\nStatistical physics methods\nSequential ltering\nThe classical approach to numerical integration is quadrature Davis Rabinowitz In this deterministic approach the integrand is evaluated at several locations knots and a function is constructed that interpolates these values The interpolant is chosen from a simple family that can be integrated analytically e g polynomials or splines The integral of the interpolant approximates the desired integral and with enough knots the approximation can be made arbitrarily accurate By using a set of prede ned knots x xn the interpolation and integration procedure can be compiled down to a simple summation of weighted function values\nI\nZ A f x dx\nI nX i wif xi\nwhere the weights wi are known This method is excellent with integrands that are simple i e that are easy to interpolate In one dimension quadrature is nearly unbeatable But in high dimensions it is infeasible because of the vast number of knots required to get a good interpolant of a complex function In Bayesian inference problems the integrands are mostly zero except in small regions i e they are sparse which makes the situation even worse most of the knots will be wasted Newer deterministic techniques try to avoid these problems by exploiting more properties of the integrand than just its value at given points Another approach is nondeterminism\nNondeterministic i e Monte Carlo methods do not try to interpolate or otherwise approximate the integrand at all they merely appeal to the law of large numbers In the simplest approach we sample knots uniformly in the region of integration A The expected value E f x under such a sampling must be the desired integral I divided by the area of A Hence the estimate\nI jAj n nX i f xi\nwill converge to the true value given enough samples and this happens independent of dimensionality and independent of the complexity of f Thus while Monte Carlo is rather ine cient in low dimensions requiring thousands of knots when quadrature would only need around it is often the only feasible method in high dimensions In Bayesian inference problems the sparsity of the integrand can be addressed by the technique of importance sampling Instead of sampling uniformly in A we sample from a proposal distribution p x that matches the shape of jf j as well as possible Then the estimate\nI\nn nX i f xi p xi\nalso converges to I and much faster than would Importance sampling also has the advantage of working for in nite regions A Various enhancements to the basic importance sampling procedure are possible Ventura With importance sampling the di culties of numerical integration are replaced by the di culties of sampling from a complex distribu tion Good proposal distributions may be hard to sample from In this case one can apply Markov Chain Monte Carlo methods Neal Liu such as Metropolis sampling and Gibbs sampling In these methods we generate samples that are approximately from p x and then apply as before For these methods careful monitoring and restarting is required to ensure that the samples adequately represent p x The Billiard algorithm for Bayes Point Machines discussed in chapter is a particularly clever Markov Chain Monte Carlo algorithm\nTo learn about a function we can compute its value at a large number of knots but we could also compute a large number of derivatives at a single knot This is the basic idea of Taylor expansion By nite di erences a given number of knots translates into an equivalent number of derivatives so theoretically this approach has no advantage over quadrature But for Bayesian inference problems it has certain conceptual advantages Since the integrand is sparse it makes sense to focus on one area where the action is Interpolation is also simpler since we just match derivatives The most popular application of this idea in statistics is Laplace s method Kass Raftery where we expand log f about its mode\nlog f x log f x gT x x x x TA x x\ng\nd log f x\ndx\nx x\nH d log f x\ndxdxT\nx x\nBecause x is the mode g and we get\nf x f x exp x x TH x x\nI\nZ A f x dx f x rows H j Hj\nw p( D\n,w )\nExact Laplace\nw\np( D\n,w )\nExact Bound\na b\nw\np( D\n,w )\nExact EP\nc\nFigure Deterministic methods for integration try to approximate the integrand a Laplace s method uses a Gaussian that has the correct curvature at the mode It produces approximations that are too local b In one type of variational bound the integrand is bounded everywhere It produces approximations that are too inaccurate c The proposed method Expectation Propagation tries to minimize KL divergence a global measure of deviation It produces the most accurate integrals\nWhat Laplace s method does is approximate f by a scaled Gaussian density that matches the value rst derivative and second derivatives of f at x Figure shows an example The drawback of this method is that it is di cult to use higher order derivatives resulting in an approximation that is limited in its accuracy and scope\nVariational bounding is a deterministic approach more global than Laplace s method We start by introducing an arbitrary function q x\nI\nZ x q x f x q x dx\nJensen s inequality for convex functions says that in the case of logarithm\nlog Z x q x g x dx Z x q x logg x dx\nif Z x q x dx\nCombining and gives the following bound on I\nI exp Z x q x log f x q x dx\nThis of course requires that f x is positive a condition that is satis ed for most but not all integrals in Bayesian inference We are free to choose q x to get the tightest bound which corresponds to maximizing the right hand side of Note that this is equivalent to minimizing the reversed KL divergence\nD q jj f Z x q x log q x f x dx\nover q subject to the constraint If q x is unconstrained the maximum is achieved at q x f x and the bound matches the original integral To achieve a simpli cation in the integral we must constrain q x in some way Typically q x is constrained to be Gaussian Hinton van Camp Barber Bishop Seeger but mixture distributions have also been suggested Jaakkola Jordan c Having a lower bound is useful since it provides a rm guarantee about the true value of the integral something none of the other methods can do However it tends to be very computational and is feasible in a limited number of cases Jensen s inequality takes advantage of the fact that log f x is often easy to integrate when f x is not But this is not always true For example in a mixture problem such as discussed in chapter f is a product of sums which does not simplify under a logarithm And in chapter the likelihood is a step function which reaches zero The step function could be softened into a sigmoid to make the Jensen bound well de ned but we could not expect a good t to result\nA less accurate but simpler way to obtain a variational bound is to bound the integrand and then integrate the bound\nf x g x for all x I Z x g x dx\nFigure shows an example Unlike the previous variational method this approach can be used in mixture problems This approach was used explicitly by Jaakkola Jordan a b and implicitly by Waterhouse et al Attias Ghahramani Beal under the name variational Bayes The implicit approach introduces hidden variables to de ne a bound Start by writing f x in terms of h x y\nf x\nZ y h x y dy\nApply the Jensen bound to get\nI Z x y h x y dydx\nexp Z x y q x y log h x y q x y dydx\nAt this point we constrain q x y to factor into separate functions for x and for y\nq x y qx x qy y\nwith no other constraints on functional form The qx and qy functions are iteratively optimized to maximize the value of the bound To see that this is equivalent to note that for any qy we can solve analytically for the optimal qx which is\nqx x g x R\nx g x dx\nwhere g x exp Z y qy y log h x y qy y dy\nWhen we substitute this qx the bound becomes\nI Z x g x dx\nRegardless of which approach we use implicit or explicit we can optimize the bound via the EM algorithm This is described in Minka c\nBesides variational bounds there are other integration techniques that are inspired by mean eld statistical physics Most of these are extensions of TAP such as the cavity method Opper Winther a Bethe approximation Yedidia and Plefka ex pansion Kappen Wiegerinck So far they have been applied to regular structures such as the Boltzmann machine and rarely to general probabilistic models where it is less obvious how to apply them An exception to this is the paper by Opper Winther c The algorithm they derive is new and accurate yet coincides with the framework proposed in this thesis It will be interesting to see what other algorithms come out of this mean eld line of research\nFor approximating an integral we thus nd ourselves in the following position We have methods that work well for simple functions in low dimensions quadrature and complex functions in high dimensions Monte Carlo We have methods that are simple and fast but inaccurate Laplace s method variational Bayes We have methods that apply in special cases Jensen bound TAP What is missing is a general and accurate deterministic method in high dimensions at least for simple functions That is what this thesis provides\nThe approach taken by this thesis continues the path started by the extended Kalman lter EKF The EKF is a sequential method developed for inference in dynamical systems with nonlinear dynamics It is not a general method for integration But there are several variations on the EKF Maybeck that have promise One is sequential Monte Carlo a family of nondeterministic techniques Liu Chen Carpenter et al Another is the assumed density lter a general deterministic method that approximately minimizes the KL divergence D f jj g between f x and its approximation g x as shown in gure The next chapter discusses the assumed density lter and its extension to Expectation Propagation"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1274,
                                "start": 1266
                            }
                        ],
                        "text": "This thesis has developed a family of algorithms for approximate inference based on ex tending assumed density ltering ADF to use iterative re nement This extension removes all order dependence from ADF and increases its accuracy The family includes loopy be lief propagation in Bayesian networks and extends it to allow approximate messages for reduced computation as well as more elaborate messages for increased accuracy For in ference in the Bayes Point Machine it includes the algorithm of Opper Winther c and provides an alternative to the costly billiard algorithm\nThe accuracy of the Expectation Propagation family was demonstrated on a variety of examples with most emphasis on the Bayes Point Machine\nSection For the clutter problem in one dimension EP was in well behaved cases times more accurate than its nearest competitor Laplace s method both in estimating the posterior mean and the normalizing constant p D In other cases when the true posterior was strongly multimodal EP did not converge at all while Restricted EP and other deterministic methods lagged behind Monte Carlo The computational cost of EP is slightly higher than Laplace s method but much less than Monte Carlo\nSection For marginalizing the mixing weight in a mixture density of two Gaussians EP was again times more accurate than Laplace s method its nearest competitor With modi cations inspired by Cowell et al EP is also faster than Laplace s method In this problem the posterior is always unimodal in fact log convex which may explain why EP always converged\nSection On a toy dataset where the Bayes Point Machine is very di erent from the Support Vector Machine EP delivers high accuracy at a fraction of the cost of its competitor the billiard algorithm The accuracy of EP degrades when points are clustered together but even then it still beats the billiard algorithm with respect to cost On separable problems the posterior is unimodal and EP seems to always converge\nSection EP is also accurate in situations that the billiard algorithm cannot handle namely when there is label noise This was demonstrated on a toy dataset more de tailed experiments showing that EP achieves theoretical bounds are given by Winther since his algorithm is equivalent to EP\nSection On benchmark datasets with around points and - features EP achieves test set error rates consistent with the billiard algorithm Beating the SVM on out\nof datasets EP realizes in practice the theoretical gains expected with a Bayesian approach\nMany opportunities for future work are available both within the framework of EP as well as beyond it First how e ective is EP for other statistical models& For example is it useful for inference in coupled hidden Markov models sigmoid belief networks Barber Sollich and dynamic trees Storkey & Is EP e ective for Bayesian parameter estimation of classi cation models beyond linear classi ers e g hidden Markov models& Is any deterministic method e ective for nonparametric models such as Dirichlet processes Rasmussen &\nSecond can we anticipate how EP will perform& Can EP provide an estimate of its error& The experiments in this paper always used the ADF initialization Are the xed points of EP unique or does initialization matter& What causes EP to diverge& Can it be made to always converge& Can EP be made to give reasonable approximations to multimodal posteriors&\nCan EP be made to run faster especially for the Bayes Point Machine& This thesis compared EP to the original quadratic programming implementation of the Support Vector Machine But much faster specialized algorithms for the SVM are now available due to intense research Can we exploit special properties of the Bayes Point Machine to speed up EP& For example can we represent the A matrix in a sparse fashion& Can we identify the terms that need to be re ned& Having an error estimate for EP could facilitate this\nIs it optimal to minimize KL divergence at each step or should we use some other criterion& The modi ed update inspired by Cowell et al shows that we may obtain computational speedups with other criteria But improvements in accuracy may also be possible if we replace the greedy KL criterion with something that incorporates lookahead For example if we know the posterior has heavy tails and we are approximating it with a Gaussian then we may choose to use a Gaussian with in ated variance to better account for the tails\nThe entire di erence between EP and ADF is that EP makes better choices for the approximate terms !ti But both algorithms base their choices on the old posterior q x which is assumed to be accurate If the true posterior is multimodal then q x cannot possibly be accurate Could we propagate additional information about q x to use in choosing !ti&\nCan iterative re nement be applied to other ltering algorithms& For example some variants of ADF do not use the exponential family Cowell et al approximate a mixture posterior with a smaller mixture after processing each data point see also the generalized pseudo Bayes algorithms in Murphy Frey et al approximate the discrete posterior with an arbitrary tree structured distribution Conventional EP is not practical with these kinds of approximations because the equivalent terms !ti x qnew x q x do not simplify\nYedidia et al give a generalization of belief propagation that is di erent from the generalization a orded by EP Their algorithm propagates exact marginals and pairwise marginals which gives it high accuracy but also limits its practicality Can it be extended to allow approximate messages as in EP& Is there a common parent of their algorithm and EP&\nBayesian inference is a fertile area for developing numerical integration algorithms espe cially deterministic ones because of the rich problem structure and prior knowledge about the functions being integrated There is also relatively little research on it compared to\noptimization for example Many researchers are swayed enough by this imbalance to use inferior techniques such as maximum likelihood estimation because they only involve op timization As argued in this thesis it doesn t have to be that way And I anticipate that there are even better integration algorithms out there waiting for someone to discover them"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1362,
                                "start": 1354
                            }
                        ],
                        "text": "One of the major obstacles to using Bayesian methods for pattern recognition has been its computational expense This thesis presents an approximation technique that can per form Bayesian inference faster and more accurately than previously possible This method Expectation Propagation uni es and generalizes two previous techniques assumed density ltering an extension of the Kalman lter and loopy belief propagation an ex tension of belief propagation in Bayesian networks The uni cation shows how both of these algorithms can be viewed as approximating the true posterior distribution with a simpler distribution which is close in the sense of KL divergence Expectation Propagation exploits the best of both algorithms the generality of assumed density ltering and the accuracy of loopy belief propagation\nLoopy belief propagation because it propagates exact belief states is useful for lim ited types of belief networks such as purely discrete networks Expectation Propagation approximates the belief states with expectations such as means and variances giving it much wider scope Expectation Propagation also extends belief propagation in the op posite direction propagating richer belief states which incorporate correlations between variables\nThis framework is demonstrated in a variety of statistical models using synthetic and real world data On Gaussian mixture problems Expectation Propagation is found for the same amount of computation to be convincingly better than rival approximation techniques Monte Carlo Laplace s method and variational Bayes For pattern recognition Expecta tion Propagation provides an algorithm for training Bayes Point Machine classi ers that is faster and more accurate than any previously known The resulting classi ers outperform Support Vector Machines on several standard datasets in addition to having a comparable training time Expectation Propagation can also be used to choose an appropriate feature set for classi cation via Bayesian model selection\nThesis Supervisor Rosalind Picard Title Associate Professor of Media Arts and Sciences"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 46
                            }
                        ],
                        "text": "Typically, q(x) is constrained to be Gaussian (Hinton & van Camp, 1993; Barber & Bishop, 1997; Seeger, 1999) but mixture distributions have also been suggested (Jaakkola & Jordan, 1999c)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 766,
                                "start": 758
                            }
                        ],
                        "text": "Classi cation using the Bayes Point\nThis chapter applies Expectation Propagation to inference in the Bayes Point Machine The Bayes Point Machine is a Bayesian approach to linear classi cation that competes with the popular but non Bayesian Support Vector Machine SVM Bayesian averaging of linear classi ers has been proven both theoretically and empirically optimal in terms of generalization performance Watkin Bouten et al Buhot et al But an e cient algorithm has remained elusive The Bayes Point Machine approximates the Bayesian average by choosing one average classi er the Bayes Point Watkin Rujan Herbrich et al Computing the Bayes Point is a simpler but still very di cult task\nThis chapter shows that Expectation Propagation using a full covariance Gaussian ap proximation to the posterior provides an accurate estimate of the Bayes Point an ap proximation to the full Bayesian average The algorithm turns out to be identical to what Opper Winther c derived by statistical physics methods However EP uses a dif ferent optimization scheme that is faster and does not require a stepsize parameter EP also provides an estimate of the evidence p D which is useful for feature selection but not provided by Opper Winther\nThe Bayes Point Machine\nThe Bayes Point Machine BPM is a Bayesian approach to linear classi cation A linear classi er classi es a point x according to y sign wTx for some parameter vector w the two classes are y Given a training set D f x y xn yn g the likelihood for w can be written\np Djw Y i p yijxi w Y i ) yiw Txi\n) z\nif z if z\nThis is a slight abuse of notation since p Djw is only a distribution for y not x This likelihood is if w is a perfect separator and otherwise A simple way to achieve linear separation is to progressively enlarge the set of features e g by computing squares and third powers until the data is separable in the new feature space This has the e ect of producing a nonlinear decision boundary in the original measurement space Feature expansion can be implemented e ciently using the kernel trick where we rewrite the algorithm in terms\nx1\nx2\nx1\nx2\na b\nFigure Two di erent classi cation data sets with label information removed The Bayes Point Machine assumes that without labels we cannot infer where the boundary lies In b one might be inclined to think that the horizontal axis determines the decision But the horizontal axis could easily be something irrelevant like the time of day the datum was collected Only domain knowledge can determine the validity of the assumption\nof inner products and perform the feature expansion implicitly via the inner product This technique will be described more fully later\nBecause it is conditional on xi this model assumes that the distribution of the x s is unrelated to the true decision boundary That is if we were given the x s without any labels we would have no information about where the boundary lies The validity of this assumption must come from domain knowledge it cannot be determined from the data itself see gure The Support Vector Machine SVM for example does not seem to make this assumption Tong Koller show that the SVM follows from assuming that the x s follow a Gaussian mixture distribution in each class In addition some workers have used the SVM with unlabeled data Bennett Demiriz while the BPM by design cannot The advantage of assuming independence in the BPM is that we avoid stronger assumptions about the nature of the dependence and thus obtain a more general algorithm Experiments show it is quite robust section\nA re nement to the basic model is to admit the possibility of errors in labeling or measurement A labeling error rate of can be modeled using Opper Winther b\np yjx w ) ywTx ) ywTx ) ywTx\nUnder this model the likelihood p Djw for a given w will be r n r where r is the number of errors on the training set Only the number of errors is important not where they are This way of modeling errors can automatically reject outliers because it doesn t care how far an error is from the boundary Other approaches based on adding slack to the boundary only allow errors near the boundary and are sensitive to outliers These approaches can be simulated by using a smooth likelihood function such as\np yjx w ywTx where is the cumulative distribution function for a Gaussian The tails of this function fall like exp x so it provides quadratic slack The logistic function could also be\nused it falls like exp x providing linear slack By changing ) to one of these smooth functions the labeling error model can be combined with slack with no computational di culties However this chapter focuses on without slack\nTo complete our Bayesian model we need to specify a prior on w Since the magnitude of w is irrelevant for classi cation some authors have restricted w to the unit sphere in d dimensions and have given w a uniform distribution on the sphere Rujan This distribution is nice because it is fair to all decision boundaries but it is not very convenient to work with A more general non informative prior is an average over spheres Let r kwk be the magnitude of w Given r let w be uniformly distributed on the sphere of radius r This prior is non informative for any r It is also non informative if r is unknown with distribution p r For example p r could be uniform from to allowing w to live in the unit ball instead of on the unit sphere By choosing p r appropriately we can also give w a spherical Gaussian distribution\np w N I\nIt is a property of the spherical Gaussian distribution that conditional on any r w is uniformly distributed on the sphere of radius r so no particular decision boundary is favored by this prior\nGiven this model the optimal way to classify a new data point x is to use the predictive distribution for y given the training data\np yjx D Z w p yjx w p wjD dw\nHowever this requires solving an integral each time A practical substitute is to use a single value ofw which approximates the predictive distribution as well as possible Watkin and Rujan have de ned the Bayes point as the single best w However this point is di cult to nd Thus following Rujan we use the posterior mean for w E wjD Following convention we will be sloppy and also call this the Bayes point Our strategy will be to make a Gaussian approximation to the posterior and use its mean as the estimated Bayes point Of course if we really wanted to we could also use EP to solve the integral for each test point The normalizing constant of the posterior is also useful because as an estimate of p D it allows us to choose among di erent models see section\nTraining via ADF\nStart with the ADF updates ADF was previously applied to the Bayes Point Machine by Csato et al Divide the joint distribution p D w into n terms one for each data point Since y and x always appear multiplied together the formulas will drop y and assume that xi is already scaled by yi Let the approximate posterior have the form\nq w N mw Vw\nFrom minimizing the KL divergence we get the expectation constraints\nEqnew w E p w\nEqnew ww T E p ww T\nTo compute these expectations use the following relations obtained from integration by parts\nZ mw Vw\nZ w t w q w dw\nE p w mw Vwrm logZ mw Vw E p ww\nT E p w E p w T Vw Vw rmrTm rv logZ mw Vw Vw These hold for any t w For the Bayes Point Machine we have combining yx into x\nt w ) wTx z Z z N z dz\nz mTwxp xTVwx\nZ mw Vw z\np xTVwx\nN z z\nrm logZ mw Vw x rv logZ mw Vw mTwx\nxTVwx xxT\nrmrTm rv logZ mw Vw xxT mTwx\nxTVwx xxT\nmw Vw x\nTx\nxTVwx xxT\nThe ADF algorithm is thus\nInitialize mw Vw I the prior Initialize s the scale factor\nFor each data point xi update mw Vw s according to\nmneww mw Vw ixi\nVneww Vw Vwxi ix\nT i m new w\nxTi Vwxi\nVwxi\nT\nsnew s Zi mw Vw\nThe nal mw is the estimate of w used for classi cation Note that this algorithm does not require matrix inversion It is the same algorithm obtained by Csato et al except they expressed it in terms of kernel inner products which makes it more complex\nTraining via EP\nNow we turn the ADF algorithm into an EP algorithm By dividing two consecutive Gaus sian posteriors we nd that the term approximations are also Gaussian parameterized by mi and Vi\n!t w Z qnew w\nq w\nZ\nN mi mw Vi Vw N w mi Vi\nwhere V i V new w\nV w mi Vi V new w\nmneww ViV w mw mw Vi Vw V w m new w mw\nTo simplify this combine it with the ADF updates to get mi Vi directly from mw Vw\nVi\nix T i m new w xTi Vwxi xix T i\nVw\nmi mw Vi Vw ixi\nThe matrix ixTi m new w\nxT i Vwxi\nxix T i has one nonzero eigenvalue which means Vi will have one nite\neigenvalue in the direction of xi This makes sense because term i only constrains the projection of w along xi This special structure allows us to represent Vi with a scalar vi\nV i v i xix T i\nxTi Vixi vi\nFrom we know that\nxTi Vixi xTi Vwxi\nixTi m new w\nxTi Vwxi\nwhich means the update for vi is\nvi x T i Vwxi\nix T i m new w\nAnother consequence of this special structure is that instead of the full vector mi we only need the projection mTi xi which can be stored as a scalar mi\nNow we can write an e cient EP algorithm\nExcept for the prior the term approximations have the form\n!ti w si exp vi wTxi mi\nInitialize them to\nvi mi\nsi\nmneww V new w I the prior\nUntil all mi vi si converge changes are less than\nloop i n\na Remove !ti from the posterior to get an old posterior\nVw V new w v i xixTi Vneww V new w xi vi xTi Vneww xi Vneww xi T mw m new w VwV i m new w mi\nmneww Vwxi v i x T i m new w mi\nThese expressions involving Vw can be computed e ciently\nVwxi V new w xi\nvi\nvi xTi Vneww xi\nxTi Vwxi\nxTi V new w xi\nvi\nb Recompute mneww V new w Zi from mw Vw as in ADF c Update !ti\nvi x T i Vwxi\nixTi m new w\nmi x T i mw vi x T i Vwxi i\nsi Zi jVi Vwj\njVij exp\nmi mw T Vi Vw mi mw\nZi q v i x T i Vwxi exp xTi Vwxi\nxTi m new w\ni\nCompute the normalizing constant\nB mneww T Vneww\nmneww X i m i vi\np D jVneww j exp B nY i si\nThis algorithm processes each data point in O d time Assuming the number of iterations is constant which seems to be true in practice computing the Bayes point therefore takes O nd time Computing the normalizing constant at the end requires O d time\nEP with kernels\nTo use the kernel trick we need to rewrite EP in terms of inner products Following the notation of Opper Winther c de ne\ni x T i V ni wxi V ni w is the Vw when term i is left out\nCij x T i xj\n* diag v vn hi x T i m new w\nh ni i x T i m ni w\nFrom the de nition of qnew w as the product of approximate terms !ti w we know that\nVneww\nI X i xix T i vi\nI X* XT\nmneww V new w X j mjxj vj\nxTi m new w\nX j xTi V new w xj mj vj\nFrom the matrix inversion lemma we therefore have\nC * * * XTVneww X* XTVneww X * * C * *\nC *\nIn this way we can compute xTi V new w xj for any i j using only C and * The EP algorithm becomes\nInitialize vi mi si Initialize hi i Cii\nUntil all mi vi si converge\nloop i n\na Remove !ti from the posterior to get an old posterior\nh ni i hi iv i hi mi\nb Recompute part of the new posterior as in ADF\nz h ni ip i\nZi z i\np i\nN z z\nhi h ni i i i\nc Set\nvi i\nihi\nmi h ni i vi i i hi vi i\nsi Zi q v i i exp\ni i hi\nd Now that * is updated nish recomputing the new posterior\nA C *\nFor all i\nhi X j Aij mj vj\nfrom\ni\nAii vi\nfrom\nCompute the normalizing constant\nB X ij Aij mimj vivj\nX i m i vi\np D j*j\njC *j exp B\nnY i si\nThe determinant expression in follows from\njVneww j I X* XT I XTX*\nI C* j*jjC *j\nIn step it would appear that we need to invert a matrix taking O n time for each data point However since only one vi changes each time A can be updated incrementally in O n time Initialize A C and then update with\nAnew C * +*\nA aia T i\naii\nwhere\nvnewi voldi\nAssuming a constant number of iterations the algorithm thus runs in O n time plus the time to compute the inner product matrix C This is a great improvement over O nd if the dimensionality is very large e g if the feature set is arti cially expanded\nTo show the equivalence with Opper Winther s algorithm we make the following observations\nAt convergence will hold for all i so that X j mjxj vj X j hjxj vj X j jxj\nmneww X j mjxj vj\nI X\nj\nxjx T j\nvj\nAmneww X\nj\njxj\nmneww X j jxj\nhi X j j x T i xj\nX j Cij j\nThis is the equation Opper Winther use instead of\nThe update for i can be written\ni\nvi v i C * ii vi vi v i h C * i ii vi h C *\ni ii\nC * ii vi\nThis is the update Opper Winther use instead of\nEP computes a normalizing constant for the posterior while Opper Winther do not\nAll other updates are identical to those in Opper Winther c though carried out in a di erent order Reordering the updates does not matter as long as both algorithms converge\nThe input to the algorithm is simply the matrix C which can be computed using an arbitrary inner product function C xi xj instead of x T i xj However in that case we need to keep yi and xi separate Cij yiyjC xi xj\nUsing a nonlinear inner product function is an e cient way to use an expanded feature space since we don t have to represent each expanded data point We only have to compute the inner product between two expanded data points which is a scalar function of the original data\nThe output of the algorithm is the i which implicitly represent m new w through\nWith these we classify a new data point according to\nf x sign xTmneww sign X i iyiC x xi\nResults on synthetic data\nFigure a demonstrates the Bayes point classi er vs the SVM classi er on training points Besides the two dimensions shown here each point had a third dimension set at\nThis provides a bias coe cient w so that the decision boundary doesn t have to pass through Each classi er is set to zero label noise and zero slack The Bayes point classi er approximates a vote between all linear separators ranging from an angle of to The Bayes point chooses an angle in the middle of this range SVM chooses the decision boundary to maximize margin the distance to the nearest data point This makes it ignore the topmost data point In fact the Bayes point and SVM would coincide if that point were removed Adding the point reduces the set of linear separators and Bayesian inference must take this into account\nFigure plots the situation in parameter space For viewing convenience we restrictw to the unit sphere The exact Bayes point was computed by likelihood weighted sampling i e sampling a random w on the sphere and discarding those which are not separators EP provides an accurate estimate of the posterior mean mw and posterior covariance Vw Compare\nExact Vw\nEP Vw\nFigure b plots cost vs error for EP versus three other algorithms for estimating the Bayes point the billiard algorithm of Herbrich et al the TAP algorithm of Opper Winther c and the mean eld MF algorithm of Opper Winther c The error is measured by Euclidean distance to the exact solution found by importance sampling The error in using the SVM solution is also plotted for reference Its unusually long running time is due to Matlab s quadprog solver TAP and MF were slower to converge than EP even with a large initial step size of As expected EP and TAP converge to the same solution\nThe billiard algorithm is a Monte Carlo method that bounces a ball inside the region de ned by hyperplane constraints It must be initialized with a linear separator and the SVM was used for that purpose Since there are many other ways one could initialize the billiard which may be much cheaper the initialization step was not counted against the billiard s FLOP count otherwise the billiard curve would be right of the SVM point The error axis must also be interpreted carefully While it is tempting to use the lower envelope of the curve as the measure of error it is actually more accurate to use the upper envelope since this is all that the algorithm can consistently achieve as samples accumulate Nevertheless it is clear that EP is much faster and more accurate\nLaplace s method and variational Bayes do not work at all on this problem Laplace fails because the derivatives of the likelihood are not informative they are either zero or in nity Variational Bayes fails for because no Gaussian can lower bound the likelihood Gaussians never reach zero Even with a Gaussian bound must be quite narrow so we can t expect competitive performance\nHerbrich Graepel point out that the SVM is sensitive to scaling an input vector i e if we replace x by x then the solution will change They argue theoretically and empirically that data vectors should therefore be normalized to unit length before SVM training This is quite a shock since no mention of this was made in the original SVM papers If the data in gure including the bias dimension is normalized before training then the SVM solution tilts slightly toward the BPM solution supporting Herbrich Graepel s suggestion The Bayes Point Machine by contrast does not require any normalization because the data likelihood is correctly invariant to scaling an input vector The solution found by EP is also invariant\nSVM Bayes\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u22124\n10 \u22123\n10 \u22122\n10 \u22121\n10 0\nEP\nBilliard\nSVM\nMF\nTAP\nFLOPS\nE rr\nor\nFigure left Bayes point machine vs Support Vector Machine on a simple data set The Bayes point more closely approximates a vote between all linear separators of the data right Cost vs error in estimating the posterior mean ADF is the rst x on the EP curve\nFigure left The same problem viewed in parameter space the unit sphere Each data point imposes a linear constraint giving an odd shaped region on the sphere The Bayes point is the centroid of the region The EP estimate is indistinguishable from the exact Bayes point on this plot right The Gaussian posterior approximation obtained by EP rendered as a one standard deviation isoprobability ellipsoid\n10 2\n10 3\n10 4\n10 5\n10 6\n10 \u22122\n10 \u22121\n10 0\nEP\nBilliard\nSVM\nMF\nTAP\nFLOPS\nE rr\nor\nFigure Cost vs error for the point problem with one point replicated times\nThe linear classi cation problem is special in that some points can have large in uence on the solution while adjacent points have zero in uence This is because the constraints imposed by the latter points may be redundant given the constraints already imposed by other points This property allows the support vector machine to focus on a small number of points the support vectors when nding its solution Unfortunately this property can cause havoc with EP EP uses Gaussians to smooth out the hard constraints and cannot always recognize when a point is redundant and should be ignored The result is that clusters of points can degrade the EP estimate Figure shows what happens to gure b when the point at is replicated times As expected the cluster of points counts more than it should making the EP boundary move slightly away from it The accuracy of EP TAP and MF degrades signi cantly while SVM and Billiard are unchanged On the bright side the error cannot be made arbitrarily high using more than replications or replicating the other points does not degrade the accuracy any further One work around for this behavior would be to reduce the dataset in advance e g to just the support vectors This idea has not been tested yet\nFigure compares the EP solution to the exact posterior mean when noisy labels are allowed Theoretically this integral is harder since we have to consider the entire parameter space not just perfect separators EP can handle it with no additional cost The solution comes out vertical because it is a compromise between the small set of perfect separators at and the larger set of boundaries between and which have one error There is also a set of boundaries past which also have one error On this dataset a similar result can be achieved with the SVM if we set the slack parameter C though this would not necessarily be true on another dataset Winther has given extensive evaluations of EP with and on synthetic datasets showing that it achieves the theoretical performance of Bayesian averaging Those experiments are not repeated here\nFigure demonstrates EP with a nonlinear kernel contrasting it to the SVM solution\n\u22121 \u22120.5 0 0.5 1 1.5 2 \u22121\n\u22120.5\n0\n0.5\n1\n1.5\n2\nExactEP\nFigure The EP solution has good agreement with the exact posterior mean when noisy labels are allowed\nwith the same kernel The kernel was Gaussian\nC xi xj exp\nxi xj T xi xj\nwith width parameter and The feature expansion equivalent to this kernel has an in nite number of features The SVM is quite sensitive to the choice of as well as the idiosyncrasies of the dataset This is related to the sparsity of the SVM solution when the boundary depends on only a few data points i e a few Gaussian kernels small changes in those kernels have a larger e ect on the boundary Similar results obtain if we use a polynomial kernel\nC xi xj x T i xj\np\nFor large p the boundaries are almost identical to those for a wide Gaussian kernel\nBPM SVM\nBPM SVM\nnarrow Gaussian kernel wide Gaussian kernel\nFigure Classi cation boundaries resulting from Support Vector Machine training vs Bayes Point Machine training with EP Both used a Gaussian kernel with the same width parameter left Narrow width The SVM tends to put extra bumps and kinks in the boundary right Wider width The SVM chooses an unusual solution in order to maximize margin in the expanded space The BPM boundary is non sparse all i but smoother It is hardly a ected by changing the kernel width Billiard gives results similar to EP\nResults on real data\nFor higher dimensional problems it is more di cult to compute the exact Bayes point and make cost vs accuracy comparisons So instead we ll measure cost vs test performance on benchmark problems\nFigure compares EP Billiard and SVM on discriminating handwritten digit from Each data point xi is an binary image dimensions The dataset was randomly split times into a small training set of points and a test set of points All algorithms were linear and set for zero noise Billiard was run for iterations which is far more computation than EP or SVM used Nevertheless EP is best\nFigures and show the same type of comparison on four datasets from the UCI repository Blake Merz Each dataset was randomly split times into a training set and test set in the ratio , , In each trial the features were normalized to have zero mean and unit variance in the training set The classi ers used zero label noise and a Gaussian kernel with Billiard was run for iterations The thyroid dataset was made into a binary classi cation problem by merging the di erent classes into normal vs abnormal Except for sonar EP and Billiard beat the SVM a majority of the time and in all cases EP performed similarly to Billiard However the running time for Billiard is signi cantly higher since it must be initialized at the SVM solution Figure shows cost vs test error curves on some typical runs The SVM using quadprog is particularly slow on thyroid The unusual success of the SVM on sonar was also reported by Herbrich et al and may be related to the di erent assumptions made by the SVM see section\nTo give an idea of the actual running time in Matlab gure plots the training time vs training set size for trials As expected the time scales as n Extrapolating from this it would take an hour for data points and weeks for data points Finding a way to speed up EP similar to the way that quadratic programming can be sped up for the SVM will be essential for large data sets\n30 40 50 60 70 80 35\n40\n45\n50\n55\n60\n65\n70\nSVM\nE P\nTest errors\n30 40 50 60 70 35\n40\n45\n50\n55\n60\n65\n70\nBilliard\nE P\nTest errors\nFigure Test error of SVM vs EP left and Billiard vs EP right on digit classi cation over random train'test splits Each point is test error for SVM'Billiard test error for EP Points under the line correspond to trials where EP had a lower test error EP beat SVM times and beat Billiard times despite being the fastest of all three algorithms of this dataset\nHeart features training points\n0.15 0.2 0.25 0.3\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\n0.26\n0.28\n0.3\n0.32\nSVM\nE P\nTest errors\n0.15 0.2 0.25 0.3\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\n0.26\n0.28\n0.3\n0.32\nBilliard\nE P\nTest errors\nThyroid features training points\n\u22120.05 0 0.05 0.1 0.15 \u22120.05\n0\n0.05\n0.1\n0.15\nSVM\nE P\nTest errors\n\u22120.05 0 0.05 0.1 0.15 \u22120.05\n0\n0.05\n0.1\n0.15\nBilliard\nE P\nTest errors\nFigure Test error rates over train'test splits Each point is test error for SVM'Billiard test error for EP Points under the line correspond to trials where EP had a lower test error For running times see gure\nIonosphere features training points\n0.05 0.1 0.15 0.2\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\nSVM\nE P\nTest errors\n0.05 0.1 0.15 0.2 0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\nBilliard\nE P\nTest errors\nSonar features training points\n0.05 0.1 0.15 0.2\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\nSVM\nE P\nTest errors\n0.05 0.1 0.15 0.2\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\nBilliard\nE P\nTest errors\nFigure Test error rates over train'test splits Each point is test error for SVM'Billiard test error for EP for one trial Points under the line correspond to tri als where EP had a lower test error For running times see gure\nHeart Thyroid\n10 7\n10 8\n10 9\n0.21\n0.22\n0.23\n0.24\n0.25\n0.26\n0.27\n0.28\n0.29\n0.3\nEP\nBilliard\nSVM\nFLOPS\nT es\nt e rr\nor\n10 7\n10 8\n10 9\n10 10\n0\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\nFLOPS\nT es\nt e rr\nor\nSVM\nEP Billiard\nIonosphere Sonar\n10 7\n10 8\n10 9\n10 10\n0.08\n0.1\n0.12\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\nFLOPS\nT es\nt e rr\nor\nSVM\nEP\nBilliard\n10 6\n10 7\n10 8\n10 9\n0.14\n0.16\n0.18\n0.2\n0.22\n0.24\n0.26\n0.28\n0.3\nFLOPS\nT es\nt e rr\nor\nSVM EP\nBilliard\nFigure Cost vs test error on a typical trial for each dataset\n0 200 400 600 800 0\n5\n10\n15\n20\n25\nTraining set size\nT ra\nin in\ng tim\ne (m\nin s)\nFigure Actual training time in Matlab for EP with kernels for di erent dataset sizes It nearly perfectly follows n growth The time to compute the inner product matrix is not included\nModel selection\nThis section reports results on Bayesian model selection using the estimated evidence p D This is a unique feature of EP because the billiard algorithm cannot provide an estimate of p D By maximizing the evidence we can select the appropriate feature set feature kernel or noise parameter For background on Bayesian model selection see MacKay Kass Raftery Minka a A popular approach to model selection for the SVM is to minimize R\nM where R is the radius of the smallest ball containing the training\nset measured in the mapped feature space and M is the margin Cristianini et al Another approach is to minimize the span bound given by thresholding the s Chapelle Vapnik Chapelle et al\nS X\nsupport vectors i\n) i h C sv i ii\nThese three criteria evidence margin and span can lead to quite di erent results Figure shows a synthetic training set classi ed according to distance from the origin i e the true decision boundary is a circle Three di erent decision boundaries result from training an SVM with three di erent kernels the decision boundaries from EP are nearly identical All of these boundaries achieve zero error so we need to invoke some other rule besides training error to select among them Over all Gaussian kernels the margin criterion is minimized by taking This produces a decision boundary with spurious kinks and bumps The span bound is minimized by an even narrower kernel where the bound is By contrast the best Gaussian kernel according to evidence has providing a much smoother and more realistic boundary The quadratic kernel which is the closest to the true boundary has even greater evidence yet less margin\nIn the noise free case the Bayesian evidence p D has a natural interpretation It is the fraction of perfect separators out of all representable classi ers If a particular set of features has a large percentage of perfect separators then we intuitively should have more faith in that feature set This is what Bayesian model selection does and in choosing the Bayes point we follow the same basic argument Maximizing the margin does not necessarily behave this way\nThe next example repeats the feature selection experiment of Weston et al Chapelle et al Synthetic data with six features was created by rst sampling y with equal probability and then setting\nx N y x N y x N y x N x N x N\nWith probability features x -x were swapped with features x -x Thus all six features are relevant to some degree To these six relevant features are appended irrelevant features with distribution N The test is to see whether we can reject the irrelevant features In Chapelle et al the algorithm was forced to keep only two features Here we use a more rigorous test features are added one by one starting with the relevant ones\nGaussian Gaussian\nKernel R M span log p D\nquadratic\nQuadratic\nFigure A dataset classi ed with three di erent kernels The margin criterion R M prefers the solution while the Bayesian evidence p D prefers the quadratic solution The span bound prefers a Gaussian with tiny not shown The true boundary is a circle\n0 5 10 15 20 10\n15\n20\n25\n30 35 M ar gi n bo un d\nNumber of features 0 5 10 15 20\n0\n1\n2\n3\n4\n5\n6\n7\nS pa\nn bo\nun d\nNumber of features\n0 5 10 15 20 \u221215\n\u221214\n\u221213\n\u221212\n\u221211\n\u221210\n\u22129\n\u22128\n\u22127\nE P\ne vi\nde nc\ne\nNumber of features\nFigure Feature selection curves for the margin bound span bound and Bayesian evidence The Bayesian evidence has a clear peak at six the correct answer The other criteria which are to be minimized do not perform as well The margin bound has only a local minimum at six and the span bound only a local minimum at ve\nand the algorithm must decide when to stop Figure shows the curves for the margin bound span bound and Bayesian evidence Both the SVM and BPM used a linear kernel with zero slack The Bayesian evidence is clearly a better measure of relevance\nFigure a Conventional billiard algorithms allow the ball to escape They project the collision point onto the surface of the sphere but preserve the rebound velocity dashed line b The new algorithm works inside the sphere using the sphere s surface as an additional wall\nA better billiard algorithm\nA major drawback of current billiard algorithms is that they do not really operate on the sphere The billiard ball always follows a straight line trajectory until it hits a wall at which point it is projected back onto the sphere gure a Unfortunately this means the ball can sometimes leave the sphere without ever hitting a wall On the point problem in gure this happens on , of the bounces Rujan recovers from this by restarting the billiard at its initial point with a random velocity Unfortunately this introduces severe bias in the estimate by overcounting the initial point Herbrich et al have a better solution leave the ball where it is but choose a new random velocity This has less bias but doesn t resemble a billiard anymore\nThe problem of escaping billiard balls can be avoided entirely if we simply rede ne the pool Remember that the unit sphere was an arbitrary choice we can use any prior distribution that assigns equal probability to all w vectors of a given length So let s use the inside of the unit sphere as shown in gure b The sphere s surface is an additional wall that prevents escape The new algorithm is\nDetermine the next collision From position w and velocity v compute the ight time to each wall and take the minimum The distance from wall xi is\ndi wTxiq xTi xi\nand the velocity normal to xi is\nvi vTxiq xTi xi\nso the ight time is\ni\ndivi if vi otherwise\nThe ight time to the surface of the sphere satis es\nw v T w v\nq wTv vTv wTw wTv\nvTv\nwhich is always positive and nite\nUpdate the position of the ball the total distance traveled s and the center of mass estimate m\nwnew w v min\nz kwnew wk mnew s\ns z m\nz\ns z\nwnew w\nsnew s z\nUpdate the velocity If xi was hit\nvnew v vi xiq xTi xi\nIf the surface of the sphere was hit\nvnew v wnew wnew Tv\nThe length of v is unchanged by these updates so if we initialize vTv it will stay that way throughout the algorithm\nThe algorithm can also be made use a kernel inner product as in Herbrich et al With this algorithm we can run one billiard trajectory without ever restarting However that is not a good idea because the pool is not perfectly ergodic By periodically randomiz ing the velocity of the ball we can achieve a more ergodic sampling Periodic randomization is important in all Markov chain Monte Carlo schemes including Gibbs sampling For the billiard randomization at every bounces seems to work well\nFigure compares the three algorithms on the point problem of section Each was run for iterations using a comparable number of ops Because of its bias Rujan s algorithm is never more accurate than in Euclidean distance to the true value Herbrich s algorithm does better but also seems to level o at The new algorithm with randomization every bounces converges nicely These characteristics are typical and hold across many di erent runs on this dataset\n10 2\n10 4\n10 6\n10 \u22123\n10 \u22122\n10 \u22121\n10 0\nRujan\nHerbrich\nNew\nFLOPS\nE rr\nor\nFigure Cost vs error of conventional billiard algorithms vs the new algorithm"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2249,
                                "start": 2241
                            }
                        ],
                        "text": "The dominant computational task in Bayesian inference is numerical integration New methods for fast and accurate integration are therefore very important and can have great impact This dissertation presents a new deterministic approximation framework Expecta tion Propagation which achieves higher accuracy than existing integration algorithms with similar computational cost\nThe general scenario of Bayesian inference is that there is some observed data and some unobserved quantity of interest Inferences about the unknown x are based on its posterior distribution given the observed D\np xjD p x D p D\np x D R\nx p x D dx\nFor example we may want to know the posterior mean and variance of the unknown which are integrals over the posterior\nE xjD Z x xp xjD dx\nR x xp x D dxR x p x D dx\nE x jD Z x x p xjD dx\nR x x\np x D dxR x p x D dx\nvar xjD E x jD E xjD\nIn real situations there are many unknowns not just the one we are interested in In Bayesian inference these must be marginalized out of the joint distribution which involves yet more integrals\np xjD R y z p x y z D R x y z p x y z D\nThus numerical integration goes hand in hand with practical Bayesian inference Numerical integration algorithms can be principally divided into deterministic vs non deterministic methods Deterministic methods try to approximate the integrand with some thing whose integral is known exactly They work from properties of the integrand like its maxima and curvature Nondeterministic methods sample the integrand at random points to get a stochastic estimate of the integral This approach is more general since it works for almost any integrand but it also requires a great deal more computation than deterministic approximation\nThe proposed method Expectation Propagation is a deterministic approximation method It is an extension to assumed density ltering ADF Maybeck Lauritzen Bernardo Giron Stephens Boyen Koller b Barber Sollich Opper Winther Frey et al a one pass sequential method for comput ing an approximate posterior distribution In ADF observations are processed one by one updating the posterior distribution which is then approximated before processing the next observation For example we might replace the exact one step posterior with a Gaussian having the same mean and same variance Maybeck Lauritzen Barber Sol lich Opper Winther Or we might replace a posterior over many variables with one that renders the variables independent Boyen Koller b or approximates them as Markovian Frey et al In each case the approximate posterior is found by minimizing KL divergence which amounts to preserving a speci c set of posterior expecta tions Note that the statistical model in question need not be a time series model and the processing order of observations need not correspond with time of arrival The weakness of ADF stems from its sequential nature information that is discarded early on may turn out to be important later Even if ADF is augmented with a backward pass Boyen Koller a this information cannot be recovered ADF is also sensitive to observation ordering which is undesirable in a batch context\nExpectation Propagation EP extends ADF to incorporate iterative re nement of the approximations by making additional passes The information from later observations re nes the choices made earlier so that the most important information is retained When the re nement converges the resulting posterior is independent of ordering and more accurate Iterative re nement has previously been used in conjunction with sampling Koller et al and extended Kalman ltering Shachter Expectation Propagation di ers by applying this idea to the deterministic approximation of general distributions not just Gaussian distributions as in Shachter EP is more expensive than ADF by only a constant factor the number of re nement passes typically or As shown in chapter the accuracy of EP is signi cantly better than ADF as well as rival approximation methods Monte Carlo Laplace s method and variational Bayes\nThinking in this framework has a number of bene ts For example in belief networks with loops it is known that approximate marginal distributions can be obtained by iterating the belief propagation recursions a process known as loopy belief propagation Frey MacKay Murphy et al As described in chapter it turns out that this heuristic procedure is a special case of Expectation Propagation where the approximate posterior is a completely disconnected network with no other constraints on functional form In other words loopy belief propagation is a direct generalization of the ADF algorithm of Boyen Koller b\nExpectation Propagation can therefore be seen as a way of generalizing loopy belief propagation to less restrictive approximations that are not completely disconnected and to useful constraints on functional form such as multivariate Gaussian Partially disconnected approximations are useful for improving accuracy just as in variational methods Jordan et al while constraints on functional form are useful for reducing computation Instead of propagating exact belief states which may be intractable EP only needs to propagate expectations relevant to the chosen approximating distribution e g means and variances Hence the name Expectation Propagation\nExpectation Propagation also has connections to statistical physics techniques Yedidia et al have shown that belief propagation tries to minimize an approximate free en ergy on discrete networks This is known as the TAP approach in statistical physics Opper\nWinther a have generalized the TAP approach to networks with mixed continuous and discrete nodes via the cavity method and applied it to Gaussian process classi ers Opper Winther c Chapter shows that Opper Winther s algorithm which has excellent performance is a special case of Expectation Propagation where the posterior approximation is Gaussian In this sense Expectation Propagation as a generalization of belief propagation parallels the cavity method as a generalization of TAP\nExpectation Propagation as a general framework for approximate Bayesian inference can be applied to many real world tasks Chapter demonstrates its use for the general task of discriminating objects into classes Classi cation via Bayesian averaging has long been popular in the theoretical community but di cult to implement in a computationally competitive way An excellent example of this is the Bayes Point Machine Rujan Herbrich et al With Expectation Propagation the advantages of Bayesian averaging can be achieved at less expense than previously possible\nIn short\nChapter reviews the prior work in approximate Bayesian inference excluding ADF Chapter reviews ADF and introduces Expectation Propagation Both are illustrated on simple statistical models\nChapter addresses belief networks describing how loopy belief propagation is a special case of Expectation Propagation and how belief propagation may be extended\nChapter applies Expectation Propagation to the Bayes Point Machine classi er Chapter summarizes the results and o ers suggestions for future work on Expecta tion Propagation"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian model selection for support vector machines"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 3
                            }
                        ],
                        "text": "In Chapelle et al. (2000), the algorithm was forced to keep only two features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 8
                            }
                        ],
                        "text": "(2000); Chapelle et al. (2000). Synthetic data with six features was created by first sampling y = \u00b11 with equal probability and then setting X1 = A (y, 1) (5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 77
                            }
                        ],
                        "text": "Another approach is to minimize the span bound given by thresholding the a's (Chapelle & Vapnik, 1999; Chapelle et al., 2000):"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Choosing kernel parameters for support vector machines"
            },
            "venue": {
                "fragments": [],
                "text": "http: //www. ens-lyon. fr/ochapell/"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1522,
                                "start": 50
                            }
                        ],
                        "text": "In fact, it is the form used in in factor graphs (Kschischang et al., 2000). All of the nodes that participate in a conditional probability table p(X jpa(X)) send messages to each other based on their partial belief states. This algorithm applies generally to any decomposition into terms ti(x), not just that given by (4.18). For example, equivalence also holds for undirected networks, if the terms ti are the clique potentials|compare to the equations in Yedidia et al. (2000). See section 4.2 for an example with an undirected network. The remaining di erence between belief propagation and EP is that belief propagation does not specify the order in which messages are sent. In the EP algorithm above, each node must exchange messages with all of its parents at each step. However, we can relax this condition by considering a simple variation of EP, where we do not minimize KLdivergence completely at each step, but only partially. Speci cally, we only update one of the ~ tik functions each time. With this variation, we can pass messages in any order. This reordering will not change the result at convergence. This equivalence shows that there is a close connection between Boyen & Koller's algorithm and loopy belief propagation. Boyen & Koller's algorithm for dynamic Bayesian networks is simply one pass of loopy belief propagation where each term ti is the product of multiple conditional probability tables|all of the tables for a given timeslice. This equivalence was also noticed by Murphy & Weiss (2000), though described in terms of modi cations to the graph."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 49
                            }
                        ],
                        "text": "In fact, it is the form used in in factor graphs (Kschischang et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 480,
                                "start": 50
                            }
                        ],
                        "text": "In fact, it is the form used in in factor graphs (Kschischang et al., 2000). All of the nodes that participate in a conditional probability table p(X jpa(X)) send messages to each other based on their partial belief states. This algorithm applies generally to any decomposition into terms ti(x), not just that given by (4.18). For example, equivalence also holds for undirected networks, if the terms ti are the clique potentials|compare to the equations in Yedidia et al. (2000). See section 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Factor graphs and the"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9454,
                                "start": 9451
                            }
                        ],
                        "text": "This chapter describes prior work in approximate Bayesian inference The outline is\nNumerical quadrature\nMonte Carlo methods importance sampling Gibbs sampling\nLaplace s method\nVariational bound on the integral using Jensen s inequality\nVariational bound on the integrand variational Bayes\nStatistical physics methods\nSequential ltering\nThe classical approach to numerical integration is quadrature Davis Rabinowitz In this deterministic approach the integrand is evaluated at several locations knots and a function is constructed that interpolates these values The interpolant is chosen from a simple family that can be integrated analytically e g polynomials or splines The integral of the interpolant approximates the desired integral and with enough knots the approximation can be made arbitrarily accurate By using a set of prede ned knots x xn the interpolation and integration procedure can be compiled down to a simple summation of weighted function values\nI\nZ A f x dx\nI nX i wif xi\nwhere the weights wi are known This method is excellent with integrands that are simple i e that are easy to interpolate In one dimension quadrature is nearly unbeatable But in high dimensions it is infeasible because of the vast number of knots required to get a good interpolant of a complex function In Bayesian inference problems the integrands are mostly zero except in small regions i e they are sparse which makes the situation even worse most of the knots will be wasted Newer deterministic techniques try to avoid these problems by exploiting more properties of the integrand than just its value at given points Another approach is nondeterminism\nNondeterministic i e Monte Carlo methods do not try to interpolate or otherwise approximate the integrand at all they merely appeal to the law of large numbers In the simplest approach we sample knots uniformly in the region of integration A The expected value E f x under such a sampling must be the desired integral I divided by the area of A Hence the estimate\nI jAj n nX i f xi\nwill converge to the true value given enough samples and this happens independent of dimensionality and independent of the complexity of f Thus while Monte Carlo is rather ine cient in low dimensions requiring thousands of knots when quadrature would only need around it is often the only feasible method in high dimensions In Bayesian inference problems the sparsity of the integrand can be addressed by the technique of importance sampling Instead of sampling uniformly in A we sample from a proposal distribution p x that matches the shape of jf j as well as possible Then the estimate\nI\nn nX i f xi p xi\nalso converges to I and much faster than would Importance sampling also has the advantage of working for in nite regions A Various enhancements to the basic importance sampling procedure are possible Ventura With importance sampling the di culties of numerical integration are replaced by the di culties of sampling from a complex distribu tion Good proposal distributions may be hard to sample from In this case one can apply Markov Chain Monte Carlo methods Neal Liu such as Metropolis sampling and Gibbs sampling In these methods we generate samples that are approximately from p x and then apply as before For these methods careful monitoring and restarting is required to ensure that the samples adequately represent p x The Billiard algorithm for Bayes Point Machines discussed in chapter is a particularly clever Markov Chain Monte Carlo algorithm\nTo learn about a function we can compute its value at a large number of knots but we could also compute a large number of derivatives at a single knot This is the basic idea of Taylor expansion By nite di erences a given number of knots translates into an equivalent number of derivatives so theoretically this approach has no advantage over quadrature But for Bayesian inference problems it has certain conceptual advantages Since the integrand is sparse it makes sense to focus on one area where the action is Interpolation is also simpler since we just match derivatives The most popular application of this idea in statistics is Laplace s method Kass Raftery where we expand log f about its mode\nlog f x log f x gT x x x x TA x x\ng\nd log f x\ndx\nx x\nH d log f x\ndxdxT\nx x\nBecause x is the mode g and we get\nf x f x exp x x TH x x\nI\nZ A f x dx f x rows H j Hj\nw p( D\n,w )\nExact Laplace\nw\np( D\n,w )\nExact Bound\na b\nw\np( D\n,w )\nExact EP\nc\nFigure Deterministic methods for integration try to approximate the integrand a Laplace s method uses a Gaussian that has the correct curvature at the mode It produces approximations that are too local b In one type of variational bound the integrand is bounded everywhere It produces approximations that are too inaccurate c The proposed method Expectation Propagation tries to minimize KL divergence a global measure of deviation It produces the most accurate integrals\nWhat Laplace s method does is approximate f by a scaled Gaussian density that matches the value rst derivative and second derivatives of f at x Figure shows an example The drawback of this method is that it is di cult to use higher order derivatives resulting in an approximation that is limited in its accuracy and scope\nVariational bounding is a deterministic approach more global than Laplace s method We start by introducing an arbitrary function q x\nI\nZ x q x f x q x dx\nJensen s inequality for convex functions says that in the case of logarithm\nlog Z x q x g x dx Z x q x logg x dx\nif Z x q x dx\nCombining and gives the following bound on I\nI exp Z x q x log f x q x dx\nThis of course requires that f x is positive a condition that is satis ed for most but not all integrals in Bayesian inference We are free to choose q x to get the tightest bound which corresponds to maximizing the right hand side of Note that this is equivalent to minimizing the reversed KL divergence\nD q jj f Z x q x log q x f x dx\nover q subject to the constraint If q x is unconstrained the maximum is achieved at q x f x and the bound matches the original integral To achieve a simpli cation in the integral we must constrain q x in some way Typically q x is constrained to be Gaussian Hinton van Camp Barber Bishop Seeger but mixture distributions have also been suggested Jaakkola Jordan c Having a lower bound is useful since it provides a rm guarantee about the true value of the integral something none of the other methods can do However it tends to be very computational and is feasible in a limited number of cases Jensen s inequality takes advantage of the fact that log f x is often easy to integrate when f x is not But this is not always true For example in a mixture problem such as discussed in chapter f is a product of sums which does not simplify under a logarithm And in chapter the likelihood is a step function which reaches zero The step function could be softened into a sigmoid to make the Jensen bound well de ned but we could not expect a good t to result\nA less accurate but simpler way to obtain a variational bound is to bound the integrand and then integrate the bound\nf x g x for all x I Z x g x dx\nFigure shows an example Unlike the previous variational method this approach can be used in mixture problems This approach was used explicitly by Jaakkola Jordan a b and implicitly by Waterhouse et al Attias Ghahramani Beal under the name variational Bayes The implicit approach introduces hidden variables to de ne a bound Start by writing f x in terms of h x y\nf x\nZ y h x y dy\nApply the Jensen bound to get\nI Z x y h x y dydx\nexp Z x y q x y log h x y q x y dydx\nAt this point we constrain q x y to factor into separate functions for x and for y\nq x y qx x qy y\nwith no other constraints on functional form The qx and qy functions are iteratively optimized to maximize the value of the bound To see that this is equivalent to note that for any qy we can solve analytically for the optimal qx which is\nqx x g x R\nx g x dx\nwhere g x exp Z y qy y log h x y qy y dy\nWhen we substitute this qx the bound becomes\nI Z x g x dx\nRegardless of which approach we use implicit or explicit we can optimize the bound via the EM algorithm This is described in Minka c\nBesides variational bounds there are other integration techniques that are inspired by mean eld statistical physics Most of these are extensions of TAP such as the cavity method Opper Winther a Bethe approximation Yedidia and Plefka ex pansion Kappen Wiegerinck So far they have been applied to regular structures such as the Boltzmann machine and rarely to general probabilistic models where it is less obvious how to apply them An exception to this is the paper by Opper Winther c The algorithm they derive is new and accurate yet coincides with the framework proposed in this thesis It will be interesting to see what other algorithms come out of this mean eld line of research\nFor approximating an integral we thus nd ourselves in the following position We have methods that work well for simple functions in low dimensions quadrature and complex functions in high dimensions Monte Carlo We have methods that are simple and fast but inaccurate Laplace s method variational Bayes We have methods that apply in special cases Jensen bound TAP What is missing is a general and accurate deterministic method in high dimensions at least for simple functions That is what this thesis provides\nThe approach taken by this thesis continues the path started by the extended Kalman lter EKF The EKF is a sequential method developed for inference in dynamical systems with nonlinear dynamics It is not a general method for integration But there are several variations on the EKF Maybeck that have promise One is sequential Monte Carlo a family of nondeterministic techniques Liu Chen Carpenter et al Another is the assumed density lter a general deterministic method that approximately minimizes the KL divergence D f jj g between f x and its approximation g x as shown in gure The next chapter discusses the assumed density lter and its extension to Expectation Propagation"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 114
                            }
                        ],
                        "text": "For example, we might replace the exact one-step posterior with a Gaussian having the same mean and same variance (Maybeck, 1982; Lauritzen, 1992; Barber & Sollich, 1999; Opper & Winther, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 53
                            }
                        ],
                        "text": "It is an extension to assumed-density ltering (ADF), (Maybeck, 1982; Lauritzen, 1992; Bernardo & Giron, 1988; Stephens, 1997; Boyen & Koller, 1998b; Barber & Sollich, 1999; Opper & Winther, 1999; Frey et al., 2000) a one-pass, sequential method for computing an approximate posterior distribution."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 44
                            }
                        ],
                        "text": "But there are several variations on the EKF (Maybeck, 1982) that have promise."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic models, estimation and control, chapter 12.7"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153684112"
                        ],
                        "name": "C. Cruz",
                        "slug": "C.-Cruz",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Cruz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Cruz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081074839"
                        ],
                        "name": "Caandmichael I. JORDANMassachusetts",
                        "slug": "Caandmichael-I.-JORDANMassachusetts",
                        "structuredName": {
                            "firstName": "Caandmichael",
                            "lastName": "JORDANMassachusetts",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Caandmichael I. JORDANMassachusetts"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14616421,
            "fieldsOfStudy": [],
            "id": "01214343041e0f5b388e833deb7da7e5a6e17d27",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Improving-the-Mean-Field-Approximation-via-the-Use-Cruz-JORDANMassachusetts",
            "title": {
                "fragments": [],
                "text": "Improving the Mean Field Approximation via the Use of Mixture Distributions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026where key groundwork for this thesis was performed\nIt has been a pleasure to exchange ideas with everyone at the Vision and Modeling group at the MIT Media Lab especially Martin Szummer Flavia Sparacino Ali Rahimi and Yuan Qi Thanks to Sumit Basu for providing his code for the billiard algorithm"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Markov c hain Monte Carlo and related topics"
            },
            "venue": {
                "fragments": [],
                "text": "Markov c hain Monte Carlo and related topics"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 138
                            }
                        ],
                        "text": "Bayesian averaging of linear classi ers has been proven both theoretically and empirically optimal in terms of generalization performance (Watkin, 1993; Bouten et al., 1995; Buhot et al., 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Finite size scaling of the Bayesian"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian mean eld algorithms for neural networks and Gaussian processes. Doctoral dissertation"
            },
            "venue": {
                "fragments": [],
                "text": "Bayesian mean eld algorithms for neural networks and Gaussian processes. Doctoral dissertation"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning switching Kalman lter models (Technical Report CSD-98-990). Compaq Cambridge Research L a b"
            },
            "venue": {
                "fragments": [],
                "text": "Learning switching Kalman lter models (Technical Report CSD-98-990). Compaq Cambridge Research L a b"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semi-supervised support vector machines. NIPS 11"
            },
            "venue": {
                "fragments": [],
                "text": "Semi-supervised support vector machines. NIPS 11"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayes factors and model uncertainty ( T echnical Report 254) University o f W ashington"
            },
            "venue": {
                "fragments": [],
                "text": "Bayes factors and model uncertainty ( T echnical Report 254) University o f W ashington"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian mean eld algorithms for neural networks and Gaussian processes. D o ctoral dissertation, University o f C o p e nhagen"
            },
            "venue": {
                "fragments": [],
                "text": "Bayesian mean eld algorithms for neural networks and Gaussian processes. D o ctoral dissertation, University o f C o p e nhagen"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Variational inference for Bayesian mixtures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 138
                            }
                        ],
                        "text": "Bayesian averaging of linear classi ers has been proven both theoretically and empirically optimal in terms of generalization performance (Watkin, 1993; Bouten et al., 1995; Buhot et al., 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 756,
                                "start": 153
                            }
                        ],
                        "text": "Bayesian averaging of linear classi ers has been proven both theoretically and empirically optimal in terms of generalization performance (Watkin, 1993; Bouten et al., 1995; Buhot et al., 1997). But an e cient algorithm has remained elusive. The Bayes Point Machine approximates the Bayesian average by choosing one `average' classi er, the Bayes Point (Watkin, 1993; Rujan, 1997; Herbrich et al., 1999). Computing the Bayes Point is a simpler, but still very di cult task. This chapter shows that Expectation Propagation, using a full-covariance Gaussian approximation to the posterior, provides an accurate estimate of the Bayes Point|an approximation to the full Bayesian average. The algorithm turns out to be identical to what Opper & Winther (2000c) derived by statistical physics methods."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gradient descent learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 78
                            }
                        ],
                        "text": "But it can also be applied to graphs with loops, to get approximate marginals (Frey & MacKay, 1997; Murphy et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 203
                            }
                        ],
                        "text": "For example, in belief networks with loops it is known that approximate marginal distributions can be obtained by iterating the belief propagation recursions, a process known as loopy belief propagation (Frey & MacKay, 1997; Murphy et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Loopy-belief propagation for approximate"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 71
                            }
                        ],
                        "text": "One is sequential Monte Carlo, a family of nondeterministic techniques (Liu & Chen, 2000; Carpenter et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Building robust simulation-based"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tractable variational structures for approximating"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 148
                            }
                        ],
                        "text": "\u2026use the factoring into n terms implied by\nt p\nti p xij For a general Bayesian network we would use the factoring into conditional probability tables Q nodes Y p Y jpa Y where pa Y is the parents of node Y in the graph\nThe second step is to choose a parametric approximating distribution It is\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian methods for mixtures of normal distributions. D o c toral dissertation, Oxford University"
            },
            "venue": {
                "fragments": [],
                "text": "Bayesian methods for mixtures of normal distributions. D o c toral dissertation, Oxford University"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian parameter estimation via variational"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian methods for mixtures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayes factors and model uncertainty (Technical"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Approximate learning of dynamic models. NIPS 11. http: //robotics .Stanford.EDU/~koller/papers/nips98.html"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026where key groundwork for this thesis was performed\nIt has been a pleasure to exchange ideas with everyone at the Vision and Modeling group at the MIT Media Lab especially Martin Szummer Flavia Sparacino Ali Rahimi and Yuan Qi Thanks to Sumit Basu for providing his code for the billiard algorithm"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Double importance sampling (Technical Report) Dept of Statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Double importance sampling (Technical Report) Dept of Statistics"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026Machines on several standard datasets in addition to having a comparable training time Expectation Propagation can also be used to choose an appropriate feature set for classi cation via Bayesian model selection\nThesis Supervisor Rosalind Picard Title Associate Professor of Media Arts and Sciences"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perceptron learning by p l a ying billiards"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A nonlinear ltering algorithm based on"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sequentially tting inclusive trees for inference in noisy-OR networks. NIPS 13"
            },
            "venue": {
                "fragments": [],
                "text": "Sequentially tting inclusive trees for inference in noisy-OR networks. NIPS 13"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The innnite Gaussian mixture model. NIPS 12"
            },
            "venue": {
                "fragments": [],
                "text": "The innnite Gaussian mixture model. NIPS 12"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026where key groundwork for this thesis was performed\nIt has been a pleasure to exchange ideas with everyone at the Vision and Modeling group at the MIT Media Lab especially Martin Szummer Flavia Sparacino Ali Rahimi and Yuan Qi Thanks to Sumit Basu for providing his code for the billiard algorithm"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic inference using Markov c hain Monte Carlo methods (Technical Report CRG-TR-93-1). Dept. of Computer Science, University o f T oronto"
            },
            "venue": {
                "fragments": [],
                "text": "Probabilistic inference using Markov c hain Monte Carlo methods (Technical Report CRG-TR-93-1). Dept. of Computer Science, University o f T oronto"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026where key groundwork for this thesis was performed\nIt has been a pleasure to exchange ideas with everyone at the Vision and Modeling group at the MIT Media Lab especially Martin Szummer Flavia Sparacino Ali Rahimi and Yuan Qi Thanks to Sumit Basu for providing his code for the billiard algorithm"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic models, estimation and control, c hapter 12.7"
            },
            "venue": {
                "fragments": [],
                "text": "Stochastic models, estimation and control, c hapter 12.7"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gaussian processes for classi cation: Mean"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026Machines on several standard datasets in addition to having a comparable training time Expectation Propagation can also be used to choose an appropriate feature set for classi cation via Bayesian model selection\nThesis Supervisor Rosalind Picard Title Associate Professor of Media Arts and Sciences"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gaussian processes for classiication: Mean eld algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 61
                            }
                        ],
                        "text": "In this case, one can apply Markov Chain Monte Carlo methods (Neal, 1993; Liu, 1999), such as Metropolis sampling and Gibbs sampling."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Markov chain Monte Carlo and related topics (Technical Report)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improving the mean eld approximation via"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gaussian Processes and SVM: Mean eld results"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Factorial hidden Markov m o d e l s"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026where key groundwork for this thesis was performed\nIt has been a pleasure to exchange ideas with everyone at the Vision and Modeling group at the MIT Media Lab especially Martin Szummer Flavia Sparacino Ali Rahimi and Yuan Qi Thanks to Sumit Basu for providing his code for the billiard algorithm"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improving the mean eld approximation via the use of mixture distributions. In Learning in graphical models"
            },
            "venue": {
                "fragments": [],
                "text": "Improving the mean eld approximation via the use of mixture distributions. In Learning in graphical models"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Approximate learning of dynamic models. NIPS 11"
            },
            "venue": {
                "fragments": [],
                "text": "Approximate learning of dynamic models. NIPS 11"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sampling-based approaches to calculating"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Murphy et al. (1999)), the original terms t, should correspond to the conditional probability tables of a directed belief network."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning switching Kalman filter models (Technical Report CSD-98-990)"
            },
            "venue": {
                "fragments": [],
                "text": "Compaq Cambridge Research Lab. http: //www. cs .berkeley . edu/~murphyk/Papers/skf .ps . gz."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Second order approximations for probability"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gaussian Processes and SVM: Mean eld results and leave-one-out. Advances in Large Margin Classiiers"
            },
            "venue": {
                "fragments": [],
                "text": "Gaussian Processes and SVM: Mean eld results and leave-one-out. Advances in Large Margin Classiiers"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adaptive T AP equations. Advanced M e an Field Methods -Theory and Practice. M I T Press"
            },
            "venue": {
                "fragments": [],
                "text": "Adaptive T AP equations. Advanced M e an Field Methods -Theory and Practice. M I T Press"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 314,
                                "start": 76
                            }
                        ],
                        "text": "Iterative refinement has previously been used in conjunction with sampling (Koller et al., 1999) and extended Kalman filtering (Shachter, 1990). Expectation Propagation differs by applying this idea to the deterministic approximation of general distributions, not just Gaussian distributions as in Shachter (1990). EP is more expensive than ADF by only a constant factor-the number of refinement passes (typically 4 or 5)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1238,
                                "start": 76
                            }
                        ],
                        "text": "Iterative refinement has previously been used in conjunction with sampling (Koller et al., 1999) and extended Kalman filtering (Shachter, 1990). Expectation Propagation differs by applying this idea to the deterministic approximation of general distributions, not just Gaussian distributions as in Shachter (1990). EP is more expensive than ADF by only a constant factor-the number of refinement passes (typically 4 or 5). As shown in chapter 3, the accuracy of EP is significantly better than ADF as well as rival approximation methods: Monte Carlo, Laplace's method, and variational Bayes. Thinking in this framework has a number of benefits. For example, in belief networks with loops it is known that approximate marginal distributions can be obtained by iterating the belief propagation recursions, a process known as loopy belief propagation (Frey & MacKay, 1997; Murphy et al., 1999). As described in chapter 4, it turns out that this heuristic procedure is a special case of Expectation Propagation, where the approximate posterior is a completely disconnected network with no other constraints on functional form. In other words, loopy belief propagation is a direct generalization of the ADF algorithm of Boyen & Koller (1998b). Expectation Propagation can therefore be seen as a way of generalizing loopy belief propagation-to less restrictive approximations that are not completely disconnected and to useful constraints on functional form such as multivariate Gaussian."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayes factors and model uncertainty (Technical Report 254)"
            },
            "venue": {
                "fragments": [],
                "text": "University of Washington. http: //www. stat. washington. edu/tech. reports/tr254. ps"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Bayesian analysis of simple mixture problems"
            },
            "venue": {
                "fragments": [],
                "text": "Bayesian Statistics"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic choice of dimensionality f o r PCA. NIPS 13. ftp://whitechapel.media.mit.edu/pub/tech-reports"
            },
            "venue": {
                "fragments": [],
                "text": "Automatic choice of dimensionality f o r PCA. NIPS 13. ftp://whitechapel.media.mit.edu/pub/tech-reports"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A PAC-Bayesian margin bound for linear classiiers: Why SVMs work. NIPS 13"
            },
            "venue": {
                "fragments": [],
                "text": "A PAC-Bayesian margin bound for linear classiiers: Why SVMs work. NIPS 13"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning switching Kalman lter models"
            },
            "venue": {
                "fragments": [],
                "text": "Learning switching Kalman lter models"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian methods for mixtures of normal distributions. Doctoral dissertation, Oxford University"
            },
            "venue": {
                "fragments": [],
                "text": "Bayesian methods for mixtures of normal distributions. Doctoral dissertation, Oxford University"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Murphy et al. (1999)), the original terms ti should correspond to the conditional probability tables of a directed belief network."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning switching Kalman lter models (Technical Report"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 112
                            }
                        ],
                        "text": "hidden Markov models? Is any deterministic method e ective for nonparametric models such as Dirichlet processes (Rasmussen, 1999)? Second, can we anticipate how EP will perform? Can EP provide an estimate of its error? (The experiments in this paper always used the ADF initialization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The in nite Gaussian mixture model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 563,
                                "start": 21
                            }
                        ],
                        "text": "This is described in Minka (2000c). Besides variational bounds, there are other integration techniques that are inspired by mean-field statistical physics. Most of these are extensions of TAP, such as the cavity method (Opper & Winther, 2000a), Bethe approximation (Yedidia, 2000), and Plefka expansion (Kappen & Wiegerinck, 2000). So far they have been applied to regular structures such as the Boltzmann machine and rarely to general probabilistic models, where it is less obvious how to apply them. An exception to this is the paper by Opper & Winther (2000c). The algorithm they derive is new and accurate, yet coincides with the framework proposed in this thesis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 21
                            }
                        ],
                        "text": "This is described in Minka (2000c). Besides variational bounds, there are other integration techniques that are inspired by mean-field statistical physics."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic models, estimation and control, chapter 12.7"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026where key groundwork for this thesis was performed\nIt has been a pleasure to exchange ideas with everyone at the Vision and Modeling group at the MIT Media Lab especially Martin Szummer Flavia Sparacino Ali Rahimi and Yuan Qi Thanks to Sumit Basu for providing his code for the billiard algorithm"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inferring parameters and structure of latent v ariable models by variational Bayes. Uncertainty in Artiicial Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "Inferring parameters and structure of latent v ariable models by variational Bayes. Uncertainty in Artiicial Intelligence"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026where key groundwork for this thesis was performed\nIt has been a pleasure to exchange ideas with everyone at the Vision and Modeling group at the MIT Media Lab especially Martin Szummer Flavia Sparacino Ali Rahimi and Yuan Qi Thanks to Sumit Basu for providing his code for the billiard algorithm"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayes factors and model uncertainty University of Washington"
            },
            "venue": {
                "fragments": [],
                "text": "Bayes factors and model uncertainty University of Washington"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Keeping neural networks simple by minimizing the"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Variational probabilistic inference and the"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 197
                            }
                        ],
                        "text": "First, how e ective is EP for other statistical models? For example, is it useful for inference in coupled hidden Markov models, sigmoid belief networks (Barber & Sollich, 1999), and dynamic trees (Storkey, 2000)? Is EP e ective for Bayesian parameter estimation of classi cation models beyond linear classi ers, e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic trees: A structured variational method giving e cient"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalized belief propagation (Technical Report TR2000-26)"
            },
            "venue": {
                "fragments": [],
                "text": "MERL. http://www.merl. com/report s/TR2000-26/ index.html"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Bayesian approach t o on-line learning. On-Line Learning in Neural Networks. C a m bridge University Press"
            },
            "venue": {
                "fragments": [],
                "text": "A Bayesian approach t o on-line learning. On-Line Learning in Neural Networks. C a m bridge University Press"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adaptive TAP equations Advanced Mean Field Methods -Theory and Practice"
            },
            "venue": {
                "fragments": [],
                "text": "Adaptive TAP equations Advanced Mean Field Methods -Theory and Practice"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026where key groundwork for this thesis was performed\nIt has been a pleasure to exchange ideas with everyone at the Vision and Modeling group at the MIT Media Lab especially Martin Szummer Flavia Sparacino Ali Rahimi and Yuan Qi Thanks to Sumit Basu for providing his code for the billiard algorithm"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian model selection for support vector machines, Gaussian processes and other kernel classiiers. NIPS 12"
            },
            "venue": {
                "fragments": [],
                "text": "Bayesian model selection for support vector machines, Gaussian processes and other kernel classiiers. NIPS 12"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gaussian elds for approximate inference in layered"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 74
                            }
                        ],
                        "text": "Iterative re nement has previously been used in conjunction with sampling (Koller et al., 1999) and extended Kalman ltering (Shachter, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A general algorithm for approximate"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian parameter estimation via variational methods. Statistics and Computing, to appear. http://www.cs.berkeley.edu/~jordan/papers/variational-bayes.ps .Z"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 89
                            }
                        ],
                        "text": "For variational Bayes, we use a Jensen bound as before, to get a Dirichlet approximation (Minka, 2000c)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 92
                            }
                        ],
                        "text": "66) For variational Bayes, we lower bound the joint distribution by bounding each data term (Minka, 2000c): (1 - w)A (x; 0, I) ll (W (x; 0, 10I)i (367 Xxi 0) i, qi2"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Variational Bayes for mixture models: Reversing EM"
            },
            "venue": {
                "fragments": [],
                "text": "http://vismod.www.media.mit. edu/~tpminka/papers/rem.html."
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 77
                            }
                        ],
                        "text": "Various enhancements to the basic importance sampling procedure are possible (Ventura, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Double importance sampling (Technical Report)"
            },
            "venue": {
                "fragments": [],
                "text": "Dept of Statistics, Carnegie Mellon University. http: //www. stat . cmu. edu/cmu-stats/tr/tr694/tr694. html. Waterhouse, S., MacKay, D., & Robinson, T. (1995). Bayesian methods for mixtures of experts. NIPS 8."
            },
            "year": 2000
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 40,
            "methodology": 30
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 127,
        "totalPages": 13
    },
    "page_url": "https://www.semanticscholar.org/paper/A-family-of-algorithms-for-approximate-Bayesian-Minka/bf527ca11d7d81a15ff5b5603374a4e9d53b55b6?sort=total-citations"
}