{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116415943"
                        ],
                        "name": "B. Yu",
                        "slug": "B.-Yu",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5196787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f565f502ad1acb81c5659b051c04683a34ed138f",
            "isKey": false,
            "numCitedBy": 576,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic text location (without character recognition capabilities) deals with extracting image regions that contain text only. The images of these regions can then be fed to an optical character recognition module or highlighted for users. This is very useful in a number of applications such as database indexing and converting paper documents to their electronic versions. The performance of our automatic text location algorithm is shown in several applications. Compared with some traditional text location methods, our method has the following advantages: 1) low computational cost; 2) robust to font size; and 3) high accuracy."
            },
            "slug": "Automatic-text-location-in-images-and-video-frames-Jain-Yu",
            "title": {
                "fragments": [],
                "text": "Automatic text location in images and video frames"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Compared with some traditional text location methods, this method has the following advantages: 1) low computational cost; 2) robust to font size; and 3) high accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48764203"
                        ],
                        "name": "Victor Wu",
                        "slug": "Victor-Wu",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31338632"
                        ],
                        "name": "E. Riseman",
                        "slug": "E.-Riseman",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Riseman",
                            "middleNames": [
                                "M."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riseman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The accuracy of the cleanup-algorithm was also measured with further discussion and details appearing in [ 17 ], [16], [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 208945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3420ab835c1af02071364b1f4e0f69abf733d88c",
            "isKey": false,
            "numCitedBy": 263,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "There are many applications in which the automatic detection and recognition of text embedded in images is useful. These applications include digad libraries, multimedia systems, and Geographical Information Systems. When machine generated text is prdnted against clean backgrounds, it can be converted to a computer readable form (ASCII) using current Optical Character Recognition (OCR) technology. However, text is often printed against shaded or textured backgrounds or is embedded in images. Examples include maps, advertisements, photographs, videos and stock certificates. Current document segmentation and recognition technologies cannot handle these situafons well. In this paper, a four-step system which automaticnlly detects and extracts text in images i& proposed. First, a texture segmentation scheme is used to focus attention on regions where text may occur. Second, strokes are extracted from the segmented text regions. Using reasonable heuristics on text strings such as height similarity, spacing and alignment, the extracted strokes are then processed to form rectangular boxes surrounding the corresponding ttzt strings. To detect text over a wide range of font sizes, the above steps are first applied to a pyramid of images generated from the input image, and then the boxes formed at each resolution level of the pyramid are fused at the image in the original resolution level. Third, text is extracted by cleaning up the background and binarizing the detected ted strings. Finally, better text bounding boxes are generated by srsiny the binarized text as strokes. Text is then cleaned and binarized from these new boxes, and can then be passed through a commercial OCR engine for recognition if the text is of an OCR-recognizable font. The system is stable, robust, and works well on imayes (with or without structured layouts) from a wide van\u2019ety of sources, including digitized video frames, photographs, *This material is based on work supported in part by the National Science Foundation, Library of Congress and Department of Commerce under cooperative agreement number EEC9209623, in part by the United States Patent and mademark Office and Defense Advanced Research Projects Agency/IT0 under ARPA order number D468, issued by ESC/AXS contract number F19628-96-C-0235, in part by the National Science Foundation under grant number IF&9619117 and in part by NSF Multimedia CDA-9502639. Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsors. Prrmission to make digital/hard copies ofall or part oflhis material for personal or clrrssroom use is granted without fee provided that the copies are not made or distributed for profit or commercial advantage, the copyright notice, the title ofthe publication and its date appear, and notice is given that copyright is by permission of the ACM, Inc. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires specific permission and/or fe DL 97 Philadelphia PA, USA Copyright 1997 AChi 0-89791~868-1197/7..$3.50 newspapers, advertisements, stock certifimtes, and personal checks. All parameters remain the same for-all the experiments."
            },
            "slug": "Finding-text-in-images-Wu-Manmatha",
            "title": {
                "fragments": [],
                "text": "Finding text in images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A four-step system which automaticnlly detects and extracts text in images is proposed and works well on imayes (with or without structured layouts) from a wide range of sources, including digitized video frames, photographs, and personal checks."
            },
            "venue": {
                "fragments": [],
                "text": "DL '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39319377"
                        ],
                        "name": "Yu Zhong",
                        "slug": "Yu-Zhong",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145211604"
                        ],
                        "name": "K. Karu",
                        "slug": "K.-Karu",
                        "structuredName": {
                            "firstName": "Kalle",
                            "lastName": "Karu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Karu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29853292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a4af75831ed098d9fea02507f36cdbc38852fe6",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a substantial interest in retrieving images from a large database using the textual information contained in the images. An algorithm which will automatically locate the textual regions in the input image will facilitate this task; the optical character recognizer can then be applied to only those regions of the image which contain text. We present a method for automatically locating text in complex color images. The algorithm first finds the approximate locations of text lines using horizontal spatial variance, and then extracts text components in these boxes using color segmentation. The proposed method has been used to locate text in compact disc (CD) and book cover images, as well as in the images of traffic scenes captured by a video camera. Initial results are encouraging and suggest that these algorithms can be used in image retrieval applications."
            },
            "slug": "Locating-text-in-complex-color-images-Zhong-Karu",
            "title": {
                "fragments": [],
                "text": "Locating text in complex color images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The proposed algorithm has been used to locate text in compact disc and book cover images, as well as in the images of traffic scenes captured by a video camera, and initial results suggest that these algorithms can be used in image retrieval applications."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1880661"
                        ],
                        "name": "F. Wahl",
                        "slug": "F.-Wahl",
                        "structuredName": {
                            "firstName": "Friedrich",
                            "lastName": "Wahl",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145470231"
                        ],
                        "name": "Kwan Y. Wong",
                        "slug": "Kwan-Y.-Wong",
                        "structuredName": {
                            "firstName": "Kwan",
                            "lastName": "Wong",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kwan Y. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34896449"
                        ],
                        "name": "R. Casey",
                        "slug": "R.-Casey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Casey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Casey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 41585742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4947ddbda627747c9b13da81514f0129597e91de",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Block-segmentation-and-text-extraction-in-mixed-Wahl-Wong",
            "title": {
                "fragments": [],
                "text": "Block segmentation and text extraction in mixed text/image documents"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Image Process."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2461436"
                        ],
                        "name": "Jiangying Zhou",
                        "slug": "Jiangying-Zhou",
                        "structuredName": {
                            "firstName": "Jiangying",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiangying Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23073168,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "3ef36b0186bb73619d08d02661616ce7df218ecd",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors examine the problem of locating and extracting text from images on the World Wide Web. They describe a text detection algorithm which is based on color clustering and connected component analysis. The algorithm first quantizes the color space of the input image into a number of color classes using a parameter-free clustering procedure. It then identifies text-like connected components in each color class based on their shapes. Finally, a post-processing procedure aligns text-like components into text lines. Experimental results suggest this approach is promising despite the challenging nature of the input data."
            },
            "slug": "Extracting-text-from-WWW-images-Zhou-Lopresti",
            "title": {
                "fragments": [],
                "text": "Extracting text from WWW images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A text detection algorithm which is based on color clustering and connected component analysis is described, which suggests this approach is promising despite the challenging nature of the input data."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2461436"
                        ],
                        "name": "Jiangying Zhou",
                        "slug": "Jiangying-Zhou",
                        "structuredName": {
                            "firstName": "Jiangying",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiangying Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3198175"
                        ],
                        "name": "T. Tasdizen",
                        "slug": "T.-Tasdizen",
                        "structuredName": {
                            "firstName": "Tolga",
                            "lastName": "Tasdizen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tasdizen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10184381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bad076c5f89ac43026a2b5fca648d488f54f45e",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we consider the problem of locating and extracting text from WWW images. A previous algorithm based on color clustering and connected components analysis works well as long as the color of each character is relatively uniform and the typography is fairly simple. It breaks down quickly, however, when these assumptions are violated. In this paper, we describe more robust techniques for dealing with this challenging problem. We present an improved color clustering algorithm that measures similarity based on both RGB and spatial proximity. Layout analysis is also incorporated to handle more complex typography. THese changes significantly enhance the performance of our text detection procedure."
            },
            "slug": "Finding-text-in-color-images-Zhou-Lopresti",
            "title": {
                "fragments": [],
                "text": "Finding text in color images"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An improved color clustering algorithm that measures similarity based on both RGB and spatial proximity is presented, and layout analysis is also incorporated to handle more complex typography."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39319377"
                        ],
                        "name": "Yu Zhong",
                        "slug": "Yu-Zhong",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39821816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14371d83ac90edc11b3604d4bf64915f99e45678",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Page-segmentation-using-tecture-analysis-Jain-Zhong",
            "title": {
                "fragments": [],
                "text": "Page segmentation using tecture analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258400"
                        ],
                        "name": "\u00d8. Trier",
                        "slug": "\u00d8.-Trier",
                        "structuredName": {
                            "firstName": "\u00d8ivind",
                            "lastName": "Trier",
                            "middleNames": [
                                "Due"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00d8. Trier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48717516"
                        ],
                        "name": "T. Taxt",
                        "slug": "T.-Taxt",
                        "structuredName": {
                            "firstName": "Torfinn",
                            "lastName": "Taxt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Taxt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "[17] ivind Due Trier and Tor nn Taxt."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "Unfortunately, global thresholding is usually not possible for complicated images, as noted by many researchers ([13], [17])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Trier and Taxt [17] report an evaluationof eleven local adaptive thresholding schemes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Trier and Taxt [17] report an evaluation of eleven local adaptive thresholding schemes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17374833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66126ec1fe61b833ae695db9c5bac54641fab482",
            "isKey": true,
            "numCitedBy": 451,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an evaluation of eleven locally adaptive binarization methods for gray scale images with low contrast, variable background intensity and noise. Niblack's method (1986) with the addition of the postprocessing step of Yanowitz and Bruckstein's method (1989) added performed the best and was also one of the fastest binarization methods. >"
            },
            "slug": "Evaluation-of-Binarization-Methods-for-Document-Trier-Taxt",
            "title": {
                "fragments": [],
                "text": "Evaluation of Binarization Methods for Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This paper presents an evaluation of eleven locally adaptive binarization methods for gray scale images with low contrast, variable background intensity and noise and Niblack's method with the addition of the postprocessing step of Yanowitz and Bruckstein's method (1989) performed the best and was also one of the fastest binarized methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47260288"
                        ],
                        "name": "L. Fletcher",
                        "slug": "L.-Fletcher",
                        "structuredName": {
                            "firstName": "Lloyd",
                            "lastName": "Fletcher",
                            "middleNames": [
                                "Alan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Fletcher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 139
                            }
                        ],
                        "text": "Any opinions, ndingsand conclusions or recommendations expressed in this material are the author(s) and do notnecessarily re ect those of the sponsors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2685456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b08e547ba4edb60902d1708a5593d71f075aa7f1",
            "isKey": false,
            "numCitedBy": 657,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described. It is intended for use in an automated system for document analysis. The principal parts of the algorithm are the generation of connected components and the application of the Hough transform in order to group components into logical character strings that can then be separated from the graphics. The algorithm outputs two images, one containing text strings and the other graphics. These images can then be processed by suitable character recognition and graphics recognition systems. The performance of the algorithm, both in terms of its effectiveness and computational efficiency, was evaluated using several test images and showed superior performance compared to other techniques. >"
            },
            "slug": "A-Robust-Algorithm-for-Text-String-Separation-from-Fletcher-Kasturi",
            "title": {
                "fragments": [],
                "text": "A Robust Algorithm for Text String Separation from Mixed Text/Graphics Images"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described and showed superior performance compared to other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111216375"
                        ],
                        "name": "Dacheng Wang",
                        "slug": "Dacheng-Wang",
                        "structuredName": {
                            "firstName": "Dacheng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dacheng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 150
                            }
                        ],
                        "text": "Any opinions, ndingsand conclusions or recommendations expressed in this material are the author(s) and do notnecessarily re ect those of the sponsors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26685555,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "873fa0ca7454bd1ca4de25128c522e088b635ddc",
            "isKey": false,
            "numCitedBy": 250,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Classification-of-newspaper-image-blocks-using-Wang-Srihari",
            "title": {
                "fragments": [],
                "text": "Classification of newspaper image blocks using texture analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145470231"
                        ],
                        "name": "Kwan Y. Wong",
                        "slug": "Kwan-Y.-Wong",
                        "structuredName": {
                            "firstName": "Kwan",
                            "lastName": "Wong",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kwan Y. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34896449"
                        ],
                        "name": "R. Casey",
                        "slug": "R.-Casey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Casey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Casey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1880661"
                        ],
                        "name": "F. Wahl",
                        "slug": "F.-Wahl",
                        "structuredName": {
                            "firstName": "Friedrich",
                            "lastName": "Wahl",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wahl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Other schemes require clean binary input [3], [13], [14], [ 15 ]; some assume specific document layouts such as video frames [12], newspapers [6], technical journals [9], l or are domain specific like mail address blocks [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15921038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7abca302c74d2f5adfd323a28e26d40b019df2b5",
            "isKey": false,
            "numCitedBy": 594,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper outlines the requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing. Several critical functions have been investigated and the technical approaches are discussed. The first is the segmentation and classification of digitized printed documents into regions of text and images. A nonlinear, run-length smoothing algorithm has been used for this purpose. By using the regular features of text lines, a linear adaptive classification scheme discriminates text regions from others. The second technique studied is an adaptive approach to the recognition of the hundreds of font styles and sizes that can occur on printed documents. A preclassifier is constructed during the input process and used to speed up a well-known pattern-matching method for clustering characters from an arbitrary print source into a small sample of prototypes. Experimental results are included."
            },
            "slug": "Document-Analysis-System-Wong-Casey",
            "title": {
                "fragments": [],
                "text": "Document Analysis System"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "The requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing, are outlined and several critical functions have been investigated and the technical approaches are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IBM J. Res. Dev."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48764203"
                        ],
                        "name": "Victor Wu",
                        "slug": "Victor-Wu",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Wu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15445857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e95912f7e0d2d0328aff9bc3afddb569e9d1ef9",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Image binarization is a diicult task for documents with text over textured or shaded backgrounds, poor contrast, and/or considerable noise. Current optical character recognition (OCR) and document analysis technology do not handle such documents well. We have developed a simple yet eeective algorithm for document image clean-up and bina-rization. The algorithm consists of two basic steps. In the rst step, the input image is smoothed using a low-pass (Gaussian) lter. The smoothing operation enhances the text relative to any background texture. This is because background texture normally has higher frequency than text does. The smoothing operation also removes speckle noise. In the second step, the intensity histogram of the smoothed image is computed and a threshold automatically selected as follows. For black text, the rst peak of the histogram corresponds to text. Thresholding the image at the value of the valley between the rst and second peaks of the histogram binarizes the image well. In order to reliably identify the valley, the histogram is smoothed by a low-pass lter before the threshold is computed. The algorithm has been applied to some 50 images from a wide variety of sources: digitized video frames, photos, newspapers, advertisements in magazines or sales yers, personal checks, etc. There are 21820 characters and 4406 words in these images. 91% of the characters and 86% of the words are successfully cleaned up and binarized. A commercial OCR was applied to the binarized text when it consisted of fonts which were OCR recognizable. The recognition rate was 84% for the characters and 77% for the words. Any opinions, ndings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reeect those of the sponsors."
            },
            "slug": "Document-Image-Clean-up-and-Binarization-Wu",
            "title": {
                "fragments": [],
                "text": "Document Image Clean-up and Binarization"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A simple yetective algorithm for document image clean-up and bina-rization for binarization of text over textured or shaded backgrounds, poor contrast, and/or considerable noise is developed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144851973"
                        ],
                        "name": "M. Kamel",
                        "slug": "M.-Kamel",
                        "structuredName": {
                            "firstName": "Mohamed",
                            "lastName": "Kamel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kamel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1500387699"
                        ],
                        "name": "A. Zhao",
                        "slug": "A.-Zhao",
                        "structuredName": {
                            "firstName": "Aiguo",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zhao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 86
                            }
                        ],
                        "text": "1\nTextFinder: An Automatic System ToDetect And Recognize Text In ImagesVictor Wu, R. Manmatha, Edward M. RisemanAbstractThere are many applications in which the automatic detection and recognitionof text embedded in images is useful."
                    },
                    "intents": []
                }
            ],
            "corpusId": 33047782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b786be0f6e167d58a9da67eca864113efbf6b01",
            "isKey": false,
            "numCitedBy": 221,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The extraction of binary character/graphics images from gray-scale document images with background pictures, shadows, highlight, smear, and smudge is a common critical image processing operation, particularly for document image analysis, optical character recognition, check image processing, image transmission, and videoconferencing. After a brief review of previous work with emphasis on five published extraction techniques, viz., a global thresholding technique, YDH technique, a nonlinear adaptive technique, an integrated function technique, and a local contrast technique, this paper presents two new extraction techniques: a logical level technique and a mask-based subtraction technique. With experiments on images of a typical check and a poor-quality text document, this paper systematically evaluates and analyses both new and published techniques with respect to six aspects, viz., speed, memory requirement, stroke width restriction, parameter number, parameter setting, and human subjective evaluation of result images. Experiments and evaluations have shown that one new technique is superior to the rest, suggesting its suitability for high-speed low-cost applications."
            },
            "slug": "Extraction-of-Binary-Character/Graphics-Images-from-Kamel-Zhao",
            "title": {
                "fragments": [],
                "text": "Extraction of Binary Character/Graphics Images from Grayscale Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents two new extraction techniques: a logical level technique and a mask-based subtraction technique, suggesting its suitability for high-speed low-cost applications."
            },
            "venue": {
                "fragments": [],
                "text": "CVGIP Graph. Model. Image Process."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48764203"
                        ],
                        "name": "Victor Wu",
                        "slug": "Victor-Wu",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The accuracy of the cleanup-algorithm was also measured with further discussion and details appearing in [17], [ 16 ], [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A simple, effective histogram-based algorithm, as described in [ 16 ], is used to find the threshold value automatically for each text region."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1084084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb5286ea64ea67ee2172eef2353629d0800051f2",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Image binarization is a difficult task for documents with text over textured or shaded backgrounds, poor contrast, and/or considerable noise. Current optical character recognition (OCR) and document analysis technology do not handle such documents well. We have developed a simple yet effective algorithm for document image clean-up and binarization. The algorithm consists of two basic steps. In the first step, the input image is smoothed using a low-pass filter. The smoothing operation enhances the text relative to any background texture. This is because background texture normally has higher frequency than text does. The smoothing operation also removes speckle noise. In the second step, the intensity histogram of the smoothed image is computed and a threshold automatically selected as follows. For black text, the first peak of the histogram corresponds to text. Thresholding the image at the value of the valley between the first and second peaks of the histogram binarizes the image well. In order to reliably identify the valley, the histogram is smoothed by a low-pass filter before the threshold is computed. The algorithm has been applied to some 50 images from a wide variety of source: digitized video frames, photos, newspapers, advertisements in magazines or sales flyers, personal checks, etc. There are 21820 characters and 4406 words in these images. 91 percent of the characters and 86 percent of the words are successfully cleaned up and binarized. A commercial OCR was applied to the binarized text when it consisted of fonts which were OCR recognizable. The recognition rate was 84 percent for the characters and 77 percent for the words."
            },
            "slug": "Document-image-cleanup-and-binarization-Wu-Manmatha",
            "title": {
                "fragments": [],
                "text": "Document image cleanup and binarization"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A simple yet effective algorithm for document image clean-up and binarization of text over textured or shaded backgrounds, poor contrast, and/or considerable noise is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1971263"
                        ],
                        "name": "K. Etemad",
                        "slug": "K.-Etemad",
                        "structuredName": {
                            "firstName": "Kamran",
                            "lastName": "Etemad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Etemad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 234
                            }
                        ],
                        "text": "\u2026part by the United States Patent and Trademark O ce and Defense Ad-vanced Research Projects Agency/ITO under ARPA order number D468, issued by ESC/AXScontract number F19628-95-C-0235, in part by the National Science Foundation under grantnumber IRI-9619117 and in part by NSF Multimedia CDA-9502639."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27678281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95dffcc92bda88d9f4f5b112d100f43951745b8c",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm for layout-independent document page segmentation based on document texture using multiscale feature vectors and fuzzy local decision information. Multiscale feature vectors are classified locally using a neural network to allow soft/fuzzy multi-class membership assignments. Segmentation is performed by integrating soft local decision vectors to reduce their \"ambiguities\"."
            },
            "slug": "Multiscale-Segmentation-of-Unstructured-Document-Etemad-Doermann",
            "title": {
                "fragments": [],
                "text": "Multiscale Segmentation of Unstructured Document Pages Using Soft Decision Integration"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "An algorithm for layout-independent document page segmentation based on document texture using multiscale feature vectors and fuzzy local decision information is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266621"
                        ],
                        "name": "M. Viswanathan",
                        "slug": "M.-Viswanathan",
                        "structuredName": {
                            "firstName": "Mahesh",
                            "lastName": "Viswanathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Viswanathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 154
                            }
                        ],
                        "text": "However, most such schemes require clean binary input [4, 18, 19, 20]; some assume speci c document layouts such as newspapers [8] and technical journals [11]; others utilize domain-speci c knowledge such as mail address blocks [14] or con gurations of chess games [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 64
                            }
                        ],
                        "text": "cut the page into smaller blocks such as columns and paragraphs [11, 15, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2530196,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62a53caea5213ea177298d7b2aff292b1386c37a",
            "isKey": false,
            "numCitedBy": 434,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Gobbledoc, a system providing remote access to stored documents, which is based on syntactic document analysis and optical character recognition (OCR), is discussed. In Gobbledoc, image processing, document analysis, and OCR operations take place in batch mode when the documents are acquired. The document image acquisition process and the knowledge base that must be entered into the system to process a family of page images are described. The process by which the X-Y tree data structure converts a 2-D page-segmentation problem into a series of 1-D string-parsing problems that can be tackled using conventional compiler tools is also described. Syntactic analysis is used in Gobbledoc to divide each page into labeled rectangular blocks. Blocks labeled text are converted by OCR to obtain a secondary (ASCII) document representation. Since such symbolic files are better suited for computerized search than for human access to the document content and because too many visual layout clues are lost in the OCR process (including some special characters), Gobbledoc preserves the original block images for human browsing. Storage, networking, and display issues specific to document images are also discussed.<<ETX>>"
            },
            "slug": "A-prototype-document-image-analysis-system-for-Nagy-Seth",
            "title": {
                "fragments": [],
                "text": "A prototype document image analysis system for technical journals"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The document image acquisition process and the knowledge base that must be entered into the system to process a family of page images are described, and the process by which the X-Y tree data structure converts a 2-D page-segmentation problem into a series of 1-D string-parsing problems that can be tackled using conventional compiler tools."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70286642"
                        ],
                        "name": "Mindy Bokser",
                        "slug": "Mindy-Bokser",
                        "structuredName": {
                            "firstName": "Mindy",
                            "lastName": "Bokser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mindy Bokser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61670519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c7e86cee5a41818b5307eefc1e31b71233c21b2",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "An optical character recognition (OCR) engine that is omnifont and reasonably robust on individual degraded characters is presented. The weakest link is its handling of characters which are difficult to segment. The engine is divided into four phases: segmentation, image recognition, ambiguity resolution, and document analysis. The features are zonal and reduce the image to a blurred, gray-level representation. The classifier is data-driven, trained offline, and model-free. Handcrafted features and decision trees tend to be brittle in the presence of noise. To satisfy the needs of full-text applications, the system captures the structure of the document so that, when viewed in a word processor or spreadsheet program, the formatting of the optically recognized document reflects that of the original document. To satisfy the needs of the forms market, a proofing and correction tool displays 'pop-up' images of uncertain characters. >"
            },
            "slug": "Omnidocument-technologies-Bokser",
            "title": {
                "fragments": [],
                "text": "Omnidocument technologies"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "An optical character recognition (OCR) engine that is omnifont and reasonably robust on individual degraded characters is presented and captures the structure of the document so that the formatting of the optically recognized document reflects that of the original document."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3151920"
                        ],
                        "name": "C. Glasbey",
                        "slug": "C.-Glasbey",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Glasbey",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Glasbey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 104
                            }
                        ],
                        "text": "A typical OCR system does the binarization to separate text from the background by global thresholding ([5, 13])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10342664,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f013f6dbf26efd35392fb4272f88ac17a53ee92",
            "isKey": false,
            "numCitedBy": 594,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Eleven histogram-based global thresholding algorithms are presented in a common notational framework. Relationships among them are identified from 654 mixtures of two Gaussian distributions, plus effects of mixed pixels. The iterated version of Kittler and Illingworth\u2032s minimum error algorithm ( Pattern Recognition , 19, 1986, 41-47) is found to be best."
            },
            "slug": "An-Analysis-of-Histogram-Based-Thresholding-Glasbey",
            "title": {
                "fragments": [],
                "text": "An Analysis of Histogram-Based Thresholding Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "Eleven histogram-based global thresholding algorithms are presented in a common notational framework and the iterated version of Kittler and Illingworth\u2032s minimum error algorithm is found to be best."
            },
            "venue": {
                "fragments": [],
                "text": "CVGIP Graph. Model. Image Process."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398550688"
                        ],
                        "name": "L. O'Gorman",
                        "slug": "L.-O'Gorman",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "O'Gorman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. O'Gorman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44674932,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2a5b702aec0aa01946f02d190bf9418000559bd",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Thresholding is a common image processing operation applied to gray-scale images to obtain binary or multilevel images. Traditionally, one of two approaches is used: global or locally adaptive processing. However, each of these approaches has a disadvantage: the global approach neglects local information, and the locally adaptive approach neglects global information. A thresholding method is described here that is global in approach, but uses a measure of local information, namely connectivity. Thresholds are found at the intensity levels that best preserve the connectivity of regions within the image. Thus, this method has advantages of both global and locally adaptive approaches. This method is applied here to document images. Experimental comparisons against other thresholding methods show that the connectivity-preserving method yields much improved results. On binary images, this method has been shown to improve subsequent OCR recognition rates from about 95% to 97,5%. More importantly, the new method has been shown to reduce the number of binarization failures (where text is so poorly binarized as to be totally unrecognizable by a commercial OCR system) from 33% to 6% on difficult images. For multilevel document images, as well, the results show similar improvement."
            },
            "slug": "Binarization-and-Multithresholding-of-Document-O'Gorman",
            "title": {
                "fragments": [],
                "text": "Binarization and Multithresholding of Document Images Using Connectivity"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This method has been shown to reduce the number of binarization failures from 33% to 6% on difficult images and to improve subsequent OCR recognition rates from about 95% to 97,5% on binary images."
            },
            "venue": {
                "fragments": [],
                "text": "CVGIP Graph. Model. Image Process."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398550688"
                        ],
                        "name": "L. O'Gorman",
                        "slug": "L.-O'Gorman",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "O'Gorman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. O'Gorman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22995244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d85097da36118fbccfeb7802abf89bf4b4c63a3e",
            "isKey": false,
            "numCitedBy": 728,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Page layout analysis is a document processing technique used to determine the format of a page. This paper describes the document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components. The method yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks. It is advantageous over many other methods in three main ways: independence from skew angle, independence from different text spacings, and the ability to process local regions of different text orientations within the same image. Results of the method shown for several different page formats and for randomly oriented subpages on the same image illustrate the versatility of the method. We also discuss the differences, advantages, and disadvantages of the docstrum with respect to other lay-out methods. >"
            },
            "slug": "The-Document-Spectrum-for-Page-Layout-Analysis-O'Gorman",
            "title": {
                "fragments": [],
                "text": "The Document Spectrum for Page Layout Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components, yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 115479255,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "a8adc8072357c7a500fe04c82f31922cea655dac",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The present invention relates to diacyloxyacids derived from the antibiotic substance, designated acid S, produced by Polyangium cellulosum var. fulvum (ATCC No. 25532), and to processes for their production. The diacyloxyacids derivatives of acid S of this invention are useful as antifungal and antibacterial agents."
            },
            "slug": "A-Color-Edge-Detector-and-Its-Use-in-Scene-Nevatia",
            "title": {
                "fragments": [],
                "text": "A Color Edge Detector and Its Use in Scene Segmentation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102213388"
                        ],
                        "name": "K. Thompson",
                        "slug": "K.-Thompson",
                        "structuredName": {
                            "firstName": "Kendall",
                            "lastName": "Thompson",
                            "middleNames": [
                                "Milar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Thompson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 265
                            }
                        ],
                        "text": "However, most such schemes require clean binary input [4, 18, 19, 20]; some assume speci c document layouts such as newspapers [8] and technical journals [11]; others utilize domain-speci c knowledge such as mail address blocks [14] or con gurations of chess games [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "Other systems utilize domain-speci c knowledge such as mail address blocks [14] or con gurations of chess games [1]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 26523155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5298e5b0a3c18f4ef4b3f09eb8bdc2f7e5f3e22f",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "By applying semantic analysis to images of extended passages of text, several volumes of a chess encyclopedia have been read with high accuracy. Although carefully proofread, the books were poorly printed and posed a severe challenge to conventional page-layout analysis and character-recognition methods. An experimental page-reader system performed strictly top-down layout analysis for identification of columns, lines, words, and characters. This proceeded rapidly and reliably thanks to a recently developed skew-estimation technique. Resegmentation of broken, touching, and dirty characters was handled in an efficient and integrated manner by a heuristic search operating on isolated words. By analyzing the syntax of game descriptions and applying the rules of chess, the error rate was reduced by a factor of 30 from what was achievable through shape analysis alone. Several computer vision systems integration issues suggested by this experience are discussed. >"
            },
            "slug": "Reading-Chess-Baird-Thompson",
            "title": {
                "fragments": [],
                "text": "Reading Chess"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "By applying semantic analysis to images of extended passages of text, several volumes of a chess encyclopedia have been read with high accuracy and the error rate was reduced by a factor of 30 from what was achievable through shape analysis alone."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116645471"
                        ],
                        "name": "Michael A. Smith",
                        "slug": "Michael-A.-Smith",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "1\nTextFinder: An Automatic System ToDetect And Recognize Text In ImagesVictor Wu, R. Manmatha, Edward M. RisemanAbstractThere are many applications in which the automatic detection and recognitionof text embedded in images is useful."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14666057,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d98302953046ebf4d574d05db26a90db95789cc",
            "isKey": false,
            "numCitedBy": 364,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital video is rapidly becoming important for education, entertainment, and a host of multimedia applications. With the size of the video collections growing to thousands of hours, technology is needed to effectively browse segments in a short time without losing the content of the video. We propose a method to extract the significant audio and video information and create a \"skim\" video which represents a very short synopsis of the original. The goal of this work is to show the utility of integrating language and image understanding techniques for video skimming by extraction of significant information, such as specific objects, audio keywords and relevant video structure. The resulting skim video is much shorter, where compaction is as high as 20:1, and yet retains the essential content of the original segment."
            },
            "slug": "Video-skimming-and-characterization-through-the-of-Smith",
            "title": {
                "fragments": [],
                "text": "Video skimming and characterization through the combination of image and language understanding techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The goal of this work is to show the utility of integrating language and image understanding techniques for video skimming by extraction of significant information, such as specific objects, audio keywords and relevant video structure."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3141168"
                        ],
                        "name": "P. W. Palumbo",
                        "slug": "P.-W.-Palumbo",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Palumbo",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. W. Palumbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064971340"
                        ],
                        "name": "Jung Soh",
                        "slug": "Jung-Soh",
                        "structuredName": {
                            "firstName": "Jung",
                            "lastName": "Soh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jung Soh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145912825"
                        ],
                        "name": "R. Sridhar",
                        "slug": "R.-Sridhar",
                        "structuredName": {
                            "firstName": "Ramalingam",
                            "lastName": "Sridhar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sridhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3145150"
                        ],
                        "name": "V. Demjanenko",
                        "slug": "V.-Demjanenko",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Demjanenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Demjanenko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16249736,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "3a9e7bd7f8911d5b2d7b4a5a755dfd4f6770589b",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The CEDAR real-time address block location system, which determines candidates for the location of the destination address from a scanned mail piece image, is described. For each candidate destination address block (DAB), the address block location (ABL) system determines the line segmentation, global orientation, block skew, an indication of whether the address appears to be handwritten or machine printed, and a value indicating the degree of confidence that the block actually contains the destination address. With 20-MHz Sparc processors, the average time per mail piece for the combined hardware and software system components is 0.210 seconds. The system located 89.0% of the addresses as the top choice. Recent developments in the system include the use of a top-down segmentation tool, address syntax analysis using only connected component data, and improvements to the segmentation refinement routines. This has increased top choice performance to 91.4%.<<ETX>>"
            },
            "slug": "Postal-address-block-location-in-real-time-Palumbo-Srihari",
            "title": {
                "fragments": [],
                "text": "Postal address block location in real time"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "Recent developments in the CEDAR real-time address block location system include the use of a top-down segmentation tool, address syntax analysis using only connected component data, and improvements to the segmentation refinement routines."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065554001"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5601682,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "29cb9c230d999a2175c31969f0d90fcae3fb4efe",
            "isKey": false,
            "numCitedBy": 1083,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a model of human preattentive texture perception. This model consists of three stages: (1) convolution of the image with a bank of even-symmetric linear filters followed by half-wave rectification to give a set of responses modeling outputs of V1 simple cells, (2) inhibition, localized in space, within and among the neural-response profiles that results in the suppression of weak responses when there are strong responses at the same or nearby locations, and (3) texture-boundary detection by using wide odd-symmetric mechanisms. Our model can predict the salience of texture boundaries in any arbitrary gray-scale image. A computer implementation of this model has been tested on many of the classic stimuli from psychophysical literature. Quantitative predictions of the degree of discriminability of different texture pairs match well with experimental measurements of discriminability in human observers."
            },
            "slug": "Preattentive-texture-discrimination-with-early-Malik-Perona",
            "title": {
                "fragments": [],
                "text": "Preattentive texture discrimination with early vision mechanisms."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A model of human preattentive texture perception that can predict the salience of texture boundaries in any arbitrary gray-scale image and Quantitative predictions of the degree of discriminability of different texture pairs match well with experimental measurements of discriminateability in human observers."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153312185"
                        ],
                        "name": "S. Mori",
                        "slug": "S.-Mori",
                        "structuredName": {
                            "firstName": "Shunji",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143686714"
                        ],
                        "name": "Kazuhiko Yamamoto",
                        "slug": "Kazuhiko-Yamamoto",
                        "structuredName": {
                            "firstName": "Kazuhiko",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuhiko Yamamoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58021636,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0627cb9872115ea4c4d3484538a2f440923d8f13",
            "isKey": false,
            "numCitedBy": 940,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "Research and development of OCR systems are considered from a historical point of view. The historical development of commercial systems is included. Both template matching and structure analysis approaches to R&D are considered. It is noted that the two approaches are coming closer and tending to merge. Commercial products are divided into three generations, for each of which some representative OCR systems are chosen and described in some detail. Some comments are made on recent techniques applied to OCR, such as expert systems and neural networks, and some open problems are indicated. The authors' views and hopes regarding future trends are presented. >"
            },
            "slug": "Historical-review-of-OCR-research-and-development-Mori-Suen",
            "title": {
                "fragments": [],
                "text": "Historical review of OCR research and development"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Both template matching and structure analysis approaches to R&D are considered and it is noted that the two approaches are coming closer and tending to merge."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "Comparing columns 3 and 4 of Table 3, it is clear that performance of automatic evaluation is close (but slightly lower) to that of visual inspection (see [18] for details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "The accuracy of the cleanup-algorithm was also measured with further discussion and details appearing in [17], [16], [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "A detailed description of the design and implementation of the system is presented in [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "using the same algorithms, with tighter constraints than those used in the Chip Generation phase (see [18] for more details)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aTextFinder: An Automatic System to Detect and Recognize Text in Images,o"
            },
            "venue": {
                "fragments": [],
                "text": "Technicial Report 99-40,"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116415943"
                        ],
                        "name": "B. Yu",
                        "slug": "B.-Yu",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34993677,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73bf7b2fdb26498c05896d99fee4b8f3608c3bd6",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-text-location-in-images-and-video-frames-Jain-Yu",
            "title": {
                "fragments": [],
                "text": "Automatic text location in images and video frames"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "Some work has been done to detect text using color information [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35696139,
            "fieldsOfStudy": [],
            "id": "d68b95534860e2bddd17d17ef7f362d16c550bde",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Locating text in complex color images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1880661"
                        ],
                        "name": "F. Wahl",
                        "slug": "F.-Wahl",
                        "structuredName": {
                            "firstName": "Friedrich",
                            "lastName": "Wahl",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145470231"
                        ],
                        "name": "Kwan Y. Wong",
                        "slug": "Kwan-Y.-Wong",
                        "structuredName": {
                            "firstName": "Kwan",
                            "lastName": "Wong",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kwan Y. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34896449"
                        ],
                        "name": "R. Casey",
                        "slug": "R.-Casey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Casey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Casey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Other schemes require clean binary input [3], [ 13 ], [14], [15]; some assume specific document layouts such as video frames [12], newspapers [6], technical journals [9], l or are domain specific like mail address blocks [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46391416,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d6ddc3eec5641b882c3918a94beb9e6d0701a24a",
            "isKey": false,
            "numCitedBy": 340,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Block-segmentation-and-text-extraction-in-mixed-Wahl-Wong",
            "title": {
                "fragments": [],
                "text": "Block segmentation and text extraction in mixed text/image documents"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Image Process."
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 236467906,
            "fieldsOfStudy": [],
            "id": "0945840c6ca76f2a011b460581ce39072585b4af",
            "isKey": false,
            "numCitedBy": 1198,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Proceedings-of-the-IEEE",
            "title": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "Although there are systems [19], [5], [4] which utilize color information to detect text in color images, the system described in this paper does not use color."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aExtracting Text from WWW Images,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. SPIE'98 Document Recognition V,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Jain and Yu Zhong . Page Segmentation Using Texture Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision , Graphics and Image Processing"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "1\nTextFinder: An Automatic System ToDetect And Recognize Text In ImagesVictor Wu, R. Manmatha, Edward M. RisemanAbstractThere are many applications in which the automatic detection and recognitionof text embedded in images is useful."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analysis System,\u00ba IBM Journal Res. Dev"
            },
            "venue": {
                "fragments": [],
                "text": "Analysis System,\u00ba IBM Journal Res. Dev"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "Other schemes require clean binary input [3], [13], [14], [15]; some assume specific document layouts such as video frames [12], newspapers [6], technical journals [9], l or are domain specific like mail address blocks [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aDocument Analysis System,o"
            },
            "venue": {
                "fragments": [],
                "text": "IBM Journal Res. Dev.,"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "Other schemes require clean binary input [3], [13], [14], [15]; some assume specific document layouts such as video frames [12], newspapers [6], technical journals [9], l or are domain specific like mail address blocks [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "Although two recent papers [12], [4] provide results on detection accuracy and false alarms, the methodology has either been restricted to specific classes of images or is not extendable for automatic evaluation on large collections of diverse images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aVideo Skimming and Characterization through the Combination of Image and Language Understanding Techniques,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Page Segmentation and Classiication. CVGIP: Graphical Models and Image Processing"
            },
            "venue": {
                "fragments": [],
                "text": "Page Segmentation and Classiication. CVGIP: Graphical Models and Image Processing"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaTextFinder: An Automatic System to Detect and Recognize Text in Images"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaTextFinder: An Automatic System to Detect and Recognize Text in Images"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classiication of Newspaper Image Blocks Using Texture Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision, Graphics and Image Processing"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "This consists of a linear filtering stage followed by a nonlinear stage [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aPreattentive Texture Discrimination with Early Vision Mechanisms,o"
            },
            "venue": {
                "fragments": [],
                "text": "J. Opt. Soc. Am.,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[2] used a neural net to classify the output of wavelets into text and nontext regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chellapa, aMultiscale Segmentation of Unstructured Document Pages Using Soft Decision Integration,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Images,\u00ba Proc. the Second Int'l Conf. Digital Libraries"
            },
            "venue": {
                "fragments": [],
                "text": "Images,\u00ba Proc. the Second Int'l Conf. Digital Libraries"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 110
                            }
                        ],
                        "text": "1\nTextFinder: An Automatic System ToDetect And Recognize Text In ImagesVictor Wu, R. Manmatha, Edward M. RisemanAbstractThere are many applications in which the automatic detection and recognitionof text embedded in images is useful."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Viswanathan, \u00aaA Prototype Document Image Analysis System for Technical Journals,\u00ba Computer"
            },
            "venue": {
                "fragments": [],
                "text": "Viswanathan, \u00aaA Prototype Document Image Analysis System for Technical Journals,\u00ba Computer"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "The accuracy of the cleanup-algorithm was also measured with further discussion and details appearing in [17], [16], [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "A simple, effective histogram-based algorithm, as described in [16], is used to find the threshold value automatically for each text region."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aDocument Image Clean-Up and Binarizationo"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. SPIE'98 Document Recognition V,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "Other schemes require clean binary input [3], [13], [14], [15]; some assume specific document layouts such as video frames [12], newspapers [6], technical journals [9], l or are domain specific like mail address blocks [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Segmentation and Text Extraction in Mixed Text/Image Documents,o"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Graphics and Image Processing,"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "However, current optical character recognition (OCR) technology [1], [8] is restricted to finding text printed against clean backgrounds, and cannot handle text printed against shaded or textured backgrounds or embedded in images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aHistorical Review of OCR Research and Development,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 145
                            }
                        ],
                        "text": "\u2026DepartmentUniversity of Massachusetts, Amherst, MA 01003-4610Email:fvwu,manmathag@cs.umass.eduNovember 18, 1997 This material is based on work supported in part by the National Science Foundation,Library of Congress and Department of Commerce under cooperative agreement numberEEC-9209623, in\u2026"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "Other schemes require clean binary input [3], [13], [14], [15]; some assume specific document layouts such as video frames [12], newspapers [6], technical journals [9], l or are domain specific like mail address blocks [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aClassification of Newspaper Image Blocks Using Texture Analysis,o"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision, Graphics, and Imaging Processing,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document Analysis System. IBM Journal Res. Dev"
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis System. IBM Journal Res. Dev"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 140
                            }
                        ],
                        "text": "Other schemes require clean binary input [3], [13], [14], [15]; some assume specific document layouts such as video frames [12], newspapers [6], technical journals [9], l or are domain specific like mail address blocks [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aExtraction of Binary Character/Graphics Images from Grayscale Document Images,o"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision, Graphics, and Imaging Processing,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 32
                            }
                        ],
                        "text": "However, current OCR technology [2, 10] is largely restricted to nding text printed against clean backgrounds, and cannot handle text printed against shaded or textured backgrounds, and/or embedded in images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Omnidocument Technoligies"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of The IEEE,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 54
                            }
                        ],
                        "text": "However, most such schemes require clean binary input [4, 18, 19, 20]; some assume speci c document layouts such as newspapers [8] and technical journals [11]; others utilize domain-speci c knowledge such as mail address blocks [14] or con gurations of chess games [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 165
                            }
                        ],
                        "text": "Classic top-down techniques are based on the run length smoothing (RLS) algorithm [18, 20] to smooth the image rst, then, horizontal and vertical projection pro les [19] are commonly used to 5"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 64
                            }
                        ],
                        "text": "cut the page into smaller blocks such as columns and paragraphs [11, 15, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classi cation of Newspaper Image Blocks Using Texture  Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision, Graphics and Image Processing, 47:327{352"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 150
                            }
                        ],
                        "text": "\u2026DepartmentUniversity of Massachusetts, Amherst, MA 01003-4610Email:fvwu,manmathag@cs.umass.eduNovember 18, 1997 This material is based on work supported in part by the National Science Foundation,Library of Congress and Department of Commerce under cooperative agreement numberEEC-9209623, in part\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1992
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 22,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 53,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/TextFinder:-An-Automatic-System-to-Detect-and-Text-Wu-Manmatha/e5c342ba0edbebadc7c95c7e59d1bef87d7e4add?sort=total-citations"
}