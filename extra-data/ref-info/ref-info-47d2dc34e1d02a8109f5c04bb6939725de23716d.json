{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360972"
                        ],
                        "name": "Abdel-rahman Mohamed",
                        "slug": "Abdel-rahman-Mohamed",
                        "structuredName": {
                            "firstName": "Abdel-rahman",
                            "lastName": "Mohamed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel-rahman Mohamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Graves et al. (2013b), on the other hand, used a separate multi-layer perceptron (MLP) to combine the two scores from the transcription and prediction networks and achieved the state-of-the-art performance on the TIMIT dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 54
                            }
                        ],
                        "text": "For instance, the proposed approach is related to the RNN Transducer in the sense that scores are computed for all pairs of positions in the input and output sentences."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 65
                            }
                        ],
                        "text": "Unlike the CTC, which can be seen as an acoustic-only model, the RNN Transducer has another RNN that acts as a language model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 31
                            }
                        ],
                        "text": "These two components allow the RNN Transducer to model the probability of observing the next output symbol given its position in both the input and output sequences."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 164
                            }
                        ],
                        "text": "The proposed model is an extension of the network used for neural machine translation (Bahdanau et al., 2014) and is closely related to CTC and the RNN Transducer (Graves et al., 2006, 2013b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 150
                            }
                        ],
                        "text": "In addition the decoder state of our model contains information about previous alignment choices unlike the states of the generation network from the RNN Transducer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 52
                            }
                        ],
                        "text": "Furthermore, it has been reported by, for instance, Graves et al. (2013a) that the improvements in the per-frame classification do not necessarily translate to the decoding accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 54
                            }
                        ],
                        "text": "As an extension of the CTC Graves (2012) proposed the RNN Transducer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 4
                            }
                        ],
                        "text": "The RNN Transducer computes the score of each possible output token based on the position in the input and output sequences."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 16
                            }
                        ],
                        "text": "However, in the RNN Transducer the scores define a distribution over a latent alignment, which is then marginalized out."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 62
                            }
                        ],
                        "text": "The model we consider in this paper is closely related to the RNN Transducer, however, with an attention mechanism that decides which input frames be used to generate the next output element."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 271
                            }
                        ],
                        "text": "\u2026has recently made important progress by adopting, as an accoustic model, deep neural networks such as fully-connected feedforward neural networks (A Mohamed et al., 2009; Hinton et al., 2012a), convolutional networks (Sainath et al., 2014), and recurrent networks (RNN, Graves et al., 2013a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 186
                            }
                        ],
                        "text": "The encoder is implemented using a cascade of a multilayer Maxout network (Goodfellow et al., 2013a) whose last layer is fed to a bi-directional RNN (BiRNN) (Schuster and Paliwal, 1997; Graves et al., 2013a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206741496,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4177ec52d1b80ed57f2e72b0f9a42365f1a8598d",
            "isKey": true,
            "numCitedBy": 6900,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score."
            },
            "slug": "Speech-recognition-with-deep-recurrent-neural-Graves-Mohamed",
            "title": {
                "fragments": [],
                "text": "Speech recognition with deep recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35188630"
                        ],
                        "name": "George E. Dahl",
                        "slug": "George-E.-Dahl",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Dahl",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George E. Dahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360972"
                        ],
                        "name": "Abdel-rahman Mohamed",
                        "slug": "Abdel-rahman-Mohamed",
                        "structuredName": {
                            "firstName": "Abdel-rahman",
                            "lastName": "Mohamed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel-rahman Mohamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3111912"
                        ],
                        "name": "Navdeep Jaitly",
                        "slug": "Navdeep-Jaitly",
                        "structuredName": {
                            "firstName": "Navdeep",
                            "lastName": "Jaitly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Navdeep Jaitly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33666044"
                        ],
                        "name": "A. Senior",
                        "slug": "A.-Senior",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Senior",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Senior"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14902530"
                        ],
                        "name": "P. Nguyen",
                        "slug": "P.-Nguyen",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Nguyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784851"
                        ],
                        "name": "T. Sainath",
                        "slug": "T.-Sainath",
                        "structuredName": {
                            "firstName": "Tara",
                            "lastName": "Sainath",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sainath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144707379"
                        ],
                        "name": "Brian Kingsbury",
                        "slug": "Brian-Kingsbury",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Kingsbury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Kingsbury"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 172
                            }
                        ],
                        "text": "\u2026has recently made important progress by adopting, as an accoustic model, deep neural networks such as fully-connected feedforward neural networks (A Mohamed et al., 2009; Hinton et al., 2012a), convolutional networks (Sainath et al., 2014), and recurrent networks (RNN, Graves et al., 2013a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 195
                            }
                        ],
                        "text": "To ease training of the network we decided to initialize the acoustic part of the RNN encoder with weights of a deep Maxout network trained with dropout regularization (Goodfellow et al., 2013a; Hinton et al., 2012b) to predict the states of the HMM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206485943,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31868290adf1c000c611dfc966b514d5a34e8d23",
            "isKey": false,
            "numCitedBy": 7452,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition."
            },
            "slug": "Deep-Neural-Networks-for-Acoustic-Modeling-in-The-Hinton-Deng",
            "title": {
                "fragments": [],
                "text": "Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "This article provides an overview of progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Processing Magazine"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360972"
                        ],
                        "name": "Abdel-rahman Mohamed",
                        "slug": "Abdel-rahman-Mohamed",
                        "structuredName": {
                            "firstName": "Abdel-rahman",
                            "lastName": "Mohamed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel-rahman Mohamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35188630"
                        ],
                        "name": "George E. Dahl",
                        "slug": "George-E.-Dahl",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Dahl",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George E. Dahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 150
                            }
                        ],
                        "text": "\u2026has recently made important progress by adopting, as an accoustic model, deep neural networks such as fully-connected feedforward neural networks (A Mohamed et al., 2009; Hinton et al., 2012a), convolutional networks (Sainath et al., 2014), and recurrent networks (RNN, Graves et al., 2013a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 131773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f37cfdc4520c56c1eaf87cee5ec2a4028ceaa9c5",
            "isKey": false,
            "numCitedBy": 406,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov Models (HMMs) have been the state-of-the-art techniques for acoustic modeling despite their unrealistic independence assumptions and the very limited representational capacity of their hidden states. There are many proposals in the research community for deeper models that are capable of modeling the many types of variability present in the speech generation p r cess. Deep Belief Networks (DBNs) have recently proved to be very effective fo r a variety of machine learning problems and this paper applies DBNs to acous ti modeling. On the standard TIMIT corpus, DBNs consistently outperform ot her techniques and the best DBN achieves a phone error rate (PER) of 23.0% on the T IMIT core test set."
            },
            "slug": "Deep-Belief-Networks-for-phone-recognition-Mohamed-Dahl",
            "title": {
                "fragments": [],
                "text": "Deep Belief Networks for phone recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Deep Belief Networks (DBNs) have recently proved to be very effective in a variety of machine learning problems and this paper applies DBNs to acous ti modeling."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144707379"
                        ],
                        "name": "Brian Kingsbury",
                        "slug": "Brian-Kingsbury",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Kingsbury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Kingsbury"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 206
                            }
                        ],
                        "text": "Once a per-frame classifier is trained, the whole system including the acoustic model and the HMM can be tuned jointly on full sentences to minimize the decoding error (LeCun et al., 1998; He et al., 2008; Kingsbury, 2009; Vesel et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14733612,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2443dc59cf3d6cc1deba6d3220d61664b1a7eada",
            "isKey": false,
            "numCitedBy": 294,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Acoustic models used in hidden Markov model/neural-network (HMM/NN) speech recognition systems are usually trained with a frame-based cross-entropy error criterion. In contrast, Gaussian mixture HMM systems are discriminatively trained using sequence-based criteria, such as minimum phone error or maximum mutual information, that are more directly related to speech recognition accuracy. This paper demonstrates that neural-network acoustic models can be trained with sequence classification criteria using exactly the same lattice-based methods that have been developed for Gaussian mixture HMMs, and that using a sequence classification criterion in training leads to considerably better performance. A neural network acoustic model with 153K weights trained on 50 hours of broadcast news has a word error rate of 34.0% on the rt04 English broadcast news test set. When this model is trained with the state-level minimum Bayes risk criterion, the rt04 word error rate is 27.7%."
            },
            "slug": "Lattice-based-optimization-of-sequence-criteria-for-Kingsbury",
            "title": {
                "fragments": [],
                "text": "Lattice-based optimization of sequence classification criteria for neural-network acoustic modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper demonstrates that neural-network acoustic models can be trained with sequence classification criteria using exactly the same lattice-based methods that have been developed for Gaussian mixture HMMs, and that using a sequence classification criterion in training leads to considerably better performance."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3111912"
                        ],
                        "name": "Navdeep Jaitly",
                        "slug": "Navdeep-Jaitly",
                        "structuredName": {
                            "firstName": "Navdeep",
                            "lastName": "Jaitly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Navdeep Jaitly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360972"
                        ],
                        "name": "Abdel-rahman Mohamed",
                        "slug": "Abdel-rahman-Mohamed",
                        "structuredName": {
                            "firstName": "Abdel-rahman",
                            "lastName": "Mohamed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel-rahman Mohamed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Graves et al. (2013b), on the other hand, used a separate multi-layer perceptron (MLP) to combine the two scores from the transcription and prediction networks and achieved the state-of-the-art performance on the TIMIT dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 54
                            }
                        ],
                        "text": "For instance, the proposed approach is related to the RNN Transducer in the sense that scores are computed for all pairs of positions in the input and output sentences."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 65
                            }
                        ],
                        "text": "Unlike the CTC, which can be seen as an acoustic-only model, the RNN Transducer has another RNN that acts as a language model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 31
                            }
                        ],
                        "text": "These two components allow the RNN Transducer to model the probability of observing the next output symbol given its position in both the input and output sequences."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 164
                            }
                        ],
                        "text": "The proposed model is an extension of the network used for neural machine translation (Bahdanau et al., 2014) and is closely related to CTC and the RNN Transducer (Graves et al., 2006, 2013b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 65
                            }
                        ],
                        "text": ", 2013a) whose last layer is fed to a bi-directional RNN (BiRNN) (Schuster and Paliwal, 1997; Graves et al., 2013a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 150
                            }
                        ],
                        "text": "In addition the decoder state of our model contains information about previous alignment choices unlike the states of the generation network from the RNN Transducer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 52
                            }
                        ],
                        "text": "Furthermore, it has been reported by, for instance, Graves et al. (2013a) that the improvements in the per-frame classification do not necessarily translate to the decoding accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 54
                            }
                        ],
                        "text": "As an extension of the CTC Graves (2012) proposed the RNN Transducer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 4
                            }
                        ],
                        "text": "The RNN Transducer computes the score of each possible output token based on the position in the input and output sequences."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 16
                            }
                        ],
                        "text": "However, in the RNN Transducer the scores define a distribution over a latent alignment, which is then marginalized out."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 62
                            }
                        ],
                        "text": "The model we consider in this paper is closely related to the RNN Transducer, however, with an attention mechanism that decides which input frames be used to generate the next output element."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 271
                            }
                        ],
                        "text": "\u2026has recently made important progress by adopting, as an accoustic model, deep neural networks such as fully-connected feedforward neural networks (A Mohamed et al., 2009; Hinton et al., 2012a), convolutional networks (Sainath et al., 2014), and recurrent networks (RNN, Graves et al., 2013a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 186
                            }
                        ],
                        "text": "The encoder is implemented using a cascade of a multilayer Maxout network (Goodfellow et al., 2013a) whose last layer is fed to a bi-directional RNN (BiRNN) (Schuster and Paliwal, 1997; Graves et al., 2013a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3338763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1149888d75af4ed5dffc25731b875651c3ccdeb2",
            "isKey": true,
            "numCitedBy": 1300,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Bidirectional LSTM (DBLSTM) recurrent neural networks have recently been shown to give state-of-the-art performance on the TIMIT speech database. However, the results in that work relied on recurrent-neural-network-specific objective functions, which are difficult to integrate with existing large vocabulary speech recognition systems. This paper investigates the use of DBLSTM as an acoustic model in a standard neural network-HMM hybrid system. We find that a DBLSTM-HMM hybrid gives equally good results on TIMIT as the previous work. It also outperforms both GMM and deep network benchmarks on a subset of the Wall Street Journal corpus. However the improvement in word error rate over the deep network is modest, despite a great increase in framelevel accuracy. We conclude that the hybrid approach with DBLSTM appears to be well suited for tasks where acoustic modelling predominates. Further investigation needs to be conducted to understand how to better leverage the improvements in frame-level accuracy towards better word error rates."
            },
            "slug": "Hybrid-speech-recognition-with-Deep-Bidirectional-Graves-Jaitly",
            "title": {
                "fragments": [],
                "text": "Hybrid speech recognition with Deep Bidirectional LSTM"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The hybrid approach with DBLSTM appears to be well suited for tasks where acoustic modelling predominates, and the improvement in word error rate over the deep network is modest, despite a great increase in framelevel accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE Workshop on Automatic Speech Recognition and Understanding"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143913738"
                        ],
                        "name": "Santiago Fern\u00e1ndez",
                        "slug": "Santiago-Fern\u00e1ndez",
                        "structuredName": {
                            "firstName": "Santiago",
                            "lastName": "Fern\u00e1ndez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Santiago Fern\u00e1ndez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145842938"
                        ],
                        "name": "Faustino J. Gomez",
                        "slug": "Faustino-J.-Gomez",
                        "structuredName": {
                            "firstName": "Faustino",
                            "lastName": "Gomez",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Faustino J. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 54
                            }
                        ],
                        "text": "For instance, the proposed approach is related to the RNN Transducer in the sense that scores are computed for all pairs of positions in the input and output sentences."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 65
                            }
                        ],
                        "text": "Unlike the CTC, which can be seen as an acoustic-only model, the RNN Transducer has another RNN that acts as a language model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 31
                            }
                        ],
                        "text": "These two components allow the RNN Transducer to model the probability of observing the next output symbol given its position in both the input and output sequences."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 164
                            }
                        ],
                        "text": "The proposed model is an extension of the network used for neural machine translation (Bahdanau et al., 2014) and is closely related to CTC and the RNN Transducer (Graves et al., 2006, 2013b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 150
                            }
                        ],
                        "text": "In addition the decoder state of our model contains information about previous alignment choices unlike the states of the generation network from the RNN Transducer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 29
                            }
                        ],
                        "text": "Along this line of research, Graves et al. (2006) proposed, more recently, an alternative approach called the Connectionist Temporal Classifier (CTC), which can be used without an explicit input-output alignment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 54
                            }
                        ],
                        "text": "As an extension of the CTC Graves (2012) proposed the RNN Transducer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 4
                            }
                        ],
                        "text": "The RNN Transducer computes the score of each possible output token based on the position in the input and output sequences."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 16
                            }
                        ],
                        "text": "However, in the RNN Transducer the scores define a distribution over a latent alignment, which is then marginalized out."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 62
                            }
                        ],
                        "text": "The model we consider in this paper is closely related to the RNN Transducer, however, with an attention mechanism that decides which input frames be used to generate the next output element."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9901844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96494e722f58705fa20302fe6179d483f52705b4",
            "isKey": true,
            "numCitedBy": 3477,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Many real-world sequence learning tasks require the prediction of sequences of labels from noisy, unsegmented input data. In speech recognition, for example, an acoustic signal is transcribed into words or sub-word units. Recurrent neural networks (RNNs) are powerful sequence learners that would seem well suited to such tasks. However, because they require pre-segmented training data, and post-processing to transform their outputs into label sequences, their applicability has so far been limited. This paper presents a novel method for training RNNs to label unsegmented sequences directly, thereby solving both problems. An experiment on the TIMIT speech corpus demonstrates its advantages over both a baseline HMM and a hybrid HMM-RNN."
            },
            "slug": "Connectionist-temporal-classification:-labelling-Graves-Fern\u00e1ndez",
            "title": {
                "fragments": [],
                "text": "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents a novel method for training RNNs to label unsegmented sequences directly, thereby solving both problems of sequence learning and post-processing."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714393"
                        ],
                        "name": "R. Mori",
                        "slug": "R.-Mori",
                        "structuredName": {
                            "firstName": "Renato",
                            "lastName": "Mori",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2376916"
                        ],
                        "name": "G. Flammia",
                        "slug": "G.-Flammia",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Flammia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Flammia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688499"
                        ],
                        "name": "R. Kompe",
                        "slug": "R.-Kompe",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Kompe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kompe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 171
                            }
                        ],
                        "text": "In contrast, some earlier works have proposed to minimize the final decoding error directly by optimizing the sum of costs along the paths in an alignment/decision graph (Bengio et al., 1992; LeCun et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 143
                            }
                        ],
                        "text": "It is possible to obtain the training target for each frame of the acoustic input by coupling a neural network to a Hidden Markov Model (HMM) (Bengio et al., 1992; Bourlard and Morgan, 1994; Bengio, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 894840,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ffbe67c217967b6bfb0a5ecc0dc4cdd5cda65776",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "An original method for integrating artificial neural networks (ANN) with hidden Markov models (HMM) is proposed. ANNs are suitable for performing phonetic classification, whereas HMMs have been proven successful at modeling the temporal structure of the speech signal. In the approach described, the ANN outputs constitute the sequence of observation vectors for the HMM. An algorithm is proposed for global optimization of all the parameters. Results on speaker-independent recognition experiments using this integrated ANN-HMM system on the TIMIT continuous speech database are reported.<<ETX>>"
            },
            "slug": "Global-optimization-of-a-neural-network-hidden-Bengio-Mori",
            "title": {
                "fragments": [],
                "text": "Global optimization of a neural network-hidden Markov model hybrid"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "An original method for integrating artificial neural networks (ANN) with hidden Markov models (HMM) with results on speaker-independent recognition experiments using this integrated ANN-HMM system on the TIMIT continuous speech database are reported."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3158246"
                        ],
                        "name": "Bart van Merrienboer",
                        "slug": "Bart-van-Merrienboer",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Merrienboer",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bart van Merrienboer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1854385"
                        ],
                        "name": "\u00c7aglar G\u00fcl\u00e7ehre",
                        "slug": "\u00c7aglar-G\u00fcl\u00e7ehre",
                        "structuredName": {
                            "firstName": "\u00c7aglar",
                            "lastName": "G\u00fcl\u00e7ehre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c7aglar G\u00fcl\u00e7ehre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335364"
                        ],
                        "name": "Dzmitry Bahdanau",
                        "slug": "Dzmitry-Bahdanau",
                        "structuredName": {
                            "firstName": "Dzmitry",
                            "lastName": "Bahdanau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dzmitry Bahdanau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076086"
                        ],
                        "name": "Fethi Bougares",
                        "slug": "Fethi-Bougares",
                        "structuredName": {
                            "firstName": "Fethi",
                            "lastName": "Bougares",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fethi Bougares"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518416"
                        ],
                        "name": "Holger Schwenk",
                        "slug": "Holger-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Holger Schwenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 53
                            }
                        ],
                        "text": "The proposed model (a variant of RNN Encoder\u2013Decoder (Cho et al., 2014; Bahdanau et al., 2014)) instead uses the scores as an explicit alignment which is used to compute a context vector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 124
                            }
                        ],
                        "text": "The recurrent state update (f ) is computed using an affine layer with a reset-update gate used as the activation function (Cho et al., 2014) to keep track of long-term dependencies."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 76
                            }
                        ],
                        "text": "The BiRNN uses the reset-update gate to account for long-term dependencies (Cho et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5590763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b544dfe355a5070b60986319a3f51fb45d1348e",
            "isKey": false,
            "numCitedBy": 15052,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel neural network model called RNN Encoder\u2010 Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder\u2010Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases."
            },
            "slug": "Learning-Phrase-Representations-using-RNN-for-Cho-Merrienboer",
            "title": {
                "fragments": [],
                "text": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Qualitatively, the proposed RNN Encoder\u2010Decoder model learns a semantically and syntactically meaningful representation of linguistic phrases."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144927151"
                        ],
                        "name": "M. Schuster",
                        "slug": "M.-Schuster",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Schuster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schuster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099761"
                        ],
                        "name": "K. Paliwal",
                        "slug": "K.-Paliwal",
                        "structuredName": {
                            "firstName": "Kuldip",
                            "lastName": "Paliwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Paliwal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 158
                            }
                        ],
                        "text": "The encoder is implemented using a cascade of a multilayer Maxout network (Goodfellow et al., 2013a) whose last layer is fed to a bi-directional RNN (BiRNN) (Schuster and Paliwal, 1997; Graves et al., 2013a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 65
                            }
                        ],
                        "text": ", 2013a) whose last layer is fed to a bi-directional RNN (BiRNN) (Schuster and Paliwal, 1997; Graves et al., 2013a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18375389,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e23c34414e66118ecd9b08cf0cd4d016f59b0b85",
            "isKey": false,
            "numCitedBy": 5379,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In the first part of this paper, a regular recurrent neural network (RNN) is extended to a bidirectional recurrent neural network (BRNN). The BRNN can be trained without the limitation of using input information just up to a preset future frame. This is accomplished by training it simultaneously in positive and negative time direction. Structure and training procedure of the proposed network are explained. In regression and classification experiments on artificial data, the proposed structure gives better results than other approaches. For real data, classification experiments for phonemes from the TIMIT database show the same tendency. In the second part of this paper, it is shown how the proposed bidirectional structure can be easily modified to allow efficient estimation of the conditional posterior probability of complete symbol sequences without making any explicit assumption about the shape of the distribution. For this part, experiments on real data are reported."
            },
            "slug": "Bidirectional-recurrent-neural-networks-Schuster-Paliwal",
            "title": {
                "fragments": [],
                "text": "Bidirectional recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown how the proposed bidirectional structure can be easily modified to allow efficient estimation of the conditional posterior probability of complete symbol sequences without making any explicit assumption about the shape of the distribution."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2459598"
                        ],
                        "name": "Karel Vesel\u00fd",
                        "slug": "Karel-Vesel\u00fd",
                        "structuredName": {
                            "firstName": "Karel",
                            "lastName": "Vesel\u00fd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karel Vesel\u00fd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2268620"
                        ],
                        "name": "Arnab Ghoshal",
                        "slug": "Arnab-Ghoshal",
                        "structuredName": {
                            "firstName": "Arnab",
                            "lastName": "Ghoshal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnab Ghoshal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1816892"
                        ],
                        "name": "L. Burget",
                        "slug": "L.-Burget",
                        "structuredName": {
                            "firstName": "Luk\u00e1\u0161",
                            "lastName": "Burget",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Burget"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792214"
                        ],
                        "name": "Daniel Povey",
                        "slug": "Daniel-Povey",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Povey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Povey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 223
                            }
                        ],
                        "text": "Once a per-frame classifier is trained, the whole system including the acoustic model and the HMM can be tuned jointly on full sentences to minimize the decoding error (LeCun et al., 1998; He et al., 2008; Kingsbury, 2009; Vesel et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2827512,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b48168acba4a6ca33ad0f11bbf1c7d8106333822",
            "isKey": false,
            "numCitedBy": 663,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequence-discriminative training of deep neural networks (DNNs) is investigated on a standard 300 hour American En- glish conversational telephone speech task. Different sequence- discriminative criteria \u2014 maximum mutual information (MMI), minimum phone error (MPE), state-level minimum Bayes risk (sMBR), and boosted MMI \u2014 are compared. Two different heuristics are investigated to improve the performance of the DNNs trained using sequence-based criteria \u2014 lattices are re- generated after the first iteration of training; and, for MMI and BMMI, the frames where the numerator and denominator hy- potheses are disjoint are removed from the gradient compu- tation. Starting from a competitive DNN baseline trained us- ing cross-entropy, different sequence-discriminative criteria are shown to lower word error rates by 7-9% relative, on aver- age. Little difference is noticed between the different sequence- based criteria that are investigated. The experiments are done using the open-source Kaldi toolkit, which makes it possible for the wider community to reproduce these results. Index Terms: speech recognition, deep learning, sequence- criterion training, neural networks, reproducible research"
            },
            "slug": "Sequence-discriminative-training-of-deep-neural-Vesel\u00fd-Ghoshal",
            "title": {
                "fragments": [],
                "text": "Sequence-discriminative training of deep neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "Different sequence-discriminative criteria are shown to lower word error rates by 7-9% relative, on a standard 300 hour American conversational telephone speech task."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 164
                            }
                        ],
                        "text": "It is possible to obtain the training target for each frame of the acoustic input by coupling a neural network to a Hidden Markov Model (HMM) (Bengio et al., 1992; Bourlard and Morgan, 1994; Bengio, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61058350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d82e058a5c40954b8f5db170a298a889a254c37",
            "isKey": false,
            "numCitedBy": 1409,
            "numCiting": 190,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nConnectionist Speech Recognition: A Hybrid Approach describes the theory and implementation of a method to incorporate neural network approaches into state-of-the-art continuous speech recognition systems based on Hidden Markov Models (HMMs) to improve their performance. In this framework, neural networks (and in particular, multilayer perceptrons or MLPs) have been restricted to well-defined subtasks of the whole system, i.e., HMM emission probability estimation and feature extraction. The book describes a successful five year international collaboration between the authors. The lessons learned form a case study that demonstrates how hybrid systems can be developed to combine neural networks with more traditional statistical approaches. The book illustrates both the advantages and limitations of neural networks in the framework of a statistical system. Using standard databases and comparing with some conventional approaches, it is shown that MLP probability estimation can improve recognition performance. Other approaches are discussed, though there is no such unequivocal experimental result for these methods. Connectionist Speech Recognition: A Hybrid Approach is of use to anyone intending to use neural networks for speech recognition or within the framework provided by an existing successful statistical approach. This includes research and development groups working in the field of speech recognition, both with standard and neural network approaches, as well as other pattern recognition and/or neural network researchers. This book is also suitable as a text for advanced courses on neural networks or speech processing."
            },
            "slug": "Connectionist-Speech-Recognition:-A-Hybrid-Approach-Bourlard-Morgan",
            "title": {
                "fragments": [],
                "text": "Connectionist Speech Recognition: A Hybrid Approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784851"
                        ],
                        "name": "T. Sainath",
                        "slug": "T.-Sainath",
                        "structuredName": {
                            "firstName": "Tara",
                            "lastName": "Sainath",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sainath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144707379"
                        ],
                        "name": "Brian Kingsbury",
                        "slug": "Brian-Kingsbury",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Kingsbury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Kingsbury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698208"
                        ],
                        "name": "G. Saon",
                        "slug": "G.-Saon",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Saon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Saon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38940652"
                        ],
                        "name": "H. Soltau",
                        "slug": "H.-Soltau",
                        "structuredName": {
                            "firstName": "Hagen",
                            "lastName": "Soltau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Soltau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360972"
                        ],
                        "name": "Abdel-rahman Mohamed",
                        "slug": "Abdel-rahman-Mohamed",
                        "structuredName": {
                            "firstName": "Abdel-rahman",
                            "lastName": "Mohamed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel-rahman Mohamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35188630"
                        ],
                        "name": "George E. Dahl",
                        "slug": "George-E.-Dahl",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Dahl",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George E. Dahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720857"
                        ],
                        "name": "B. Ramabhadran",
                        "slug": "B.-Ramabhadran",
                        "structuredName": {
                            "firstName": "Bhuvana",
                            "lastName": "Ramabhadran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ramabhadran"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 219
                            }
                        ],
                        "text": "\u2026has recently made important progress by adopting, as an accoustic model, deep neural networks such as fully-connected feedforward neural networks (A Mohamed et al., 2009; Hinton et al., 2012a), convolutional networks (Sainath et al., 2014), and recurrent networks (RNN, Graves et al., 2013a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 33
                            }
                        ],
                        "text": ", 2012a), convolutional networks (Sainath et al., 2014), and recurrent networks (RNN, Graves et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 25303291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ef763cb4f13f8dc9d4376b5ad8f377331e8572d",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Deep-Convolutional-Neural-Networks-for-Large-scale-Sainath-Kingsbury",
            "title": {
                "fragments": [],
                "text": "Deep Convolutional Neural Networks for Large-scale Speech Tasks"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 191
                            }
                        ],
                        "text": "It is possible to obtain the training target for each frame of the acoustic input by coupling a neural network to a Hidden Markov Model (HMM) (Bengio et al., 1992; Bourlard and Morgan, 1994; Bengio, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61008692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a02df6b956612047a9493baba5218f01ed44af00",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Connectionist models Learning theory The back-propagation algorithm Introduction to back-propagation Formal description Heuristics to improve convergence and generalization Extensions Integrating domain knowledge and learning from examples Automatic speech recognition Importance of pre-processing input data Input coding. Input invariances Importance of architecture constraints on the network Modularization Output coding Sequence analysis Introduction Time delay neural networks Recurrent networks BPS Supervision of a recurrent network does not need to be everywhere Problems with training of recurrent networks Dynamic programming post-processors Hidden Markov models Integrating ANNs with other systems Advantages and disadvantages of current algorithms for ANNs Modularization and joint optimization Radial basis functions and local representation Radial basis funtions networks Neurobiological plausibility Relation to vector quantization, clustering and semi-continuous HMMs Methodology Experiments on phoneme recognition with RBFs Density estimation with a neural network Relation between input PDF and output PDF Density estimation Conclusion Post-processors based on dynamic programming ANN/DP hybrids ANN/HMM Hybrids ANN/HMM Hybrid: Phoneme recognition experiments ANN/HMM hybrid: online handwriting recognition experiments."
            },
            "slug": "Neural-networks-for-speech-and-sequence-recognition-Bengio",
            "title": {
                "fragments": [],
                "text": "Neural networks for speech and sequence recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents post-processors based on dynamic programming ANN/DP hybrids ANN/HMM Hybrids, and experiments on phoneme recognition with RBFs and online handwriting recognition experiments."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "Similarly to the CTC, the probability of observing an output sequence for a given input is computed using the forward-backward algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "Unlike the CTC, which can be seen as an acoustic-only model, the RNN Transducer has another RNN that acts as a language model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 136
                            }
                        ],
                        "text": "The proposed model is an extension of the network used for neural machine translation (Bahdanau et al., 2014) and is closely related to CTC and the RNN Transducer (Graves et al., 2006, 2013b)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "In the CTC-based model, each per-frame prediction is either one of the set of desired outputs (words, phones) or a special separator symbol."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 145
                            }
                        ],
                        "text": "Along this line of research, Graves et al. (2006) proposed, more recently, an alternative approach called the Connectionist Temporal Classifier (CTC), which can be used without an explicit input-output alignment."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 27
                            }
                        ],
                        "text": "As an extension of the CTC Graves (2012) proposed the RNN Transducer."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17194112,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "7b4f3d0e4e2486a8d5d3f8e00549cf9a117bf88f",
            "isKey": true,
            "numCitedBy": 974,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Many machine learning tasks can be expressed as the transformation---or \\emph{transduction}---of input sequences into output sequences: speech recognition, machine translation, protein secondary structure prediction and text-to-speech to name but a few. One of the key challenges in sequence transduction is learning to represent both the input and output sequences in a way that is invariant to sequential distortions such as shrinking, stretching and translating. Recurrent neural networks (RNNs) are a powerful sequence learning architecture that has proven capable of learning such representations. However RNNs traditionally require a pre-defined alignment between the input and output sequences to perform transduction. This is a severe limitation since \\emph{finding} the alignment is the most difficult aspect of many sequence transduction problems. Indeed, even determining the length of the output sequence is often challenging. This paper introduces an end-to-end, probabilistic sequence transduction system, based entirely on RNNs, that is in principle able to transform any input sequence into any finite, discrete output sequence. Experimental results for phoneme recognition are provided on the TIMIT speech corpus."
            },
            "slug": "Sequence-Transduction-with-Recurrent-Neural-Graves",
            "title": {
                "fragments": [],
                "text": "Sequence Transduction with Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper introduces an end-to-end, probabilistic sequence transduction system, based entirely on RNNs, that is in principle able to transform any input sequence into any finite, discrete output sequence."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 58
                            }
                        ],
                        "text": "The attention mechanism in this respect was first used by Graves (2013) to build a neural network that generates convincing handwriting from a given text."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 138
                            }
                        ],
                        "text": "Accessing the input sequence through a context vector is related to the model that generates handwritten characters, proposed recently by Graves (2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1697424,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89b1f4740ae37fd04f6ac007577bdd34621f0861",
            "isKey": false,
            "numCitedBy": 3153,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles."
            },
            "slug": "Generating-Sequences-With-Recurrent-Neural-Networks-Graves",
            "title": {
                "fragments": [],
                "text": "Generating Sequences With Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2897313"
                        ],
                        "name": "Nitish Srivastava",
                        "slug": "Nitish-Srivastava",
                        "structuredName": {
                            "firstName": "Nitish",
                            "lastName": "Srivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nitish Srivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 172
                            }
                        ],
                        "text": "\u2026has recently made important progress by adopting, as an accoustic model, deep neural networks such as fully-connected feedforward neural networks (A Mohamed et al., 2009; Hinton et al., 2012a), convolutional networks (Sainath et al., 2014), and recurrent networks (RNN, Graves et al., 2013a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 195
                            }
                        ],
                        "text": "To ease training of the network we decided to initialize the acoustic part of the RNN encoder with weights of a deep Maxout network trained with dropout regularization (Goodfellow et al., 2013a; Hinton et al., 2012b) to predict the states of the HMM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14832074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1366de5bb112746a555e9c0cd00de3ad8628aea8",
            "isKey": false,
            "numCitedBy": 6191,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This \"overfitting\" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random \"dropout\" gives big improvements on many benchmark tasks and sets new records for speech and object recognition."
            },
            "slug": "Improving-neural-networks-by-preventing-of-feature-Hinton-Srivastava",
            "title": {
                "fragments": [],
                "text": "Improving neural networks by preventing co-adaptation of feature detectors"
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792214"
                        ],
                        "name": "Daniel Povey",
                        "slug": "Daniel-Povey",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Povey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Povey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2268620"
                        ],
                        "name": "Arnab Ghoshal",
                        "slug": "Arnab-Ghoshal",
                        "structuredName": {
                            "firstName": "Arnab",
                            "lastName": "Ghoshal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnab Ghoshal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2541218"
                        ],
                        "name": "Gilles Boulianne",
                        "slug": "Gilles-Boulianne",
                        "structuredName": {
                            "firstName": "Gilles",
                            "lastName": "Boulianne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gilles Boulianne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1816892"
                        ],
                        "name": "L. Burget",
                        "slug": "L.-Burget",
                        "structuredName": {
                            "firstName": "Luk\u00e1\u0161",
                            "lastName": "Burget",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Burget"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3075141"
                        ],
                        "name": "O. Glembek",
                        "slug": "O.-Glembek",
                        "structuredName": {
                            "firstName": "Ondrej",
                            "lastName": "Glembek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Glembek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46356878"
                        ],
                        "name": "N. Goel",
                        "slug": "N.-Goel",
                        "structuredName": {
                            "firstName": "Nagendra",
                            "lastName": "Goel",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Goel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2592983"
                        ],
                        "name": "M. Hannemann",
                        "slug": "M.-Hannemann",
                        "structuredName": {
                            "firstName": "Mirko",
                            "lastName": "Hannemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hannemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2745667"
                        ],
                        "name": "P. Motl\u00edcek",
                        "slug": "P.-Motl\u00edcek",
                        "structuredName": {
                            "firstName": "Petr",
                            "lastName": "Motl\u00edcek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Motl\u00edcek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2480051"
                        ],
                        "name": "Y. Qian",
                        "slug": "Y.-Qian",
                        "structuredName": {
                            "firstName": "Yanmin",
                            "lastName": "Qian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Qian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35455336"
                        ],
                        "name": "Petr Schwarz",
                        "slug": "Petr-Schwarz",
                        "structuredName": {
                            "firstName": "Petr",
                            "lastName": "Schwarz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Petr Schwarz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3330139"
                        ],
                        "name": "J. Silovsk\u00fd",
                        "slug": "J.-Silovsk\u00fd",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Silovsk\u00fd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Silovsk\u00fd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708033"
                        ],
                        "name": "G. Stemmer",
                        "slug": "G.-Stemmer",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Stemmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Stemmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2459598"
                        ],
                        "name": "Karel Vesel\u00fd",
                        "slug": "Karel-Vesel\u00fd",
                        "structuredName": {
                            "firstName": "Karel",
                            "lastName": "Vesel\u00fd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karel Vesel\u00fd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1774023,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a1a2cff2b70fb84a7ca7d97f8adcc5855851795",
            "isKey": false,
            "numCitedBy": 5127,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the design of Kaldi, a free, open-source toolkit for speech recognition research. Kaldi provides a speech recognition system based on finite-state automata (using the freely available OpenFst), together with detailed documentation and a comprehensive set of scripts for building complete recognition systems. Kaldi is written is C++, and the core library supports modeling of arbitrary phonetic-context sizes, acoustic modeling with subspace Gaussian mixture models (SGMM) as well as standard Gaussian mixture models, together with all commonly used linear and affine transforms. Kaldi is released under the Apache License v2.0, which is highly nonrestrictive, making it suitable for a wide community of users."
            },
            "slug": "The-Kaldi-Speech-Recognition-Toolkit-Povey-Ghoshal",
            "title": {
                "fragments": [],
                "text": "The Kaldi Speech Recognition Toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The design of Kaldi is described, a free, open-source toolkit for speech recognition research that provides a speech recognition system based on finite-state automata together with detailed documentation and a comprehensive set of scripts for building complete recognition systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335364"
                        ],
                        "name": "Dzmitry Bahdanau",
                        "slug": "Dzmitry-Bahdanau",
                        "structuredName": {
                            "firstName": "Dzmitry",
                            "lastName": "Bahdanau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dzmitry Bahdanau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 46
                            }
                        ],
                        "text": "sequence with elements of the output sequence (Bahdanau et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 104
                            }
                        ],
                        "text": "A similar approach of attention was used more recently in a so-called \u201cneural machine translation model\u201d (Bahdanau et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 87
                            }
                        ],
                        "text": "The proposed model is an extension of the network used for neural machine translation (Bahdanau et al., 2014) and is closely related to CTC and the RNN Transducer (Graves et al., 2006, 2013b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 71
                            }
                        ],
                        "text": "The proposed model (a variant of RNN Encoder\u2013Decoder (Cho et al., 2014; Bahdanau et al., 2014)) instead uses the scores as an explicit alignment which is used to compute a context vector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 142
                            }
                        ],
                        "text": "This is different from the usual use of the word decoder in speech recognition systems to talk\nsequence with elements of the output sequence (Bahdanau et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11212020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "isKey": false,
            "numCitedBy": 19346,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition."
            },
            "slug": "Neural-Machine-Translation-by-Jointly-Learning-to-Bahdanau-Cho",
            "title": {
                "fragments": [],
                "text": "Neural Machine Translation by Jointly Learning to Align and Translate"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and it is proposed to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 169
                            }
                        ],
                        "text": "Once a per-frame classifier is trained, the whole system including the acoustic model and the HMM can be tuned jointly on full sentences to minimize the decoding error (LeCun et al., 1998; He et al., 2008; Kingsbury, 2009; Vesel et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 192
                            }
                        ],
                        "text": "In contrast, some earlier works have proposed to minimize the final decoding error directly by optimizing the sum of costs along the paths in an alignment/decision graph (Bengio et al., 1992; LeCun et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35268,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48799969"
                        ],
                        "name": "Matthew D. Zeiler",
                        "slug": "Matthew-D.-Zeiler",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Zeiler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew D. Zeiler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 87
                            }
                        ],
                        "text": "The RNN was trained with stochastic gradient descent using the AdaDelta learning rule (Zeiler, 2012) and an adaptive gradient clipping mechanism described in section 3.2.1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7365802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8729441d734782c3ed532a7d2d9611b438c0a09a",
            "isKey": true,
            "numCitedBy": 5464,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment."
            },
            "slug": "ADADELTA:-An-Adaptive-Learning-Rate-Method-Zeiler",
            "title": {
                "fragments": [],
                "text": "ADADELTA: An Adaptive Learning Rate Method"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A novel per-dimension learning rate method for gradient descent called ADADELTA that dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153440022"
                        ],
                        "name": "Ian J. Goodfellow",
                        "slug": "Ian-J.-Goodfellow",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Goodfellow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian J. Goodfellow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393680089"
                        ],
                        "name": "David Warde-Farley",
                        "slug": "David-Warde-Farley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Warde-Farley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Warde-Farley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153583218"
                        ],
                        "name": "Mehdi Mirza",
                        "slug": "Mehdi-Mirza",
                        "structuredName": {
                            "firstName": "Mehdi",
                            "lastName": "Mirza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mehdi Mirza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 70
                            }
                        ],
                        "text": "We have chosen this hybrid architecture to combine the ability of the Maxout network to nonlinearly transform speech features with the efficient summarization of nearby preceding and following input frames provided by the BiRNN."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 169
                            }
                        ],
                        "text": "To ease training of the network we decided to initialize the acoustic part of the RNN encoder with weights of a deep Maxout network trained with dropout regularization (Goodfellow et al., 2013a; Hinton et al., 2012b) to predict the states of the HMM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 74
                            }
                        ],
                        "text": "The encoder is implemented using a cascade of a multilayer Maxout network (Goodfellow et al., 2013a) whose last layer is fed to a bi-directional RNN (BiRNN) (Schuster and Paliwal, 1997; Graves et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 55
                            }
                        ],
                        "text": "Finally, we included into training the pre-initialized Maxout part of the encoder."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 76
                            }
                        ],
                        "text": "The next output prediction (g) is realized with an MLP composed of a Maxout (Goodfellow et al., 2013a) and SoftMax layers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 77
                            }
                        ],
                        "text": "The next output prediction (g) is realized with an MLP composed of a Maxout (Goodfellow et al., 2013a) and SoftMax layers.\nabout the search algorithm which approximately looks for the most probable configuration of latent and output variables (the output sequence), e.g., using beam-search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 85
                            }
                        ],
                        "text": "The networks were implemented using the Theano (Bergstra et al., 2010) and Pylearn2 (Goodfellow et al., 2013b) libraries."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 75
                            }
                        ],
                        "text": "The encoder is implemented using a cascade of a multilayer Maxout network (Goodfellow et al., 2013a) whose last layer is fed to a bi-directional RNN (BiRNN) (Schuster and Paliwal, 1997; Graves et al., 2013a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 38
                            }
                        ],
                        "text": "Each utterance was processed with the Maxout network, and then we appended a frame containing only zeros to indicate to the RNN where the utterance ends."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10600578,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7b915d508987b73b61eccd2b237e7ed099a2d29",
            "isKey": false,
            "numCitedBy": 1822,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN."
            },
            "slug": "Maxout-Networks-Goodfellow-Warde-Farley",
            "title": {
                "fragments": [],
                "text": "Maxout Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A simple new model called maxout is defined designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996134"
                        ],
                        "name": "Razvan Pascanu",
                        "slug": "Razvan-Pascanu",
                        "structuredName": {
                            "firstName": "Razvan",
                            "lastName": "Pascanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Razvan Pascanu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 129
                            }
                        ],
                        "text": "In order to avoid the issue of exploding gradient, we rescaled the norm of the gradient, if it went over a predefined threshold (Pascanu et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14650762,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84069287da0a6b488b8c933f3cb5be759cb6237e",
            "isKey": false,
            "numCitedBy": 3802,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "There are two widely known issues with properly training recurrent neural networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section."
            },
            "slug": "On-the-difficulty-of-training-recurrent-neural-Pascanu-Mikolov",
            "title": {
                "fragments": [],
                "text": "On the difficulty of training recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper proposes a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem and validates empirically the hypothesis and proposed solutions."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137069"
                        ],
                        "name": "Xiaodong He",
                        "slug": "Xiaodong-He",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145320076"
                        ],
                        "name": "W. Chou",
                        "slug": "W.-Chou",
                        "structuredName": {
                            "firstName": "Wu",
                            "lastName": "Chou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Chou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 189
                            }
                        ],
                        "text": "Once a per-frame classifier is trained, the whole system including the acoustic model and the HMM can be tuned jointly on full sentences to minimize the decoding error (LeCun et al., 1998; He et al., 2008; Kingsbury, 2009; Vesel et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17976965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d63cdc1d1f023c63f8aa3b64cd5e853670680c3e",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we studied the objective functions of MMI, MCE, and MPE/MWE for discriminative learning in sequential pattern recognition. We presented an approach that unifies the objective functions of MMI, MCE, and MPE/MWE in a common rational-function form of (25). The exact structure of the rational-function form for each discriminative criterion was derived and studied. While the rational-function form of MMI has been known in the past, we provided the theoretical proof that the similar rational-function form exists for the objective functions of MCE and MPE/MWE. Moreover, we showed that the rational function forms for objective functions of MMI, MCE, and MPE/MWE differ in the constant weighting factors CDT (s1 . . . sR) and these weighting factors depend only on the labeled sequence s1 . . . sR, and are independent of the parameter set - to be optimized. The derived rational-function form for MMI, MCE, and MPE/MWE allows the GT/EBW-based parameter optimization framework to be applied directly in discriminative learning. In the past, lack of the appropriate rational-function form was a difficulty for MCE and MPE/MWE, because without this form, the GT/EBW-based parameter optimization framework cannot be directly applied. Based on the unified rational-function form, in a tutorial style, we derived the GT/EBW-based parameter optimization formulas for both discrete HMMs and CDHMMs in discriminative learning using MMI, MCE, and MPE/MWE criteria. The unifying review provided in this article has been based upon a large number of earlier contributions that have been cited and discussed throughout the article. Here we provide a brief summary of such background work. Extension to large-scale speech recognition tasks was accomplished in the work of [59] and [60]. The dissertation of [47] further improved the MMI criterion to that of MPE/MWE. In a parallel vein, the work of [20] provided an alternative approach to that of [41], with an attempt to more rigorously provide a CDHMM model re-estimation formula that gives positive growth of the MMI objective function. A crucial error of this attempt was corrected in [2] for establishing an existence proof of such positive growth. The main goal of this article is to provide an underlying foundation for MMI, MCE, and MPE/MWE at the objective function level to facilitate the development of new parameter optimization techniques and to incorporate other pattern recognition concepts, e.g., discriminative margins [66], into the current discriminative learning paradigm."
            },
            "slug": "Discriminative-learning-in-sequential-pattern-He-Deng",
            "title": {
                "fragments": [],
                "text": "Discriminative learning in sequential pattern recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The main goal of this article is to provide an underlying foundation for MMI, MCE, and MPE/MWE at the objective function level to facilitate the development of new parameter optimization techniques and to incorporate other pattern recognition concepts, e.g., discriminative margins [66], into the current discrim inative learning paradigm."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Processing Magazine"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 70
                            }
                        ],
                        "text": "We have chosen this hybrid architecture to combine the ability of the Maxout network to nonlinearly transform speech features with the efficient summarization of nearby preceding and following input frames provided by the BiRNN."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 169
                            }
                        ],
                        "text": "To ease training of the network we decided to initialize the acoustic part of the RNN encoder with weights of a deep Maxout network trained with dropout regularization (Goodfellow et al., 2013a; Hinton et al., 2012b) to predict the states of the HMM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 55
                            }
                        ],
                        "text": "Finally, we included into training the pre-initialized Maxout part of the encoder."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 77
                            }
                        ],
                        "text": "The next output prediction (g) is realized with an MLP composed of a Maxout (Goodfellow et al., 2013a) and SoftMax layers.\nabout the search algorithm which approximately looks for the most probable configuration of latent and output variables (the output sequence), e.g., using beam-search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 85
                            }
                        ],
                        "text": "The networks were implemented using the Theano (Bergstra et al., 2010) and Pylearn2 (Goodfellow et al., 2013b) libraries."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 75
                            }
                        ],
                        "text": "The encoder is implemented using a cascade of a multilayer Maxout network (Goodfellow et al., 2013a) whose last layer is fed to a bi-directional RNN (BiRNN) (Schuster and Paliwal, 1997; Graves et al., 2013a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 38
                            }
                        ],
                        "text": "Each utterance was processed with the Maxout network, and then we appended a frame containing only zeros to indicate to the RNN where the utterance ends."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maxout networks. In ICML'2013"
            },
            "venue": {
                "fragments": [],
                "text": "Maxout networks. In ICML'2013"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153440022"
                        ],
                        "name": "Ian J. Goodfellow",
                        "slug": "Ian-J.-Goodfellow",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Goodfellow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian J. Goodfellow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393680089"
                        ],
                        "name": "David Warde-Farley",
                        "slug": "David-Warde-Farley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Warde-Farley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Warde-Farley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087941"
                        ],
                        "name": "Pascal Lamblin",
                        "slug": "Pascal-Lamblin",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Lamblin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Lamblin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3074927"
                        ],
                        "name": "Vincent Dumoulin",
                        "slug": "Vincent-Dumoulin",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Dumoulin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Dumoulin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153583218"
                        ],
                        "name": "Mehdi Mirza",
                        "slug": "Mehdi-Mirza",
                        "structuredName": {
                            "firstName": "Mehdi",
                            "lastName": "Mirza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mehdi Mirza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996134"
                        ],
                        "name": "Razvan Pascanu",
                        "slug": "Razvan-Pascanu",
                        "structuredName": {
                            "firstName": "Razvan",
                            "lastName": "Pascanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Razvan Pascanu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32837403"
                        ],
                        "name": "J. Bergstra",
                        "slug": "J.-Bergstra",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227028"
                        ],
                        "name": "Fr\u00e9d\u00e9ric Bastien",
                        "slug": "Fr\u00e9d\u00e9ric-Bastien",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Bastien",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fr\u00e9d\u00e9ric Bastien"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 70
                            }
                        ],
                        "text": "We have chosen this hybrid architecture to combine the ability of the Maxout network to nonlinearly transform speech features with the efficient summarization of nearby preceding and following input frames provided by the BiRNN."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 169
                            }
                        ],
                        "text": "To ease training of the network we decided to initialize the acoustic part of the RNN encoder with weights of a deep Maxout network trained with dropout regularization (Goodfellow et al., 2013a; Hinton et al., 2012b) to predict the states of the HMM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 55
                            }
                        ],
                        "text": "Finally, we included into training the pre-initialized Maxout part of the encoder."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 77
                            }
                        ],
                        "text": "The next output prediction (g) is realized with an MLP composed of a Maxout (Goodfellow et al., 2013a) and SoftMax layers.\nabout the search algorithm which approximately looks for the most probable configuration of latent and output variables (the output sequence), e.g., using beam-search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 85
                            }
                        ],
                        "text": "The networks were implemented using the Theano (Bergstra et al., 2010) and Pylearn2 (Goodfellow et al., 2013b) libraries."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 75
                            }
                        ],
                        "text": "The encoder is implemented using a cascade of a multilayer Maxout network (Goodfellow et al., 2013a) whose last layer is fed to a bi-directional RNN (BiRNN) (Schuster and Paliwal, 1997; Graves et al., 2013a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 38
                            }
                        ],
                        "text": "Each utterance was processed with the Maxout network, and then we appended a frame containing only zeros to indicate to the RNN where the utterance ends."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2172854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "836acf6fc99ebf81d219e2b67f7ab25efc29a6a4",
            "isKey": false,
            "numCitedBy": 297,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Pylearn2 is a machine learning research library. This does not just mean that it is a collection of machine learning algorithms that share a common API; it means that it has been designed for flexibility and extensibility in order to facilitate research projects that involve new or unusual use cases. In this paper we give a brief history of the library, an overview of its basic philosophy, a summary of the library's architecture, and a description of how the Pylearn2 community functions socially."
            },
            "slug": "Pylearn2:-a-machine-learning-research-library-Goodfellow-Warde-Farley",
            "title": {
                "fragments": [],
                "text": "Pylearn2: a machine learning research library"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A brief history of the library, an overview of its basic philosophy, a summary of the Library's architecture, and a description of how the Pylearn2 community functions socially are given."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 48
                            }
                        ],
                        "text": "The networks were implemented using the Theano (Bergstra et al., 2010) and Pylearn2 (Goodfellow et al., 2013b) libraries."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theano: a CPU and GPU math expression compiler"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Python for scientific computing conference (SciPy), volume 4, page 3. 7"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theano: a CPU and GPU math expression compiler"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Python for scientific computing conference (SciPy)"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 23,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 27,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/End-to-end-Continuous-Speech-Recognition-using-NN:-Chorowski-Bahdanau/47d2dc34e1d02a8109f5c04bb6939725de23716d?sort=total-citations"
}