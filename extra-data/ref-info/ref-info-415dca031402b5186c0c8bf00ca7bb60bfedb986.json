{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403615640"
                        ],
                        "name": "D. Servan-Schreiber",
                        "slug": "D.-Servan-Schreiber",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Servan-Schreiber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Servan-Schreiber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29942829"
                        ],
                        "name": "A. Cleeremans",
                        "slug": "A.-Cleeremans",
                        "structuredName": {
                            "firstName": "Axel",
                            "lastName": "Cleeremans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cleeremans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701656"
                        ],
                        "name": "James L. McClelland",
                        "slug": "James-L.-McClelland",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "McClelland",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James L. McClelland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18569620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0d7f8b5d54e3d68fd45a70d4a0d13f42e8d71ff",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore a network architecture introduced by Elman (1988) for predicting successive elements of a sequence. The network uses the pattern of activation over a set of hidden units from time-step t-1, together with element t, to predict element t+1. When the network is trained with strings from a particular finite-state grammar, it can learn to be a perfect finite-state recognizer for the grammar. Cluster analyses of the hidden-layer patterns of activation showed that they encode prediction-relevant information about the entire path traversed through the network. We illustrate the phases of learning with cluster analyses performed at different points during training."
            },
            "slug": "Learning-Subsequential-Structure-in-Simple-Networks-Servan-Schreiber-Cleeremans",
            "title": {
                "fragments": [],
                "text": "Learning Subsequential Structure in Simple Recurrent Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A network architecture introduced by Elman (1988) for predicting successive elements of a sequence using the pattern of activation over a set of hidden units to be illustrated with cluster analyses performed at different points during training."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34922532"
                        ],
                        "name": "Guo-Zheng Sun",
                        "slug": "Guo-Zheng-Sun",
                        "structuredName": {
                            "firstName": "Guo-Zheng",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guo-Zheng Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115401300"
                        ],
                        "name": "Hsing-Hen Chen",
                        "slug": "Hsing-Hen-Chen",
                        "structuredName": {
                            "firstName": "Hsing-Hen",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsing-Hen Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2552960"
                        ],
                        "name": "Yee-Chun Lee",
                        "slug": "Yee-Chun-Lee",
                        "structuredName": {
                            "firstName": "Yee-Chun",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yee-Chun Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158193072"
                        ],
                        "name": "Dong Chen",
                        "slug": "Dong-Chen",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 25151650,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25c19c8c1d6778a16f8b27beac4d9c6a55357580",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A higher order single layer recursive network easily learns to simulate a deterministic finite state machine and recognize regular grammars. When an enhanced version of this neural net state machine is connected through a common error term to an external analog stack memory, the combination can be interpreted as a neural net pushdown automata. The neural net finite state machine is given the primitives, push and POP, and is able to read the top of the stack. Through a gradient descent learning rule derived from the common error function, the hybrid network learns to effectively use the stack actions to manipulate the stack memory and to learn simple contextfree grammars."
            },
            "slug": "Higher-Order-Recurrent-Networks-and-Grammatical-Giles-Sun",
            "title": {
                "fragments": [],
                "text": "Higher Order Recurrent Networks and Grammatical Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A higher order single layer recursive network easily learns to simulate a deterministic finite state machine and recognize regular grammars and can be interpreted as a neural net pushdown automata."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 93
                            }
                        ],
                        "text": "These results are of import to many related neural models currently under development, e.g. (Elman, 1990; Giles et aI., 1990; Servan-Schreiber et al., 1989), and relates ultimately to the question of how linguistic capacity can arise in nature."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 0
                            }
                        ],
                        "text": "(Elman, 1990; Giles et aI., 1990; Servan-Schreiber et al., 1989), and relates ultimately to the question of how linguistic capacity can arise in nature."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2763403,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "668087f0ae7ce1de6e0bd0965dbb480c08103260",
            "isKey": false,
            "numCitedBy": 9858,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands; indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction."
            },
            "slug": "Finding-Structure-in-Time-Elman",
            "title": {
                "fragments": [],
                "text": "Finding Structure in Time"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory and suggests a method for representing lexical categories and the type/token distinction is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761373"
                        ],
                        "name": "J. Crutchfield",
                        "slug": "J.-Crutchfield",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Crutchfield",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Crutchfield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065242656"
                        ],
                        "name": "K. Young",
                        "slug": "K.-Young",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Young"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 150
                            }
                        ],
                        "text": "\u2026been brought out in the work of (Wolfram, 1984) and others on the universality of cellular automata, and more recently in the work of (Crutchfield & Young, 1989) on the descriptive complexity of bifurcating systems: What is the relationship between complex dynamics (of neural systems) and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6669806,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c321c8d9d9231ddfe661a03ae7b872adab3fc3fe",
            "isKey": false,
            "numCitedBy": 212,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Computationat levelsbeyondstorageandtransmissionof informationappearsin physical systemsat phasetransitions.We investigatethis phenomenonusingminimal computational modelsof dynamicalsystemsthat undergo a transitionto chaosasa function of a nonlinearity parameter.For period-doublingandband-mer ging cascades, we deriveexpressionsfor the entropy,the interdependenceof -machinecomplexityandentropy,andthe latentcomplexity of the transitionto chaos.At the transitiondeterministicfinite automatonmodelsdiverge in size. Although thereis no regularor context-freeChomskygrammarin this case,we give finite descriptionsat the highercomputationalevel of context-freeLindenmayersystems.We constructa restrictedindexedcontext-freegrammarand its associatedone-way nondeterministicnestedstackautomatonfor the cascadelimit language. This analysisof a family of dynamicalsystemssuggestsa complexity theoreticdescriptionof phasetransitionsbasedon the informationaldiversity andcomputationalcomplexityof observeddatathat is independent of particularsystemcontrol parameters.The approachgives a muchmorerefinedpictureof the architectureof critical statesthan is availablevia correlationfunctions,mutual information,andstatisticalmechanicsgenerally.The analytic methodsestablishquantitativelythe longstandingobservationthat significant computationis associatedwith the critical statesfound at the borderbetweenorderandchaos. Appearing in Complexity, Entropy, and Physics of Information, W. Zur ek, editor, Addison-Wesley,Reading, Massachusetts(1989). *JPC\u2019sInternetaddressis chaos@gojira.berkeley.edu. KY\u2019s permanentaddress:PhysicsBoardof Studies,University of California,SantaCruz, CA 95064.His Internetaddressis karl@gojira.berkeley.edu"
            },
            "slug": "Computation-at-the-Onset-of-Chaos-Crutchfield-Young",
            "title": {
                "fragments": [],
                "text": "Computation at the Onset of Chaos"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This analysis of a family of dynamicalsystemsuggests a complexity theoretic description of phasetransitions based on the informational diversity andcomputationalcomplexity of observeddatathat is independent of particular systemcontrol parameters."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794321"
                        ],
                        "name": "B. Huberman",
                        "slug": "B.-Huberman",
                        "structuredName": {
                            "firstName": "Bernardo",
                            "lastName": "Huberman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Huberman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144157926"
                        ],
                        "name": "T. Hogg",
                        "slug": "T.-Hogg",
                        "structuredName": {
                            "firstName": "Tad",
                            "lastName": "Hogg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hogg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5143317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c4ef6b97566c1ee8ecb00462c547fe071407ab3",
            "isKey": false,
            "numCitedBy": 147,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Phase-Transitions-in-Artificial-Intelligence-Huberman-Hogg",
            "title": {
                "fragments": [],
                "text": "Phase Transitions in Artificial Intelligence Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145539951"
                        ],
                        "name": "J. Pollack",
                        "slug": "J.-Pollack",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Pollack",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pollack"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 64
                            }
                        ],
                        "text": "The complete experimental data is available in a longer report (pollack, 1990b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 770011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a835df43fdc2f79126319f6fa033bb42147c6f6",
            "isKey": false,
            "numCitedBy": 948,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recursive-Distributed-Representations-Pollack",
            "title": {
                "fragments": [],
                "text": "Recursive Distributed Representations"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143898851"
                        ],
                        "name": "S. Wolfram",
                        "slug": "S.-Wolfram",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Wolfram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wolfram"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 51772341,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dfa75daabfc8201a98c892bb706bbf179f2ba4bf",
            "isKey": false,
            "numCitedBy": 1962,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Universality-and-complexity-in-cellular-automata-Wolfram",
            "title": {
                "fragments": [],
                "text": "Universality and complexity in cellular automata"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51902284"
                        ],
                        "name": "C. Skarda",
                        "slug": "C.-Skarda",
                        "structuredName": {
                            "firstName": "Christine",
                            "lastName": "Skarda",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Skarda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144784302"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Freeman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 125
                            }
                        ],
                        "text": "The link between work in complex dynamical systems and neural networks is wellestablished both on the neurobiological level (Skarda & Freeman, 1987) and on the mathematical level (Derrida & Meir, 1988; Huberman & Hogg, 1987; Kurten, 1987; Smolensky, 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18498339,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "fa18cf2efa4c454da93178180258524f9a0add17",
            "isKey": false,
            "numCitedBy": 1933,
            "numCiting": 206,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Recent \u201cconnectionist\u201d models provide a new explanatory alternative to the digital computer as a model for brain function. Evidence from our EEG research on the olfactory bulb suggests that the brain may indeed use computational mechanisms like those found in connectionist models. In the present paper we discuss our data and develop a model to describe the neural dynamics responsible for odor recognition and discrimination. The results indicate the existence of sensory- and motor-specific information in the spatial dimension of EEG activity and call for new physiological metaphors and techniques of analysis. Special emphasis is placed in our model on chaotic neural activity. We hypothesize that chaotic behavior serves as the essential ground state for the neural perceptual apparatus, and we propose a mechanism for acquiring new forms of patterned activity corresponding to new learned odors. Finally, some of the implications of our neural model for behavioral theories are briefly discussed. Our research, in concert with the connectionist work, encourages a reevaluation of explanatory models that are based only on the digital computer metaphor."
            },
            "slug": "How-brains-make-chaos-in-order-to-make-sense-of-the-Skarda-Freeman",
            "title": {
                "fragments": [],
                "text": "How brains make chaos in order to make sense of the world"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A model to describe the neural dynamics responsible for odor recognition and discrimination is developed and it is hypothesized that chaotic behavior serves as the essential ground state for the neural perceptual apparatus and a mechanism for acquiring new forms of patterned activity corresponding to new learned odors is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Behavioral and Brain Sciences"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748557"
                        ],
                        "name": "P. Smolensky",
                        "slug": "P.-Smolensky",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Smolensky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Smolensky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 179
                            }
                        ],
                        "text": "The link between work in complex dynamical systems and neural networks is wellestablished both on the neurobiological level (Skarda & Freeman, 1987) and on the mathematical level (Derrida & Meir, 1988; Huberman & Hogg, 1987; Kurten, 1987; Smolensky, 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 533055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f7476037408ac3d993f5088544aab427bc319c1",
            "isKey": false,
            "numCitedBy": 1947,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : At this early stage in the development of cognitive science, methodological issues are both open and central. There may have been times when developments in neuroscience, artificial intelligence, or cognitive psychology seduced researchers into believing that their discipline was on the verge of discovering the secret of intelligence. But a humbling history of hopes disappointed has produced the realization that understanding the mind will challenge the power of all these methodologies combined. The work reported in this chapter rests on the conviction that a methodology that has a crucial role to play in the development of cognitive science is mathematical analysis. The success of cognitive science, like that of many other sciences, will, I believe, depend upon the construction of a solid body of theoretical results: results that express in a mathematical language the conceptual insights of the field; results that squeeze all possible implications out of those insights by exploiting powerful mathematical techniques. This body of results, which I will call the theory of information processing, exists because information is a concept that lends itself to mathematical formalization. One part of the theory of information processing is already well-developed. The classical theory of computation provides powerful and elegant results about the notion of effective procedure, including languages for precisely expressing them and theoretical machines for realizing them."
            },
            "slug": "Information-processing-in-dynamical-systems:-of-Smolensky",
            "title": {
                "fragments": [],
                "text": "Information processing in dynamical systems: foundations of harmony theory"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The work reported in this chapter rests on the conviction that a methodology that has a crucial role to play in the development of cognitive science is mathematical analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4605464"
                        ],
                        "name": "W. McCulloch",
                        "slug": "W.-McCulloch",
                        "structuredName": {
                            "firstName": "Warren",
                            "lastName": "McCulloch",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. McCulloch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50314979"
                        ],
                        "name": "W. Pitts",
                        "slug": "W.-Pitts",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Pitts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Pitts"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 120118103,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "3573a93812370debd39ba8c40288ffd59abe8ff2",
            "isKey": false,
            "numCitedBy": 8114,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Logical-Calculus-of-the-Ideas-Immanent-in-Nervous-McCulloch-Pitts",
            "title": {
                "fragments": [],
                "text": "A logical calculus of the ideas immanent in nervous activity"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145539951"
                        ],
                        "name": "J. Pollack",
                        "slug": "J.-Pollack",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Pollack",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pollack"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 91
                            }
                        ],
                        "text": "This paper expands a theme from an earlier proposal to link them at the \"cognitive\" level (pollack, 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11012105,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d259baddcfcbcdd3471eb66444633d7c60352a8c",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "I will describe my recent results on the automatic development of fixed-width recursive distributed representations of variable-sized hierarchal data structures. One implication of this work is that certain types of AI-style data-structures can now be represented in fixed-width analog vectors. Simple inferences can be performed using the type of pattern associations that neural networks excel at Another implication arises from noting that these representations become self-similar in the limit. Once this door to chaos is opened, many interesting new questions about the representational basis of intelligence emerge, and can (and will) be discussed."
            },
            "slug": "Implications-of-Recursive-Distributed-Pollack",
            "title": {
                "fragments": [],
                "text": "Implications of Recursive Distributed Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The recent results on the automatic development of fixed-width recursive distributed representations of variable-sized hierarchal data structures suggest that certain types of AI-style data-structures can now be represented in fixed- width analog vectors."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2445287"
                        ],
                        "name": "P. Grassberger",
                        "slug": "P.-Grassberger",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Grassberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Grassberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4056787"
                        ],
                        "name": "I. Procaccia",
                        "slug": "I.-Procaccia",
                        "structuredName": {
                            "firstName": "Itamar",
                            "lastName": "Procaccia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Procaccia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 209833433,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e0d11f893fa0b9bd1553e5b1bc2b005c940801b1",
            "isKey": false,
            "numCitedBy": 5276,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Measuring-the-Strangeness-of-Strange-Attractors-Grassberger-Procaccia",
            "title": {
                "fragments": [],
                "text": "Measuring the Strangeness of Strange Attractors"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30091034"
                        ],
                        "name": "Derrida",
                        "slug": "Derrida",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Derrida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derrida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97296556"
                        ],
                        "name": "Meir",
                        "slug": "Meir",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Meir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meir"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 180
                            }
                        ],
                        "text": "The link between work in complex dynamical systems and neural networks is wellestablished both on the neurobiological level (Skarda & Freeman, 1987) and on the mathematical level (Derrida & Meir, 1988; Huberman & Hogg, 1987; Kurten, 1987; Smolensky, 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19257983,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "16bdfafe2fa40178eaf6d9ba58f41fbae2b720e7",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the evolution of configurations in a layered feed-forward neural network. Exact expressions for the evolution of the distance between two configurations are obtained in the thermodynamic limit. Our results show that the distance between two arbitrarily close configurations always increases, implying chaotic behavior, even in the phase of good retrieval."
            },
            "slug": "Chaotic-behavior-of-a-layered-neural-network.-Derrida-Meir",
            "title": {
                "fragments": [],
                "text": "Chaotic behavior of a layered neural network."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The results show that the distance between two arbitrarily close configurations always increases, implying chaotic behavior, even in the phase of good retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "Physical review. A, General physics"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094349809"
                        ],
                        "name": "W. H. Zurek",
                        "slug": "W.-H.-Zurek",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Zurek",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. H. Zurek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117051291,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "acff8daa079ccd0744efbb397b4cb512c21399d2",
            "isKey": false,
            "numCitedBy": 918,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "That's it, a book to wait for in this month. Even you have wanted for long time for releasing this book complexity entropy and the physics of information; you may not be able to get in some stress. Should you go around and seek fro the book until you really get it? Are you sure? Are you that free? This condition will force you to always end up to get a book. But now, we are coming to give you excellent solution."
            },
            "slug": "Complexity,-Entropy-and-the-Physics-of-Information-Zurek",
            "title": {
                "fragments": [],
                "text": "Complexity, Entropy and the Physics of Information"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911738"
                        ],
                        "name": "D. Angluin",
                        "slug": "D.-Angluin",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Angluin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Angluin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205885265,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "d2cc9aecd8a9cc4d1cceac2380c7da9d116a8218",
            "isKey": false,
            "numCitedBy": 272,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-Complexity-of-Minimum-Inference-of-Regular-Angluin",
            "title": {
                "fragments": [],
                "text": "On the Complexity of Minimum Inference of Regular Sets"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Control."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1877119"
                        ],
                        "name": "M. Barnsley",
                        "slug": "M.-Barnsley",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Barnsley",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Barnsley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075691280"
                        ],
                        "name": "V. Ervin",
                        "slug": "V.-Ervin",
                        "structuredName": {
                            "firstName": "Valerie",
                            "lastName": "Ervin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ervin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67338077"
                        ],
                        "name": "D. Hardin",
                        "slug": "D.-Hardin",
                        "structuredName": {
                            "firstName": "Deanna",
                            "lastName": "Hardin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hardin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086680178"
                        ],
                        "name": "J. Lancaster",
                        "slug": "J.-Lancaster",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Lancaster",
                            "middleNames": [
                                "Charles",
                                "Swinburne"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lancaster"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 314,
                                "start": 311
                            }
                        ],
                        "text": "Each image contains 2048 points corresponding to the states of all boolean strings up to length 10. interesting to note that by eliminating the sigmoid and commuting the Yj and Zk terms, the forward equation for higher order recurrent networks with is identical to the generator of an Iterated Function System (IFS) (Bamsley et al., 1985)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 272
                            }
                        ],
                        "text": "\u2026to the states of all boolean strings up to length 10. interesting to note that by eliminating the sigmoid and commuting the Yj and Zk terms, the forward equation for higher order recurrent networks with is identical to the generator of an Iterated Function System (IFS) (Bamsley et al., 1985)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 31837234,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2d3198137c7cc9621ee54689b954262005a91fdb",
            "isKey": false,
            "numCitedBy": 329,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of providing succinct approximate descriptions of given bounded subsets of R(n) can be solved by application of the contraction mapping principle."
            },
            "slug": "Solution-of-an-inverse-problem-for-fractals-and-Barnsley-Ervin",
            "title": {
                "fragments": [],
                "text": "Solution of an inverse problem for fractals and other sets."
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The problem of providing succinct approximate descriptions of given bounded subsets of R(n) can be solved by application of the contraction mapping principle."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Induction of Dynamical Recognizers Tech Report 90- lP-Automata. Columbus. OH 43210: LAIR. Ohio State University Learning Internal Representations through Error Propagation"
            },
            "venue": {
                "fragments": [],
                "text": "D. E. Rumelhart. 1. L. McClelland & the PDP research Group. (Eds.). Parallel Distributed Processing: Experiments in the Microstructure of Cognition"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 126
                            }
                        ],
                        "text": "These results are of import to many related neural models currently under development, e.g. (Elman, 1990; Giles et aI., 1990; Servan-Schreiber et al., 1989), and relates ultimately to the question of how linguistic capacity can arise in nature."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Encoding Sequential Structure in Simple Recurrent Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 64
                            }
                        ],
                        "text": "The complete experimental data is available in a longer report (pollack, 1990b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recursive Distributed Representation"
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Tomita (1982) performed elegant experiments in inducing finite automata from positive and negative evidence using hillclim bing in the space of 9-state automata."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic construction of finite-state automata from examples using hill-climbing"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth Annual Cognitive Science Conference"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cascaded Back Propagation on Dynamic Connectionist Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Ninth Conference of the Cognitive Science Society. Seattle. 391-404."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Internal Representations through Error Propagation"
            },
            "venue": {
                "fragments": [],
                "text": "PDP research Group. (Eds.). Parallel Distributed Processing: Experiments in the Microstructure of Cognition"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recursive Distributed Representation"
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence. 46, 77-105. Pollack. J. B. (1990). The Induction of Dynamical Recognizers. Tech Report 90lP-Automata. Columbus. OH 43210: LAIR. Ohio State University."
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Phase transitions in quasirandom neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Institute of Electrical and Electronics Engineers First International Conference on Neural Networks. San Diego. 11-197-20. McCulloch. w. S. & Pitts. W. (1943). A logical calculus of the ideas immanent in nervous activity. Bulletin of Mathematical Biophysics. 5. 115-133."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Encoding Sequential Structure in Simple Recurrent Networks"
            },
            "venue": {
                "fragments": [],
                "text": "In D. Touretzky. (Ed.). Advances in Neural Information Processing Systems"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic construction of finite - state automata from examples using hillclimbing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "How brains make chaos. Brain & Behavioral Science.lO"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "How brains make chaos"
            },
            "venue": {
                "fragments": [],
                "text": "Brain & Behavioral Science"
            },
            "year": 1987
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 28,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Language-Induction-by-Phase-Transition-in-Dynamical-Pollack/415dca031402b5186c0c8bf00ca7bb60bfedb986?sort=total-citations"
}