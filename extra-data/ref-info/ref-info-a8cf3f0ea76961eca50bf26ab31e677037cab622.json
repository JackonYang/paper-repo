{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2123706"
                        ],
                        "name": "P. Lipson",
                        "slug": "P.-Lipson",
                        "structuredName": {
                            "firstName": "Pamela",
                            "lastName": "Lipson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lipson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2299381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f397089fe531f621988f78f7bd7be728486a696",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of scene classification is one of the significant open challenges in the field of machine vision. During the past few years, there has been a resurgence of interest in this area due to the potential applications in content-based digital image database indexing. Most proposed solutions have either skirted the problem by using textual annotation or have employed image statistics such as color histograms or local textural measures. While adequate for some tasks, these approaches are unable to capture the global configuration of a scene, which seems to be of critical significance in perceptual judgments of scene similarity. The key question this thesis addresses is how to encode a scene so as to incorporate its overall structure in a manner that would allow subsequent generalization to other members of the scene class. We present a novel approach, called \"configural recognition\", as a partial solution to this problem. The main features of this approach are its use of qualitative spatial and photometric relationships within and across regions in low-resolution images. The emphasis on qualitative measures endows the approach with an impressive generalization ability and the use of low-resolution images renders it computationally efficient. We present results of testing this approach on a large database of natural scenes. We also describe how qualitative scene concepts may be automatically learned from examples. The applicability of the configural recognition approach is not limited to natural scenes; we conclude by describing some other domains for which the approach seems well suited. Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-1690."
            },
            "slug": "Context-and-configuration-based-scene-Lipson",
            "title": {
                "fragments": [],
                "text": "Context and configuration based scene classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The key question is how to encode a scene so as to incorporate its overall structure in a manner that would allow subsequent generalization to other members of the scene class, and a novel approach, called \"configural recognition\", is presented, as a partial solution to this problem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118965263"
                        ],
                        "name": "John R. Smith",
                        "slug": "John-R.-Smith",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7831560,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa9a2a4e6b0f4b8641c5cf511028c275e98573b6",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a unified system for the extraction, representation and query of spatially localized color and texture regions. The system utilizes a back-projection of binary feature sets to identify and extract prominent regions. The binary feature sets provide an effective and easily indexable representation of color and texture. We also provide a mechanism for integrating features by combining the binary color and texture feature sets. This enables the extraction and representation of joint color and texture regions. Since all extracted regions are spatially localized, in image database queries the user can specify the locations and spatial boundaries of regions. We present the unified color and texture back-projection method and describe its implementation in the VisualSEEk content-based image retrieval system."
            },
            "slug": "Local-color-and-texture-extraction-and-spatial-Smith-Chang",
            "title": {
                "fragments": [],
                "text": "Local color and texture extraction and spatial query"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A unified system for the extraction, representation and query of spatially localized color and texture regions by utilizing a back-projection of binary feature sets to identify and extract prominent regions is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd IEEE International Conference on Image Processing"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40434992"
                        ],
                        "name": "J. Bach",
                        "slug": "J.-Bach",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052276135"
                        ],
                        "name": "Charles Fuller",
                        "slug": "Charles-Fuller",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Fuller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles Fuller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722619"
                        ],
                        "name": "Amarnath Gupta",
                        "slug": "Amarnath-Gupta",
                        "structuredName": {
                            "firstName": "Amarnath",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amarnath Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690709"
                        ],
                        "name": "A. Hampapur",
                        "slug": "A.-Hampapur",
                        "structuredName": {
                            "firstName": "Arun",
                            "lastName": "Hampapur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hampapur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144152544"
                        ],
                        "name": "B. Horowitz",
                        "slug": "B.-Horowitz",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Horowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143988415"
                        ],
                        "name": "R. Humphrey",
                        "slug": "R.-Humphrey",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Humphrey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Humphrey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938732"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144808138"
                        ],
                        "name": "Chiao-Fe Shu",
                        "slug": "Chiao-Fe-Shu",
                        "structuredName": {
                            "firstName": "Chiao-Fe",
                            "lastName": "Shu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chiao-Fe Shu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41630036,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87cc226aa060db976fbf6ac3a07969b33b544b96",
            "isKey": false,
            "numCitedBy": 1008,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Until recently, the management of large image databases has relied exclusively on manually entered alphanumeric annotations. Systems are beginning to emerge in both the research and commercial sectors based on 'content-based' image retrieval, a technique which explicitly manages image assets by directly representing their visual attributes. The Virage image search engine provides an open framework for building such systems. The Virage engine expresses visual features as image 'primitives.' Primitives can be very general (such as color, shape, or texture) or quite domain specific (face recognition, cancer cell detection, etc.). The basic philosophy underlying this architecture is a transformation from the data-rich representation of explicit image pixels to a compact, semantic-rich representation of visually salient characteristics. In practice, the design of such primitives is non-trivial, and is driven by a number of conflicting real-world constraints (e.g. computation time vs. accuracy). The virage engine provides an open framework for developers to 'plug-in' primitives to solve specific image management problems. The architecture has been designed to support both static images and video in a unified paradigm. The infrastructure provided by the Virage engine can be utilized to address high-level problems as well, such as automatic, unsupervised keyword assignment, or image classification."
            },
            "slug": "Virage-image-search-engine:-an-open-framework-for-Bach-Fuller",
            "title": {
                "fragments": [],
                "text": "Virage image search engine: an open framework for image management"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The Virage engine provides an open framework for developers to 'plug-in' primitives to solve specific image management problems and can be utilized to address high-level problems as well, such as automatic, unsupervised keyword assignment, or image classification."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741887"
                        ],
                        "name": "M. Bar",
                        "slug": "M.-Bar",
                        "structuredName": {
                            "firstName": "Moshe",
                            "lastName": "Bar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10106848,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "5dee65f0a49765629ed282c87f835975b8a7d193",
            "isKey": false,
            "numCitedBy": 201,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In recognizing objects and scenes, partial recognition of objects or their parts can be used to guide the recognition of other objects. Here, the role of individual objects in the recognition of complete figures and the influence of contextual information on the identification of ambiguous objects were investigated. Configurations of objects that were placed in either proper or improper spatial relations were used, and response times and error rates in a recognition task were measured. Two main results were obtained. First, proper spatial relations among the objects of a scene decrease response times and error rates in the recognition of individual objects. Second, the presence of objects that have a unique interpretation improves the identification of ambigous objects in the scene. Ambiguous objects were recognized faster and with fewer errors in the presence of clearly recognized objects compared with the same objects in isolation or in improper spatial relations. The implications of these findings for the organization of recognition memory are discussed."
            },
            "slug": "Spatial-Context-in-Recognition-Bar-Ullman",
            "title": {
                "fragments": [],
                "text": "Spatial Context in Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The role of individual objects in the recognition of complete figures and the influence of contextual information on the identification of ambiguous objects were investigated and proper spatial relations among the objects of a scene decreased response times and error rates."
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917542"
                        ],
                        "name": "Chinchen Chang",
                        "slug": "Chinchen-Chang",
                        "structuredName": {
                            "firstName": "Chinchen",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chinchen Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733135"
                        ],
                        "name": "Suh-Yin Lee",
                        "slug": "Suh-Yin-Lee",
                        "structuredName": {
                            "firstName": "Suh-Yin",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Suh-Yin Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13589988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f33ab691655bbefea841eabaac34903ae9755ab7",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Retrieval-of-similar-pictures-on-pictorial-Chang-Lee",
            "title": {
                "fragments": [],
                "text": "Retrieval of similar pictures on pictorial databases"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745416"
                        ],
                        "name": "H. Tagare",
                        "slug": "H.-Tagare",
                        "structuredName": {
                            "firstName": "Hemant",
                            "lastName": "Tagare",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Tagare"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144674005"
                        ],
                        "name": "F. Vos",
                        "slug": "F.-Vos",
                        "structuredName": {
                            "firstName": "Frans",
                            "lastName": "Vos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Vos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2855937"
                        ],
                        "name": "C. Jaffe",
                        "slug": "C.-Jaffe",
                        "structuredName": {
                            "firstName": "Conrade",
                            "lastName": "Jaffe",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jaffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145947161"
                        ],
                        "name": "J. Duncan",
                        "slug": "J.-Duncan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Duncan",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Duncan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12541831,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efa92ac080227e50a9e181b6e972ff24d76e157e",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Medical tomographic images are formed by the intersection of the image plane and an object. As the image plane changes, different parts of the object come in view or drop out of view. However, for small changes of the image plane, most parts continue to remain visible and their qualitative embedding in the image remains similar. Therefore, similarity of part embeddings can be used to infer similarity of image planes. Part embeddings are useful features for other vision applications as well. In view of this, a spatial relation called \"arrangement\" is proposed to describe part embeddings. The relation describes how each part is surrounded by its neighbors. Further, a metric for arrangements is formulated by expressing arrangements in terms of the Voronoi diagram of the parts. Arrangements and their metric are used to retrieve images by image plane similarity in a cardiac magnetic resonance image database. Experiments with the database are reported which (1) validate the observation that similarity of image planes can be inferred from similarity of part embeddings, and (2) compare the performance of arrangement based image retrieval with that of expert radiologists. >"
            },
            "slug": "Arrangement:-A-Spatial-Relation-Between-Parts-for-Tagare-Vos",
            "title": {
                "fragments": [],
                "text": "Arrangement: A Spatial Relation Between Parts for Evaluating Similarity of Tomographic Section"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experiments are reported which validate the observation that similarity of image planes can be inferred from similarity of part embeddings, and compare the performance of arrangement based image retrieval with that of expert radiologists."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1880650"
                        ],
                        "name": "J. Tanaka",
                        "slug": "J.-Tanaka",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Tanaka",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tanaka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704633"
                        ],
                        "name": "M. Farah",
                        "slug": "M.-Farah",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Farah",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Farah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 33396424,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "bf00469afdb00598255314051088395684efe484",
            "isKey": false,
            "numCitedBy": 2054,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Are faces recognized using more holistic representations than other types of stimuli? Taking holistic representation to mean representation without an internal part structure, we interpret the available evidence on this issue and then design new empirical tests. Based on previous research, we reasoned that if a portion of an object corresponds to an explicitly represented part in a hierarchical visual representation, then when that portion is presented in isolation it will be identified relatively more easily than if it did not have the status of an explicitly represented part. The hypothesis that face recognition is holistic therefore predicts that a part of a face will be disproportionately more easily recognized in the whole face than as an isolated part, relative to recognition of the parts and wholes of other kinds of stimuli. This prediction was borne out in three experiments: subjects were more accurate at identifying the parts of faces, presented in the whole object, than they were at identifying the same part presented in isolation, even though both parts and wholes were tested in a forced-choice format and the whole faces differed only by one part. In contrast, three other types of stimuli\u2013-scrambled faces, inverted faces, and houses\u2013-did not show this advantage for part identification in whole object recognition."
            },
            "slug": "Parts-and-Wholes-in-Face-Recognition-Tanaka-Farah",
            "title": {
                "fragments": [],
                "text": "Parts and Wholes in Face Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The hypothesis that face recognition is holistic predicts that a part of a face will be disproportionately more easily recognized in the whole face than as an isolated part, relative to recognition of the parts and wholes of other kinds of stimuli."
            },
            "venue": {
                "fragments": [],
                "text": "The Quarterly journal of experimental psychology. A, Human experimental psychology"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46677463"
                        ],
                        "name": "C. B. Cave",
                        "slug": "C.-B.-Cave",
                        "structuredName": {
                            "firstName": "Carolyn",
                            "lastName": "Cave",
                            "middleNames": [
                                "Backer"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. B. Cave"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2914641"
                        ],
                        "name": "S. Kosslyn",
                        "slug": "S.-Kosslyn",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Kosslyn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kosslyn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20441186,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b8bede7bcffa3358a0bd76c63137230fa856e0cc",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "An investigation of the role of parts and their spatial relations in object identification is reported. At the most general level, two important results were obtained. First, proper spatial relations among components of an object are critical for easy identification. When parts were scrambled on the page, naming times and error rates increased. And, second, the way an object is divided into parts (parsed) affects identification only under the most impoverished viewing conditions. When subjects had as little as 1 s (and sometimes as little as 200 ms) to view an object, the way objects were divided into parts had no effect on naming times or accuracy. There was no hint of an interaction between type of parse and how parts were arranged on the page. This pattern of effects supports theories that suggest that objects typically are recognized without being parsed into parts. The findings are in agreement with theories suggesting that object features (not specifically related to parts) are matched directly with such features stored in long-term memory, with the constraint that the features of a single object are seen from a single viewpoint."
            },
            "slug": "The-Role-of-Parts-and-Spatial-Relations-in-Object-Cave-Kosslyn",
            "title": {
                "fragments": [],
                "text": "The Role of Parts and Spatial Relations in Object Identification"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "An investigation of the role of parts and their spatial relations in object identification finds that object features are matched directly with such features stored in long-term memory, with the constraint that the features of a single object are seen from a single viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299972"
                        ],
                        "name": "I. Biederman",
                        "slug": "I.-Biederman",
                        "structuredName": {
                            "firstName": "Irving",
                            "lastName": "Biederman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Biederman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42548767,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "fa93c0307c66e63967ded06fb65e6cffc3c561f9",
            "isKey": false,
            "numCitedBy": 633,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "When a briefly presented real-world scene was jumbled, the accuracy of identifying a single, cued object was less than that when the scene was coherent. Jumbling remained an effective variable even when the subject knew where to look and what to look for. Thus an object's meaningful context may affect the course of perceptual recognition and not just peripheral scanning or memory."
            },
            "slug": "Perceiving-Real-World-Scenes-Biederman",
            "title": {
                "fragments": [],
                "text": "Perceiving Real-World Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "An object's meaningful context may affect the course of perceptual recognition and not just peripheral scanning or memory."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729390"
                        ],
                        "name": "Euripides G. M. Petrakis",
                        "slug": "Euripides-G.-M.-Petrakis",
                        "structuredName": {
                            "firstName": "Euripides",
                            "lastName": "Petrakis",
                            "middleNames": [
                                "G.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Euripides G. M. Petrakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702392"
                        ],
                        "name": "C. Faloutsos",
                        "slug": "C.-Faloutsos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Faloutsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faloutsos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58710763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "836bfe1994a174b41c46e7244845b44f8702eeab",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Similarity-Searching-in-Large-Image-DataBases-Petrakis-Faloutsos",
            "title": {
                "fragments": [],
                "text": "Similarity Searching in Large Image DataBases"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Duncan"
            },
            "venue": {
                "fragments": [],
                "text": "\u201cArrangement: A spatial relation between parts for evaluatingsimilarity of tomographic sections,\u201d PAMI, Vol. 17, No. 9, pp. 225-245, Sept."
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Query by image content and its applications,"
            },
            "venue": {
                "fragments": [],
                "text": "IBM Research Report,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "Several image database indexing systems are based on this idea, such as QBIC [l], VIRAGE [3], and Visualseek [IO]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chang"
            },
            "venue": {
                "fragments": [],
                "text": "\u201cLocal color and texture extraction and spatial query,\u201d IEEE Int. Cor$ on Image Processing,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image invariants for object recognition,"
            },
            "venue": {
                "fragments": [],
                "text": "Invest Opth. and Vis. Science,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Parts and wholse in face recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Quarterly J. of Exp. Psych"
            },
            "year": 1993
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 15,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Configuration-based-scene-classification-and-image-Lipson-Grimson/a8cf3f0ea76961eca50bf26ab31e677037cab622?sort=total-citations"
}