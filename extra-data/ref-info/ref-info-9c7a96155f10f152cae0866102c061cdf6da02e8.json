{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "Tuytelaars and Van Gool [16] detect affine invariant regions based on image intensities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 112
                            }
                        ],
                        "text": "This image pair presents a more significant change in viewpoint than the images in figure 7c which were used in [13, 16] as an example for matching."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 552096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ad20e6f6f89631caf6960516bb9939b9430bba0",
            "isKey": false,
            "numCitedBy": 568,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "\u2018Invariant regions\u2019 are image patches that automatically deform with changing viewpoint as to keep on covering identical physical parts of a scene. Such regions are then described by a set of invariant features, which makes it relatively easy to match them between views and under changing illumination. In previous work, we have presented invariant regions that are based on a combination of corners and edges. The application discussed then was image database retrieval. Here, an alternative method for extracting (affinely) invariant regions is given, that does not depend on the presence of edges or corners in the image but is purely intensity-based. Also, we demonstrate the use of such regions for another application, which is wide baseline stereo matching. As a matter of fact, the goal is to build an opportunistic system that exploits several types of invariant regions as it sees fit. This yields more correspondences and a system that can deal with a wider range of images. To increase the robustness of the system even further, two semi-local constraints on combinations of region correspondences are derived (one geometric, the other photometric). They allow to test the consistency of correspondences and hence to reject falsely matched regions."
            },
            "slug": "Wide-Baseline-Stereo-Matching-based-on-Local,-Tuytelaars-Gool",
            "title": {
                "fragments": [],
                "text": "Wide Baseline Stereo Matching based on Local, Affinely Invariant Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents an alternative method for extracting invariant regions that does not depend on the presence of edges or corners in the image but is purely intensity-based, and demonstrates the use of such regions for another application, which is wide baseline stereo matching."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40316280"
                        ],
                        "name": "Dennis Tell",
                        "slug": "Dennis-Tell",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Tell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dennis Tell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153120475"
                        ],
                        "name": "S. Carlsson",
                        "slug": "S.-Carlsson",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Carlsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carlsson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Tell and Carlsson [15] also address the problem of wide baseline matching and use an affine invariant descriptors for point pairs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38014951,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a6ea7bd5be7631f671ea0069bc296cc51654895",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of establishing correspondences between images taken from different viewpoints is fundamental in computer vision. We propose an algorithm which is capable of handling larger changes in viewpoint than classical correlation based techniques. Optimal performance for the algorithm is achieved for textured objects which are locally planar in at least one direction. The algorithm works by computing affinely invariant fourier features from intensity profiles in each image. The intensity profiles are extracted from the image data between randomly selected pairs of image interest points. Using a voting scheme, pairs of interest points are matched across images by comparing vectors of fourier features. Outliers among the matches are rejected in two stages, a fast stage using novel view consistency constraints, and a second, slower stage using RANSAC and fundamental matrix computation. In order to demonstrate the quality of the results, the algorithm is tested on several different image pairs."
            },
            "slug": "Wide-Baseline-Point-Matching-Using-Affine-Computed-Tell-Carlsson",
            "title": {
                "fragments": [],
                "text": "Wide Baseline Point Matching Using Affine Invariants Computed from Intensity Profiles"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An algorithm which is capable of handling larger changes in viewpoint than classical correlation based techniques is proposed, which works by computing affinely invariant fourier features from intensity profiles in each image."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 72
                            }
                        ],
                        "text": "A uniform Gaussian scale-space is often used to deal with scale changes [3, 7, 10, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Lowe [10] proposes an efficient algorithm for recognition based on local extrema of difference-of-Gaussian filters in scale-space."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 73
                            }
                        ],
                        "text": "Scale invariant interest points detectors have been presented previously [10, 11]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5258236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9f836d28f52ad260213d32224a6d227f8e8849a",
            "isKey": false,
            "numCitedBy": 16255,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "slug": "Object-recognition-from-local-scale-invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale-invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3260234"
                        ],
                        "name": "J. G\u00e5rding",
                        "slug": "J.-G\u00e5rding",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "G\u00e5rding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. G\u00e5rding"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 70
                            }
                        ],
                        "text": "Our approach is based on a method introduced by Lindeberg and Garding [9] which iteratively estimates an affine invariant neighbourhood."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 188
                            }
                        ],
                        "text": "Baumberg [2] extracts interest points at several scales and then adapts the shape of the region to the local image structure using an iterative procedure based on the second moment matrix [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "Lindeberg [9] showed that if the second moment descriptor of the point xL verifies \u03bc(xL, \u03a3I,L, \u03a3D,L) = ML \u03a3I,L = tM \u22121 L \u03a3D,L = dM \u22121 L"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "The affine adaptation is based on the second moment matrix [9] and local extrema over scale of normalized derivatives [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "The convergence properties of the shape adaptation algorithm are extensively studied in [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 178
                            }
                        ],
                        "text": "In order to preserve invariance to scale changes we select the integration scale \u03c3I for which the normalized Laplacian |\u03c3(2)(Lxx(\u03c3) + Lyy(\u03c3))| attains a local maximum over scale [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "The proof and the outline of an iterative method for computing the matrices can be found in [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18264626,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f87bcdf4a0dc79f85e171ec26733424d0e459cd2",
            "isKey": true,
            "numCitedBy": 290,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Shape-adapted-smoothing-in-estimation-of-3-D-shape-Lindeberg-G\u00e5rding",
            "title": {
                "fragments": [],
                "text": "Shape-adapted smoothing in estimation of 3-D shape cues from affine deformations of local 2-D brightness structure"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775242"
                        ],
                        "name": "Frederik Schaffalitzky",
                        "slug": "Frederik-Schaffalitzky",
                        "structuredName": {
                            "firstName": "Frederik",
                            "lastName": "Schaffalitzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederik Schaffalitzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 14
                            }
                        ],
                        "text": "Pritchett and Zisserman [12] estimate homographies of local planar surfaces in order to correct the cross-correlation and grow regions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "The properties of the second moment matrix were also explored by Schaffalitzky and Zisserman [13], but their goal was to obtain an affine invariant texture descriptor."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 112
                            }
                        ],
                        "text": "This image pair presents a more significant change in viewpoint than the images in figure 7c which were used in [13, 16] as an example for matching."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2964260,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aac66ac5e90cc4c187a5aa063b522e5193ef8834",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and demonstrate a texture region descriptor which is invariant to affine geometric and photometric transformations, and insensitive to the shape of the texture region. It is applicable to texture patches which are locally planar and have stationary statistics. The novelty of the descriptor is that it is based on statistics aggregated over the region, resulting in richer and more stable descriptors than those computed at a point. Two texture matching applications of this descriptor are demonstrated: (1) it is used to automatically identify, regions of the same type of texture, but with varying surface pose, within a single image; (2) it is used to support wide baseline stereo, i.e. to enable the automatic computation of the epipolar geometry between two images acquired from quite separated viewpoints. Results are presented on several sets of real images."
            },
            "slug": "Viewpoint-invariant-texture-matching-and-wide-Schaffalitzky-Zisserman",
            "title": {
                "fragments": [],
                "text": "Viewpoint invariant texture matching and wide baseline stereo"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A texture region descriptor is described and demonstrated which is invariant to affine geometric and photometric transformations, and insensitive to the shape of the texture region, resulting in richer and more stable descriptors than those computed at a point."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2679389"
                        ],
                        "name": "A. Baumberg",
                        "slug": "A.-Baumberg",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Baumberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Baumberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 64
                            }
                        ],
                        "text": "We compare our Harris-Affine method with two similar approaches [2, 11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "Baumberg [2] extracts interest points at several scales and then adapts the shape of the region to the local image structure using an iterative procedure based on the second moment matrix [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 50
                            }
                        ],
                        "text": "A quantitative comparison with existing detectors [2, 11] shows a significant improvement of our method in the presence of large affine transformations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "Baumberg [2] shows that if the neighbourhoods of points xL, xR are normalized by transformations x\u2032L 7\u2192 M \u22121/2 L xL and x \u2032 R 7\u2192 M \u22121/2 R xR respectively, then the normalized regions are related by a pure rotation x\u2032L 7\u2192 Rx\u2032R."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "Baumberg [2] extracts Harris interest points at several scales and then adapts the shape of the region to the local image structure using an iterative procedure based on the second moment matrix."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15626261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67f693427d956c0dbc822e7f3452aee8ca36204b",
            "isKey": true,
            "numCitedBy": 767,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints. Unlike conventional stereo matching approaches we assume no prior knowledge about the relative camera positions and orientations. In fact in our application this is the information we wish to determine from the image feature matches. Features are detected in two or more images and characterised using affine texture invariants. The problem of window effects is explicitly addressed by our method-our feature characterisation is invariant to linear transformations of the image data including rotation, stretch and skew. The feature matching process is optimised for a structure-from-motion application where we wish to ignore unreliable matches at the expense of reducing the number of feature matches."
            },
            "slug": "Reliable-feature-matching-across-widely-separated-Baumberg",
            "title": {
                "fragments": [],
                "text": "Reliable feature matching across widely separated views"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints that is optimised for a structure-from-motion application where it wishes to ignore unreliable matches at the expense of reducing the number of feature matches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 151
                            }
                        ],
                        "text": "To deal with significant scale changes, points are extracted at several scales and the characteristic scale is determined by automatic scale selection [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "Mikolajczyk and Schmid [11] use a multi-scale framework to detect points and then apply scale selection [8] to select characteristic points."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 118
                            }
                        ],
                        "text": "The affine adaptation is based on the second moment matrix [9] and local extrema over scale of normalized derivatives [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 723210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b02f474196fb9bd61fa3d418a7ba8ac500e8d422",
            "isKey": false,
            "numCitedBy": 2940,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "The fact that objects in the world appear in different ways depending on the scale of observation has important implications if one aims at describing them. It shows that the notion of scale is of utmost importance when processing unknown measurement data by automatic methods. In their seminal works, Witkin (1983) and Koenderink (1984) proposed to approach this problem by representing image structures at different scales in a so-called scale-space representation. Traditional scale-space theory building on this work, however, does not address the problem of how to select local appropriate scales for further analysis. This article proposes a systematic methodology for dealing with this problem. A framework is presented for generating hypotheses about interesting scale levels in image data, based on a general principle stating that local extrema over scales of different combinations of \u03b3-normalized derivatives are likely candidates to correspond to interesting structures. Specifically, it is shown how this idea can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure.Support for the proposed approach is given in terms of a general theoretical investigation of the behaviour of the scale selection method under rescalings of the input pattern and by integration with different types of early visual modules, including experiments on real-world and synthetic data. Support is also given by a detailed analysis of how different types of feature detectors perform when integrated with a scale selection mechanism and then applied to characteristic model patterns. Specifically, it is described in detail how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation.In many computer vision applications, the poor performance of the low-level vision modules constitutes a major bottleneck. It is argued that the inclusion of mechanisms for automatic scale selection is essential if we are to construct vision systems to automatically analyse complex unknown environments."
            },
            "slug": "Feature-Detection-with-Automatic-Scale-Selection-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Feature Detection with Automatic Scale Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation and how it can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2891524"
                        ],
                        "name": "Yves Dufournaud",
                        "slug": "Yves-Dufournaud",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Dufournaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yves Dufournaud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794229"
                        ],
                        "name": "R. Horaud",
                        "slug": "R.-Horaud",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Horaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Horaud"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 135
                            }
                        ],
                        "text": "In order to limit the search space we initialize the affine detector with interest points extracted by the multi-scale Harris detector [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 72
                            }
                        ],
                        "text": "A uniform Gaussian scale-space is often used to deal with scale changes [3, 7, 10, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3] use a multi-scale framework to match images at different scales."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 163
                            }
                        ],
                        "text": "If there is no distinctive texture in the region around the points, there are too many mismatches and additional constraints as for example semi-local constraints [3] should be used."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13979044,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "501e089c923e099ad235e0269df8ed37a10a98fb",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we address the problem of matching two images with two different resolutions: a high-resolution image and a low-resolution one. On the premise that changes in resolution act as a smoothing equivalent to changes in scale, a scale-space representation of the high-resolution image is produced. Hence the one-to-one classical image matching paradigm becomes one-to-many because the low-resolution image is compared with all the scale-space representations of the high-resolution one. Key to the success of such a process is the proper representation of the features to be matched in scale-space. We show how to extract interest points at variable scales and we devise a method allowing the comparison of two images at two different resolutions. The method comprises the use of photometric- and rotation-invariant descriptors, a geometric model mapping the high-resolution image onto a low-resolution image region, and an image matching strategy based on the robust estimation of this geometric model. Extensive experiments show that our matching method can be used for scale changes up to a factor 6."
            },
            "slug": "Matching-images-with-different-resolutions-Dufournaud-Schmid",
            "title": {
                "fragments": [],
                "text": "Matching images with different resolutions"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper shows how to extract interest points at variable scales and devise a method allowing the comparison of two images at two different resolutions, which comprises the use of photometric- and rotation-invariant descriptors, a geometric model mapping the high-resolution image onto a low- resolution image region, and an image matching strategy based on the robust estimation of this geometric model."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713633"
                        ],
                        "name": "Andr\u00e9s Almansa",
                        "slug": "Andr\u00e9s-Almansa",
                        "structuredName": {
                            "firstName": "Andr\u00e9s",
                            "lastName": "Almansa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9s Almansa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "A similar approach for local scale selection was proposed in [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14480964,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "154db6db5772ec009e376a03ce22b12175dffd0a",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "This work presents two mechanisms for processing fingerprint images; shape-adapted smoothing based on second moment descriptors and automatic scale selection based on normalized derivatives. The shape adaptation procedure adapts the smoothing operation to the local ridge structures, which allows interrupted ridges to be joined without destroying essential singularities such as branching points and enforces continuity of their directional fields. The scale selection procedure estimates local ridge width and adapts the amount of smoothing to the local amount of noise. In addition, a ridgeness measure is defined, which reflects how well the local image structure agrees with a qualitative ridge model, and is used for spreading the results of shape adaptation into noisy areas. The combined approach makes it possible to resolve fine scale structures in clear areas while reducing the risk of enhancing noise in blurred or fragmented areas. The result is a reliable and adaptively detailed estimate of the ridge orientation field and ridge width, as well as a smoothed grey-level version of the input image. We propose that these general techniques should be of interest to developers of automatic fingerprint identification systems as well as in other applications of processing related types of imagery."
            },
            "slug": "Fingerprint-enhancement-by-shape-adaptation-of-with-Almansa-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Fingerprint enhancement by shape adaptation of scale-space operators with automatic scale selection"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This work presents two mechanisms for processing fingerprint images; shape-adapted smoothing based on second moment descriptors and automatic scale selection based on normalized derivatives, which makes it possible to resolve fine scale structures in clear areas while reducing the risk of enhancing noise in blurred or fragmented areas."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "One of the first recognition techniques based on interest points has been proposed by Schmid and Mohr [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 325871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fcd806450d947e56c82ef2b438ad9c484069dc",
            "isKey": false,
            "numCitedBy": 1792,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations."
            },
            "slug": "Local-Grayvalue-Invariants-for-Image-Retrieval-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Local Grayvalue Invariants for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of retrieving images from large image databases with a method based on local grayvalue invariants which are computed at automatically detected interest points and allows for efficient retrieval from a database of more than 1,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40309692"
                        ],
                        "name": "C. G. Harris",
                        "slug": "C.-G.-Harris",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Harris",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. G. Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40365651"
                        ],
                        "name": "M. Stephens",
                        "slug": "M.-Stephens",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Stephens",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stephens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "The points are extracted with the Harris detector [5] which is invariant to image rotation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1694378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6818668fb895d95861a2eb9673ddc3a41e27b3b3",
            "isKey": false,
            "numCitedBy": 14111,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem we are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work. For example, we desire to obtain an understanding of natural scenes, containing roads, buildings, trees, bushes, etc., as typified by the two frames from a sequence illustrated in Figure 1. The solution to this problem that we are pursuing is to use a computer vision system based upon motion analysis of a monocular image sequence from a mobile camera. By extraction and tracking of image features, representations of the 3D analogues of these features can be constructed."
            },
            "slug": "A-Combined-Corner-and-Edge-Detector-Harris-Stephens",
            "title": {
                "fragments": [],
                "text": "A Combined Corner and Edge Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The problem the authors are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work."
            },
            "venue": {
                "fragments": [],
                "text": "Alvey Vision Conference"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682208"
                        ],
                        "name": "K. Kanatani",
                        "slug": "K.-Kanatani",
                        "structuredName": {
                            "firstName": "Kenichi",
                            "lastName": "Kanatani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kanatani"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 28
                            }
                        ],
                        "text": "A model selection algorithm [6] can be used to automatically decide which transformation is the most appropriate one."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 19248991,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "206c02090982637c5fa30201868522713bf9d3f7",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "In building a 3-D model of the environment from image and sensor data, one must fit to the data an appropriate class of models, which can be regarded as a parametrized manifold, or geometric model, defined in the data space. In this paper, we present a statistical framework for detecting degeneracies of a geometric model by evaluating its predictive capability in terms of the expected residual and derive the geometric AIC. We show that it allows us to detect singularities in a structure-from-motion analysis without introducing any empirically adjustable thresholds. We illustrate our approach by simulation examples. We also discuss the application potential of this theory for a wide range of computer vision and robotics problems."
            },
            "slug": "Geometric-Information-Criterion-for-Model-Selection-Kanatani",
            "title": {
                "fragments": [],
                "text": "Geometric Information Criterion for Model Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents a statistical framework for detecting degeneracies of a geometric model by evaluating its predictive capability in terms of the expected residual and derive the geometric AIC, which allows us to detect singularities in a structure-from-motion analysis without introducing any empirically adjustable thresholds."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "Invariance to rotation is obtained by \u201csteering\u201d the derivatives in the direction of the gradient [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29187618,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "993b1083455b5c4d631eaf44f230b061994e75c3",
            "isKey": false,
            "numCitedBy": 3378,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present an efficient architecture to synthesize filters of arbitrary orientations from linear combinations of basis filters, allowing one to adaptively steer a filter to any orientation, and to determine analytically the filter output as a function of orientation. Steerable filters may be designed in quadrature pairs to allow adaptive control over phase as well as orientation. The authors show how to design and steer the filters and present examples of their use in the analysis of orientation and phase, angularly adaptive filtering, edge detection, and shape from shading. One can also build a self-similar steerable pyramid representation. The same concepts can be generalized to the design of 3-D steerable filters. >"
            },
            "slug": "The-Design-and-Use-of-Steerable-Filters-Freeman-Adelson",
            "title": {
                "fragments": [],
                "text": "The Design and Use of Steerable Filters"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors present an efficient architecture to synthesize filters of arbitrary orientations from linear combinations of basis filters, allowing one to adaptively steer a filter to any orientation, and to determine analytically the filter output as a function of orientation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 72
                            }
                        ],
                        "text": "A uniform Gaussian scale-space is often used to deal with scale changes [3, 7, 10, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "To obtain invariance to scale changes interest points can be extracted in the scale space of an image [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10336140,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c55dfe48a3c49a6dc366d50a60521f73aa31151a",
            "isKey": false,
            "numCitedBy": 2435,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A basic problem when deriving information from measured data, such as images, originates from the fact that objects in the world, and hence image structures, exist as meaningful entities only over ..."
            },
            "slug": "Scale-Space-Theory-in-Computer-Vision-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Scale-Space Theory in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A basic problem when deriving information from measured data, such as images, originates from the fact that objects in the world, and hence image structures, exist as meaningful entities only over measured data."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 15,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/An-Affine-Invariant-Interest-Point-Detector-Mikolajczyk-Schmid/9c7a96155f10f152cae0866102c061cdf6da02e8?sort=total-citations"
}