{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47392513"
                        ],
                        "name": "Jonathan Baxter",
                        "slug": "Jonathan-Baxter",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Baxter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Baxter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 49
                            }
                        ],
                        "text": "This assumption was also made in (Baxter, 1995b, Baxter, 1996b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 131
                            }
                        ],
                        "text": "Whether or not there actually exists a hypothesis space containing good solutions to all the tasks will depend upon the family of hypothesis spaces provided to the learner, or equivalently upon thehyper-biasof the learner."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 141
                            }
                        ],
                        "text": "In this paper a Bayesian model of bias learning is introduced, based on the VC/PACtype models of bias learning introduced in (Baxter, 1995b, Baxter, 1996b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 185
                            }
                        ],
                        "text": "Theorem 1 can also be derived via quite different techniques as a special case of theorem 2 in (Haussler & Opper, 1995b) (which appeared as an earlier incarnation of the present paper (Baxter, 1996a) was being prepared)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 116
                            }
                        ],
                        "text": "This scenario is not covered by the Bayesian model presented here, nor by the VC/PAC type models of (Baxter, 1995b, Baxter, 1996b), because these models assume that independent training sets are available for each output node."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 19
                            }
                        ],
                        "text": "In (Baxter, 1995b, Baxter, 1996b) it was shown that under certain restrictions on this family of hypothesis spaces (these restrictions are analogous to the \u201cfinite VC dimension\u201d restrictions on ordinary learners), it is possible for the learner to sample sufficiently often from sufficiently many\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14605454,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0ee1219f78e5b53938718e9a8f140491cef1523",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper the problem of learning appropriate bias for an environment of related tasks is examined from a Bayesian perspective. The environment of related tasks is shown to be naturally modelled by the concept of an {\\em objective} prior distribution. Sampling from the objective prior corresponds to sampling different learning tasks from the environment. It is argued that for many common machine learning problems, although we don't know the true (objective) prior for the problem, we do have some idea of a set of possible priors to which the true prior belongs. It is shown that under these circumstances a learner can use Bayesian inference to learn the true prior by sampling from the objective prior. Bounds are given on the amount of information required to learn a task when it is simultaneously learnt with several other tasks. The bounds show that if the learner has little knowledge of the true prior, and the dimensionality of the true prior is small, then sampling multiple tasks is highly advantageous."
            },
            "slug": "A-Bayesian/information-theoretic-model-of-bias-Baxter",
            "title": {
                "fragments": [],
                "text": "A Bayesian/information theoretic model of bias learning"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "In this paper the problem of learning appropriate bias for an environment of related tasks is examined from a Bayesian perspective and it is shown that under these circumstances a learner can use Bayesian inference to learn the true prior by sampling from the objective prior."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47392513"
                        ],
                        "name": "Jonathan Baxter",
                        "slug": "Jonathan-Baxter",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Baxter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Baxter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 34
                            }
                        ],
                        "text": "This assumption was also made in (Baxter, 1995b, Baxter, 1996b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 77
                            }
                        ],
                        "text": "Experimental verification of this for feedforward nets was also reported in (Baxter, 1995b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 32
                            }
                        ],
                        "text": "In particular, it was shown in (Baxter, 1995b) that if the learner is learning a common feature set (LDR) for ann task training set then the number of examplesm required of each task to ensure good generalisation on average across alln tasks obeys\nm = O ( a+ b\nn\n) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 71
                            }
                        ],
                        "text": "Typically such bias is introduced by hand through the skill and insights of experts, but despite many notable successes, this process is clearly limited by the experts\u2019 abilities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 126
                            }
                        ],
                        "text": "In this paper a Bayesian model of bias learning is introduced, based on the VC/PACtype models of bias learning introduced in (Baxter, 1995b, Baxter, 1996b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 180
                            }
                        ],
                        "text": "(41)\nThe similarity of this expression to the upper bound on the number of examples required per task for good generalisation in a PAC sense ofO(WOUT + WLDR/n) is noteworthy\n(see (Baxter, 1995b) for a derivation of the latter expression)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 101
                            }
                        ],
                        "text": "This scenario is not covered by the Bayesian model presented here, nor by the VC/PAC type models of (Baxter, 1995b, Baxter, 1996b), because these models assume that independent training sets are available for each output node."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 111
                            }
                        ],
                        "text": "If the learner is learningn tasks simultaneously then it will receive n such samples (called an( ,m)-samplein (Baxter, 1995b, Baxter, 1995a)):\nz(n,m) = z11 . . . z1m ... ... ...\nzn1 . . . znm\n(42)\nEach row ofz(n,m) is sampled according top(z|\u03b8i) where\u03b81, . . . , \u03b8n are then tasks being learnt."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 4
                            }
                        ],
                        "text": "In (Baxter, 1995b, Baxter, 1996b) it was shown that under certain restrictions on this family of hypothesis spaces (these restrictions are analogous to the \u201cfinite VC dimension\u201d restrictions on ordinary learners), it is possible for the learner to sample sufficiently often from sufficiently many\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: Hierarchichal Bayesian Inference, Bias learning, Feature Learning, Neural Networks, Information Theory"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 209
                            }
                        ],
                        "text": "Equations (2) and (3) are derived in section 3 and the constants\u2032 andb\u2032(\u03c0\u2217) are calculated for the neural network example, where contact is made between the Bayesian model results and the VC/PAC model results of (Baxter, 1995b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6211302,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a24508e65e599b5b20c33af96dbe7017d5caca37",
            "isKey": false,
            "numCitedBy": 343,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Probably the most important problem in machine learning is the preliminary biasing of a learner's hypothesis space so that it is small enough to ensure good generalisation from reasonable training sets, yet large enough that it contains a good solution to the problem being learnt. In this paper a mechanism for {\\em automatically} learning or biasing the learner's hypothesis space is introduced. It works by first learning an appropriate {\\em internal representation} for a learning environment and then using that representation to bias the learner's hypothesis space for the learning of future tasks drawn from the same environment. \nAn internal representation must be learnt by sampling from {\\em many similar tasks}, not just a single task as occurs in ordinary machine learning. It is proved that the number of examples $m$ {\\em per task} required to ensure good generalisation from a representation learner obeys $m = O(a+b/n)$ where $n$ is the number of tasks being learnt and $a$ and $b$ are constants. If the tasks are learnt independently ({\\em i.e.} without a common representation) then $m=O(a+b)$. It is argued that for learning environments such as speech and character recognition $b\\gg a$ and hence representation learning in these environments can potentially yield a drastic reduction in the number of examples required per task. It is also proved that if $n = O(b)$ (with $m=O(a+b/n)$) then the representation learnt will be good for learning novel tasks from the same environment, and that the number of examples required to generalise well on a novel task will be reduced to $O(a)$ (as opposed to $O(a+b)$ if no representation is used). \nIt is shown that gradient descent can be used to train neural network representations and experiment results are reported providing strong qualitative support for the theoretical results."
            },
            "slug": "Learning-internal-representations-Baxter",
            "title": {
                "fragments": [],
                "text": "Learning internal representations"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is proved that the number of examples required to ensure good generalisation from a representation learner obeys and that gradient descent can be used to train neural network representations and experiment results are reported providing strong qualitative support for the theoretical results."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47392513"
                        ],
                        "name": "Jonathan Baxter",
                        "slug": "Jonathan-Baxter",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Baxter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Baxter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 49
                            }
                        ],
                        "text": "This assumption was also made in (Baxter, 1995b, Baxter, 1996b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 141
                            }
                        ],
                        "text": "In this paper a Bayesian model of bias learning is introduced, based on the VC/PACtype models of bias learning introduced in (Baxter, 1995b, Baxter, 1996b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 185
                            }
                        ],
                        "text": "Theorem 1 can also be derived via quite different techniques as a special case of theorem 2 in (Haussler & Opper, 1995b) (which appeared as an earlier incarnation of the present paper (Baxter, 1996a) was being prepared)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 116
                            }
                        ],
                        "text": "This scenario is not covered by the Bayesian model presented here, nor by the VC/PAC type models of (Baxter, 1995b, Baxter, 1996b), because these models assume that independent training sets are available for each output node."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 19
                            }
                        ],
                        "text": "In (Baxter, 1995b, Baxter, 1996b) it was shown that under certain restrictions on this family of hypothesis spaces (these restrictions are analogous to the \u201cfinite VC dimension\u201d restrictions on ordinary learners), it is possible for the learner to sample sufficiently often from sufficiently many\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16307826,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "d37250b498f66b8d43a336b54fca8b83328e4ede",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper the problem of learning appropriate domain-specific bias is addressed. It is shown that this can be achieved by learning many related tasks from the same domain, and a theorem is given bounding the number tasks that must be learnt. A corollary of the theorem is that if the tasks are known to possess a common internal representation or preprocessing then the number of examples required per task for good generalisation when learning n tasks simultaneously scales like O(a + b/n), where O(a) is a bound on the minimum number of examples requred to learn a single task, and O(a + b) is a bound on the number of examples required to learn each task independently. An experiment providing strong qualitative support for the theoretical results is reported."
            },
            "slug": "Learning-Model-Bias-Baxter",
            "title": {
                "fragments": [],
                "text": "Learning Model Bias"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "The problem of learning appropriate domain-specific bias is addressed, and it is shown that this can be achieved by learning many related tasks from the same domain, and a theorem is given bounding the number tasks that must be learnt."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 3
                            }
                        ],
                        "text": "This work was supported by EPSRC grants #K70366 and #K70373.\ntasks are things like face recognition (each individual face classifier can be thought of as a separate learning problem), speech recognition (the word classifiers are related) character recognition, fingerprint recognition and so on."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 34
                            }
                        ],
                        "text": "This assumption was also made in (Baxter, 1995b, Baxter, 1996b)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 77
                            }
                        ],
                        "text": "Experimental verification of this for feedforward nets was also reported in (Baxter, 1995b)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 217
                            }
                        ],
                        "text": "For the most part hierarchical Bayes has been used to tune a small number of \u201cnuisance\u201d (hyper) parameters (such as the parameter\u03bb controlling the trade-off between regularisation and data-misfit in regression networks (Mackay, 1991)), and this tuning has been based on learning asingletask."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 32
                            }
                        ],
                        "text": "In particular, it was shown in (Baxter, 1995b) that if the learner is learning a common feature set (LDR) for ann task training set then the number of examplesm required of each task to ensure good generalisation on average across alln tasks obeys\nm = O ( a+ b\nn\n) ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 126
                            }
                        ],
                        "text": "In this paper a Bayesian model of bias learning is introduced, based on the VC/PACtype models of bias learning introduced in (Baxter, 1995b, Baxter, 1996b)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 185
                            }
                        ],
                        "text": "Theorem 1 can also be derived via quite different techniques as a special case of theorem 2 in (Haussler & Opper, 1995b) (which appeared as an earlier incarnation of the present paper (Baxter, 1996a) was being prepared)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 4
                            }
                        ],
                        "text": "In (Baxter, 1995b, Baxter, 1996b) it was shown that under certain restrictions on this family of hypothesis spaces (these restrictions are analogous to the \u201cfinite VC dimension\u201d restrictions on ordinary learners), it is possible for the learner to sample sufficiently often from sufficiently many tasks to ensure that a hypothesis space containing hypotheses with small empirical loss on all the tasks will, with high probability, contain good solutions to novel tasks drawn from the same environment."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 180
                            }
                        ],
                        "text": "(41)\nThe similarity of this expression to the upper bound on the number of examples required per task for good generalisation in a PAC sense ofO(WOUT + WLDR/n) is noteworthy\n(see (Baxter, 1995b) for a derivation of the latter expression)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 137
                            }
                        ],
                        "text": "In contrast to other techniques for Bayes learning with neural networks in which there are at most a handful of hyper-parameters (see.g.(Mackay, 1991)), here the hyper-parameters vastly outnumber the model parameters."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 101
                            }
                        ],
                        "text": "This scenario is not covered by the Bayesian model presented here, nor by the VC/PAC type models of (Baxter, 1995b, Baxter, 1996b), because these models assume that independent training sets are available for each output node."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 111
                            }
                        ],
                        "text": "If the learner is learningn tasks simultaneously then it will receive n such samples (called an( ,m)-samplein (Baxter, 1995b, Baxter, 1995a)):\nz(n,m) = z11 . . . z1m ... ... ...\nzn1 . . . znm\n(42)\nEach row ofz(n,m) is sampled according top(z|\u03b8i) where\u03b81, . . . , \u03b8n are then tasks being learnt."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 119
                            }
                        ],
                        "text": "Hierarchical Bayesian inference has also been discussed in the context of neural networks by several authors (seee.g. (Mackay, 1991), although the techniques presented there are not explicitly identified as hierarchical Bayes)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 63
                            }
                        ],
                        "text": "One can think of the LDR as a preprocessing applied to the input data that extracts features that are important for classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 25
                            }
                        ],
                        "text": "In (Baxter, 1995b, Baxter, 1996b) it was shown that under certain restrictions on this family of hypothesis spaces (these restrictions are analogous to the \u201cfinite VC dimension\u201d restrictions on ordinary learners), it is possible for the learner to sample sufficiently often from sufficiently many\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 209
                            }
                        ],
                        "text": "Equations (2) and (3) are derived in section 3 and the constants\u2032 andb\u2032(\u03c0\u2217) are calculated for the neural network example, where contact is made between the Bayesian model results and the VC/PAC model results of (Baxter, 1995b)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1762283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e68c54f39e87daf3a8bdc0ee005aece3c652d11",
            "isKey": true,
            "numCitedBy": 3960,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Although Bayesian analysis has been in use since Laplace, the Bayesian method of model-comparison has only recently been developed in depth. In this paper, the Bayesian approach to regularization and model-comparison is demonstrated by studying the inference problem of interpolating noisy data. The concepts and methods described are quite general and can be applied to many other data modeling problems. Regularizing constants are set by examining their posterior probability distribution. Alternative regularizers (priors) and alternative basis sets are objectively compared by evaluating the evidence for them. Occam's razor is automatically embodied by this process. The way in which Bayes infers the values of regularizing constants and noise levels has an elegant interpretation in terms of the effective number of parameters determined by the data set. This framework is due to Gull and Skilling."
            },
            "slug": "Bayesian-Interpolation-Mackay",
            "title": {
                "fragments": [],
                "text": "Bayesian Interpolation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The Bayesian approach to regularization and model-comparison is demonstrated by studying the inference problem of interpolating noisy data by examining the posterior probability distribution of regularizing constants and noise levels."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 137
                            }
                        ],
                        "text": "In contrast to other techniques for Bayes learning with neural networks in which there are at most a handful of hyper-parameters (see.g.(Mackay, 1991)), here the hyper-parameters vastly outnumber the model parameters."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 119
                            }
                        ],
                        "text": "Hierarchical Bayesian inference has also been discussed in the context of neural networks by several authors (seee.g. (Mackay, 1991), although the techniques presented there are not explicitly identified as hierarchical Bayes)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 217
                            }
                        ],
                        "text": "For the most part hierarchical Bayes has been used to tune a small number of \u201cnuisance\u201d (hyper) parameters (such as the parameter\u03bb controlling the trade-off between regularisation and data-misfit in regression networks (Mackay, 1991)), and this tuning has been based on learning asingletask."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6530745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7abda1941534d3bb558dd959025d67f1df526303",
            "isKey": false,
            "numCitedBy": 792,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Three Bayesian ideas are presented for supervised adaptive classifiers. First, it is argued that the output of a classifier should be obtained by marginalizing over the posterior distribution of the parameters; a simple approximation to this integral is proposed and demonstrated. This involves a \"moderation\" of the most probable classifier's outputs, and yields improved performance. Second, it is demonstrated that the Bayesian framework for model comparison described for regression models in MacKay (1992a,b) can also be applied to classification problems. This framework successfully chooses the magnitude of weight decay terms, and ranks solutions found using different numbers of hidden units. Third, an information-based data selection criterion is derived and demonstrated within this framework."
            },
            "slug": "The-Evidence-Framework-Applied-to-Classification-Mackay",
            "title": {
                "fragments": [],
                "text": "The Evidence Framework Applied to Classification Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is demonstrated that the Bayesian framework for model comparison described for regression models in MacKay (1992a,b) can also be applied to classification problems and an information-based data selection criterion is derived and demonstrated within this framework."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2177274"
                        ],
                        "name": "B. Clarke",
                        "slug": "B.-Clarke",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Clarke",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Clarke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20658113"
                        ],
                        "name": "A. Barron",
                        "slug": "A.-Barron",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barron",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 150
                            }
                        ],
                        "text": "\u2026on this family of hypothesis spaces (these restrictions are analogous to the \u201cfinite VC dimension\u201d restrictions on ordinary learners), it is possible for the learner to sample sufficiently often from sufficiently many tasks to ensure that a hypothesis space containing hypotheses with small\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 44
                            }
                        ],
                        "text": "Theorem 7 holds for all\u03b8 in this model (see (Clarke & Barron, 1990)), and so condition 5 of the definition of an(a, b)-model ( 1, b) in this case) holds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 129
                            }
                        ],
                        "text": "The asymptotic results for smooth Euclidean models given in section 4.2 could also be derived more directly from the results of (Clarke & Barron, 1990)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 175
                            }
                        ],
                        "text": "(3)\nThe form of this equation aslogn multiplied by the dimension of the space of possible priors around the true prior\u03c0\u2217 is similar to results from ordinary Bayesian inference (Clarke & Barron, 1990)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: Hierarchichal Bayesian Inference, Bias learning, Feature Learning, Neural Networks, Information Theory"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11635626,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52af2a10ae1eb70222cd5d0a58d02594eaf9e311",
            "isKey": true,
            "numCitedBy": 461,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "In the absence of knowledge of the true density function, Bayesian models take the joint density function for a sequence of n random variables to be an average of densities with respect to a prior. The authors examine the relative entropy distance D/sub n/ between the true density and the Bayesian density and show that the asymptotic distance is (d/2)(log n)+c, where d is the dimension of the parameter vector. Therefore, the relative entropy rate D/sub n//n converges to zero at rate (log n)/n. The constant c, which the authors explicitly identify, depends only on the prior density function and the Fisher information matrix evaluated at the true parameter value. Consequences are given for density estimation, universal data compression, composite hypothesis testing, and stock-market portfolio selection. >"
            },
            "slug": "Information-theoretic-asymptotics-of-Bayes-methods-Clarke-Barron",
            "title": {
                "fragments": [],
                "text": "Information-theoretic asymptotics of Bayes methods"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The authors examine the relative entropy distance D/sub n/ between the true density and the Bayesian density and show that the asymptotic distance is (d/2)(log n)+c, where d is the dimension of the parameter vector."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2177274"
                        ],
                        "name": "B. Clarke",
                        "slug": "B.-Clarke",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Clarke",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Clarke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20658113"
                        ],
                        "name": "A. Barron",
                        "slug": "A.-Barron",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barron",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 72
                            }
                        ],
                        "text": "This question has only recently been settled for ordinary Bayes models (Barron & Clarke, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10826532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4730db145ba4d49d5deb7414cd4bdc7012e7836",
            "isKey": false,
            "numCitedBy": 297,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Jeffreys'-prior-is-asymptotically-least-favorable-Clarke-Barron",
            "title": {
                "fragments": [],
                "text": "Jeffreys' prior is asymptotically least favorable under entropy risk"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 163
                            }
                        ],
                        "text": "Several authors have made empirical studies of the idea that learning multiple related tasks should improve performance, see.g. (Caruana, 1993, Abu-Mostafa, 1989, Mitchell & Thrun, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 97
                            }
                        ],
                        "text": "In a machine learning context, this means that a learner must be biased in some way for it to generalise well (Mitchell, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6046155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b65b99e772727dadc1b5e50a9d83367a892ec28",
            "isKey": false,
            "numCitedBy": 157,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Most research on machine learning has focused on scenarios in which a learner faces a single, isolated learning task. The lifelong learning framework assumes instead that the learner encounters a multitude of related learning tasks over its lifetime, providing the opportunity for the transfer of knowledge. This paper studies lifelong learning in the context of binary classification. It presents the invariance approach, in which knowledge is transferred via a learned model of the invariances of the domain. Results on learning to recognize objects from color images demonstrate superior generalization capabilities if invariances are learned and used to bias subsequent learning."
            },
            "slug": "Learning-One-More-Thing-Thrun-Mitchell",
            "title": {
                "fragments": [],
                "text": "Learning One More Thing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results on learning to recognize objects from color images demonstrate superior generalization capabilities if invariances are learned and used to bias subsequent learning."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 36
                            }
                        ],
                        "text": "Also,\u2206K(\u03c0, \u03c0\u2032) \u2265 12\u2206H(\u03c0, \u03c0\u2032) always (seee.g. (Haussler & Opper, 1995a))."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 87
                            }
                        ],
                        "text": "(A.5)\nProof: The arguments used in the proof of lemma 11 are similar to those used in (Haussler & Opper, 1995a) for proving corresponding global metric entropy bounds."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 22
                            }
                        ],
                        "text": "Also, the results of (Haussler & Opper, 1995b) can be used to derive asymptotic bounds on the KL divergence even when the model is infinite dimensional."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 141
                            }
                        ],
                        "text": "\u2026on ordinary learners), it is possible for the learner to sample sufficiently often from sufficiently many tasks to ensure that a hypothesis space containing hypotheses with small empirical loss on all the tasks will, with high probability, contain good solutions to novel tasks drawn from\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 96
                            }
                        ],
                        "text": "Theorem 1 can also be derived via quite different techniques as a special case of theorem 2 in (Haussler & Opper, 1995b) (which appeared as an earlier incarnation of the present paper (Baxter, 1996a) was being prepared)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 79
                            }
                        ],
                        "text": "The motivation behind the approach taken here (which is based on the ideas in (Haussler & Opper, 1995a)) is that it provides results for general metric spaces, not just Euclidean models, although this is at the expense of losing lower order terms in the asymptotic estimates."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 12
                            }
                        ],
                        "text": "Theorem 9 ((Haussler & Opper, 1995a), theorem 1)For all n \u2265 1,\n\u2212E\u03a0\u2217 logE\u03a0e\u2212 n 4 \u2206H(\u03c0 \u2217,\u03c0) \u2264 I(\u03a0; \u0398n) \u2264 \u2212E\u03a0\u2217 logE\u03a0e\u2212n\u2206K(\u03c0,\u03c0 \u2217)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 101
                            }
                        ],
                        "text": "Proof: See appendix A.\nNote that if\nsup \u03c0,\u03c0\u2217\u2208\u03a0 and\u03b8\u2208\u0398\np(\u03b8|\u03c0) p(\u03b8|\u03c0\u2217)  \u221e (28)\nthen there exists\u03b1  \u221e such that\u2206K(\u03c0, \u03c0\u2032) \u2264 \u03b1\u2206H(\u03c0, \u03c0\u2032) (Haussler & Opper, 1995a)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2542990,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "fc5a356d7a908271544728a5d85bce900e78ba2c",
            "isKey": true,
            "numCitedBy": 32,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Each parameter in an abstract parameter space is associated with a di erent probability distribution on a set Y A parameter is chosen at random from ac cording to some a priori distribution on and n condi tionally independent random variables Y n Y Yn are observed with common distribution determined by We obtain bounds on the mutual information be tween the random variable giving the choice of pa rameter and the random variable Y n giving the se quence of observations We also bound the supremum of the mutual information over choices of the prior dis tribution on These quantities have applications in density estimation computational learning theory uni versal coding hypothesis testing and portfolio selection theory The bounds are given in terms of the metric and information dimensions of the parameter space with respect to the Hellinger distance"
            },
            "slug": "General-bounds-on-the-mutual-information-between-a-Haussler-Opper",
            "title": {
                "fragments": [],
                "text": "General bounds on the mutual information between a parameter and n conditionally independent observations"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "B bounds are given in terms of the metric and information dimensions of the parameter space with respect to the Hellinger distance and the supremum of the mutual information over choices of the prior dis tribution is bound."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398965769"
                        ],
                        "name": "Y. Abu-Mostafa",
                        "slug": "Y.-Abu-Mostafa",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Abu-Mostafa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Abu-Mostafa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 144
                            }
                        ],
                        "text": "Several authors have made empirical studies of the idea that learning multiple related tasks should improve performance, see.g. (Caruana, 1993, Abu-Mostafa, 1989, Mitchell & Thrun, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 78
                            }
                        ],
                        "text": "In a machine learning context, this means that a learner must be biased in some way for it to generalise well (Mitchell, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 319536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3cd36c092abd65d6ac8e648f3468eeee90ee1fc",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-from-hints-in-neural-networks-Abu-Mostafa",
            "title": {
                "fragments": [],
                "text": "Learning from hints in neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "J. Complex."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145727186"
                        ],
                        "name": "R. Caruana",
                        "slug": "R.-Caruana",
                        "structuredName": {
                            "firstName": "Rich",
                            "lastName": "Caruana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Caruana"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 112
                            }
                        ],
                        "text": "However, note that the theoretical model presented here does not apply directly to the experimental results of (Caruana, 1993) because there the training sets are not generated independently for each task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 129
                            }
                        ],
                        "text": "Several authors have made empirical studies of the idea that learning multiple related tasks should improve performance, see.g. (Caruana, 1993, Abu-Mostafa, 1989, Mitchell & Thrun, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 63
                            }
                        ],
                        "text": "In a machine learning context, this means that a learner must be biased in some way for it to generalise well (Mitchell, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 9
                            }
                        ],
                        "text": "Caruana (Caruana, 1993) has observed that adding extra output nodes to a single-hidden layer net and training them to perform correctly on related tasks can improve performance on a reference problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9667898,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "210da45e57f86a50c04bdd7b37d498c8ecc288da",
            "isKey": true,
            "numCitedBy": 251,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Hinton [6] proposed that generalization in artificial neural nets should improve if nets learn to represent the domain's underlying regularities. Abu-Mustafa's hints work [1] shows that the outputs of a backprop net can be used as inputs through which domain-specific information can be given to the net. We extend these ideas by showing that a backprop net learning many related tasks at the same time can use these tasks as inductive bias for each other and thus learn better. We identify five mechanisms by which multitask backprop improves generalization and give empirical evidence that multitask backprop generalizes better in real domains."
            },
            "slug": "Learning-Many-Related-Tasks-at-the-Same-Time-with-Caruana",
            "title": {
                "fragments": [],
                "text": "Learning Many Related Tasks at the Same Time with Backpropagation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work shows that a backprop net learning many related tasks at the same time can use these tasks as inductive bias for each other and thus learn better and give empirical evidence that multitask backprop generalizes better in real domains."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110094"
                        ],
                        "name": "J. Bridle",
                        "slug": "J.-Bridle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bridle",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bridle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 114
                            }
                        ],
                        "text": "Denoting the output of a network with weights\u03b8 by f\u03b8(x), and interpretingf\u03b8(x) asp(y = 1|x), it can easily be shown (Bridle, 1989) that the probability of data setzn = (x1, y1), . . . , (xn, yn) given weights\u03b8 is\np(zn|\u03b8) = n\u220f i=1 p(xi)e\u2212E(z n;\u03b8) (10)\nwhere\nE(zn; \u03b8) = n\u2211 i=1 yi log(f\u03b8(xi)) + (1\u2212 yi)\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59636530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f462943c8d0af69c12a09058251848324135e5a",
            "isKey": false,
            "numCitedBy": 1100,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We are concerned with feed-forward non-linear networks (multi-layer perceptrons, or MLPs) with multiple outputs. We wish to treat the outputs of the network as probabilities of alternatives (e.g. pattern classes), conditioned on the inputs. We look for appropriate output non-linearities and for appropriate criteria for adaptation of the parameters of the network (e.g. weights). We explain two modifications: probability scoring, which is an alternative to squared error minimisation, and a normalised exponential (softmax) multi-input generalisation of the logistic non-linearity. The two modifications together result in quite simple arithmetic, and hardware implementation is not difficult either. The use of radial units (squared distance instead of dot product) immediately before the softmax output stage produces a network which computes posterior distributions over class labels based on an assumption of Gaussian within-class distributions. However the training, which uses cross-class information, can result in better performance at class discrimination than the usual within-class training method, unless the within-class distribution assumptions are actually correct."
            },
            "slug": "Probabilistic-Interpretation-of-Feedforward-Network-Bridle",
            "title": {
                "fragments": [],
                "text": "Probabilistic Interpretation of Feedforward Classification Network Outputs, with Relationships to Statistical Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Two modifications are explained: probability scoring, which is an alternative to squared error minimisation, and a normalised exponential (softmax) multi-input generalisation of the logistic non- linearity of feed-forward non-linear networks with multiple outputs."
            },
            "venue": {
                "fragments": [],
                "text": "NATO Neurocomputing"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145179124"
                        ],
                        "name": "I. Good",
                        "slug": "I.-Good",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Good",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Good"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 141
                            }
                        ],
                        "text": "The central assumption of all these models (including that of the present paper) is that the learner is embedded within anenvironmentof related tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 155
                            }
                        ],
                        "text": "The Bayesian aspect of the model presented here is a special case of what is known as hierarchical Bayesian inference(see e.g (Berger, 1985, Berger, 1986, Good, 1980))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 121270218,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "0e04161b26757f32a005635f46c66dcc05bc46d5",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "SummaryA standard technique in subjective \u201cBayesian\u201d methodology is for a subject (\u201cyou\u201d) to make judgements of the probabilities that a physical probability lies in various intervals. In the hierarchical Bayesian technique you make probability judgements (of a higher type, order, level, or stage) concerning the judgements of lower type. The paper will outlinesome of the history of this hierarchical technique with emphasis on the contributions by I. J. Good because I have read every word written by him."
            },
            "slug": "Some-history-of-the-hierarchical-Bayesian-Good",
            "title": {
                "fragments": [],
                "text": "Some history of the hierarchical Bayesian methodology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144007105"
                        ],
                        "name": "Philip M. Long",
                        "slug": "Philip-M.-Long",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Long",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip M. Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143957317"
                        ],
                        "name": "R. C. Williamson",
                        "slug": "R.-C.-Williamson",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Williamson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. C. Williamson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2551295,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "fc48a9403b5d01a2d1724d4e04218a4a9b78cb3a",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning real-valued functions from random examples when the function values are corrupted with noise. With mild conditions on independent observation noise, we provide characterizations of the learnability of a real-valued function class in terms of a generalization of the Vapnik-Chervonenkis dimension, the fat shattering function, introduced by Kearns and Schapire. We show that, given some restrictions on the noise, a function class is learnable in our model if and only if its fat-shattering function is finite. With different (also quite mild) restrictions, satisfied for example by gaussian noise, we show that a function class is learnable from polynomially many examples if and only if its fat-shattering function grows polynomially. We prove analogous results in an agnostic setting, where there is no assumption of an underlying function class."
            },
            "slug": "Fat-shattering-and-the-learnability-of-real-valued-Bartlett-Long",
            "title": {
                "fragments": [],
                "text": "Fat-shattering and the learnability of real-valued functions"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that, given some restrictions on the noise, a function class is learnable in this model if and only if its fat-shattering function is finite, and analogous results in an agnostic setting, where there is no assumption of an underlying function class."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145004630"
                        ],
                        "name": "M. Anthony",
                        "slug": "M.-Anthony",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Anthony",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Anthony"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: Hierarchichal Bayesian Inference, Bias learning, Feature Learning, Neural Networks, Information Theory"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 271
                            }
                        ],
                        "text": "\u2026lower bounds within a real-valued VC/PAC framework can only be obtained by making extra assumptions, such as that the function values are corrupted by noise (Bartlett, Long & Williamson, 1994), or that every algorithm within a certain class of algorithms performs well (Anthony & Bartlett, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10454061,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "07e5be1e9339af65685b08a84a9d0fc9153507af",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we study a statistical property of classes of real-valued functions that we call approximation from interpolated examples. We derive a characterization of function classes that have this property, in terms of their \u2018fat-shattering function\u2019, a notion that has proved useful in computational learning theory. The property is central to a problem of learning real-valued functions from random examples in which we require satisfactory performance from every algorithm that returns a function which approximately interpolates the training examples."
            },
            "slug": "Function-Learning-from-Interpolation-Anthony-Bartlett",
            "title": {
                "fragments": [],
                "text": "Function Learning From Interpolation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper requires that, for most training samples, with high probability the absolute difference between the values of the learner's hypothesis and the target function on a random point is small."
            },
            "venue": {
                "fragments": [],
                "text": "Comb. Probab. Comput."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 36
                            }
                        ],
                        "text": "Also,\u2206K(\u03c0, \u03c0\u2032) \u2265 12\u2206H(\u03c0, \u03c0\u2032) always (seee.g. (Haussler & Opper, 1995a))."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 87
                            }
                        ],
                        "text": "(A.5)\nProof: The arguments used in the proof of lemma 11 are similar to those used in (Haussler & Opper, 1995a) for proving corresponding global metric entropy bounds."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 22
                            }
                        ],
                        "text": "Also, the results of (Haussler & Opper, 1995b) can be used to derive asymptotic bounds on the KL divergence even when the model is infinite dimensional."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 96
                            }
                        ],
                        "text": "Theorem 1 can also be derived via quite different techniques as a special case of theorem 2 in (Haussler & Opper, 1995b) (which appeared as an earlier incarnation of the present paper (Baxter, 1996a) was being prepared)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 79
                            }
                        ],
                        "text": "The motivation behind the approach taken here (which is based on the ideas in (Haussler & Opper, 1995a)) is that it provides results for general metric spaces, not just Euclidean models, although this is at the expense of losing lower order terms in the asymptotic estimates."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 12
                            }
                        ],
                        "text": "Theorem 9 ((Haussler & Opper, 1995a), theorem 1)For all n \u2265 1,\n\u2212E\u03a0\u2217 logE\u03a0e\u2212 n 4 \u2206H(\u03c0 \u2217,\u03c0) \u2264 I(\u03a0; \u0398n) \u2264 \u2212E\u03a0\u2217 logE\u03a0e\u2212n\u2206K(\u03c0,\u03c0 \u2217)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 101
                            }
                        ],
                        "text": "Proof: See appendix A.\nNote that if\nsup \u03c0,\u03c0\u2217\u2208\u03a0 and\u03b8\u2208\u0398\np(\u03b8|\u03c0) p(\u03b8|\u03c0\u2217)  \u221e (28)\nthen there exists\u03b1  \u221e such that\u2206K(\u03c0, \u03c0\u2032) \u2264 \u03b1\u2206H(\u03c0, \u03c0\u2032) (Haussler & Opper, 1995a)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14787619,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "3e65ec49a6a32aa3b6985bf414c757f3e143d2ff",
            "isKey": true,
            "numCitedBy": 7,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Assume $\\{P_\\theta: \\theta \\in \\Theta\\}$ is a set of probability distributions with a common dominating measure on a complete separable metric space $Y$. A state $\\theta^* \\in \\Theta$ is chosen by Nature. A statistician gets $n$ independent observations $Y_1, \\ldots, Y_n$ distributed according to $P_{\\theta^*}$. For each time $t$ between 1 and $n$, based on the observations $Y_1, \\ldots, Y_{t-1}$, the statistician produces an estimated distribution $Q_t$ for $P_{\\theta^*}$, and suffers a loss equal to the average of L(P_{\\theta^*},Q_t)$ over the observations. The cumulative risk for the statistician is the average total loss up to time $n$. Of special interest in information theory, data compression, mathematical finance, computational learning theory and statistical physics is the special case when the loss $L(P_{\\theta^*},Q_t)$ is the relative entropy between the true distribution $P_{\\theta^*}$ and the estimated distribution $Q_t$. Here the cumulative Bayes risk is the mutual information between the random parameter $\\Theta^*$ and the observations $Y_1, \\ldots, Y_n$. New bounds on this mutual information are given in terms of the Laplace transform of the Hellinger distance between distributions in $\\Theta$. From these, bounds on the cumulative minimax risk are given in terms of the metric entropy of $\\Theta$ with respect to the Hellinger distance. The assumptions required for these bounds are very general and do not depend on the choice of the dominating measure. They apply to both finite and infinite dimensional $\\Theta$. They apply in some cases where $Y$ is infinite dimensional, in some cases where $Y$ is not compact, in some cases where the distributions are not smooth, and in some parametric cases where asymptotic normality of the posterior distribution fails. Using these bounds for cumulative relative entropy risk, we also examine the Bayes and minimax risk of this game at specific times $t$ for various loss functions $L$, including the relative entropy, the squared Hellinger distance, and the $L_1$ distance."
            },
            "slug": "MUTUAL-INFORMATION,-METRIC-ENTROPY,-AND-RISK-IN-OF-Haussler-Opper",
            "title": {
                "fragments": [],
                "text": "MUTUAL INFORMATION, METRIC ENTROPY, AND RISK IN ESTIMATION OF PROBABILITY DISTRIBUTIONS"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Borders on the cumulative minimax risk of this game are given in terms of the metric entropy of $\\Theta$ with respect to the Hellinger distance and the assumptions required are very general and do not depend on the choice of the dominating measure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764952"
                        ],
                        "name": "K. Hornik",
                        "slug": "K.-Hornik",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Hornik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hornik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Thus for large enoughn the learner can be said to havelearnt the prior."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 168
                            }
                        ],
                        "text": "\u2026net withl hidden units followed byk output units (any boundedk-dimensional LDR can be approximated to arbitrarily high accuracy by such a two-layer structure (see.g. (Hornik, 1991))), while each individual classifier task is assumed to be a sigmoidal map composed with the output of the LDR."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7343126,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d35f1e533b72370683d8fa2dabff5f0fc16490cc",
            "isKey": false,
            "numCitedBy": 4665,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Approximation-capabilities-of-multilayer-networks-Hornik",
            "title": {
                "fragments": [],
                "text": "Approximation capabilities of multilayer feedforward networks"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144442133"
                        ],
                        "name": "L. Pratt",
                        "slug": "L.-Pratt",
                        "structuredName": {
                            "firstName": "Lorien",
                            "lastName": "Pratt",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pratt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 147613,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b66fcdaca4c9e789bd4fae5dfd08a325bbb9fa48",
            "isKey": false,
            "numCitedBy": 309,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Previously, we have introduced the idea of neural network transfer, where learning on a target problem is sped up by using the weights obtained from a network trained for a related source task. Here, we present a new algorithm, called Discriminability-Based Transfer (DBT), which uses an information measure to estimate the utility of hyperplanes defined by source weights in the target network, and rescales transferred weight magnitudes accordingly. Several experiments demonstrate that target networks initialized via DBT learn significantly faster than networks initialized randomly."
            },
            "slug": "Discriminability-Based-Transfer-between-Neural-Pratt",
            "title": {
                "fragments": [],
                "text": "Discriminability-Based Transfer between Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new algorithm, called Discriminability-Based Transfer (DBT), is presented, which uses an information measure to estimate the utility of hyperplanes defined by source weights in the target network, and rescales transferred weight magnitudes accordingly."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115282352"
                        ],
                        "name": "Joy A. Thomas",
                        "slug": "Joy-A.-Thomas",
                        "structuredName": {
                            "firstName": "Joy",
                            "lastName": "Thomas",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joy A. Thomas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 121
                            }
                        ],
                        "text": "The penultimate line follows because the KL divergence is additive over the product of independent distributions (see.g.(Cover & Thomas, 1991))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 190432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dbdb4209626fd92d2436a058663206216036e68",
            "isKey": false,
            "numCitedBy": 42796,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface to the Second Edition. Preface to the First Edition. Acknowledgments for the Second Edition. Acknowledgments for the First Edition. 1. Introduction and Preview. 1.1 Preview of the Book. 2. Entropy, Relative Entropy, and Mutual Information. 2.1 Entropy. 2.2 Joint Entropy and Conditional Entropy. 2.3 Relative Entropy and Mutual Information. 2.4 Relationship Between Entropy and Mutual Information. 2.5 Chain Rules for Entropy, Relative Entropy, and Mutual Information. 2.6 Jensen's Inequality and Its Consequences. 2.7 Log Sum Inequality and Its Applications. 2.8 Data-Processing Inequality. 2.9 Sufficient Statistics. 2.10 Fano's Inequality. Summary. Problems. Historical Notes. 3. Asymptotic Equipartition Property. 3.1 Asymptotic Equipartition Property Theorem. 3.2 Consequences of the AEP: Data Compression. 3.3 High-Probability Sets and the Typical Set. Summary. Problems. Historical Notes. 4. Entropy Rates of a Stochastic Process. 4.1 Markov Chains. 4.2 Entropy Rate. 4.3 Example: Entropy Rate of a Random Walk on a Weighted Graph. 4.4 Second Law of Thermodynamics. 4.5 Functions of Markov Chains. Summary. Problems. Historical Notes. 5. Data Compression. 5.1 Examples of Codes. 5.2 Kraft Inequality. 5.3 Optimal Codes. 5.4 Bounds on the Optimal Code Length. 5.5 Kraft Inequality for Uniquely Decodable Codes. 5.6 Huffman Codes. 5.7 Some Comments on Huffman Codes. 5.8 Optimality of Huffman Codes. 5.9 Shannon-Fano-Elias Coding. 5.10 Competitive Optimality of the Shannon Code. 5.11 Generation of Discrete Distributions from Fair Coins. Summary. Problems. Historical Notes. 6. Gambling and Data Compression. 6.1 The Horse Race. 6.2 Gambling and Side Information. 6.3 Dependent Horse Races and Entropy Rate. 6.4 The Entropy of English. 6.5 Data Compression and Gambling. 6.6 Gambling Estimate of the Entropy of English. Summary. Problems. Historical Notes. 7. Channel Capacity. 7.1 Examples of Channel Capacity. 7.2 Symmetric Channels. 7.3 Properties of Channel Capacity. 7.4 Preview of the Channel Coding Theorem. 7.5 Definitions. 7.6 Jointly Typical Sequences. 7.7 Channel Coding Theorem. 7.8 Zero-Error Codes. 7.9 Fano's Inequality and the Converse to the Coding Theorem. 7.10 Equality in the Converse to the Channel Coding Theorem. 7.11 Hamming Codes. 7.12 Feedback Capacity. 7.13 Source-Channel Separation Theorem. Summary. Problems. Historical Notes. 8. Differential Entropy. 8.1 Definitions. 8.2 AEP for Continuous Random Variables. 8.3 Relation of Differential Entropy to Discrete Entropy. 8.4 Joint and Conditional Differential Entropy. 8.5 Relative Entropy and Mutual Information. 8.6 Properties of Differential Entropy, Relative Entropy, and Mutual Information. Summary. Problems. Historical Notes. 9. Gaussian Channel. 9.1 Gaussian Channel: Definitions. 9.2 Converse to the Coding Theorem for Gaussian Channels. 9.3 Bandlimited Channels. 9.4 Parallel Gaussian Channels. 9.5 Channels with Colored Gaussian Noise. 9.6 Gaussian Channels with Feedback. Summary. Problems. Historical Notes. 10. Rate Distortion Theory. 10.1 Quantization. 10.2 Definitions. 10.3 Calculation of the Rate Distortion Function. 10.4 Converse to the Rate Distortion Theorem. 10.5 Achievability of the Rate Distortion Function. 10.6 Strongly Typical Sequences and Rate Distortion. 10.7 Characterization of the Rate Distortion Function. 10.8 Computation of Channel Capacity and the Rate Distortion Function. Summary. Problems. Historical Notes. 11. Information Theory and Statistics. 11.1 Method of Types. 11.2 Law of Large Numbers. 11.3 Universal Source Coding. 11.4 Large Deviation Theory. 11.5 Examples of Sanov's Theorem. 11.6 Conditional Limit Theorem. 11.7 Hypothesis Testing. 11.8 Chernoff-Stein Lemma. 11.9 Chernoff Information. 11.10 Fisher Information and the Cram-er-Rao Inequality. Summary. Problems. Historical Notes. 12. Maximum Entropy. 12.1 Maximum Entropy Distributions. 12.2 Examples. 12.3 Anomalous Maximum Entropy Problem. 12.4 Spectrum Estimation. 12.5 Entropy Rates of a Gaussian Process. 12.6 Burg's Maximum Entropy Theorem. Summary. Problems. Historical Notes. 13. Universal Source Coding. 13.1 Universal Codes and Channel Capacity. 13.2 Universal Coding for Binary Sequences. 13.3 Arithmetic Coding. 13.4 Lempel-Ziv Coding. 13.5 Optimality of Lempel-Ziv Algorithms. Compression. Summary. Problems. Historical Notes. 14. Kolmogorov Complexity. 14.1 Models of Computation. 14.2 Kolmogorov Complexity: Definitions and Examples. 14.3 Kolmogorov Complexity and Entropy. 14.4 Kolmogorov Complexity of Integers. 14.5 Algorithmically Random and Incompressible Sequences. 14.6 Universal Probability. 14.7 Kolmogorov complexity. 14.9 Universal Gambling. 14.10 Occam's Razor. 14.11 Kolmogorov Complexity and Universal Probability. 14.12 Kolmogorov Sufficient Statistic. 14.13 Minimum Description Length Principle. Summary. Problems. Historical Notes. 15. Network Information Theory. 15.1 Gaussian Multiple-User Channels. 15.2 Jointly Typical Sequences. 15.3 Multiple-Access Channel. 15.4 Encoding of Correlated Sources. 15.5 Duality Between Slepian-Wolf Encoding and Multiple-Access Channels. 15.6 Broadcast Channel. 15.7 Relay Channel. 15.8 Source Coding with Side Information. 15.9 Rate Distortion with Side Information. 15.10 General Multiterminal Networks. Summary. Problems. Historical Notes. 16. Information Theory and Portfolio Theory. 16.1 The Stock Market: Some Definitions. 16.2 Kuhn-Tucker Characterization of the Log-Optimal Portfolio. 16.3 Asymptotic Optimality of the Log-Optimal Portfolio. 16.4 Side Information and the Growth Rate. 16.5 Investment in Stationary Markets. 16.6 Competitive Optimality of the Log-Optimal Portfolio. 16.7 Universal Portfolios. 16.8 Shannon-McMillan-Breiman Theorem (General AEP). Summary. Problems. Historical Notes. 17. Inequalities in Information Theory. 17.1 Basic Inequalities of Information Theory. 17.2 Differential Entropy. 17.3 Bounds on Entropy and Relative Entropy. 17.4 Inequalities for Types. 17.5 Combinatorial Bounds on Entropy. 17.6 Entropy Rates of Subsets. 17.7 Entropy and Fisher Information. 17.8 Entropy Power Inequality and Brunn-Minkowski Inequality. 17.9 Inequalities for Determinants. 17.10 Inequalities for Ratios of Determinants. Summary. Problems. Historical Notes. Bibliography. List of Symbols. Index."
            },
            "slug": "Elements-of-Information-Theory-Cover-Thomas",
            "title": {
                "fragments": [],
                "text": "Elements of Information Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author examines the role of entropy, inequality, and randomness in the design of codes and the construction of codes in the rapidly changing environment."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39201543"
                        ],
                        "name": "J. Berger",
                        "slug": "J.-Berger",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Berger",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Berger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 40
                            }
                        ],
                        "text": "In Bayesian models of learning (see.g. (Berger, 1985)) the learner receives datazn = z1, . . . , zn which are observations onn random variablesZn = Z1, . . . , Zn."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 127
                            }
                        ],
                        "text": "The Bayesian aspect of the model presented here is a special case of what is known as hierarchical Bayesian inference(see e.g (Berger, 1985, Berger, 1986, Good, 1980))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120366929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9dd05b69d6906fff6ea6c4ba3609a6d97c9b8a3",
            "isKey": false,
            "numCitedBy": 7326,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "An overview of statistical decision theory, which emphasizes the use and application of the philosophical ideas and mathematical structure of decision theory. The text assumes a knowledge of basic probability theory and some advanced calculus is also required."
            },
            "slug": "Statistical-Decision-Theory-and-Bayesian-Analysis-Berger",
            "title": {
                "fragments": [],
                "text": "Statistical Decision Theory and Bayesian Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An overview of statistical decision theory, which emphasizes the use and application of the philosophical ideas and mathematical structure of decision theory."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1848427"
                        ],
                        "name": "C. Fefferman",
                        "slug": "C.-Fefferman",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Fefferman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fefferman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121350232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be837da1e2054672b0c0542a9a5acc12375fa72f",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural nets were originally introduced as highly simplified systems of the neural system. Today they are widely used in technology and studied theoretically by scientists from several disciplines. (See e.g. [N]). However they remain little understood. (...)"
            },
            "slug": "Reconstructing-a-neural-net-from-its-output-Fefferman",
            "title": {
                "fragments": [],
                "text": "Reconstructing a neural net from its output"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "Neural nets were originally introduced as highly simplified systems of the neural system and are widely used in technology and studied theoretically by scientists from several disciplines, but remain little understood."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 34
                            }
                        ],
                        "text": "This assumption was also made in (Baxter, 1995b, Baxter, 1996b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 77
                            }
                        ],
                        "text": "Experimental verification of this for feedforward nets was also reported in (Baxter, 1995b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 32
                            }
                        ],
                        "text": "In particular, it was shown in (Baxter, 1995b) that if the learner is learning a common feature set (LDR) for ann task training set then the number of examplesm required of each task to ensure good generalisation on average across alln tasks obeys\nm = O ( a+ b\nn\n) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 126
                            }
                        ],
                        "text": "In this paper a Bayesian model of bias learning is introduced, based on the VC/PACtype models of bias learning introduced in (Baxter, 1995b, Baxter, 1996b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 180
                            }
                        ],
                        "text": "(41)\nThe similarity of this expression to the upper bound on the number of examples required per task for good generalisation in a PAC sense ofO(WOUT + WLDR/n) is noteworthy\n(see (Baxter, 1995b) for a derivation of the latter expression)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 101
                            }
                        ],
                        "text": "This scenario is not covered by the Bayesian model presented here, nor by the VC/PAC type models of (Baxter, 1995b, Baxter, 1996b), because these models assume that independent training sets are available for each output node."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 111
                            }
                        ],
                        "text": "If the learner is learningn tasks simultaneously then it will receive n such samples (called an( ,m)-samplein (Baxter, 1995b, Baxter, 1995a)):\nz(n,m) = z11 . . . z1m ... ... ...\nzn1 . . . znm\n(42)\nEach row ofz(n,m) is sampled according top(z|\u03b8i) where\u03b81, . . . , \u03b8n are then tasks being learnt."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 4
                            }
                        ],
                        "text": "In (Baxter, 1995b, Baxter, 1996b) it was shown that under certain restrictions on this family of hypothesis spaces (these restrictions are analogous to the \u201cfinite VC dimension\u201d restrictions on ordinary learners), it is possible for the learner to sample sufficiently often from sufficiently many\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 209
                            }
                        ],
                        "text": "Equations (2) and (3) are derived in section 3 and the constants\u2032 andb\u2032(\u03c0\u2217) are calculated for the neural network example, where contact is made between the Bayesian model results and the VC/PAC model results of (Baxter, 1995b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Model of Bias Learning"
            },
            "venue": {
                "fragments": [],
                "text": "A Model of Bias Learning"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Model of Bias Learning. Technical Report LSE-MPS-97, London School of Economics, Centre for Discrete and Applicable Mathematics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 141
                            }
                        ],
                        "text": "The Bayesian aspect of the model presented here is a special case of what is known as hierarchical Bayesian inference(see e.g (Berger, 1985, Berger, 1986, Good, 1980))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multivariate Estimation: Bayes, Empirical Bayes, and Stein Approaches"
            },
            "venue": {
                "fragments": [],
                "text": "Multivariate Estimation: Bayes, Empirical Bayes, and Stein Approaches"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reconstructing a neural network from its output"
            },
            "venue": {
                "fragments": [],
                "text": "Rev . Mat . Iberoamericana"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reconstructing a neural network from its output"
            },
            "venue": {
                "fragments": [],
                "text": "Rev. Mat. Iberoamericana"
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 18,
            "methodology": 13,
            "result": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 26,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Bayesian/Information-Theoretic-Model-of-Learning-Baxter/1bd6e929ed8384ea2212d50ab3c103ec018cc9fd?sort=total-citations"
}