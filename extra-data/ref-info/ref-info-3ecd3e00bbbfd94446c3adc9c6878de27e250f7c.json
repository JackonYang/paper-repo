{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50649676"
                        ],
                        "name": "J. Clarke",
                        "slug": "J.-Clarke",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Clarke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Clarke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2877164"
                        ],
                        "name": "Dan Goldwasser",
                        "slug": "Dan-Goldwasser",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Goldwasser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Goldwasser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744179"
                        ],
                        "name": "Ming-Wei Chang",
                        "slug": "Ming-Wei-Chang",
                        "structuredName": {
                            "firstName": "Ming-Wei",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Wei Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5667590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92fb5e045bb23f13c11d8bb277925013b24b5930",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Current approaches to semantic parsing, the task of converting text to a formal meaning representation, rely on annotated training data mapping sentences to logical forms. Providing this supervision is a major bottleneck in scaling semantic parsers. This paper presents a new learning paradigm aimed at alleviating the supervision burden. We develop two novel learning algorithms capable of predicting complex structures which only rely on a binary feedback signal based on the context of an external world. In addition we reformulate the semantic parsing problem to reduce the dependency of the model on syntactic patterns, thus allowing our parser to scale better using less supervision. Our results surprisingly show that without using any annotated meaning representations learning with a weak feedback signal is capable of producing a parser that is competitive with fully supervised parsers."
            },
            "slug": "Driving-Semantic-Parsing-from-the-World\u2019s-Response-Clarke-Goldwasser",
            "title": {
                "fragments": [],
                "text": "Driving Semantic Parsing from the World\u2019s Response"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper develops two novel learning algorithms capable of predicting complex structures which only rely on a binary feedback signal based on the context of an external world and reformulates the semantic parsing problem to reduce the dependency of the model on syntactic patterns, thus allowing the parser to scale better using less supervision."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787006"
                        ],
                        "name": "Ruifang Ge",
                        "slug": "Ruifang-Ge",
                        "structuredName": {
                            "firstName": "Ruifang",
                            "lastName": "Ge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruifang Ge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 76
                            }
                        ],
                        "text": "Supervised semantic parsers (Zelle and Mooney, 1996; Tang and Mooney, 2001; Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Kate and Mooney, 2007; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Kwiatkowski et al., 2010) rely on manual annotation of logical forms, which is expensive."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 590\u2013599, Portland, Oregon, June 19-24, 2011. c\u00a92011 Association for Computational Linguistics"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2046600,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ae207cfaf01dc2b6799da67f454190b34994870",
            "isKey": false,
            "numCitedBy": 201,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a learning semantic parser, Scissor, that maps natural-language sentences to a detailed, formal, meaning-representation language. It first uses an integrated statistical parser to produce a semantically augmented parse tree, in which each non-terminal node has both a syntactic and a semantic label. A compositional-semantics procedure is then used to map the augmented parse tree into a final meaning representation. We evaluate the system in two domains, a natural-language database interface and an interpreter for coaching instructions in robotic soccer. We present experimental results demonstrating that Scissor produces more accurate semantic representations than several previous approaches."
            },
            "slug": "A-Statistical-Semantic-Parser-that-Integrates-and-Ge-Mooney",
            "title": {
                "fragments": [],
                "text": "A Statistical Semantic Parser that Integrates Syntax and Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A learning semantic parser that maps natural-language sentences to a detailed, formal, meaning-representation language and presents experimental results demonstrating that Scissor produces more accurate semantic representations than several previous approaches."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710450"
                        ],
                        "name": "J. Zelle",
                        "slug": "J.-Zelle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Zelle",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 29
                            }
                        ],
                        "text": "Supervised semantic parsers (Zelle and Mooney, 1996; Tang and Mooney, 2001; Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Kate and Mooney, 2007; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Kwiatkowski et al., 2010) rely on manual annotation of logical forms, which is expensive."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The GEO data set, originally created by Zelle and Mooney (1996), contains 880 questions about U."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 263135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7c0e47f8b768258b7d536c21b218e6c46ab8791",
            "isKey": false,
            "numCitedBy": 642,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural-language interface for database queries. CHILL treats parser acquisition as the learning of search-control rules within a logic program representing a shift-reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge. Starting with a general framework for constructing a suitable logical form, CHILL is able to train on a corpus comprising sentences paired with database queries and induce parsers that map subsequent sentences directly into executable queries. Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart. These results demonstrate the ability of a corpus-based system to produce more than purely syntactic representations. They also provide direct evidence of the utility of an empirical approach at the level of a complete natural language application."
            },
            "slug": "Learning-to-Parse-Database-Queries-Using-Inductive-Zelle-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning to Parse Database Queries Using Inductive Logic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart, and provide direct evidence of the utility of an empirical approach at the level of a complete natural language application."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI, Vol. 2"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767307"
                        ],
                        "name": "H. Alshawi",
                        "slug": "H.-Alshawi",
                        "structuredName": {
                            "firstName": "Hiyan",
                            "lastName": "Alshawi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Alshawi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113641500"
                        ],
                        "name": "Pi-Chuan Chang",
                        "slug": "Pi-Chuan-Chang",
                        "structuredName": {
                            "firstName": "Pi-Chuan",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pi-Chuan Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2895331"
                        ],
                        "name": "Michael Ringgaard",
                        "slug": "Michael-Ringgaard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ringgaard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Ringgaard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 84
                            }
                        ],
                        "text": "DCS has a family resemblance to a semantic representation called natural logic form (Alshawi et al., 2011), which is also motivated by the benefits of working with dependency-based logical forms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6360793,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad79cdcefbe68f7c15eec61f886f74ef2adaecf3",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for training a statistical model for mapping natural language sentences to semantic expressions. The semantics are expressions of an underspecified logical form that has properties making it particularly suitable for statistical mapping from text. An encoding of the semantic expressions into dependency trees with automatically generated labels allows application of existing methods for statistical dependency parsing to the mapping task (without the need for separate traditional dependency labels or parts of speech). The encoding also results in a natural per-word semantic-mapping accuracy measure. We report on the results of training and testing statistical models for mapping sentences of the Penn Treebank into the semantic expressions, for which per-word semantic mapping accuracy ranges between 79% and 86% depending on the experimental conditions. The particular choice of algorithms used also means that our trained mapping is deterministic (in the sense of deterministic parsing), paving the way for large-scale text-to-semantic mapping."
            },
            "slug": "Deterministic-Statistical-Mapping-of-Sentences-to-Alshawi-Chang",
            "title": {
                "fragments": [],
                "text": "Deterministic Statistical Mapping of Sentences to Underspecified Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The particular choice of algorithms used means that the trained mapping is deterministic (in the sense of deterministic parsing), paving the way for large-scale text-to-semantic mapping."
            },
            "venue": {
                "fragments": [],
                "text": "IWCS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 28
                            }
                        ],
                        "text": "Supervised semantic parsers (Zelle and Mooney, 1996; Tang and Mooney, 2001; Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Kate and Mooney, 2007; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Kwiatkowski et al., 2010) rely on manual annotation of logical forms, which is expensive."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 449252,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74fe7ec751cd50295b15cfd46389a8fefb37c414",
            "isKey": false,
            "numCitedBy": 874,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of mapping natural language sentences to lambda\u2013calculus encodings of their meaning. We describe a learning algorithm that takes as input a training set of sentences labeled with expressions in the lambda calculus. The algorithm induces a grammar for the problem, along with a log-linear model that represents a distribution over syntactic and semantic analyses conditioned on the input sentence. We apply the method to the task of learning natural language interfaces to databases and show that the learned parsers outperform previous methods in two benchmark database domains."
            },
            "slug": "Learning-to-Map-Sentences-to-Logical-Form:-with-Zettlemoyer-Collins",
            "title": {
                "fragments": [],
                "text": "Learning to Map Sentences to Logical Form: Structured Classification with Probabilistic Categorial Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A learning algorithm is described that takes as input a training set of sentences labeled with expressions in the lambda calculus and induces a grammar for the problem, along with a log-linear model that represents a distribution over syntactic and semantic analyses conditioned on the input sentence."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8075439"
                        ],
                        "name": "Y. W. Wong",
                        "slug": "Y.-W.-Wong",
                        "structuredName": {
                            "firstName": "Yuk",
                            "lastName": "Wong",
                            "middleNames": [
                                "Wah"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. W. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", whereas our system learns from annotated answers. On the other hand, many of the later systems require essentially no manually-crafted lexicon and instead rely on unsupervised word alignment (e.g., Wong and Mooney (2006, 2007); Kwiatkowski et al. (2010, 2011)) and/or lexicon learning (e.g., Zettlemoyer and Collins (2005, 2007); Kwiatkowski et al. (2010, 2011)). We cannot use these automatic techniques because they r"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Answer Cocktail (Tang and Mooney, 2001) 79.4 { Precise (Popescu et al., 2003) 77.5 77.5 Scissor (Ge and Mooney, 2005) 72.3 { Silt (Kate et al., 2005) 54.1 { Krisp (Kate and Mooney, 2006) 71.7 { Wasp (Wong and Mooney, 2006) 74.8 { -Wasp (Wong and Mooney, 2007) 86.6 { LNLZ08 (Lu et al., 2008) 81.8 { ZC05 (Zettlemoyer and Collins, 2005) 79.3 { ZC07 (Zettlemoyer and Collins, 2007) 86.1 { KZGS10 (Kwiatkowski et al., 2010) "
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": " set of transformation rules for mapping utterances to logical forms. Krisp (Kate and Mooney, 2006) uses SVMs with string kernels to drive the local decisions of a chartbased semantic parser. Wasp (Wong and Mooney, 2006) uses log-linear synchronous grammars to transform utterances into logical forms, starting with word alignments obtained from the IBM models. -Wasp (Wong and Mooney, 2007) extends Wasp to work with "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ions and machine learning techniques (Zelle and Mooney, 1996; Miller et al., 1996; Tang and Mooney, 2001; Ge and Mooney, 2005; Kate et al., 2005; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2006; Kate and Mooney, 2007; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Kwiatkowski et al., 2010, 2011). However, while statistical methods provided advantages such as robustness and portabilit"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7785983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "687dce9ac01f5996601655035c34b449c27c3b6a",
            "isKey": true,
            "numCitedBy": 293,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel statistical approach to semantic parsing, WASP, for constructing a complete, formal meaning representation of a sentence. A semantic parser is learned given a set of sentences annotated with their correct meaning representations. The main innovation of WASP is its use of state-of-the-art statistical machine translation techniques. A word alignment model is used for lexical acquisition, and the parsing model itself can be seen as a syntax-based translation model. We show that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision, and shows better robustness to variations in task complexity and word order."
            },
            "slug": "Learning-for-Semantic-Parsing-with-Statistical-Wong-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning for Semantic Parsing with Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision, and shows better robustness to variations in task complexity and word order."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37859488"
                        ],
                        "name": "A. Giordani",
                        "slug": "A.-Giordani",
                        "structuredName": {
                            "firstName": "Alessandra",
                            "lastName": "Giordani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Giordani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719404"
                        ],
                        "name": "Alessandro Moschitti",
                        "slug": "Alessandro-Moschitti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Moschitti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Moschitti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "tional mechanisms for constructing those logical forms? The semantic parsing literature is quite multilingual with respect to the formal language used for the logical form: Researchers have used SQL (Giordani and Moschitti, 2009), Prolog (Zelle and Mooney, 1996; Tang and Mooney, 2001), a simple functional query language called FunQL (Kate et al., 2005), and lambda calculus (Zettlemoyer and Collins, 2005), just to name a few. "
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17115955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f8a99790dd9124d528a718e55a0b27683685c77",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatically mapping natural language semantics into programming languages has always been a major and interesting challenge in Computer Science. In this paper, we approach such problem by carrying out mapping at syntactic level and then applying machine learning algorithms to derive an automatic translator of natural language questions into their associated SQL queries. To build the required training and test sets, we designed an algorithm, which, given an initial corpus of questions and their answers, semi-automatically generates the set of possible incorrect and correct pairs. \n \nWe encode such relational pairs in Support Vector Machines by means of kernel functions applied to the syntactic trees of questions and queries. The accurate results on automatic classification of the above pairs above, suggest that our approach captures the shared semantics between the two languages."
            },
            "slug": "Semantic-Mapping-between-Natural-Language-Questions-Giordani-Moschitti",
            "title": {
                "fragments": [],
                "text": "Semantic Mapping between Natural Language Questions and SQL Queries via Syntactic Pairing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper designs an algorithm, which, given an initial corpus of questions and their answers, semi-automatically generates the set of possible incorrect and correct pairs, and encodes such relational pairs in Support Vector Machines by means of kernel functions applied to the syntactic trees of Questions and queries."
            },
            "venue": {
                "fragments": [],
                "text": "NLDB"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15652489"
                        ],
                        "name": "T. Kwiatkowski",
                        "slug": "T.-Kwiatkowski",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Kwiatkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kwiatkowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1991315"
                        ],
                        "name": "S. Goldwater",
                        "slug": "S.-Goldwater",
                        "structuredName": {
                            "firstName": "Sharon",
                            "lastName": "Goldwater",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Goldwater"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145332819"
                        ],
                        "name": "Mark Steedman",
                        "slug": "Mark-Steedman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Steedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6228816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7a40c3ef180d847bb3db40fd01990e08a6264f7",
            "isKey": false,
            "numCitedBy": 318,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of learning to map sentences to logical form, given training data consisting of natural language sentences paired with logical representations of their meaning. Previous approaches have been designed for particular natural languages or specific meaning representations; here we present a more general method. The approach induces a probabilistic CCG grammar that represents the meaning of individual words and defines how these meanings can be combined to analyze complete sentences. We use higher-order unification to define a hypothesis space containing all grammars consistent with the training data, and develop an online learning algorithm that efficiently searches this space while simultaneously estimating the parameters of a log-linear parsing model. Experiments demonstrate high accuracy on benchmark data sets in four languages with two different meaning representations."
            },
            "slug": "Inducing-Probabilistic-CCG-Grammars-from-Logical-Kwiatkowski-Zettlemoyer",
            "title": {
                "fragments": [],
                "text": "Inducing Probabilistic CCG Grammars from Logical Form with Higher-Order Unification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper uses higher-order unification to define a hypothesis space containing all grammars consistent with the training data, and develops an online learning algorithm that efficiently searches this space while simultaneously estimating the parameters of a log-linear parsing model."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108641"
                        ],
                        "name": "Rohit J. Kate",
                        "slug": "Rohit-J.-Kate",
                        "structuredName": {
                            "firstName": "Rohit",
                            "lastName": "Kate",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rohit J. Kate"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8075439"
                        ],
                        "name": "Y. W. Wong",
                        "slug": "Y.-W.-Wong",
                        "structuredName": {
                            "firstName": "Yuk",
                            "lastName": "Wong",
                            "middleNames": [
                                "Wah"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. W. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7396224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8dd9fd6a45afd266d48255c398429e01ea4fd6db",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for inducing transformation rules that map natural-language sentences into a formal query or command language. The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non-terminal symbols in this grammar. The learned transformation rules incrementally map a natural-language sentence or its syntactic parse tree into a parse-tree for the target formal language. Experimental results are presented for two corpora. one which maps English instructions into an existing formal coaching language for simulated RoboCup soccer agents, and another which maps English U.S.-geography questions into a database query language. We show that our method performs overall better and faster than previous approaches in both domains."
            },
            "slug": "Learning-to-Transform-Natural-to-Formal-Languages-Kate-Wong",
            "title": {
                "fragments": [],
                "text": "Learning to Transform Natural to Formal Languages"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This paper presents a method for inducing transformation rules that map natural-language sentences into a formal query or command language and shows that this method performs overall better and faster than previous approaches in both domains."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 28
                            }
                        ],
                        "text": "Supervised semantic parsers (Zelle and Mooney, 1996; Tang and Mooney, 2001; Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Kate and Mooney, 2007; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Kwiatkowski et al., 2010) rely on manual annotation of logical forms, which is expensive."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 149
                            }
                        ],
                        "text": "These rules are often too stringent, and for complex utterances, especially in free wordorder languages, either disharmonic combinators are employed (Zettlemoyer and Collins, 2007) or words are given multiple lexical entries (Kwiatkowski et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12728987,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "774113732db34ce0b797fc3dcceded811fb6edbc",
            "isKey": false,
            "numCitedBy": 448,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning to parse sentences to lambda-calculus representations of their underlying semantics and present an algorithm that learns a weighted combinatory categorial grammar (CCG). A key idea is to introduce non-standard CCG combinators that relax certain parts of the grammar\u2014for example allowing flexible word order, or insertion of lexical items\u2014 with learned costs. We also present a new, online algorithm for inducing a weighted CCG. Results for the approach on ATIS data show 86% F-measure in recovering fully correct semantic analyses and 95.9% F-measure by a partial-match criterion, a more than 5% improvement over the 90.3% partial-match figure reported by He and Young (2006)."
            },
            "slug": "Online-Learning-of-Relaxed-CCG-Grammars-for-Parsing-Zettlemoyer-Collins",
            "title": {
                "fragments": [],
                "text": "Online Learning of Relaxed CCG Grammars for Parsing to Logical Form"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A key idea is to introduce non-standard CCG combinators that relax certain parts of the grammar\u2014for example allowing flexible word order, or insertion of lexical items\u2014 with learned costs."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759772"
                        ],
                        "name": "Hoifung Poon",
                        "slug": "Hoifung-Poon",
                        "structuredName": {
                            "firstName": "Hoifung",
                            "lastName": "Poon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hoifung Poon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 58
                            }
                        ],
                        "text": "On the other hand, existing unsupervised semantic parsers (Poon and Domingos, 2009) do not handle deeper linguistic phenomena such as quantification, negation, and superlatives."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5337047,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6df733a3274c55414629c5e90debef629631fcaa",
            "isKey": false,
            "numCitedBy": 294,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the first unsupervised approach to the problem of learning a semantic parser, using Markov logic. Our USP system transforms dependency trees into quasi-logical forms, recursively induces lambda forms from these, and clusters them to abstract away syntactic variations of the same meaning. The MAP semantic parse of a sentence is obtained by recursively assigning its parts to lambda-form clusters and composing them. We evaluate our approach by using it to extract a knowledge base from biomedical abstracts and answer questions. USP substantially outperforms TextRunner, DIRT and an informed baseline on both precision and recall on this task."
            },
            "slug": "Unsupervised-Semantic-Parsing-Poon",
            "title": {
                "fragments": [],
                "text": "Unsupervised Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work presents the first unsupervised approach to the problem of learning a semantic parser, using Markov logic, and substantially outperforms TextRunner, DIRT and an informed baseline on both precision and recall on this task."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15652489"
                        ],
                        "name": "T. Kwiatkowski",
                        "slug": "T.-Kwiatkowski",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Kwiatkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kwiatkowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1991315"
                        ],
                        "name": "S. Goldwater",
                        "slug": "S.-Goldwater",
                        "structuredName": {
                            "firstName": "Sharon",
                            "lastName": "Goldwater",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Goldwater"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145332819"
                        ],
                        "name": "Mark Steedman",
                        "slug": "Mark-Steedman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Steedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "KZGS11 (Kwiatkowski et al. 2011) extends KZGS10 by factoring lexical entries into a template plus a sequence of predicates that fill the slots of the template."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "To improve generalization, the lexicon can be further factorized (Kwiatkowski et al. 2011), but this is all done within the constraints of CCG."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Compactly representing a set of CCG lexical entries can also be done within the CCG framework by factoring lexical entries into a lexeme and a lexical template (Kwiatkowski et al. 2011)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8597719,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "36d69fec4884389c1709d3ca74394cac814ce4a4",
            "isKey": true,
            "numCitedBy": 218,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning factored probabilistic CCG grammars for semantic parsing from data containing sentences paired with logical-form meaning representations. Traditional CCG lexicons list lexical items that pair words and phrases with syntactic and semantic content. Such lexicons can be inefficient when words appear repeatedly with closely related lexical content. In this paper, we introduce factored lexicons, which include both lexemes to model word meaning and templates to model systematic variation in word usage. We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance benefits greatly from the lexical factoring."
            },
            "slug": "Lexical-Generalization-in-CCG-Grammar-Induction-for-Kwiatkowski-Zettlemoyer",
            "title": {
                "fragments": [],
                "text": "Lexical Generalization in CCG Grammar Induction for Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model, which includes both lexemes to model word meaning and templates to model systematic variation in word usage are presented."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879397"
                        ],
                        "name": "D. Warren",
                        "slug": "D.-Warren",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Warren",
                            "middleNames": [
                                "H.",
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Warren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "exacerbates the unpredictability ( Liang and Klein 2009 )."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2498523,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42abe494a940aecf215ddc64ddd8827f077567ec",
            "isKey": false,
            "numCitedBy": 300,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper gives an overall account of a prototype natural language question answering system, called Chat-80. Chat-80 has been designed to be both efficient and easily adaptable to a variety of applications. The system is implemented entirely in Prolog, a programming language based on logic. With the aid of a logic-based grammar formalism called extraposition grammars, Chat-80 translates English questions into the Prolog subset of logic. The resulting logical expression is then transformed by a planning algorithm into efficient Prolog, cf. \"query optimisation\" in a relational database. Finally, the Prolog form is executed to yield the answer. On a domain of world geography, most questions within the English subset are answered in well under one second, including relatively complex queries."
            },
            "slug": "An-Efficient-Easily-Adaptable-System-for-Natural-Warren-Pereira",
            "title": {
                "fragments": [],
                "text": "An Efficient Easily Adaptable System for Interpreting Natural Language Queries"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "This paper gives an overall account of a prototype natural language question answering system, called Chat-80, designed to be both efficient and easily adaptable to a variety of applications."
            },
            "venue": {
                "fragments": [],
                "text": "Am. J. Comput. Linguistics"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143844110"
                        ],
                        "name": "Wei Lu",
                        "slug": "Wei-Lu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789794"
                        ],
                        "name": "H. Ng",
                        "slug": "H.-Ng",
                        "structuredName": {
                            "firstName": "Hwee",
                            "lastName": "Ng",
                            "middleNames": [
                                "Tou"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740222"
                        ],
                        "name": "Wee Sun Lee",
                        "slug": "Wee-Sun-Lee",
                        "structuredName": {
                            "firstName": "Wee",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wee Sun Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "6 \u2013 LNLZ08 (Lu et al. 2008) 81."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "LNLZ08 (Lu et al. 2008) learns a generative model over hybrid trees, which are logical forms augmented with natural language words."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The construction mechanisms are equally diverse, including synchronous grammars (Wong and Mooney 2007), hybrid trees (Lu et al. 2008), Combinatory Categorial Grammars (CCG) (Zettlemoyer and Collins 2005), and shiftreduce derivations (Zelle and Mooney 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "as Montague\u2019s (1973) quantifying in, Cooper storage (Cooper 1975), and Carpenter\u2019s (1998) scoping constructor handle scope divergence during semantic interpretation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8045822,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d39d39a6246c13928bbd66d122f3e61e67b584ef",
            "isKey": true,
            "numCitedBy": 153,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an algorithm for learning a generative model of natural language sentences together with their formal meaning representations with hierarchical structures. The model is applied to the task of mapping sentences to hierarchical representations of their underlying meaning. We introduce dynamic programming techniques for efficient training and decoding. In experiments, we demonstrate that the model, when coupled with a discriminative reranking technique, achieves state-of-the-art performance when tested on two publicly available corpora. The generative model degrades robustly when presented with instances that are different from those seen in training. This allows a notable improvement in recall compared to previous models."
            },
            "slug": "A-Generative-Model-for-Parsing-Natural-Language-to-Lu-Ng",
            "title": {
                "fragments": [],
                "text": "A Generative Model for Parsing Natural Language to Meaning Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The generative model is applied to the task of mapping sentences to hierarchical representations of their underlying meaning and achieves state-of-the-art performance when tested on two publicly available corpora."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7901127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fc44ff7f37ec5585310666c183c65e0a0bb2446",
            "isKey": false,
            "numCitedBy": 2062,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes three statistical models for natural language parsing. The models extend methods from probabilistic context-free grammars to lexicalized grammars, leading to approaches in which a parse tree is represented as the sequence of decisions corresponding to a head-centered, top-down derivation of the tree. Independence assumptions then lead to parameters that encode the X-bar schema, subcategorization, ordering of complements, placement of adjuncts, bigram lexical dependencies, wh-movement, and preferences for close attachment. All of these preferences are expressed by probabilities conditioned on lexical heads. The models are evaluated on the Penn Wall Street Journal Treebank, showing that their accuracy is competitive with other models in the literature. To gain a better understanding of the models, we also give results on different constituent types, as well as a breakdown of precision/recall results in recovering various types of dependencies. We analyze various characteristics of the models through experiments on parsing accuracy, by collecting frequencies of various structures in the treebank, and through linguistically motivated examples. Finally, we compare the models to others that have been applied to parsing the treebank, aiming to give some explanation of the difference in performance of the various models."
            },
            "slug": "Head-Driven-Statistical-Models-for-Natural-Language-Collins",
            "title": {
                "fragments": [],
                "text": "Head-Driven Statistical Models for Natural Language Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "Three statistical models for natural language parsing are described, leading to approaches in which a parse tree is represented as the sequence of decisions corresponding to a head-centered, top-down derivation of the tree."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108641"
                        ],
                        "name": "Rohit J. Kate",
                        "slug": "Rohit-J.-Kate",
                        "structuredName": {
                            "firstName": "Rohit",
                            "lastName": "Kate",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rohit J. Kate"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 137
                            }
                        ],
                        "text": "Supervised semantic parsers (Zelle and Mooney, 1996; Tang and Mooney, 2001; Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Kate and Mooney, 2007; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Kwiatkowski et al., 2010) rely on manual annotation of logical forms, which is expensive."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7760740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee710964af56cdbe5f2d494343b06898cd3b87f1",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for learning a semantic parser from ambiguous supervision. Training data consists of natural language sentences annotated with multiple potential meaning representations, only one of which is correct. Such ambiguous supervision models the type of supervision that can be more naturally available to language-learning systems. Given such weak supervision, our approach produces a semantic parser that maps sentences into meaning representations. An existing semantic parsing learning system that can only learn from unambiguous supervision is augmented to handle ambiguous supervision. Experimental results show that the resulting system is able to cope up with ambiguities and learn accurate semantic parsers."
            },
            "slug": "Learning-Language-Semantics-from-Ambiguous-Kate-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning Language Semantics from Ambiguous Supervision"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This paper presents a method for learning a semantic parser from ambiguous supervision and shows that the resulting system is able to cope up with ambiguities and learn accurate semantic parsers."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6766605"
                        ],
                        "name": "S. Piantadosi",
                        "slug": "S.-Piantadosi",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Piantadosi",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Piantadosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144002017"
                        ],
                        "name": "Noah D. Goodman",
                        "slug": "Noah-D.-Goodman",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Goodman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noah D. Goodman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144952754"
                        ],
                        "name": "Benjamin A. Ellis",
                        "slug": "Benjamin-A.-Ellis",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Ellis",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin A. Ellis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080398744"
                        ],
                        "name": "benjelli ndg",
                        "slug": "benjelli-ndg",
                        "structuredName": {
                            "firstName": "benjelli",
                            "lastName": "ndg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "benjelli ndg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51998659"
                        ],
                        "name": "Jbt",
                        "slug": "Jbt",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Jbt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jbt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 694241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de935b5c35f2bac57fea852f92f538537c41ec67",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised, cross-situational Bayesian learning model for the acquisition of compositional semantics. We show that the model acquires the correct grammar for a toy version of English using a psychologically-plausible amount of data, over a wide range of possible learning environments. By assuming that speakers typically produce sentences which are true in the world, the model learns the semantic representation of content and function words, using only positive evidence in the form of sentences and world contexts. We argue that the model can adequately solve both the problem of referential uncertainty and the subset problem in this domain, and show that the model makes mistakes analogous to those made by children."
            },
            "slug": "A-Bayesian-Model-of-the-Acquisition-of-Semantics-Piantadosi-Goodman",
            "title": {
                "fragments": [],
                "text": "A Bayesian Model of the Acquisition of Compositional Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An unsupervised, cross-situational Bayesian learning model for the acquisition of compositional semantics is presented and it is argued that the model can adequately solve both the problem of referential uncertainty and the subset problem in this domain."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747648"
                        ],
                        "name": "William Schuler",
                        "slug": "William-Schuler",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Schuler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Schuler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 91
                            }
                        ],
                        "text": "Even for syntactic parsing, information from the denotation of an utterance can be helpful (Schuler, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 71
                            }
                        ],
                        "text": "Feedback from the world has been used to guide both syntactic parsing (Schuler, 2003) and semantic parsing (Popescu et al., 2003; Clarke et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6991244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d6105382ce0a1ddddeb401cea70aaf26e3c3493",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an extension of the semantic grammars used in conventional statistical spoken language interfaces to allow the probabilities of derived analyses to be conditioned on the meanings or denotations of input utterances in the context of an interface's underlying application environment or world model. Since these denotations will be used to guide disambiguation in interactive applications, they must be efficiently shared among the many possible analyses that may be assigned to an input utterance. This paper therefore presents a formal restriction on the scope of variables in a semantic grammar which guarantees that the denotations of all possible analyses of an input utterance can be calculated in polynomial time, without undue constraints on the expressivity of the derived semantics. Empirical tests show that this model-theoretic interpretation yields a statistically significant improvement on standard measures of parsing accuracy over a baseline grammar not conditioned on denotations."
            },
            "slug": "Using-Model-Theoretic-Semantic-Interpretation-to-in-Schuler",
            "title": {
                "fragments": [],
                "text": "Using Model-Theoretic Semantic Interpretation to Guide Statistical Parsing and Word Recognition in a Spoken Language Interface"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A formal restriction on the scope of variables in a semantic grammar is presented which guarantees that the denotations of all possible analyses of an input utterance can be calculated in polynomial time, without undue constraints on the expressivity of the derived semantics."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153642390"
                        ],
                        "name": "David L. Chen",
                        "slug": "David-L.-Chen",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David L. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ame of Civilization (Branavan et al., 2011), play a legal game of solitaire (Eisenstein et al., 2009; Goldwasser and Roth, 2011), and navigate a map by following directions (Vogel and Jurafsky, 2010; Chen and Mooney, 2011). Even when the objective in the world is dened independently of language (e.g., in Civilization), language can provide a useful bias towards the non-linguistic end goal. 5.4 Conclusions The main con"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215717032,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37fc406f739283d1f3738a872317b5ac2cc92362",
            "isKey": true,
            "numCitedBy": 456,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to understand natural-language instructions is critical to building intelligent agents that interact with humans. We present a system that learns to transform natural-language navigation instructions into executable formal plans. Given no prior linguistic knowledge, the system learns by simply observing how humans follow navigation instructions. The system is evaluated in three complex virtual indoor environments with numerous objects and landmarks. A previously collected realistic corpus of complex English navigation instructions for these environments is used for training and testing data. By using a learned lexicon to refine inferred plans and a supervised learner to induce a semantic parser, the system is able to automatically learn to correctly interpret a reasonable fraction of the complex instructions in this corpus."
            },
            "slug": "Learning-to-interpret-natural-language-navigation-Chen-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning to interpret natural language navigation instructions from observations"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A system that learns to transform natural-language navigation instructions into executable formal plans by using a learned lexicon to refine inferred plans and a supervised learner to induce a semantic parser."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108641"
                        ],
                        "name": "Rohit J. Kate",
                        "slug": "Rohit-J.-Kate",
                        "structuredName": {
                            "firstName": "Rohit",
                            "lastName": "Kate",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rohit J. Kate"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ew semantic representations and machine learning techniques (Zelle and Mooney, 1996; Miller et al., 1996; Tang and Mooney, 2001; Ge and Mooney, 2005; Kate et al., 2005; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2006; Kate and Mooney, 2007; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Kwiatkowski et al., 2010, 2011). However, while statistical methods provided advantages such as ro"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "1999) with semantic labels, so that syntactic and semantic parsing can be done jointly. Silt (Kate et al., 2005) learns a set of transformation rules for mapping utterances to logical forms. Krisp (Kate and Mooney, 2006) uses SVMs with string kernels to drive the local decisions of a chartbased semantic parser. Wasp (Wong and Mooney, 2006) uses log-linear synchronous grammars to transform utterances into logical for"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "r version of the code. 36 System LF Answer Cocktail (Tang and Mooney, 2001) 79.4 { Precise (Popescu et al., 2003) 77.5 77.5 Scissor (Ge and Mooney, 2005) 72.3 { Silt (Kate et al., 2005) 54.1 { Krisp (Kate and Mooney, 2006) 71.7 { Wasp (Wong and Mooney, 2006) 74.8 { -Wasp (Wong and Mooney, 2007) 86.6 { LNLZ08 (Lu et al., 2008) 81.8 { ZC05 (Zettlemoyer and Collins, 2005) 79.3 { ZC07 (Zettlemoyer and Collins, 2007) 86.1 "
                    },
                    "intents": []
                }
            ],
            "corpusId": 245587,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64a6439ed59e3c1dd54e778450f4758a59a2b0e0",
            "isKey": true,
            "numCitedBy": 270,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach for mapping natural language sentences to their formal meaning representations using string-kernel-based classifiers. Our system learns these classifiers for every production in the formal language grammar. Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these string classifiers. Our experiments on two real-world data sets show that this approach compares favorably to other existing systems and is particularly robust to noise."
            },
            "slug": "Using-String-Kernels-for-Learning-Semantic-Parsers-Kate-Mooney",
            "title": {
                "fragments": [],
                "text": "Using String-Kernels for Learning Semantic Parsers"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work presents a new approach for mapping natural language sentences to their formal meaning representations using string-kernel-based classifiers, which compares favorably to other existing systems and is particularly robust to noise."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36445704"
                        ],
                        "name": "Ana-Maria Popescu",
                        "slug": "Ana-Maria-Popescu",
                        "structuredName": {
                            "firstName": "Ana-Maria",
                            "lastName": "Popescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana-Maria Popescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690271"
                        ],
                        "name": "Henry A. Kautz",
                        "slug": "Henry-A.-Kautz",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Kautz",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Henry A. Kautz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 108
                            }
                        ],
                        "text": "Feedback from the world has been used to guide both syntactic parsing (Schuler, 2003) and semantic parsing (Popescu et al., 2003; Clarke et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9101619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b50f78c9534182a09c060580811274928702b38d",
            "isKey": false,
            "numCitedBy": 465,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The need for Natural Language Interfaces to databases (NLIs) has become increasingly acute as more and more people access information through their web browsers, PDAs, and cell phones. Yet NLIs are only usable if they map natural language questions to SQL queries correctly. As Schneiderman and Norman have argued, people are unwilling to trade reliable and predictable user interfaces for intelligent but unreliable ones. In this paper, we introduce a theoretical framework for reliable NLIs, which is the foundation for the fully implemented Precise NLI. We prove that, for a broad class of semantically tractable natural language questions, Precise is guaranteed to map each question to the corresponding SQL query. We report on experiments testing Precise on several hundred questions drawn from user studies over three benchmark databases. We find that over 80% of the questions are semantically tractable questions, which Precise answers correctly. Precise automatically recognizes the 20% of questions that it cannot handle, and requests a paraphrase. Finally, we show that Precise compares favorably with Mooney's learning NLI and with Microsoft's English Query product"
            },
            "slug": "Towards-a-theory-of-natural-language-interfaces-to-Popescu-Etzioni",
            "title": {
                "fragments": [],
                "text": "Towards a theory of natural language interfaces to databases"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proves that, for a broad class of semantically tractable natural language questions, Precise is guaranteed to map each question to the corresponding SQL query, and shows that Precise compares favorably with Mooney's learning NLI and with Microsoft's English Query product."
            },
            "venue": {
                "fragments": [],
                "text": "IUI '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387994164"
                        ],
                        "name": "Jason Baldridge",
                        "slug": "Jason-Baldridge",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Baldridge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Baldridge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708708"
                        ],
                        "name": "G. Kruijff",
                        "slug": "G.-Kruijff",
                        "structuredName": {
                            "firstName": "Geert-Jan",
                            "lastName": "Kruijff",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kruijff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 459113,
            "fieldsOfStudy": [
                "Philosophy",
                "Computer Science"
            ],
            "id": "8f9b34e29a3636ca05eb18ff58bf47d9a3517c82",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Categorial grammar has traditionally used the \u03bb-calculus to represent meaning. We present an alternative, dependency-based perspective on linguistic meaning and situate it in the computational setting. This perspective is formalized in terms of hybrid logic and has a rich yet perspicuous propositional ontology that enables a wide variety of semantic phenomena to be represented in a single meaning formalism. Finally, we show how we can couple this formalization to Combinatory Categorial Grammar to produce interpretations compositionally."
            },
            "slug": "Coupling-CCG-and-Hybrid-Logic-Dependency-Semantics-Baldridge-Kruijff",
            "title": {
                "fragments": [],
                "text": "Coupling CCG and Hybrid Logic Dependency Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An alternative, dependency-based perspective on linguistic meaning is presented and formalized in terms of hybrid logic and has a rich yet perspicuous propositional ontology that enables a wide variety of semantic phenomena to be represented in a single meaning formalism."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746013"
                        ],
                        "name": "R. Muskens",
                        "slug": "R.-Muskens",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Muskens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Muskens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 122
                            }
                        ],
                        "text": "Our mark-execute construct is analogous to Montague\u2019s quantifying in, Cooper storage, and Carpenter\u2019s scoping constructor (Carpenter, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 37254056,
            "fieldsOfStudy": [
                "Philosophy",
                "Linguistics"
            ],
            "id": "81e982e91ab1c307e001301948caeda47cad43e0",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Type-logical semantics studies linguistic meaning with the help of the theory of types. The latter originated with Russell as an answer to the paradoxes, but has the additional virtue that it is very close to ordinary language. In fact, type theory is so much more similar to language than predicate logic is, that adopting it as a vehicle of representation can overcome the mismatches between grammatical form and predicate logical form that were observed by Frege and Russell. The grammatical forms of ordinary language sentences consequently may be taken to be much less misleading than logicians in the first half of the 20th century often thought them to be. This was realized by Richard Montague, who used the theory of types to translate fragments of ordinary language into a logical language. Semantics is commonly divided into lexical semantics, which studies the meaning of words, and compositional semantics, which studies the way in which complex phrases obtain a meaning from their constituents. The strength of type-logical semantics lies with the latter, but type-logical theories can be combined with many competing hypotheses about lexical meaning, provided these hypotheses are expressed using the language of type theory."
            },
            "slug": "Type-logical-semantics-Muskens",
            "title": {
                "fragments": [],
                "text": "Type-logical semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Type-logical semantics studies linguistic meaning with the help of the theory of types, which has the additional virtue that it is very close to ordinary language, and can be combined with many competing hypotheses about lexical meaning, provided these hypotheses are expressed using the language of type theory."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3167681"
                        ],
                        "name": "Yoav Artzi",
                        "slug": "Yoav-Artzi",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Artzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Artzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Artzi and Zettlemoyer (2011) learns a semantic parser not from annotated logical forms, but from user interactions with a dialog system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "(2011); Artzi and Zettlemoyer (2011))."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In response to these concerns, researchers have recently begun to explore the possibility of learning a semantic parser without any annotated logical forms (Clarke et al., 2010; Liang et al., 2011; Goldwasser et al., 2011; Artzi and Zettlemoyer, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1140108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "508e5b724c8b841aecfae864e5d6dcd02eb28772",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Conversations provide rich opportunities for interactive, continuous learning. When something goes wrong, a system can ask for clarification, rewording, or otherwise redirect the interaction to achieve its goals. In this paper, we present an approach for using conversational interactions of this type to induce semantic parsers. We demonstrate learning without any explicit annotation of the meanings of user utterances. Instead, we model meaning with latent variables, and introduce a loss function to measure how well potential meanings match the conversation. This loss drives the overall learning approach, which induces a weighted CCG grammar that could be used to automatically bootstrap the semantic analysis component in a complete dialog system. Experiments on DARPA Communicator conversational logs demonstrate effective learning, despite requiring no explicit meaning annotations."
            },
            "slug": "Bootstrapping-Semantic-Parsers-from-Conversations-Artzi-Zettlemoyer",
            "title": {
                "fragments": [],
                "text": "Bootstrapping Semantic Parsers from Conversations"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper introduces a loss function to measure how well potential meanings match the conversation, and induces a weighted CCG grammar that could be used to automatically bootstrap the semantic analysis component in a complete dialog system."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190169"
                        ],
                        "name": "L. Tang",
                        "slug": "L.-Tang",
                        "structuredName": {
                            "firstName": "Lappoon",
                            "lastName": "Tang",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16100071,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f60d8dd8ca3a7dfa7d0a14988af73084ad93619d",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we explored a learning approach which combines different learning methods in inductive logic programming (ILP) to allow a learner to produce more expressive hypotheses than that of each individual learner. Such a learning approach may be useful when the performance of the task depends on solving a large amount of classification problems and each has its own characteristics which may or may not fit a particular learning method. The task of semantic parser acquisition in two different domains was attempted and preliminary results demonstrated that such an approach is promising."
            },
            "slug": "Using-Multiple-Clause-Constructors-in-Inductive-for-Tang-Mooney",
            "title": {
                "fragments": [],
                "text": "Using Multiple Clause Constructors in Inductive Logic Programming for Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "Preliminary results demonstrated that an approach which combines different learning methods in inductive logic programming (ILP) to allow a learner to produce more expressive hypotheses than that of each individual learner is promising."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8075439"
                        ],
                        "name": "Y. W. Wong",
                        "slug": "Y.-W.-Wong",
                        "structuredName": {
                            "firstName": "Yuk",
                            "lastName": "Wong",
                            "middleNames": [
                                "Wah"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. W. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 9
                            }
                        ],
                        "text": "\u2022 \u03bb-Wasp (Wong and Mooney, 2007) extends Wasp to work with logical forms that contain bound variables (lambda abstraction)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 182
                            }
                        ],
                        "text": "Supervised semantic parsers (Zelle and Mooney, 1996; Tang and Mooney, 2001; Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Kate and Mooney, 2007; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Kwiatkowski et al., 2010) rely on manual annotation of logical forms, which is expensive."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 467,
                                "start": 173
                            }
                        ],
                        "text": "Since then, there has been a healthy line of work yielding increasingly more accurate semantic parsers by using new semantic representations and machine learning techniques (Zelle and Mooney, 1996; Miller et al., 1996; Tang and Mooney, 2001; Ge and Mooney, 2005; Kate et al., 2005; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2006; Kate and Mooney, 2007; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Kwiatkowski et al., 2010, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 80
                            }
                        ],
                        "text": "The construction mechanisms are equally diverse, including synchronous grammars (Wong and Mooney, 2007), hybrid trees (Lu et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9337134,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2ecc66c0e5f976b0e0d95c64ed2d1e283a2625d",
            "isKey": true,
            "numCitedBy": 354,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the first empirical results to our knowledge on learning synchronous grammars that generate logical forms. Using statistical machine translation techniques, a semantic parser based on a synchronous context-free grammar augmented with \ufffdoperators is learned given a set of training sentences and their correct logical forms. The resulting parser is shown to be the bestperforming system so far in a database query domain."
            },
            "slug": "Learning-Synchronous-Grammars-for-Semantic-Parsing-Wong-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning Synchronous Grammars for Semantic Parsing with Lambda Calculus"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A semantic parser based on a synchronous context-free grammar augmented with \ufffdoperators is learned given a set of training sentences and their correct logical forms, and is shown to be the bestperforming system so far in a database query domain."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144955737"
                        ],
                        "name": "J. Judge",
                        "slug": "J.-Judge",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Judge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Judge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145557710"
                        ],
                        "name": "A. Cahill",
                        "slug": "A.-Cahill",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Cahill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cahill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7519068"
                        ],
                        "name": "Josef van Genabith",
                        "slug": "Josef-van-Genabith",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "van Genabith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef van Genabith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 34
                            }
                        ],
                        "text": ", 1993) and the Question Treebank (Judge et al., 2006)\u2014thanks to Slav Petrov for providing the trained grammar."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8317576,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "956d4b97f5814dd9e53abf286cc8cfe1283a01eb",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the development of QuestionBank, a corpus of 4000 parse-annotated questions for (i) use in training parsers employed in QA, and (ii) evaluation of question parsing. We present a series of experiments to investigate the effectiveness of QuestionBank as both an exclusive and supplementary training resource for a state-of-the-art parser in parsing both question and non-question test sets. We introduce a new method for recovering empty nodes and their antecedents (capturing long distance dependencies) from parser output in CFG trees using LFG f-structure reentrancies. Our main findings are (i) using QuestionBank training data improves parser performance to 89.75% labelled bracketing f-score, an increase of almost 11% over the baseline; (ii) back-testing experiments on non-question data (Penn-II WSJ Section 23) shows that the retrained parser does not suffer a performance drop on non-question material; (iii) ablation experiments show that the size of training material provided by QuestionBank is sufficient to achieve optimal results; (iv) our method for recovering empty nodes captures long distance dependencies in questions from the ATIS corpus with high precision (96.82%) and low recall (39.38%). In summary, QuestionBank provides a useful new resource in parser-based QA research."
            },
            "slug": "QuestionBank:-Creating-a-Corpus-of-Parse-Annotated-Judge-Cahill",
            "title": {
                "fragments": [],
                "text": "QuestionBank: Creating a Corpus of Parse-Annotated Questions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Using QuestionBank training data improves parser performance to 89.75% labelled bracketing f-score, and a new method for recovering empty nodes and their antecedents (capturing long distance dependencies) from parser output in CFG trees using LFG f-structure reentrancies is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154709"
                        ],
                        "name": "Jacob Eisenstein",
                        "slug": "Jacob-Eisenstein",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Eisenstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacob Eisenstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50649676"
                        ],
                        "name": "J. Clarke",
                        "slug": "J.-Clarke",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Clarke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Clarke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2877164"
                        ],
                        "name": "Dan Goldwasser",
                        "slug": "Dan-Goldwasser",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Goldwasser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Goldwasser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 0
                            }
                        ],
                        "text": "Eisenstein et al. (2009) induces conjunctive formulae and uses them as features in another learning problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 146
                            }
                        ],
                        "text": "2009; Branavan, Zettlemoyer, and Barzilay 2010), win a game of Civilization (Branavan, Silver, and Barzilay 2011), play a legal game of solitaire (Eisenstein et al. 2009; Goldwasser and Roth 2011), and navigate a map by following directions (Vogel and Jurafsky 2010; Chen and Mooney 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1174836,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "17b109bb35936845c74e9af31718e2fa2406beba",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine learning offers a range of tools for training systems from data, but these methods are only as good as the underlying representation. This paper proposes to acquire representations for machine learning by reading text written to accommodate human learning. We propose a novel form of semantic analysis called reading to learn, where the goal is to obtain a high-level semantic abstract of multiple documents in a representation that facilitates learning. We obtain this abstract through a generative model that requires no labeled data, instead leveraging repetition across multiple documents. The semantic abstract is converted into a transformed feature space for learning, resulting in improved generalization on a relational learning task."
            },
            "slug": "Reading-to-Learn:-Constructing-Features-from-Eisenstein-Clarke",
            "title": {
                "fragments": [],
                "text": "Reading to Learn: Constructing Features from Semantic Abstracts"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper proposes a novel form of semantic analysis called reading to learn, where the goal is to obtain a high-level semantic abstract of multiple documents in a representation that facilitates learning."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754497"
                        ],
                        "name": "Slav Petrov",
                        "slug": "Slav-Petrov",
                        "structuredName": {
                            "firstName": "Slav",
                            "lastName": "Petrov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Slav Petrov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37157794"
                        ],
                        "name": "Leon Barrett",
                        "slug": "Leon-Barrett",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Barrett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leon Barrett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3323298"
                        ],
                        "name": "R. Thibaux",
                        "slug": "R.-Thibaux",
                        "structuredName": {
                            "firstName": "Romain",
                            "lastName": "Thibaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Thibaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 54
                            }
                        ],
                        "text": "1 To perform POS tagging, we used the Berkeley Parser (Petrov et al., 2006), trained on the WSJ Treebank (Marcus et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 30
                            }
                        ],
                        "text": "3We used the Berkeley Parser (Petrov et al., 2006) to perform POS tagging."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6684426,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f52de7242e574b70410ca6fb70b79c811919fc00",
            "isKey": false,
            "numCitedBy": 965,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank. Starting with a simple X-bar grammar, we learn a new grammar whose nonterminals are subsymbols of the original nonterminals. In contrast with previous work, we are able to split various terminals to different degrees, as appropriate to the actual complexity in the data. Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation. On the other hand, our grammars are much more compact and substantially more accurate than previous work on automatic annotation. Despite its simplicity, our best grammar achieves an F1 of 90.2% on the Penn Treebank, higher than fully lexicalized systems."
            },
            "slug": "Learning-Accurate,-Compact,-and-Interpretable-Tree-Petrov-Barrett",
            "title": {
                "fragments": [],
                "text": "Learning Accurate, Compact, and Interpretable Tree Annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2877164"
                        ],
                        "name": "Dan Goldwasser",
                        "slug": "Dan-Goldwasser",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Goldwasser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Goldwasser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ned to interpret language to troubleshoot a Windows machine (Branavan et al., 2009, 2010), win a game of Civilization (Branavan et al., 2011), play a legal game of solitaire (Eisenstein et al., 2009; Goldwasser and Roth, 2011), and navigate a map by following directions (Vogel and Jurafsky, 2010; Chen and Mooney, 2011). Even when the objective in the world is dened independently of language (e.g., in Civilization), langua"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11068497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1699e5c56f9fa8e34b2b5b8fdbca4bb74cee0ca3",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine learning is traditionally formalized and investigated as the study of learning concepts and decision functions from labeled examples, requiring a representation that encodes information about the domain of the decision function to be learned. We are interested in providing a way for a human teacher to interact with an automated learner using natural instructions, thus allowing the teacher to communicate the relevant domain expertise to the learner without necessarily knowing anything about the internal representations used in the learning process.In this paper we suggest to view the process of learning a decision function as a natural language lesson interpretation problem, as opposed to learning from labeled examples. This view of machine learning is motivated by human learning processes, in which the learner is given a lesson describing the target concept directly and a few instances exemplifying it. We introduce a learning algorithm for the lesson interpretation problem that receives feedback from its performance on the final task, while learning jointly (1) how to interpret the lesson and (2) how to use this interpretation to do well on the final task. traditional machine learning by focusing on supplying the learner only with information that can be provided by a task expert.We evaluate our approach by applying it to the rules of the solitaire card game. We show that our learning approach can eventually use natural language instructions to learn the target concept and play the game legally. Furthermore, we show that the learned semantic interpreter also generalizes to previously unseen instructions."
            },
            "slug": "Learning-from-natural-instructions-Goldwasser-Roth",
            "title": {
                "fragments": [],
                "text": "Learning from natural instructions"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The process of learning a decision function as a natural language lesson interpretation problem, as opposed to learning from labeled examples, is suggested to view."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46926166"
                        ],
                        "name": "C. Barker",
                        "slug": "C.-Barker",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Barker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Barker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Continuation, from programming languages, is another solution (Barker 2002; Shan 2004); this sets the semantics of a quantifier to be a function from its continuation (which captures all the semantic content of the clause minus the quantifier) to the final denotation of the clause."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118870676,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "d9811cddbd8d4244f6090d2e8f45cddd147f2efb",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes that the meanings of some natural language expressions should be thought of as functions on their own continuations. Continuations are a well-established analytic tool in the theory of programming language semantics; in brief, a continuation is the entire default future of a computation. I show how a continuation-based grammar can unify several aspects of natural language quantification in a new way: merely stating the truth conditions for quantificational expressions in terms of continuations automatically accounts for scope displacement and scope ambiguity. To prove this claim, I exhibit a simple finite context-free grammar with a strictly compositional semantics in which quantificational NPs are interpreted in situ but take semantic scope over larger constituents. There is no Quantifier Raising (nor any use of a level of Logical Form distinct from overt syntax), no Cooper Storage (or similar mechanisms used in many recent HPSG, Categorial, or Type-logical treatments), and no need for type-shifting (as in Hendriks' Flexible Types account). Continuations also provide a natural account of generalized coordination that does not require either type-shifting or type polymorphism. Compositionality issues are discussed in some detail."
            },
            "slug": "Continuations-and-the-Nature-of-Quantification-Barker",
            "title": {
                "fragments": [],
                "text": "Continuations and the Nature of Quantification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2877164"
                        ],
                        "name": "Dan Goldwasser",
                        "slug": "Dan-Goldwasser",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Goldwasser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Goldwasser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762757"
                        ],
                        "name": "Roi Reichart",
                        "slug": "Roi-Reichart",
                        "structuredName": {
                            "firstName": "Roi",
                            "lastName": "Reichart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roi Reichart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50649676"
                        ],
                        "name": "J. Clarke",
                        "slug": "J.-Clarke",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Clarke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Clarke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "required for various semantics-related tasks (Zettlemoyer and Collins 2005; Branavan et al. 2009; Liang, Jordan, and Klein 2009; Clarke et al. 2010; Artzi and Zettlemoyer 2011; Goldwasser et al. 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Other researchers have also pushed in this direction in various ways: learning a semantic parser based on bootstrapping and estimating the confidence of its own predictions (Goldwasser et al. 2011), learning a semantic parser from user interactions with a dialog system (Artzi and Zettlemoyer 2011), and learning to execute natural language instructions from just a reward signal using reinforcement learning (Branavan et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9111381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7add86884b03ded456bd0fd09fa28030f3d64d9",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Current approaches for semantic parsing take a supervised approach requiring a considerable amount of training data which is expensive and difficult to obtain. This supervision bottleneck is one of the major difficulties in scaling up semantic parsing. \n \nWe argue that a semantic parser can be trained effectively without annotated data, and introduce an unsupervised learning algorithm. The algorithm takes a self training approach driven by confidence estimation. Evaluated over Geoquery, a standard dataset for this task, our system achieved 66% accuracy, compared to 80% of its fully supervised counterpart, demonstrating the promise of unsupervised approaches for this task."
            },
            "slug": "Confidence-Driven-Unsupervised-Semantic-Parsing-Goldwasser-Reichart",
            "title": {
                "fragments": [],
                "text": "Confidence Driven Unsupervised Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is argued that a semantic parser can be trained effectively without annotated data, and an unsupervised learning algorithm is introduced, which takes a self training approach driven by confidence estimation."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3461596"
                        ],
                        "name": "Johan Bos",
                        "slug": "Johan-Bos",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Bos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johan Bos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523372"
                        ],
                        "name": "S. Clark",
                        "slug": "S.-Clark",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145332819"
                        ],
                        "name": "Mark Steedman",
                        "slug": "Mark-Steedman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Steedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733593"
                        ],
                        "name": "J. Curran",
                        "slug": "J.-Curran",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Curran",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Curran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3118681"
                        ],
                        "name": "J. Hockenmaier",
                        "slug": "J.-Hockenmaier",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hockenmaier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hockenmaier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9317139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c7a1d0b183d0db47a438299d023684491461eac",
            "isKey": false,
            "numCitedBy": 260,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows how to construct semantic representations from the derivations produced by a wide-coverage CCG parser. Unlike the dependency structures returned by the parser itself, these can be used directly for semantic interpretation. We demonstrate that well-formed semantic representations can be produced for over 97% of the sentences in unseen WSJ text. We believe this is a major step towards widecoverage semantic interpretation, one of the key objectives of the field of NLP."
            },
            "slug": "Wide-Coverage-Semantic-Representations-from-a-CCG-Bos-Clark",
            "title": {
                "fragments": [],
                "text": "Wide-Coverage Semantic Representations from a CCG Parser"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is demonstrated that well-formed semantic representations can be produced for over 97% of the sentences in unseen WSJ text, a major step towards widecoverage semantic interpretation, one of the key objectives of the field of NLP."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3461596"
                        ],
                        "name": "Johan Bos",
                        "slug": "Johan-Bos",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Bos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johan Bos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 54
                            }
                        ],
                        "text": "The restriction to trees is similar to economical DRT (Bos, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 94
                            }
                        ],
                        "text": "The idea of using CSPs to represent semantics is inspired by Discourse Representation Theory (DRT) (Kamp and Reyle, 1993; Kamp et al., 2005), where variables are discourse referents."
                    },
                    "intents": []
                }
            ],
            "corpusId": 876026,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "07d7cc2e6689526de2894ab1553e5ba1cb00d7ae",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "First-order logic (FOL) is undecidable \u2014 that is, no algorithm exists that can decide whether a formula of FOL is valid or not. However, there are various fragments of FOL that are known to be decidable. FO, the two-variable fragment of FOL, is one of such languages [1, 2]. FO is a first-order language where formulas have maximally two variables, no function symbols, but possibly do have equality. FO has the finite model property [1], which means that if a formula of FO is satisfiable, it is satisfiable in a finite model. In this paper we propose a controlled fragment of Discourse Representation Theory (DRT, [3]) with a semantics formalised on the basis of the two-variable fragment with equality. DRT encapsulates the idea of text interpretation that \u201cone and the same structure serves simultaneously as content and context\u201d [4], where content refers to the semantic interpretation of sentences already processed, and context serves in aiding the interpretation of anaphoric expressions in subsequent sentences. However, providing a two-variable natural language fragment is, in itself, not a new idea. In fact, the framework presented here is very much inspired by Ian Pratt-Hartmann\u2019s language E2V [5]. But as Pratt-Hartmann himself notes, E2V is \u201ccertainly not proposed as a useful controlled language\u201d. Our aim is to try to find out how useful a controlled language based on the two-variable fragment actually can be, mostly from a computational linguistic point of view. We will do this by:"
            },
            "slug": "A-Controlled-Fragment-of-DRT-Bos",
            "title": {
                "fragments": [],
                "text": "A Controlled Fragment of DRT"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper proposes a controlled fragment of Discourse Representation Theory (DRT) with a semantics formalised on the basis of the two-variable fragment with equality, and aims to find out how useful a controlled language based on theTwo- variable fragment actually can be, mostly from a computational linguistic point of view."
            },
            "venue": {
                "fragments": [],
                "text": "CNL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752430"
                        ],
                        "name": "Ion Androutsopoulos",
                        "slug": "Ion-Androutsopoulos",
                        "structuredName": {
                            "firstName": "Ion",
                            "lastName": "Androutsopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ion Androutsopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34739267"
                        ],
                        "name": "G. Ritchie",
                        "slug": "G.-Ritchie",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Ritchie",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ritchie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798843"
                        ],
                        "name": "P. Thanisch",
                        "slug": "P.-Thanisch",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Thanisch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Thanisch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "nterfaces to databases (NLIDBs) has a long history in NLP, starting from the early days of AI with systems such as Lunar (Woods et al., 1972), Chat-80 (Warren and Pereira, 1982), and many others (see Androutsopoulos et al. (1995) for an overview). While quite successful in their respective limited domains, because these systems were constructed from manually-built rules, they became dicult to scale up, both to other domains "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3033151,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1df699c7da1b948bffd449ac44809017ee4206e0",
            "isKey": false,
            "numCitedBy": 815,
            "numCiting": 149,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is an introduction to natural language interfaces to databases (NLIDBS). A brief overview of the history of NLIDBS is first given. Some advantages and disadvantages of NLIDBS are then discussed, comparing NLIDBS to formal query languages, form-based interfaces, and graphical interfaces. An introduction to some of the linguistic problems NLIDBS have to confront follows, for the benefit of readers less familiar with computational linguistics. The discussion then moves on to NLIDB architectures, portability issues, restricted natural language input systems (including menu-based NLIDBS), and NLIDBS with reasoning capabilities. Some less explored areas of NLIDB research are then presented, namely database updates, meta-knowledge questions, temporal questions, and multi-modal NLIDBS. The paper ends with reflections on the current state of the art."
            },
            "slug": "Natural-language-interfaces-to-databases-an-Androutsopoulos-Ritchie",
            "title": {
                "fragments": [],
                "text": "Natural language interfaces to databases - an introduction"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This paper is an introduction to natural language interfaces to databases (NLIDBS) and some less explored areas of NLIDB research are presented, namely database updates, meta-knowledge questions, temporal questions, and multi-modal NLIDBS."
            },
            "venue": {
                "fragments": [],
                "text": "Nat. Lang. Eng."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3026041"
                        ],
                        "name": "Daniel Bonevac",
                        "slug": "Daniel-Bonevac",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Bonevac",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Bonevac"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 83
                            }
                        ],
                        "text": "Supervised semantic parsers (Zelle and Mooney, 1996; Tang and Mooney, 2001; Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Kate and Mooney, 2007; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Kwiatkowski et al., 2010) rely on manual annotation of logical forms, which is expensive."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 373015,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "c4f4802b752e22c1dd911b6c3a80d1439a1ce432",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Fourteenth-century logicians such as Burley and Buridan note that quantifiers not only express relations between terms but also introduce items in discourse that can be referred to anaphorically. The problem this raises is not one of truth conditions, as we have seen\u2014it is not difficult to give first-order representations of sentences such as \u2018an animal is running and it is a man\u2019 or \u2018Every farmer who owns a donkey beats it\u2019\u2014 but rather of compositionality. The problem, in other words, is typically not a lack of appropriate truth conditions but a rule-governed way of generating them. In Aristotelian logic, we can represent \u2018an animal is running\u2019 as \u2018Some A is R,\u2019 but we then have no way of indicating that the running animal is a man. Appending another categorical proposition will not help. In first-order logic, similarly, we can represent \u2018an animal is running\u2019 as \u2203x(Ax \u2227 Rx). Having done that, however, we have no way of adding another formula representing that the x in question is a man. What we have to do in both cases is extend the original representation, writing \u2018Some A is R and M\u2019 or \u2203x(Ax \u2227 Rx \u2227 Mx). Since the anaphora occurs within the same sentence, we could perhaps write rules requiring this. But similar anaphora can occur across sentential boundaries. Buridan\u2019s example could just as easily have been \u2018an animal is running. It is a man.\u2019 These could moreover be separated by intervening discourse: \u2018an animal is running. People look on in surprise. It is uncommon to see such a sight in the square, amidst the crowds, in the midday heat. It is a man.\u2019 This makes a strategy of waiting to close off the representation of the first sentence until all later anaphors have been collected implausible. Sometimes, the problem is a lack of appropriate truth conditions. Consider this discourse:"
            },
            "slug": "Discourse-Representation-Theory-Bonevac",
            "title": {
                "fragments": [],
                "text": "Discourse Representation Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9817314"
                        ],
                        "name": "I. Heim",
                        "slug": "I.-Heim",
                        "structuredName": {
                            "firstName": "Irene",
                            "lastName": "Heim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Heim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2824542"
                        ],
                        "name": "A. Kratzer",
                        "slug": "A.-Kratzer",
                        "structuredName": {
                            "firstName": "Angelika",
                            "lastName": "Kratzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kratzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 57341324,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "0dc0d0cfebc2ea1f88c64a159a76d0cb8258bff9",
            "isKey": false,
            "numCitedBy": 2585,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface. 1. Truth-conditional Semantics and the Fregean Program. 2. Executing the Fregean Program. 3. Semantics and Syntax. 4. More of English: Non-verbal Predicates, Modifiers, Definite Descriptions. 5. Relative Clauses, Variables, Variable Binding. 6. Quantifiers: Their Semantic Type. 7. Quantification and Grammar. 8. Syntactic and Semantic Constraints on Quantifier Movement. 9. Bound and Referential Pronouns and Ellipsis. 10. Syntactic and Semantic Binding. 11. E-Type Anaphora. 12. First Steps Towards an Intensional Semantics. Index."
            },
            "slug": "Semantics-in-generative-grammar-Heim-Kratzer",
            "title": {
                "fragments": [],
                "text": "Semantics in generative grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This chapter discusses truth-conditional Semantics and the Fregean Program, and first steps towards an Intensional Semantics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075292388"
                        ],
                        "name": "P. Liang",
                        "slug": "P.-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 238873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3051b3e18eee9c498a2e94d0811d1a3551e64e4",
            "isKey": false,
            "numCitedBy": 291,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A central problem in grounded language acquisition is learning the correspondences between a rich world state and a stream of text which references that world state. To deal with the high degree of ambiguity present in this setting, we present a generative model that simultaneously segments the text into utterances and maps each utterance to a meaning representation grounded in the world state. We show that our model generalizes across three domains of increasing difficulty---Robocup sportscasting, weather forecasts (a new domain), and NFL recaps."
            },
            "slug": "Learning-Semantic-Correspondences-with-Less-Liang-Jordan",
            "title": {
                "fragments": [],
                "text": "Learning Semantic Correspondences with Less Supervision"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A generative model is presented that simultaneously segments the text into utterances and maps each utterance to a meaning representation grounded in the world state and generalizes across three domains of increasing difficulty."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110271578"
                        ],
                        "name": "Scott Miller",
                        "slug": "Scott-Miller",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145482266"
                        ],
                        "name": "D. Stallard",
                        "slug": "D.-Stallard",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stallard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stallard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2189985"
                        ],
                        "name": "R. Bobrow",
                        "slug": "R.-Bobrow",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bobrow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bobrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 467,
                                "start": 173
                            }
                        ],
                        "text": "Since then, there has been a healthy line of work yielding increasingly more accurate semantic parsers by using new semantic representations and machine learning techniques (Zelle and Mooney, 1996; Miller et al., 1996; Tang and Mooney, 2001; Ge and Mooney, 2005; Kate et al., 2005; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2006; Kate and Mooney, 2007; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Kwiatkowski et al., 2010, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10983275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9c1f510bcf5933d3cf8ec8108a04a9ba601a843",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a natural language interface system which is based entirely on trained statistical models. The system consists of three stages of processing: parsing, semantic interpretation, and discourse. Each of these stages is modeled as a statistical process. The models are fully integrated, resulting in an end-to-end system that maps input utterances into meaning representation frames."
            },
            "slug": "A-Fully-Statistical-Approach-to-Natural-Language-Miller-Stallard",
            "title": {
                "fragments": [],
                "text": "A Fully Statistical Approach to Natural Language Interfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This work presents a natural language interface system which is based entirely on trained statistical models, resulting in an end-to-end system that maps input utterances into meaning representation frames."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145663546"
                        ],
                        "name": "Chung-chieh Shan",
                        "slug": "Chung-chieh-Shan",
                        "structuredName": {
                            "firstName": "Chung-chieh",
                            "lastName": "Shan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung-chieh Shan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 412,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0553a8df9b127e1b2031e94415d9a2788fdb3d5",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Making a linguistic theory is like making a programming language: one typically devises a type system to delineate the acceptable utterances and a denotational semantics to explain observations on their behavior. Via this connection, the programming language concept of delimited continuations can help analyze natural language phenomena such as quantification and polarity sensitivity. Using a logical metalanguage whose syntax includes control operators and whose semantics involves evaluation order, these analyses can be expressed in direct style rather than continuation-passing style, and these phenomena can be thought of as computational side effects."
            },
            "slug": "Delimited-continuations-in-natural-language:-and-Shan",
            "title": {
                "fragments": [],
                "text": "Delimited continuations in natural language: quantification and polarity sensitivity"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The programming language concept of delimited continuations can help analyze natural language phenomena such as quantification and polarity sensitivity using a logical metalanguage whose syntax includes control operators and whose semantics involves evaluation order."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48312837"
                        ],
                        "name": "Michael White",
                        "slug": "Michael-White",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "White",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael White"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We might be able to incorporate some ideas from Hybrid Logic Dependency Semantics (Baldridge and Kruijff 2002; White 2006), given that hybrid logic extends the tree structures of modal logic with nominals, thereby allowing a node to freely reference other nodes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1130644,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c1775c992847f31a9bda931a1ecb8cac5365367",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a chart realization algorithm for Combinatory Categorial Grammar (CCG), and show how it can be used to efficiently realize a wide range of coordination phenomena, including argument cluster coordination and gapping. The algorithm incorporates three novel methods for improving the efficiency of chart realization: (i) using rules to chunk the input logical form into sub-problems to be solved independently prior to further combination; (ii) pruning edges from the chart based on the n-gram score of the edge\u2019s string, in comparison to other edges with equivalent categories; and (iii) formulating the search as a best-first anytime algorithm, using n-gram scores to sort the edges on the agenda. The algorithm has been implemented as an extension to the OpenCCG open source CCG parser, and initial performance tests indicate that the realizer is fast enough for practical use in natural language dialogue systems."
            },
            "slug": "Efficient-Realization-of-Coordinate-Structures-in-White",
            "title": {
                "fragments": [],
                "text": "Efficient Realization of Coordinate Structures in Combinatory Categorial Grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A chart realization algorithm for Combinatory Categorial Grammar (CCG) is described, and it is shown how it can be used to efficiently realize a wide range of coordination phenomena, including argument cluster coordination and gapping."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145938212"
                        ],
                        "name": "H. Kamp",
                        "slug": "H.-Kamp",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Kamp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kamp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750946"
                        ],
                        "name": "Uwe Reyle",
                        "slug": "Uwe-Reyle",
                        "structuredName": {
                            "firstName": "Uwe",
                            "lastName": "Reyle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uwe Reyle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "The restriction to trees is similar to economical DRT (Bos, 2009)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 100
                            }
                        ],
                        "text": "The idea of using CSPs to represent semantics is inspired by Discourse Representation Theory (DRT) (Kamp and Reyle, 1993; Kamp et al., 2005), where variables are discourse referents."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 45807661,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "d9dc7d27ad31e977dec4f703bc75f699ae456f76",
            "isKey": false,
            "numCitedBy": 1396,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface. 0: Preliminaries. 0.1. Theories of Meaning. 0.2. Logic. 0.3. Logic and Semantics. 0.4. Syntax. 1: DRT and Predicate Logic. 1.1. Simple Sentences. 1.2. Models. 1.3. Negation. 1.4. Verification, Truth and Accessibility. 1.5. From DRT to Predicate Logic. 2: Quantification and Connectives. 2.1. Conditionals. 2.2. Universal Quantification. 2.3. Disjunction. 2.4. Conjunction. 3: Loose Ends. 3.1. Reflexives. 3.2. Possessive Noun Phrases. 3.3. Proper Names. 3.4. Definite Descriptions. 3.5. Stipulated Identity and Asserted Identity. 3.6. Identity and Predication. 3.7. Scope Amibiguity. 4: The Plural. 4.1. Introduction. 4.2. DRS-Construction for Plurals I. 4.3. Model Theory. 4.4. DRS-Construction for Plurals II. 5: Tense and Aspect. 5.1. The Semantics and Logic of Temporal Reference. 5.2. DRS-Construction for Tensed Sentences. 5.3. Aspect. 5.4. Temporal Perspective. 5.5. Temporal Adverbials. 5.6. Model Theory. 5.7. Syntactic Rules. Bibliography. Table of Construction Rules. Index of Symbols, Features and Feature Values. Index of Names. Index of Subjects."
            },
            "slug": "From-Discourse-to-Logic-Introduction-to-Semantics-Kamp-Reyle",
            "title": {
                "fragments": [],
                "text": "From Discourse to Logic - Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This chapter discusses DRS-Construction for Plurals I, the Semantics and Logic of Temporal Reference, and model theory, which aims to explain the construction of these sentences and its application in the context of a discrete-time model."
            },
            "venue": {
                "fragments": [],
                "text": "Studies in linguistics and philosophy"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144162125"
                        ],
                        "name": "J. Langford",
                        "slug": "J.-Langford",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Langford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Langford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "round 97%. 39 In our algorithm, learning and search are deeply intertwined. Search is of course needed to learn, but learning also improves search. The general approach is similar in spirit to Searn (Daume et al., 2009), although we do not have any formal guarantees at this point. Our algorithm also has a bootstrapping avor. The \\easy&quot; examples are processed rst, where easy is dened by the ability of beam sear"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 704519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c9d9f3c6f7508f4e29730924529dc993c27cddc",
            "isKey": false,
            "numCitedBy": 570,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "We present Searn, an algorithm for integrating search and learning to solve complex structured prediction problems such as those that occur in natural language, speech, computational biology, and vision. Searn is a meta-algorithm that transforms these complex problems into simple classification problems to which any binary classifier may be applied. Unlike current algorithms for structured learning that require decomposition of both the loss function and the feature functions over the predicted structure, Searn is able to learn prediction functions for any loss function and any class of features. Moreover, Searn comes with a strong, natural theoretical guarantee: good performance on the derived classification problems implies good performance on the structured prediction problem."
            },
            "slug": "Search-based-structured-prediction-Daum\u00e9-Langford",
            "title": {
                "fragments": [],
                "text": "Search-based structured prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "Searn is an algorithm for integrating search and learning to solve complex structured prediction problems such as those that occur in natural language, speech, computational biology, and vision and comes with a strong, natural theoretical guarantee: good performance on the derived classification problems implies goodperformance on the structured prediction problem."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424234"
                        ],
                        "name": "Beatrice Santorini",
                        "slug": "Beatrice-Santorini",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Santorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Santorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063206"
                        ],
                        "name": "Mary Ann Marcinkiewicz",
                        "slug": "Mary-Ann-Marcinkiewicz",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Marcinkiewicz",
                            "middleNames": [
                                "Ann"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary Ann Marcinkiewicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "anchors. This strategy is more exible than requiring each predicate to spring from some word. 7 To perform POS tagging, we used the Berkeley Parser (Petrov et al., 2006), trained on the WSJ Treebank (Marcus et al., 1993) and the Question Treebank (Judge et al., 2006)|thanks to Slav Petrov for providing the trained grammar. 33 Domain-independent triggers nojnotjdont jdoesnt joutside jexclude ` not each jevery ` every "
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 252796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
            "isKey": false,
            "numCitedBy": 8177,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant."
            },
            "slug": "Building-a-Large-Annotated-Corpus-of-English:-The-Marcus-Santorini",
            "title": {
                "fragments": [],
                "text": "Building a Large Annotated Corpus of English: The Penn Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "As a result of this grant, the researchers have now published on CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, which includes a fully hand-parsed version of the classic Brown corpus."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743057"
                        ],
                        "name": "P. Cousot",
                        "slug": "P.-Cousot",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Cousot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cousot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758667"
                        ],
                        "name": "R. Cousot",
                        "slug": "R.-Cousot",
                        "structuredName": {
                            "firstName": "Radhia",
                            "lastName": "Cousot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cousot"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Computing denotations on an abstract world is called abstract interpretation (Cousot and Cousot, 1977) and is very powerful framework commonly used in the programming languages community."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207614632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c77cd64f26228442ffff9219bfd870c83c8747c0",
            "isKey": false,
            "numCitedBy": 6556,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A program denotes computations in some universe of objects. Abstract interpretation of programs consists in using that denotation to describe computations in another universe of abstract objects, so that the results of abstract execution give some information on the actual computations. An intuitive example (which we borrow from Sintzoff [72]) is the rule of signs. The text -1515 * 17 may be understood to denote computations on the abstract universe {(+), (-), (\u00b1)} where the semantics of arithmetic operators is defined by the rule of signs. The abstract execution -1515 * 17 \u2192 -(+) * (+) \u2192 (-) * (+) \u2192 (-), proves that -1515 * 17 is a negative number. Abstract interpretation is concerned by a particular underlying structure of the usual universe of computations (the sign, in our example). It gives a summary of some facets of the actual executions of a program. In general this summary is simple to obtain but inaccurate (e.g. -1515 + 17 \u2192 -(+) + (+) \u2192 (-) + (+) \u2192 (\u00b1)). Despite its fundamentally incomplete results abstract interpretation allows the programmer or the compiler to answer questions which do not need full knowledge of program executions or which tolerate an imprecise answer, (e.g. partial correctness proofs of programs ignoring the termination problems, type checking, program optimizations which are not carried in the absence of certainty about their feasibility, \u2026)."
            },
            "slug": "Abstract-interpretation:-a-unified-lattice-model-of-Cousot-Cousot",
            "title": {
                "fragments": [],
                "text": "Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints"
            },
            "venue": {
                "fragments": [],
                "text": "POPL"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741598"
                        ],
                        "name": "S. Branavan",
                        "slug": "S.-Branavan",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Branavan",
                            "middleNames": [
                                "R.",
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Branavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3152698"
                        ],
                        "name": "Harr Chen",
                        "slug": "Harr-Chen",
                        "structuredName": {
                            "firstName": "Harr",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harr Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741283"
                        ],
                        "name": "R. Barzilay",
                        "slug": "R.-Barzilay",
                        "structuredName": {
                            "firstName": "Regina",
                            "lastName": "Barzilay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barzilay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 115
                            }
                        ],
                        "text": "Past work has also focused on aligning text to a world (Liang et al., 2009), using text in reinforcement learning (Branavan et al., 2009; Branavan et al., 2010), and many others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 90
                            }
                        ],
                        "text": "For example, previous work learned to interpret language to troubleshoot aWindows machine (Branavan et al. 2009; Branavan, Zettlemoyer, and Barzilay 2010), win a game of Civilization (Branavan, Silver, and Barzilay 2011), play a legal game of solitaire (Eisenstein et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 45
                            }
                        ],
                        "text": "required for various semantics-related tasks (Zettlemoyer and Collins 2005; Branavan et al. 2009; Liang, Jordan, and Klein 2009; Clarke et al. 2010; Artzi and Zettlemoyer 2011; Goldwasser et al. 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 318,
                                "start": 217
                            }
                        ],
                        "text": "2011), learning a semantic parser from user interactions with a dialog system (Artzi and Zettlemoyer 2011), and learning to execute natural language instructions from just a reward signal using reinforcement learning (Branavan et al. 2009; Branavan, Zettlemoyer, and Barzilay 2010; Branavan, Silver, and Barzilay 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5249151,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc1648c91ffda21bbe6e5f08f69c683588fc384c",
            "isKey": true,
            "numCitedBy": 263,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a reinforcement learning approach for mapping natural language instructions to sequences of executable actions. We assume access to a reward function that defines the quality of the executed actions. During training, the learner repeatedly constructs action sequences for a set of documents, executes those actions, and observes the resulting reward. We use a policy gradient algorithm to estimate the parameters of a log-linear model for action selection. We apply our method to interpret instructions in two domains --- Windows troubleshooting guides and game tutorials. Our results demonstrate that this method can rival supervised learning techniques while requiring few or no annotated training examples."
            },
            "slug": "Reinforcement-Learning-for-Mapping-Instructions-to-Branavan-Chen",
            "title": {
                "fragments": [],
                "text": "Reinforcement Learning for Mapping Instructions to Actions"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This paper presents a reinforcement learning approach for mapping natural language instructions to sequences of executable actions, and uses a policy gradient algorithm to estimate the parameters of a log-linear model for action selection."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145493610"
                        ],
                        "name": "M. Kay",
                        "slug": "M.-Kay",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "Note that having lexical triggers is a much weaker requirement than having a CCG lexicon, and far easier to obtain than logical forms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 25
                            }
                        ],
                        "text": "CCG is one instantiation (Steedman, 2000), which is used by many semantic parsers, e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "Piantadosi et al. (2008) induces first-order formulae using CCG in a small domain assuming observed lexical semantics."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "In DCS, we start with lexical triggers, which are more basic than CCG lexical entries."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "CCG is one instantiation (Steedman, 2000), which is used by many semantic parsers, e.g., Zettlemoyer and Collins (2005)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 26
                            }
                        ],
                        "text": "To contrast, consider CCG (Steedman, 2000), in which semantic parsing is driven from the lexicon."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58106824,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "ce8cca19455e8d3055c57a9bafe882984c95a201",
            "isKey": true,
            "numCitedBy": 911,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "In computational linguistics, which began in the 1950's with machine translation, systems that are based mainly on the lexicon have a longer t r a d i t i o n than anything e l se f o r these purposes, twenty f i ve years must be allowed to count as a tradition. The bulk of many of the early translation systems was made up by a d ic t ionary whose ent r ies consisted of a rb i t ra ry ins t ruc t ions In machine language. In the early 60's, computational llnsulsts---at least those with theoretical pretentlons---abandoned this way of doing business for at least three related reasons:"
            },
            "slug": "Syntactic-Process-Kay",
            "title": {
                "fragments": [],
                "text": "Syntactic Process"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "In computational linguistics, which began in the 1950's with machine translation, systems that are based mainly on the lexicon have a longer lifespan than anything else, so twenty years must be allowed to count as a tradition."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741598"
                        ],
                        "name": "S. Branavan",
                        "slug": "S.-Branavan",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Branavan",
                            "middleNames": [
                                "R.",
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Branavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741283"
                        ],
                        "name": "R. Barzilay",
                        "slug": "R.-Barzilay",
                        "structuredName": {
                            "firstName": "Regina",
                            "lastName": "Barzilay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barzilay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 138
                            }
                        ],
                        "text": "Past work has also focused on aligning text to a world (Liang et al., 2009), using text in reinforcement learning (Branavan et al., 2009; Branavan et al., 2010), and many others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "as Montague\u2019s (1973) quantifying in, Cooper storage (Cooper 1975), and Carpenter\u2019s (1998) scoping constructor handle scope divergence during semantic interpretation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5902718,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66ff889f25829822169d5971e706013ed909d574",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the task of mapping high-level instructions to sequences of commands in an external environment. Processing these instructions is challenging---they posit goals to be achieved without specifying the steps required to complete them. We describe a method that fills in missing information using an automatically derived environment model that encodes states, transitions, and commands that cause these transitions to happen. We present an efficient approximate approach for learning this environment model as part of a policy-gradient reinforcement learning algorithm for text interpretation. This design enables learning for mapping high-level instructions, which previous statistical methods cannot handle."
            },
            "slug": "Reading-between-the-Lines:-Learning-to-Map-to-Branavan-Zettlemoyer",
            "title": {
                "fragments": [],
                "text": "Reading between the Lines: Learning to Map High-Level Instructions to Commands"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A method that fills in missing information using an automatically derived environment model that encodes states, transitions, and commands that cause these transitions to happen that enables learning for mapping high-level instructions, which previous statistical methods cannot handle."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741598"
                        ],
                        "name": "S. Branavan",
                        "slug": "S.-Branavan",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Branavan",
                            "middleNames": [
                                "R.",
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Branavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741283"
                        ],
                        "name": "R. Barzilay",
                        "slug": "R.-Barzilay",
                        "structuredName": {
                            "firstName": "Regina",
                            "lastName": "Barzilay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barzilay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 42
                            }
                        ],
                        "text": ", 2009, 2010), win a game of Civilization (Branavan et al., 2011), play a legal game of solitaire (Eisenstein et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8781666,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99f1921a8ba5ceecb18e5ca7ff19b7f95c4e250d",
            "isKey": false,
            "numCitedBy": 147,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach for leveraging automatically extracted textual knowledge to improve the performance of control applications such as games. Our ultimate goal is to enrich a stochastic player with high-level guidance expressed in text. Our model jointly learns to identify text that is relevant to a given game state in addition to learning game strategies guided by the selected text. Our method operates in the Monte-Carlo search framework, and learns both text analysis and game strategies based only on environment feedback. We apply our approach to the complex strategy game Civilization II using the official game manual as the text guide. Our results show that a linguistically-informed game-playing agent significantly outperforms its language-unaware counterpart, yielding a 27% absolute improvement and winning over 78% of games when playing against the built-in AI of Civilization II."
            },
            "slug": "Learning-to-Win-by-Reading-Manuals-in-a-Monte-Carlo-Branavan-Silver",
            "title": {
                "fragments": [],
                "text": "Learning to Win by Reading Manuals in a Monte-Carlo Framework"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The results show that a linguistically-informed game-playing agent significantly outperforms its language-unaware counterpart, yielding a 27% absolute improvement and winning over 78% of games when playing against the built-in AI of Civilization II."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075292388"
                        ],
                        "name": "P. Liang",
                        "slug": "P.-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6756014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c26770f29afafe22f2a507506e3f43c413f6a619",
            "isKey": false,
            "numCitedBy": 106,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We are interested in learning programs for multiple related tasks given only a few training examples per task. Since the program for a single task is underdetermined by its data, we introduce a nonparametric hierarchical Bayesian prior over programs which shares statistical strength across multiple tasks. The key challenge is to parametrize this multi-task sharing. For this, we introduce a new representation of programs based on combinatory logic and provide an MCMC algorithm that can perform safe program transformations on this representation to reveal shared inter-program substructures."
            },
            "slug": "Learning-Programs:-A-Hierarchical-Bayesian-Approach-Liang-Jordan",
            "title": {
                "fragments": [],
                "text": "Learning Programs: A Hierarchical Bayesian Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A nonparametric hierarchical Bayesian prior over programs which shares statistical strength across multiple tasks is introduced and an MCMC algorithm is provided that can perform safe program transformations on this representation to reveal shared inter-program substructures."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30333061"
                        ],
                        "name": "Adam Vogel",
                        "slug": "Adam-Vogel",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Vogel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Vogel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": " al., 2009, 2010), win a game of Civilization (Branavan et al., 2011), play a legal game of solitaire (Eisenstein et al., 2009; Goldwasser and Roth, 2011), and navigate a map by following directions (Vogel and Jurafsky, 2010; Chen and Mooney, 2011). Even when the objective in the world is dened independently of language (e.g., in Civilization), language can provide a useful bias towards the non-linguistic end goal. 5.4 "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10395192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da5289121e139b6810781301a890c94c25a0d3d7",
            "isKey": true,
            "numCitedBy": 193,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system that learns to follow navigational natural language directions. Where traditional models learn from linguistic annotation or word distributions, our approach is grounded in the world, learning by apprenticeship from routes through a map paired with English descriptions. Lacking an explicit alignment between the text and the reference path makes it difficult to determine what portions of the language describe which aspects of the route. We learn this correspondence with a reinforcement learning algorithm, using the deviation of the route we follow from the intended path as a reward signal. We demonstrate that our system successfully grounds the meaning of spatial terms like above and south into geometric properties of paths."
            },
            "slug": "Learning-to-Follow-Navigational-Directions-Vogel-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Learning to Follow Navigational Directions"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A system that learns to follow navigational natural language directions by learning by apprenticeship from routes through a map paired with English descriptions using a reinforcement learning algorithm, which grounds the meaning of spatial terms like above and south into geometric properties of paths."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2407157"
                        ],
                        "name": "Varol Akman",
                        "slug": "Varol-Akman",
                        "structuredName": {
                            "firstName": "Varol",
                            "lastName": "Akman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Varol Akman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60783006,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "2e767232d59f92b4e397866b7696574fcd1df0b6",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This is a review of From Discourse to Logic: Introduction to Model-theoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory, by Hans Kamp and Uwe Reyle, published by Kluwer Academic Publishers in 1993."
            },
            "slug": "Book-Review-Hans-Kamp-and-Uwe-Reyle,-From-Discourse-Akman",
            "title": {
                "fragments": [],
                "text": "Book Review -- Hans Kamp and Uwe Reyle, From Discourse to Logic: Introduction to Model-theoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This is a review of From Discourse to Logic: Introduction to Model-theoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory, by Hans Kamp and Uwe Reyle, published by Kluwer Academic Publishers in 1993."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123333909"
                        ],
                        "name": "M.I. Jordan",
                        "slug": "M.I.-Jordan",
                        "structuredName": {
                            "firstName": "M.I.",
                            "lastName": "Jordan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M.I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207178945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d98d0d1900b13b87aa4ffd6b69c046beb63f0434",
            "isKey": false,
            "numCitedBy": 3901,
            "numCiting": 303,
            "paperAbstract": {
                "fragments": [],
                "text": "The formalism of probabilistic graphical models provides a unifying framework for capturing complex dependencies among random variables, and building large-scale multivariate statistical models. Graphical models have become a focus of research in many statistical, computational and mathematical fields, including bioinformatics, communication theory, statistical physics, combinatorial optimization, signal and image processing, information retrieval and statistical machine learning. Many problems that arise in specific instances \u2014 including the key problems of computing marginals and modes of probability distributions \u2014 are best studied in the general setting. Working with exponential family representations, and exploiting the conjugate duality between the cumulant function and the entropy for exponential families, we develop general variational representations of the problems of computing likelihoods, marginal probabilities and most probable configurations. We describe how a wide variety of algorithms \u2014 among them sum-product, cluster variational methods, expectation-propagation, mean field methods, max-product and linear programming relaxation, as well as conic programming relaxations \u2014 can all be understood in terms of exact or approximate forms of these variational representations. The variational approach provides a complementary alternative to Markov chain Monte Carlo as a general source of approximation methods for inference in large-scale statistical models."
            },
            "slug": "Graphical-Models,-Exponential-Families,-and-Wainwright-Jordan",
            "title": {
                "fragments": [],
                "text": "Graphical Models, Exponential Families, and Variational Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The variational approach provides a complementary alternative to Markov chain Monte Carlo as a general source of approximation methods for inference in large-scale statistical models."
            },
            "venue": {
                "fragments": [],
                "text": "Found. Trends Mach. Learn."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153642390"
                        ],
                        "name": "David L. Chen",
                        "slug": "David-L.-Chen",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David L. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some can learn from utterances paired with a set of logical forms, one of which is correct (Kate and Mooney, 2007; Chen and Mooney, 2008). Liang et al. (2009) tackles the even more difficult alignment problem of segmenting and aligning a discourse to a database of facts, where many parts on either side are irrelevant."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Some can learn from utterances paired with a set of logical forms, one of which is correct (Kate and Mooney, 2007; Chen and Mooney, 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2488088,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0008076a1968d9fb590c9013ab27b824849a4e80",
            "isKey": false,
            "numCitedBy": 232,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel commentator system that learns language from sportscasts of simulated soccer games. The system learns to parse and generate commentaries without any engineered knowledge about the English language. Training is done using only ambiguous supervision in the form of textual human commentaries and simulation states of the soccer games. The system simultaneously tries to establish correspondences between the commentaries and the simulation states as well as build a translation model. We also present a novel algorithm, Iterative Generation Strategy Learning (IGSL), for deciding which events to comment on. Human evaluations of the generated commentaries indicate they are of reasonable quality compared to human commentaries."
            },
            "slug": "Learning-to-sportscast:-a-test-of-grounded-language-Chen-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning to sportscast: a test of grounded language acquisition"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A novel commentator system that learns language from sportscasts of simulated soccer games and uses a novel algorithm, Iterative Generation Strategy Learning (IGSL), for deciding which events to comment on."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683297"
                        ],
                        "name": "R. Bart\u00e1k",
                        "slug": "R.-Bart\u00e1k",
                        "structuredName": {
                            "firstName": "Roman",
                            "lastName": "Bart\u00e1k",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bart\u00e1k"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 106
                            }
                        ],
                        "text": "Computation We can compute the denotation JzKw of a DCS tree z by exploiting dynamic programming on trees (Dechter, 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1898851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39775860ff0702974844049fca907cf756b98596",
            "isKey": false,
            "numCitedBy": 594,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "INTRODUCTION Constraints appear in many areas of human endeavour starting from puzzles like crosswords (the words can only overlap at the same letter) and recently popular Sudoku (no number appears twice in a row) through everyday problems such as planning a meeting (the meeting room must accommodate all participants) till solving hard optimization problems for example in manufacturing scheduling (a job must finish before another job). Though all these problems look like being from completely different worlds, they all share a similar base \u2013 the task is to find values of decision variables, such as the start time of the job or the position of the number at a board, respecting given constraints. This problem is called a Constraint Satisfaction Problem (CSP). Constraint processing emerged from AI research in 1970s (Montanary, 1974) when problems such as scene labelling were studied (Waltz, 1975). The goal of scene labelling was to recognize a type of line (and then a type of object) in the 2D picture of a 3D scene. The possible types were convex, concave, and occlud-ing lines and the combination of types was restricted at junctions of lines to be physically feasible. This scene labelling problem is probably the first problem formalised as a CSP and some techniques developed for solving this problem, namely arc consistency, are still in the core of constraint processing. Systematic use of constraints in programming systems has started in 1980s when researchers identified a similarity between unification in logic programming and constraint satisfaction (Gallaire, 1985) (Jaffar & Lassez, 1987). Constraint Logic Programming was born. Today Constraint Programming is a separate subject independent of the underlying programming language, though constraint logic programming still plays a prominent role thanks to natural integration of constraints into a logic programming framework. This article presents mainstream techniques for solving constraint satisfaction problems. These techniques stay behind the existing constraint solvers and their understanding is important to exploit fully the available technology."
            },
            "slug": "Constraint-Processing-Bart\u00e1k",
            "title": {
                "fragments": [],
                "text": "Constraint Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Mainstream techniques for solving constraint satisfaction problems are presented, which stay behind the existing constraint solvers and their understanding is important to exploit fully the available technology."
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of Artificial Intelligence"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48959839"
                        ],
                        "name": "R. Montague",
                        "slug": "R.-Montague",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Montague",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Montague"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The dominant paradigm, which stems from the seminal work of Richard Montague (1973) in the early 1970s, states that parts are lambda calculus expressions that correspond to syntactic constituents, and composition is function application."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195895453,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "a376f76c6029cd053db3a601f95b0f4e9b3d56fc",
            "isKey": false,
            "numCitedBy": 2117,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The aim of this paper is to present in a rigorous way the syntax and semantics of a certain fragment of a certain dialect of English. For expository purposes the fragment has been made as simple and restricted as it can be while accommodating all the more puzzling cases of quantification and reference with which I am acquainted.1"
            },
            "slug": "The-Proper-Treatment-of-Quantification-in-Ordinary-Montague",
            "title": {
                "fragments": [],
                "text": "The Proper Treatment of Quantification in Ordinary English"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The aim of this paper is to present in a rigorous way the syntax and semantics of a certain fragment of acertain dialect of English."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075292388"
                        ],
                        "name": "P. Liang",
                        "slug": "P.-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "e we are interleaving the SGD updates with beam search, which might also lead to unpredictable consequences. Furthermore, the non-convexity of the objective function exacerbates the unpredictability (Liang and Klein, 2009). Nonetheless, with a proper , SGD converges much faster than L-BFGS and even to a slightly better solution. 40 100 200 300 400 examples 20 40 60 80 100 Accuracy Random 1 Random 2 Random 3 Random 4 Ra"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7027442,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "226966243877f186d346be01047cf71cee1b5ec4",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The (batch) EM algorithm plays an important role in unsupervised induction, but it sometimes suffers from slow convergence. In this paper, we show that online variants (1) provide significant speedups and (2) can even find better solutions than those found by batch EM. We support these findings on four unsupervised tasks: part-of-speech tagging, document classification, word segmentation, and word alignment."
            },
            "slug": "Online-EM-for-Unsupervised-Models-Liang-Klein",
            "title": {
                "fragments": [],
                "text": "Online EM for Unsupervised Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that online variants provide significant speedups and can even find better solutions than those found by batch EM on four unsupervised tasks: part-of-speech tagging, document classification, word segmentation, and word alignment."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784955"
                        ],
                        "name": "J. Nocedal",
                        "slug": "J.-Nocedal",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Nocedal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nocedal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 116
                            }
                        ],
                        "text": "Optimization algorithm To optimize the objective functionO(\u03b8,C) our default is to use the standard L-BFGS algorithm (Nocedal 1980) with a backtracking line search for choosing the step size."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 92
                            }
                        ],
                        "text": "We optimize O\u0303(\u03b8, \u03b8\u2032) by setting \u03b8(0) = ~0 and iteratively solving \u03b8(t+1) = argmax\u03b8 O\u0303(\u03b8, \u03b8(t)) using L-BFGS until t = T ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 36
                            }
                        ],
                        "text": "Thus far, we have been using L-BFGS (Nocedal 1980), which is a batch algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9033333,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2aaf56fb183ad66d099ac6c9110c5c365ab27f3",
            "isKey": true,
            "numCitedBy": 2414,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We study how to use the BFGS quasi-Newton matrices to precondition minimization methods for problems where the storage is critical. We give an update formula which generates matrices using information from the last m iterations, where m is any number supplied by the user. The quasi-Newton matrix is updated at every iteration by dropping the oldest information and replacing it by the newest informa- tion. It is shown that the matrices generated have some desirable properties. The resulting algorithms are tested numerically and compared with several well- known methods. 1. Introduction. For the problem of minimizing an unconstrained function / of n variables, quasi-Newton methods are widely employed (4). They construct a se- quence of matrices which in some way approximate the hessian of /(or its inverse). These matrices are symmetric; therefore, it is necessary to have n(n + l)/2 storage locations for each one. For large dimensional problems it will not be possible to re- tain the matrices in the high speed storage of a computer, and one has to resort to other kinds of algorithms. For example, one could use the methods (Toint (15), Shanno (12)) which preserve the sparsity structure of the hessian, or conjugate gradient methods (CG) which only have to store 3 or 4 vectors. Recently, some CG algorithms have been developed which use a variable amount of storage and which do not require knowledge about the sparsity structure of the problem (2), (7), (8). A disadvantage of these methods is that after a certain number of iterations the quasi-Newton matrix is discarded, and the algorithm is restarted using an initial matrix (usually a diagonal matrix). We describe an algorithm which uses a limited amount of storage and where the quasi-Newton matrix is updated continuously. At every step the oldest information contained in the matrix is discarded and replaced by new one. In this way we hope to have a more up to date model of our function. We will concentrate on the BFGS method since it is considered to be the most efficient. We believe that similar algo- rithms cannot be developed for the other members of the Broyden 0-class (1). Let / be the function to be nnnimized, g its gradient and h its hessian. We define"
            },
            "slug": "Updating-Quasi-Newton-Matrices-With-Limited-Storage-Nocedal",
            "title": {
                "fragments": [],
                "text": "Updating Quasi-Newton Matrices With Limited Storage"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An update formula which generates matrices using information from the last m iterations, where m is any number supplied by the user, and the BFGS method is considered to be the most efficient."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145648751"
                        ],
                        "name": "H. Robbins",
                        "slug": "H.-Robbins",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Robbins",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Robbins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": " construct the candidate sets C(t)(x) for all the training examples before solving the optimization problem argmax  O(;C(t)). We now consider an online algorithm, stochastic gradient descent (SGD) (Robbins and Monro, 1951), which updates the parameters after computing the candidate set for each example. In particular, we iteratively scan through the training examples in a random order. For each example (x;y), we comput"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16945044,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "34ddd8865569c2c32dec9bf7ffc817ff42faaa01",
            "isKey": false,
            "numCitedBy": 6431,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Let M(x) denote the expected value at level x of the response to a certain experiment. M(x) is assumed to be a monotone function of x but is unknown tot he experiment, and it is desire to find the solution x=0 of the equation M(x) = a, where x is a given constant. we give a method for making successive experiments at levels x1, x2,... in such a way that x, will tend to 0 in probability."
            },
            "slug": "A-Stochastic-Approximation-Method-Robbins",
            "title": {
                "fragments": [],
                "text": "A Stochastic Approximation Method"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 303,
                                "start": 262
                            }
                        ],
                        "text": "Why did we choose this particular logical subset as a starting point, rather than allowing universal quantification, negation, or disjunction? There seems to be something fundamental about this subset, which also appears in Discourse Representation Theory (DRT) (Kamp and Reyle, 1993; Kamp et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 100
                            }
                        ],
                        "text": "The idea of using CSPs to represent semantics is inspired by Discourse Representation Theory (DRT) (Kamp and Reyle, 1993; Kamp et al., 2005), where variables are discourse referents."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 121
                            }
                        ],
                        "text": "Perhaps not immediately apparent is the fact that DCS draws an important idea from Discourse Representation Theory (DRT) (Kamp and Reyle, 1993)\u2014not from its treatment of anaphora and presupposition which it is known for, but something closer to its core."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "The restriction to trees is similar to economical DRT (Bos, 2009)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 111
                            }
                        ],
                        "text": "Linguistically, it appears that existential quantifiers play an important role and should be treated specially (Kamp and Reyle, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "From Discourse to Logic: An Introduction to the Model-theoretic Semantics of Natural Language, Formal Logic and Discourse"
            },
            "venue": {
                "fragments": [],
                "text": "Representation Theory. Kluwer,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 97
                            }
                        ],
                        "text": "the database/world reduces the set of candidate logical forms and leads to more accurate systems (Popescu et al., 2003; Liang et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 29
                            }
                        ],
                        "text": "9 LJK11 w/augmented triggers (Liang et al., 2011) \u2013 91."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 84
                            }
                        ],
                        "text": "We can obtain answers given a world, which are cheaper to obtain than logical forms (Clarke et al., 2010; Liang et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 29
                            }
                        ],
                        "text": "7 LJK11 w/augmented triggers (Liang et al., 2011) \u2013 95."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 156
                            }
                        ],
                        "text": "In response to these concerns, researchers have recently begun to explore the possibility of learning a semantic parser without any annotated logical forms (Clarke et al., 2010; Liang et al., 2011; Goldwasser et al., 2011; Artzi and Zettlemoyer, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning dependency-based compositional semantics. In Association for Computational Linguistics (ACL), pages 590\u2013599"
            },
            "venue": {
                "fragments": [],
                "text": "Association for Computational Linguistics,"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 97
                            }
                        ],
                        "text": "the database/world reduces the set of candidate logical forms and leads to more accurate systems (Popescu et al., 2003; Liang et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 29
                            }
                        ],
                        "text": "9 LJK11 w/augmented triggers (Liang et al., 2011) \u2013 91."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 84
                            }
                        ],
                        "text": "We can obtain answers given a world, which are cheaper to obtain than logical forms (Clarke et al., 2010; Liang et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 29
                            }
                        ],
                        "text": "7 LJK11 w/augmented triggers (Liang et al., 2011) \u2013 95."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 156
                            }
                        ],
                        "text": "In response to these concerns, researchers have recently begun to explore the possibility of learning a semantic parser without any annotated logical forms (Clarke et al., 2010; Liang et al., 2011; Goldwasser et al., 2011; Artzi and Zettlemoyer, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning dependency-based compositional semantics. In Association for Computational Linguistics (ACL)"
            },
            "venue": {
                "fragments": [],
                "text": "Association for Computational Linguistics,"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46887822"
                        ],
                        "name": "R. Cooper",
                        "slug": "R.-Cooper",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Cooper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cooper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 52
                            }
                        ],
                        "text": "as Montague\u2019s (1973) quantifying in, Cooper storage (Cooper 1975), and Carpenter\u2019s (1998) scoping constructor handle scope divergence during semantic interpretation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117586676,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "ca90dcc562b5887e9bc5350d1c5f844038c162d9",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "MONTAGUE'S-SEMANTIC-THEORY-AND-TRANSFORMATIONAL-Cooper",
            "title": {
                "fragments": [],
                "text": "MONTAGUE'S SEMANTIC THEORY AND TRANSFORMATIONAL SYNTAX."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 219305770,
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Dependency-Based Compositional Semantics"
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "population): a predicate p \u2208 P represents its semantics p w = w(p). @BULLET Filter (e.g., >{\u00b7 2 = 10 6 }): e{\u00b7 i ="
            },
            "venue": {
                "fragments": [],
                "text": "population): a predicate p \u2208 P represents its semantics p w = w(p). @BULLET Filter (e.g., >{\u00b7 2 = 10 6 }): e{\u00b7 i ="
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An algorithm for suffix stripping Robbins and S. Monro. A stochastic approximation method"
            },
            "venue": {
                "fragments": [],
                "text": "Program Annals of Mathematical Statistics"
            },
            "year": 1951
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 42
                            }
                        ],
                        "text": ", 2009, 2010), win a game of Civilization (Branavan et al., 2011), play a legal game of solitaire (Eisenstein et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to win by reading manuals in a MonteCarlo framework. In Association for Computational Linguistics (ACL), pages 268\u2013277"
            },
            "venue": {
                "fragments": [],
                "text": "Association for Computational Linguistics,"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inducing probabilistic CCG"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 89
                            }
                        ],
                        "text": "We might be able to incorporate some ideas from Hybrid Logic Dependency Semantics (HLDS) (Baldridge and Kruijff, 2002; White, 2006), given that hybrid logic extends the tree structures of modal logic with nominals, thereby allowing a node to freely reference other nodes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Coupling CCG with hybrid logic dependency semantics. In Association for Computational Linguistics (ACL), pages 319\u2013326"
            },
            "venue": {
                "fragments": [],
                "text": "Association for Computational Linguistics,"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "@BULLET Product (e.g., population \u00d7 area): e 1 \u00d7 e 2 w = {x + y : x \u2208 e 1 w"
            },
            "venue": {
                "fragments": [],
                "text": "@BULLET Product (e.g., population \u00d7 area): e 1 \u00d7 e 2 w = {x + y : x \u2208 e 1 w"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 169
                            }
                        ],
                        "text": "The problem of building these natural language interfaces to databases (NLIDBs) has a long history in NLP, starting from the early days of AI with systems such as Lunar (Woods et al., 1972), Chat-80 (Warren and Pereira, 1982), and many others (see Androutsopoulos et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The lunar sciences natural language information system: Final report"
            },
            "venue": {
                "fragments": [],
                "text": "Technical report, BBN Report"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 34
                            }
                        ],
                        "text": ", 1993) and the Question Treebank (Judge et al., 2006)\u2014thanks to Slav Petrov for providing the trained parser."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Question-bank: creating a corpus of parseannotated questions"
            },
            "venue": {
                "fragments": [],
                "text": "In International Conference on Computational Linguistics and Association for Computational Linguistics (COLING/ACL),"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 156
                            }
                        ],
                        "text": "In response to these concerns, researchers have recently begun to explore the possibility of learning a semantic parser without any annotated logical forms (Clarke et al., 2010; Liang et al., 2011; Goldwasser et al., 2011; Artzi and Zettlemoyer, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Confidence driven unsupervised semantic parsing. In Association for Computational Linguistics (ACL), pages 1486\u20131495"
            },
            "venue": {
                "fragments": [],
                "text": "Association for Computational Linguistics,"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 76
                            }
                        ],
                        "text": "Supervised semantic parsers (Zelle and Mooney, 1996; Tang and Mooney, 2001; Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Kate and Mooney, 2007; Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Kwiatkowski et al., 2010) rely on manual annotation of logical forms, which is expensive."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A statistical semantic"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 90
                            }
                        ],
                        "text": "Furthermore, the non-convexity of the objective function exacerbates the unpredictability (Liang and Klein, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Online EM for unsupervised models. In North American Association for Computational Linguistics (NAACL)"
            },
            "venue": {
                "fragments": [],
                "text": "Association for Computational Linguistics,"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 138
                            }
                        ],
                        "text": "Past work has also focused on aligning text to a world (Liang et al., 2009), using text in reinforcement learning (Branavan et al., 2009; Branavan et al., 2010), and many others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reading between the lines: Learning to map high-level instructions to commands. In Association for Computational Linguistics (ACL)"
            },
            "venue": {
                "fragments": [],
                "text": "Association for Computational Linguistics,"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 138
                            }
                        ],
                        "text": "Past work has also focused on aligning text to a world (Liang et al., 2009), using text in reinforcement learning (Branavan et al., 2009; Branavan et al., 2010), and many others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reading between the lines: Learning to map high-level instructions to commands. In Association for Computational Linguistics (ACL), pages 1268\u20131277"
            },
            "venue": {
                "fragments": [],
                "text": "Association for Computational Linguistics,"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 61
                            }
                        ],
                        "text": "Continuations from programming languages is another solution (Barker, 2002; Shan, 2004), which sets the semantics of a quantifier to be a function from its continuation (which captures all the semantic content of the clause minus the quantifier) to the final denotation of the clause."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Delimited continuations in natural language"
            },
            "venue": {
                "fragments": [],
                "text": "Technical report, ArXiv,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 156
                            }
                        ],
                        "text": "In response to these concerns, researchers have recently begun to explore the possibility of learning a semantic parser without any annotated logical forms (Clarke et al., 2010; Liang et al., 2011; Goldwasser et al., 2011; Artzi and Zettlemoyer, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Confidence driven unsupervised semantic parsing. In Association for Computational Linguistics (ACL)"
            },
            "venue": {
                "fragments": [],
                "text": "Association for Computational Linguistics,"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 42
                            }
                        ],
                        "text": ", 2009, 2010), win a game of Civilization (Branavan et al., 2011), play a legal game of solitaire (Eisenstein et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to win by reading manuals in a MonteCarlo framework. In Association for Computational Linguistics (ACL)"
            },
            "venue": {
                "fragments": [],
                "text": "Association for Computational Linguistics,"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 42
                            }
                        ],
                        "text": ", 2009, 2010), win a game of Civilization (Branavan et al., 2011), play a legal game of solitaire (Eisenstein et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to win by reading manuals in a MonteCarlo framework. In Association for Computational Linguistics (ACL)"
            },
            "venue": {
                "fragments": [],
                "text": "Association for Computational Linguistics,"
            },
            "year": 2011
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 43,
            "methodology": 25
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 81,
        "totalPages": 9
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-Dependency-Based-Compositional-Semantics-Liang-Jordan/3ecd3e00bbbfd94446c3adc9c6878de27e250f7c?sort=total-citations"
}