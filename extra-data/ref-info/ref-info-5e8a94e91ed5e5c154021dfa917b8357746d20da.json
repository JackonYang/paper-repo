{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769383"
                        ],
                        "name": "Lubomir D. Bourdev",
                        "slug": "Lubomir-D.-Bourdev",
                        "structuredName": {
                            "firstName": "Lubomir",
                            "lastName": "Bourdev",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lubomir D. Bourdev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35208858"
                        ],
                        "name": "Subhransu Maji",
                        "slug": "Subhransu-Maji",
                        "structuredName": {
                            "firstName": "Subhransu",
                            "lastName": "Maji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Subhransu Maji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 141
                            }
                        ],
                        "text": "In segmentation, shape is typically used as a category-specific cue, whereby known object models are integrated with bottom-up grouping cues [6, 7, 11, 12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2634569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2efe575c931cf923e47ec5c7f444d53aae549cd",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose techniques to make use of two complementary bottom-up features, image edges and texture patches, to guide top-down object segmentation towards higher precision. We build upon the part-based pose-let detector, which can predict masks for numerous parts of an object. For this purpose we extend poselets to 19 other categories apart from person. We non-rigidly align these part detections to potential object contours in the image, both to increase the precision of the predicted object mask and to sort out false positives. We spatially aggregate object information via a variational smoothing technique while ensuring that object regions do not overlap. Finally, we propose to refine the segmentation based on self-similarity defined on small image patches. We obtain competitive results on the challenging Pascal VOC benchmark. On four classes we achieve the best numbers to-date."
            },
            "slug": "Object-segmentation-by-alignment-of-poselet-to-Brox-Bourdev",
            "title": {
                "fragments": [],
                "text": "Object segmentation by alignment of poselet activations to image contours"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper builds upon the part-based pose-let detector, which can predict masks for numerous parts of an object, and extends poselets to 19 other categories apart from person."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143856002"
                        ],
                        "name": "N. Vu",
                        "slug": "N.-Vu",
                        "structuredName": {
                            "firstName": "Nhat",
                            "lastName": "Vu",
                            "middleNames": [
                                "Linh"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 141
                            }
                        ],
                        "text": "In segmentation, shape is typically used as a category-specific cue, whereby known object models are integrated with bottom-up grouping cues [6, 7, 11, 12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1014543,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e25a613790947590e716caa2144576c38b168d0",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new shape prior segmentation method using graph cuts capable of segmenting multiple objects. The shape prior energy is based on a shape distance popular with level set approaches. We also present a multiphase graph cut framework to simultaneously segment multiple, possibly overlapping objects. The multiphase formulation differs from multiway cuts in that the former can account for object overlaps by allowing a pixel to have multiple labels. We then extend the shape prior energy to encompass multiple shape priors. Unlike variational methods, a major advantage of our approach is that the segmentation energy is minimized directly without having to compute its gradient, which can be a cumbersome task and often relies on approximations. Experiments demonstrate that our algorithm can cope with image noise and clutter, as well as partial occlusions and affine transformations of the shape."
            },
            "slug": "Shape-prior-segmentation-of-multiple-objects-with-Vu-Manjunath",
            "title": {
                "fragments": [],
                "text": "Shape prior segmentation of multiple objects with graph cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A major advantage of this approach is that the segmentation energy is minimized directly without having to compute its gradient, which can be a cumbersome task and often relies on approximations."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746335"
                        ],
                        "name": "T. Chan",
                        "slug": "T.-Chan",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Chan",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Chan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39518694"
                        ],
                        "name": "Wei Zhu",
                        "slug": "Wei-Zhu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6428775,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b7812794b02b183a9d663fd072b42b89ed372238",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a level set based variational approach that incorporates shape priors into Chan-Vese's model for the shape prior segmentation problem. In our model, besides the level set function for segmentation, as in Cremers' work, we introduce another labelling level set function to indicate the regions on which the prior shape should be compared. Our model can segment an object, whose shape is similar to the given prior shape, from a background where there are several objects. Moreover, we provide a proof for a fast solution principle, which was mentioned by F. Gibou et al., and similar to the one proposed in [B. Song et al., (2002)], for minimizing Chan-Vese's segmentation model without length term. We extend the principle to the minimization of our prescribed functionals."
            },
            "slug": "Level-set-based-shape-prior-segmentation-Chan-Zhu",
            "title": {
                "fragments": [],
                "text": "Level set based shape prior segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A level set based variational approach that incorporates shape priors into Chan-Vese's model for the shape prior segmentation problem and provides a proof for a fast solution principle, which was mentioned by F. Gibou et al., (2002) and extended to the minimization of the prescribed functionals."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732672"
                        ],
                        "name": "A. Leonardis",
                        "slug": "A.-Leonardis",
                        "structuredName": {
                            "firstName": "Ale\u0161",
                            "lastName": "Leonardis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Leonardis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": ", in early model-based recognition [26] or voting-based implicit shape models [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6533591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38101fac622a70b78f13625fc6502000b8756d3a",
            "isKey": false,
            "numCitedBy": 1036,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for object categorization in real-world scenes. Following a common consensus in the field, we do not assume that a figure- ground segmentation is available prior to recognition. However, in contrast to most standard approaches for object class recognition, our approach automati- cally segments the object as a result of the categorization. This combination of recognition and segmentation into one process is made pos- sible by our use of an Implicit Shape Model, which integrates both into a common probabilistic framework. In addition to the recognition and segmentation result, it also generates a per-pixel confidence measure specifying the area that supports a hypothesis and how much it can be trusted. We use this confidence to derive a nat- ural extension of the approach to handle multiple objects in a scene and resolve ambiguities between overlapping hypotheses with a novel MDL-based criterion. In addition, we present an extensive evaluation of our method on a standard dataset for car detection and compare its performance to existing methods from the literature. Our results show that the proposed method significantly outper- forms previously published methods while needing one order of magnitude less training examples. Finally, we present results for articulated objects, which show that the proposed method can categorize and segment unfamiliar objects in differ- ent articulations and with widely varying texture patterns, even under significant partial occlusion."
            },
            "slug": "Combined-Object-Categorization-and-Segmentation-an-Leibe-Leonardis",
            "title": {
                "fragments": [],
                "text": "Combined Object Categorization and Segmentation With an Implicit Shape Model"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results for articulated objects, which show that the proposed method can categorize and segment unfamiliar objects in differ- ent articulations and with widely varying texture patterns, even under significant partial occlusion."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2365442"
                        ],
                        "name": "B. Alexe",
                        "slug": "B.-Alexe",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Alexe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Alexe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879646"
                        ],
                        "name": "Thomas Deselaers",
                        "slug": "Thomas-Deselaers",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Deselaers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Deselaers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5611404,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d957ad316f7145c054d2dcbd47949869e46776b0",
            "isKey": false,
            "numCitedBy": 1008,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel method for unsupervised class segmentation on a set of images. It alternates between segmenting object instances and learning a class model. The method is based on a segmentation energy defined over all images at the same time, which can be optimized efficiently by techniques used before in interactive segmentation. Over iterations, our method progressively learns a class model by integrating observations over all images. In addition to appearance, this model captures the location and shape of the class with respect to an automatically determined coordinate frame common across images. This frame allows us to build stronger shape and location models, similar to those used in object class detection. Our method is inspired by interactive segmentation methods [1], but it is fully automatic and learns models characteristic for the object class rather than specific to one particular object/image. We experimentally demonstrate on the Caltech4, Caltech101, and Weizmann horses datasets that our method (a) transfers class knowledge across images and this improves results compared to segmenting every image independently; (b) outperforms Grabcut [1] for the task of unsupervised segmentation; (c) offers competitive performance compared to the state-of-the-art in unsupervised segmentation and in particular it outperforms the topic model [2]."
            },
            "slug": "ClassCut-for-Unsupervised-Class-Segmentation-Alexe-Deselaers",
            "title": {
                "fragments": [],
                "text": "ClassCut for Unsupervised Class Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A novel method for unsupervised class segmentation on a set of images that alternates between segmenting object instances and learning a class model based on a segmentation energy defined over all images at the same time, which can be optimized efficiently by techniques used before in interactive segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32928116"
                        ],
                        "name": "Amir Rosenfeld",
                        "slug": "Amir-Rosenfeld",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amir Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789171"
                        ],
                        "name": "D. Weinshall",
                        "slug": "D.-Weinshall",
                        "structuredName": {
                            "firstName": "Daphna",
                            "lastName": "Weinshall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Weinshall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 62
                            }
                        ],
                        "text": "Some recent work tackles segmentation in a data-driven manner [22, 23], using image-level matching to gather exemplars with similar scene layouts, and then combining them with graph-cuts to preserve spatial coherence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7200919,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68813373102f66183922a7dcb6bd37d9cd8a670f",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Effective segmentation prior to recognition has been shown to improve recognition performance. However, most segmentation algorithms adopt methods which are not explicitly linked to the goal of object recognition. Here we solve a related but slightly different problem in order to assist object recognition more directly - the extraction of a foreground mask, which identifies the locations of objects in the image. We propose a novel foreground/background segmentation algorithm that attempts to segment the interesting objects from the rest of the image, while maximizing an objective function which is tightly related to object recognition. We do this in a manner which requires no class-specific knowledge of object categories, using a probabilistic formulation which is derived from manually segmented images. The model includes a geometric prior and an appearance prior, whose parameters are learnt on the fly from images that are similar to the query image. We use graph-cut based energy minimization to enforce spatial coherence on the model's output. The method is tested on the challenging VOC09 and VOC10 segmentation datasets, achieving excellent results in providing a foreground mask. We also provide comparisons to the recent segmentation method of [7]."
            },
            "slug": "Extracting-foreground-masks-towards-object-Rosenfeld-Weinshall",
            "title": {
                "fragments": [],
                "text": "Extracting foreground masks towards object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work proposes a novel foreground/background segmentation algorithm that attempts to segment the interesting objects from the rest of the image, while maximizing an objective function which is tightly related to object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35681810"
                        ],
                        "name": "Jo\u00e3o Carreira",
                        "slug": "Jo\u00e3o-Carreira",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Carreira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00e3o Carreira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 111
                            }
                        ],
                        "text": "Also relevant to our work are recent methods that generate category-independent object segmentation hypotheses [3, 4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 119
                            }
                        ],
                        "text": "To focus on raw segmentation quality, we do not consider post-processing with a learned region-ranking function (as in [3], [4]), which could equally benefit all methods, in terms of the number of segments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "The trend with color easiness is especially pronounced in the comparison to [3] (see (a) and (b)), which makes sense because its cues are strictly color-based."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "2 In order to isolate the impact of a color-based graph-cut likelihood, for [3], we select an option in the author\u2019s code to forgo graph-cut outputs with uniform foreground bias, which do not rely on image cues."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 189
                            }
                        ],
                        "text": "Final segmentation with graph-cuts: Next we compare our full approach to existing segmentation methods, including the state-of-the-art categoryindependent object segmentation generators of [3] and [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 92
                            }
                        ],
                        "text": "Evaluation metrics: To evaluate segmentation quality, we use the covering metric, following [10, 3], which is the average best overlapping score between ground-truth and generated segments, weighted by object size."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 27
                            }
                        ],
                        "text": "The best competing methods [3, 4] also use multi-parametric graph-cuts; so, the additional time required by our method is fairly small and could be reduced further by parallelizing the shape projection step."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 82
                            }
                        ],
                        "text": "Figure 8 show example results from our method and the best competing method, CPMC [3], illustrating when the shape prior is most beneficial."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 139
                            }
                        ],
                        "text": "This yields multiple segment hypotheses for a given prior, and is in the common spirit of the sequence of parametric min-cuts performed in [3, 4] (though, our focus is to incorporate the shape prior)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 230
                            }
                        ],
                        "text": "Results on the PASCAL 2010 and Berkeley Segmentation datasets show that our approach outperforms not only bottom-up segmentation [10], but also stateof-the-art category-independent region generation methods that lack shape priors [3, 4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6041168,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4131a2862d9f926c6727da6dc75c8fda25f4a9e5",
            "isKey": true,
            "numCitedBy": 476,
            "numCiting": 103,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel framework for generating and ranking plausible objects hypotheses in an image using bottom-up processes and mid-level cues. The object hypotheses are represented as figure-ground segmentations, and are extracted automatically, without prior knowledge about properties of individual object classes, by solving a sequence of constrained parametric min-cut problems (CPMC) on a regular image grid. We then learn to rank the object hypotheses by training a continuous model to predict how plausible the segments are, given their mid-level region properties. We show that this algorithm significantly outperforms the state of the art for low-level segmentation in the VOC09 segmentation dataset. It achieves the same average best segmentation covering as the best performing technique to date [2], 0.61 when using just the top 7 ranked segments, instead of the full hierarchy in [2]. Our method achieves 0.78 average best covering using 154 segments. In a companion paper [18], we also show that the algorithm achieves state-of-the art results when used in a segmentation-based recognition pipeline."
            },
            "slug": "Constrained-parametric-min-cuts-for-automatic-Carreira-Sminchisescu",
            "title": {
                "fragments": [],
                "text": "Constrained parametric min-cuts for automatic object segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that this algorithm significantly outperforms the state of the art for low-level segmentation in the VOC09 segmentation dataset and achieves the same average best segmentation covering as the best performing technique to date."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144421225"
                        ],
                        "name": "Michael Stark",
                        "slug": "Michael-Stark",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Stark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Stark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689293"
                        ],
                        "name": "M. Goesele",
                        "slug": "M.-Goesele",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Goesele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Goesele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 138
                            }
                        ],
                        "text": "In object recognition, model parameters learned on one set of categories can be transferred to more efficiently learn new related objects [17, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15213272,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1949636081c32463b3fea0afc6ba8198cfbd325d",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Object class models trained on hundreds or thousands of images have shown to enable robust detection. Transferring knowledge from such models to new object classes trained from a few or even as little as one training instance however is still in its infancy. This paper designs a shape-based model that allows to easily and explicitly transfer knowledge on three different levels: transfer of individual parts' shape and appearance information, transfer of local symmetry between parts, and transfer of part topology. Due to the factorized form of the model, knowledge can either be transferred for the complete model or just partial knowledge corresponding to certain aspects of the model. The experiments clearly demonstrate that the proposed model is competitive with the state-of-the-art and enables both full and partial knowledge transfer."
            },
            "slug": "A-shape-based-object-class-model-for-knowledge-Stark-Goesele",
            "title": {
                "fragments": [],
                "text": "A shape-based object class model for knowledge transfer"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A shape-based model that allows to easily and explicitly transfer knowledge on three different levels: transfer of individual parts' shape and appearance information, transfer of local symmetry between parts, and transfer of part topology is designed."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2329582"
                        ],
                        "name": "Alex Levinshtein",
                        "slug": "Alex-Levinshtein",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Levinshtein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Levinshtein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779136"
                        ],
                        "name": "S. Dickinson",
                        "slug": "S.-Dickinson",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Dickinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dickinson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": ", Gestalt cues like symmetry [19], or handcrafted geometric primitives [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12368711,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0d728af75fdc360e0cf8823ae7ea37505cdc1d4",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Skeletonization algorithms typically decompose an object\u2019s silhouette into a set of symmetric parts, offering a powerful representation for shape categorization. However, having access to an object\u2019s silhouette assumes correct figure-ground segmentation, leading to a disconnect with the mainstream categorization community, which attempts to recognize objects from cluttered images. In this paper, we present a novel approach to recovering and grouping the symmetric parts of an object from a cluttered scene. We begin by using a multiresolution superpixel segmentation to generate medial point hypotheses, and use a learned affinity function to perceptually group nearby medial points likely to belong to the same medial branch. In the next stage, we learn higher granularity affinity functions to group the resulting medial branches likely to belong to the same object. The resulting framework yields a skeletal approximation that is free of many of the instabilities that occur with traditional skeletons. More importantly, it does not require a closed contour, enabling the application of skeleton-based categorization systems to more realistic imagery."
            },
            "slug": "Multiscale-Symmetric-Part-Detection-and-Grouping-Levinshtein-Sminchisescu",
            "title": {
                "fragments": [],
                "text": "Multiscale Symmetric Part Detection and Grouping"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel approach to recovering and grouping the symmetric parts of an object from a cluttered scene by using a multiresolution superpixel segmentation to generate medial point hypotheses, and using a learned affinity function to perceptually group nearby medial points likely to belong to the same medial branch."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3045340"
                        ],
                        "name": "Tomasz Malisiewicz",
                        "slug": "Tomasz-Malisiewicz",
                        "structuredName": {
                            "firstName": "Tomasz",
                            "lastName": "Malisiewicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomasz Malisiewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 177
                            }
                        ],
                        "text": "We compare against two existing methods on the PASCAL data: (1) a merging method that combines pairs and triples of neighboring superpixels, without considering layout or shape [2], and (2) the state-of-the-art bottom-up hierarchal segmentation algorithm [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "Both are important baselines, since [2]"
                    },
                    "intents": []
                }
            ],
            "corpusId": 15599169,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "562b04ee16f27c47625b4989ab011510518d0b0a",
            "isKey": false,
            "numCitedBy": 331,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Sliding window scanning is the dominant paradigm in object recognition research today. But while much success has been reported in detecting several rectangular-shaped object classes (i.e. faces, cars, pedestrians), results have been much less impressive for more general types of objects. Several researchers have advocated the use of image segmentation as a way to get a better spatial support for objects. In this paper, our aim is to address this issue by studying the following two questions: 1) how important is good spatial support for recognition? 2) can segmentation provide better spatial support for objects? To answer the first, we compare recognition performance using ground-truth segmentation vs. bounding boxes. To answer the second, we use the multiple segmentation approach to evaluate how close can real segments approach the ground-truth for real objects, and at what cost. Our results demonstrate the importance of finding the right spatial support for objects, and the feasibility of doing so without excessive computational burden."
            },
            "slug": "Improving-Spatial-Support-for-Objects-via-Multiple-Malisiewicz-Efros",
            "title": {
                "fragments": [],
                "text": "Improving Spatial Support for Objects via Multiple Segmentations"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "The multiple segmentation approach is used to evaluate how close can real segments approach the ground-truth for real objects, and at what cost."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40462943"
                        ],
                        "name": "D. K\u00fcttel",
                        "slug": "D.-K\u00fcttel",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "K\u00fcttel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. K\u00fcttel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "A contemporary approach uses window-level matching for more robust exemplar retrieval under image variations [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1443031,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "683874b070da69ce358ed5dd673ebe3e42fc2137",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel technique for figure-ground segmentation, where the goal is to separate all foreground objects in a test image from the background. We decompose the test image and all images in a supervised training set into overlapping windows likely to cover foreground objects. The key idea is to transfer segmentation masks from training windows that are visually similar to windows in the test image. These transferred masks are then used to derive the unary potentials of a binary, pairwise energy function defined over the pixels of the test image, which is minimized with standard graph-cuts. This results in a fully automatic segmentation scheme, as opposed to interactive techniques based on similar energy functions. Using windows as support regions for transfer efficiently exploits the training data, as the test image does not need to be globally similar to a training image for the method to work. This enables to compose novel scenes using local parts of training images. Our approach obtains very competitive results on three datasets (PASCAL VOC 2010 segmentation challenge, Weizmann horses, Graz-02)."
            },
            "slug": "Figure-ground-segmentation-by-transferring-window-K\u00fcttel-Ferrari",
            "title": {
                "fragments": [],
                "text": "Figure-ground segmentation by transferring window masks"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel technique for figure-ground segmentation, where the goal is to separate all foreground objects in a test image from the background, by transferring segmentation masks from training windows that are visually similar to windows in the test image."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25633106"
                        ],
                        "name": "Eran Borenstein",
                        "slug": "Eran-Borenstein",
                        "structuredName": {
                            "firstName": "Eran",
                            "lastName": "Borenstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eran Borenstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 141
                            }
                        ],
                        "text": "In segmentation, shape is typically used as a category-specific cue, whereby known object models are integrated with bottom-up grouping cues [6, 7, 11, 12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5558414,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44db1c6eb500984a230e1c07c5b2c8482b6d4c39",
            "isKey": false,
            "numCitedBy": 479,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a novel class-based segmentation method, which is guided by a stored representation of the shape of objects within a general class (such as horse images). The approach is different from bottom-up segmentation methods that primarily use the continuity of grey-level, texture, and bounding contours. We show that the method leads to markedly improved segmentation results and can deal with significant variation in shape and varying backgrounds. We discuss the relative merits of class-specific and general image-based segmentation methods and suggest how they can be usefully combined."
            },
            "slug": "Class-Specific,-Top-Down-Segmentation-Borenstein-Ullman",
            "title": {
                "fragments": [],
                "text": "Class-Specific, Top-Down Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A novel class-based segmentation method, which is guided by a stored representation of the shape of objects within a general class (such as horse images), which leads to markedly improved segmentation results and can deal with significant variation in shape and varying backgrounds."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49835695"
                        ],
                        "name": "Long Zhu",
                        "slug": "Long-Zhu",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144034946"
                        ],
                        "name": "Yuanhao Chen",
                        "slug": "Yuanhao-Chen",
                        "structuredName": {
                            "firstName": "Yuanhao",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuanhao Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 94
                            }
                        ],
                        "text": "In image parsing, hierarchical representations can exploit local parts shared between objects [15, 16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6960041,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "120081166fc0d780c84e198622d638152a7cdf3e",
            "isKey": false,
            "numCitedBy": 294,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a latent hierarchical structural learning method for object detection. An object is represented by a mixture of hierarchical tree models where the nodes represent object parts. The nodes can move spatially to allow both local and global shape deformations. The models can be trained discriminatively using latent structural SVM learning, where the latent variables are the node positions and the mixture component. But current learning methods are slow, due to the large number of parameters and latent variables, and have been restricted to hierarchies with two layers. In this paper we describe an incremental concave-convex procedure (iCCCP) which allows us to learn both two and three layer models efficiently. We show that iCCCP leads to a simple training algorithm which avoids complex multi-stage layer-wise training, careful part selection, and achieves good performance without requiring elaborate initialization. We perform object detection using our learnt models and obtain performance comparable with state-of-the-art methods when evaluated on challenging public PASCAL datasets. We demonstrate the advantages of three layer hierarchies - outperforming Felzenszwalb et al.'s two layer models on all 20 classes."
            },
            "slug": "Latent-hierarchical-structural-learning-for-object-Zhu-Chen",
            "title": {
                "fragments": [],
                "text": "Latent hierarchical structural learning for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper describes an incremental concave-convex procedure (iCCCP) which allows us to learn both two and three layer models efficiently and demonstrates the advantages of three layer hierarchies - outperforming Felzenszwalb et al.'s two layer models on all 20 classes."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756979"
                        ],
                        "name": "K. V. D. Sande",
                        "slug": "K.-V.-D.-Sande",
                        "structuredName": {
                            "firstName": "Koen",
                            "lastName": "Sande",
                            "middleNames": [
                                "E.",
                                "A.",
                                "van",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. V. D. Sande"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1823362"
                        ],
                        "name": "J. Uijlings",
                        "slug": "J.-Uijlings",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Uijlings",
                            "middleNames": [
                                "R.",
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Uijlings"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695527"
                        ],
                        "name": "T. Gevers",
                        "slug": "T.-Gevers",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Gevers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gevers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11442196,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37e41557932cc0035eab23fd767bde68f6475c3a",
            "isKey": false,
            "numCitedBy": 711,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "For object recognition, the current state-of-the-art is based on exhaustive search. However, to enable the use of more expensive features and classifiers and thereby progress beyond the state-of-the-art, a selective search strategy is needed. Therefore, we adapt segmentation as a selective search by reconsidering segmentation: We propose to generate many approximate locations over few and precise object delineations because (1) an object whose location is never generated can not be recognised and (2) appearance and immediate nearby context are most effective for object recognition. Our method is class-independent and is shown to cover 96.7% of all objects in the Pascal VOC 2007 test set using only 1,536 locations per image. Our selective search enables the use of the more expensive bag-of-words method which we use to substantially improve the state-of-the-art by up to 8.5% for 8 out of 20 classes on the Pascal VOC 2010 detection challenge."
            },
            "slug": "Segmentation-as-selective-search-for-object-Sande-Uijlings",
            "title": {
                "fragments": [],
                "text": "Segmentation as selective search for object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work adapt segmentation as a selective search by reconsidering segmentation to generate many approximate locations over few and precise object delineations because an object whose location is never generated can not be recognised and appearance and immediate nearby context are most effective for object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114833718"
                        ],
                        "name": "Xiaofeng Ren",
                        "slug": "Xiaofeng-Ren",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 204
                            }
                        ],
                        "text": "A recent method for figure-ground contour classification discovers prototypical local geometric features, yet it depends on bottom-up cues alone when grouping the labels predicted by each local prototype [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11043721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6aaa3d8f1990fc3d4c97f9b012dd11a4344b4869",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Figure/ground assignment is a key step in perceptual organization which assigns contours to one of the two abutting regions, providing information about occlusion and allowing high-level processing to focus on non-accidental shapes of figural regions. In this paper, we develop a computational model for figure/ground assignment in complex natural scenes. We utilize a large dataset of images annotated with human-marked segmentations and figure/ground labels for training and quantitative evaluation. \n \nWe operationalize the concept of familiar configuration by constructing prototypical local shapes, i.e. shapemes, from image data. Shapemes automatically encode mid-level visual cues to figure/ground assignment such as convexity and parallelism. Based on the shapeme representation, we train a logistic classifier to locally predict figure/ground labels. We also consider a global model using a conditional random field (CRF) to enforce global figure/ground consistency at T-junctions. We use loopy belief propagation to perform approximate inference on this model and learn maximum likelihood parameters from ground-truth labels. \n \nWe find that the local shapeme model achieves an accuracy of 64% in predicting the correct figural assignment. This compares favorably to previous studies using classical figure/ground cues [1]. We evaluate the global model using either a set of contours extracted from a low-level edge detector or the set of contours given by human segmentations. The global CRF model significantly improves the performance over the local model, most notably when using human-marked boundaries (78%). These promising experimental results show that this is a feasible approach to bottom-up figure/ground assignment in natural images."
            },
            "slug": "Figure/Ground-Assignment-in-Natural-Images-Ren-Fowlkes",
            "title": {
                "fragments": [],
                "text": "Figure/Ground Assignment in Natural Images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A computational model for figure/ground assignment in complex natural scenes based on the shapeme representation, which achieves an accuracy of 64% in predicting the correct figural assignment and considers a global model using a conditional random field (CRF) to enforce global figure/Ground consistency at T-junctions."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831988"
                        ],
                        "name": "Ian Endres",
                        "slug": "Ian-Endres",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Endres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian Endres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 111
                            }
                        ],
                        "text": "Also relevant to our work are recent methods that generate category-independent object segmentation hypotheses [3, 4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 124
                            }
                        ],
                        "text": "To focus on raw segmentation quality, we do not consider post-processing with a learned region-ranking function (as in [3], [4]), which could equally benefit all methods, in terms of the number of segments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 197
                            }
                        ],
                        "text": "Final segmentation with graph-cuts: Next we compare our full approach to existing segmentation methods, including the state-of-the-art categoryindependent object segmentation generators of [3] and [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "We also report recall as a function of overlap, following [4], to quantify the percentage of objects recalled at a given covering score."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "In contrast, compared to [4] the trend is a bit flatter, since that method uses not only color but also a local layout cue (see (c) and (d))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "For BSD, we use the ground truth region annotations given by [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 27
                            }
                        ],
                        "text": "The best competing methods [3, 4] also use multi-parametric graph-cuts; so, the additional time required by our method is fairly small and could be reduced further by parallelizing the shape projection step."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 139
                            }
                        ],
                        "text": "This yields multiple segment hypotheses for a given prior, and is in the common spirit of the sequence of parametric min-cuts performed in [3, 4] (though, our focus is to incorporate the shape prior)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 230
                            }
                        ],
                        "text": "Results on the PASCAL 2010 and Berkeley Segmentation datasets show that our approach outperforms not only bottom-up segmentation [10], but also stateof-the-art category-independent region generation methods that lack shape priors [3, 4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 697224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0640da2565bad7037d969e9f07276c10102083d",
            "isKey": true,
            "numCitedBy": 495,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a category-independent method to produce a bag of regions and rank them, such that top-ranked regions are likely to be good segmentations of different objects. Our key objectives are completeness and diversity: every object should have at least one good proposed region, and a diverse set should be top-ranked. Our approach is to generate a set of segmentations by performing graph cuts based on a seed region and a learned affinity function. Then, the regions are ranked using structured learning based on various cues. Our experiments on BSDS and PASCAL VOC 2008 demonstrate our ability to find most objects within a small bag of proposed regions."
            },
            "slug": "Category-Independent-Object-Proposals-Endres-Hoiem",
            "title": {
                "fragments": [],
                "text": "Category Independent Object Proposals"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A category-independent method to produce a bag of regions and rank them, such that top-ranked regions are likely to be good segmentations of different objects, and the ability to find most objects within a small bag of proposed regions is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3188179"
                        ],
                        "name": "A. Opelt",
                        "slug": "A.-Opelt",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Opelt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Opelt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718587"
                        ],
                        "name": "A. Pinz",
                        "slug": "A.-Pinz",
                        "structuredName": {
                            "firstName": "Axel",
                            "lastName": "Pinz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pinz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 111
                            }
                        ],
                        "text": "In object detection, jointly training multi-class detectors allows the reuse of common discriminative features [13, 14]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 673415,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3c48c85c9da6441547288f48ae9735f1ff2016e",
            "isKey": false,
            "numCitedBy": 208,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of multiclass object detection. Our aims are to enable models for new categories to benefit from the detectors built previously for other categories, and for the complexity of the multiclass system to grow sublinearly with the number of categories. To this end we introduce a visual alphabet representation which can be learnt incrementally, and explicitly shares boundary fragments (contours) and spatial configurations (relation to centroid) across object categories. We develop a learning algorithm with the following novel contributions: (i) AdaBoost is adapted to learn jointly, based on shape features; (ii) a new learning schedule enables incremental additions of new categories; and (iii) the algorithm learns to detect objects (instead of categorizing images). Furthermore, we show that category similarities can be predicted from the alphabet. We obtain excellent experimental results on a variety of complex categories over several visual aspects. We show that the sharing of shape features not only reduces the number of features required per category, but also often improves recognition performance, as compared to individual detectors which are trained on a per-class basis."
            },
            "slug": "Incremental-learning-of-object-detectors-using-a-Opelt-Pinz",
            "title": {
                "fragments": [],
                "text": "Incremental learning of object detectors using a visual shape alphabet"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A visual alphabet representation which can be learnt incrementally, and explicitly shares boundary fragments and spatial configurations across object categories, and shows that category similarities can be predicted from the alphabet."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 138
                            }
                        ],
                        "text": "In object recognition, model parameters learned on one set of categories can be transferred to more efficiently learn new related objects [17, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2096065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d044d7d92dd1fb80275d04d035aed71bcd3374e5",
            "isKey": false,
            "numCitedBy": 556,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning visual models of object categories notoriously requires thousands of training examples; this is due to the diversity and richness of object appearance which requires models containing hundreds of parameters. We present a method for learning object categories from just a few images (1 /spl sim/ 5). It is based on incorporating \"generic\" knowledge which may be obtained from previously learnt models of unrelated categories. We operate in a variational Bayesian framework: object categories are represented by probabilistic models, and \"prior\" knowledge is represented as a probability density function on the parameters of these models. The \"posterior\" model for an object category is obtained by updating the prior in the light of one or more observations. Our ideas are demonstrated on four diverse categories (human faces, airplanes, motorcycles, spotted cats). Initially three categories are learnt from hundreds of training examples, and a \"prior\" is estimated from these. Then the model of the fourth category is learnt from 1 to 5 training examples, and is used for detecting new exemplars a set of test images."
            },
            "slug": "A-Bayesian-approach-to-unsupervised-one-shot-of-Fei-Fei-Fergus",
            "title": {
                "fragments": [],
                "text": "A Bayesian approach to unsupervised one-shot learning of object categories"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents a method for learning object categories from just a few images, based on incorporating \"generic\" knowledge which may be obtained from previously learnt models of unrelated categories, in a variational Bayesian framework."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206769405,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ae89592317675c9c7642a3976c3a064cef736f92",
            "isKey": false,
            "numCitedBy": 757,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Many computer vision algorithms limit their performance by ignoring the underlying 3D geometric structure in the image. We show that we can estimate the coarse geometric properties of a scene by learning appearance-based models of geometric classes, even in cluttered natural scenes. Geometric classes describe the 3D orientation of an image region with respect to the camera. We provide a multiple-hypothesis framework for robustly estimating scene structure from a single image and obtaining confidences for each geometric label. These confidences can then be used to improve the performance of many other applications. We provide a thorough quantitative evaluation of our algorithm on a set of outdoor images and demonstrate its usefulness in two applications: object detection and automatic single-view reconstruction."
            },
            "slug": "Geometric-context-from-a-single-image-Hoiem-Efros",
            "title": {
                "fragments": [],
                "text": "Geometric context from a single image"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work shows that it can estimate the coarse geometric properties of a scene by learning appearance-based models of geometric classes, even in cluttered natural scenes, and provides a multiple-hypothesis framework for robustly estimating scene structure from a single image and obtaining confidences for each geometric label."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37895334"
                        ],
                        "name": "S. Fidler",
                        "slug": "S.-Fidler",
                        "structuredName": {
                            "firstName": "Sanja",
                            "lastName": "Fidler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fidler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765505"
                        ],
                        "name": "M. Boben",
                        "slug": "M.-Boben",
                        "structuredName": {
                            "firstName": "Marko",
                            "lastName": "Boben",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Boben"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732672"
                        ],
                        "name": "A. Leonardis",
                        "slug": "A.-Leonardis",
                        "structuredName": {
                            "firstName": "Ale\u0161",
                            "lastName": "Leonardis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Leonardis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 94
                            }
                        ],
                        "text": "In image parsing, hierarchical representations can exploit local parts shared between objects [15, 16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3036784,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c09c802d6eb88ef9e29788df47247c9a329eac7c",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new concept in hierarchical representations that exploits features of different granularity and specificity coming from all layers of the hierarchy. The concept is realized within a cross-layered compositional representation learned from the visual data. We show how similarity connections among discrete labels within and across hierarchical layers can be established in order to produce a set of layer-independent shape-terminals, i.e. shapinals. We thus break the traditional notion of hierarchies and show how the category-specific layers can make use of all the necessary features stemming from all hierarchical layers. This, on the one hand, brings higher generalization into the representation, yet on the other hand, it also encodes the notion of scales directly into the hierarchy, thus enabling a multi-scale representation of object categories. By focusing on shape information only, the approach is tested on the Caltech 101 dataset demonstrating good performance in comparison with other state-of-the-art methods."
            },
            "slug": "Similarity-based-cross-layered-hierarchical-for-Fidler-Boben",
            "title": {
                "fragments": [],
                "text": "Similarity-based cross-layered hierarchical representation for object categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is shown how similarity connections among discrete labels within and across hierarchical layers can be established in order to produce a set of layer-independent shape-terminals, i.e. shapinals, thus enabling a multi-scale representation of object categories."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36668046"
                        ],
                        "name": "Bill Freeman",
                        "slug": "Bill-Freeman",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Freeman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bill Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 62
                            }
                        ],
                        "text": "Some recent work tackles segmentation in a data-driven manner [22, 23], using image-level matching to gather exemplars with similar scene layouts, and then combining them with graph-cuts to preserve spatial coherence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2621730,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03a112100cca059efff3964de17c49697de49730",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we investigate how, given an image, similar images sharing the same global description can help with unsupervised scene segmentation. In contrast to recent work in semantic alignment of scenes, we allow an input image to be explained by partial matches of similar scenes. This allows for a better explanation of the input scenes. We perform MRF-based segmentation that optimizes over matches, while respecting boundary information. The recovered segments are then used to re-query a large database of images to retrieve better matches for the target regions. We show improved performance in detecting the principal occluding and contact boundaries for the scene over previous methods on data gathered from the LabelMe database."
            },
            "slug": "Segmenting-Scenes-by-Matching-Image-Composites-Russell-Efros",
            "title": {
                "fragments": [],
                "text": "Segmenting Scenes by Matching Image Composites"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper performs MRF-based segmentation that optimizes over matches, while respecting boundary information, and shows improved performance in detecting the principal occluding and contact boundaries for the scene over previous methods on data gathered from the LabelMe database."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 156
                            }
                        ],
                        "text": "On the other hand, contour-based seeding respects the object shapes, and is motivated by how users tend to manually give seeds for interactive segmentation [28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 1
                            }
                        ],
                        "text": ",[28]: the cost of assigning different labels to neighboring pixels is inversely proportional to the strength of the contour at that position."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6202829,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f26d35d2e32934150cd27b030d4d769942126184",
            "isKey": false,
            "numCitedBy": 5202,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of efficient, interactive foreground/background segmentation in still images is of great practical importance in image editing. Classical image segmentation tools use either texture (colour) information, e.g. Magic Wand, or edge (contrast) information, e.g. Intelligent Scissors. Recently, an approach based on optimization by graph-cut has been developed which successfully combines both types of information. In this paper we extend the graph-cut approach in three respects. First, we have developed a more powerful, iterative version of the optimisation. Secondly, the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result. Thirdly, a robust algorithm for \"border matting\" has been developed to estimate simultaneously the alpha-matte around an object boundary and the colours of foreground pixels. We show that for moderately difficult examples the proposed method outperforms competitive tools."
            },
            "slug": "\"GrabCut\":-interactive-foreground-extraction-using-Rother-Kolmogorov",
            "title": {
                "fragments": [],
                "text": "\"GrabCut\": interactive foreground extraction using iterated graph cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A more powerful, iterative version of the optimisation of the graph-cut approach is developed and the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2599292"
                        ],
                        "name": "J. Mairal",
                        "slug": "J.-Mairal",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Mairal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mairal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749627"
                        ],
                        "name": "M. Leordeanu",
                        "slug": "M.-Leordeanu",
                        "structuredName": {
                            "firstName": "Marius",
                            "lastName": "Leordeanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Leordeanu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144570279"
                        ],
                        "name": "F. Bach",
                        "slug": "F.-Bach",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18747497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b11f559432f453fb801befe5e43768a97855c8ca",
            "isKey": false,
            "numCitedBy": 230,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Sparse signal models learned from data are widely used in audio, image, and video restoration. They have recently been generalized to discriminative image understanding tasks such as texture segmentation and feature selection. This paper extends this line of research by proposing a multiscale method to minimize least-squares reconstruction errors and discriminative cost functions under ?0 or ?1 regularization constraints. It is applied to edge detection, category-based edge selection and image classification tasks. Experiments on the Berkeley edge detection benchmark and the PASCAL VOC'05 and VOC'07 datasets demonstrate the computational efficiency of our algorithm and its ability to learn local image descriptions that effectively support demanding computer vision tasks."
            },
            "slug": "Discriminative-Sparse-Image-Models-for-Edge-and-Mairal-Leordeanu",
            "title": {
                "fragments": [],
                "text": "Discriminative Sparse Image Models for Class-Specific Edge Detection and Image Interpretation"
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9739979"
                        ],
                        "name": "P. Arbel\u00e1ez",
                        "slug": "P.-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Arbel\u00e1ez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1505240324"
                        ],
                        "name": "C. Fowlkes",
                        "slug": "C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charlotte",
                            "lastName": "Fowlkes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787589"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 259,
                                "start": 255
                            }
                        ],
                        "text": "We compare against two existing methods on the PASCAL data: (1) a merging method that combines pairs and triples of neighboring superpixels, without considering layout or shape [2], and (2) the state-of-the-art bottom-up hierarchal segmentation algorithm [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "For superpixels, we use the output of gPb-owt-ucm [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 92
                            }
                        ],
                        "text": "Evaluation metrics: To evaluate segmentation quality, we use the covering metric, following [10, 3], which is the average best overlapping score between ground-truth and generated segments, weighted by object size."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "We ignore any boundary pixels having weak gPb [10] values."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "also entails merging superpixels but lacks top-down shape cues, while [10] provides the original regions to both merging methods."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "To describe the shape of each detected region, we extract a pHOG descriptor computed on a gPb [10] contour map, which captures both boundary shape and coarse inner texture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "Results on the PASCAL 2010 and Berkeley Segmentation datasets show that our approach outperforms not only bottom-up segmentation [10], but also stateof-the-art category-independent region generation methods that lack shape priors [3, 4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206764694,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e5a262bf59b68ba8a7a1103d16fa33a9f5ffc28",
            "isKey": true,
            "numCitedBy": 4197,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates two fundamental problems in computer vision: contour detection and image segmentation. We present state-of-the-art algorithms for both of these tasks. Our contour detector combines multiple local cues into a globalization framework based on spectral clustering. Our segmentation algorithm consists of generic machinery for transforming the output of any contour detector into a hierarchical region tree. In this manner, we reduce the problem of image segmentation to that of contour detection. Extensive experimental evaluation demonstrates that both our contour detection and segmentation methods significantly outperform competing algorithms. The automatically generated hierarchical segmentations can be interactively refined by user-specified annotations. Computation at multiple image resolutions provides a means of coupling our system to recognition applications."
            },
            "slug": "Contour-Detection-and-Hierarchical-Image-Arbel\u00e1ez-Maire",
            "title": {
                "fragments": [],
                "text": "Contour Detection and Hierarchical Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper investigates two fundamental problems in computer vision: contour detection and image segmentation and presents state-of-the-art algorithms for both of these tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 111
                            }
                        ],
                        "text": "In object detection, jointly training multi-class detectors allows the reuse of common discriminative features [13, 14]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2741819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd626564bd47e9fc67a5b276301282ba2fe3d833",
            "isKey": false,
            "numCitedBy": 793,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of detecting a large number of different classes of objects in cluttered scenes. Traditional approaches require applying a battery of different classifiers to the image, at multiple locations and scales. This can be slow and can require a lot of training data since each classifier requires the computation of many different image features. In particular, for independently trained detectors, the (runtime) computational complexity and the (training-time) sample complexity scale linearly with the number of classes to be detected. We present a multitask learning procedure, based on boosted decision stumps, that reduces the computational and sample complexity by finding common features that can be shared across the classes (and/or views). The detectors for each class are trained jointly, rather than independently. For a given performance level, the total number of features required and, therefore, the runtime cost of the classifier, is observed to scale approximately logarithmically with the number of classes. The features selected by joint training are generic edge-like features, whereas the features chosen by training each class separately tend to be more object-specific. The generic features generalize better and considerably reduce the computational cost of multiclass object detection"
            },
            "slug": "Sharing-Visual-Features-for-Multiclass-and-Object-Torralba-Murphy",
            "title": {
                "fragments": [],
                "text": "Sharing Visual Features for Multiclass and Multiview Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A multitask learning procedure, based on boosted decision stumps, that reduces the computational and sample complexity by finding common features that can be shared across the classes (and/or views) and considerably reduce the computational cost of multiclass object detection."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299972"
                        ],
                        "name": "I. Biederman",
                        "slug": "I.-Biederman",
                        "structuredName": {
                            "firstName": "Irving",
                            "lastName": "Biederman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Biederman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": ", Gestalt cues like symmetry [19], or handcrafted geometric primitives [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8054340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b37258659bcdbc380b1e6c4e22cce9ea06397a1",
            "isKey": false,
            "numCitedBy": 5632,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "The perceptual recognition of objects is conceptualized to be a process in which the image of the input is segmented at regions of deep concavity into an arrangement of simple geometric components, such as blocks, cylinders, wedges, and cones. The fundamental assumption of the proposed theory, recognition-by-components (RBC), is that a modest set of generalized-cone components, called geons (N \u00a3 36), can be derived from contrasts of five readily detectable properties of edges in a two-dimensiona l image: curvature, collinearity, symmetry, parallelism, and cotermination. The detection of these properties is generally invariant over viewing position an$ image quality and consequently allows robust object perception when the image is projected from a novel viewpoint or is degraded. RBC thus provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition: The constraints toward regularization (Pragnanz) characterize not the complete object but the object's components. Representational power derives from an allowance of free combinations of the geons. A Principle of Componential Recovery can account for the major phenomena of object recognition: If an arrangement of two or three geons can be recovered from the input, objects can be quickly recognized even when they are occluded, novel, rotated in depth, or extensively degraded. The results from experiments on the perception of briefly presented pictures by human observers provide empirical support for the theory. Any single object can project an infinity of image configurations to the retina. The orientation of the object to the viewer can vary continuously, each giving rise to a different two-dimensional projection. The object can be occluded by other objects or texture fields, as when viewed behind foliage. The object need not be presented as a full-colored textured image but instead can be a simplified line drawing. Moreover, the object can even be missing some of its parts or be a novel exemplar of its particular category. But it is only with rare exceptions that an image fails to be rapidly and readily classified, either as an instance of a familiar object category or as an instance that cannot be so classified (itself a form of classification)."
            },
            "slug": "Recognition-by-components:-a-theory-of-human-image-Biederman",
            "title": {
                "fragments": [],
                "text": "Recognition-by-components: a theory of human image understanding."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Recognition-by-components (RBC) provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145246674"
                        ],
                        "name": "A. Heyden",
                        "slug": "A.-Heyden",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Heyden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Heyden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2561175"
                        ],
                        "name": "G. Sparr",
                        "slug": "G.-Sparr",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "Sparr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sparr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145118299"
                        ],
                        "name": "M. Nielsen",
                        "slug": "M.-Nielsen",
                        "structuredName": {
                            "firstName": "Mads",
                            "lastName": "Nielsen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nielsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153623949"
                        ],
                        "name": "P. Johansen",
                        "slug": "P.-Johansen",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Johansen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Johansen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19228750,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "435ace68aa855103d76f869a88d34fee0771383b",
            "isKey": false,
            "numCitedBy": 1087,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel algorithm for recovering a smooth manifold of unknown dimension and topology from a set of points known to belong to it. Numerous applications in computer vision can be naturally interpreted as instanciations of this fundamental problem. Recently, a non-iterative discrete approach, tensor voting, has been introduced to solve this problem and has been applied successfully to various applications. As an alternative, we propose a variational formulation of this problem in the continuous setting and derive an iterative algorithm which approximates its solutions. This method and tensor voting are somewhat the differential and integral form of one another. Although iterative methods are slower in general, the strength of the suggested method is that it can easily be applied when the ambient space is not Euclidean, which is important in many applications. The algorithm consists in solving a partial differential equation that performs a special anisotropic diffusion on an implicit representation of the known set of points. This results in connecting isolated neighbouring points. This approach is very simple, mathematically sound, robust and powerful since it handles in a homogeneous way manifolds of arbitrary dimension and topology, embedded in Euclidean or non-Euclidean spaces, with or without border. We shall present this approach and demonstrate both its benefits and shortcomings in two different contexts: (i) data visual analysis, (ii) skin detection in color images."
            },
            "slug": "Computer-Vision-\u2014-ECCV-2002-Heyden-Sparr",
            "title": {
                "fragments": [],
                "text": "Computer Vision \u2014 ECCV 2002"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A novel algorithm for recovering a smooth manifold of unknown dimension and topology from a set of points known to belong to it is presented and it can easily be applied when the ambient space is not Euclidean, which is important in many applications."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2658890"
                        ],
                        "name": "Marius Muja",
                        "slug": "Marius-Muja",
                        "structuredName": {
                            "firstName": "Marius",
                            "lastName": "Muja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marius Muja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "To efficiently identify nearest neighbor matches, we use FLANN [29]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7317448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35d81066cb1369acf4b6c5117fcbb862be2af350",
            "isKey": false,
            "numCitedBy": 2833,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "For many computer vision problems, the most time consuming component consists of nearest neighbor matching in high-dimensional spaces. There are no known exact algorithms for solving these high-dimensional problems that are faster than linear search. Approximate algorithms are known to provide large speedups with only minor loss in accuracy, but many such algorithms have been published with only minimal guidance on selecting an algorithm and its parameters for any given problem. In this paper, we describe a system that answers the question, \u201cWhat is the fastest approximate nearest-neighbor algorithm for my data?\u201d Our system will take any given dataset and desired degree of precision and use these to automatically determine the best algorithm and parameter values. We also describe a new algorithm that applies priority search on hierarchical k-means trees, which we have found to provide the best known performance on many datasets. After testing a range of alternatives, we have found that multiple randomized k-d trees provide the best performance for other datasets. We are releasing public domain code that implements these approaches. This library provides about one order of magnitude improvement in query time over the best previously available software and provides fully automated parameter selection."
            },
            "slug": "Fast-Approximate-Nearest-Neighbors-with-Automatic-Muja-Lowe",
            "title": {
                "fragments": [],
                "text": "Fast Approximate Nearest Neighbors with Automatic Algorithm Configuration"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A system that answers the question, \u201cWhat is the fastest approximate nearest-neighbor algorithm for my data?\u201d and a new algorithm that applies priority search on hierarchical k-means trees, which is found to provide the best known performance on many datasets."
            },
            "venue": {
                "fragments": [],
                "text": "VISAPP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144760431"
                        ],
                        "name": "Charlie Rothwell",
                        "slug": "Charlie-Rothwell",
                        "structuredName": {
                            "firstName": "Charlie",
                            "lastName": "Rothwell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charlie Rothwell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3453447"
                        ],
                        "name": "J. Mundy",
                        "slug": "J.-Mundy",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Mundy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mundy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": ", in early model-based recognition [26] or voting-based implicit shape models [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 837592,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "20cd1111991abc6ee4252877b9a6a732720c7019",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a canonical frame construction for determining projectively invariant indexing functions for non-algebraic smooth plane curves. These invariants are semi-local rather than global, which promotes tolerance to occlusion."
            },
            "slug": "Canonical-Frames-for-Planar-Object-Recognition-Rothwell-Zisserman",
            "title": {
                "fragments": [],
                "text": "Canonical Frames for Planar Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A canonical frame construction is presented for determining projectively invariant indexing functions for non-algebraic smooth plane curves that are semi-local rather than global, which promotes tolerance to occlusion."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678909"
                        ],
                        "name": "G. Sandini",
                        "slug": "G.-Sandini",
                        "structuredName": {
                            "firstName": "Giulio",
                            "lastName": "Sandini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sandini"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29749335,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f636462eeff5553a5077e23c6349b5ef0513c9f",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-Vision-\u2014-ECCV'92-Sandini",
            "title": {
                "fragments": [],
                "text": "Computer Vision \u2014 ECCV'92"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112683288"
                        ],
                        "name": "Srinath Sridhar",
                        "slug": "Srinath-Sridhar",
                        "structuredName": {
                            "firstName": "Srinath",
                            "lastName": "Sridhar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Srinath Sridhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49876729"
                        ],
                        "name": "Franziska Mueller",
                        "slug": "Franziska-Mueller",
                        "structuredName": {
                            "firstName": "Franziska",
                            "lastName": "Mueller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Franziska Mueller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699058"
                        ],
                        "name": "M. Zollh\u00f6fer",
                        "slug": "M.-Zollh\u00f6fer",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Zollh\u00f6fer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zollh\u00f6fer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1863006"
                        ],
                        "name": "D. Casas",
                        "slug": "D.-Casas",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Casas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Casas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2663734"
                        ],
                        "name": "Antti Oulasvirta",
                        "slug": "Antti-Oulasvirta",
                        "structuredName": {
                            "firstName": "Antti",
                            "lastName": "Oulasvirta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antti Oulasvirta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680185"
                        ],
                        "name": "C. Theobalt",
                        "slug": "C.-Theobalt",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Theobalt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Theobalt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5238630,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fdbcf7d898f25bb745519e705ed31b2327ff24e7",
            "isKey": false,
            "numCitedBy": 879,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-Vision-\u2013-ECCV-2006-Sridhar-Mueller",
            "title": {
                "fragments": [],
                "text": "Computer Vision \u2013 ECCV 2006"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2006
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 10
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Shape-Sharing-for-Object-Segmentation-Kim-Grauman/5e8a94e91ed5e5c154021dfa917b8357746d20da?sort=total-citations"
}