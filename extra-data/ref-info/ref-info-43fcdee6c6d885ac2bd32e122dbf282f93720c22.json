{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6686370,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e85a68602abf92fcc1efb8b7aa90d27d141a80c2",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 149,
            "paperAbstract": {
                "fragments": [],
                "text": "A test sequence is used to select the best rule from a class of discrimination rules defined in terms of the training sequence. The Vapnik-Chervonenkis and related inequalities are used to obtain distribution-free bounds on the difference between the probability of error of the selected rule and the probability of error of the best rule in the given class. The bounds are used to prove the consistency and asymptotic optimality for several popular classes, including linear discriminators, nearest-neighbor rules, kernel-based rules, histogram rules, binary tree classifiers, and Fourier series classifiers. In particular, the method can be used to choose the smoothing parameter in kernel-based rules, to choose k in the k-nearest neighbor rule, and to choose between parametric and nonparametric rules. >"
            },
            "slug": "Automatic-Pattern-Recognition:-A-Study-of-the-of-Devroye",
            "title": {
                "fragments": [],
                "text": "Automatic Pattern Recognition: A Study of the Probability of Error"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The Vapnik-Chervonenkis method can be used to choose the smoothing parameter in kernel-based rules, to choose k in the k-nearest neighbor rule, and to choose between parametric and nonparametric rules."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117814422,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "7f0d78ecef08f57afc544cbb56b8f60c7d02b0e6",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The asymptotic properties of generalized nearest neighbor rules and other nonparametric discrimination rules are investigated. The problem is to estimate an M-ary valued parameter theta if an observed random vector X and data consisting of a sequence of independent random vectors (X sub 1, theta sub 1) (X sub n, theta sub n) with the same distrubition as (X, theta) are given. Conditions are given under which the rules are asymptotically optimal. Consistent density estimates can be used to construct asymptotically optimal rules if the distribution function of X is absolutely continuous. A detailed study is made of the pointwise, integral and uniform convergence of the Parzen-Rosenblatt and Loftsgaarden-Quesenberry density estimates. In addition, methods of estimating the conditional probability of error with a particular data set are given. For linear discrimination rules, local rules and two-step rules, estimates are found whose performance is bounded independently of the distribution of (X theta). (Author)"
            },
            "slug": "Nonparametric-Discrimination-and-Density-Devroye",
            "title": {
                "fragments": [],
                "text": "Nonparametric Discrimination and Density Estimation."
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "The asymptotic properties of generalized nearest neighbor rules and other nonparametric discrimination rules are investigated and estimates are found whose performance is bounded independently of the distribution of (X theta)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2106306019"
                        ],
                        "name": "Tsvi Lissack",
                        "slug": "Tsvi-Lissack",
                        "structuredName": {
                            "firstName": "Tsvi",
                            "lastName": "Lissack",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsvi Lissack"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97306284"
                        ],
                        "name": "K. Fu",
                        "slug": "K.-Fu",
                        "structuredName": {
                            "firstName": "King-Sun",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10834315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b83d0c4b3806ca2f57243e2e89c46eada9580b5",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The L^{ \\alpha} -distance between posterior density functions (PDF's) is proposed as a separability measure to replace the probability of error as a criterion for feature extraction in pattern recognition. Upper and lower bounds on Bayes error are derived for \\alpha > 0 . If \\alpha = 1 , the lower and upper bounds coincide; an increase (or decrease) in \\alpha loosens these bounds. For \\alpha = 2 , the upper bound equals the best commonly used bound and is equal to the asymptotic probability of error of the first nearest neighbor classifier. The case when \\alpha = 1 is used for estimation of the probability of error in different problem situations, and a comparison is made with other methods. It is shown how unclassified samples may also be used to improve the variance of the estimated error. For the family of exponential probability density functions (pdf's), the relation between the distance of a sample from the decision boundary and its contribution to the error is derived. In the nonparametric case, a consistent estimator is discussed which is computationally more efficient than estimators based on Parzen's estimation. A set of computer simulation experiments are reported to demonstrate the statistical advantages of the separability measure with \\alpha = 1 when used in an error estimation scheme."
            },
            "slug": "Error-estimation-in-pattern-recognition-via-LAlpha-Lissack-Fu",
            "title": {
                "fragments": [],
                "text": "Error estimation in pattern recognition via LAlpha -distance between posterior density functions"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A consistent estimator is discussed which is computationally more efficient than estimators based on Parzen's estimation and its relation between the distance of a sample from the decision boundary and its contribution to the error is derived."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5246200,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "0efb841403aa6252b39ae6975c1cc5410554ef7b",
            "isKey": false,
            "numCitedBy": 10768,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The nearest neighbor decision rule assigns to an unclassified sample point the classification of the nearest of a set of previously classified points. This rule is independent of the underlying joint distribution on the sample points and their classifications, and hence the probability of error R of such a rule must be at least as great as the Bayes probability of error R^{\\ast} --the minimum probability of error over all decision rules taking underlying probability structure into account. However, in a large sample analysis, we will show in the M -category case that R^{\\ast} \\leq R \\leq R^{\\ast}(2 --MR^{\\ast}/(M-1)) , where these bounds are the tightest possible, for all suitably smooth underlying distributions. Thus for any number of categories, the probability of error of the nearest neighbor rule is bounded above by twice the Bayes probability of error. In this sense, it may be said that half the classification information in an infinite sample set is contained in the nearest neighbor."
            },
            "slug": "Nearest-neighbor-pattern-classification-Cover-Hart",
            "title": {
                "fragments": [],
                "text": "Nearest neighbor pattern classification"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "The nearest neighbor decision rule assigns to an unclassified sample point the classification of the nearest of a set of previously classified points, so it may be said that half the classification information in an infinite sample set is contained in the nearest neighbor."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38794960"
                        ],
                        "name": "Dennis L. Wilson",
                        "slug": "Dennis-L.-Wilson",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Wilson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dennis L. Wilson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6699477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dea8658ee4750ec6bb408a2281cf922cbb300a0a",
            "isKey": false,
            "numCitedBy": 1559,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The convergence properties of a nearest neighbor rule that uses an editing procedure to reduce the number of preclassified samples and to improve the performance of the rule are developed. Editing of the preclassified samples using the three-nearest neighbor rule followed by classification using the single-nearest neighbor rule with the remaining preclassified samples appears to produce a decision procedure whose risk approaches the Bayes' risk quite closely in many problems with only a few preclassified samples. The asymptotic risk of the nearest neighbor rules and the nearest neighbor rules using edited preclassified samples is calculated for several problems."
            },
            "slug": "Asymptotic-Properties-of-Nearest-Neighbor-Rules-Wilson",
            "title": {
                "fragments": [],
                "text": "Asymptotic Properties of Nearest Neighbor Rules Using Edited Data"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The convergence properties of a nearest neighbor rule that uses an editing procedure to reduce the number of preclassified samples and to improve the performance of the rule are developed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087848"
                        ],
                        "name": "R. Dubes",
                        "slug": "R.-Dubes",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dubes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dubes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830341"
                        ],
                        "name": "Chaur-Chin Chen",
                        "slug": "Chaur-Chin-Chen",
                        "structuredName": {
                            "firstName": "Chaur-Chin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chaur-Chin Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15415663,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "832b00e86a2cf638124128825210ab7789c7b7f6",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The design of a pattern recognition system requires careful attention to error estimation. The error rate is the most important descriptor of a classifier's performance. The commonly used estimates of error rate are based on the holdout method, the resubstitution method, and the leave-one-out method. All suffer either from large bias or large variance and their sample distributions are not known. Bootstrapping refers to a class of procedures that resample given data by computer. It permits determining the statistical properties of an estimator when very little is known about the underlying distribution and no additional samples are available. Since its publication in the last decade, the bootstrap technique has been successfully applied to many statistical estimations and inference problems. However, it has not been exploited in the design of pattern recognition systems. We report results on the application of several bootstrap techniques in estimating the error rate of 1-NN and quadratic classifiers. Our experiments show that, in most cases, the confidence interval of a bootstrap estimator of classification error is smaller than that of the leave-one-out estimator. The error of 1-NN, quadratic, and Fisher classifiers are estimated for several real data sets."
            },
            "slug": "Bootstrap-Techniques-for-Error-Estimation-Jain-Dubes",
            "title": {
                "fragments": [],
                "text": "Bootstrap Techniques for Error Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Results on the application of several bootstrap techniques in estimating the error rate of 1-NN and quadratic classifiers show that, in most cases, the confidence interval of a bootstrap estimator of classification error is smaller than that of the leave-one-out estimator."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940156"
                        ],
                        "name": "T. Wagner",
                        "slug": "T.-Wagner",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Wagner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wagner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38912495,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "942f37ae066e1db5b6660241c84e689d2f6b5c20",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "If the nearest neighbor rule is used to classify unknown samples then Cover and Hart have shown that the average probability of error using n known samples (denoted by Rn)converges to a number R as n tends to infinity where R* ? R ? 2R* (1-R*) and R* is the Bayes probability of error. Here it is shown that when the samples lie in n-dimensional Euclidean space, the probability of error for the nearest nearest neighbor rule conditioned on the n known samples (denoted by Ln so that ELn = Rn) converges to R with probability 1 for mild continuity and moment assumptions on the class densities. Two estimates of R from the n known samples are shown to be consistent. Rates of convergence of Ln to R are also given."
            },
            "slug": "Convergence-of-the-nearest-neighbor-rule-Wagner",
            "title": {
                "fragments": [],
                "text": "Convergence of the nearest neighbor rule"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that when the samples lie in n-dimensional Euclidean space, the probability of error for the nearest nearest neighbor rule conditioned on the n known samples converges to R with probability 1 for mild continuity and moment assumptions on the class densities."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490865"
                        ],
                        "name": "E. Patrick",
                        "slug": "E.-Patrick",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Patrick",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Patrick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35178972"
                        ],
                        "name": "F. P. Fischer",
                        "slug": "F.-P.-Fischer",
                        "structuredName": {
                            "firstName": "Frederic",
                            "lastName": "Fischer",
                            "middleNames": [
                                "P."
                            ],
                            "suffix": "II"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. P. Fischer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 38982246,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d57e30df0bd0ac93915c06ca1a46a64f26e4662",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Generalized-k-Nearest-Neighbor-Rule-Patrick-Fischer",
            "title": {
                "fragments": [],
                "text": "A Generalized k-Nearest Neighbor Rule"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Control."
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765522"
                        ],
                        "name": "J. Sklansky",
                        "slug": "J.-Sklansky",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Sklansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sklansky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2888714"
                        ],
                        "name": "L. Michelotti",
                        "slug": "L.-Michelotti",
                        "structuredName": {
                            "firstName": "Leo",
                            "lastName": "Michelotti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Michelotti"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2759396,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24cb005e52250a0364c132b87dc33d43a82ed886",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a versatile technique for designing computer algorithms for separating multiple-dimensional data (feature vectors) into two classes. We refer to these algorithms as classifiers. Our classifiers achieve nearly Bayes-minimum error rates while requiring relatively small amounts of memory. Our design procedure finds a set of close-opposed pairs of clusters of data. From these pairs the procedure generates a piecewise-linear approximation of the Bayes-optimum decision surface. A window training procedure on each linear segment of the approximation provides great flexibility of design over a wide range of class densities. The data consumed in the training of each segment are restricted to just those data lying near that segment, which makes possible the construction of efficient data bases for the training process. Interactive simplification of the classifier is facilitated by an adjacency matrix and an incidence matrix. The adjacency matrix describes the interrelationships of the linear segments {\u00a3i}. The incidence matrix describes the interrelationships among the polyhedrons formed by the hyperplanes containing {\u00a3i}. We exploit switching theory to minimize the decision logic."
            },
            "slug": "Locally-Trained-Piecewise-Linear-Classifiers-Sklansky-Michelotti",
            "title": {
                "fragments": [],
                "text": "Locally Trained Piecewise Linear Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A versatile technique for designing computer algorithms for separating multiple-dimensional data (feature vectors) into two classes, referred to as classifiers, that achieve nearly Bayes-minimum error rates while requiring relatively small amounts of memory."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707376"
                        ],
                        "name": "S. Geva",
                        "slug": "S.-Geva",
                        "structuredName": {
                            "firstName": "Shlomo",
                            "lastName": "Geva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731763"
                        ],
                        "name": "J. Sitte",
                        "slug": "J.-Sitte",
                        "structuredName": {
                            "firstName": "Joaquin",
                            "lastName": "Sitte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sitte"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23742950,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb9b68ce8eec6f974c41529face7730465fc6988",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A variant of nearest-neighbor (NN) pattern classification and supervised learning by learning vector quantization (LVQ) is described. The decision surface mapping method (DSM) is a fast supervised learning algorithm and is a member of the LVQ family of algorithms. A relatively small number of prototypes are selected from a training set of correctly classified samples. The training set is then used to adapt these prototypes to map the decision surface separating the classes. This algorithm is compared with NN pattern classification, learning vector quantization, and a two-layer perceptron trained by error backpropagation. When the class boundaries are sharply defined (i.e., no classification error in the training set), the DSM algorithm outperforms these methods with respect to error rates, learning rates, and the number of prototypes required to describe class boundaries."
            },
            "slug": "Adaptive-nearest-neighbor-pattern-classification-Geva-Sitte",
            "title": {
                "fragments": [],
                "text": "Adaptive nearest neighbor pattern classification"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A variant of nearest-neighbor (NN) pattern classification and supervised learning by learning vector quantization (LVQ) is described and the DSM algorithm outperforms these methods with respect to error rates, learning rates, and the number of prototypes required to describe class boundaries."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755694"
                        ],
                        "name": "G. Lugosi",
                        "slug": "G.-Lugosi",
                        "structuredName": {
                            "firstName": "G\u00e1bor",
                            "lastName": "Lugosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lugosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143803534"
                        ],
                        "name": "M. Pawlak",
                        "slug": "M.-Pawlak",
                        "structuredName": {
                            "firstName": "Miroslaw",
                            "lastName": "Pawlak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pawlak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 195866108,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "4e3dd5e0773658ba6ac65c50981a9bf09bef93ff",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of estimating the error probability of nonparametric classification rules. Instead of the well known counting-type estimators we propose a so called posterior probability estimator, which plugs a nonparametric estimate of the a posteriori probabilities into an algebraic expression of the error probability. We explore the properties of the plug-in estimator. Unlike the standard estimators, the variance of our estimator is shown to have some remarkable distribution-free properties for the k-nearest neighbor, kernel and histogram roles. We pay special attention of histogram classification rules, and show the consistency of the estimate in this case. Investigating the bias of the estimate we also obtain rate-of-convergence results under mild conditions on the distribution."
            },
            "slug": "On-the-Posterior-Probability-estimate-of-the-error-Lugosi-Pawlak",
            "title": {
                "fragments": [],
                "text": "On the Posterior Probability estimate of the error rate of nonparametric classification rules"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A so called posterior probability estimator, which plugs a nonparametric estimate of the a posteriori probabilities into an algebraic expression of the error probability, is proposed and the properties of the plug-in estimator are explored."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. IEEE International Symposium on Information Theory"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17061845"
                        ],
                        "name": "G. Wassel",
                        "slug": "G.-Wassel",
                        "structuredName": {
                            "firstName": "Gustav",
                            "lastName": "Wassel",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wassel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765522"
                        ],
                        "name": "J. Sklansky",
                        "slug": "J.-Sklansky",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Sklansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sklansky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32064930,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "0ac90374125eeaaa2f344ba1ea9b7fb8015921fe",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Some of the results of a study of asymptotically optimum nonparametric training procedures for two-category pattern classifiers are reported. The decision surfaces yielded by earlier forms of nonparametric training procedures generally do not minimize the probability of error. We derive a modification of the Robbins-Monro method of stochastic approximation, and show how this modification leads to training procedures that minimize the probability of error of a one-dimensional two-category pattern classifier. The class of probability density functions admitted by these training procedures is quite broad. We show that the sequence of decision points generated by any of these training procedures converges with probability one to the minimum-probability-of-error decision point."
            },
            "slug": "Training-a-One-Dimensional-Classifier-to-Minimize-Wassel-Sklansky",
            "title": {
                "fragments": [],
                "text": "Training a One-Dimensional Classifier to Minimize the Probability of Error"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work derives a modification of the Robbins-Monro method of stochastic approximation, and shows how this modification leads to training procedures that minimize the probability of error of a one-dimensional two-category pattern classifier."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069581"
                        ],
                        "name": "A. Farag\u00f3",
                        "slug": "A.-Farag\u00f3",
                        "structuredName": {
                            "firstName": "Andr\u00e1s",
                            "lastName": "Farag\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Farag\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755694"
                        ],
                        "name": "G. Lugosi",
                        "slug": "G.-Lugosi",
                        "structuredName": {
                            "firstName": "G\u00e1bor",
                            "lastName": "Lugosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lugosi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 195864959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "256fe370199610c14256023eccb777bc08a4af3c",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In statistical pattern recognition, a classifier is called universally consistent if its error probability converges to the Bayes-risk as the size of the training data grows for all possible distributions of the random variable pair of the observation vector and its class. It is proven that if a one-layered neural network with properly chosen number of nodes is trained to minimize the empirical risk on the training data, then a universally consistent classifier results. It is shown that the exponent in the rate of convergence does not depend on the dimension if certain smoothness conditions on the distribution are satisfied. That is, this class of universally consistent classifiers does not suffer from the curse of dimensionality. A training algorithm is presented that finds the optimal set of parameters in polynomial time if the number of nodes and the space dimension is fixed and the amount of training data grows. >"
            },
            "slug": "Strong-Universal-Consistency-of-Neural-Network-Farag\u00f3-Lugosi",
            "title": {
                "fragments": [],
                "text": "Strong Universal Consistency of Neural Network Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that the exponent in the rate of convergence does not depend on the dimension if certain smoothness conditions on the distribution are satisfied, and this class of universally consistent classifiers does not suffer from the curse of dimensionality."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. IEEE International Symposium on Information Theory"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144629886"
                        ],
                        "name": "G. Loizou",
                        "slug": "G.-Loizou",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Loizou",
                            "middleNames": [
                                "D"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Loizou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144555237"
                        ],
                        "name": "S. Maybank",
                        "slug": "S.-Maybank",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Maybank",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Maybank"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15544992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67bdea3835dddd5b4cde0d9f2cafdb9c7c347178",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The (k, l) nearest neighbor method of pattern classification is compared to the Bayes method. If the two acceptance rates are equal then the asymptotic error rates satisfy the inequalities Ek,l + 1 \u00bf E*(\u00bf) \u00bf Ek,l dE*(\u00bf), where d is a function of k, l, and the number of pattern classes, and \u00bf is the reject threshold for the Bayes method. An explicit expression for d is given which is optimal in the sense that for some probability distributions Ek,l and dE* (\u00bf) are equal."
            },
            "slug": "The-Nearest-Neighbor-and-the-Bayes-Error-Rates-Loizou-Maybank",
            "title": {
                "fragments": [],
                "text": "The Nearest Neighbor and the Bayes Error Rates"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The (k, l) nearest neighbor method of pattern classification is compared to the Bayes method and an explicit expression for d is given which is optimal in the sense that for some probability distributions Ek,l and dE* (\u00bf) are equal."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720816"
                        ],
                        "name": "P. Chou",
                        "slug": "P.-Chou",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Chou",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Chou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12866188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9576c0f4202ea4e6b30f9c13b397e3ccc5476250",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "An iterative algorithm that finds a locally optimal partition for an arbitrary loss function, in time linear in N for each iteration is presented. The algorithm is a K-means-like clustering algorithm that uses as its distance measure a generalization of Kullback's information divergence. Moreover, it is proven that the globally optimal partition must satisfy a nearest neighbour condition using divergence as the distance measure. These results generalize similar results of L. Breiman et al. (1984) to an arbitrary number of classes or regression variables and to an arbitrary number of bills. Experimental results on a text-to-speech example are provided and additional applications of the algorithm, including the design of variable combinations, surrogate splits, composite nodes, and decision graphs, are suggested. >"
            },
            "slug": "Optimal-Partitioning-for-Classification-and-Trees-Chou",
            "title": {
                "fragments": [],
                "text": "Optimal Partitioning for Classification and Regression Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "An iterative algorithm that finds a locally optimal partition for an arbitrary loss function, in time linear in N for each iteration, is presented and it is proven that the globally optimal partition must satisfy a nearest neighbour condition using divergence as the distance measure."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782873"
                        ],
                        "name": "M. Hellman",
                        "slug": "M.-Hellman",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Hellman",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hellman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10077064,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f943f08c231ae41634bdd4a98cf0ea4f5219a34",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "An observation comes from one of two possible classes. If all the statistics of the problem are known, Bayes' classification scheme yields the minimum probability of error. If, instead, the statistics are not known and one is given only a labeled training set, it is known that the nearest neighbor rule has an asymptotic error no greater than twice that of Bayes' rule. Here the (k,k?) nearest neighbor rule with a reject option is examined. This rule looks at the k nearest neighbors and rejects if less than k? of these are from the same class; if k? or more are from one class, a decision is made in favor of that class. The error rate of such a rule is bounded in terms of the Bayes' error rate."
            },
            "slug": "The-Nearest-Neighbor-Classification-Rule-with-a-Hellman",
            "title": {
                "fragments": [],
                "text": "The Nearest Neighbor Classification Rule with a Reject Option"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Here the (k,k?) nearest neighbor rule with a reject option is examined, which looks at the k nearest neighbors and rejects if less than k? of these are from the same class; if k? or more are from one class, a decision is made in favor of that class."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Sci. Cybern."
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59922518,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbd124947391213c2fd67a665d5a440f2f5ecdfc",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "STATISTICAL-PATTERN-RECOGNITION-REVISITED-Kohonen",
            "title": {
                "fragments": [],
                "text": "STATISTICAL PATTERN RECOGNITION REVISITED"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16638070"
                        ],
                        "name": "C. W. Swonger",
                        "slug": "C.-W.-Swonger",
                        "structuredName": {
                            "firstName": "Claron",
                            "lastName": "Swonger",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. W. Swonger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57464979,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c96e06213fc7a008a7ec53fac7d60e026cc47ca8",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "SAMPLE-SET-CONDENSATION-FOR-A-CONDENSED-NEAREST-FOR-Swonger",
            "title": {
                "fragments": [],
                "text": "SAMPLE SET CONDENSATION FOR A CONDENSED NEAREST NEIGHBOR DECISION RULE FOR PATTERN RECOGNITION"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121445745"
                        ],
                        "name": "J. Garnett",
                        "slug": "J.-Garnett",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Garnett",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Garnett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31677578"
                        ],
                        "name": "S. Yau",
                        "slug": "S.-Yau",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Yau",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Yau"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29791101,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7611cb05bc0fd9513a7ab72f7183edfb2cf2c4b",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Since the Bayes classifier is the optimum classifier in the sense of having minimum probability of misclassification among all the classifiers using the same set of pattern features, the error rate of the Bayes classifier using the set of features provided by a feature extractor, called the Bayes error of the feature extractor, is the smallest possible for the feature extractor. Consequently, the Bayes error can be used to evaluate the effectiveness of the feature extractors in a pattern recognition system. In this paper, a nonparametric technique for estimating the Bayes error for any two-category feature extractor is presented. This technique uses the nearest neighbor sample sets and is based on an infinite series expansion of the general form of the Bayes error. It is shown that this technique is better than the existing methods, and the estimates obtained by this technique are more meaningful in evaluating the quality of feature extractors. Computer simulation as well as application to electrocardiogram analysis are used to demonstrate this technique."
            },
            "slug": "Nonparametric-Estimation-of-the-Bayes-Error-of-Sets-Garnett-Yau",
            "title": {
                "fragments": [],
                "text": "Nonparametric Estimation of the Bayes Error of Feature Extractors Using Ordered Nearest Neighbor Sets"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "In this paper, a nonparametric technique for estimating the Bayes error for any two-category feature extractor is presented and is shown that this technique is better than the existing methods, and the estimates obtained are more meaningful in evaluating the quality of feature extractors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794435"
                        ],
                        "name": "A. Nobel",
                        "slug": "A.-Nobel",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Nobel",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Nobel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18229293,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "f4056843953cd8ecfbc1e43495bd737dd3528da0",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We establish general sufficient conditions for the L 2 -conoistency of multivariate histogram regression estimates based on data-dependent partitions. These same conditions insure the consistency of partitioning regression estimates based on local polynomial fits, and, with an additional regularity assumption, the consistency of histogram estimates for conditional medians. Our conditions require shrinking cells, subexponential growth of a combinatorial complexity measure and sublinear growth of restricted cell counts. It is not assumed that the cells of every partition be rectangles with sides parallel to the coordinate axis or that each cell contain a minimum number of points. Response variables are assumed to be bounded throughout. Our results may be applied to a variety of partitioning schemes. We established the consistency of histograms regression estimates based on cubic partitions with data-dependent offsets, k-thresholding in one dimension and empirically optimal nearest-neighbor clustering schemes. In addition, it is shown that empirically optimal regression trees are consistent when the size of the trees grows with the number of samples at an appropriate rate."
            },
            "slug": "Histogram-regression-estimation-using-partitions-Nobel",
            "title": {
                "fragments": [],
                "text": "Histogram regression estimation using data-dependent partitions"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The consistency of histograms regression estimates based on cubic partitions with data-dependent offsets, k-thresholding in one dimension and empirically optimal nearest-neighbor clustering schemes are established."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46802499"
                        ],
                        "name": "M. Ben-Bassat",
                        "slug": "M.-Ben-Bassat",
                        "structuredName": {
                            "firstName": "Moshe",
                            "lastName": "Ben-Bassat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ben-Bassat"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117564792,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "d1fe215302c161cc92c1e480f63bb97a548bd54f",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "35-Use-of-distance-measures,-information-measures-Ben-Bassat",
            "title": {
                "fragments": [],
                "text": "35 Use of distance measures, information measures and error bounds in feature evaluation"
            },
            "venue": {
                "fragments": [],
                "text": "Classification, Pattern Recognition and Reduction of Dimensionality"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785855"
                        ],
                        "name": "W. Greblicki",
                        "slug": "W.-Greblicki",
                        "structuredName": {
                            "firstName": "W\u0142odzimierz",
                            "lastName": "Greblicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Greblicki"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27721922,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "a104a7506331a16455b0385fa828ad057718596c",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Pattern recognition procedures derived from a nonparametric estimate of multivariate probability density functions using the orthogonal Hermite system are examined. For sufficiently regular densities, the convergence rate of the mean integrated square error (MISE) is O(n^{-l+\\epsilon}) , \\epsilon >0 , where n is the number of observations and is independent of the dimension. As a consequence, the rate at which the probability of misclassification converges to the Bayes probability of error as the length n of the learning sequence tends to infinity is also independent of the dimension of the class densities and equals O(n^{-1/2+ \\delta}), \\delta >O ."
            },
            "slug": "Asymptotic-efficiency-of-classifying-procedures-the-Greblicki",
            "title": {
                "fragments": [],
                "text": "Asymptotic efficiency of classifying procedures using the Hermite series estimate of multivariate probability densities"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "Pattern recognition procedures derived from a nonparametric estimate of multivariate probability density functions using the orthogonal Hermite system are examined to find the convergence rate of the mean integrated square error."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052317"
                        ],
                        "name": "R. Short",
                        "slug": "R.-Short",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Short",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Short"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45759580,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b6c835ed3f011f1221006586989a73998a75fbcb",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A local distance measure is shown to optimize the performance of the nearest neighbor two-class classifier for a finite number of samples. The difference between the finite sample error and the asymptotic error is used as the criterion of improvement. This new distance measure is compared to the well-known Euclidean distance. An algorithm for practical implementation is introduced. This algorithm is shown to be computationally competitive with the present nearest neighbor procedures and is illustrated experimentally. A closed form for the corresponding second-order moment of this criterion is found. Finally, the above results are extended to"
            },
            "slug": "The-optimal-distance-measure-for-nearest-neighbor-Short-Fukunaga",
            "title": {
                "fragments": [],
                "text": "The optimal distance measure for nearest neighbor classification"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A local distance measure is shown to optimize the performance of the nearest neighbor two-class classifier for a finite number of samples using the difference between the finite sample error and the asymptotic error as the criterion of improvement."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16824873"
                        ],
                        "name": "C. Wolverton",
                        "slug": "C.-Wolverton",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Wolverton",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wolverton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940156"
                        ],
                        "name": "T. Wagner",
                        "slug": "T.-Wagner",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Wagner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wagner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206729919,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "579ba5134f52ef88b5395b6e95d6f060eddffd74",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The two category classification problem is treated. No a priori knowledge of the statistics of the classes is assumed. A sequence of labeled samples from the two classes is used to construct a sequence of approximations of a discriminant function that is optimum in the sense of minimizing the probability of misclassification but which requires knowledge of all the statistics of the classes. Depending on the assumptions made about the probability densities corresponding to the two classes, the integrated square error of the approximations converges to 0 in probability or with probability 1 . The approximations are nonparametric and recursive for each fixed point of the domain. Rates of convergence are given. The approximations are used to define a decision procedure for classifying unlabeled samples. It is shown that as the number of labeled samples used to construct the approximations increases, the resulting sequence of discriminant functions is asymptotically optimal in the sense that the probability of misclassification when using the approximations in the decision procedure converges in probability or with probability 1 , depending on the assumptions made, to the probability of misclassification of the optimum discriminant function. The results can be easily extended to the multicategory problem and to the case of arbitrary loss functions, that is, where the costs of misclassification are not necessarily equal to 1 ."
            },
            "slug": "Asymptotically-optimal-discriminant-functions-for-Wolverton-Wagner",
            "title": {
                "fragments": [],
                "text": "Asymptotically optimal discriminant functions for pattern classification"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "It is shown that as the number of labeled samples used to construct the approximations increases, the resulting sequence of discriminant functions is asymptotically optimal in the sense that the probability of misclassification when using the approxIMations in the decision procedure converges in probability or with probability 1, depending on the assumptions made."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18251470,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "445ad69010658097fc317f7b83f1198179eebae8",
            "isKey": false,
            "numCitedBy": 1840,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper develops the separating capacities of families of nonlinear decision surfaces by a direct application of a theorem in classical combinatorial geometry. It is shown that a family of surfaces having d degrees of freedom has a natural separating capacity of 2d pattern vectors, thus extending and unifying results of Winder and others on the pattern-separating capacity of hyperplanes. Applying these ideas to the vertices of a binary n-cube yields bounds on the number of spherically, quadratically, and, in general, nonlinearly separable Boolean functions of n variables. It is shown that the set of all surfaces which separate a dichotomy of an infinite, random, separable set of pattern vectors can be characterized, on the average, by a subset of only 2d extreme pattern vectors. In addition, the problem of generalizing the classifications on a labeled set of pattern points to the classification of a new point is defined, and it is found that the probability of ambiguous generalization is large unless the number of training patterns exceeds the capacity of the set of separating surfaces."
            },
            "slug": "Geometrical-and-Statistical-Properties-of-Systems-Cover",
            "title": {
                "fragments": [],
                "text": "Geometrical and Statistical Properties of Systems of Linear Inequalities with Applications in Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that a family of surfaces having d degrees of freedom has a natural separating capacity of 2d pattern vectors, thus extending and unifying results of Winder and others on the pattern-separating capacity of hyperplanes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Electron. Comput."
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16907511"
                        ],
                        "name": "C. Hilborn",
                        "slug": "C.-Hilborn",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Hilborn",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Hilborn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645792"
                        ],
                        "name": "D. Lainiotis",
                        "slug": "D.-Lainiotis",
                        "structuredName": {
                            "firstName": "Demetrios",
                            "lastName": "Lainiotis",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lainiotis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9664198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c3771fd6829630cf450af853df728ecd8da4ab2",
            "isKey": false,
            "numCitedBy": 985,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Since, by (8) pertaining to the nearest neighbor decision rule (NN rule). We briefly review the NN rule and then describe the CNN rule. The NN rule['l-[ \" I assigns an unclassified sample to the same class as the nearest of n stored, correctly classified samples. In other words, given a collection of n reference points, each classified by some external source, a new point is assigned to the same class as its nearest neighbor. The most interesting t)heoretical property of the NN rule is that under very mild regularity assumptions on the underlying statistics, for any metric, and for a variety of loss functions , the large-sample risk incurred is less than twice the Bayes risk. (The Bayes decision rule achieves minimum risk but ,requires complete knowledge of the underlying statistics.) From a practical point of view, however, the NN rule is not a prime candidate for many applications because of the storage requirements it imposes. The CNN rule is suggested as a rule which retains the basic approach of the NN rule without imposing such stringent storage requirements. Before describing the CNN rule we first define the notion of a consistent subset of a sample set. This is a subset which, when used as a stored reference set for the NN rule, correctly classifies all of the remaining points in the sample set. A minimal consistent subset is a consistent subset with a minimum number of elements. Every set has a consistent subset, since every set is trivially a consistent subset of itself. Obviously, every finite set has a minimal consistent subset, although the minimum size is not, in general, achieved uniquely. The CNN rule uses the following algorithm to determine a consistent subset of the original sample set. In general, however, the algorithm will not find a minimal consistent subset. We assume that the original sample set is arranged in some order; then we set up bins called STORE and GRABHAG and proceed as follows. 1) The first sample is placed in STORE. 2) The second sample is classified by the NN rule, using as a reference set the current contents of STORE. (Since STORE has only one point, the classification is trivial at this stage.) If the second sample is classified correctly it is placed in GRABBAG; otherwise it is placed in STORE. 3) Proceeding inductively, the ith sample is classified by the current contents of \u2026"
            },
            "slug": "The-Condensed-Nearest-Neighbor-Rule-Hilborn-Lainiotis",
            "title": {
                "fragments": [],
                "text": "The Condensed Nearest Neighbor Rule"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The CNN rule is suggested as a rule which retains the basic approach of the NN rule without imposing such stringent storage requirements, and the notion of a consistent subset of a sample set is defined."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755694"
                        ],
                        "name": "G. Lugosi",
                        "slug": "G.-Lugosi",
                        "structuredName": {
                            "firstName": "G\u00e1bor",
                            "lastName": "Lugosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lugosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794435"
                        ],
                        "name": "A. Nobel",
                        "slug": "A.-Nobel",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Nobel",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Nobel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18687713,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "cc4f9cd158b8448cc5426fc806af45000e852423",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We present general sufficient conditions for the almost sureL1-consistency of histogram density estimates based on data-dependent partitions. Analogous conditions guarantee the almost-sure risk consistency of histogram classification schemes based on data-dependent partitions. Multivariate data is considered throughout. In each case, the desired consistency requires shrinking cells, subexponential growth of a combinatorial complexity measure, and sub-linear growth of the number of cells. It is not required that the cells of every partition be rectangles with sides paralles to the coordinate axis, or that each cell contain a minimum number of points. No assumptions are made concerning the common distribution of the training vectors. We apply the results to establish the consistency of several known partitioning estimates, including the kn-spacing density estimate, classifiers based on statistically equivalent blocks, and classifiers based on multivariate clustering schemes."
            },
            "slug": "Consistency-of-Data-driven-Histogram-Methods-for-Lugosi-Nobel",
            "title": {
                "fragments": [],
                "text": "Consistency of Data-driven Histogram Methods for Density Estimation and Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "General sufficient conditions for the almost sureL1-consistency of histogram density estimates based on data-dependent partitions are presented and the results are applied to establish the consistency of several known partitioning estimates, including the kn-spacing density estimate, classifiers based on statistically equivalent blocks, and classifier based on multivariate clustering schemes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3129654"
                        ],
                        "name": "S. Raudys",
                        "slug": "S.-Raudys",
                        "structuredName": {
                            "firstName": "Sarunas",
                            "lastName": "Raudys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Raudys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2335089"
                        ],
                        "name": "Vitalijus Pikelis",
                        "slug": "Vitalijus-Pikelis",
                        "structuredName": {
                            "firstName": "Vitalijus",
                            "lastName": "Pikelis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vitalijus Pikelis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15314450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4f4ee04501dfb66d8fd9a2c208845e661a6008a",
            "isKey": false,
            "numCitedBy": 169,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper compares four classification algorithms-discriminant functions when classifying individuals into two multivariate populations. The discriminant functions (DF's) compared are derived according to the Bayes rule for normal populations and differ in assumptions on the covariance matrices' structure. Analytical formulas for the expected probability of misclassification EPN are derived and show that the classification error EPN depends on the structure of a classification algorithm, asymptotic probability of misclassification P\u00bf, and the ratio of learning sample size N to dimensionality p:N/p for all linear DF's discussed and N2/p for quadratic DF's. The tables for learning quantity H = EPN/P\u00bf depending on parameters P\u00bf, N, and p for four classifilcation algorithms analyzed are presented and may be used for estimating the necessary learning sample size, detennining the optimal number of features, and choosing the type of the classification algorithm in the case of a limited learning sample size."
            },
            "slug": "On-Dimensionality,-Sample-Size,-Classification-and-Raudys-Pikelis",
            "title": {
                "fragments": [],
                "text": "On Dimensionality, Sample Size, Classification Error, and Complexity of Classification Algorithm in Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "Four classification algorithms-discriminant functions when classifying individuals into two multivariate populations are compared and it is shown that the classification error EPN depends on the structure of a classification algorithm, asymptotic probability of misclassification P\u00bf, and the ratio of learning sample size N to dimensionality p:N/p."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922810"
                        ],
                        "name": "P. Devijver",
                        "slug": "P.-Devijver",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Devijver",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Devijver"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45053842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64184ac56733d5e7da95d9df0caf5c73ee8a615a",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A distribution-free lower bound on the Bayes error rate is formulated in terms of the asymptotic error rate of the nearest neighbor rule with a reject option. Next, a closed form expression for an upper bound of the k th nearest neighbor error rate in terms of the Bayes rate is established. These results are discussed in the framework of recent works on nonparametric estimation of the Bayes error rate."
            },
            "slug": "New-error-bounds-with-the-nearest-neighbor-rule-Devijver",
            "title": {
                "fragments": [],
                "text": "New error bounds with the nearest neighbor rule (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A distribution-free lower bound on the Bayes error rate is formulated in terms of the asymptotic error rate of the nearest neighbor rule with a reject option and a closed form expression for an upper bound is established."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055719541"
                        ],
                        "name": "D. W. Peterson",
                        "slug": "D.-W.-Peterson",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Peterson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. W. Peterson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 506497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "676d2e74dd55ca0fdf631b32ba75c54bce70addd",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper focuses on the problem of the relationship between the risk incurred using a nearest neighbor rule and the size of the data base. Theoretical results include demonstrations of the facts that the proximity of the nearest neighbor to a new sample in a collection of n samples becomes (in probability) arbitrarily small as n is increased; that the convergence is often (but not always) with probability 1; that as a result of these convergences, the risk associated with a decision may be closely controlled; and that these facts and their demonstrations aid one in determining the size of a sample of data to be used as a nearest neighbor decision-making base. An example serves to demonstrate that the size of the data base required to meet performance criteria other than the relatively lax expected risk criterion can be unreasonably large."
            },
            "slug": "Some-convergence-properties-of-a-nearest-neighbor-Peterson",
            "title": {
                "fragments": [],
                "text": "Some convergence properties of a nearest neighbor decision rule"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Theoretical results include demonstrations of the facts that the proximity of the nearest neighbor to a new sample in a collection of n samples becomes (in probability) arbitrarily small as n is increased and that the convergence is often (but not always) with probability 1."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3265474"
                        ],
                        "name": "T. E. Flick",
                        "slug": "T.-E.-Flick",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Flick",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. E. Flick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145491571"
                        ],
                        "name": "L. Jones",
                        "slug": "L.-Jones",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Jones",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50072499"
                        ],
                        "name": "R. Priest",
                        "slug": "R.-Priest",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Priest",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Priest"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059851178"
                        ],
                        "name": "Charles Herman",
                        "slug": "Charles-Herman",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Herman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles Herman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12920183,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f4c8b70385985334df59ef7003754b403d0426d5",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pattern-classification-using-projection-pursuit-Flick-Jones",
            "title": {
                "fragments": [],
                "text": "Pattern classification using projection pursuit"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3265474"
                        ],
                        "name": "T. E. Flick",
                        "slug": "T.-E.-Flick",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Flick",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. E. Flick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17537491,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "393cd31439d4cdde54a32a32f48c9980d89b6bec",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "A quadratic metric dAO (X, Y) =[(X - Y)T AO(X - Y)]\u00bf is proposed which minimizes the mean-squared error between the nearest neighbor asymptotic risk and the finite sample risk. Under linearity assumptions, a heuristic argument is given which indicates that this metric produces lower mean-squared error than the Euclidean metric. A nonparametric estimate of Ao is developed. If samples appear to come from a Gaussian mixture, an alternative, parametrically directed distance measure is suggested for nearness decisions within a limited region of space. Examples of some two-class Gaussian mixture distributions are included."
            },
            "slug": "An-Optimal-Global-Nearest-Neighbor-Metric-Fukunaga-Flick",
            "title": {
                "fragments": [],
                "text": "An Optimal Global Nearest Neighbor Metric"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A quadratic metric dAO (X, Y) =[( X - Y)T AO(X - Y)]\u00bf is proposed which minimizes the mean-squared error between the nearest neighbor asymptotic risk and the finite sample risk."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9745969"
                        ],
                        "name": "A. Krzy\u017cak",
                        "slug": "A.-Krzy\u017cak",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Krzy\u017cak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krzy\u017cak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28501989,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "27534c2740c20745579f30b2c18dcc0dd714c7f7",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The exponential, distribution-free bounds for the kernel classification rule are derived. The equivalence of all modes of the global convergence of the rule is established under optimal assumptions on the smoothing sequence. Also derived is the optimal global rate of convergence of the kernel regression estimate within the class of Lipschitz distributions. The rate is optimal for the nonparametric regression, but not for classifications. It is shown. using the martingale device, that weak, strong, and complete L/sub 1/ Bayes risk consistencies are equivalent. Consequently the conditions on the smoothing sequence h/sub n/ to 0 and nh/sub n/ to infinity are necessary and sufficient for Bayes risk consistency of the kernel classification rule. The rate of convergence of the kernel classification rule is also given. >"
            },
            "slug": "On-exponential-bounds-on-the-Bayes-risk-of-the-rule-Krzy\u017cak",
            "title": {
                "fragments": [],
                "text": "On exponential bounds on the Bayes risk of the kernel classification rule"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The exponential, distribution-free bounds for the kernel classification rule are derived and the equivalence of all modes of the global convergence of the rule is established under optimal assumptions on the smoothing sequence."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399953072"
                        ],
                        "name": "Baek S. Kim",
                        "slug": "Baek-S.-Kim",
                        "structuredName": {
                            "firstName": "Baek S.",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Baek S. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400004206"
                        ],
                        "name": "Song B. Park",
                        "slug": "Song-B.-Park",
                        "structuredName": {
                            "firstName": "Song B.",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song B. Park"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9517913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a810292f51dca1aeae2d3093145530ecad8cfd11",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a fast nearest neighbor finding algorithm, named tentatively an ordered partition, based on the ordered lists of the training samples of each projection axis. The ordered partition contains two properties, one is ordering\u00bfto bound the search region, and the other is partitioning\u00bfto reject the unwanted samples without actual distance computations. It is proved that the proposed algorithm can find k nearest neighbors in a constant expected time. Simulations show that the algorithm is rather distribution free, and only 4.6 distance calculations, on the average, were required to find a nearest neighbor among 10 000 samples drawn from a bivariate normal distribution."
            },
            "slug": "A-Fast-k-Nearest-Neighbor-Finding-Algorithm-Based-Kim-Park",
            "title": {
                "fragments": [],
                "text": "A Fast k Nearest Neighbor Finding Algorithm Based on the Ordered Partition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is proved that the proposed algorithm can find k nearest neighbors in a constant expected time and is distribution free, and only 4.6 distance calculations were required to find a nearest neighbor among 10 000 samples drawn from a bivariate normal distribution."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16614627"
                        ],
                        "name": "D. Kessell",
                        "slug": "D.-Kessell",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kessell",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kessell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27704857,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "9c19873f06e403a9b09a10d89546aa6b0a171939",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The key measure of performance in a pattern recognition problem is the cost of making a decision. For the special case in which the relative cost of a correct decision is zero and the relative cost of an incorrect decision is unity, this cost is equal to the probability of an incorrect decision or error. A pattern recognition system may be viewed as a decision rule which transforms measurements into class assignments. The Bayes error is the minimum achievable error, where the minimization is with respect to all decision rules. The Bayes error is a function of the prior probabilities and the probability density functions of the respective classes. Unfortunately, in many applications, the probability density functions are unknown and therefore the Bayes error is unknown."
            },
            "slug": "Nonparametric-Bayes-error-estimation-using-samples-Fukunaga-Kessell",
            "title": {
                "fragments": [],
                "text": "Nonparametric Bayes error estimation using unclassified samples"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A pattern recognition system may be viewed as a decision rule which transforms measurements into class assignments and the Bayes error is the minimum achievable error, where the minimization is with respect to all decision rules."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2806380"
                        ],
                        "name": "J. Talmon",
                        "slug": "J.-Talmon",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Talmon",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Talmon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34331302,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df8abb3101abee977c04c236217b18d3482ff060",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-multiclass-nonparametric-partitioning-algorithm-Talmon",
            "title": {
                "fragments": [],
                "text": "A multiclass nonparametric partitioning algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34413349"
                        ],
                        "name": "Youngtae Park",
                        "slug": "Youngtae-Park",
                        "structuredName": {
                            "firstName": "Youngtae",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Youngtae Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765522"
                        ],
                        "name": "J. Sklansky",
                        "slug": "J.-Sklansky",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Sklansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sklansky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5492789,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d6334aa47fb727069b10a5bd2ffece0394d3cbd5",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automated-design-of-linear-tree-classifiers-Park-Sklansky",
            "title": {
                "fragments": [],
                "text": "Automated design of linear tree classifiers"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2181156"
                        ],
                        "name": "C. Penrod",
                        "slug": "C.-Penrod",
                        "structuredName": {
                            "firstName": "Clark",
                            "lastName": "Penrod",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Penrod"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940156"
                        ],
                        "name": "T. Wagner",
                        "slug": "T.-Wagner",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Wagner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wagner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118027678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e9462664edde073562f384baa2e3a5f8bf30807",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : In this paper we present a slight modification of Wilson's Edited Nearest Neighbor Rule (1) in the one dimensional case for which it is possible to compute tight bounds on the average asymptotic risk. It is pointed out that the argument used by Wilson to establish his bounds is probably incorrect with the bounds being somewhat optimistic. The rule presented here is not in itself of any great significance since it does not generalize to more than one dimension. The contribution lies in the fact that for this type of rule (which is very similar to Wilson's rule) an exact analysis is possible which permits comparison of the relative merits of various editing schemes. Although no proof is offered, the strong similarities involved give reason to believe that the results concerning the relative efficiencies of the various editing schemes will carry over to higher dimensional problems with the usual version of the nearest neighbor rule. (Author)"
            },
            "slug": "Another-Look-at-the-Edited-Nearest-Neighbor-Rule.-Penrod-Wagner",
            "title": {
                "fragments": [],
                "text": "Another Look at the Edited Nearest Neighbor Rule."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The strong similarities involved give reason to believe that the results concerning the relative efficiencies of the various editing schemes will carry over to higher dimensional problems with the usual version of the nearest neighbor rule."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17620884,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2bc7bb8ca04b1599eab2c363d9212914af694d5d",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In discrimination problems, one considers estimates Y of Y where Y denotes a (0, 1)valued Borel measurable function of X and (X 1, Y1 ), \u2022., (X,~, Yn ) . For example, the knearest neighbor estimate Yis defined as follows (Fix and Hodges,1951) : find the k nearest neighbors of X among X 1 , \u2022 . . , X, ; break ties by comparing indices ; take a majority vote among the Yi's that correspond to selected XD 's; set Y equal to the chosen integer; in case of a voting tie, set Y equal to Y 1 where i is the smallest index among the selected X 1's . Cover and Hart (1965) have shown that under some conditions on \u03bc and r~, if Ln P( Y Y) is the probability of error (error rate), then"
            },
            "slug": "On-the-Asymptotic-Probability-of-Error-in-Devroye",
            "title": {
                "fragments": [],
                "text": "On the Asymptotic Probability of Error in Nonparametric Discrimination"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2283937"
                        ],
                        "name": "Zen-Yi Chen",
                        "slug": "Zen-Yi-Chen",
                        "structuredName": {
                            "firstName": "Zen-Yi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zen-Yi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97306284"
                        ],
                        "name": "K. Fu",
                        "slug": "K.-Fu",
                        "structuredName": {
                            "firstName": "King-Sun",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17384797,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "e47e4602cd78d9676a6787ef7bf9594863631bcf",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The performance of a pattern classification system is often evaluated based on the risk committed by the classification procedure. The minimum attainable risk is the Bayes risk. Therefore, the Bayes risk can be used as a measure of the intrinsic complexity of the system, and it also serves as a reference of the optimality measure of a classification procedure. There are many practical situations in which the nonparametric methods may have to be called upon to estimate the Bayes risk. One of the nonparametric methods is via the probability density estimation technique. The convergence properties of this estimation technique are studied under fairly general assumptions. In the computer experiments reported, the estimate of the Bayes risk is taken as the sample mean of the density estimate by making use of the leave-one-out method. The probability density estimate used is the one proposed by Loftsgaarden and Quesenberry. This estimate is shown to be, in general, superior to the risk associated with a Bayes-like decision rule based on the error-counting scheme. This estimate is also compared experimentally with the risk estimate associated with the nearest neighbor rule."
            },
            "slug": "Nonparametric-Bayes-Risk-Estimation-for-Pattern-Chen-Fu",
            "title": {
                "fragments": [],
                "text": "Nonparametric Bayes Risk Estimation for Pattern Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The probability density estimate used is the one proposed by Loftsgaarden and Quesenberry and is shown to be, in general, superior to the risk associated with a Bayes-like decision rule based on the error-counting scheme."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755694"
                        ],
                        "name": "G. Lugosi",
                        "slug": "G.-Lugosi",
                        "structuredName": {
                            "firstName": "G\u00e1bor",
                            "lastName": "Lugosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lugosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18283189,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3885981d45322bbb73f2b092a0c99297d25e6d3b",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Lower-bounds-in-pattern-recognition-and-learning-Devroye-Lugosi",
            "title": {
                "fragments": [],
                "text": "Lower bounds in pattern recognition and learning"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103188660"
                        ],
                        "name": "A. Barron",
                        "slug": "A.-Barron",
                        "structuredName": {
                            "firstName": "A.R.",
                            "lastName": "Barron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 51276807,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "72d761afbe35634213849419ff63fad5bc9fabeb",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Convergence properties of empirically estimated neural networks are examined. In this theory, an appropriate size feedforward network is automatically determined from the data. The networks studied include two- and three-layer networks with an increasing number of simple sigmoidal nodes, multiple-layer polynomial networks, and networks with certain fixed structures but an increasing complexity in each unit. Each of these classes of networks is dense in the space of continuous functions on compact subsets of d-dimensional Euclidean space, with respect to the topology of uniform convergence. It is shown how, with the use of an appropriate complexity regularization criterion, the statistical risk of network estimators converges to zero as the sample size increases. Bounds on the rate of convergence are given in terms of an index of the approximation capability of the class of networks.<<ETX>>"
            },
            "slug": "Statistical-properties-of-artificial-neural-Barron",
            "title": {
                "fragments": [],
                "text": "Statistical properties of artificial neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown how, with the use of an appropriate complexity regularization criterion, the statistical risk of network estimators converges to zero as the sample size increases."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 28th IEEE Conference on Decision and Control,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053229584"
                        ],
                        "name": "E. Ruiz",
                        "slug": "E.-Ruiz",
                        "structuredName": {
                            "firstName": "Eugenia",
                            "lastName": "Ruiz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ruiz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123469655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9fd84e71cebfa381ae678d697b6f8ebaa0a16b80",
            "isKey": false,
            "numCitedBy": 270,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-algorithm-for-finding-nearest-neighbours-in-time-Ruiz",
            "title": {
                "fragments": [],
                "text": "An algorithm for finding nearest neighbours in (approximately) constant average time"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20658113"
                        ],
                        "name": "A. Barron",
                        "slug": "A.-Barron",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barron",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barron"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118425960,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "8b7d60f49e7a5368920457c885c813a912c34997",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Concepts of universal data compression lead to minimum description-length criteria for parsimonious statistical model selection for the estimation of functions. In this paper we define general complexity regularization criteria and establish bounds on the statistical risk of the estimated functions. These bounds establish consistency, yield rates of convergence, and demonstrate the near asymptotic optimality of the model selection criterion in both parametric and nonparametric cases. A fundamental role is played by an index of resolvability that quantifies the tradeoff between complexity and accuracy of candidate models. Applications are given to polynomial regression and artificial neural networks."
            },
            "slug": "Complexity-Regularization-with-Application-to-Barron",
            "title": {
                "fragments": [],
                "text": "Complexity Regularization with Application to Artificial Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper defines general complexity regularization criteria and establishes bounds on the statistical risk of the estimated functions and establishes consistency, yield rates of convergence, and the near asymptotic optimality of the model selection criterion in both parametric and nonparametric cases."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9745969"
                        ],
                        "name": "A. Krzy\u017cak",
                        "slug": "A.-Krzy\u017cak",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Krzy\u017cak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krzy\u017cak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143649637"
                        ],
                        "name": "T. Linder",
                        "slug": "T.-Linder",
                        "structuredName": {
                            "firstName": "Tam\u00e1s",
                            "lastName": "Linder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Linder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399769304"
                        ],
                        "name": "G. Lugosi",
                        "slug": "G.-Lugosi",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Lugosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lugosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206458141,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "bed6503a8304d7bbcc32b7f8bc7ecfeea7c87407",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Studies convergence properties of radial basis function (RBF) networks for a large class of basis functions, and reviews the methods and results related to this topic. The authors obtain the network parameters through empirical risk minimization. The authors show the optimal nets to be consistent in the problem of nonlinear function approximation and in nonparametric classification. For the classification problem the authors consider two approaches: the selection of the RBF classifier via nonlinear function estimation and the direct method of minimizing the empirical error probability. The tools used in the analysis include distribution-free nonasymptotic probability inequalities and covering numbers for classes of functions."
            },
            "slug": "Nonparametric-estimation-and-classification-using-Krzy\u017cak-Linder",
            "title": {
                "fragments": [],
                "text": "Nonparametric estimation and classification using radial basis function nets and empirical risk minimization"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The authors show the optimal nets to be consistent in the problem of nonlinear function approximation and in nonparametric classification in RBF networks and obtain the network parameters through empirical risk minimization."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38450582"
                        ],
                        "name": "Heng Guo",
                        "slug": "Heng-Guo",
                        "structuredName": {
                            "firstName": "Heng",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heng Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700484"
                        ],
                        "name": "S. Gelfand",
                        "slug": "S.-Gelfand",
                        "structuredName": {
                            "firstName": "Saul",
                            "lastName": "Gelfand",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gelfand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 39286264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d62f72b17e170711a46c20c1e9adadfb348999b",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of small multilayer nets at the decision nodes of a binary classification tree to extract nonlinear features is proposed. This approach exploits the power of tree classifiers to use appropriate local features at the different levels and nodes of the tree. The nets are trained and the tree is grown using a gradient-type learning algorithm in conjunction with a heuristic class aggregation algorithm. The method improves on standard classification tree design methods in that it generally produces trees with lower error rates and fewer nodes. It also provides a structured approach to neural network classifier design which reduces the problem associated with training large unstructured nets, and transfers the problem of selecting the size of the net to the simpler problem of finding the right size tree. Example concern waveform and handwritten character recognition.<<ETX>>"
            },
            "slug": "Classification-trees-with-neural-network-feature-Guo-Gelfand",
            "title": {
                "fragments": [],
                "text": "Classification trees with neural network feature extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The use of small multilayer nets at the decision nodes of a binary classification tree to extract nonlinear features is proposed, which improves on standard classification tree design methods and provides a structured approach to neural network classifier design."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31677578"
                        ],
                        "name": "S. Yau",
                        "slug": "S.-Yau",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Yau",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Yau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144015572"
                        ],
                        "name": "T. Lin",
                        "slug": "T.-Lin",
                        "structuredName": {
                            "firstName": "Ta-Tung",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121141225,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "552814d217af1310256dd8d40b80f91d5d26ae31",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a set of sample patterns for two pattern classes, some simple expressions for the upper bound of the probability of error for a linear pattern classifier and the optimal linear discriminant function minimizing the upper bound are obtained. Using these results, if the tolerable probability of error of classifying patterns in the two pattern classes is not smaller than this upper bound, not only a linear pattern classifier is known to be feasible, but also a satisfactory linear discriminant function is given. The results presented here are independent of the probability distribution of the patterns in the pattern classes. For some special cases, a smaller upper bound is found."
            },
            "slug": "On-the-upper-bound-of-the-probability-of-error-of-a-Yau-Lin",
            "title": {
                "fragments": [],
                "text": "On the upper bound of the probability of error of a linear pattern classifier for probabilistic pattern classes"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "If the tolerable probability of error of classifying patterns in the two pattern classes is not smaller than this upper bound, not only a linear pattern classifier is known to be feasible, but also a satisfactory linear discriminant function is given."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16252030,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "65479e8e0c748244a46c7a94c839b092d272a8cf",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper extends the notions of capacity and distribution-free error estimation to nonlinear Boolean classifiers on patterns with binary-valued features. We establish quantitative relationships between the dimensionality of the feature vectors (d), the combinational complexity of the decision rule (c), the number of samples in the training set (n), and the classification performance of the resulting classifier. Our results state that the discriminating capacity of Boolean classifiers is given by the product dc, and the probability of ambiguous generalization is asymptotically given by (n/dc-1)-1 0(log d)/d) for large d, and n=0(dc). In addition we show that if a fraction \u00bf of the training samples is misclassified then the probability of error (\u00bf) in subsequent samples satisfies P(|\u00bf-\u00bf| \u00bf) m=<2.773 exp (dc-e2n/8) for all distributions, regardless of how the classifier was discovered."
            },
            "slug": "Capacity-and-Error-Estimates-for-Boolean-with-Pearl",
            "title": {
                "fragments": [],
                "text": "Capacity and Error Estimates for Boolean Classifiers with Limited Complexity"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This paper extends the notions of capacity and distribution-free error estimation to nonlinear Boolean classifiers on patterns with binary-valued features and establishes quantitative relationships between the dimensionality of the feature vectors, the combinational complexity of the decision rule, the number of samples in the training set, and the classification performance of the resulting classifier."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2285810"
                        ],
                        "name": "D. Specht",
                        "slug": "D.-Specht",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Specht",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Specht"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31917696,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "659c266e66a8c568d99f493b5e3b1289c415db27",
            "isKey": false,
            "numCitedBy": 524,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Two methods for classification based on the Bayes strategy and nonparametric estimators for probability density functions are reviewed. The two methods are named the probabilistic neural network (PNN) and the polynomial Adaline. Both methods involve one-pass learning algorithms that can be implemented directly in parallel neural network architectures. The performances of the two methods are compared with multipass backpropagation networks, and relative advantages and disadvantages are discussed. PNN and the polynomial Adaline are complementary techniques because they implement the same decision boundaries but have different advantages for applications. PNN is easy to use and is extremely fast for moderate-sized databases. For very large databases and for mature applications in which classification speed is more important than training speed, the polynomial equivalent can be found."
            },
            "slug": "Probabilistic-neural-networks-and-the-polynomial-as-Specht",
            "title": {
                "fragments": [],
                "text": "Probabilistic neural networks and the polynomial Adaline as complementary techniques for classification"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "Two methods for classification based on the Bayes strategy and nonparametric estimators for probability density functions are reviewed and the polynomial equivalent can be found."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678771"
                        ],
                        "name": "P. Bickel",
                        "slug": "P.-Bickel",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bickel",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bickel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122913895,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fbc83c07122dcf7e54cac9da3cfd5d79e649168d",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The limiting behavior of sums of functions of nearest neighbor distances is studied for an m dimensional sample. A central limit theorem and moment bounds for such sums, and an invariance principle for the empirical process of nearest neighbor distances are both established. As a consequence the asymptotic behavior of a practicable goodness of fit test is obtained based on nearest neighbor distances."
            },
            "slug": "Sums-of-Functions-of-Nearest-Neighbor-Distances,-a-Bickel-Breiman",
            "title": {
                "fragments": [],
                "text": "Sums of Functions of Nearest Neighbor Distances, Moment Bounds, Limit Theorems and a Goodness of Fit Test"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940156"
                        ],
                        "name": "T. Wagner",
                        "slug": "T.-Wagner",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Wagner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wagner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30609331,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5733fdb28f417d3305818fd455aa0f5821bfabd4",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The edited k nearest neighbor rule ( k -NNR) consists of 1) eliminating those samples from the data which are not classified correctly by the k -NNR and the remainder of the data, and 2) using the NNR with the samples which remain from 1) to classify new observations. Wilson has shown that this rule has an asymptotic probability of error which is better than that of the k -NNR. A key step in his development is showing the convergence of the edited nearest neighbor. His lengthy argument is replaced here by a somewhat simpler one which uses an intuitive fact about the editing procedure."
            },
            "slug": "Convergence-of-the-edited-nearest-neighbor-Wagner",
            "title": {
                "fragments": [],
                "text": "Convergence of the edited nearest neighbor (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Wilson has shown that this rule has an asymptotic probability of error which is better than that of the k -NNR, and shows the convergence of the edited nearest neighbor."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784553"
                        ],
                        "name": "D. Psaltis",
                        "slug": "D.-Psaltis",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Psaltis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Psaltis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2802766"
                        ],
                        "name": "R. Snapp",
                        "slug": "R.-Snapp",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Snapp",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Snapp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144694846"
                        ],
                        "name": "S. Venkatesh",
                        "slug": "S.-Venkatesh",
                        "structuredName": {
                            "firstName": "Santosh",
                            "lastName": "Venkatesh",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Venkatesh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13310161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c0fa90a17c396aed0fdc414b6c44e26ff78eb00",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The finite sample performance of a nearest neighbor classifier is analyzed for a two-class pattern recognition problem. An exact integral expression is derived for the m-sample risk R/sub m/ given that a reference m-sample of labeled points, drawn independently from Euclidean n-space according to a fixed probability distribution, is available to the classifier. For a family of smooth distributions characterized by asymptotic expansions in general form, it is shown that the m-sample risk R/sub m/ has a complete asymptotic series expansion R/sub m/ ~ R/spl infin/ + /spl Sigma//sup /spl infin///sub k=1/ ckm/sup -k/n/ (m - /spl infin/) where R/spl infin/ denotes the nearest neighbor risk in the infinite-sample limit. Improvements in convergence rate are shown under stronger smoothness assumptions, and in particular, R/sub m/ = R/spl infin/ + O(m/sup -2/n/) if the class-conditional probability densities have uniformly bounded third derivatives on their probability one support. This analysis thus provides further analytic validation of Bellman's curse of dimensionality. Numerical simulations corroborating the formal results are included, and extensions of the theory discussed. The analysis also contains a novel application of Laplace's asymptotic method of integration to a multidimensional integral where the integrand attains its maximum on a continuum of points."
            },
            "slug": "On-the-Finite-Sample-Performance-of-the-Nearest-Psaltis-Snapp",
            "title": {
                "fragments": [],
                "text": "On the Finite Sample Performance of the Nearest Neighbor Classifier"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The finite sample performance of a nearest neighbor classifier is analyzed for a two-class pattern recognition problem and a novel application of Laplace's asymptotic method of integration to a multidimensional integral where the integrand attains its maximum on a continuum of points."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. IEEE International Symposium on Information Theory"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17118021"
                        ],
                        "name": "E. Henrichon",
                        "slug": "E.-Henrichon",
                        "structuredName": {
                            "firstName": "Ernest",
                            "lastName": "Henrichon",
                            "middleNames": [
                                "G."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Henrichon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97306284"
                        ],
                        "name": "K. Fu",
                        "slug": "K.-Fu",
                        "structuredName": {
                            "firstName": "King-Sun",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11260872,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3dde1c197631dfb0ff4c041e5e88accb9ce5a7e",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A nonparametric procedure is developed for determining a structure for multivariate, multiclass pattern classification. The resultant classifier is in the form of a layered machine which is composed of multithreshold elements. The basic algorithm determines partitions which are parallel hyperplanes orthogonal to the feature coordinate dimensions. Inherent in the procedure is the concept of a transgenerator unit used to establish new feature dimensions such that effective partitioning can be obtained. While the choice of which classes of transgeneration units to consider is ultimately up to the user, a number of such units are suggested herein. The algorithm gives an indication as to the effectiveness of various transgeneration units and hence can also be used in an interactive manner if so desired for the actual design of a classification structure."
            },
            "slug": "A-Nonparametric-Partitioning-Procedure-for-Pattern-Henrichon-Fu",
            "title": {
                "fragments": [],
                "text": "A Nonparametric Partitioning Procedure for Pattern Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The algorithm gives an indication as to the effectiveness of various transgeneration units and hence can also be used in an interactive manner if so desired for the actual design of a classification structure."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145040745"
                        ],
                        "name": "G. L. Ritter",
                        "slug": "G.-L.-Ritter",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Ritter",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. L. Ritter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40244241"
                        ],
                        "name": "H. Woodruff",
                        "slug": "H.-Woodruff",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Woodruff",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Woodruff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5653326"
                        ],
                        "name": "S. Lowry",
                        "slug": "S.-Lowry",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Lowry",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lowry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798074"
                        ],
                        "name": "T. Isenhour",
                        "slug": "T.-Isenhour",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Isenhour",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Isenhour"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39185970,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b606e20a877bd55671e83e053b71ba79d871f732",
            "isKey": false,
            "numCitedBy": 341,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A procedure is introduced to approximate nearest neighbor (INN) decision boundaries. The algorithm produces a selective subset of the original data so that 1) the subset is consistent, 2) the distance between any sample and its nearest selective neighbor is less than the distance from the sample to any sample of the other class, and 3) the subset is the smallest possible."
            },
            "slug": "An-algorithm-for-a-selective-nearest-neighbor-rule-Ritter-Woodruff",
            "title": {
                "fragments": [],
                "text": "An algorithm for a selective nearest neighbor decision rule (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A procedure is introduced to approximate nearest neighbor (INN) decision boundaries that produces a selective subset of the original data so that the subset is consistent, the distance between any sample and its nearest selective neighbor is less than the distance from the sample to any sample of the other class."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47865278"
                        ],
                        "name": "Takayasu Ito",
                        "slug": "Takayasu-Ito",
                        "structuredName": {
                            "firstName": "Takayasu",
                            "lastName": "Ito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takayasu Ito"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 21351007,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a01916c9dc4d57cfb463706179ac815ceed5ae47",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical recognition procedures can be derived from the functional form of underlying probability distributions. Successive approximation to the probability function leads to a class of recognition procedures. In this note we give a hierarchical method of designing recognition functions which satisfy both the least-square error property and a minimum decision error rate property, although our discussions are restricted to a binary measurement space and its dichotomous classification."
            },
            "slug": "Note-on-a-Class-of-Statistical-Recognition-Ito",
            "title": {
                "fragments": [],
                "text": "Note on a Class of Statistical Recognition Functions"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This note gives a hierarchical method of designing recognition functions which satisfy both the least-square error property and a minimum decision error rate property, although the discussions are restricted to a binary measurement space and its dichotomous classification."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2322936"
                        ],
                        "name": "L. Hostetler",
                        "slug": "L.-Hostetler",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Hostetler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hostetler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27985441,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "477f3090ca606035efd9a435b510212b0dec9215",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Nonparametric density estimation using the k -nearest-neighbor approach is discussed. By developing a relation between the volume and the coverage of a region, a functional form for the optimum k in terms of the sample size, the dimensionality of the observation space, and the underlying probability distribution is obtained. Within the class of density functions that can be made circularly symmetric by a linear transformation, the optimum matrix for use in a quadratic form metric is obtained. For Gaussian densities this becomes the inverse covariance matrix that is often used without proof of optimality. The close relationship of this approach to that of Parzen estimators is then investigated."
            },
            "slug": "Optimization-of-k-nearest-neighbor-density-Fukunaga-Hostetler",
            "title": {
                "fragments": [],
                "text": "Optimization of k nearest neighbor density estimates"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "Nonparametric density estimation using the k -nearest-neighbor approach is discussed and a functional form for the optimum k in terms of the sample size, the dimensionality of the observation space, and the underlying probability distribution is obtained."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102015721"
                        ],
                        "name": "P. Argentiero",
                        "slug": "P.-Argentiero",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Argentiero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Argentiero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21754467"
                        ],
                        "name": "R. Chin",
                        "slug": "R.-Chin",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Chin",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3180816"
                        ],
                        "name": "P. Beaudet",
                        "slug": "P.-Beaudet",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Beaudet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Beaudet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7245466,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "da861f844ba47256bc4b0d1839325cf8802afd95",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The classification of large dimensional data sets arising from the merging of remote sensing data with more traditional forms of ancillary data causes a significant computational problem. Decision tree classification is a popular approach to the problem. This type of classifier is characterized by the property that samples are subjected to a sequence of decision rules before they are assigned to a unique class. If a decision tree classifier is well designed, the result in many cases is a classification scheme which is accurate, flexible, and computationally efficient. This correspondence provides an automated technique for effective decision tree design which relies only on a priori statistics. This procedure utilizes canonical transforms and Bayes table look-up decision rules. An optimal design at each node is derived based on the associated decision table. A procedure for computing the global probability of correct classification is also provided. An example is given in which class statistics obtained from an actual Landsat scene are used as input to the program. The resulting decision tree design has an associated probability of correct classification of 0.75 compared to the theoretically optimum 0.79 probability of correct classification associated with a full dimensional Bayes classifier. Recommendations for future research are included."
            },
            "slug": "An-Automated-Approach-to-the-Design-of-Decision-Argentiero-Chin",
            "title": {
                "fragments": [],
                "text": "An Automated Approach to the Design of Decision Tree Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This correspondence provides an automated technique for effective decision tree design which relies only on a priori statistics."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319258"
                        ],
                        "name": "C. Darken",
                        "slug": "C.-Darken",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Darken",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Darken"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32498041"
                        ],
                        "name": "M. Donahue",
                        "slug": "M.-Donahue",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Donahue",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Donahue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48491389"
                        ],
                        "name": "L. Gurvits",
                        "slug": "L.-Gurvits",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Gurvits",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gurvits"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790264"
                        ],
                        "name": "Eduardo Sontag",
                        "slug": "Eduardo-Sontag",
                        "structuredName": {
                            "firstName": "Eduardo",
                            "lastName": "Sontag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eduardo Sontag"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6260397,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "01a3956e07bef9474080a70903c27521112130c2",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The set of functions which a single hidden layer neural network can approximate is increasingly well understood, yet our knowledge of how the approximation error depends upon the number of hidden units, i.e. the rate of approximation, remains relatively primitive. Barron [1991] and Jones [1992] give bounds on the rate of approximation valid for Hilbert spaces. We derive bounds for L spaces, 1 < p < m, recovering the 0(1 /&) bounds of Barron and Jones for the case p = 2. The results were motivated in part by the desire to understand approximation in the more \u201crobust\u201d (resistant to exemplar noise) LP, 1 ~ p <2 norms. Consider the task of approximating a given target function f by a linear combination of n functions from a set S. For example, S may be the set of possible sigmoidal activation functions, {g : ~d ~[% 6 ~d, b E ~, s.t. g(z) = a(a . z + b)}, in which case the approximants are single hidden layer neural networks with a linear output layer. It is known that under very weak conditions on IS (it must be Riemann integrable and nonpolynomial), the linear span of S is dense in the set of continuous functions on compact subsets of ~d (i.e. for all positive c there is a linear combination of functions in S which can approximate any continuous function to within c everywhere on a compact domain) [Leshno et al. 1992]. Consider the important rate of approximation issue, i.e. the rate at which the achievable error reduces as we allow larger subsets of S to be used in const rutting the approximant. In the context of neural networks, this is the question of how the approximation error scales with the number of hidden units in the network. Unfortunately, approximation bounds for target functions ~ arbitrarily located in the linear closure (i.e. the closure of the span) of S are unknown. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. ACM COLT \u201993 17/931CA, USA @ 1993 ACM 0-89791-61 1-5193 /000710303 . ..$1 .50 Leonid Gurvits Eduardo Sontag Learning Systems Dept. Dept. of Mathematics Siemens Corp. Research Rutgers University 755 College Road East New Brunswick, NJ 08903 Princeton, NJ 08540 sontag@control. rutgers. edu gurvitsrlscr. aiemena. com However, progress haa been made recently by introducing the assumptions that f is in the convex closure of S, and that S is bounded in the relevant norm. This theory depends neither on the continuity of f nor on the form of the functions in S (i.e. the functions in S do not need to be sigmoidal or obey the constraints on ~ listed above), but only on the properties of the function space and some generic properties of S. Definition 1 Let X be a Banach space v.rith norm II ! II. Let S ~ X and f E X. Dejine lllinnS fl[ := inf \u2018&W, \u2013 f , (1) i=l where the injimum is over all gl, . . . . gn c S and al, ..., an E ~. Also define llconS \u2013 fll := inf ~ a~ga f , (2) %=1 where the infimum is over all gl, . . . . g~ E S and al, ..., crn G ~+ U {O} such that ~ ai = 1. That is, lllinnS \u2013 fll is the distance of f from the closest span of n functions from S (linear approximation bound), and llconS \u2013 fll is the distance off from the closest convex hull of n functions from S (convex approximation bound). Note that [1Iinn S \u2013 f II ~ IIco.S f Il. These bounds converge to zero as n ~ co for approximable f and thus represent the convergence rates of the best approximants to the target function. The study of such rates is standard in approximation theory (e.g. [Powell 1981] ), but the cases of interest for neural networks are not among those classically considered. For spaces of square-integrable functions (or more general Hilbert spaces) and bounded sets S, Barron [1991] presented results at this conference to the effect that llco~S \u2013 fllz = 0(1/@). Subsequently, under additional conditions on S, he has shown that the same rate obtains for the uniform norm [Barren 1992]. If we consider the procedure of constructing approximants to f incrementally, bv formimz a convex combination of the last approxirna~t with a-single new element convergence rate in Lz is interestingly again 303 of S, the o(l/fi)"
            },
            "slug": "Rate-of-approximation-results-motivated-by-robust-Darken-Donahue",
            "title": {
                "fragments": [],
                "text": "Rate of approximation results motivated by robust neural network learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Bounds on the rate of approximation valid for Hilbert spaces are derived and bounds for L spaces, 1 < p < m, are derived, recovering the 0(1 /&) bounds of Barron and Jones for the case p = 2."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1955900"
                        ],
                        "name": "C. Hwang",
                        "slug": "C.-Hwang",
                        "structuredName": {
                            "firstName": "Chii-Ruey",
                            "lastName": "Hwang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Hwang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14650349,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2d00d92e9ff17ce7fe991e700a1ce8ced639c2c8",
            "isKey": false,
            "numCitedBy": 378,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Maximum likelihood estimation often fails when the parameter takes values in an infinite dimensional space. For example, the maximum likelihood method cannot be applied to the completely nonparametric estimation of a density function from an iid sample; the maximum of the likelihood is not attained by any density. In this example, as in many other examples, the parameter space (positive functions with area one) is too big. But the likelihood method can often be salvaged if we first maximize over a constrained subspace of the parameter space and then relax the constraint as the sample size grows. This is Grenander's \"method of sieves.\" Application of the method sometimes leads to new estimators for familiar problems, or to a new motivation for an already well-studied technique. We will establish some general consistency results for the method, and then we will focus on three applications."
            },
            "slug": "Nonparametric-Maximum-Likelihood-Estimation-by-the-Geman-Hwang",
            "title": {
                "fragments": [],
                "text": "Nonparametric Maximum Likelihood Estimation by the Method of Sieves"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102383712"
                        ],
                        "name": "K. Matusita",
                        "slug": "K.-Matusita",
                        "structuredName": {
                            "firstName": "Kameo",
                            "lastName": "Matusita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Matusita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117761864,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "72fde2839c7de5c202c606371f1def0f9f41406a",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "DISCRIMINATION-AND-THE-AFFINITY-OF-DISTRIBUTIONS-Matusita",
            "title": {
                "fragments": [],
                "text": "DISCRIMINATION AND THE AFFINITY OF DISTRIBUTIONS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1887059"
                        ],
                        "name": "W. Loh",
                        "slug": "W.-Loh",
                        "structuredName": {
                            "firstName": "Wei-Yin",
                            "lastName": "Loh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Loh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13617534"
                        ],
                        "name": "N. Vanichsetakul",
                        "slug": "N.-Vanichsetakul",
                        "structuredName": {
                            "firstName": "Nunta",
                            "lastName": "Vanichsetakul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vanichsetakul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120681576,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1bddf0884c1629f77833eb59b8fa76fe02773bab",
            "isKey": false,
            "numCitedBy": 345,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The problem of constructing classification rules that can be represented as decision trees is considered. Each object to be classified has an associated x vector containing possibly incomplete covariate information. Tree construction is based on the information provided in a \u201clearning sample\u201d of objects with known class identities. The x vectors in the learning sample may have missing values as well. Procedures are proposed for each of the components of classifier construction, such as split selection, tree-size determination, treatment of missing values, and ranking of variables. The main idea is recursive application of linear discriminant analysis, with the variables at each stage being appropriately chosen according to the data and the type of splits desired. Standard statistical techniques used as basic building blocks include analysis of variance, linear and canonical discriminant analysis, and principal component analysis. A new method of tree-structured classification is obtained by assem..."
            },
            "slug": "Tree-Structured-Classification-via-Generalized-Loh-Vanichsetakul",
            "title": {
                "fragments": [],
                "text": "Tree-Structured Classification via Generalized Discriminant Analysis."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new method of tree-structured classification is obtained by recursive application of linear discriminant analysis, with the variables at each stage being appropriately chosen according to the data and the type of splits desired."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16045616,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "32ba0664f51c88960fc9b783a9c0adb6b0546e73",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Let R^{\\ast} denote the Bayes risk (minimum expected loss) for the problem of estimating \\theta \\varepsilon \\Theta , given an observed random variable x , joint probability distribution F(x,\\theta) , and loss function L . Consider the problem in which the only knowledge of F is that which can be inferred from samples (x_{1},\\theta_{1}),(x_{2},\\theta_{2}), \\cdots ,(x_{n}, \\theta_{n}) , where the (x_{i}, \\theta_{i})'s are independently identically distributed according to F . Let the nearest neighbor estimate of the parameter \\theta associated with an observation x be defined to be the parameter \\theta_{n}^{'} associated with the nearest neighbor x_{n}^{'} to x . Let R be the large sample risk of the nearest neighbor rule. It will be shown, for a wide range of probability distributions, that R \\leq 2R^{\\ast} for metric loss functions and R = 2R^{\\ast} for squared-error loss functions. A simple estimator using the nearest k neighbors yields R = R^{\\ast} (1 + 1/k) in the squared-error loss case. In this sense, it can be said that at least haft the information in the infinite training set is contained in the nearest neighbor. This paper is an extension of earlier work[q from the problem of classification by the nearest neighbor rule to that of estimation. However, the unbounded loss functions in the estimation problem introduce additional problems concerning the convergence of the unconditional risk. Thus some work is devoted to the investigation of natural conditions on the underlying distribution assuring the desired convergence."
            },
            "slug": "Estimation-by-the-nearest-neighbor-rule-Cover",
            "title": {
                "fragments": [],
                "text": "Estimation by the nearest neighbor rule"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper is an extension of earlier work from the problem of classification by the nearest neighbor rule to that of estimation, where the unbounded loss functions in the estimation problem introduce additional problems concerning the convergence of the unconditional risk."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49231821"
                        ],
                        "name": "P. Chaudhuri",
                        "slug": "P.-Chaudhuri",
                        "structuredName": {
                            "firstName": "Probal",
                            "lastName": "Chaudhuri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Chaudhuri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069291118"
                        ],
                        "name": "Wen-da Lo",
                        "slug": "Wen-da-Lo",
                        "structuredName": {
                            "firstName": "Wen-da",
                            "lastName": "Lo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen-da Lo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1887059"
                        ],
                        "name": "W. Loh",
                        "slug": "W.-Loh",
                        "structuredName": {
                            "firstName": "Wei-Yin",
                            "lastName": "Loh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Loh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102756749"
                        ],
                        "name": "Ching-Ching Yang",
                        "slug": "Ching-Ching-Yang",
                        "structuredName": {
                            "firstName": "Ching-Ching",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ching-Ching Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9942566,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "15dec78f135d7d55a8e1557b3c9b5a1145b11910",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of generalized regression that blends tree-structured nonparametric regression and adaptive recursive partitioning with maximum likelihood estimation is studied. The function estimate is a piecewise polynomial, with the pieces determined by the terminal nodes of a binary decision tree. The decision tree is constructed by recursively partitioning the data according to the signs of the residuals from a model fitted by maximum likelihood to each node. Algorithms for tree-structured Poisson and logistic regression and examples to illustrate them are given. Large-sample properties of the estimates are derived under appropriate regularity conditions."
            },
            "slug": "Generalized-regression-trees-Chaudhuri-Lo",
            "title": {
                "fragments": [],
                "text": "Generalized regression trees"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A method of generalized regression that blends tree-structured nonparametric regression and adaptive recursive partitioning with maximum likelihood estimation is studied and large-sample properties of the estimates are derived under appropriate regularity conditions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31575758"
                        ],
                        "name": "Chin-Liang Chang",
                        "slug": "Chin-Liang-Chang",
                        "structuredName": {
                            "firstName": "Chin-Liang",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Liang Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11156800,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a9674c5a65e745ce6ed40b5d76a1d8701ffa709",
            "isKey": false,
            "numCitedBy": 365,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A nearest neighbor classifier is one which assigns a pattern to the class of the nearest prototype. An algorithm is given to find prototypes for a nearest neighbor classifier. The idea is to start with every sample in a training set as a prototype, and then successively merge any two nearest prototypes of the same class so long as the recognition rate is not downgraded. The algorithm is very effective. For example, when it was applied to a training set of 514 cases of liver disease, only 34 prototypes were found necessary to achieve the same recognition rate as the one using the 514 samples of the training set as prototypes. Furthermore, the number of prototypes in the algorithm need not be specified beforehand."
            },
            "slug": "Finding-Prototypes-For-Nearest-Neighbor-Classifiers-Chang",
            "title": {
                "fragments": [],
                "text": "Finding Prototypes For Nearest Neighbor Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An algorithm is given to find prototypes for a nearest neighbor classifier, which is to start with every sample in a training set as a prototype, and then successively merge any two nearest prototypes of the same class so long as the recognition rate is not downgraded."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2160457"
                        ],
                        "name": "T. Yunck",
                        "slug": "T.-Yunck",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Yunck",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Yunck"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28699935,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5799ec483676e88fead0087e595f8620a25aee3c",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A nonarithmetic procedure is described for discovering among a set of points in a d-dimensional space, the k neighbors nearest a given point, according to the Minkowski \"max metric.\" It is shown that this procedure may be used to eliminate distance calculations when finding nearest neighbors according to any Minkowski p-metric. When used with a set of uniformly distributed sample points, the expected number of distance calculations n required by this technique is given by E[n] \u00bf kCp,d where Cp,d is a constant determined by p and d. In the case of the Euclidean metric used in two dimensions with 1000 uniformly distributed sample points, the effective number of distance calculations required to find the nearest neighbor is approximately five."
            },
            "slug": "A-Technique-to-Identify-Nearest-Neighbors-Yunck",
            "title": {
                "fragments": [],
                "text": "A Technique to Identify Nearest Neighbors"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "It is shown that this procedure may be used to eliminate distance calculations when finding nearest neighbors according to any Minkowski p-metric."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32022171"
                        ],
                        "name": "Sahibsingh A. Dudani",
                        "slug": "Sahibsingh-A.-Dudani",
                        "structuredName": {
                            "firstName": "Sahibsingh",
                            "lastName": "Dudani",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sahibsingh A. Dudani"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23693378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56cfeec725f5ef9dd620e9d836faacd79f5a812d",
            "isKey": false,
            "numCitedBy": 1224,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Among the simplest and most intuitively appealing classes of nonprobabilistic classification procedures are those that weight the evidence of nearby sample observations most heavily. More specifically, one might wish to weight the evidence of a neighbor close to an unclassified observation more heavily than the evidence of another neighbor which is at a greater distance from the unclassified observation. One such classification rule is described which makes use of a neighbor weighting function for the purpose of assigning a class to an unclassified sample. The admissibility of such a rule is also considered."
            },
            "slug": "The-Distance-Weighted-k-Nearest-Neighbor-Rule-Dudani",
            "title": {
                "fragments": [],
                "text": "The Distance-Weighted k-Nearest-Neighbor Rule"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "One such classification rule is described which makes use of a neighbor weighting function for the purpose of assigning a class to an unclassified sample."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775720"
                        ],
                        "name": "D. Hummels",
                        "slug": "D.-Hummels",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Hummels",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hummels"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12662708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb360bdebe84b014c3d3096c950a0ef3fe3dbd7e",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of k nearest neighbor (k-NN) and Parzen density estimates to obtain estimates of the Bayes error is investigated under limited design set conditions. By drawing analogies between the k-NN and Parzen procedures, new procedures are suggested, and experimental results are given which indicate that these procedures yield a significant improvement over the conventional k-NN and Parzen procedures. We show that, by varying the decision threshold, many of the biases associated with the k-NN or Parzen density estimates may be compensated, and successful error estimation may be performed in spite of these biases. Experimental results are given which demonstrate the effect of kernel size and shape (Parzen), the size of k (k-NN), and the number of samples in the design set."
            },
            "slug": "Bayes-Error-Estimation-Using-Parzen-and-k-NN-Fukunaga-Hummels",
            "title": {
                "fragments": [],
                "text": "Bayes Error Estimation Using Parzen and k-NN Procedures"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that, by varying the decision threshold, many of the biases associated with the k-NN or Parzen density estimates may be compensated, and successful error estimation may be performed in spite of these biases."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12790395"
                        ],
                        "name": "G. Wise",
                        "slug": "G.-Wise",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Wise",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wise"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2285097,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6689636d1394eb075a205ef3925acf9e2e99a738",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Consistency-of-a-recursive-nearest-neighbor-Devroye-Wise",
            "title": {
                "fragments": [],
                "text": "Consistency of a recursive nearest neighbor regression function estimate"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67049458"
                        ],
                        "name": "G. Tutz",
                        "slug": "G.-Tutz",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Tutz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tutz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121826981,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c79943bc5bb69bb3d9479fd48351b407bebecac1",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY The kernel method of estimating the cell probabilities of a multivariate categorical distribution, due to Aitchison & Aitken (1976), depends crucially on an unknown smoothing parameter A. A method of estimating A is introduced which is explicitly connected to multivariate discrimination. The method, based on maximization of the leaving-one-out estimator of the nonerror rate, is shown to be Bayes risk strongly consistent. An example is given to illustrate the application."
            },
            "slug": "An-alternative-choice-of-smoothing-for-kernel-based-Tutz",
            "title": {
                "fragments": [],
                "text": "An alternative choice of smoothing for kernel-based density estimates in discrete discriminant analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2960620"
                        ],
                        "name": "W. Meisel",
                        "slug": "W.-Meisel",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Meisel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Meisel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39926861"
                        ],
                        "name": "D. Michalopoulos",
                        "slug": "D.-Michalopoulos",
                        "structuredName": {
                            "firstName": "Demetrios",
                            "lastName": "Michalopoulos",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Michalopoulos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39513211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5189ef7b7a7e9a1b49decfca061d57f441087bac",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The efficient partitioning of a finite-dimensional space by a decision tree, each node of which corresponds to a comparison involving a single variable, is a problem occurring in pattern classification, piecewise-constant approximation, and in the efficient programming of decision trees. A two-stage algorithm is proposed. The first stage obtains a sufficient partition suboptimally, either by methods suggested in the paper or developed elsewhere; the second stage optimizes the results of the first stage through a dynamic programming approach. In pattern classification, the resulting decision rule yields the minimum average number of calculations to reach a decision. In approximation, arbitrary accuracy for a finite number of unique samples is possible. In programming decision trees, the expected number of computations to reach a decision is minimized."
            },
            "slug": "A-Partitioning-Algorithm-with-Application-in-and-of-Meisel-Michalopoulos",
            "title": {
                "fragments": [],
                "text": "A Partitioning Algorithm with Application in Pattern Classification and the Optimization of Decision Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A two-stage algorithm that obtains a sufficient partition suboptimally, either by methods suggested in the paper or developed elsewhere, and optimizes the results of the first stage through a dynamic programming approach is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67049458"
                        ],
                        "name": "G. Tutz",
                        "slug": "G.-Tutz",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Tutz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tutz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123382286,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "f258eb15ebbb59b8dd9cad7f3cd4ef297622e220",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The choice of smoothing determines the properties of nonparametric estimates of probability densities. In the discrimination problem, the choice is often tied to loss functions. A framework for the cross\u2013validatory choice of smoothing parameters based on general loss functions is given. Several loss functions are considered as special cases. In particular, a family of loss functions, which is connected to discrimination problems, is directly related to measures of performance used in discrimination. Consistency results are given for a general class of loss functions which comprise this family of discriminant loss functions."
            },
            "slug": "On-cross-validation-for-discrete-kernel-estimates-Tutz",
            "title": {
                "fragments": [],
                "text": "On cross-validation for discrete kernel estimates in discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A framework for the cross\u2013validatory choice of smoothing parameters based on general loss functions is given and a family of loss functions, connected to discrimination problems, is connected to measures of performance used in discrimination."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149702798"
                        ],
                        "name": "H. White",
                        "slug": "H.-White",
                        "structuredName": {
                            "firstName": "Halbert",
                            "lastName": "White",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. White"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 205119351,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77fdd39ab366b65a617015a72fe8dc9d0b394d64",
            "isKey": false,
            "numCitedBy": 716,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Connectionist-nonparametric-regression:-Multilayer-White",
            "title": {
                "fragments": [],
                "text": "Connectionist nonparametric regression: Multilayer feedforward networks can learn arbitrary mappings"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642550"
                        ],
                        "name": "W. Krzanowski",
                        "slug": "W.-Krzanowski",
                        "structuredName": {
                            "firstName": "Wojtek",
                            "lastName": "Krzanowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Krzanowski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121996661,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "45c7b0082a3078fbd65843e23d11840c290cb843",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A distance-based classification procedure suggested by Matusita (1956) has long been available as an alternative to the usual Bayes decision rule. Unsatisfactory features of both approaches when applied to multinomial data led Goldstein and Dillon (1978) to propose a new distance-based principle for classification. We subject the Goldstein/Dillon principle to some theoretical scrutiny by deriving the population classification rules appropriate not only to multinomial data but also to multivariate normal and mixed multinomial/multinormal data. These rules demonstrate equivalence of the Goldstein/Dillon and Matusita approaches for the first two data types, and similar equivalence is conjectured (but not explicitly obtained) for the mixed data case. Implications for sample-based rules are noted."
            },
            "slug": "A-comparison-between-two-distance-based-principles-Krzanowski",
            "title": {
                "fragments": [],
                "text": "A comparison between two distance-based discriminant principles"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67049458"
                        ],
                        "name": "G. Tutz",
                        "slug": "G.-Tutz",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Tutz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tutz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20694543,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0740f6aebc75d4ac3ccdb69a3738a6fcbcd1fc64",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Smoothed-additive-estimators-for-non-error-rates-in-Tutz",
            "title": {
                "fragments": [],
                "text": "Smoothed additive estimators for non-error rates in multiple discriminant analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702517"
                        ],
                        "name": "I. Sethi",
                        "slug": "I.-Sethi",
                        "structuredName": {
                            "firstName": "Ishwar",
                            "lastName": "Sethi",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Sethi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3266532"
                        ],
                        "name": "G. P. R. Sarvarayudu",
                        "slug": "G.-P.-R.-Sarvarayudu",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Sarvarayudu",
                            "middleNames": [
                                "P.",
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. P. R. Sarvarayudu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18707355,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66ee4bb5d704856f43d751c259a7b5de9c77b764",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A nonparametric algorithm is presented for the hierarchical partitioning of the feature space. The algorithm is based on the concept of average mutual information, and is suitable for multifeature multicategory pattern recognition problems. The algorithm generates an efficient partitioning tree for specified probability of error by maximizing the amount of average mutual information gain at each partitioning step. A confidence bound expression is presented for the resulting classifier. Three examples, including one of handprinted numeral recognition, are presented to demonstrate the effectiveness of the algorithm."
            },
            "slug": "Hierarchical-Classifier-Design-Using-Mutual-Sethi-Sarvarayudu",
            "title": {
                "fragments": [],
                "text": "Hierarchical Classifier Design Using Mutual Information"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A nonparametric algorithm is presented for the hierarchical partitioning of the feature space that generates an efficient partitioning tree for specified probability of error by maximizing the amount of average mutual information gain at each partitioning step."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49257941"
                        ],
                        "name": "G. Beakley",
                        "slug": "G.-Beakley",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Beakley",
                            "middleNames": [
                                "W."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Beakley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9365227"
                        ],
                        "name": "F. Tuteur",
                        "slug": "F.-Tuteur",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Tuteur",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Tuteur"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206619049,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5277f4af5f79950ba03f928434152987ca8dbf1",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "A nonparametric classification procedure based on distribution-free tolerance regions is presented. Without knlowledge of the class probability distributions, the procedure gives information about the expected performance of the classifier through use of only one sample of statistically independent observations from each class. With this procedure, a two-class discriminant can be designed for a given expected false alarm probability or for a given confidence that the false alarm probability is less than a given amount. Three ordering methods are presented that appear intuitively reasonable for minimizing the miss probability. Even though the methods do not, in general, meet this objective, they are easily implemented on a computer and can give good results. A procedure for obtaining a measure of the miss probability is also presented. These methods are applied to the problem of verifying the purported identity of a speaker from a sample of the speaker's voice."
            },
            "slug": "Distribution-Free-Pattern-Verification-Using-Blocks-Beakley-Tuteur",
            "title": {
                "fragments": [],
                "text": "Distribution-Free Pattern Verification Using Statistically Equivalent Blocks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Three ordering methods are presented that appear intuitively reasonable for minimizing the miss probability and are applied to the problem of verifying the purported identity of a speaker from a sample of the speaker's voice."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145617206"
                        ],
                        "name": "J. Myles",
                        "slug": "J.-Myles",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Myles",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Myles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781982"
                        ],
                        "name": "D. Hand",
                        "slug": "D.-Hand",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hand",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hand"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46365060,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "63f8da040bf2eb1249b0e0b38ce3b0c18844cb66",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-multi-class-metric-problem-in-nearest-neighbour-Myles-Hand",
            "title": {
                "fragments": [],
                "text": "The multi-class metric problem in nearest neighbour discrimination rules"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158092105"
                        ],
                        "name": "L. Zhao",
                        "slug": "L.-Zhao",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Zhao",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Zhao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122188207,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "64af91d07129bd20c216e68a9a397afc85c23760",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Exponential-bounds-of-mean-error-for-the-nearest-of-Zhao",
            "title": {
                "fragments": [],
                "text": "Exponential bounds of mean error for the nearest neighbor estimates of regression functions*1"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3023298"
                        ],
                        "name": "I. Tomek",
                        "slug": "I.-Tomek",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Tomek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Tomek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26445841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6138b121632b6df163f9bf521ccf0a71e16abc84",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A modification of the k-nearest neighbors (k-NN) rule is presented in which classification is made not according to the ``majority vote'' but rather an integer threshold k1 (k1-NN rule). It is shown that while k-NN approximates the minimum expected error rule, k1-NN approximates the minimum expected risk rule with a threshold t. The relationship between t and values of k and k1 is derived. Several practical methods of using k1-NN for minimum expected risk classification and for classification with a reject option are described and illustrated with examples."
            },
            "slug": "A-Generalization-of-the-k-NN-Rule-Tomek",
            "title": {
                "fragments": [],
                "text": "A Generalization of the k-NN Rule"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A modification of the k-nearest neighbors (k-NN) rule is presented in which classification is made not according to the ``majority vote'' but rather an integer threshold k1 (k1-NN rule)."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144589701"
                        ],
                        "name": "H. Payne",
                        "slug": "H.-Payne",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Payne",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Payne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2960620"
                        ],
                        "name": "W. Meisel",
                        "slug": "W.-Meisel",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Meisel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Meisel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7004358,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "8c9fa00e4b148060c5f79a9d5446b9ec1e1e54c3",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of optimally partitioning an n-dimensional lattice, L = L, X ... X LN, where Lj is a one-dimensional lattice with kj elements, by means of a binary tree into specified (labeled) subsets of L. Such lattices arise from problems in pattern classification, in nonlinear regression, in defining logical equations, and a number of related areas. When viewed as the partitioning of a vector space, each point in the lattice corresponds to a subregion of the space which is relatively homogeneous with respect to classification or range of a dependent variable. Optimality is defined in terms of a general cost function which includes the following: 1) min-max path length (i. e., minimize the maximum number of nodes traversed in making a decision); 2) minimum number of nodes in the tree; and 3) expected path length. It is shown that an optimal tree can be recursively constructed through the application of invariant imbedding (dynamic programming). An algorithm is detailed which embodies this recursive approach. The algorithm allows the assignment of a \"don't care\" label to elements of L."
            },
            "slug": "An-Algorithm-for-Constructing-Optimal-Binary-Trees-Payne-Meisel",
            "title": {
                "fragments": [],
                "text": "An Algorithm for Constructing Optimal Binary Decision Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "It is shown that an optimal tree can be recursively constructed through the application of invariant imbedding (dynamic programming) and an algorithm is detailed which embodies this recursive approach."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068269859"
                        ],
                        "name": "G. Gates",
                        "slug": "G.-Gates",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Gates",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gates"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59807665,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a64897e672e3f112a012e41ef40d905b599d1e1",
            "isKey": false,
            "numCitedBy": 505,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Fig. 3 shows PG,.,,,,, (m) for various numbers of observations N and various sizes of memory m. The Chernoff bound on P,*(a) was used for N 2 32. Quite naturally one does better with more memory. The P~,sym(m) curve for any given value of m follows the P,*(co) line for low values of N, diverges from it for larger values of N, and approaches a nonzero limit P,*(m) as N + co. This behavior is easily explained. Any given machine can \u201cremember\u201d all of the observations for low values of N. Here infinite memory offers no advantages. For larger values of N, a finite-state machine necessarily loses some information and thus does not do so well as one with infinite memory. As N -+ co, Pz sym(m) approaches Pm*(m), the infinite-time lower bound on the probability of error, since from [I] we know that for N = co the optimal machine is symmetric."
            },
            "slug": "The-Reduced-Nearest-Neighbor-Rule-Gates",
            "title": {
                "fragments": [],
                "text": "The Reduced Nearest Neighbor Rule"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16614627"
                        ],
                        "name": "D. Kessell",
                        "slug": "D.-Kessell",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kessell",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kessell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5998114,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "fb0b4d98e343d413f36b070947297687d01358a6",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses methods of estimating the probability of error for the Bayes' classifier which must be designed and tested with a finite number of classified samples. The expected difference between estimates is discussed. A simplifled algorithm to compute the leaving-one-out method is proposed for multivariate normal distributions wtih unequal co-variance matrices. The discussion is extended to nonparametric classifiers by using the Parzen approximation for the density functions. Experimental results are shown for both parametric and nonparametric cases."
            },
            "slug": "Estimation-of-Classification-Error-Fukunaga-Kessell",
            "title": {
                "fragments": [],
                "text": "Estimation of Classification Error"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "Methods of estimating the probability of error for the Bayes' classifier which must be designed and tested with a finite number of classified samples are discussed and the expected difference between estimates is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3013580"
                        ],
                        "name": "Q. Wang",
                        "slug": "Q.-Wang",
                        "structuredName": {
                            "firstName": "Qing",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ren"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16172821,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b343361ceecb7bd67185f10a9721dfc410daafb",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Based on a recursive process of reducing the entropy, the general decision tree classifier with overlap has been analyzed. Several theorems have been proposed and proved. When the number of pattern classes is very large, the theorems can reveal both the advantages of a tree classifier and the main difficulties in its implementation. Suppose H is Shannon's entropy measure of the given problem. The theoretical results indicate that the tree searching time can be minimized to the order O(H), but the error rate is also in the same order O(H) due to error accumulation. However, the memory requirement is in the order 0(H exp(H)) which poses serious problems in the implementation of a tree classifier for a large number of classes. To solve these problems, several theorems related to the bounds on the search time, error rate, memory requirement and overlap factor in the design of a decision tree have been proposed and some principles have been established to analyze the behaviors of the decision tree. When applied to classify sets of 64, 450, and 3200 Chinese characters, respectively, the experimental results support the theoretical predictions. For 3200 classes, a very high recognition rate of 99.88 percent was achieved at a high speed of 873 samples/s when the experiment was conducted on a Cyber 172 computer using a high-level language."
            },
            "slug": "Analysis-and-Design-of-a-Decision-Tree-Based-on-and-Wang-Suen",
            "title": {
                "fragments": [],
                "text": "Analysis and Design of a Decision Tree Based on Entropy Reduction and Its Application to Large Character Set Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Several theorems related to the bounds on the search time, error rate, memory requirement and overlap factor in the design of a decision tree have been proposed and some principles have been established to analyze the behaviors of the decision tree."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12416004"
                        ],
                        "name": "J. Stoffel",
                        "slug": "J.-Stoffel",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Stoffel",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Stoffel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206620347,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9a1e5d2867543c9c8890c09702f85ef6f679527",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new computerized technique to aid the designers of pattern classifiers when the measurement variables are discrete and the values form a simple nominal scale (no inherent metric). A theory of \"prime events\" which applies to patterns with measurements of this type is presented. A procedure for applying the theory of \"prime events\" and an analysis of the \"prime event estimates\" is given. To manifest additional characteristics of this technique, an example optical character recognition (OCR) application is discussed."
            },
            "slug": "A-Classifier-Design-Technique-for-Discrete-Variable-Stoffel",
            "title": {
                "fragments": [],
                "text": "A Classifier Design Technique for Discrete Variable Pattern Recognition Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A new computerized technique to aid the designers of pattern classifiers when the measurement variables are discrete and the values form a simple nominal scale (no inherent metric)."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069581"
                        ],
                        "name": "A. Farag\u00f3",
                        "slug": "A.-Farag\u00f3",
                        "structuredName": {
                            "firstName": "Andr\u00e1s",
                            "lastName": "Farag\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Farag\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143649637"
                        ],
                        "name": "T. Linder",
                        "slug": "T.-Linder",
                        "structuredName": {
                            "firstName": "Tam\u00e1s",
                            "lastName": "Linder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Linder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755694"
                        ],
                        "name": "G. Lugosi",
                        "slug": "G.-Lugosi",
                        "structuredName": {
                            "firstName": "G\u00e1bor",
                            "lastName": "Lugosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lugosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15862292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25f7b9017d9cc1a2f955c2a6d81ebb5e15df5714",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A fast nearest-neighbor algorithm is presented. It works in general spaces in which the known cell techniques cannot be implemented for various reasons, such as the absence of coordinate structure or high dimensionality. The central idea has already appeared several times in the literature with extensive computer simulation results. An exact probabilistic analysis of this family of algorithms that proves its O(1) asymptotic average complexity measured in the number of dissimilarity calculations is presented. >"
            },
            "slug": "Fast-Nearest-Neighbor-Search-in-Dissimilarity-Farag\u00f3-Linder",
            "title": {
                "fragments": [],
                "text": "Fast Nearest-Neighbor Search in Dissimilarity Spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An exact probabilistic analysis of this family of algorithms that proves its O(1) asymptotic average complexity measured in the number of dissimilarity calculations is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143971171"
                        ],
                        "name": "P. Hall",
                        "slug": "P.-Hall",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hall"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121299539,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ecd1da6d6b55accde66a26e4a1f51bf579ee3c32",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Aitchison & Aitken (1976) introduced a novel and ingenious nonparametric method for estimating probabilities in a multidimensional binary space. The technique is designed for use in multivariate binary discrimination. Their estimator depends crucially on an unknown smoothing parameter A, and Aitchison & Aitken proposed a maximum likelihood method for determining A from the sample. Unfortunately this leads to an adaptive estimator which can behave very erratically when there are a number of empty or near empty cells present. We demonstrate this both theoretically and by example. To overcome these difficulties we introduce another method of estimating A which is designed to minimize a global function of the mean squared error."
            },
            "slug": "On-nonparametric-multivariate-binary-discrimination-Hall",
            "title": {
                "fragments": [],
                "text": "On nonparametric multivariate binary discrimination"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40371037"
                        ],
                        "name": "Alan J. Broder",
                        "slug": "Alan-J.-Broder",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Broder",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alan J. Broder"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43905614,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0c7f2a9d6a71e5f4a18921e552b8ed3b476b592",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Strategies-for-efficient-incremental-nearest-search-Broder",
            "title": {
                "fragments": [],
                "text": "Strategies for efficient incremental nearest neighbor search"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701411"
                        ],
                        "name": "J. Ullmann",
                        "slug": "J.-Ullmann",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Ullmann",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ullmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45278551,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec68cf5de7cbd2147965b7fa1bd0256f31e9cf84",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Two methods for automatic selection of nearest-neighbor reference data have been compared in small-scale experimentation. One of the methods is original and appears to be more successful than Hart's well-known \"condensed nearest-neighbor\" method [1]."
            },
            "slug": "Automatic-selection-of-reference-data-for-use-in-a-Ullmann",
            "title": {
                "fragments": [],
                "text": "Automatic selection of reference data for use in a nearest-neighbor method of pattern classification (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Two methods for automatic selection of nearest-neighbor reference data have been compared in small-scale experimentation and one of the methods is original and appears to be more successful than Hart's well-known \"condensed nearest-NEighbor\" method."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3291954"
                        ],
                        "name": "M. Golea",
                        "slug": "M.-Golea",
                        "structuredName": {
                            "firstName": "Mostefa",
                            "lastName": "Golea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Golea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143858557"
                        ],
                        "name": "M. Marchand",
                        "slug": "M.-Marchand",
                        "structuredName": {
                            "firstName": "Mario",
                            "lastName": "Marchand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marchand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 121480878,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "998422c0ec8eee016f9852a7dd347bd6a60a659b",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the application of neural network principles to the construction of decision trees from examples. We consider the problem of constructing a tree of perceptrons able to execute a given but arbitrary Boolean function defined on Ni input bits. We apply a sequential (from one tree level to the next) and parallel (for neurons in the same level) learning procedure to add hidden units until the task in hand is performed. At each step, we use a perceptron-type algorithm over a suitable defined input space to minimize a classification error. The internal representations obtained in this way are linearly separable. Preliminary results of this algorithm are presented."
            },
            "slug": "A-Growth-Algorithm-for-Neural-Network-Decision-Golea-Marchand",
            "title": {
                "fragments": [],
                "text": "A Growth Algorithm for Neural Network Decision Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This paper considers the problem of constructing a tree of perceptrons able to execute a given but arbitrary Boolean function defined on Ni input bits and applies a sequential and parallel learning procedure to add hidden units until the task in hand is performed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97306284"
                        ],
                        "name": "K. Fu",
                        "slug": "K.-Fu",
                        "structuredName": {
                            "firstName": "King-Sun",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074916591"
                        ],
                        "name": "P. Min",
                        "slug": "P.-Min",
                        "structuredName": {
                            "firstName": "Pyung",
                            "lastName": "Min",
                            "middleNames": [
                                "June"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Min"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2162165018"
                        ],
                        "name": "Timothy J. Li",
                        "slug": "Timothy-J.-Li",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Li",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy J. Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31801771,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1092260f7aba26ece6ac0e332ec59d76974254fa",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of feature selection in pattern recognition is briefly reviewed. Feature selection techniques discussed include 1) information theoretic approach, 2) direct estimation of error probability, 3) feature-space transformation, and 4) approach of using stochastic automata model. These techniques are applied to the selection of features in the crop classification problem. Computer similation results are presented and compared."
            },
            "slug": "Feature-Selection-in-Pattern-Recognition-Fu-Min",
            "title": {
                "fragments": [],
                "text": "Feature Selection in Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "Computer similation results are presented and compared and feature selection techniques discussed include 1) information theoretic approach, 2) direct estimation of error probability, 3) feature-space transformation, and 4) approach of using stochastic automata model."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Sci. Cybern."
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9745969"
                        ],
                        "name": "A. Krzy\u017cak",
                        "slug": "A.-Krzy\u017cak",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Krzy\u017cak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krzy\u017cak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143803534"
                        ],
                        "name": "M. Pawlak",
                        "slug": "M.-Pawlak",
                        "structuredName": {
                            "firstName": "Miroslaw",
                            "lastName": "Pawlak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pawlak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45186769,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "3ac98ce8b3cbb39ed7fc66a25c58a7bfa646ed28",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that the kernel estimate of the regression E(Y|X = x) is weakly or strongly consistent for almost all x(\\mu) , where \\mu is the probability measure of X . The result is valid for any distribution of X . The asymptotical optimality of classification rules derived from the estimate is examined. The optimality is independent of class distributions, i.e., it is distribution-free."
            },
            "slug": "Distribution-free-consistency-of-a-nonparametric-Krzy\u017cak-Pawlak",
            "title": {
                "fragments": [],
                "text": "Distribution-free consistency of a nonparametric kernel regression estimate and classification"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "It is shown that the kernel estimate of the regression E(Y|X = x) is weakly or strongly consistent for almost all x(\\mu) , where \\mu is the probability measure of X ."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755694"
                        ],
                        "name": "G. Lugosi",
                        "slug": "G.-Lugosi",
                        "structuredName": {
                            "firstName": "G\u00e1bor",
                            "lastName": "Lugosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lugosi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41368912,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbf2e0a6d48081cb74f8a7abfb6dd14009c9dc2f",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-with-an-unreliable-teacher-Lugosi",
            "title": {
                "fragments": [],
                "text": "Learning with an unreliable teacher"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145913258"
                        ],
                        "name": "N. Glick",
                        "slug": "N.-Glick",
                        "structuredName": {
                            "firstName": "Ned",
                            "lastName": "Glick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Glick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10903624,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1f4aff9f179618e70b089fe5e41c3874f399b682",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Additive-estimators-for-probabilities-of-correct-Glick",
            "title": {
                "fragments": [],
                "text": "Additive estimators for probabilities of correct classification"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2285810"
                        ],
                        "name": "D. Specht",
                        "slug": "D.-Specht",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Specht",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Specht"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122186748,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "818709afcc56b45c4a8aab15e5a69035f31a6cc8",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A class of nonparametric estimators of f(x) based on a set of n observations has been proved by Parzen [l] to be consistent and asymptotically normal subject to certain conditions. Although quite useful for a wide variety of practical problems, these estimators have two serious disadvantages when n is large: 1. All n observations must be stored in rapid-access storage. 2. Evaluation of f(x) for a particular value of x requires a long computation involving each of the observations. The Parzen estimator, which has n terms, can be replaced by a series approximation which has a number of terms determined by the accuracy required in the estimate rather than by the number of observations in the sample. The summation over all of the observations is performed only to establish the value of the coefficients in the series. Although no member of the class of estimators has been proved \u201cbest\u201d for estimating an unknown density from a finite sample, a power series expansion for a particular member of the class was sing..."
            },
            "slug": "Series-Estimation-of-a-Probability-Density-Function-Specht",
            "title": {
                "fragments": [],
                "text": "Series Estimation of a Probability Density Function"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702517"
                        ],
                        "name": "I. Sethi",
                        "slug": "I.-Sethi",
                        "structuredName": {
                            "firstName": "Ishwar",
                            "lastName": "Sethi",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Sethi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116148967"
                        ],
                        "name": "Biswanath Chattkerjee",
                        "slug": "Biswanath-Chattkerjee",
                        "structuredName": {
                            "firstName": "Biswanath",
                            "lastName": "Chattkerjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Biswanath Chattkerjee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29975961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c4a39e43d22b9e39507cde0ccae50859d447a7e",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Efficient-decision-tree-design-for-discrete-pattern-Sethi-Chattkerjee",
            "title": {
                "fragments": [],
                "text": "Efficient decision tree design for discrete variable pattern recognition problems"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801638"
                        ],
                        "name": "J. Kittler",
                        "slug": "J.-Kittler",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Kittler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kittler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922810"
                        ],
                        "name": "P. Devijver",
                        "slug": "P.-Devijver",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Devijver",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Devijver"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42025351,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e1514ec33f0511de688715498c66f7a24dd0b86",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-efficient-estimator-of-pattern-recognition-error-Kittler-Devijver",
            "title": {
                "fragments": [],
                "text": "An efficient estimator of pattern recognition system error probability"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799764"
                        ],
                        "name": "Lasse Holmstr\u00f6m",
                        "slug": "Lasse-Holmstr\u00f6m",
                        "structuredName": {
                            "firstName": "Lasse",
                            "lastName": "Holmstr\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lasse Holmstr\u00f6m"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2838489"
                        ],
                        "name": "Jussi Klemel\u00e4",
                        "slug": "Jussi-Klemel\u00e4",
                        "structuredName": {
                            "firstName": "Jussi",
                            "lastName": "Klemel\u00e4",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jussi Klemel\u00e4"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120900342,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d3ded44ead0c00c5e881b563f5b2adbe91fa8581",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Asymptotic-bounds-for-the-expected-L-1-error-of-a-Holmstr\u00f6m-Klemel\u00e4",
            "title": {
                "fragments": [],
                "text": "Asymptotic bounds for the expected L 1 error of a multivariate kernel density estimator"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2031033"
                        ],
                        "name": "P. Narendra",
                        "slug": "P.-Narendra",
                        "structuredName": {
                            "firstName": "Patrenahalli",
                            "lastName": "Narendra",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Narendra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5941649,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72713a8e1e0fe291b28513dee97596690f4e1376",
            "isKey": false,
            "numCitedBy": 700,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Computation of the k-nearest neighbors generally requires a large number of expensive distance computations. The method of branch and bound is implemented in the present algorithm to facilitate rapid calculation of the k-nearest neighbors, by eliminating the necesssity of calculating many distances. Experimental results demonstrate the efficiency of the algorithm. Typically, an average of only 61 distance computations were made to find the nearest neighbor of a test sample among 1000 design samples."
            },
            "slug": "A-Branch-and-Bound-Algorithm-for-Computing-Fukunaga-Narendra",
            "title": {
                "fragments": [],
                "text": "A Branch and Bound Algorithm for Computing k-Nearest Neighbors"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The method of branch and bound is implemented in the present algorithm to facilitate rapid calculation of the k-nearest neighbors, by eliminating the necesssity of calculating many distances."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085147747"
                        ],
                        "name": "H. Kazmierczak",
                        "slug": "H.-Kazmierczak",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Kazmierczak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kazmierczak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16003990"
                        ],
                        "name": "K. Steinbuch",
                        "slug": "K.-Steinbuch",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Steinbuch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Steinbuch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33241873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be57969160a7fe70bc4305b7c24491396ee961b9",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The perceptual superiority of the human visual system over automata is outlined comparing the properties of both systems. The most effective property with regard to pattern recognition is the internal adaptability and the ability of abstracting. Both properties are well performed by human beings. A mechanical perceptor for complex pattern recognition must also have these capabilities. The use of adaptation for pattern recognition is discussed. The realization of these properties by machines is difficult, especially the development of an adequate feature generator which performs the internal adaptability and thus solves the problem of identification-criteria invariance of patterns. This is assumed to be the main task in pattern recognition research. External teaching processes may be accomplished by adaptive categorizers. The existing classification methods are outlined and discussed with regard to adaptive systems. Adaptive categorizers of a learning matrix type and a perceptron type are compared as to structure, linear classification performance, and training routine. It is assumed, however, that the somewhat passive external adaptation of categorizers must be supplemented by a more active adaptation by the system itself."
            },
            "slug": "Adaptive-Systems-in-Pattern-Recognition-Kazmierczak-Steinbuch",
            "title": {
                "fragments": [],
                "text": "Adaptive Systems in Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "The perceptual superiority of the human visual system over automata is outlined comparing the properties of both systems and the existing classification methods are outlined and discussed with regard to adaptive systems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Electron. Comput."
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940156"
                        ],
                        "name": "T. Wagner",
                        "slug": "T.-Wagner",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Wagner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wagner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16814791,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "b99c508c00d282e7818c9730d1809b27da1922b1",
            "isKey": false,
            "numCitedBy": 204,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In the discrimination problem the random variable \\theta , known to take values in {1, \\cdots ,M} , is estimated from the random vector X . All that is known about the joint distribution of (X, \\theta) is that which can be inferred from a sample (X_{1}, \\theta_{1}), \\cdots ,(X_{n}, \\theta_{n}) of size n drawn from that distribution. A discrimination nde is any procedure which determines a decision \\hat{ \\theta} for \\theta from X and (X_{1}, \\theta_{1}) , \\cdots , (X_{n}, \\theta_{n}) . For rules which are determined by potential functions it is shown that the mean-square difference between the probability of error for the nde and its deleted estimate is bounded by A/ \\sqrt{n} where A is an explicitly given constant depending only on M and the potential function. The O(n ^{-1/2}) behavior is shown to be the best possible for one of the most commonly encountered rules of this type."
            },
            "slug": "Distribution-free-performance-bounds-for-potential-Devroye-Wagner",
            "title": {
                "fragments": [],
                "text": "Distribution-free performance bounds for potential function rules"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that the mean-square difference between the probability of error for the nde and its deleted estimate is bounded by A/ \\sqrt{n} where A is an explicitly given constant depending only on M and the potential function."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687662"
                        ],
                        "name": "O. Gascuel",
                        "slug": "O.-Gascuel",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Gascuel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Gascuel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3298731"
                        ],
                        "name": "G. Caraux",
                        "slug": "G.-Caraux",
                        "structuredName": {
                            "firstName": "Gilles",
                            "lastName": "Caraux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Caraux"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18058208,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "936df18bb86850dcdf5c0500eeaf151e477075e2",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Distribution-free-performance-bounds-with-the-error-Gascuel-Caraux",
            "title": {
                "fragments": [],
                "text": "Distribution-free performance bounds with the resubstitution error estimate"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2910658"
                        ],
                        "name": "C. Koutsougeras",
                        "slug": "C.-Koutsougeras",
                        "structuredName": {
                            "firstName": "Cris",
                            "lastName": "Koutsougeras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koutsougeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687231"
                        ],
                        "name": "C. Papachristou",
                        "slug": "C.-Papachristou",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Papachristou",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papachristou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10066603,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4957a895985b8ee3b62740a6541c90557a63c86",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A neural net model for pattern classification is introduced. Unlike models in which the network topology is specified before training, in this model the network expands during training. The proposed model introduces a novel type of unit (neuron) and a standard treelike feedforward network topology. The simplicity of the interconnection pattern is a particular advantage over existing models. Internal representations are formed by separating hyperplanes. Selection of the hyperplanes and expansion of the network is based on an entropy measure which is appropriately defined. The weight vectors of all units with a certain layer are determined in a single presentation of the training set.<<ETX>>"
            },
            "slug": "Training-of-a-neural-network-for-pattern-based-on-Koutsougeras-Papachristou",
            "title": {
                "fragments": [],
                "text": "Training of a neural network for pattern classification based on an entropy measure"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A neural net model for pattern classification is introduced that introduces a novel type of unit (neuron) and a standard treelike feedforward network topology and the network expands during training."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE 1988 International Conference on Neural Networks"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2960620"
                        ],
                        "name": "W. Meisel",
                        "slug": "W.-Meisel",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Meisel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Meisel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075067855"
                        ],
                        "name": "Edward Purcell",
                        "slug": "Edward-Purcell",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Purcell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward Purcell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119977987,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3e1d1e0c0835819e170654af9b58bab6e59939c",
            "isKey": false,
            "numCitedBy": 482,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A class of density estimates using a superposition of kernels where the kernel parameter can depend on the nearest neighbor distances is studied by the use of simulated data. Their performance using several measures of error is superior to that of the usual Parzen estimators. A tentative solution is given to the problem of calibrating the kernel peakedness when faced with a finite sample set."
            },
            "slug": "Variable-Kernel-Estimates-of-Multivariate-Densities-Breiman-Meisel",
            "title": {
                "fragments": [],
                "text": "Variable Kernel Estimates of Multivariate Densities"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A class of density estimates using a superposition of kernels where the kernel parameter can depend on the nearest neighbor distances is studied by the use of simulated data and their performance is superior to that of the usual Parzen estimators."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755694"
                        ],
                        "name": "G. Lugosi",
                        "slug": "G.-Lugosi",
                        "structuredName": {
                            "firstName": "G\u00e1bor",
                            "lastName": "Lugosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lugosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751563"
                        ],
                        "name": "K. Zeger",
                        "slug": "K.-Zeger",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Zeger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Zeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5683813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5f78a09f13c2fcb7168e0533156fa9700d577af",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We apply the method of complexity regularization to learn concepts from large concept classes. The method is shown to automatically find the best balance between the approximation error and the estimation error. In particular, the error probability of the obtained classifier is shown to decrease as 0(/spl radic/(log n/n)) to the achievable optimum, for large nonparametric classes of distributions, as the sample size n grows. In pattern recognition, or concept learning, the value of a {0,1}-valued random variable Y is to be predicted based upon observing an R/sup d/-valued random variable X."
            },
            "slug": "Concept-learning-using-complexity-regularization-Lugosi-Zeger",
            "title": {
                "fragments": [],
                "text": "Concept learning using complexity regularization"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The method of complexity regularization is shown to automatically find the best balance between the approximation error and the estimation error, for large nonparametric classes of distributions, as the sample size n grows."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1995 IEEE International Symposium on Information Theory"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064177950"
                        ],
                        "name": "A. G. Ivakhnenko",
                        "slug": "A.-G.-Ivakhnenko",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ivakhnenko",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. G. Ivakhnenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17606980,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7efb6b6f7e9ffa017e970a098665f76d4dfeca2",
            "isKey": false,
            "numCitedBy": 1390,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A complex multidimensional decision hypersurface can be approximated by a set of polynomials in the input signals (properties) which contain information about the hypersurface of interest. The hypersurface is usually described by a number of experimental (vector) points and simple functions of their coordinates. The approach taken in this paper to approximating the decision hypersurface, and hence the input-output relationship of a complex system, is to fit a high-degree multinomial to the input properties using a multilayered perceptronlike network structure. Thresholds are employed at each layer in the network to identify those polynomials which best fit into the desired hypersurface. Only the best combinations of the input properties are allowed to pass to succeeding layers, where more complex combinations are formed. Each element in each layer in the network implements a nonlinear function of two inputs. The coefficients of each element are determined by a regression technique which enables each element to approximate the true outputs with minimum mean-square error. The experimental data base is divided into a training and testing set. The training set is used to obtain the element coefficients, and the testing set is used to determine the utility of a given element in the network and to control overfitting of the experimental data. This latter feature is termed \"decision regularization."
            },
            "slug": "Polynomial-Theory-of-Complex-Systems-Ivakhnenko",
            "title": {
                "fragments": [],
                "text": "Polynomial Theory of Complex Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The approach taken in this paper to approximating the decision hypersurface, and hence the input-output relationship of a complex system, is to fit a high-degree multinomial to the input properties using a multilayered perceptronlike network structure."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087528"
                        ],
                        "name": "L. Gy\u00f6rfi",
                        "slug": "L.-Gy\u00f6rfi",
                        "structuredName": {
                            "firstName": "L\u00e1szl\u00f3",
                            "lastName": "Gy\u00f6rfi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gy\u00f6rfi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9745969"
                        ],
                        "name": "A. Krzy\u017cak",
                        "slug": "A.-Krzy\u017cak",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Krzy\u017cak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krzy\u017cak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755694"
                        ],
                        "name": "G. Lugosi",
                        "slug": "G.-Lugosi",
                        "structuredName": {
                            "firstName": "G\u00e1bor",
                            "lastName": "Lugosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lugosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16901337,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "bb4299c520fbe9954193d27956a1f75e3db1652b",
            "isKey": false,
            "numCitedBy": 262,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Two results are presented concerning the consistency of the k-nearest neighbor regression estimate. We show that all modes of convergence in L 1 (in probability, almost sure, complete) are equivalent if the regression variable is bounded. Under the additional condition k/log n \u2192 \u221e we also obtain the strong universal consistency of the estimate"
            },
            "slug": "On-the-Strong-Universal-Consistency-of-Nearest-Devroye-Gy\u00f6rfi",
            "title": {
                "fragments": [],
                "text": "On the Strong Universal Consistency of Nearest Neighbor Regression Function Estimates"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that all modes of convergence in L 1 are equivalent if the regression variable is bounded and under the additional condition k/log n \u2192 \u221e the strong universal consistency of the estimate is obtained."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145535366"
                        ],
                        "name": "J. Yukich",
                        "slug": "J.-Yukich",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Yukich",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yukich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122658429,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "689cf2db74dd76ff9c92b4f9264c35dc22e4a234",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Laws-of-large-numbers-for-classes-of-functions-Yukich",
            "title": {
                "fragments": [],
                "text": "Laws of large numbers for classes of functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2960620"
                        ],
                        "name": "W. Meisel",
                        "slug": "W.-Meisel",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Meisel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Meisel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206617386,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f53c22ed4f130cf1e703af4cb212de4518d8b405",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses a class of methods for pattern classification using a set of samples. They may also be used in reconstructing a probability density from samples. The methods discussed are potential function methods of a type directly derived from concepts related to superposition. The characteristics required of a potential function are examined, and it is shown that smooth potential functions exist that will separate arbitrary sets of sample points. Ideas suggested by Specht in regard to polynomial potential functions are extended."
            },
            "slug": "Potential-Functions-in-Mathematical-Pattern-Meisel",
            "title": {
                "fragments": [],
                "text": "Potential Functions in Mathematical Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A class of methods for pattern classification using a set of samples of a type directly derived from concepts related to superposition, and it is shown that smooth potential functions exist that will separate arbitrary sets of sample points."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122942"
                        ],
                        "name": "B. Ripley",
                        "slug": "B.-Ripley",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Ripley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ripley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 86569949,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2004356cf836faf746f713c6fb888c506c9c8a91",
            "isKey": false,
            "numCitedBy": 570,
            "numCiting": 136,
            "paperAbstract": {
                "fragments": [],
                "text": "Feed-forward neural networks are now widely used in classification problems, whereas nonlinear methods of discrimination developed in the statistical field are much less widely known. A general framework for classification is set up within which methods from statistics, neural networks, pattern recognition and machine learning can be compared. Neural networks emerge as one of a class of flexible non-linear regression methods which can be used to classify via regression. Many interesting issues remain, including parameter estimation, the assessment of the classifiers and in algorithm development."
            },
            "slug": "Neural-Networks-and-Related-Methods-for-Ripley",
            "title": {
                "fragments": [],
                "text": "Neural Networks and Related Methods for Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A general framework for classification is set up within which methods from statistics, neural networks, pattern recognition and machine learning can be compared, and neural networks emerge as one of a class of flexible non-linear regression methods which can be used to classify via regression."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737945"
                        ],
                        "name": "H. Akaike",
                        "slug": "H.-Akaike",
                        "structuredName": {
                            "firstName": "Hirotugu",
                            "lastName": "Akaike",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Akaike"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 411526,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "50a42ed2f81b9fe150883a6c89194c88a9647106",
            "isKey": false,
            "numCitedBy": 42032,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "The history of the development of statistical hypothesis testing in time series analysis is reviewed briefly and it is pointed out that the hypothesis testing procedure is not adequately defined as the procedure for statistical model identification. The classical maximum likelihood estimation procedure is reviewed and a new estimate minimum information theoretical criterion (AIC) estimate (MAICE) which is designed for the purpose of statistical identification is introduced. When there are several competing models the MAICE is defined by the model and the maximum likelihood estimates of the parameters which give the minimum of AIC defined by AIC = (-2)log-(maximum likelihood) + 2(number of independently adjusted parameters within the model). MAICE provides a versatile procedure for statistical model identification which is free from the ambiguities inherent in the application of conventional hypothesis testing procedure. The practical utility of MAICE in time series analysis is demonstrated with some numerical examples."
            },
            "slug": "A-new-look-at-the-statistical-model-identification-Akaike",
            "title": {
                "fragments": [],
                "text": "A new look at the statistical model identification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16695067"
                        ],
                        "name": "T. Vilmansen",
                        "slug": "T.-Vilmansen",
                        "structuredName": {
                            "firstName": "Toomas",
                            "lastName": "Vilmansen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vilmansen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43541913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7be6a27f2107fa684d330c7d301490d80b221f82",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, measures of probabilistic dependence are derived from distance measures and are applied to feature evaluation in pattern recognition. The main properties of the measures are derived and are discussed in their application to feature-class dependency. Relations between the measures and error probability are derived. Experiments using feature subsets extracted from Munson's hand-printed data are performed to compare the feature-evaluating capabilities of the measures both relative to each other and relative to error probability."
            },
            "slug": "Feature-Evalution-with-Measures-of-Probabilistic-Vilmansen",
            "title": {
                "fragments": [],
                "text": "Feature Evalution with Measures of Probabilistic Dependence"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The main properties of the measures are derived and are discussed in their application to feature-class dependency and relations between the measures and error probability are derived."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144290244"
                        ],
                        "name": "H. Niemann",
                        "slug": "H.-Niemann",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "Niemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Niemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3164998"
                        ],
                        "name": "R. Goppert",
                        "slug": "R.-Goppert",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Goppert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Goppert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26716286,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d78e6eefa5d7e1bb8c9feb762eb46edd205fccf",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-efficient-branch-and-bound-nearest-neighbour-Niemann-Goppert",
            "title": {
                "fragments": [],
                "text": "An efficient branch-and-bound nearest neighbour classifier"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9745969"
                        ],
                        "name": "A. Krzy\u017cak",
                        "slug": "A.-Krzy\u017cak",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Krzy\u017cak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krzy\u017cak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5391464,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "84e93ba04164904c7fbca54328daa9c7de98cd47",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Both nonrecursive and recursive nonparametric regression estimates are studied. The rates of weak and strong convergence of kernel estimates, as well as corresponding multiple classification errors, are derived without assuming the existence of the density of the measurements. An application of the obtained results to a nonparametric Bayes predication is presented."
            },
            "slug": "The-rates-of-convergence-of-kernel-regression-and-Krzy\u017cak",
            "title": {
                "fragments": [],
                "text": "The rates of convergence of kernel regression estimates and classification rules"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Both nonrecursive and recursive nonparametric regression estimates are studied and the rates of weak and strong convergence of kernel estimates, as well as corresponding multiple classification errors, are derived without assuming the existence of the density of the measurements."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785855"
                        ],
                        "name": "W. Greblicki",
                        "slug": "W.-Greblicki",
                        "structuredName": {
                            "firstName": "W\u0142odzimierz",
                            "lastName": "Greblicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Greblicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143803540"
                        ],
                        "name": "M. Pawlak",
                        "slug": "M.-Pawlak",
                        "structuredName": {
                            "firstName": "Miros\u0142aw",
                            "lastName": "Pawlak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pawlak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8236005,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "8d5ce154ac860c6188ead23695df6f67d3e43620",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that, for a nonparametric recursive kernel classification rule, \\sum^{n}_{i=1}h^{d}(i)I_{ \\{h(i) > \\epsilon \\} } / \\sum^{n}_{j=1} h^{d} (j) \\rightarrow 0 {\\rm as} n \\rightarrow \\infty, all \\epsilon > 0 and \\sum^{\\infty}_{i=1}h^{d}(i)= \\infty constitute a set of conditions which are not only sufficient but also necessary for weak and strong Bayes risk consistency of the rule. In this way, weak and strong consistencies are shown to be equivalent."
            },
            "slug": "Necessary-and-sufficient-conditions-for-Bayes-risk-Greblicki-Pawlak",
            "title": {
                "fragments": [],
                "text": "Necessary and sufficient conditions for Bayes risk consistency of a recursive kernel classification rule"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that a set of conditions are not only sufficient but also necessary for weak and strong Bayes risk consistency of the rule."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145004630"
                        ],
                        "name": "M. Anthony",
                        "slug": "M.-Anthony",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Anthony",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Anthony"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2732041"
                        ],
                        "name": "S. Holden",
                        "slug": "S.-Holden",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Holden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Holden"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15079238,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f03ce2b5ba574e8fff505d069b5333c63a2d1333",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we examine the representational and expressive power of two types of linearly weighted neural network: the polynomial discriminators (PDFs) and the radial basis function networks (RBFNs). A {O, 1}-valued function on Rn is a polyne mial discriminator of degree at most k if there is a surface in Rn which separates the positive examples of ! from the negative examples and which can be described by a polynomial equation of degree at mat k. The set of such functions is denoted P(n, k). In a similar way, ~B (n, k) denotes the set of boolean functions on {O, 1}n whose positive and negative examples can be separated by a surface whose equation is a polynomial of degree at most k. The threshold order of a boolean function f is the least value of k such that / c PB (n, k). By bounding the number of boole~ functions having at most a given threshold order, we prove that for large n, all but a negligible pr~ portion of boolean functions on n variables have threshold order at least [n/2J and that if n is odd, at most 1/2 of all such functions have threshold order at most [n/2J. We then determine precisely the VC dimensions of \u2018PB (n, k) and P(n, k). These dimensions coincide for k = 1 but thereafter they diverge. In passing, we provide a new proof of a result of Dudley. We then examine radial basis function networks. Using results of Micchelli and others on the interpolation properties of such networks, we obtain bounds on the VC dimensions of RBFNs with certain standard basis functions. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice IS given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. ACM COLT \u201993 171931 CA, USA @ 1993 ACM 0-89791-61 1-5/93 /0007 /0158 . ..$l .50 . Sean B. Holden Engineering Department University of Cambridge Trumpington Street Cambridge CB2 lPZ United Kingdom sbh@eng. cam. ac. uk"
            },
            "slug": "On-the-power-of-polynomial-discriminators-and-basis-Anthony-Holden",
            "title": {
                "fragments": [],
                "text": "On the power of polynomial discriminators and radial basis function networks"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This paper examines the representational and expressive power of two types of linearly weighted neural network: the polynomial discriminators (PDFs) and the radial basis function networks (RBFNs), and obtains bounds on the VC dimensions of RBFNs with certain standard basis functions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2796350"
                        ],
                        "name": "P. Diaconis",
                        "slug": "P.-Diaconis",
                        "structuredName": {
                            "firstName": "Persi",
                            "lastName": "Diaconis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Diaconis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144665070"
                        ],
                        "name": "M. Shahshahani",
                        "slug": "M.-Shahshahani",
                        "structuredName": {
                            "firstName": "Mehrdad",
                            "lastName": "Shahshahani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shahshahani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53656111,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b0f09280ba01ab2e2c60e9450bef332d183ba2f3",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Projection pursuit algorithms approximate a function of p variables by a sum of nonlinear functions of linear combinations: \\[ (1)\\qquad f\\left( {x_1 , \\cdots ,x_p } \\right) \\doteq \\sum_{i = 1}^n {g_i \\left( {a_{i1} x_1 + \\cdots + a_{ip} x_p } \\right)} . \\] We develop some approximation theory, give a necessary and sufficient condition for equality in (1), and discuss nonuniqueness of the representation."
            },
            "slug": "On-Nonlinear-Functions-of-Linear-Combinations-Diaconis-Shahshahani",
            "title": {
                "fragments": [],
                "text": "On Nonlinear Functions of Linear Combinations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712156"
                        ],
                        "name": "R. Brent",
                        "slug": "R.-Brent",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Brent",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6444831,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e29fc5ecdff863692ed78c9554e4aaf4aa43e315",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm that is faster than back-propagation and for which it is not necessary to specify the number of hidden units in advance is described. The relationship with other fast pattern-recognition algorithms, such as algorithms based on k-d trees, is discussed. The algorithm has been implemented and tested on artificial problems, such as the parity problem, and on real problems arising in speech recognition. Experimental results, including training times and recognition accuracy, are given. Generally, the algorithm achieves accuracy as good as or better than nets trained using back-propagation. Accuracy is comparable to that for the nearest-neighbor algorithm, which is slower and requires more storage space."
            },
            "slug": "Fast-training-algorithms-for-multilayer-neural-nets-Brent",
            "title": {
                "fragments": [],
                "text": "Fast training algorithms for multilayer neural nets"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "An algorithm that is faster than back-propagation and for which it is not necessary to specify the number of hidden units in advance is described, and accuracy is comparable to that for the nearest-neighbor algorithm, which is slower and requires more storage space."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648880"
                        ],
                        "name": "Jooyoung Park",
                        "slug": "Jooyoung-Park",
                        "structuredName": {
                            "firstName": "Jooyoung",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jooyoung Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2493659"
                        ],
                        "name": "I. Sandberg",
                        "slug": "I.-Sandberg",
                        "structuredName": {
                            "firstName": "Irwin",
                            "lastName": "Sandberg",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Sandberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 34868087,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05df5d4ae7b6460831318f0a7ea0b6db771aebde",
            "isKey": false,
            "numCitedBy": 3542,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "There have been several recent studies concerning feedforward networks and the problem of approximating arbitrary functionals of a finite number of real variables. Some of these studies deal with cases in which the hidden-layer nonlinearity is not a sigmoid. This was motivated by successful applications of feedforward networks with nonsigmoidal hidden-layer units. This paper reports on a related study of radial-basis-function (RBF) networks, and it is proved that RBF networks having one hidden layer are capable of universal approximation. Here the emphasis is on the case of typical RBF networks, and the results show that a certain class of RBF networks with the same smoothing factor in each kernel node is broad enough for universal approximation."
            },
            "slug": "Universal-Approximation-Using-Radial-Basis-Function-Park-Sandberg",
            "title": {
                "fragments": [],
                "text": "Universal Approximation Using Radial-Basis-Function Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is proved thatRBF networks having one hidden layer are capable of universal approximation, and a certain class of RBF networks with the same smoothing factor in each kernel node is broad enough for universal approximation."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516166"
                        ],
                        "name": "J. Rissanen",
                        "slug": "J.-Rissanen",
                        "structuredName": {
                            "firstName": "Jorma",
                            "lastName": "Rissanen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rissanen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122569569,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ae7beb7920485aca9c252ce3ecc3972c52eb3c37",
            "isKey": false,
            "numCitedBy": 1832,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "of the number of bits required to write down the observed data, has been reformulated to extend the classical maximum likelihood principle. The principle permits estimation of the number of the parameters in statistical models in addition to their values and even of the way the parameters appear in the models; i.e., of the model structures. The principle rests on a new way to interpret and construct a universal prior distribution for the integers, which makes sense even when the parameter is an individual object. Truncated realvalued parameters are converted to integers by dividing them by their precision, and their prior is determined from the universal prior for the integers by optimizing the precision. 1. Introduction. In this paper we study estimation based upon the principle of minimizing the total number of binary digits required to rewrite the observed data, when each observation is given with some precision. Instead of attempting at an absolutely shortest description, which would be futile, we look for the optimum relative to a class of parametrically given distributions. This Minimum Description Length (MDL) principle, which we introduced in a less comprehensive form in [25], turns out to degenerate to the more familiar Maximum Likelihood (ML) principle in case the number of parameters in the models is fixed, so that the description length of the parameters themselves can be ignored. In another extreme case, where the parameters determine the data, it similarly degenerates to Jaynes's principle of maximum entropy, [14]. But the main power of the new criterion is that it permits estimates of the entire model, its parameters, their number, and even the way the parameters appear in the model; i.e., the model structure. Hence, there will be no need to supplement the estimated parameters with a separate hypothesis test to decide whether a model is adequately parameterized or, perhaps, over parameterized."
            },
            "slug": "A-UNIVERSAL-PRIOR-FOR-INTEGERS-AND-ESTIMATION-BY-Rissanen",
            "title": {
                "fragments": [],
                "text": "A UNIVERSAL PRIOR FOR INTEGERS AND ESTIMATION BY MINIMUM DESCRIPTION LENGTH"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2403454"
                        ],
                        "name": "E. Baum",
                        "slug": "E.-Baum",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Baum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Baum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 37243943,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d20eff70cb168111fb5cc320cb692a11f1adf62",
            "isKey": false,
            "numCitedBy": 329,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-capabilities-of-multilayer-perceptrons-Baum",
            "title": {
                "fragments": [],
                "text": "On the capabilities of multilayer perceptrons"
            },
            "venue": {
                "fragments": [],
                "text": "J. Complex."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109349510"
                        ],
                        "name": "Xiaobo Li",
                        "slug": "Xiaobo-Li",
                        "structuredName": {
                            "firstName": "Xiaobo",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaobo Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087848"
                        ],
                        "name": "R. Dubes",
                        "slug": "R.-Dubes",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dubes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dubes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22210642,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08d831a3e709989b7d7015d73aab59b2cca04af8",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Tree-classifier-design-with-a-permutation-statistic-Li-Dubes",
            "title": {
                "fragments": [],
                "text": "Tree classifier design with a permutation statistic"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700484"
                        ],
                        "name": "S. Gelfand",
                        "slug": "S.-Gelfand",
                        "structuredName": {
                            "firstName": "Saul",
                            "lastName": "Gelfand",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gelfand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36729903"
                        ],
                        "name": "C. Ravishankar",
                        "slug": "C.-Ravishankar",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Ravishankar",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ravishankar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741483"
                        ],
                        "name": "E. Delp",
                        "slug": "E.-Delp",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Delp",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Delp"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43158592,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da15bf953fd7bab529046c5ba3826e48288f1272",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "An efficient iterative method is proposed to grow and prune classification trees. This method divides the data sample into two subsets and iteratively grows a tree with one subset and prunes it with the other subset, successively interchanging the roles of the two subsets. The convergence and other properties of the algorithm are established. Theoretical and practical considerations suggest that the iterative tree growing and pruning algorithm should perform better and require less computation than other widely used tree growing and pruning algorithms. Numerical results on a waveform recognition problem are presented to support this view.<<ETX>>"
            },
            "slug": "An-iterative-growing-and-pruning-algorithm-for-tree-Gelfand-Ravishankar",
            "title": {
                "fragments": [],
                "text": "An iterative growing and pruning algorithm for classification tree design"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Numerical results on a waveform recognition problem are presented to support the theory and practical considerations suggest that the iterative tree growing and pruning algorithm should perform better and require less computation than other widely used tree grow and prune algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Conference Proceedings., IEEE International Conference on Systems, Man and Cybernetics"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785855"
                        ],
                        "name": "W. Greblicki",
                        "slug": "W.-Greblicki",
                        "structuredName": {
                            "firstName": "W\u0142odzimierz",
                            "lastName": "Greblicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Greblicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143803540"
                        ],
                        "name": "M. Pawlak",
                        "slug": "M.-Pawlak",
                        "structuredName": {
                            "firstName": "Miros\u0142aw",
                            "lastName": "Pawlak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pawlak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20840061,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "169fe49e8d86d5300d3c39a50810e34b9019409c",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Almost-sure-convergence-of-classification-using-Greblicki-Pawlak",
            "title": {
                "fragments": [],
                "text": "Almost sure convergence of classification procedures using Hermite series density estimates"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73515694"
                        ],
                        "name": "Y. Chow",
                        "slug": "Y.-Chow",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Chow",
                            "middleNames": [
                                "Shih"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49232442"
                        ],
                        "name": "H. Teicher",
                        "slug": "H.-Teicher",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Teicher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Teicher"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120741536,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8db1313cfce4a340539b76d8e816d8f87dd66f49",
            "isKey": false,
            "numCitedBy": 1283,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Classes of Sets, Measures, and Probability Spaces.- 1.1 Sets and set operations.- 1.2 Spaces and indicators.- 1.3 Sigma-algebras, measurable spaces, and product spaces.- 1.4 Measurable transformations.- 1.5 Additive set functions, measures, and probability spaces.- 1.6 Induced measures and distribution functions.- 2 Binomial Random Variables.- 2.1 Poisson theorem, interchangeable events, and their limiting probabilities.- 2.2 Bernoulli, Borel theorems.- 2.3 Central limit theorem for binomial random variables, large deviations.- 3 Independence.- 3.1 Independence, random allocation of balls into cells.- 3.2 Borel-Cantelli theorem, characterization of independence, Kolmogorov zero-one law.- 3.3 Convergence in probability, almost certain convergence, and their equivalence for sums of independent random variables.- 3.4 Bernoulli trials.- 4 Integration in a Probability Space.- 4.1 Definition, properties of the integral, monotone convergence theorem.- 4.2 Indefinite integrals, uniform integrability, mean convergence.- 4.3 Jensen, Holder, Schwarz inequalities.- 5 Sums of Independent Random Variables.- 5.1 Three series theorem.- 5.2 Laws of large numbers.- 5.3 Stopping times, copies of stopping times, Wald's equation.- 5.4 Chung-Fuchs theorem, elementary renewal theorem, optimal stopping.- 6 Measure Extensions, Lebesgue-Stieltjes Measure,Kolmogorov Consistency Theorem.- 6.1 Measure extensions, Lebesgue-Stieltjes measure 165 6.2 Integration in a measure space.- 6.3 Product measure, Fubini's theorem, n-dimensional Lebesgue-Stieltjes measure.- 6.4 Infinite-dimensional product measure space, Kolmogorov consistency theorem.- 6.5 Absolute continuity of measures, distribution functions Radon-Nikodym theorem.- 7 Conditional Expectation, Conditional Independence, Introduction to Martingales.- 7.1 Conditional expectations.- 7.2 Conditional probabilities, conditional probability measures.- 7.3 Conditional independence, interchangeable random variables.- 7.4 Introduction to martingales.- 7.5 U-statistics.- 8 Distribution Functions and Characteristic Functions.- 8.1 Convergence of distribution functions, uniform integrability, Helly-Bray theorem.- 8.2 Weak compactness, Frechet-Shohat, GlivenkoCantelli theorems.- 8.3 Characteristic functions, inversion formula, Levy continuity theorem.- 8.4 The nature of characteristic functions, analytic characteristic functions, Cramer-Levy theorem.- 8.5 Remarks on k-dimensional distribution functions and characteristic functions.- 9 Central Limit Theorems.- 9.1 Independent components.- 9.2 Interchangeable components.- 9.3 The martingale case.- 9.4 Miscellaneous central limit theorems.- 9.5 Central limit theorems for double arrays.- 10 Limit Theorems for Independent Random Variables.- 10.1 Laws of large numbers.- 10.2 Law of the iterated logarithm.- 10.3 Marcinkiewicz-Zygmund inequality, dominated ergodic theorems.- 10.4 Maxima of random walks.- 11 Martingales.- 11.1 Uperossing inequality and convergence.- 11.2 Martingale extension of Marcinkiewicz-Zygmund inequalities.- 11.3 Convex function inequalities for martingales.- 11.4 Stochastic inequalities.- 12 Infinitely Divisible Laws.- 12.1 Infinitely divisible characteristic functions.- 12.2 Infinitely divisible laws as limits.- 12.3 Stable laws."
            },
            "slug": "Probability-theory:-Independence,-martingales-Chow-Teicher",
            "title": {
                "fragments": [],
                "text": "Probability theory: Independence, interchangeability, martingales"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73756592"
                        ],
                        "name": "M. Gessaman",
                        "slug": "M.-Gessaman",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "Gessaman",
                            "middleNames": [
                                "Palmer"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gessaman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69385681"
                        ],
                        "name": "P. Gessaman",
                        "slug": "P.-Gessaman",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Gessaman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gessaman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123074994,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a4f9442c9c8c835e069dc9cb812e2748541590e2",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A sequence of observations is obtained; each observation is known to be a value on one of two distinct absolutely continuous p-dimensional random variables, X and Y. The problem is to decide whether each observation is on X or Y. Some discrimination procedures are suggested and, using Monte Carlo methods, they are compared with other discrimination procedures to be found in the literature. The overall best performer in the comparisons of this study is one of the suggested procedures, a \u201cnearest neighbor\u201d type procedure based on statistically equivalent blocks."
            },
            "slug": "A-Comparison-of-Some-Multivariate-Discrimination-Gessaman-Gessaman",
            "title": {
                "fragments": [],
                "text": "A Comparison of Some Multivariate Discrimination Procedures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20658113"
                        ],
                        "name": "A. Barron",
                        "slug": "A.-Barron",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barron",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15383918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04113e8974341f97258800126d05fd8df2751b7e",
            "isKey": false,
            "numCitedBy": 2593,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Approximation properties of a class of artificial neural networks are established. It is shown that feedforward networks with one layer of sigmoidal nonlinearities achieve integrated squared error of order O(1/n), where n is the number of nodes. The approximated function is assumed to have a bound on the first moment of the magnitude distribution of the Fourier transform. The nonlinear parameters associated with the sigmoidal nodes, as well as the parameters of linear combination, are adjusted in the approximation. In contrast, it is shown that for series expansions with n terms, in which only the parameters of linear combination are adjusted, the integrated squared approximation error cannot be made smaller than order 1/n/sup 2/d/ uniformly for functions satisfying the same smoothness assumption, where d is the dimension of the input to the function. For the class of functions examined, the approximation rate and the parsimony of the parameterization of the networks are shown to be advantageous in high-dimensional settings. >"
            },
            "slug": "Universal-approximation-bounds-for-superpositions-a-Barron",
            "title": {
                "fragments": [],
                "text": "Universal approximation bounds for superpositions of a sigmoidal function"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The approximation rate and the parsimony of the parameterization of the networks are shown to be advantageous in high-dimensional settings and the integrated squared approximation error cannot be made smaller than order 1/n/sup 2/d/ uniformly for functions satisfying the same smoothness assumption."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144293634"
                        ],
                        "name": "A. Macintyre",
                        "slug": "A.-Macintyre",
                        "structuredName": {
                            "firstName": "Angus",
                            "lastName": "Macintyre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Macintyre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790264"
                        ],
                        "name": "Eduardo Sontag",
                        "slug": "Eduardo-Sontag",
                        "structuredName": {
                            "firstName": "Eduardo",
                            "lastName": "Sontag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eduardo Sontag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 762531,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "f5aa16dfe293b58263662e31005bd200a807ce89",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Proc. 25th Annual Symp. Theory Computing , San Diego, May 1993 This paper deals with analog circuits. It establishes the finiteness of VC dimension, teaching dimension, and several other measures of sample complexity which arise in learning theory. It also shows that the equivalence of behaviors, and the loading problem, are effectively decidable, modulo a widely believed conjecture in number theory. The results, the first ones that are independent of weight size, apply when the gate function is the \u201cstandard sigmoid\u201d commonly used in neural networks research. The proofs rely on very recent developments in the elementary theory of real numbers with exponentiation. (Some weaker conclusions are also given for more general analytic gate functions.) Applications to learnability of sparse polynomials are also mentioned."
            },
            "slug": "Finiteness-results-for-sigmoidal-\u201cneural\u201d-networks-Macintyre-Sontag",
            "title": {
                "fragments": [],
                "text": "Finiteness results for sigmoidal \u201cneural\u201d networks"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "It establishes the finiteness of VC dimension, teaching dimension, and several other measures of sample complexity which arise in learning theory, and shows that the equivalence of behaviors, and the loading problem, are effectively decidable."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109788281"
                        ],
                        "name": "Marshall W. Anderson",
                        "slug": "Marshall-W.-Anderson",
                        "structuredName": {
                            "firstName": "Marshall",
                            "lastName": "Anderson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marshall W. Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114566062"
                        ],
                        "name": "R. Benning",
                        "slug": "R.-Benning",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Benning",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Benning"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22052763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9b2985d9774b193608148db4ab538b81b866258",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is presented for constructing distribution-free tolerance regions for one distribution based on the clusters of the sample from a second distribution. The tolerance regions are constructed so as to minimize the probability of reserve judgment in a two-class discrimination procedure that allows the conditional error probabilities to be controlled within prescribed upper bounds. The method results in discrimination functions that are easily implemented on a computer. Although the method is not, in general, consistent with optimal procedures, it is appealing for high-dimensional problems with multimodal distributions."
            },
            "slug": "A-distribution-free-discrimination-procedure-based-Anderson-Benning",
            "title": {
                "fragments": [],
                "text": "A distribution-free discrimination procedure based on clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "A method is presented for constructing distribution-free tolerance regions for one distribution based on the clusters of the sample from a second distribution so as to minimize the probability of reserve judgment in a two-class discrimination procedure."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "100942540"
                        ],
                        "name": "M. Lo\u00e8ve",
                        "slug": "M.-Lo\u00e8ve",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Lo\u00e8ve",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lo\u00e8ve"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 123533290,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f18307ebabf398bb7fd1b3375b2f09a7f9f6c5be",
            "isKey": false,
            "numCitedBy": 6129,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "These notes cover the basic definitions of discrete probability theory, and then present some results including Bayes' rule, inclusion-exclusion formula, Chebyshev's inequality, and the weak law of large numbers. 1 Sample spaces and events To treat probability rigorously, we define a sample space S whose elements are the possible outcomes of some process or experiment. For example, the sample space might be the outcomes of the roll of a die, or flips of a coin. To each element x of the sample space, we assign a probability, which will be a non-negative number between 0 and 1, which we will denote by p(x). We require that x\u2208S p(x) = 1, so the total probability of the elements of our sample space is 1. What this means intuitively is that when we perform our process, exactly one of the things in our sample space will happen. Example. The sample space could be S = {a, b, c}, and the probabilities could be p(a) = 1/2, p(b) = 1/3, p(c) = 1/6. If all elements of our sample space have equal probabilities, we call this the uniform probability distribution on our sample space. For example, if our sample space was the outcomes of a die roll, the sample space could be denoted S = {x 1 , x 2 ,. .. , x 6 }, where the event x i correspond to rolling i. The uniform distribution, in which every outcome x i has probability 1/6 describes the situation for a fair die. Similarly, if we consider tossing a fair coin, the outcomes would be H (heads) and T (tails), each with probability 1/2. In this situation we have the uniform probability distribution on the sample space S = {H, T }. We define an event A to be a subset of the sample space. For example, in the roll of a die, if the event A was rolling an even number, then A = {x 2 , x 4 , x 6 }. The probability of an event A, denoted by P(A), is the sum of the probabilities of the corresponding elements in the sample space. For rolling an even number, we have P(A) = p(x 2) + p(x 4) + p(x 6) = 1 2 Given an event A of our sample space, there is a complementary event which consists of all points in our sample space that are not \u2026"
            },
            "slug": "Probability-Theory-I-Lo\u00e8ve",
            "title": {
                "fragments": [],
                "text": "Probability Theory I"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "These notes cover the basic definitions of discrete probability theory, and then present some results including Bayes' rule, inclusion-exclusion formula, Chebyshev's inequality, and the weak law of large numbers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20658113"
                        ],
                        "name": "A. Barron",
                        "slug": "A.-Barron",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barron",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14460436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fca98082fa9ff8e9dbae9922491ae54976a0ccef",
            "isKey": false,
            "numCitedBy": 525,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors introduce an index of resolvability that is proved to bound the rate of convergence of minimum complexity density estimators as well as the information-theoretic redundancy of the corresponding total description length. The results on the index of resolvability demonstrate the statistical effectiveness of the minimum description-length principle as a method of inference. The minimum complexity estimator converges to true density nearly as fast as an estimator based on prior knowledge of the true subclass of densities. Interpretations and basic properties of minimum complexity estimators are discussed. Some regression and classification problems that can be examined from the minimum description-length framework are considered. >"
            },
            "slug": "Minimum-complexity-density-estimation-Barron-Cover",
            "title": {
                "fragments": [],
                "text": "Minimum complexity density estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An index of resolvability is proved to bound the rate of convergence of minimum complexity density estimators as well as the information-theoretic redundancy of the corresponding total description length to demonstrate the statistical effectiveness of the minimum description-length principle as a method of inference."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699388"
                        ],
                        "name": "L. Ljung",
                        "slug": "L.-Ljung",
                        "structuredName": {
                            "firstName": "Lennart",
                            "lastName": "Ljung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ljung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144386472"
                        ],
                        "name": "G. Pflug",
                        "slug": "G.-Pflug",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Pflug",
                            "middleNames": [
                                "Ch."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Pflug"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158720"
                        ],
                        "name": "Harro Walk",
                        "slug": "Harro-Walk",
                        "structuredName": {
                            "firstName": "Harro",
                            "lastName": "Walk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harro Walk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 115883146,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a1a2b349d43db56afa1a204c20c9876870f0a694",
            "isKey": false,
            "numCitedBy": 240,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "I Foundations of stochastic approximation.- 1 Almost sure convergence of stochastic approximation procedures.- 2 Recursive methods for linear problems.- 3 Stochastic optimization under stochastic constraints.- 4 A learning model recursive density estimation.- 5 Invariance principles in stochastic approximation.- 6 On the theory of large deviations.- References for Part I.- II Applicational aspects of stochastic approximation.- 7 Markovian stochastic optimization and stochastic approximation procedures.- 8 Asymptotic distributions.- 9 Stopping times.- 10 Applications of stochastic approximation methods.- References for Part II.- III Applications to adaptation algorithms.- 11 Adaptation and tracking.- 12 Algorithm development.- 13 Asymptotic Properties in the decreasing gain case.- 14 Estimation of the tracking ability of the algorithms.- References for Part III."
            },
            "slug": "Stochastic-approximation-and-optimization-of-random-Ljung-Pflug",
            "title": {
                "fragments": [],
                "text": "Stochastic approximation and optimization of random systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This chapter discusses applications to adaptation algorithms and asymptotic properties in the decreasing gain case, as well as applications to recursive density estimation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2184725"
                        ],
                        "name": "Tianping Chen",
                        "slug": "Tianping-Chen",
                        "structuredName": {
                            "firstName": "Tianping",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianping Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118061163"
                        ],
                        "name": "Hong Chen",
                        "slug": "Hong-Chen",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144852081"
                        ],
                        "name": "Ruey-Wen Liu",
                        "slug": "Ruey-Wen-Liu",
                        "structuredName": {
                            "firstName": "Ruey-Wen",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruey-Wen Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123998749,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "601a6cb89075806d7026fc58acc84c92e9e635fb",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a constructive proof of approximation by superposition of sigmoidal functions. We point out a sufficient condition that the set of finite linear combinations of the form \\(\\sum \\alpha _j\\sigma (y_jx+\\theta _j)\\) is dense in \\(C(\\mathbb{I}^n)\\), is the boundedness of the sigmoidal function \u03c3(x). Moreover, we show that if the set of finite linear combinations of the form \\(\\sum c_j\\omega (\\xi _j+\\eta _j)\\), where \u03c9 is a univariate function, is dense in \\(L^p[a,b] (1\\leq p< \\infty )\\) (or C[a,b]) for any finite a,b, then the set of finite linear combinations of the form \\(\\sum c_j\\omega (y_j.x+\\theta _j)\\) is dense in \\(L^p(\\mathbb{I}^n)(or C(\\mathbb{I}^n))\\). An extension in another direction is also presented in Theorem 4 of this paper."
            },
            "slug": "A-Constructive-Proof-and-An-Extension-of-Cybenko\u2019s-Chen-Chen",
            "title": {
                "fragments": [],
                "text": "A Constructive Proof and An Extension of Cybenko\u2019s Approximation Theorem"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A constructive proof of approximation by superposition of sigmoidal functions is presented, and it is shown that if the set of finite linear combinations of the form \\(\\sum c_j\\omega (y_j.x+\\theta _j)\\) is dense in \\(L^p(\\mathbb{I}^n)(or C(\\mathBB{I]^n))\\)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144134946"
                        ],
                        "name": "J. Mielniczuk",
                        "slug": "J.-Mielniczuk",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Mielniczuk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mielniczuk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3254350"
                        ],
                        "name": "J. Tyrcha",
                        "slug": "J.-Tyrcha",
                        "structuredName": {
                            "firstName": "Joanna",
                            "lastName": "Tyrcha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tyrcha"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 21655715,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02176e7891d455ee920558975c4e4b365f696c1b",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Consistency-of-multilayer-perceptron-regression-Mielniczuk-Tyrcha",
            "title": {
                "fragments": [],
                "text": "Consistency of multilayer perceptron regression estimators"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143803540"
                        ],
                        "name": "M. Pawlak",
                        "slug": "M.-Pawlak",
                        "structuredName": {
                            "firstName": "Miros\u0142aw",
                            "lastName": "Pawlak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pawlak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45084775,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9e19d72009196dc785dda5ef32a5934d9a45e3d2",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-asymptotic-properties-of-smoothed-estimators-Pawlak",
            "title": {
                "fragments": [],
                "text": "On the asymptotic properties of smoothed estimators of the classification error rate"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690163"
                        ],
                        "name": "G. McLachlan",
                        "slug": "G.-McLachlan",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "McLachlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. McLachlan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14159881,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "20ce95262aa2781c2c3127ca77f18afece3c8f69",
            "isKey": false,
            "numCitedBy": 2627,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a systematic account of the subject area, concentrating on the most recent advances in the field. While the focus is on practical considerations, both theoretical and practical issues are explored. Among the advances covered are: regularized discriminant analysis and bootstrap-based assessment of the performance of a sample-based discriminant rule and extensions of discriminant analysis motivated by problems in statistical image analysis. Includes over 1,200 references in the bibliography."
            },
            "slug": "Discriminant-Analysis-and-Statistical-Pattern-McLachlan",
            "title": {
                "fragments": [],
                "text": "Discriminant Analysis and Statistical Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696575"
                        ],
                        "name": "J. Bentley",
                        "slug": "J.-Bentley",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Bentley",
                            "middleNames": [
                                "Louis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bentley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2236311"
                        ],
                        "name": "R. Finkel",
                        "slug": "R.-Finkel",
                        "structuredName": {
                            "firstName": "Raphael",
                            "lastName": "Finkel",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Finkel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10811510,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cab3c73f1b2140231b98944c720100b356d91b28",
            "isKey": false,
            "numCitedBy": 2965,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm and data structure are presented for searching a file containing N records, each described by k real valued keys, for the m closest matches or nearest neighbors to a given query record. The computation required to organize the file is proportional to kNlogN. The expected number of records examined in each search is independent of the file size. The expected computation to perform each search is proportional to logN. Empirical evidence suggests that except for very small files, this algorithm is considerably faster than other methods."
            },
            "slug": "An-Algorithm-for-Finding-Best-Matches-in-Expected-Friedman-Bentley",
            "title": {
                "fragments": [],
                "text": "An Algorithm for Finding Best Matches in Logarithmic Expected Time"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An algorithm and data structure are presented for searching a file containing N records, each described by k real valued keys, for the m closest matches or nearest neighbors to a given query record."
            },
            "venue": {
                "fragments": [],
                "text": "TOMS"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2403454"
                        ],
                        "name": "E. Baum",
                        "slug": "E.-Baum",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Baum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15659829,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "25406e6733a698bfc4ac836f8e74f458e75dad4f",
            "isKey": false,
            "numCitedBy": 1696,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the question of when a network can be expected to generalize from m random training examples chosen from some arbitrary probability distribution, assuming that future test examples are drawn from the same distribution. Among our results are the following bounds on appropriate sample vs. network size. Assume 0 < \u220a 1/8. We show that if m O(W/\u220a log N/\u220a) random examples can be loaded on a feedforward network of linear threshold functions with N nodes and W weights, so that at least a fraction 1 \u220a/2 of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify a fraction 1 \u220a of future test examples drawn from the same distribution. Conversely, for fully-connected feedforward nets with one hidden layer, any learning algorithm using fewer than (W/\u220a) random training examples will, for some distributions of examples consistent with an appropriate weight choice, fail at least some fixed fraction of the time to find a weight choice that will correctly classify more than a 1 \u220a fraction of the future test examples."
            },
            "slug": "What-Size-Net-Gives-Valid-Generalization-Baum-Haussler",
            "title": {
                "fragments": [],
                "text": "What Size Net Gives Valid Generalization?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that if m O(W/ \u220a log N/\u220a) random examples can be loaded on a feedforward network of linear threshold functions with N nodes and W weights, so that at least a fraction 1 \u220a/2 of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify a fraction 2 \u220a of future test examples drawn from the same distribution."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697413"
                        ],
                        "name": "S. Kulkarni",
                        "slug": "S.-Kulkarni",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Kulkarni",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kulkarni"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34071213,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "91439aa7526d9b4be618747d8d47acfb1123f2ad",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In this thesis, we consider a number of problems in the areas of machine vision and learning. Our results take steps towards understanding the computational and information complexity of problems in areas such as machine vision and signal processing. In the first part of the thesis, we study problems concerning computational requirements/limitations in machine vision. We first consider relationships between variational methods and discrete Markov random field formulations for the problem of image restoration and segmentation. Several discrete formulations are presented which correctly approximate the continuous segmentation problem. The results for the segmentation problem lead us to consider a question concerning the computation of the length of a digitized contour. It is shown that for a particular model of parallel computation, length cannot be computed locally with a rectangular digitization, but can be computed locally using a random tesselation and an appropriate deterministic one. Finally, we study the complexity of model based recognition and show that certain formulations of model based recognition are NP-complete. \nIn the second part of the thesis, we study a number of extensions to models in machine learning with a view towards obtaining information complexity results applicable to areas such as machine vision and signal processing. We first consider extensions to the Probably Approximately Correct (PAC) learning model, including learning over a class of distributions, active learning, and learning with generalized samples. We study a particular application of learning with generalized samples to a problem of reconstructing a curve by counting intersections with straight lines. Our results refine a classical result from stochastic geometry. Finally, we consider a problem concerning the classification of an unknown probability measure from empirical data. Using large deviations techniques, we simplify and extend previous results on classifying the mean of a random variable. We also study the much more general case of classifying the measure itself, and consider applications to density estimation and the problem of order determination of a Markov chain. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)"
            },
            "slug": "Problems-of-computational-and-informational-in-and-Kulkarni",
            "title": {
                "fragments": [],
                "text": "Problems of computational and informational complexity in machine vision and learning"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This thesis considers relationships between variational methods and discrete Markov random field formulations for the problem of image restoration and segmentation, and considers extensions to the Probably Approximately Correct (PAC) learning model."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35567771"
                        ],
                        "name": "K. Buescher",
                        "slug": "K.-Buescher",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Buescher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Buescher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "151478680"
                        ],
                        "name": "P. R. Kumar",
                        "slug": "P.-R.-Kumar",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Kumar",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. R. Kumar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6540475,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "996ada3d17d3a7b184cf96f6d82ed1f46dec30d1",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper examines the problem of learning from examples in a framework that is based on, but more general than, Valiant's probably approximately correct (PAC) model for learning. In our framework, the Learner observes examples that consist of sample points drawn and labeled according to a fixed, unknown probability distribution. Based on this empirical data, the learner must select, from a set of candidate functions, a par- ticular function or \"hypothesis\" that will accurately predict the labels of future sample points. The expected mismatch between a hypothesis' prediction and the label of a new sample point is called the hypothesis' \"generalization error.\" Following the pioneering work of Vapnik and Chervonenkis, others have attacked this sort of learning problem by finding hypotheses that minimize the relative frequency-based empirical error estimate. We generalize this approach by examining the \"simultaneous estimation\" problem: When does some procedure exist for estimating the generalization error of all of the candidate hypotheses, simultaneously, from the same labeled sample? We demonstrate how one can learn from such a simultaneous error estimate and propose a new class of estimators called \"smooth estimators\" that, in many cases of interest, contains the empirical estimator. We characterize the class of simultaneous estimation problems solvable by a smooth estimator and give a canonical form for the smooth simultaneous estimator."
            },
            "slug": "Learning-by-Canonical-Smooth-Es-timation-Part-I:-Buescher-Kumar",
            "title": {
                "fragments": [],
                "text": "Learning by Canonical Smooth Es timation-Part I: Simultaneous Estimation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18607413,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9f2f44a1502cb5e2b2657d24760ff11dbd509668",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "When (X1, \u00bf1),..., (Xn, \u00bfn) are independent identically distributed random vectors from IRd X {0, 1} distributed as (X, \u00bf), and when \u00bf is estimated by its nearest neighbor estimate \u00bf(1), then Cover and Hart have shown that P{\u00bf(1) \u00bf \u00bf}n \u00bf \u00bf \u00bf 2E {\u00bf (X) (1 - \u00bf(X))} \u00bf 2R*(1 - R*) where R* is the Bayes probability of error and \u00bf(x) = P{\u00bf = 1 | X = x}. They have conditions on the distribution of (X, \u00bf). We give two proofs, one due to Stone and a short original one, of the same result for all distributions of (X, \u00bf). If ties are carefully taken care of, we also show that P{\u00bf(1) \u00bf \u00bf|X1, \u00bf1, ..., Xn, \u00bfn} converges in probability to a constant for all distributions of (X, \u00bf), thereby strengthening results of Wagner and Fritz."
            },
            "slug": "On-the-Inequality-of-Cover-and-Hart-in-Nearest-Devroye",
            "title": {
                "fragments": [],
                "text": "On the Inequality of Cover and Hart in Nearest Neighbor Discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "If ties are carefully taken care of, it is shown that P{\u00bf(1) \u00bf|X1, \u00bf1, ..., Xn, \u00b7n} converges in probability to a constant for all distributions of (X, \u00bd), thereby strengthening results of Wagner and Fritz."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102636025"
                        ],
                        "name": "C. Chow",
                        "slug": "C.-Chow",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Chow",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206730137,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea36358e4363fa452b55de2325ceae9802a51d81",
            "isKey": false,
            "numCitedBy": 776,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The performance of a pattern recognition system is characterized by its error and reject tradeoff. This paper describes an optimum rejection rule and presents a general relation between the error and reject probabilities and some simple properties of the tradeoff in the optimum recognition system. The error rate can be directly evaluated from the reject function. Some practical implications of the results are discussed. Examples in normal distributions and uniform distributions are given."
            },
            "slug": "On-optimum-recognition-error-and-reject-tradeoff-Chow",
            "title": {
                "fragments": [],
                "text": "On optimum recognition error and reject tradeoff"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An optimum rejection rule is described and a general relation between the error and reject probabilities and some simple properties of the tradeoff in the optimum recognition system are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940156"
                        ],
                        "name": "T. Wagner",
                        "slug": "T.-Wagner",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Wagner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wagner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18446401,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e843041dd927e7057300ea3f09b44c8b7d981ac8",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In the discrimination problem the random variable \\theta , known to take values in {1 ,\\ldots ,M} , is estimated from the random vector X taking values in {\\bfR}^{d} . Ali that is known about the joint distribution of (X,O) is that which can be inferred from a sample (X_{1} , \\theta_{1}, \\ldots , (X_{n}, \\theta_{n}) of size n drawn from that distribution. A discrimination rule is any procedure which determines a decision \\hat{\\theta} for \\theta from X and (X_{1},\\theta_{1}) , \\ldots , (X_{n}, \\theta_{n}) . The rule is called k -local if the decision \\hat{\\theta} depends only on X and the pairs (X_{i}, \\theta_{i}) ,for which X_{i} is one of the k closest to X from X_{1} , \\ldots ,X_{n} . If L_{n} denotes the probability of error for a k -local rule given the sample, then estimates \\hat{L}_{n} of L_{n} , are determined for which P {| \\hat{L}_{n} - L_{n} \\geq \\epsilon} \\exp (- Bn) , where A and B are positive constants depending only on d , M , and \\epsilon ."
            },
            "slug": "Distribution-free-inequalities-for-the-deleted-and-Devroye-Wagner",
            "title": {
                "fragments": [],
                "text": "Distribution-free inequalities for the deleted and holdout error estimates"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "In the discrimination problem the random variable \\theta, known to take values in {1,\\ldots,M} , is estimated from the random vector X taking values in {\\bfR}^{d} ."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145913258"
                        ],
                        "name": "N. Glick",
                        "slug": "N.-Glick",
                        "structuredName": {
                            "firstName": "Ned",
                            "lastName": "Glick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Glick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26683740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c7586feff70afaf8d4f85a9a8f0ac831081fc64",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We present new classes of binary codes that are constructed on the basis of concatenated codes and product codes. We discuss the random-error-correction capabilities of these codes. Some examples of the codes for the correction of random errors are given which have at least as many codewords as the best codes previously known (to the authors) with the same minimum distance and same number of check symbols. The burst-error-correction capabilities of the codes are also discussed. Several examples of the codes for the correction of both random errors and burst errors are given. A decoding algorithm for the codes is also described."
            },
            "slug": "Sample-based-classification-procedures-related-to-Glick",
            "title": {
                "fragments": [],
                "text": "Sample-based classification procedures related to empiric distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "New classes of binary codes that are constructed on the basis of concatenated codes and product codes are presented and the random-error-correction capabilities of these codes are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145652961"
                        ],
                        "name": "L. Xu",
                        "slug": "L.-Xu",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9745969"
                        ],
                        "name": "A. Krzy\u017cak",
                        "slug": "A.-Krzy\u017cak",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Krzy\u017cak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krzy\u017cak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726997"
                        ],
                        "name": "E. Oja",
                        "slug": "E.-Oja",
                        "structuredName": {
                            "firstName": "Erkki",
                            "lastName": "Oja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Oja"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23917271,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55fa7af102d8eee340dfda360db4723e55253dda",
            "isKey": false,
            "numCitedBy": 637,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that frequency sensitive competitive learning (FSCL), one version of the recently improved competitive learning (CL) algorithms, significantly deteriorates in performance when the number of units is inappropriately selected. An algorithm called rival penalized competitive learning (RPCL) is proposed. In this algorithm, not only is the winner unit modified to adapt to the input for each input, but its rival (the 2nd winner) is delearned by a smaller learning rate. RPCL can be regarded as an unsupervised extension of Kohonen's supervised LVQ2. RPCL has the ability to automatically allocate an appropriate number of units for an input data set. The experimental results show that RPCL outperforms FSCL when used for unsupervised classification, for training a radial basis function (RBF) network, and for curve detection in digital images."
            },
            "slug": "Rival-penalized-competitive-learning-for-clustering-Xu-Krzy\u017cak",
            "title": {
                "fragments": [],
                "text": "Rival penalized competitive learning for clustering analysis, RBF net, and curve detection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results show that RPCL outperforms FSCL when used for unsupervised classification, for training a radial basis function (RBF) network, and for curve detection in digital images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14921581,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "fedfc9fbcfe46d50b81078560bce724678f90176",
            "isKey": false,
            "numCitedBy": 979,
            "numCiting": 124,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Decision-Theoretic-Generalizations-of-the-PAC-Model-Haussler",
            "title": {
                "fragments": [],
                "text": "Decision Theoretic Generalizations of the PAC Model for Neural Net and Other Learning Applications"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Comput."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940156"
                        ],
                        "name": "T. Wagner",
                        "slug": "T.-Wagner",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Wagner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wagner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121662740,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "54b30522cd44f1ea987b823d8fa3a77fe8ec5207",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "SummaryAn estimate mnof a regression function m(x)=E{Y|X=x} is weakly (strongly) consistent in L1 if \u221d\u00a6mn(x)-m(x)\u00a6\u03bc(dx) converges to 0 in probability (w.p. 1) as the sample size grows large (\u03bc is the probability measure of X).We show that the well-known kernel estimate (Nadaraya, Watson) and several recursive modifications of it are weakly (strongly) consistent in L1 under no conditions on (X, Y) other than the boundedness of Y and the absolute continuity of \u03bc. No continuity restrictions are put on the density corresponding to \u03bc. We further notice that several kernel-type discrimination rules are weakly (strongly) Bayes risk consistent whenever X has a density."
            },
            "slug": "On-the-L1-convergence-of-kernel-estimators-of-with-Devroye-Wagner",
            "title": {
                "fragments": [],
                "text": "On the L1 convergence of kernel estimators of regression functions with applications in discrimination"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755694"
                        ],
                        "name": "G. Lugosi",
                        "slug": "G.-Lugosi",
                        "structuredName": {
                            "firstName": "G\u00e1bor",
                            "lastName": "Lugosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lugosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751563"
                        ],
                        "name": "K. Zeger",
                        "slug": "K.-Zeger",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Zeger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Zeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5860393,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "033b5755745d75f595ab1ecbf28a8c1cd97d25bb",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "A general notion of universal consistency of nonparametric estimators is introduced that applies to regression estimation, conditional median estimation, curve fitting, pattern recognition, and learning concepts. General methods for proving consistency of estimators based on minimizing the empirical error are shown. In particular, distribution-free almost sure consistency of neural network estimates and generalized linear estimators is established. >"
            },
            "slug": "Nonparametric-estimation-via-empirical-risk-Lugosi-Zeger",
            "title": {
                "fragments": [],
                "text": "Nonparametric estimation via empirical risk minimization"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A general notion of universal consistency of nonparametric estimators is introduced that applies to regression estimation, conditional median estimation, curve fitting, pattern recognition, and learning concepts and distribution-free almost sure consistency of neural network estimates and generalized linear estimators are established."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115282352"
                        ],
                        "name": "Joy A. Thomas",
                        "slug": "Joy-A.-Thomas",
                        "structuredName": {
                            "firstName": "Joy",
                            "lastName": "Thomas",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joy A. Thomas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 190432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dbdb4209626fd92d2436a058663206216036e68",
            "isKey": false,
            "numCitedBy": 42793,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface to the Second Edition. Preface to the First Edition. Acknowledgments for the Second Edition. Acknowledgments for the First Edition. 1. Introduction and Preview. 1.1 Preview of the Book. 2. Entropy, Relative Entropy, and Mutual Information. 2.1 Entropy. 2.2 Joint Entropy and Conditional Entropy. 2.3 Relative Entropy and Mutual Information. 2.4 Relationship Between Entropy and Mutual Information. 2.5 Chain Rules for Entropy, Relative Entropy, and Mutual Information. 2.6 Jensen's Inequality and Its Consequences. 2.7 Log Sum Inequality and Its Applications. 2.8 Data-Processing Inequality. 2.9 Sufficient Statistics. 2.10 Fano's Inequality. Summary. Problems. Historical Notes. 3. Asymptotic Equipartition Property. 3.1 Asymptotic Equipartition Property Theorem. 3.2 Consequences of the AEP: Data Compression. 3.3 High-Probability Sets and the Typical Set. Summary. Problems. Historical Notes. 4. Entropy Rates of a Stochastic Process. 4.1 Markov Chains. 4.2 Entropy Rate. 4.3 Example: Entropy Rate of a Random Walk on a Weighted Graph. 4.4 Second Law of Thermodynamics. 4.5 Functions of Markov Chains. Summary. Problems. Historical Notes. 5. Data Compression. 5.1 Examples of Codes. 5.2 Kraft Inequality. 5.3 Optimal Codes. 5.4 Bounds on the Optimal Code Length. 5.5 Kraft Inequality for Uniquely Decodable Codes. 5.6 Huffman Codes. 5.7 Some Comments on Huffman Codes. 5.8 Optimality of Huffman Codes. 5.9 Shannon-Fano-Elias Coding. 5.10 Competitive Optimality of the Shannon Code. 5.11 Generation of Discrete Distributions from Fair Coins. Summary. Problems. Historical Notes. 6. Gambling and Data Compression. 6.1 The Horse Race. 6.2 Gambling and Side Information. 6.3 Dependent Horse Races and Entropy Rate. 6.4 The Entropy of English. 6.5 Data Compression and Gambling. 6.6 Gambling Estimate of the Entropy of English. Summary. Problems. Historical Notes. 7. Channel Capacity. 7.1 Examples of Channel Capacity. 7.2 Symmetric Channels. 7.3 Properties of Channel Capacity. 7.4 Preview of the Channel Coding Theorem. 7.5 Definitions. 7.6 Jointly Typical Sequences. 7.7 Channel Coding Theorem. 7.8 Zero-Error Codes. 7.9 Fano's Inequality and the Converse to the Coding Theorem. 7.10 Equality in the Converse to the Channel Coding Theorem. 7.11 Hamming Codes. 7.12 Feedback Capacity. 7.13 Source-Channel Separation Theorem. Summary. Problems. Historical Notes. 8. Differential Entropy. 8.1 Definitions. 8.2 AEP for Continuous Random Variables. 8.3 Relation of Differential Entropy to Discrete Entropy. 8.4 Joint and Conditional Differential Entropy. 8.5 Relative Entropy and Mutual Information. 8.6 Properties of Differential Entropy, Relative Entropy, and Mutual Information. Summary. Problems. Historical Notes. 9. Gaussian Channel. 9.1 Gaussian Channel: Definitions. 9.2 Converse to the Coding Theorem for Gaussian Channels. 9.3 Bandlimited Channels. 9.4 Parallel Gaussian Channels. 9.5 Channels with Colored Gaussian Noise. 9.6 Gaussian Channels with Feedback. Summary. Problems. Historical Notes. 10. Rate Distortion Theory. 10.1 Quantization. 10.2 Definitions. 10.3 Calculation of the Rate Distortion Function. 10.4 Converse to the Rate Distortion Theorem. 10.5 Achievability of the Rate Distortion Function. 10.6 Strongly Typical Sequences and Rate Distortion. 10.7 Characterization of the Rate Distortion Function. 10.8 Computation of Channel Capacity and the Rate Distortion Function. Summary. Problems. Historical Notes. 11. Information Theory and Statistics. 11.1 Method of Types. 11.2 Law of Large Numbers. 11.3 Universal Source Coding. 11.4 Large Deviation Theory. 11.5 Examples of Sanov's Theorem. 11.6 Conditional Limit Theorem. 11.7 Hypothesis Testing. 11.8 Chernoff-Stein Lemma. 11.9 Chernoff Information. 11.10 Fisher Information and the Cram-er-Rao Inequality. Summary. Problems. Historical Notes. 12. Maximum Entropy. 12.1 Maximum Entropy Distributions. 12.2 Examples. 12.3 Anomalous Maximum Entropy Problem. 12.4 Spectrum Estimation. 12.5 Entropy Rates of a Gaussian Process. 12.6 Burg's Maximum Entropy Theorem. Summary. Problems. Historical Notes. 13. Universal Source Coding. 13.1 Universal Codes and Channel Capacity. 13.2 Universal Coding for Binary Sequences. 13.3 Arithmetic Coding. 13.4 Lempel-Ziv Coding. 13.5 Optimality of Lempel-Ziv Algorithms. Compression. Summary. Problems. Historical Notes. 14. Kolmogorov Complexity. 14.1 Models of Computation. 14.2 Kolmogorov Complexity: Definitions and Examples. 14.3 Kolmogorov Complexity and Entropy. 14.4 Kolmogorov Complexity of Integers. 14.5 Algorithmically Random and Incompressible Sequences. 14.6 Universal Probability. 14.7 Kolmogorov complexity. 14.9 Universal Gambling. 14.10 Occam's Razor. 14.11 Kolmogorov Complexity and Universal Probability. 14.12 Kolmogorov Sufficient Statistic. 14.13 Minimum Description Length Principle. Summary. Problems. Historical Notes. 15. Network Information Theory. 15.1 Gaussian Multiple-User Channels. 15.2 Jointly Typical Sequences. 15.3 Multiple-Access Channel. 15.4 Encoding of Correlated Sources. 15.5 Duality Between Slepian-Wolf Encoding and Multiple-Access Channels. 15.6 Broadcast Channel. 15.7 Relay Channel. 15.8 Source Coding with Side Information. 15.9 Rate Distortion with Side Information. 15.10 General Multiterminal Networks. Summary. Problems. Historical Notes. 16. Information Theory and Portfolio Theory. 16.1 The Stock Market: Some Definitions. 16.2 Kuhn-Tucker Characterization of the Log-Optimal Portfolio. 16.3 Asymptotic Optimality of the Log-Optimal Portfolio. 16.4 Side Information and the Growth Rate. 16.5 Investment in Stationary Markets. 16.6 Competitive Optimality of the Log-Optimal Portfolio. 16.7 Universal Portfolios. 16.8 Shannon-McMillan-Breiman Theorem (General AEP). Summary. Problems. Historical Notes. 17. Inequalities in Information Theory. 17.1 Basic Inequalities of Information Theory. 17.2 Differential Entropy. 17.3 Bounds on Entropy and Relative Entropy. 17.4 Inequalities for Types. 17.5 Combinatorial Bounds on Entropy. 17.6 Entropy Rates of Subsets. 17.7 Entropy and Fisher Information. 17.8 Entropy Power Inequality and Brunn-Minkowski Inequality. 17.9 Inequalities for Determinants. 17.10 Inequalities for Ratios of Determinants. Summary. Problems. Historical Notes. Bibliography. List of Symbols. Index."
            },
            "slug": "Elements-of-Information-Theory-Cover-Thomas",
            "title": {
                "fragments": [],
                "text": "Elements of Information Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author examines the role of entropy, inequality, and randomness in the design of codes and the construction of codes in the rapidly changing environment."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 5119145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5609ee7a8c7432c0f502b2a6dcfe9c0039206ab",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We consider the problem of predicting {0, 1}-valued functions on Rn and smaller domains, based on their values on randomly drawn points. Our model is related to Valiant\u2032s PAC learning model, but does not require the hypotheses used for prediction to be represented in any specified form. In our main result we show how to construct prediction strategies that are optimal to within a constant factor for any reasonable class F of target functions. This result is based on new combinatorial results about classes of functions of finite VC dimension. We also discuss more computationally efficient algorithms for predicting indicator functions of axis-parallel rectangles, more general intersection closed concept classes, and halfspaces in Rn. These are also optimal to within a constant factor. Finally, we compare the general performance of prediction strategies derived by our method to that of those derived from methods in PAC learning theory."
            },
            "slug": "Predicting-{0,1}-functions-on-randomly-drawn-points-Haussler-Littlestone",
            "title": {
                "fragments": [],
                "text": "Predicting {0,1}-functions on randomly drawn points"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This model is related to Valiant\u2032s PAC learning model, but does not require the hypotheses used for prediction to be represented in any specified form and shows how to construct prediction strategies that are optimal to within a constant factor for any reasonable class F of target functions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31443676"
                        ],
                        "name": "K. Alexander",
                        "slug": "K.-Alexander",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Alexander",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Alexander"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120288220,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "24d4e3065872d673197055dcf74b7b8fc5ca0d88",
            "isKey": false,
            "numCitedBy": 225,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a class -F of functions on X, we can view Vn as a stochastic process indexed by -F and consider limit theorems for this process. To prove such theorems it is often helpful to have bounds on the tail of the r.v. sup _W I n(f ) I (see for example Dudley, 1978, Kuelbs and Dudley, 1980, Dudley and Phillip, 1983, or Gine and Zinn, 1983.) Our main question of interest is, for what classes -F can \"best possible\" bounds be obtained? So first we must ask, what are these best possible bounds? Of course"
            },
            "slug": "Probability-Inequalities-for-Empirical-Processes-a-Alexander",
            "title": {
                "fragments": [],
                "text": "Probability Inequalities for Empirical Processes and a Law of the Iterated Logarithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30883040"
                        ],
                        "name": "S. Ganesalingam",
                        "slug": "S.-Ganesalingam",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Ganesalingam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ganesalingam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690163"
                        ],
                        "name": "G. McLachlan",
                        "slug": "G.-McLachlan",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "McLachlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. McLachlan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28246450,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8c197c6679265078ef4789931701ded7a8b3c85b",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Error-rate-estimation-on-the-basis-of-posterior-Ganesalingam-McLachlan",
            "title": {
                "fragments": [],
                "text": "Error rate estimation on the basis of posterior probabilities"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881615"
                        ],
                        "name": "R. Dudley",
                        "slug": "R.-Dudley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dudley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dudley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121416923,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "10fd7180b2c0f14e5575b4892e74932b983af822",
            "isKey": false,
            "numCitedBy": 570,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Let $(X, \\mathscr{A}, P)$ be a probability space. Let $X_1, X_2,\\cdots,$ be independent $X$-valued random variables with distribution $P$. Let $P_n := n^{-1}(\\delta_{X_1} + \\cdots + \\delta_{X_n})$ be the empirical measure and let $\\nu_n := n^\\frac{1}{2}(P_n - P)$. Given a class $\\mathscr{C} \\subset \\mathscr{a}$, we study the convergence in law of $\\nu_n$, as a stochastic process indexed by $\\mathscr{C}$, to a certain Gaussian process indexed by $\\mathscr{C}$. If convergence holds with respect to the supremum norm $\\sup_{C \\in \\mathscr{C}}|f(C)|$, in a suitable (usually nonseparable) function space, we call $\\mathscr{C}$ a Donsker class. For measurability, $X$ may be a complete separable metric space, $\\mathscr{a} =$ Borel sets, and $\\mathscr{C}$ a suitable collection of closed sets or open sets. Then for the Donsker property it suffices that for some $m$, and every set $F \\subset X$ with $m$ elements, $\\mathscr{C}$ does not cut all subsets of $F$ (Vapnik-Cervonenkis classes). Another sufficient condition is based on metric entropy with inclusion. If $\\mathscr{C}$ is a sequence $\\{C_m\\}$ independent for $P$, then $\\mathscr{C}$ is a Donsker class if and only if for some $r, \\sigma_m(P(C_m)(1 - P(C_m)))^r < \\infty$."
            },
            "slug": "Central-Limit-Theorems-for-Empirical-Measures-Dudley",
            "title": {
                "fragments": [],
                "text": "Central Limit Theorems for Empirical Measures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72184075"
                        ],
                        "name": "F. William",
                        "slug": "F.-William",
                        "structuredName": {
                            "firstName": "Feller",
                            "lastName": "William",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. William"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "Most proofs are omitted as they may be found in standard textbooks on probability, such as Feller [1], Ash [2], Shiryayev [3], Chow and Teicher [4], Durrett [5], Grimmett and Stirzaker [6], and Zygmund [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 65112646,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "65ba8fd8ef9c2a70cee99d2e5cab9302d0307a1e",
            "isKey": false,
            "numCitedBy": 12393,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Office hours: MWF, immediately after class or early afternoon (time TBA). We will cover the mathematical foundations of probability theory. The basic terminology and concepts of probability theory include: random experiments, sample or outcome spaces (discrete and continuous case), events and their algebra, probability measures, conditional probability A First Course in Probability (8th ed.) by S. Ross. This is a lively text that covers the basic ideas of probability theory including those needed in statistics. Theoretical concepts are introduced via interesting concrete examples. In 394 I will begin my lectures with the basics of probability theory in Chapter 2. However, your first assignment is to review Chapter 1, which treats elementary counting methods. They are used in applications in Chapter 2. I expect to cover Chapters 2-5 plus portions of 6 and 7. You are encouraged to read ahead. In lectures I will not be able to cover every topic and example in Ross, and conversely, I may cover some topics/examples in lectures that are not treated in Ross. You will be responsible for all material in my lectures, assigned reading, and homework, including supplementary handouts if any."
            },
            "slug": "An-Introduction-To-Probability-Theory-And-Its-William",
            "title": {
                "fragments": [],
                "text": "An Introduction To Probability Theory And Its Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A First Course in Probability (8th ed.) by S. Ross is a lively text that covers the basic ideas of probability theory including those needed in statistics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1950
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5717204,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35634e8971494be944db8ed6500280c02719b729",
            "isKey": false,
            "numCitedBy": 403,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A new criterion for deriving a recursive partitioning decision rule for nonparametric classification is presented. The criterion is both conceptually and computationally simple, and can be shown to have strong statistical merit. The resulting decision rule is asymptotically Bayes' risk efficient. The notion of adaptively generated features is introduced and methods are presented for dealing with missing features in both training and test vectors."
            },
            "slug": "A-Recursive-Partitioning-Decision-Rule-for-Friedman",
            "title": {
                "fragments": [],
                "text": "A Recursive Partitioning Decision Rule for Nonparametric Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A new criterion for deriving a recursive partitioning decision rule for nonparametric classification is presented and the resulting decision rule is asymptotically Bayes' risk efficient."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32396362"
                        ],
                        "name": "D. Stoller",
                        "slug": "D.-Stoller",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stoller",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stoller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122728856,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "82632115349c627214a445698db78e8a9bf64d6e",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A distribution-free procedure for classifying a univariate random variable, z, into one of two populations on the basis of a sample of size N, in which m members are classified into one population and the remaining (N \u2013 m) into the other, is given as follows: Let t(z) = k(z) \u2013 h(z), where k(z) is the number of observations from the first population which are less than z and h(z) is similarly defined for the second population. If z \u2266 \u03b6*, where \u03b6* is that value of z for which t(z) is a maximum, classify z into the first population, otherwise into the second. The probability of correct classification, and its estimate, [N \u2013 m + t(\u03b6*)]/N, both converge in probability to the maximum attainable probability of correct classification."
            },
            "slug": "Univariate-Two-Population-Distribution-Free-Stoller",
            "title": {
                "fragments": [],
                "text": "Univariate Two-Population Distribution-Free Discrimination"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1954
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881615"
                        ],
                        "name": "R. Dudley",
                        "slug": "R.-Dudley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dudley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dudley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "Most proofs are omitted as they may be found in standard textbooks on probability, such as Feller [1], Ash [2], Shiryayev [3], Chow and Teicher [4], Durrett [5], Grimmett and Stirzaker [6], and Zygmund [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 116062098,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6c06333850b96721709b3162c6332939a2fdce31",
            "isKey": false,
            "numCitedBy": 2183,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Foundations: set theory 2. General topology 3. Measures 4. Integration 5. Lp spaces: introduction to functional analysis 6. Convex sets and duality of normed spaces 7. Measure, topology, and differentiation 8. Introduction to probability theory 9. Convergence of laws and central limit theorems 10. Conditional expectations and martingales 11. Convergence of laws on separable metric spaces 12. Stochastic processes 13. Measurability: Borel isomorphism and analytic sets Appendixes: A. Axiomatic set theory B. Complex numbers, vector spaces, and Taylor's theorem with remainder C. The problem of measure D. Rearranging sums of nonnegative terms E. Pathologies of compact nonmetric spaces Indices."
            },
            "slug": "Real-Analysis-and-Probability-Dudley",
            "title": {
                "fragments": [],
                "text": "Real Analysis and Probability"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2706323"
                        ],
                        "name": "H. Chernoff",
                        "slug": "H.-Chernoff",
                        "structuredName": {
                            "firstName": "Herman",
                            "lastName": "Chernoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Chernoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123072467,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "5d1eb89c40d08f7138e0bd01dbcdfe62ffc28d2b",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Given two univariate distribution functions F sub 1 and F sub 2 with means and variances mu sub 1, mu sub 2, (sigma sub 1) squared, (sigma sub 2) squared, Becker((1968), Recognition of Patterns, Polyteknisk Forlag, Copenhagen) has proposed S = (absolute value of (mu sub 1- mu sub 2))/(sigma sub 1 + sigma sub 2) as a measure of separability of F sub 1 and F sub 2. He has conjectured that of all pairs F sub 1, F sub 2 with specified means and variances, the worst pair using one-sided tests based on a single observation yields an error probability of (2(1 + S squared)) exp (-1) when F sub 1 and F sub 2 are equally likely. In this paper the conjecture is verified and a related conjecture is shown to apply equally well to the likelihood ratio test. (Author)"
            },
            "slug": "A-BOUND-ON-THE-CLASSIFICATION-ERROR-FOR-BETWEEN-AND-Chernoff",
            "title": {
                "fragments": [],
                "text": "A BOUND ON THE CLASSIFICATION ERROR FOR DISCRIMINATING BETWEEN POPULATIONS WITH SPECIFIED MEANS AND VARIANCES."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16943438,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dad6dabfeb8372e77fb98b50a06bdce4eb686607",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper applies the theory of Probably Approximately Correct (PAC) learning to feedforward neural networks with sigmoidal activation functions. Despite the best known upper bound on the VC dimension of such networks being 0((WlV)2), for W parameters and N computational nodes, it is shown that the asymptotic bound on the sample size required for learning with increasing accuracy 1 \u2013 c and decreasing probabllty of failure d is o((l/e)(wlog(l/c) + (WN)2 +log(l/6)), For practical values of .s and d the formula obtained for the sample sizes is a factor 2 log(2e/c) smaller than a naive use of the VC dimension result would give. Similar results are obtained for learning where the hypothesis is only guaranteed to correctly classify a given proportion of the training sample. The results are formulated in general terms and show that for many learning classes defined by smooth functions thresholded at the output, the sample size for a class with VC-dimension d and 1 parameters is 0(%10\u2019 (:)+0 [ \u20193\u2019+10w *Work supported by the ESPRIT Working Group NeuroCOLT, No. 8556"
            },
            "slug": "Sample-sizes-for-sigmoidal-neural-networks-Shawe-Taylor",
            "title": {
                "fragments": [],
                "text": "Sample sizes for sigmoidal neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940156"
                        ],
                        "name": "T. Wagner",
                        "slug": "T.-Wagner",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Wagner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wagner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 120504471,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "051c6e55c017c83d75e9425df224716f55d1a73c",
            "isKey": false,
            "numCitedBy": 238,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "first proposed by Watson (1964) and Nadaraya (1964) . In (1) k is a nonnegative function on R\" and {h} n is a sequence of positive numbers . The pointwise consistency of (1) is discussed by Watson (1964), Nadaraya (1964, 1965), Rosenblatt (1969), Schuster (1972), Greblicki (1974) and Noda (1976) . The uniform consistency is treated in the papers by Nadaraya (1965, 1970), Greblicki (1974) and Devroye (1978a) ."
            },
            "slug": "Distribution-Free-Consistency-Results-in-and-Devroye-Wagner",
            "title": {
                "fragments": [],
                "text": "Distribution-Free Consistency Results in Nonparametric Discrimination and Regression Function Estimation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16926,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11827568"
                        ],
                        "name": "R. Kronmal",
                        "slug": "R.-Kronmal",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Kronmal",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kronmal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34716098"
                        ],
                        "name": "M. Tarter",
                        "slug": "M.-Tarter",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Tarter",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tarter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121988795,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a4dbcf7925704aac134c431e613eed55d802aa8e",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A class of estimators (referred to as the Fourier estimators m and m) of the probability density function f and the associated cumulative distribution function F are considered. Here m = \u03a3mk=0 \u00e2k\u03c8k and m = \u03a3mk=0 \u00c2k \u03c8k where the functions {\u03c8k} comprise an orthogonal set with respect to weight function w(x), and the statistics \u00e2k and \u00c2k are formed from the n unordered observations.Simple expressions are found for the mean integrated square errors, M.I.S.E., of the estimators m and m, i.e., E\u222b{\u0192(x) \u2013 m(x)}2\u03c9(x)dx and E\u222b{F(x) \u2013 m(x)}2w(x)dx in terms of the variances of \u00e2k and \u00c2k and the Fourier coefficients of f and F.For Fourier estimators based upon the trigonometric orthogonal functions the \u00e2k are the sample trigonometric moments. The variances and covariances of the statistics \u00e2k and \u00c2k for these special cases are shown to be linear functions of the density f's Fourier coefficients. Therefore, simple expressions are obtained which relate the M.I.S.E. of the Fourier estimators m and m to the Fourier coeffi..."
            },
            "slug": "The-Estimation-of-Probability-Densities-and-by-Kronmal-Tarter",
            "title": {
                "fragments": [],
                "text": "The Estimation of Probability Densities and Cumulatives by Fourier Series Methods"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145822375"
                        ],
                        "name": "G. Toussaint",
                        "slug": "G.-Toussaint",
                        "structuredName": {
                            "firstName": "Godfried",
                            "lastName": "Toussaint",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Toussaint"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34682029"
                        ],
                        "name": "R. W. Donaldson",
                        "slug": "R.-W.-Donaldson",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Donaldson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. W. Donaldson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31074009,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e4ebdc9496d5f1e6706a2b5c5c8697a3e76a487",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A contour-tracing technique originally devised by Clemens and Mason was modified and used with several different classifiers to recognize upper case handprinted characters. Recognition accuracies obtained compare favorably with other published results, particularly when additional simple tests are performed to differentiate commonly confused characters. One suboptimum classifier, in addition to yielding near optimum performance when tested on training data, uses much less statistical information than the optimum Bayes classifier and is significantly better than the optimum classifier when training and test data are limited."
            },
            "slug": "Algorithms-for-Recognizing-Contour-Traced-Toussaint-Donaldson",
            "title": {
                "fragments": [],
                "text": "Algorithms for Recognizing Contour-Traced Handprinted Characters"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "A contour-tracing technique originally devised by Clemens and Mason was modified and used with several different classifiers to recognize upper case handprinted characters, and recognition accuracies obtained compare favorably with other published results."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2960620"
                        ],
                        "name": "W. Meisel",
                        "slug": "W.-Meisel",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Meisel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Meisel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60951611,
            "fieldsOfStudy": [
                "Art",
                "Education"
            ],
            "id": "5ee6ff0c6d4c610be461d41f47d7c3ee3b11a74d",
            "isKey": false,
            "numCitedBy": 331,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-oriented-approaches-to-pattern-recognition-Meisel",
            "title": {
                "fragments": [],
                "text": "Computer-oriented approaches to pattern recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143971171"
                        ],
                        "name": "P. Hall",
                        "slug": "P.-Hall",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50467915"
                        ],
                        "name": "M. Wand",
                        "slug": "M.-Wand",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "Wand",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 121655938,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "015c51fa1eb167694bb7c1d55abdd3cfe5a0a043",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY We propose a technique for nonparametric discrimination in which smoothing parameters are chosen jointly, according to a criterion based on the difference between two densities. The approach is suitable for categorical, continuous and mixed data, and uses information from both populations to determine the smoothing parameter for any one population. In the case of categorical data, optimal performance is sometimes achieved using negative smoothing parameters, a property which does not emerge if the smoothing parameters are chosen individually."
            },
            "slug": "On-nonparametric-discrimination-using-density-Hall-Wand",
            "title": {
                "fragments": [],
                "text": "On nonparametric discrimination using density differences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15643492,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ef2512575677726dc72057d27f09559d23d103ec",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive exponential inequalities for the oscillation of functions of random variables about their mean. This is illustrated on the Kolmogorov-Smirnov statistic, the total variation distance for empirical measures, the Vapnik-Chervonenkis distance, and various performance criteria in nonparametric density estimation. We also derive bounds for the variances of these quantities."
            },
            "slug": "Exponential-Inequalities-in-Nonparametric-Devroye",
            "title": {
                "fragments": [],
                "text": "Exponential Inequalities in Nonparametric Estimation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145247053"
                        ],
                        "name": "W. Maass",
                        "slug": "W.-Maass",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Maass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Maass"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8700364,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e606728c2e325aea8153992bf26e4e78fe6c2cfc",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that high-order feedforward neural nets of constant depth with piecewise-polynomial activation functions and arbitrary real weights can be simulated for Boolean inputs and outputs by neural nets of a somewhat larger size and depth with Heaviside gates and weights from {-1, 0, 1}. This provides the first known upper bound for the computational power of the former type of neural nets. It is also shown that in the case of first-order nets with piecewise-linear activation functions one can replace arbitrary real weights by rational numbers with polynomially many bits without changing the Boolean function that is computed by the neural net. In order to prove these results, we introduce two new methods for reducing nonlinear problems about weights in multilayer neural nets to linear problems for a transformed set of parameters. These transformed parameters can be interpreted as weights in a somewhat larger neural net. \nAs another application of our new proof technique we show that neural nets with piecewise-polynomial activation functions and a constant number of analog inputs are probably approximately correct (PAC) learnable (in Valiant's model for PAC learning [Comm. Assoc. Comput. Mach., 27 (1984), pp. 1134--1142])."
            },
            "slug": "Bounds-for-the-computational-power-and-learning-of-Maass",
            "title": {
                "fragments": [],
                "text": "Bounds for the computational power and learning complexity of analog neural nets"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "It is shown that high order feedforward neural nets of constant depth with piecewise polynomial activation functions and arbitrary real weights can be simulated for boolean inputs and outputs by neuralnets of a somewhat larger size and depth with linear threshold gates and weights, providing the first known upper bound for the computational power and VC-dimension of the former type of neural nets."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061635449"
                        ],
                        "name": "J. Ott",
                        "slug": "J.-Ott",
                        "structuredName": {
                            "firstName": "J\u00fcrg",
                            "lastName": "Ott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11827568"
                        ],
                        "name": "R. Kronmal",
                        "slug": "R.-Kronmal",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Kronmal",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kronmal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123084404,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5efe95b6603833595a19308192bb91dd577022cd",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Four new methods for classification of multivariate binary data are presented, based on an orthogonal expansion of the density in terms of discrete Fourier series. The performance of these methods in 11 populations of various structures was measured in terms of mean error of misclassification and was compared to three well-known methods. Also, performance in density estimation was measured for the appropriate methods. In general, the new methods seem to be superior for classification as well as for density estimation."
            },
            "slug": "Some-Classification-Procedures-for-Multivariate-Ott-Kronmal",
            "title": {
                "fragments": [],
                "text": "Some Classification Procedures for Multivariate Binary Data Using Orthogonal Functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3766517"
                        ],
                        "name": "J. Knoke",
                        "slug": "J.-Knoke",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Knoke",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Knoke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121313506,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a46ce77b9c6e865f4f4de004d58117ac7044394",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-robust-estimation-of-classification-error-rates-Knoke",
            "title": {
                "fragments": [],
                "text": "The robust estimation of classification error rates"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076400"
                        ],
                        "name": "B. Caprile",
                        "slug": "B.-Caprile",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Caprile",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caprile"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10243731,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "898c01de58eb3b8e790b60e0fe0db2230d88f15b",
            "isKey": false,
            "numCitedBy": 699,
            "numCiting": 152,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning an input-output mapping from a set of examples, of the type that many neural networks have been constructed to perform, can be regarded as synthesizing an approximation of a multi-dimensional function. We develop a theoretical framework for approximation based on regularization techniques that leads to a class of three-layer networks that we call Generalized Radial Basis Functions (GRBF). GRBF networks are not only equivalent to generalized splines, but are also closely related to several pattern recognition methods and neural network algorithms. The paper introduces several extensions and applications of the technique and discusses intriguing analogies with neurobiological data."
            },
            "slug": "Extensions-of-a-Theory-of-Networks-for-and-Learning-Girosi-Poggio",
            "title": {
                "fragments": [],
                "text": "Extensions of a Theory of Networks for Approximation and Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A theoretical framework for approximation based on regularization techniques that leads to a class of three-layer networks that is called Generalized Radial Basis Functions (GRBF), which is not only equivalent to generalized splines, but is closely related to several pattern recognition methods and neural network algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2031033"
                        ],
                        "name": "P. Narendra",
                        "slug": "P.-Narendra",
                        "structuredName": {
                            "firstName": "Patrenahalli",
                            "lastName": "Narendra",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Narendra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26204315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8aee4e1022b18e7ecad7a963a5f6a3edb3832f2d",
            "isKey": false,
            "numCitedBy": 1240,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A feature subset selection algorithm based on branch and bound techniques is developed to select the best subset of m features from an n-feature set. Existing procedures for feature subset selection, such as sequential selection and dynamic programming, do not guarantee optimality of the selected feature subset. Exhaustive search, on the other hand, is generally computationally unfeasible. The present algorithm is very efficient and it selects the best subset without exhaustive search. Computational aspects of the algorithm are discussed. Results of several experiments demonstrate the very substantial computational savings realized. For example, the best 12-feature set from a 24-feature set was selected with the computational effort of evaluating only 6000 subsets. Exhaustive search would require the evaluation of 2 704 156 subsets."
            },
            "slug": "A-Branch-and-Bound-Algorithm-for-Feature-Subset-Narendra-Fukunaga",
            "title": {
                "fragments": [],
                "text": "A Branch and Bound Algorithm for Feature Subset Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A feature subset selection algorithm based on branch and bound techniques is developed to select the best subset of m features from an n-feature set with the computational effort of evaluating only 6000 subsets."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98149878"
                        ],
                        "name": "Fredrick W. Machell",
                        "slug": "Fredrick-W.-Machell",
                        "structuredName": {
                            "firstName": "Fredrick",
                            "lastName": "Machell",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fredrick W. Machell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15311449,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13d99619d0de4d69f23b5042129985bbfb9e67eb",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze and compare several data structures and algorithms for evaluating the kernel density estimate. Frequent evaluations of this estimate are for example needed for plotting, error estimation, Monte Carlo estimation of probabilities and functionals, and pattern classification. An experimental comparison is included."
            },
            "slug": "Data-Structures-in-Kernel-Density-Estimation-Devroye-Machell",
            "title": {
                "fragments": [],
                "text": "Data Structures in Kernel Density Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Frequent evaluations of this estimate are for example needed for plotting, error estimation, Monte Carlo estimation of probabilities and functionals, and pattern classification."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065748442"
                        ],
                        "name": "P. Goldberg",
                        "slug": "P.-Goldberg",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Goldberg",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Goldberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2875953"
                        ],
                        "name": "M. Jerrum",
                        "slug": "M.-Jerrum",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Jerrum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jerrum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11293090,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "94d43b9ba85a57523c9b553dd5ca645aa5716d03",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The Vapnik-Chervonenkis (V-C) dimension is an important combinatorial tool in the analysis of learning problems in the PAC framework. For polynomial learnability, we seek upper bounds on the V-C dimension that are polynomial in the syntactic complexity of concepts. Such upper bounds are automatic for discrete concept classes, but hitherto little has been known about what general conditions guarantee polynomial bounds on V-C dimension for classes in which concepts and examples are represented by tuples of real numbers. In this paper, we show that for two general kinds of concept class the V-C dimension is polynomially bounded in the number of real numbers used to define a problem instance. One is classes where the criterion for membership of an instance in a concept can be expressed as a formula (in the first-order theory of the reals) with fixed quantification depth and exponentially-bounded length, whose atomic predicates are polynomial inequalities of exponentially-bounded degree, The other is classes where containment of an instance in a concept is testable in polynomial time, assuming we may compute standard arithmetic operations on reals exactly in constant time.Our results show that in the continuous case, as in the discrete, the real barrier to efficient learning in the Occam sense is complexity-theoretic and not information-theoretic. We present examples to show how these results apply to concept classes defined by geometrical figures and neural nets, and derive polynomial bounds on the V-C dimension for these classes."
            },
            "slug": "Bounding-the-Vapnik-Chervonenkis-Dimension-of-by-Goldberg-Jerrum",
            "title": {
                "fragments": [],
                "text": "Bounding the Vapnik-Chervonenkis Dimension of Concept Classes Parameterized by Real Numbers"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The results show that for two general kinds of concept class the V-C dimension is polynomially bounded in the number of real numbers used to define a problem instance, and that in the continuous case, as in the discrete, the real barrier to efficient learning in the Occam sense is complexity- theoretic and not information-theoretic."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 6886185,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa9f34e869d7b8cca2f1cdcf4f79ee9a4478409b",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning in multilayer feed-forward networks of linear threshold units. We show that the Vapnik-Chervonenkis dimension of the class of functions that can be computed by a two-layer threshold network with real inputs is at least proportional to the number of weights in the network. This result also holds for a large class of twolayer networks with binary inputs, and a large class of three-layer networks with real inputs. In Valiant's probably approximately correct learning framework, this implies that the number of examples necessary for learning in these networks is at least linear in the number of weights. This bound is within a log factor of the upper bound."
            },
            "slug": "Lower-bounds-on-the-Vapnik-Chervonenkis-dimension-Bartlett",
            "title": {
                "fragments": [],
                "text": "Lower bounds on the Vapnik-Chervonenkis dimension of multi-layer threshold networks"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "It is shown that the Vapnik-Chervonenkis dimension of the class of functions that can be computed by a two-layer threshold network with real inputs is at least proportional to the number of weights in the network."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143725639"
                        ],
                        "name": "W. Wong",
                        "slug": "W.-Wong",
                        "structuredName": {
                            "firstName": "Wing",
                            "lastName": "Wong",
                            "middleNames": [
                                "Hung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2266946"
                        ],
                        "name": "Xiaotong Shen",
                        "slug": "Xiaotong-Shen",
                        "structuredName": {
                            "firstName": "Xiaotong",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaotong Shen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120727005,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4cb91932b17952b9368199de1b84fb31da308944",
            "isKey": false,
            "numCitedBy": 282,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Let Y 1 ,...,Y n be independent identically distributed with density p 0 and let F be a space of densities. We show that the supremum of the likelihood ratios \u03a0 i=1 n p(Y i )/p 0 (Y i ), where the supremum is over p \u2208 F with \u2225p l/2 - p 0 1/2 \u2225 2 \u2265 e, is exponentially small with probability exponentially close to 1. The exponent is proportional to ne 2 . The only condition required for this to hold is that e exceeds a value determined by the bracketing Hellinger entropy of F. A similar inequality also holds if we replace F by F n and p 0 by q n , where q n is an approximation to p 0 in a suitable sense. These results are applied to establish rates of convergence of sieve MLEs. Furthermore, weak conditions are given under which the optimal rate e n defined by H(e n ,F)=ne n 2 , where H(.,F) is the Hellinger entropy of F, is nearly achievable by sieve estimators."
            },
            "slug": "Probability-inequalities-for-likelihood-ratios-and-Wong-Shen",
            "title": {
                "fragments": [],
                "text": "Probability inequalities for likelihood ratios and convergence rates of sieve MLEs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1888694"
                        ],
                        "name": "K. Gabriel",
                        "slug": "K.-Gabriel",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Gabriel",
                            "middleNames": [
                                "Ruben"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Gabriel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5967937"
                        ],
                        "name": "R. Sokal",
                        "slug": "R.-Sokal",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Sokal",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sokal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 83538839,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "3f99f6292ca37768b237311b250de814fac1a100",
            "isKey": false,
            "numCitedBy": 1281,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors discuss the problems of describing geographic variation data and develop statistical methods for categorizing sets of populations sampled from different localities. The general approach of the simultaneous test procedures, available with a variety of statistical tests and for continuous as well as for categorical data, is employed with these techniques. Geographical regions are defined as sets of connected localities, with connectedness being defined geometrically. Maximal acceptahle connected sets of localities (defined as regions) or coarsest acceptable connected partitions of the entire set of localities are found by these procedures. These are illustrated with several examples. I. AIMS AND PURPOSES The primary aim of geographic variation anialysis in biological systematics is the description and summarization of patterns of variation and covariation of characteristics of organisms that are distributed over an area. Such analyses are generally applied to species populations to study the variation of diverse characters. The most frequently studied characters are morphological, but recently there have also been such studies of biochemical, physiological, behavioral, cytological, immunological, as well as genetic characters. The basis for studies in geographic variation rests on the existence of populations of comparable organisms at a number of localities in the area under study. Comparisons of these populations are made in terms of one or more observable characters and the analyses relate these comparisons to differences in location. Data for studies in geographic variation consist of samples taken from the populations at a given number of localities, with a set of characteristics observed for each organism sampled. Summary statistics may be computed for each sample, as, for example, means and standard deviations for single measurable characteristics, correlations for pairs of such variables, etc. A summary of the data would then consist of a list of localities, each accompanied by its set of summary statistics for observed characteristics. In most cases, the infornation in such a list would be difficult to grasp and much would be gained by plotting the statistics on a map (or several maps) according to their location. Such graphic representation often reveals a good deal about the geographic variation pattern involved. A step beyond mere description of the pattern of variation of the characteristics of organisms is categorization. Usually, one prefers to group together localities that are geographically adjacent and whose populations are similar in their characteristics. This may be desired merely for purposes of simplification and summarization, or for the formal or semi-formal recognition of a population or series of populations in terms of the Linnean system. The study of patterns of geographic variation will often lead to causal ana:lysis. One may attempt to interpret the variational and correlational patterns of a species as adaptations to variation in known environmental factors, such as climatic, topographic, or edaphic variables. Other possible causes of variation may be differences in associated species populations, such as host plants, parasites, predators, etc. Marked and abrupt changes in characters between close localities may be related to abrupt changes in the above factors, to strong barriers to dispersal of the organisms or to secondary zones of intergradation between allopatrically differentiated populations. Unusual patterns of"
            },
            "slug": "A-New-Statistical-Approach-to-Geographic-Variation-Gabriel-Sokal",
            "title": {
                "fragments": [],
                "text": "A New Statistical Approach to Geographic Variation Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "The authors discuss the problems of describing geographic variation data and develop statistical methods for categorizing sets of populations sampled from different localities and describe the approach of the simultaneous test procedures employed with these techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2436799"
                        ],
                        "name": "M. Kraaijveld",
                        "slug": "M.-Kraaijveld",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kraaijveld",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kraaijveld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747298"
                        ],
                        "name": "R. Duin",
                        "slug": "R.-Duin",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Duin",
                            "middleNames": [
                                "P.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61571232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed40971c21446a5069ae4a901340c19b3bbd613e",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors discuss and analyze a class of kernal-based networks which are based on the Parzen classifier. Although this class of networks has the highly desirable feature of consistency, it has very high computational demands. Therefore, a novel method and an existing method to minimize the size of these networks while preserving the classification performance are discussed. The authors present a theorem that explicitly states the relation between various parameters in the network design procedure and the confidence that one can have in the classification performance of the minimized network. The methods presented facilitate a powerful reduction of the network size and are essentially independent of the probability distributions.<<ETX>>"
            },
            "slug": "Generalization-capabilities-of-minimal-kernel-based-Kraaijveld-Duin",
            "title": {
                "fragments": [],
                "text": "Generalization capabilities of minimal kernel-based networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The authors present a theorem that explicitly states the relation between various parameters in the network design procedure and the confidence that one can have in the classification performance of the minimized network."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNN-91-Seattle International Joint Conference on Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720911"
                        ],
                        "name": "T. Kailath",
                        "slug": "T.-Kailath",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kailath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kailath"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61287295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5b2ee1af1c0a867f564e44f3f79b8d2bdeca749",
            "isKey": false,
            "numCitedBy": 1797,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Minimization of the error probability to determine optimum signals is often difficult to carry out. Consequently, several suboptimum performance measures that are easier than the error probability to evaluate and manipulate have been studied. In this partly tutorial paper, we compare the properties of an often used measure, the divergence, with a new measure that we have called the Bhattacharyya distance. This new distance measure is often easier to evaluate than the divergence. In the problems we have worked, it gives results that are at least as good as, and are often better, than those given by the divergence."
            },
            "slug": "The-Divergence-and-Bhattacharyya-Distance-Measures-Kailath",
            "title": {
                "fragments": [],
                "text": "The Divergence and Bhattacharyya Distance Measures in Signal Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This partly tutorial paper compares the properties of an often used measure, the divergence, with a new measure that is often easier to evaluate, called the Bhattacharyya distance, which gives results that are at least as good and often better than those given by the divergence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34896449"
                        ],
                        "name": "R. Casey",
                        "slug": "R.-Casey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Casey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Casey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34555453,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb73120b579eceff08cc7308d81839ce50280038",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A sequential optical character recognition algorithm, ideally suited for implementation by means of microprocessors with limited storage capabilities, is formulated in terms of a binary decision tree. Upper bounds On the recognition performance are derived in terms of the stability of the digitized picture elements. The design process is described in detail. The algorithm is tested on single-font typewritten characters and the experimental and theoretical results are compared."
            },
            "slug": "Decision-tree-design-using-a-probabilistic-model-Casey-Nagy",
            "title": {
                "fragments": [],
                "text": "Decision tree design using a probabilistic model"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A sequential optical character recognition algorithm, ideally suited for implementation by means of microprocessors with limited storage capabilities, is formulated in terms of a binary decision tree."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145016534"
                        ],
                        "name": "J. Moody",
                        "slug": "J.-Moody",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Moody",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Moody"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319258"
                        ],
                        "name": "C. Darken",
                        "slug": "C.-Darken",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Darken",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Darken"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31251383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e7c4f513f24c3b82a1138b9f22ed87ed00cbe76",
            "isKey": false,
            "numCitedBy": 4527,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a network architecture which uses a single internal layer of locally-tuned processing units to learn both classification tasks and real-valued function approximations (Moody and Darken 1988). We consider training such networks in a completely supervised manner, but abandon this approach in favor of a more computationally efficient hybrid learning method which combines self-organized and supervised learning. Our networks learn faster than backpropagation for two reasons: the local representations ensure that only a few units respond to any given input, thus reducing computational overhead, and the hybrid learning rules are linear rather than nonlinear, thus leading to faster convergence. Unlike many existing methods for data analysis, our network architecture and learning rules are truly adaptive and are thus appropriate for real-time use."
            },
            "slug": "Fast-Learning-in-Networks-of-Locally-Tuned-Units-Moody-Darken",
            "title": {
                "fragments": [],
                "text": "Fast Learning in Networks of Locally-Tuned Processing Units"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This work proposes a network architecture which uses a single internal layer of locally-tuned processing units to learn both classification tasks and real-valued function approximations (Moody and Darken 1988)."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723095"
                        ],
                        "name": "H. Simon",
                        "slug": "H.-Simon",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Simon",
                            "middleNames": [
                                "Ulrich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Simon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 10928763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a63ee9bb7c0b6bdbe4b78cbcb8dc503598325a12",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a p-concept classC, we define two important functionsdC(\ufffd),d\ufffdC(\ufffd) (related to the notion of\ufffd-shattering). We prove a lower bound of\ufffd((dC(\ufffd)\ufffd1)/(\ufffd\ufffd2)) on the number of examples required for learningCwith an (\ufffd,\ufffd\ufffd)-good model of probability. We prove similar lower bounds for some other learning models like learning with\ufffd-bounded absolute (or quadratic) difference or learning with a\ufffd-good decision rule. For the class ND of nondecreasing p-concepts on the real domain,dND(\ufffd)=\ufffd(1/\ufffd). It can be shown that the resulting lower bounds for learning ND (within the models in consideration) are tight to within a logarithmic factor. In order to get the \u201calmost-matching\u201d upper bounds, we introduce a new method for designing learning algorithms: dynamic partitioning of the domain by use of splitting trees. The paper also contains a discussion of the gaps between the general lower bounds and the corresponding general upper bounds. It can be shown that, under very mild conditions, these gaps are quite narrow."
            },
            "slug": "General-bounds-on-the-number-of-examples-needed-for-Simon",
            "title": {
                "fragments": [],
                "text": "General bounds on the number of examples needed for learning probabilistic concepts"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new method for designing learning algorithms: dynamic partitioning of the domain by use of splitting trees is introduced and it can be shown that the resulting lower bounds for learning ND are tight to within a logarithmic factor."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145037127"
                        ],
                        "name": "K. Gowda",
                        "slug": "K.-Gowda",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Gowda",
                            "middleNames": [
                                "Chidananda"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Gowda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144848910"
                        ],
                        "name": "G. Krishna",
                        "slug": "G.-Krishna",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Krishna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Krishna"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18982205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44731460f9a1ca3e30c376d2a4f0c843573b2c6b",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A two-stage iterative algorithm for selecting a subset of a training set of samples for use in a condensed nearest neighbor (CNN) decision rule is introduced. The proposed method uses the concept of mutual nearest neighborhood for selecting samples close to the decision line. The efficacy of the algorithm is brought out by means of an example."
            },
            "slug": "The-condensed-nearest-neighbor-rule-using-the-of-Gowda-Krishna",
            "title": {
                "fragments": [],
                "text": "The condensed nearest neighbor rule using the concept of mutual nearest neighborhood (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A two-stage iterative algorithm for selecting a subset of a training set of samples for use in a condensed nearest neighbor (CNN) decision rule is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2679330"
                        ],
                        "name": "J. Burbea",
                        "slug": "J.-Burbea",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Burbea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burbea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144532256"
                        ],
                        "name": "C. R. Rao",
                        "slug": "C.-R.-Rao",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Rao",
                            "middleNames": [
                                "Radhakrishna"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. R. Rao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10173046,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "35da3a6da1d785488c08d79e065f4182d2403395",
            "isKey": false,
            "numCitedBy": 409,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Three measures of divergence between vectors in a convex set of a n -dimensional real vector space are defined in terms of certain types of entropy functions, and their convexity property is studied. Among other results, a classification of the entropies of degree \\alpha is obtained by the convexity of these measures. These results have applications in information theory and biological studies."
            },
            "slug": "On-the-convexity-of-some-divergence-measures-based-Burbea-Rao",
            "title": {
                "fragments": [],
                "text": "On the convexity of some divergence measures based on entropy functions"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Three measures of divergence between vectors in a convex set of a n -dimensional real vector space are defined in terms of certain types of entropy functions, and their convexity property is studied."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2550392"
                        ],
                        "name": "B. Efron",
                        "slug": "B.-Efron",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Efron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Efron"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121169833,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6957cb5b8335a27e7bcccad134ae730523e5de8e",
            "isKey": false,
            "numCitedBy": 2313,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We construct a prediction rule on the basis of some data, and then wish to estimate the error rate of this rule in classifying future observations. Cross-validation provides a nearly unbiased estimate, using only the original data. Cross-validation turns out to be related closely to the bootstrap estimate of the error rate. This article has two purposes: to understand better the theoretical basis of the prediction problem, and to investigate some related estimators, which seem to offer considerably improved estimation in small samples."
            },
            "slug": "Estimating-the-Error-Rate-of-a-Prediction-Rule:-on-Efron",
            "title": {
                "fragments": [],
                "text": "Estimating the Error Rate of a Prediction Rule: Improvement on Cross-Validation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153340899"
                        ],
                        "name": "J. Aitchison",
                        "slug": "J.-Aitchison",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Aitchison",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aitchison"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46578843"
                        ],
                        "name": "C. Aitken",
                        "slug": "C.-Aitken",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Aitken",
                            "middleNames": [
                                "G.",
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Aitken"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120740797,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "530842bc3328fac3d8fb34a735d9ee0280cc3443",
            "isKey": false,
            "numCitedBy": 598,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY An extension of the kernel method of density estimation from continuous to multivariate binary spaces is described. Its simple nonparametric nature together with its consistency properties make it an attractive tool in discrimination problems, with some advantages over already proposed parametric counterparts. The method is illustrated by an application to a particular medical diagnostic problem. Simple extensions of the method to categorical data and to data of mixed binary and continuous form are indicated."
            },
            "slug": "Multivariate-binary-discrimination-by-the-kernel-Aitchison-Aitken",
            "title": {
                "fragments": [],
                "text": "Multivariate binary discrimination by the kernel method"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "The kernel method of density estimation from continuous to multivariate binary spaces is described, finding its simple nonparametric nature together with its consistency properties make it an attractive tool in discrimination problems, with some advantages over already proposed parametric counterparts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18822307,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7a17fe7b45f610afbecd204b8284f1ec85f8b061",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "THE-EXPECTED-SIZE-OF-SOME-GRAPHS-IN-COMPUTATIONAL-Devroye",
            "title": {
                "fragments": [],
                "text": "THE EXPECTED SIZE OF SOME GRAPHS IN COMPUTATIONAL GEOMETRY"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102636025"
                        ],
                        "name": "C. Chow",
                        "slug": "C.-Chow",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Chow",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chow"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44251259,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "238716b21a220929bc60ae606032495f9a23d587",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The memory we describe here is a logical and practical outgrowth of the content addressable distributed logic memory of Lee and Paull.1 However, there are several significant differences: the inclusion of a \"match\" flip-flop and a \"control\" flip-flop in each cell of the memory, the addition of a \"Mark\" line to activate many cells simultaneously, and the control of the propagation of the marking signal. As a consequence of these, the memory has some novel capabilities, among which are the ability to simultaneously shift the contents of a large group of cells, thus opening or closing a gap in the memory, and the ability to simultaneously mark strings of interest in separate parts of the memory."
            },
            "slug": "Statistical-Independence-and-Threshold-Functions-Chow",
            "title": {
                "fragments": [],
                "text": "Statistical Independence and Threshold Functions"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A logical and practical outgrowth of the content addressable distributed logic memory of Lee and Paull, this memory has some novel capabilities, among which are the ability to simultaneously shift the contents of a large group of cells, thus opening or closing a gap in the memory."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Electron. Comput."
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158092105"
                        ],
                        "name": "L. Zhao",
                        "slug": "L.-Zhao",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Zhao",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Zhao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122992005,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2ceb4db78517afccc5b45809fa6ac843939c5bb5",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Exponential-bounds-of-mean-error-for-the-kernel-of-Zhao",
            "title": {
                "fragments": [],
                "text": "Exponential bounds of mean error for the kernel estimates of regression functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398005725"
                        ],
                        "name": "J. Mui",
                        "slug": "J.-Mui",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Mui",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97306284"
                        ],
                        "name": "K. Fu",
                        "slug": "K.-Fu",
                        "structuredName": {
                            "firstName": "King-Sun",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14243002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4905bc8345636d0649399afaf819ceba242e7f46",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Describes the interactive design of a binary tree classifier. The binary tree classifier with a quadratic discriminant function using up to ten features at each nonterminal node was applied to classify 1294 cells into one of 17 classes. Classification accuracies of 83 percent and 77 percent were obtained by the binary tree classifier using the resubstitution and the leave-one-out methods of error estimation, respectively, whereas the existing results using the same data are 71 percent and 67 percent using a single stage linear classifier with 20 features and the resubstitution and the half-and-half methods of error estimation, respectively."
            },
            "slug": "Automated-classification-of-nucleated-blood-cells-a-Mui-Fu",
            "title": {
                "fragments": [],
                "text": "Automated classification of nucleated blood cells using a binary tree classifier"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The binary tree classifier with a quadratic discriminant function using up to ten features at each nonterminal node was applied to classify 1294 cells into one of 17 classes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785855"
                        ],
                        "name": "W. Greblicki",
                        "slug": "W.-Greblicki",
                        "structuredName": {
                            "firstName": "W\u0142odzimierz",
                            "lastName": "Greblicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Greblicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143803540"
                        ],
                        "name": "M. Pawlak",
                        "slug": "M.-Pawlak",
                        "structuredName": {
                            "firstName": "Miros\u0142aw",
                            "lastName": "Pawlak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pawlak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8106526,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8290bb941539a889ed23c67d03dbebf5a1713b47",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-classification-procedure-using-the-multiple-Greblicki-Pawlak",
            "title": {
                "fragments": [],
                "text": "A classification procedure using the multiple Fourier series"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Sci."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2771517"
                        ],
                        "name": "S. Hora",
                        "slug": "S.-Hora",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Hora",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hora"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12698541"
                        ],
                        "name": "J. Wilcox",
                        "slug": "J.-Wilcox",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wilcox",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wilcox"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 168056184,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c17bd05c4a0027ece69439da2d0d1ccd17851f79",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Researchers seeking to estimate the classification accuracy of linear discriminant functions in a more than two-population setting have had little guidance as to the most appropriate technique. The authors review the available techniques and present an additional alternative which combines features of the U-method and the recently developed posterior probability estimator. The new alternative is compared with other methods by Mont\u00e9 Carlo simulation."
            },
            "slug": "Estimation-of-Error-Rates-in-Several-Population-Hora-Wilcox",
            "title": {
                "fragments": [],
                "text": "Estimation of Error Rates in Several-Population Discriminant Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47022813"
                        ],
                        "name": "J.A. Anderson",
                        "slug": "J.A.-Anderson",
                        "structuredName": {
                            "firstName": "J.A.",
                            "lastName": "Anderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J.A. Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061358113"
                        ],
                        "name": "Edward Rosenfeld",
                        "slug": "Edward-Rosenfeld",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8160958,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d0e5a21512d2aea34026f83b1ff86ea30b8c0d6",
            "isKey": false,
            "numCitedBy": 986,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "ion for Knowledge Acquisition\u201d by T. Bylander and B. Chadrasekaran. Chandrasekaran\u2019s papers are usually illuminating, and this one does not fail: He and Bylander re-examine such traditional beliefs as knowledge should be uniformly represented and controlled and the knowledge base should be separated from the inference engine. The final 10 papers in volume 1 discuss generalized learning and ruleinduction techniques. They are interesting and informative, particularly \u201cGeneralization and Noise\u201d by Y. Kodratoff and M. Manango, which discusses symbolic and numeric rule induction. Most rule-induction techniques focus on the use of examples and numeric analysis such as repertory grids. Kodratoff\u2019s and Manango\u2019s exploration of how the two complement each other is refreshing. Because of their technical nature and the amount of work it would take to put their content to use, most of the papers in this section of the volume are more appropriate for a specialized or research-oriented group. For those just getting involved in knowledge-based\u2013systems development, Knowledge Acquisition Tools for Expert Systems is the more useful volume. In addition to discussing the tools themselves, most of the papers contain details of the knowledgeacquisition techniques that are automated, thus providing much of the same information which is available in the first volume. As an added benefit, they also often discuss the underlying architectures for solving domain-specific problems. For instance, the details of the medical diagnostic architecture laid out in \u201cDesign for Acquisition: Principles of Knowledge System Design to Facilitate Knowledge Acquisition\u201d by T. R. Gruber and P. R. Cohen are almost as useful as the discussion of how to build a knowledge-acquisition system. Volume 2 is particularly germane given the rise in commercial interest about automated knowledge acquisition following this year\u2019s introduction of Neuron Data\u2019s NEXTRATM product and last year\u2019s introduction of Test Bench by Texas Instruments. Test Bench is actually discussed in \u201cA Mixed-Initiative Workbench for Knowledge Acquisition\u201d by G. S. Kahn, E. H. Breaux, P. De Klerk, and R. L. Joseph. This volume provides the background necessary to evaluate knowledge-acquisition tools such as NEXTRA, Test Bench, and AutoIntelligence (IntelligenceWare). The vendors of knowledge-based\u2013systems development tools, for example, Inference, IntelliCorp, Aion, AI Corp., and IBM, would do well to pay heed to these books because they point the way to removing the knowledge bottleneck from knowledge-based\u2013systems development. Overall, the papers in both volumes are comprehensive and well integrated, a sometimes difficult state to achieve when compiling a collection of papers resulting from a small conference. The collection is comparable to Anna Hart\u2019s Knowledge Acquisition for Expert Systems (McGraw-Hill, 1986), but it is broader in scope and not as structured. The arrangement of the papers is marred only by an overly brief index. Few readers can be expected to read a collection from beginning to end, and a better index would facilitate more enlightened use. Less important\u2014but nevertheless distracting\u2014is the large number of typographical errors in both volumes. In conclusion, the set is recommended for both the commercial and research knowledge-based\u2013systems practitioner. Reading the volumes in reverse order might be more useful to the commercial developer given the extra information available in volume 2. Neurocomputing: Foundations of Research"
            },
            "slug": "Neurocomputing:-Foundations-of-Research-Anderson-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Neurocomputing: Foundations of Research"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The set is recommended for both the commercial and research knowledge-based\u2013systems practitioner and provides the background necessary to evaluate knowledge-acquisition tools such as NEXTRA, Test Bench, and AutoIntelligence (IntelligenceWare)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20658113"
                        ],
                        "name": "A. Barron",
                        "slug": "A.-Barron",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barron",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087528"
                        ],
                        "name": "L. Gy\u00f6rfi",
                        "slug": "L.-Gy\u00f6rfi",
                        "structuredName": {
                            "firstName": "L\u00e1szl\u00f3",
                            "lastName": "Gy\u00f6rfi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gy\u00f6rfi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071706341"
                        ],
                        "name": "E. V. D. Meulen",
                        "slug": "E.-V.-D.-Meulen",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Meulen",
                            "middleNames": [
                                "C.",
                                "van",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. V. D. Meulen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5731928,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ec64cd6ee30f41e5f507d8213ec2df9d0e607089",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of the nonparametric estimation of a probability distribution is considered from three viewpoints: the consistency in total variation, the consistency in information divergence, and consistency in reversed-order information divergence. These types of consistencies are relatively strong criteria of convergence, and a probability distribution cannot be consistently estimated in either type of convergence without any restrictions on the class of probability distributions allowed. Histogram-based estimators of distribution are presented which, under certain conditions, converge in total variation, in information divergence, and in reversed-order information divergence to the unknown probability distribution. Some a priori information about the true probability distribution is assumed in each case. As the concept of consistency in information divergence is stronger than that of convergence in total variation, additional assumptions are imposed in the cases of informational divergences. >"
            },
            "slug": "Distribution-estimation-consistent-in-total-and-in-Barron-Gy\u00f6rfi",
            "title": {
                "fragments": [],
                "text": "Distribution estimation consistent in total variation and in two types of information divergence"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "Histogram-based estimators of distribution are presented which, under certain conditions, converge in total variation, in information divergence, and in reversed-order information divergence to the unknown probability distribution."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6324626"
                        ],
                        "name": "P. Lachenbruch",
                        "slug": "P.-Lachenbruch",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Lachenbruch",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lachenbruch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6402394"
                        ],
                        "name": "M. R. Mickey",
                        "slug": "M.-R.-Mickey",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Mickey",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. R. Mickey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122840922,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3baebcdba313a1a52533fb5c43987169c0c3b5a4",
            "isKey": false,
            "numCitedBy": 1493,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Several methods of estimating error rates in Discriminant Analysis are evaluated by sampling methods. Multivariate normal samples are generated on a computer which have various true probabilities of misclassification for different combinations of sample sizes and different numbers of parameters. The two methods in most common use are found to be significantly poorer than some new methods that are proposed."
            },
            "slug": "Estimation-of-Error-Rates-in-Discriminant-Analysis-Lachenbruch-Mickey",
            "title": {
                "fragments": [],
                "text": "Estimation of Error Rates in Discriminant Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102627379"
                        ],
                        "name": "L. Gyorfi",
                        "slug": "L.-Gyorfi",
                        "structuredName": {
                            "firstName": "L'aszl'o",
                            "lastName": "Gyorfi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gyorfi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 203670245,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f17a61d39c0582fe17007c771cc33c7b69b10ed",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "An erroneous method for maximizing the projected divergence between two Gaussian multivariate hypotheses appeared in a recent paper. The correct solution is given."
            },
            "slug": "On-the-rate-of-convergence-of-nearest-neighbor-Gyorfi",
            "title": {
                "fragments": [],
                "text": "On the rate of convergence of nearest neighbor rules (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An erroneous method for maximizing the projected divergence between two Gaussian multivariate hypotheses appeared in a recent paper and the correct solution is given."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809954"
                        ],
                        "name": "I. J. Taneja",
                        "slug": "I.-J.-Taneja",
                        "structuredName": {
                            "firstName": "Inder",
                            "lastName": "Taneja",
                            "middleNames": [
                                "Jeet"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. J. Taneja"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120301998,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6aa2ddbb5fb33a44e8cc5e68204821b4de619acb",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "STATISTICAL-ASPECTS-OF-DIVERGENCE-MEASURES-Taneja",
            "title": {
                "fragments": [],
                "text": "STATISTICAL ASPECTS OF DIVERGENCE MEASURES"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122176916,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2735273b5cfb02774b120f34b097179164944a36",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "THEOREM 1. Let K be a nonnegative Borel measurable function on Rd with f K(x) dx = 1. Then the following conditions are equivalent: (i) J -* 0 in probability as n -oo, some f; (ii) Jn -O 0 in probability as n -s oo, all f; (iii) Jn -s 0 almost surely as n -* oo, all f; (iv) Jn --* 0 exponentially as n -> oc (i.e. for all E > 0, there exist r, no > 0 such that P(JnE) no), all f; (v) lim0h = 0 and limnnhd = oo. Also, (v) implies (iv) when K is merely absolutely integrable and f K(x) dx = 1. 0"
            },
            "slug": "The-Equivalence-of-Weak,-Strong-and-Complete-in-for-Devroye",
            "title": {
                "fragments": [],
                "text": "The Equivalence of Weak, Strong and Complete Convergence in $L_1$ for Kernel Density Estimates"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16298171"
                        ],
                        "name": "D. Gabor",
                        "slug": "D.-Gabor",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Gabor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gabor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403509947"
                        ],
                        "name": "W. Wildes",
                        "slug": "W.-Wildes",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Wildes",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wildes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46363985"
                        ],
                        "name": "R. Woodcock",
                        "slug": "R.-Woodcock",
                        "structuredName": {
                            "firstName": "R",
                            "lastName": "Woodcock",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Woodcock"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60050025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c88cd9075eac2ae6e93c2be08487ec2d040cd63",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "A machine is described consisting of a universal non-linear filter, which is a highly adaptable analogue computer, together with a training device. The analogue machine has 18 input quantities from which it can compute in about 2 millisec 94 terms of a polynomial, each term containing products and powers of the input quantities, with adjustable coefficients, and can form their sum. The input quantities may be, for instance, 18 past samples of the values of a stochastic variable which is fed into the machine, and the result of the computation is an output function which contains 94 free variables. The training device optimizes the output by successive adjustment of the variable coefficients, until it has approached a target function as closely as can be achieved with a polynomial of 94 terms, by the criterion of the least mean-square error. This is done by repeatedly feeding into the machine a record of the stochastic process, long enough to be representative, and adjusting the variable coefficients, one at a time after each run, by a strategy which ensures that the error will monotonically decrease from run to run.In order to make the machine an optimum filter it is trained on a record of a noisy process, together with a target record which contains the signal only. It is taught as a predictor by taking as the target function a value of the stochastic process advanced by a certain time interval beyond the last value which goes into the input. It is trained as a simulator, for instance of an unknown mechanism, by feeding it with the input of the mechanism to be simulated at one end and presenting it at the other with its output as target function. The machine will then make itself into a model of the device to be simulated and the non-linear transfer function of the device can be read off from the final setting of the coefficients, as nearly as it can be represented by a 94-term polynomial. The machine is not confined to single-input systems.The machine incorporates 80 analogue multipliers of a novel \u2018piezomagnetic\u2019 type which, in its present form, can perform over 1000 multiplications per second with an error of 0.5% or less.A few examples of the first test applications of the machine are described."
            },
            "slug": "A-universal-nonlinear-filter,-predictor-and-which-a-Gabor-Wildes",
            "title": {
                "fragments": [],
                "text": "A universal nonlinear filter, predictor and simulator which optimizes itself by a learning process"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A machine is described consisting of a universal non-linear filter, which is a highly adaptable analogue computer, together with a training device, which incorporates 80 analogue multipliers of a novel \u2018piezomagnetic\u2019 type which, in its present form, can perform over 1000 multiplications per second with an error of 0.5% or less."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70416525"
                        ],
                        "name": "W. Hoeffding",
                        "slug": "W.-Hoeffding",
                        "structuredName": {
                            "firstName": "Wassily",
                            "lastName": "Hoeffding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hoeffding"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 121341745,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1c74180188a592d20a63cedb45d53089201fe127",
            "isKey": false,
            "numCitedBy": 8037,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Upper bounds are derived for the probability that the sum S of n independent random variables exceeds its mean ES by a positive number nt. It is assumed that the range of each summand of S is bounded or bounded above. The bounds for Pr {S \u2013 ES \u2265 nt} depend only on the endpoints of the ranges of the summands and the mean, or the mean and the variance of S. These results are then used to obtain analogous inequalities for certain sums of dependent random variables such as U statistics and the sum of a random sample without replacement from a finite population."
            },
            "slug": "Probability-inequalities-for-sum-of-bounded-random-Hoeffding",
            "title": {
                "fragments": [],
                "text": "Probability inequalities for sum of bounded random variables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50456127"
                        ],
                        "name": "I. J. Schoenberg",
                        "slug": "I.-J.-Schoenberg",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Schoenberg",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. J. Schoenberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 115315068,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1669e5ceb32b8e48d90212d4bbe5260c116c9fbe",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A real matrix A=\u2225a ik \u2225 (i=1, m; k= 1,..., n) is said to be totally positive if all its minors, of any order, are non-negative. In 19302) the author showed that if A is totally positive, then the linear transformation \n \n$$ {y_i} = \\sum\\limits_{k = 1}^n {{a_{ik}}{x_k}} \\quad \\left( {i = 1, \\ldots ,m} \\right) $$ \n \n(1) \n \nis variation-diminishing in the sense that if v(x k ) denotes the number of variations of sign in the sequence x k and v(y i ) the corresponding number in the sequence y i , then we always have the inequality v(y i ) \u2266v(x k ). In the same paper of 1930 the author showed that (1) is certainly variationdiminishing if the matrix A does not possess two minors of equal orders and of opposite signs; also the converse holds to a certain extent: If (1) is variation-diminishing, then A cannot have two minors of equal orders and of opposite signs, provided the rank of A is = n. The necessary and sufficient conditions in order that (1) be variation-diminishing were found in 1933 by Th. Motzkin 3). Since they will be used in this paper we state them here as follows: Let r be the rank of A then A should not have two minors of equal orders and of opposite signs if their common order is < r, while if their common order is = r then again they should never be of opposite signs if they belong to the same combination of r columns of A."
            },
            "slug": "On-P\u00f3lya-frequency-functions.-II:-integral-of-the-Schoenberg",
            "title": {
                "fragments": [],
                "text": "On P\u00f3lya frequency functions. II: Variation-diminishing integral operators of the convolution type"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3239270"
                        ],
                        "name": "W. Hashlamoun",
                        "slug": "W.-Hashlamoun",
                        "structuredName": {
                            "firstName": "Wael",
                            "lastName": "Hashlamoun",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hashlamoun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925309"
                        ],
                        "name": "P. Varshney",
                        "slug": "P.-Varshney",
                        "structuredName": {
                            "firstName": "Pramod",
                            "lastName": "Varshney",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Varshney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1852324"
                        ],
                        "name": "V. Samarasooriya",
                        "slug": "V.-Samarasooriya",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Samarasooriya",
                            "middleNames": [
                                "N.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Samarasooriya"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45883716,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "e950eb18f61bdf5022288b29272a2e2dd4053b75",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a new upper bound on the minimum probability of error of Bayesian decision systems for statistical pattern recognition. This new bound is continuous everywhere and is shown to be tighter than several existing bounds such as the Bhattacharyya and the Bayesian bounds. Numerical results are also presented. >"
            },
            "slug": "A-Tight-Upper-Bound-on-the-Bayesian-Probability-of-Hashlamoun-Varshney",
            "title": {
                "fragments": [],
                "text": "A Tight Upper Bound on the Bayesian Probability of Error"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This new upper bound on the minimum probability of error of Bayesian decision systems for statistical pattern recognition is shown to be tighter than several existing bounds such as the Bhattacharyya and the Bayesian bounds."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764952"
                        ],
                        "name": "K. Hornik",
                        "slug": "K.-Hornik",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Hornik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hornik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1232663,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7366c49b20da27233599544cda01e44e80d51593",
            "isKey": false,
            "numCitedBy": 496,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Some-new-results-on-neural-network-approximation-Hornik",
            "title": {
                "fragments": [],
                "text": "Some new results on neural network approximation"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057698717"
                        ],
                        "name": "Wen-Shou Chou",
                        "slug": "Wen-Shou-Chou",
                        "structuredName": {
                            "firstName": "Wen-Shou",
                            "lastName": "Chou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen-Shou Chou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103218849"
                        ],
                        "name": "Yung-Chang Chen",
                        "slug": "Yung-Chang-Chen",
                        "structuredName": {
                            "firstName": "Yung-Chang",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yung-Chang Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37226177,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d0f9caf365443622885300ae7e5a8f0d2a1745a",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-new-fast-algorithm-for-effective-training-of-Chou-Chen",
            "title": {
                "fragments": [],
                "text": "A new fast algorithm for effective training of neural classifiers"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2173152186"
                        ],
                        "name": "D. Moore",
                        "slug": "D.-Moore",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Moore",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3026266"
                        ],
                        "name": "S. J. Whitsitt",
                        "slug": "S.-J.-Whitsitt",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Whitsitt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. J. Whitsitt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773449"
                        ],
                        "name": "D. Landgrebe",
                        "slug": "D.-Landgrebe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Landgrebe",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Landgrebe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 3945973,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c48945266459c7430aed6287f10875b466727c04",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Variance relationships among certain count estimators and posterior probability estimators of probability of correct classification are investigated. An estimator using posterior probabilities is presented for use in stratified sampling designs. A test case involving three normal classes is examined."
            },
            "slug": "Variance-comparisons-for-unbiased-estimators-of-of-Moore-Whitsitt",
            "title": {
                "fragments": [],
                "text": "Variance comparisons for unbiased estimators of probability of correct classification (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An estimator using posterior probabilities is presented for use in stratified sampling designs and a test case involving three normal classes is examined."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90661057"
                        ],
                        "name": "L. Gordon",
                        "slug": "L.-Gordon",
                        "structuredName": {
                            "firstName": "Louis",
                            "lastName": "Gordon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gordon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378652"
                        ],
                        "name": "R. Olshen",
                        "slug": "R.-Olshen",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Olshen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Olshen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120477553,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "536633929701fc2f74466cebbee97899b78e1fab",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Consistent-nonparametric-regression-from-recursive-Gordon-Olshen",
            "title": {
                "fragments": [],
                "text": "Consistent nonparametric regression from recursive partitioning schemes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785855"
                        ],
                        "name": "W. Greblicki",
                        "slug": "W.-Greblicki",
                        "structuredName": {
                            "firstName": "W\u0142odzimierz",
                            "lastName": "Greblicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Greblicki"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6764265,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "629031d379635b14d1b17bc6a6cbddcc3e8ce2ef",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The asymptotic optimality of pattern recognition procedures derived from pointwise consistent density estimates is established."
            },
            "slug": "Asymptotically-optimal-pattern-recognition-with-Greblicki",
            "title": {
                "fragments": [],
                "text": "Asymptotically optimal pattern recognition procedures with density estimates (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The asymptotic optimality of pattern recognition procedures derived from pointwise consistent density estimates is established."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911738"
                        ],
                        "name": "D. Angluin",
                        "slug": "D.-Angluin",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Angluin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Angluin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 1279641,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c92795deeea3f6765e7b5e593f4f31ffb634ed76",
            "isKey": false,
            "numCitedBy": 666,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The main purpose of this paper is to give techniques for analysing the probabilistic performance of certain kinds of algorithms, and hence to suggest some fast algorithms with provably desirable probabilistic behaviour. The particular problems we consider are: finding Hamiltonian circuits in directed graphs (DHC), finding Hamiltonian circuits in undirected graphs (UHC), and finding perfect matchings in undirected graphs (PM). We show that for each problem there is an algorithm that is extremely fast (0(n(log n)2) for DHC and UHC, and 0(nlog n) for PM), and which with probability tending to one finds a solution in randomly chosen graphs of sufficient density. These results contrast with the known NP-completeness of the first two problems [2,12] and the best worst-case upper bound known of 0(n2.5) for the last [9]."
            },
            "slug": "Fast-probabilistic-algorithms-for-hamiltonian-and-Angluin-Valiant",
            "title": {
                "fragments": [],
                "text": "Fast probabilistic algorithms for hamiltonian circuits and matchings"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that for each problem there is an algorithm that is extremely fast, and which with probability tending to one finds a solution in randomly chosen graphs of sufficient density, and the results contrast with the known NP-completeness of the first two problems."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '77"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25030625"
                        ],
                        "name": "J. Max",
                        "slug": "J.-Max",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Max",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Max"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10960406,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "466d6ecaca726323d0ba2e9a41e9c255ba328e89",
            "isKey": false,
            "numCitedBy": 1988,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses the problem of the minimization of the distortion of a signal by a quantizer when the number of output levels of the quantizer is fixed. The distortion is defined as the expected value of some function of the error between the input and the output of the quantizer. Equations are derived for the parameters of a quantizer with minimum distortion. The equations are not soluble without recourse to numerical methods, so an algorithm is developed to simplify their numerical solution. The case of an input signal with normally distributed amplitude and an expected squared error distortion measure is explicitly computed and values of the optimum quantizer parameters are tabulated. The optimization of a quantizer subject to the restriction that both input and output levels be equally spaced is also treated, and appropriate parameters are tabulated for the same case as above."
            },
            "slug": "Quantizing-for-minimum-distortion-Max",
            "title": {
                "fragments": [],
                "text": "Quantizing for minimum distortion"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "This paper discusses the problem of the minimization of the distortion of a signal by a quantizer when the number of output levels of the quantizer is fixed and an algorithm is developed to simplify their numerical solution."
            },
            "venue": {
                "fragments": [],
                "text": "IRE Trans. Inf. Theory"
            },
            "year": 1960
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101639166"
                        ],
                        "name": "S. P. Lloyd",
                        "slug": "S.-P.-Lloyd",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Lloyd",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. P. Lloyd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10833328,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9241ea3d8cb85633d314ecb74b31567b8e73f6af",
            "isKey": false,
            "numCitedBy": 11645,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likely to fall. It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes. In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy. The optimization criterion used is that the average quantization noise power be a minimum. It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large. The optimum quautization schemes for 2^{b} quanta, b=1,2, \\cdots, 7 , are given numerically for Gaussian and for Laplacian distribution of signal amplitudes."
            },
            "slug": "Least-squares-quantization-in-PCM-Lloyd",
            "title": {
                "fragments": [],
                "text": "Least squares quantization in PCM"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684300"
                        ],
                        "name": "W. Stuetzle",
                        "slug": "W.-Stuetzle",
                        "structuredName": {
                            "firstName": "Werner",
                            "lastName": "Stuetzle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Stuetzle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14183758,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "589b8659007e1124f765a5d1bd940b2bf4d79054",
            "isKey": false,
            "numCitedBy": 2178,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A new method for nonparametric multiple regression is presented. The procedure models the regression surface as a sum of general smooth functions of linear combinations of the predictor variables in an iterative manner. It is more general than standard stepwise and stagewise regression procedures, does not require the definition of a metric in the predictor space, and lends itself to graphical interpretation."
            },
            "slug": "Projection-Pursuit-Regression-Friedman-Stuetzle",
            "title": {
                "fragments": [],
                "text": "Projection Pursuit Regression"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145231918"
                        ],
                        "name": "E. M. Rounds",
                        "slug": "E.-M.-Rounds",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Rounds",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. M. Rounds"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11059508,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0945b9ee1712dfed28b74b4aa81b970fd14941fd",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-combined-nonparametric-approach-to-feature-and-Rounds",
            "title": {
                "fragments": [],
                "text": "A combined nonparametric approach to feature selection and binary decision tree design"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5634448,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "bdbb4153852303873f978183836db172575d3cf7",
            "isKey": false,
            "numCitedBy": 213,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Let (X, Y), (X1, Y1), .\u2022, (X,, Yn ) be independent identically distributed random vectors from R dxR, and let E(I Y 1 p) < oo for some p > 1 . We wish to estimate the regression function m(x) = E(Y I X = x) by mn(x), a function of x and (X1 , Y1), .\u2022, (X,, Yn ) . For large classes of kernel estimates and nearest neighbor estimates, sufficient conditions are given for E { l m(x) m(x) 0 ) -* 0 as n -* oo, almost all x . No additional conditions are imposed on the distribution of (X, Y) . As a by-product, just assuming the boundedness of Y, the almost sure convergence to O of E { I m(X) m (X) I I Xl , Yl, \u2022 \u2022 \u2022 , X,, Yn } is established for the same estimates. Finally, the weak and strong Bayes risk consistency of the corresponding nonparametric discrimination rules is proved for all possible distributions of the data ."
            },
            "slug": "On-the-Almost-Everywhere-Convergence-of-Regression-Devroye",
            "title": {
                "fragments": [],
                "text": "On the Almost Everywhere Convergence of Nonparametric Regression Function Estimates"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2270210"
                        ],
                        "name": "R. S. Wenocur",
                        "slug": "R.-S.-Wenocur",
                        "structuredName": {
                            "firstName": "Roberta",
                            "lastName": "Wenocur",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. S. Wenocur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881615"
                        ],
                        "name": "R. Dudley",
                        "slug": "R.-Dudley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dudley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dudley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 204985985,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5e6dfb46ed298ff037e166291c128a465f90bfc0",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Some-special-vapnik-chervonenkis-classes-Wenocur-Dudley",
            "title": {
                "fragments": [],
                "text": "Some special vapnik-chervonenkis classes"
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Math."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2647026"
                        ],
                        "name": "A. Blumer",
                        "slug": "A.-Blumer",
                        "structuredName": {
                            "firstName": "Anselm",
                            "lastName": "Blumer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blumer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683946"
                        ],
                        "name": "A. Ehrenfeucht",
                        "slug": "A.-Ehrenfeucht",
                        "structuredName": {
                            "firstName": "Andrzej",
                            "lastName": "Ehrenfeucht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ehrenfeucht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1138467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0b8fa3496283d4d808fba9ff62d5f024bcf23be",
            "isKey": false,
            "numCitedBy": 1909,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Valiant's learnability model is extended to learning classes of concepts defined by regions in Euclidean space En. The methods in this paper lead to a unified treatment of some of Valiant's results, along with previous results on distribution-free convergence of certain pattern recognition algorithms. It is shown that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned. Using this parameter, the complexity and closure properties of learnable classes are analyzed, and the necessary and sufficient conditions are provided for feasible learnability."
            },
            "slug": "Learnability-and-the-Vapnik-Chervonenkis-dimension-Blumer-Ehrenfeucht",
            "title": {
                "fragments": [],
                "text": "Learnability and the Vapnik-Chervonenkis dimension"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144420921"
                        ],
                        "name": "M. Rosenblatt",
                        "slug": "M.-Rosenblatt",
                        "structuredName": {
                            "firstName": "Murray",
                            "lastName": "Rosenblatt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rosenblatt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16643156,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2c455f0da2bd86a9b9ea432d1485049073d7c63d",
            "isKey": false,
            "numCitedBy": 3833,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Summary. This note discusses some aspects of the estimation of the density function of a univariate probability distribution. All estimates of the density function satisfying relatively mild conditions are shown to be biased. The asymp\u00ad totic mean square error of a particular class of estimates is evaluated."
            },
            "slug": "Remarks-on-Some-Nonparametric-Estimates-of-a-Rosenblatt",
            "title": {
                "fragments": [],
                "text": "Remarks on Some Nonparametric Estimates of a Density Function"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1956
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698850"
                        ],
                        "name": "N. Matloff",
                        "slug": "N.-Matloff",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Matloff",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Matloff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153879019"
                        ],
                        "name": "Ronald Pruitt",
                        "slug": "Ronald-Pruitt",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Pruitt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald Pruitt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42363825,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "30ac4d6092bb608df69f43bf30d6f581156c4070",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-asymptotic-distribution-of-an-estimator-of-the-Matloff-Pruitt",
            "title": {
                "fragments": [],
                "text": "The asymptotic distribution of an estimator of the Bayes error rate"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144117841"
                        ],
                        "name": "A. Gallant",
                        "slug": "A.-Gallant",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Gallant",
                            "middleNames": [
                                "Ronald"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gallant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 27938565,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "877ede912fbbfb34fbc96169f43b142b7d54bf22",
            "isKey": false,
            "numCitedBy": 1179,
            "numCiting": 178,
            "paperAbstract": {
                "fragments": [],
                "text": "Univariate Nonlinear Regression. Univariate Nonlinear Regression: Special Situations. A Unified Asymptotic Theory for Nonlinear Models with Regression Structure. Univariate Nonlinear Regression: Asymptotic Theory. Multivariate Nonlinear Regression. Nonlinear Simultaneous Equations Models. A Unified Asymptotic Theory for Dynamic Nonlinear Models. References. Index."
            },
            "slug": "Nonlinear-Statistical-Models-Gallant",
            "title": {
                "fragments": [],
                "text": "Nonlinear Statistical Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2135764"
                        ],
                        "name": "A. Kolmogorov",
                        "slug": "A.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Andrei",
                            "lastName": "Kolmogorov",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kolmogorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "100859010"
                        ],
                        "name": "V. Tikhomirov",
                        "slug": "V.-Tikhomirov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Tikhomirov",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Tikhomirov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121117171,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b21b75140076a263f25d017fe24dd13f5a6a131e",
            "isKey": false,
            "numCitedBy": 756,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The article is mainly devoted to the systematic exposition of results that were published in the years 1954\u20131958 by K. I. Babenko [1], A. G. Vitushkin [2,3], V. D. Yerokhin [4], A. N. Kolmogorov [5,6] and V. M. Tikhomirov [7]. It is natural that when these materials were systematically rewritten, several new theorems were proved and certain examples were computed in more detail. This review also incorporates results not published previously which go beyond the framework of such a systematization, and belong to V. I. Arnold (\u00a76) and V. M. Tikhomirov (\u00a7\u00a74,7 and \u00a78)."
            },
            "slug": "Entropy-and-\"-capacity-of-sets-in-func-tional-Kolmogorov-Tikhomirov",
            "title": {
                "fragments": [],
                "text": "Entropy and \"-capacity of sets in func-tional spaces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 222292199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10055eb6f2f711a36d9aa8f759d3b3f01ebddb5d",
            "isKey": false,
            "numCitedBy": 6561,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Various Aspects of Memory.- 1.1 On the Purpose and Nature of Biological Memory.- 1.1.1 Some Fundamental Concepts.- 1.1.2 The Classical Laws of Association.- 1.1.3 On Different Levels of Modelling.- 1.2 Questions Concerning the Fundamental Mechanisms of Memory.- 1.2.1 Where Do the Signals Relating to Memory Act Upon?.- 1.2.2 What Kind of Encoding is Used for Neural Signals?.- 1.2.3 What are the Variable Memory Elements?.- 1.2.4 How are Neural Signals Addressed in Memory?.- 1.3 Elementary Operations Implemented by Associative Memory.- 1.3.1 Associative Recall.- 1.3.2 Production of Sequences from the Associative Memory.- 1.3.3 On the Meaning of Background and Context.- 1.4 More Abstract Aspects of Memory.- 1.4.1 The Problem of Infinite-State Memory.- 1.4.2 Invariant Representations.- 1.4.3 Symbolic Representations.- 1.4.4 Virtual Images.- 1.4.5 The Logic of Stored Knowledge.- 2. Pattern Mathematics.- 2.1 Mathematical Notations and Methods.- 2.1.1 Vector Space Concepts.- 2.1.2 Matrix Notations.- 2.1.3 Further Properties of Matrices.- 2.1.4 Matrix Equations.- 2.1.5 Projection Operators.- 2.1.6 On Matrix Differential Calculus.- 2.2 Distance Measures for Patterns.- 2.2.1 Measures of Similarity and Distance in Vector Spaces.- 2.2.2 Measures of Similarity and Distance Between Symbol Strings.- 2.2.3 More Accurate Distance Measures for Text.- 3. Classical Learning Systems.- 3.1 The Adaptive Linear Element (Adaline).- 3.1.1 Description of Adaptation by the Stochastic Approximation.- 3.2 The Perceptron.- 3.3 The Learning Matrix.- 3.4 Physical Realization of Adaptive Weights.- 3.4.1 Perceptron and Adaline.- 3.4.2 Classical Conditioning.- 3.4.3 Conjunction Learning Switches.- 3.4.4 Digital Representation of Adaptive Circuits.- 3.4.5 Biological Components.- 4. A New Approach to Adaptive Filters.- 4.1 Survey of Some Necessary Functions.- 4.2 On the \"Transfer Function\" of the Neuron.- 4.3 Models for Basic Adaptive Units.- 4.3.1 On the Linearization of the Basic Unit.- 4.3.2 Various Cases of Adaptation Laws.- 4.3.3 Two Limit Theorems.- 4.3.4 The Novelty Detector.- 4.4 Adaptive Feedback Networks.- 4.4.1 The Autocorrelation Matrix Memory.- 4.4.2 The Novelty Filter.- 5. Self-Organizing Feature Maps.- 5.1 On the Feature Maps of the Brain.- 5.2 Formation of Localized Responses by Lateral Feedback.- 5.3 Computational Simplification of the Process.- 5.3.1 Definition of the Topology-Preserving Mapping.- 5.3.2 A Simple Two-Dimensional Self-Organizing System.- 5.4 Demonstrations of Simple Topology-Preserving Mappings.- 5.4.1 Images of Various Distributions of Input Vectors.- 5.4.2 \"The Magic TV\".- 5.4.3 Mapping by a Feeler Mechanism.- 5.5 Tonotopic Map.- 5.6 Formation of Hierarchical Representations.- 5.6.1 Taxonomy Example.- 5.6.2 Phoneme Map.- 5.7 Mathematical Treatment of Self-Organization.- 5.7.1 Ordering of Weights.- 5.7.2 Convergence Phase.- 5.8 Automatic Selection of Feature Dimensions.- 6. Optimal Associative Mappings.- 6.1 Transfer Function of an Associative Network.- 6.2 Autoassociative Recall as an Orthogonal Projection.- 6.2.1 Orthogonal Projections.- 6.2.2 Error-Correcting Properties of Projections.- 6.3 The Novelty Filter.- 6.3.1 Two Examples of Novelty Filter.- 6.3.2 Novelty Filter as an Autoassociative Memory.- 6.4 Autoassociative Encoding.- 6.4.1 An Example of Autoassociative Encoding.- 6.5 Optimal Associative Mappings.- 6.5.1 The Optimal Linear Associative Mapping.- 6.5.2 Optimal Nonlinear Associative Mappings.- 6.6 Relationship Between Associative Mapping, Linear Regression, and Linear Estimation.- 6.6.1 Relationship of the Associative Mapping to Linear Regression.- 6.6.2 Relationship of the Regression Solution to the Linear Estimator.- 6.7 Recursive Computation of the Optimal Associative Mapping.- 6.7.1 Linear Corrective Algorithms.- 6.7.2 Best Exact Solution (Gradient Projection).- 6.7.3 Best Approximate Solution (Regression).- 6.7.4 Recursive Solution in the General Case.- 6.8 Special Cases.- 6.8.1 The Correlation Matrix Memory.- 6.8.2 Relationship Between Conditional Averages and Optimal Estimator.- 7. Pattern Recognition.- 7.1 Discriminant Functions.- 7.2 Statistical Formulation of Pattern Classification.- 7.3 Comparison Methods.- 7.4 The Subspace Methods of Classification.- 7.4.1 The Basic Subspace Method.- 7.4.2 The Learning Subspace Method (LSM).- 7.5 Learning Vector Quantization.- 7.6 Feature Extraction.- 7.7 Clustering.- 7.7.1 Simple Clustering (Optimization Approach).- 7.7.2 Hierarchical Clustering (Taxonomy Approach).- 7.8 Structural Pattern Recognition Methods.- 8. More About Biological Memory.- 8.1 Physiological Foundations of Memory.- 8.1.1 On the Mechanisms of Memory in Biological Systems.- 8.1.2 Structural Features of Some Neural Networks.- 8.1.3 Functional Features of Neurons.- 8.1.4 Modelling of the Synaptic Plasticity.- 8.1.5 Can the Memory Capacity Ensue from Synaptic Changes?.- 8.2 The Unified Cortical Memory Model.- 8.2.1 The Laminar Network Organization.- 8.2.2 On the Roles of Interneurons.- 8.2.3 Representation of Knowledge Over Memory Fields.- 8.2.4 Self-Controlled Operation of Memory.- 8.3 Collateral Reading.- 8.3.1 Physiological Results Relevant to Modelling.- 8.3.2 Related Modelling.- 9. Notes on Neural Computing.- 9.1 First Theoretical Views of Neural Networks.- 9.2 Motives for the Neural Computing Research.- 9.3 What Could the Purpose of the Neural Networks be?.- 9.4 Definitions of Artificial \"Neural Computing\" and General Notes on Neural Modelling.- 9.5 Are the Biological Neural Functions Localized or Distributed?.- 9.6 Is Nonlinearity Essential to Neural Computing?.- 9.7 Characteristic Differences Between Neural and Digital Computers.- 9.7.1 The Degree of Parallelism of the Neural Networks is Still Higher than that of any \"Massively Parallel\" Digital Computer.- 9.7.2 Why the Neural Signals Cannot be Approximated by Boolean Variables.- 9.7.3 The Neural Circuits do not Implement Finite Automata.- 9.7.4 Undue Views of the Logic Equivalence of the Brain and Computers on a High Level.- 9.8 \"Connectionist Models\".- 9.9 How can the Neural Computers be Programmed?.- 10. Optical Associative Memories.- 10.1 Nonholographic Methods.- 10.2 General Aspects of Holographic Memories.- 10.3 A Simple Principle of Holographic Associative Memory.- 10.4 Addressing in Holographic Memories.- 10.5 Recent Advances of Optical Associative Memories.- Bibliography on Pattern Recognition.- References."
            },
            "slug": "Self-Organization-and-Associative-Memory-Kohonen",
            "title": {
                "fragments": [],
                "text": "Self-Organization and Associative Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The purpose and nature of Biological Memory, as well as some of the aspects of Memory Aspects, are explained."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49794603"
                        ],
                        "name": "X. Chen",
                        "slug": "X.-Chen",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Chen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158092105"
                        ],
                        "name": "L. Zhao",
                        "slug": "L.-Zhao",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Zhao",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Zhao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121630872,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7c5f9b0846da75d992a84465b4677f701958b05e",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Almost-sure-L-1-norm-convergence-for-data-based-Chen-Zhao",
            "title": {
                "fragments": [],
                "text": "Almost sure L 1 -norm convergence for data-based histogram density estimates"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144492106"
                        ],
                        "name": "V. K\u016frkov\u00e1",
                        "slug": "V.-K\u016frkov\u00e1",
                        "structuredName": {
                            "firstName": "V\u011bra",
                            "lastName": "K\u016frkov\u00e1",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. K\u016frkov\u00e1"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5748809,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "82566f380f61e835292e483cda84eb3d22e32cd4",
            "isKey": false,
            "numCitedBy": 643,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Kolmogorov's-theorem-and-multilayer-neural-networks-K\u016frkov\u00e1",
            "title": {
                "fragments": [],
                "text": "Kolmogorov's theorem and multilayer neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8995695,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7f9014eb1a484eb5b059d9708325017a9814a2b4",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Bounds-for-the-Uniform-Deviation-of-Empirical-Devroye",
            "title": {
                "fragments": [],
                "text": "Bounds for the Uniform Deviation of Empirical Measures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1834116"
                        ],
                        "name": "F. Baskett",
                        "slug": "F.-Baskett",
                        "structuredName": {
                            "firstName": "Forest",
                            "lastName": "Baskett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Baskett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142925"
                        ],
                        "name": "L. J. Shustek",
                        "slug": "L.-J.-Shustek",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Shustek",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. J. Shustek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4574636,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "d6656edc4271a301ae7420ef07d9690be6762567",
            "isKey": false,
            "numCitedBy": 426,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm that finds the k nearest neighbors of a point, from a sample of size N in a d-dimensional space, with an expected number of distance calculations is described, its properties examined, and the validity of the estimate verified with simulated data."
            },
            "slug": "An-Algorithm-for-Finding-Nearest-Neighbors-Friedman-Baskett",
            "title": {
                "fragments": [],
                "text": "An Algorithm for Finding Nearest Neighbors"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An algorithm that finds the k nearest neighbors of a point, from a sample of size N in a d-dimensional space, with an expected number of distance calculations is described, its properties examined, and the validity of the estimate verified with simulated data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1899177"
                        ],
                        "name": "Ken-ichi Funahashi",
                        "slug": "Ken-ichi-Funahashi",
                        "structuredName": {
                            "firstName": "Ken-ichi",
                            "lastName": "Funahashi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ken-ichi Funahashi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10203109,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "386cbc45ceb59a7abb844b5078e5c944f17723b4",
            "isKey": false,
            "numCitedBy": 4188,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-approximate-realization-of-continuous-by-Funahashi",
            "title": {
                "fragments": [],
                "text": "On the approximate realization of continuous mappings by neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145247053"
                        ],
                        "name": "W. Maass",
                        "slug": "W.-Maass",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Maass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Maass"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11924538,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c60f3ee93b489d1b85ea2de2571a7f4b4cc6ecfa",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "It has been known for quite a while that the Vapnik-Chervonenkis dimension (VC-dimension) of a feedforward neural net with linear threshold gates is at most O(w log w), where w is the total number of weights in the neural net. We show in this paper that this bound is in fact asymptotically optimal. More precisely, we exhibit for any depth d 3 a large class of feedforward neural nets of depth d with w weights that have VC-dimension (w log w). This lower bound holds even if the inputs are restricted to Boolean values. The proof of this result relies on a new method that allows us to encode more program-bits in the weights of a neural net than previously thought possible."
            },
            "slug": "Neural-Nets-with-Superlinear-VC-Dimension-Maass",
            "title": {
                "fragments": [],
                "text": "Neural Nets with Superlinear VC-Dimension"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper exhibits for any depth d 3 a large class of feedforward neural nets of depth d with w weights that have VC-dimension (w log w), and shows that this lower bound holds even if the inputs are restricted to Boolean values."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3129654"
                        ],
                        "name": "S. Raudys",
                        "slug": "S.-Raudys",
                        "structuredName": {
                            "firstName": "Sarunas",
                            "lastName": "Raudys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Raudys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2335089"
                        ],
                        "name": "Vitalijus Pikelis",
                        "slug": "Vitalijus-Pikelis",
                        "structuredName": {
                            "firstName": "Vitalijus",
                            "lastName": "Pikelis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vitalijus Pikelis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 715333,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "id": "d3dd71de00ae318e1d8c033a12b3d5f32dd9a311",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Collective-selection-of-the-best-version-of-a-Raudys-Pikelis",
            "title": {
                "fragments": [],
                "text": "Collective selection of the best version of a pattern recognition system"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8142232,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a36b028d024bf358c4af1a5e1dc3ca0aed23b553",
            "isKey": false,
            "numCitedBy": 3710,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter reproduces the English translation by B. Seckler of the paper by Vapnik and Chervonenkis in which they gave proofs for the innovative results they had obtained in a draft form in July 1966 and announced in 1968 in their note in Soviet Mathematics Doklady. The paper was first published in Russian as \u0412\u0430\u043f\u043d\u0438\u043a \u0412. \u041d. and \u0427\u0435\u0440\u0432\u043e\u043d\u0435\u043d\u043a\u0438\u0441 \u0410. \u042f. \u041e \u0440\u0430\u0432\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0419 \u0441\u0445\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438 \u0447\u0430\u0441\u0442\u043e\u0442 \u043f\u043e\u044f\u0432\u043b\u0435\u043d\u0438\u044f \u0441\u043e\u0431\u044b\u0442\u0438\u0419 \u043a \u0438\u0445 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044f\u043c. \u0422\u0435\u043e\u0440\u0438\u044f \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0435\u0419 \u0438 \u0435\u0435 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u044f 16(2), 264\u2013279 (1971)."
            },
            "slug": "Chervonenkis:-On-the-uniform-convergence-of-of-to-Vapnik",
            "title": {
                "fragments": [],
                "text": "Chervonenkis: On the uniform convergence of relative frequencies of events to their probabilities"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter reproduces the English translation by B. Seckler of the paper by Vapnik and Chervonenkis in which they gave proofs for the innovative results they had obtained in a draft form in July 1966 and announced in 1968 in their note in Soviet Mathematics Doklady."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "100859010"
                        ],
                        "name": "V. Tikhomirov",
                        "slug": "V.-Tikhomirov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Tikhomirov",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Tikhomirov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116968444,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "300328d09233d3ada652d6aace66353c3bdb5762",
            "isKey": false,
            "numCitedBy": 410,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The aim of this paper is to present a brief proof of the following theorem: Theorem. For any integer n \u2265 2 there are continuous real functions \u03c8 p q (x) on the closed unit interval E 1 = [0;1] such that each continuous real function f(x 1 ,\u2026,x n ) on the n-dimensional unit cube E n is representable as \n \n$$f\\left( {{{x}_{1}}, \\ldots ,{{x}_{n}}} \\right) = \\sum\\limits_{{q = 1}}^{{q = 2n + 1}} {Xq\\left[ {\\sum\\limits_{{p = 1}}^{n} {{{\\psi }^{{pq}}}\\left( {{{x}_{p}}} \\right)} } \\right]} ,$$ \n \n(1) \n \nwhere x q (y) are continuous real functions."
            },
            "slug": "On-the-Representation-of-Continuous-Functions-of-as-Tikhomirov",
            "title": {
                "fragments": [],
                "text": "On the Representation of Continuous Functions of Several Variables as Superpositions of Continuous Functions of one Variable and Addition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2837737"
                        ],
                        "name": "M. Talagrand",
                        "slug": "M.-Talagrand",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Talagrand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Talagrand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121400976,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "14cd6aecc30fe2b61d890d21d0e1451d36c1eb22",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We give a new type of characterization of the Glivenko-Cantelli classes. In the case of a class $\\mathscr{L}$ of sets, the characterization is closely related to the configuration that the sets of $\\mathscr{L}$ can have. It allows one to decide simply whether a given class is a Glivenko-Cantelli class. The characterization is based on a new measure theoretic analysis of sets of measurable functions. This analysis also gives an approximation theorem for Glivenko-Cantelli classes, sharpenings of the Vapnik-Cervonenkis criteria and the value of the asymptotic discrepancy for classes that are not Glivenko-Cantelli. An application is given to the law of large numbers in a Banach space for functions that need not be random variables."
            },
            "slug": "The-Glivenko-Cantelli-Problem-Talagrand",
            "title": {
                "fragments": [],
                "text": "The Glivenko-Cantelli Problem"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058906009"
                        ],
                        "name": "G. M. Fitzmaurice",
                        "slug": "G.-M.-Fitzmaurice",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Fitzmaurice",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. M. Fitzmaurice"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781982"
                        ],
                        "name": "D. Hand",
                        "slug": "D.-Hand",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hand",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hand"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7981147,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "488a89c1c2c30fd9682de3cb1275f751609054c8",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-comparison-of-two-average-conditional-error-rate-Fitzmaurice-Hand",
            "title": {
                "fragments": [],
                "text": "A comparison of two average conditional error rate estimators"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145924374"
                        ],
                        "name": "L. Birge",
                        "slug": "L.-Birge",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Birge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Birge"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123155614,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "64e70ebe67350dd8318ec37f30c137b1927e6120",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "R\u00e9sum\u00e9On s'int\u00e9resse ici aux possibles vitesses d'estimation d'une densit\u00e9 \u00e0 support compact dans \u211dm sous des hypoth\u00e8ses de r\u00e9gularit\u00e9, lorsque la perte est mesur\u00e9e par le carr\u00e9 de la distance de Hellinger (on regardera aussi le cas connu des normes \n$$\\mathbb{L}^q $$\n pour 1\u2266q\u22662) et le risque est le risque minimax sur la famille. On donne une m\u00e9thode g\u00e9n\u00e9rale permettant de traiter les probl\u00e8mes dans le cadre de la th\u00e9orie de l'approximation sous des conditions concernant l'entropie m\u00e9trique et l' \u03b5-capacit\u00e9 des familles \u00e0 estimer. Les rapports entre r\u00e9gularit\u00e9 et entropie m\u00e9trique \u00e9tant bien connus, nous pourrons aussi traiter les cas classiques et d'autres qui le sont moins. Sous des conditions de bornes inf\u00e9rieures les vitesses sont celles observ\u00e9es pour la norme \n$$\\mathbb{L}^q $$\n mais elles diff\u00e8rent dans le cas g\u00e9n\u00e9ral. On montre aussi que les restrictions sur la compacit\u00e9 du support ou la r\u00e9gularit\u00e9 sont indispensables et que leur absence m\u00e8ne \u00e0 l'impossibilit\u00e9 d'obtenir une estimation raisonnable en ce sens que n'importe quelle suite d'estimateurs sera arbitrairement mauvaise en un point au moins. Un r\u00e9sultat analogue est vrai sous des conditions de r\u00e9gularit\u00e9."
            },
            "slug": "On-estimating-a-density-using-Hellinger-distance-Birge",
            "title": {
                "fragments": [],
                "text": "On estimating a density using Hellinger distance and some other strange facts"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2358049"
                        ],
                        "name": "J. Mantock",
                        "slug": "J.-Mantock",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Mantock",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mantock"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14920130,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "691d653efa0b9fd0b0e9f90c376abd375192e339",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A nonparametric data reduction technique is proposed. Its goal is to select samples that are ``representative'' of the entire data set. The technique is iterative and is based on the use of a criterion function and nearest neighbor density estimates. Experiments are presented to demonstrate the algorithm."
            },
            "slug": "Nonparametric-Data-Reduction-Fukunaga-Mantock",
            "title": {
                "fragments": [],
                "text": "Nonparametric Data Reduction"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A nonparametric data reduction technique is proposed that is iterative and based on the use of a criterion function and nearest neighbor density estimates to select samples that are ``representative'' of the entire data set."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7353451"
                        ],
                        "name": "G. Schwemer",
                        "slug": "G.-Schwemer",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Schwemer",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Schwemer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102093452"
                        ],
                        "name": "O. J. Dunn",
                        "slug": "O.-J.-Dunn",
                        "structuredName": {
                            "firstName": "Olive",
                            "lastName": "Dunn",
                            "middleNames": [
                                "Jean"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. J. Dunn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119557894,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "90a3cb81a2e354b309b0af769e45de7da2a1e1e5",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Class specific stratified posterior probability estimators of misclassification probabilities in discriminant analysis simulations are introduced. These estimators afford a significant variance reduction over the usual count estimators. Sufficient conditions for a variance reduction are given. The stratified posterior probability estimator is generalized to other class specific expectations."
            },
            "slug": "Posterior-probability-estimators-in-classification-Schwemer-Dunn",
            "title": {
                "fragments": [],
                "text": "Posterior probability estimators in classification simulations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145472944"
                        ],
                        "name": "H. Fuchs",
                        "slug": "H.-Fuchs",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Fuchs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Fuchs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682592"
                        ],
                        "name": "Z. Kedem",
                        "slug": "Z.-Kedem",
                        "structuredName": {
                            "firstName": "Zvi",
                            "lastName": "Kedem",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Kedem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144875366"
                        ],
                        "name": "B. Naylor",
                        "slug": "B.-Naylor",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Naylor",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Naylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6825303,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a744fe29d4658542cd3d692fd6ff92f7f6b9104",
            "isKey": false,
            "numCitedBy": 928,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new algorithm for solving the hidden surface (or line) problem, to more rapidly generate realistic images of 3-D scenes composed of polygons, and presents the development of theoretical foundations in the area as well as additional related algorithms. As in many applications the environment to be displayed consists of polygons many of whose relative geometric relations are static, we attempt to capitalize on this by preprocessing the environment's database so as to decrease the run-time computations required to generate a scene. This preprocessing is based on generating a \u201cbinary space partitioning\u201d tree whose in order traversal of visibility priority at run-time will produce a linear order, dependent upon the viewing position, on (parts of) the polygons, which can then be used to easily solve the hidden surface problem. In the application where the entire environment is static with only the viewing-position changing, as is common in simulation, the results presented will be sufficient to solve completely the hidden surface problem."
            },
            "slug": "On-visible-surface-generation-by-a-priori-tree-Fuchs-Kedem",
            "title": {
                "fragments": [],
                "text": "On visible surface generation by a priori tree structures"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A new algorithm for solving the hidden surface (or line) problem is described, to more rapidly generate realistic images of 3-D scenes composed of polygons, and the development of theoretical foundations in the area are presented."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '80"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144665059"
                        ],
                        "name": "Y. Linde",
                        "slug": "Y.-Linde",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Linde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Linde"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805395"
                        ],
                        "name": "A. Buzo",
                        "slug": "A.-Buzo",
                        "structuredName": {
                            "firstName": "Andres",
                            "lastName": "Buzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Buzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18530691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c46799502bebfe6a9ae0f457b7b8b92248ec260",
            "isKey": false,
            "numCitedBy": 7891,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "An efficient and intuitive algorithm is presented for the design of vector quantizers based either on a known probabilistic model or on a long training sequence of data. The basic properties of the algorithm are discussed and demonstrated by examples. Quite general distortion measures and long blocklengths are allowed, as exemplified by the design of parameter vector quantizers of ten-dimensional vectors arising in Linear Predictive Coded (LPC) speech compression with a complicated distortion measure arising in LPC analysis that does not depend only on the error vector."
            },
            "slug": "An-Algorithm-for-Vector-Quantizer-Design-Linde-Buzo",
            "title": {
                "fragments": [],
                "text": "An Algorithm for Vector Quantizer Design"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An efficient and intuitive algorithm is presented for the design of vector quantizers based either on a known probabilistic model or on a long training sequence of data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73756592"
                        ],
                        "name": "M. Gessaman",
                        "slug": "M.-Gessaman",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "Gessaman",
                            "middleNames": [
                                "Palmer"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gessaman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80011542"
                        ],
                        "name": "C. Quesenberry",
                        "slug": "C.-Quesenberry",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Quesenberry",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Quesenberry"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122097262,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b0eae4c19136a014517a57faa414324079698ffa",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Nonparametric discrimination among distributions on Euclidean space with continuous distribution functions by tolerance regions method, emphasizing errors probability distribution control"
            },
            "slug": "Nonparametric-Discrimination-Using-Tolerance-Gessaman-Quesenberry",
            "title": {
                "fragments": [],
                "text": "Nonparametric Discrimination Using Tolerance Regions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145407960"
                        ],
                        "name": "Y. K. Lin",
                        "slug": "Y.-K.-Lin",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Lin",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. K. Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97306284"
                        ],
                        "name": "K. Fu",
                        "slug": "K.-Fu",
                        "structuredName": {
                            "firstName": "King-Sun",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28717583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80f0cd515ddb0d9e2f2001385a1e292dd7c29bee",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-classification-of-cervical-cells-using-a-Lin-Fu",
            "title": {
                "fragments": [],
                "text": "Automatic classification of cervical cells using a binary tree classifier"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143649637"
                        ],
                        "name": "T. Linder",
                        "slug": "T.-Linder",
                        "structuredName": {
                            "firstName": "Tam\u00e1s",
                            "lastName": "Linder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Linder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755694"
                        ],
                        "name": "G. Lugosi",
                        "slug": "G.-Lugosi",
                        "structuredName": {
                            "firstName": "G\u00e1bor",
                            "lastName": "Lugosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lugosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751563"
                        ],
                        "name": "K. Zeger",
                        "slug": "K.-Zeger",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Zeger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Zeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 100038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c33ce56983828995a2d315779dfb6c7c0c576b5",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Rates of convergence results are established for vector quantization. Convergence rates are given for an increasing vector dimension and/or an increasing training set size. In particular, the following results are shown for memoryless real valued sources with bounded support at transmission rate R. (1) If a vector quantizer with fixed dimension k is designed to minimize the empirical MSE with respect to m training vectors, then its MSE for the true source converges almost surely to the minimum possible MSE as O(/spl radic/(log m/m)); (2) The MSE of an optimal k-dimensional vector quantizer for the true source converges, as the dimension grows, to the distortion-rate function D(R) as O(/spl radic/(log k/k)); (3) There exists a fixed rate universal lossy source coding scheme whose per letter MSE on n real valued source samples converges almost surely to the distortion-rate function D(R) as O(/spl radic/(log log n/log n)); and (4) Consider a training set of n real valued source samples blocked into vectors of dimension k, and a k-dimensional vector quantizer designed to minimize the empirical MSE with respect to the m=[n/k] training vectors. Then the MSE of this quantizer for the true source converges almost surely to the distortion-rate function D(R) as O(/spl radic/(log log n/log n)), if one chooses k=[1/R(1-/spl epsiv/)(log n)] /spl forall//spl epsiv/ /spl epsiv/(0,1).<<ETX>>"
            },
            "slug": "Rates-of-convergence-in-the-source-coding-theorem,-Linder-Lugosi",
            "title": {
                "fragments": [],
                "text": "Rates of convergence in the source coding theorem, in empirical quantizer design, and in universal lossy source coding"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "Rates of convergence results are established for vector quantization for memoryless real valued sources with bounded support at transmission rate R and for an increasing vector dimension and/or an increasing training set size."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE International Symposium on Information Theory"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881615"
                        ],
                        "name": "R. Dudley",
                        "slug": "R.-Dudley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dudley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dudley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 122230395,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c59250736174b8d80c40de6e1d5e1641366ef416",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "When \\(\\mathfrak{F}\\) is a universal Donsker class, then for independent, indetically distributed (i.i.d) observation \\(\\mathbf{X}_1,\\ldots,\\mathbf{X}_n\\) with an unknown law P, for any \\(\\mathfrak{f}_i\\)in \\(\\mathfrak{F},\\) \\(i=1,\\ldots,m,\\quad n^{-1/2}\\left\\{ \\mathfrak{f}_1\\left(\\mathbf{X}_1\\right)+\\ldots+\\mathfrak{f}_i\\left(\\mathbf{X}_n\\right)\\right\\}_{1\\leq i\\leq m}\\) is asymptotically normal with mean Vector \\(n^{1/2}\\left\\{\\int\\mathfrak{f}_i\\left(\\mathbf{X}_n\\right)d\\mathbf{P}\\left(x\\right)\\right\\}_{1_\\leq i\\leq m}\\) and covariance matrix \\(\\int\\mathfrak{f}_i\\mathfrak{f}_j d\\mathbf{P}-\\int\\mathfrak{f}_id\\mathbf{P}\\int\\mathfrak{f}_jd\\mathbf{P},\\) uniformly for \\({\\mathfrak{f}_i}\\in \\mathfrak{F}.\\) Then, for certain Statistics formed frome the \\(\\mathfrak{f}_i\\left(\\mathbf{X}_k\\right),\\) even where \\(\\mathfrak{f}_i\\) may be chosen depending on the \\(\\mathbf{X}_k\\) there will be asymptotic distribution as \\(n \\rightarrow \\infty.\\) For example, for \\(\\mathbf{X}^2\\) statistics, where \\(f_i\\) are indicators of disjoint intervals, depending suitably on \\(\\mathbf{X}_1,\\ldots,\\mathbf{X}_n\\), whose union is the real line, \\(\\mathbf{X}^2\\) quadratic forms have limiting distributions [Roy (1956) and Watson (1958)] which may, however, not be \\(\\mathbf{X}^2\\) distributions and may depend on P [Chernoff and Lehmann (1954)]. Universal Donsker classes of sets are, up to mild measurability conditions, just classes satisfying the Vapnik\u2013Cervonenkis comdinatorial conditions defined later in this section Donsker the Vapnik-Cervonenkis combinatorial conditions defined later in this section [Durst and Dudley (1981) and Dudley (1984) Chapter 11]. The use of such classes allows a variety of extensions of the Roy\u2013Watson results to general (multidimensional) sample spaces [Pollard (1979) and Moore and Subblebine (1981)]. Vapnik and Cervonenkis (1974) indicated application of their families of sets to classification (pattern recognition) problems. More recently, the classes have been applied to tree-structured classifiacation [Breiman, Friedman, Olshen and Stone (1984), Chapter 12]."
            },
            "slug": "Universal-Donsker-Classes-and-Metric-Entropy-Dudley",
            "title": {
                "fragments": [],
                "text": "Universal Donsker Classes and Metric Entropy"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3226094"
                        ],
                        "name": "P. Massart",
                        "slug": "P.-Massart",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Massart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Massart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 119656664,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "58a3c954ebef4a61877bb8aa3888255b1edc017e",
            "isKey": false,
            "numCitedBy": 664,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Let F^ n denote the empirical distribution function for a sample of n i.i.d. random variables with distribution function F. In 1956 Dvoretzky, Kiefer and Wolfowitz proved that P(\u221an sup x (F^ n (x)\u2212F(x))>\u03bb)\u2264C exp(\u22122\u03bb 2 ), where C is some unspecified constant. We show that C can be taken as 1, provided that exp(\u22122\u03bb 2 )\u22641/2. In particular, the two-sided inequality P(\u221an sup x |F^ n (x)\u2212F(x)|>\u03bb)\u22642 exp(\u22122\u03bb 2 ) holds without any restriction on \u03bb. In the one-sided as well as in the two-sided case, the constants cannot be further improved"
            },
            "slug": "The-Tight-Constant-in-the-Inequality-Massart",
            "title": {
                "fragments": [],
                "text": "The Tight Constant in the Dvoretzky-Kiefer-Wolfowitz Inequality"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90661057"
                        ],
                        "name": "L. Gordon",
                        "slug": "L.-Gordon",
                        "structuredName": {
                            "firstName": "Louis",
                            "lastName": "Gordon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gordon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378652"
                        ],
                        "name": "R. Olshen",
                        "slug": "R.-Olshen",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Olshen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Olshen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122021803,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e76a67deb9a65142371f593860507bf2566f0082",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Almost-surely-consistent-nonparametric-regression-Gordon-Olshen",
            "title": {
                "fragments": [],
                "text": "Almost surely consistent nonparametric regression from recursive partitioning schemes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9745969"
                        ],
                        "name": "A. Krzy\u017cak",
                        "slug": "A.-Krzy\u017cak",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Krzy\u017cak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krzy\u017cak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31046998,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "471b54e6b471d1ccf28b63020847197a3d0bd61e",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Classification-procedures-using-multivariate-kernel-Krzy\u017cak",
            "title": {
                "fragments": [],
                "text": "Classification procedures using multivariate variable kernel density estimate"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3303987"
                        ],
                        "name": "J. V. Campenhout",
                        "slug": "J.-V.-Campenhout",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Campenhout",
                            "middleNames": [
                                "M.",
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Campenhout"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120824287,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "591eaab7bbf084b482c5c7770cb84b8c0e2a0443",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Let Pe (S) denote the Bayes risk (probability of error) in testing two equally likely hypotheses H 0 versus H 1 using measurements in S, a subset of the set of possible measurements. The possible values of Pe (S) as a function of S are considered. It has been shown that all orderings on Pe (S), satisfying the natural monotonicity constraint S\u2032 \u2282 S \u21d2 Pe (S\u2032) \u2265 Pe (S) can occur. We show that no other restrictions exist on the numbers Pe (S), 0 < Pe (S) \u2264 \u00bd, thus extending the known result from the achievability of orderings to the achievability of numerically specified sequences. Thus nonexhaustive (suboptimal) measurement-selection algorithms can be arbitrarily bad."
            },
            "slug": "The-arbitrary-relation-between-probability-of-error-Campenhout",
            "title": {
                "fragments": [],
                "text": "The arbitrary relation between probability of error and measurement subset"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059460250"
                        ],
                        "name": "G. Bennett",
                        "slug": "G.-Bennett",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Bennett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Bennett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120762322,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f169d03d8db5b10c995deb1df016d8b2e201f61a",
            "isKey": false,
            "numCitedBy": 758,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract This paper proves a number of inequalities which improve on existing upper limits to the probability distribution of the sum of independent random variables. The inequalities presented require knowledge only of the variance of the sum and the means and bounds of the component random variables. They are applicable when the number of component random variables is small and/or have different distributions. Figures show the improvement on existing inequalities."
            },
            "slug": "Probability-Inequalities-for-the-Sum-of-Independent-Bennett",
            "title": {
                "fragments": [],
                "text": "Probability Inequalities for the Sum of Independent Random Variables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764952"
                        ],
                        "name": "K. Hornik",
                        "slug": "K.-Hornik",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Hornik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hornik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7343126,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d35f1e533b72370683d8fa2dabff5f0fc16490cc",
            "isKey": false,
            "numCitedBy": 4665,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Approximation-capabilities-of-multilayer-networks-Hornik",
            "title": {
                "fragments": [],
                "text": "Approximation capabilities of multilayer feedforward networks"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2091402938"
                        ],
                        "name": "T. Farago",
                        "slug": "T.-Farago",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Farago",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Farago"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087528"
                        ],
                        "name": "L. Gy\u00f6rfi",
                        "slug": "L.-Gy\u00f6rfi",
                        "structuredName": {
                            "firstName": "L\u00e1szl\u00f3",
                            "lastName": "Gy\u00f6rfi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gy\u00f6rfi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7323196,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4589634f9f1b34567f17884a5f1f9b054af341ee",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Analogously to the rate distortion function, the error distortion function is defined for a multiple-hypothesis decision problem. The error distortion function e(d) is defined as the supremum of the Bayes' error probability for transformed observations for which the average distortion is less than d (d \\geq O) The main result is that the function e(d) is continuous at O."
            },
            "slug": "On-the-continuity-of-the-error-distortion-function-Farago-Gy\u00f6rfi",
            "title": {
                "fragments": [],
                "text": "On the continuity of the error distortion function for multiple-hypothesis decisions (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "Analogously to the rate distortion function, the error distortion function is defined for a multiple-hypothesis decision problem and the main result is that the function e(d) is continuous at O."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47358212"
                        ],
                        "name": "E. Fix",
                        "slug": "E.-Fix",
                        "structuredName": {
                            "firstName": "Evelyn",
                            "lastName": "Fix",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fix"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2541903"
                        ],
                        "name": "J. L. Hodges",
                        "slug": "J.-L.-Hodges",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Hodges",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. L. Hodges"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120323383,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "088a6ae9149aa83d22b7cca1c542ce938f27cfe7",
            "isKey": false,
            "numCitedBy": 2168,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The discrimination problem (two population case) may be defined as follows: e random variable Z, of observed value z, is distributed over some space (say, p-dimensional) either according to distribution F, or according to distribution G. The problem is to decide, on the basis of z, which of the two distributions Z has."
            },
            "slug": "Discriminatory-Analysis-Nonparametric-Consistency-Fix-Hodges",
            "title": {
                "fragments": [],
                "text": "Discriminatory Analysis - Nonparametric Discrimination: Consistency Properties"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145115302"
                        ],
                        "name": "N. Sauer",
                        "slug": "N.-Sauer",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Sauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sauer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 7231983,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "788c6d1b1419a0f7b7695c0e7e9e41cf54fbfe1b",
            "isKey": false,
            "numCitedBy": 894,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-Density-of-Families-of-Sets-Sauer",
            "title": {
                "fragments": [],
                "text": "On the Density of Families of Sets"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comb. Theory, Ser. A"
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785855"
                        ],
                        "name": "W. Greblicki",
                        "slug": "W.-Greblicki",
                        "structuredName": {
                            "firstName": "W\u0142odzimierz",
                            "lastName": "Greblicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Greblicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143803540"
                        ],
                        "name": "M. Pawlak",
                        "slug": "M.-Pawlak",
                        "structuredName": {
                            "firstName": "Miros\u0142aw",
                            "lastName": "Pawlak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pawlak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122334416,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "aa3c64545470f6624ad4a4d41de241f3d0366054",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pointwise-consistency-of-the-hermite-series-density-Greblicki-Pawlak",
            "title": {
                "fragments": [],
                "text": "Pointwise consistency of the hermite series density estimate"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2884287,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "625c429a6d0602e9deb02609551104423fdb41a3",
            "isKey": false,
            "numCitedBy": 335,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Sphere-Packing-Numbers-for-Subsets-of-the-Boolean-Haussler",
            "title": {
                "fragments": [],
                "text": "Sphere Packing Numbers for Subsets of the Boolean n-Cube with Bounded Vapnik-Chervonenkis Dimension"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comb. Theory, Ser. A"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2724170"
                        ],
                        "name": "Y. Yatracos",
                        "slug": "Y.-Yatracos",
                        "structuredName": {
                            "firstName": "Yannis",
                            "lastName": "Yatracos",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yatracos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121532209,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ebb6db4c6e780255d613688cfe8ef9d941dbfb44",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "On construit des estimateurs robustes, et on montre que le taux de convergence resultant depend naturellement d'une fonction entropie"
            },
            "slug": "Rates-of-Convergence-of-Minimum-Distance-Estimators-Yatracos",
            "title": {
                "fragments": [],
                "text": "Rates of Convergence of Minimum Distance Estimators and Kolmogorov's Entropy"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3268154"
                        ],
                        "name": "C. Hartmann",
                        "slug": "C.-Hartmann",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Hartmann",
                            "middleNames": [
                                "R.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Hartmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925309"
                        ],
                        "name": "P. Varshney",
                        "slug": "P.-Varshney",
                        "structuredName": {
                            "firstName": "Pramod",
                            "lastName": "Varshney",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Varshney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743871"
                        ],
                        "name": "K. Mehrotra",
                        "slug": "K.-Mehrotra",
                        "structuredName": {
                            "firstName": "Kishan",
                            "lastName": "Mehrotra",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mehrotra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17126878"
                        ],
                        "name": "C. L. Gerberich",
                        "slug": "C.-L.-Gerberich",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Gerberich",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Gerberich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 18200443,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e30a6b22ed4e4800a92eea07d3b297456f02f846",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of conversion of decision tables to decision trees is treated. In most cases, the construction of optimal decision trees is an NP-complete problem and, therefore, a heuristic approach to this problem is necessary. In this heuristic approach, an application of information theoretic concepts to construct efficient decision trees for decision tables which may include \"don't care\" entries is made. In contrast to most of the existing heuristic algorithms, this algorithm is systematic and is intuitively appealing from an information theoretic standpoint. The algorithm has low design complexity and yet provides near-optimal decision trees."
            },
            "slug": "Application-of-information-theory-to-the-of-trees-Hartmann-Varshney",
            "title": {
                "fragments": [],
                "text": "Application of information theory to the construction of efficient decision trees"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This heuristic approach to the problem of conversion of decision tables to decision trees is treated and has low design complexity and yet provides near-optimal decision trees."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101429065"
                        ],
                        "name": "A. Shiryayev",
                        "slug": "A.-Shiryayev",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Shiryayev",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shiryayev"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 115965100,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a85dbc127137416ea202cc7d72f50290d9bc08f9",
            "isKey": false,
            "numCitedBy": 578,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Consider the sum of two independent discrete random variables X and Y whose values are restricted to the non-negative integers. Let f X (\u00b7) denote the probability distribution of X and f Y (\u00b7) denote the probability distribution of Y. The distribution of their sum Z = X + Y is given by the discrete convolution formula."
            },
            "slug": "On-Sums-of-Independent-Random-Variables-Shiryayev",
            "title": {
                "fragments": [],
                "text": "On Sums of Independent Random Variables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9745969"
                        ],
                        "name": "A. Krzy\u017cak",
                        "slug": "A.-Krzy\u017cak",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Krzy\u017cak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krzy\u017cak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143803534"
                        ],
                        "name": "M. Pawlak",
                        "slug": "M.-Pawlak",
                        "structuredName": {
                            "firstName": "Miroslaw",
                            "lastName": "Pawlak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pawlak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116477056,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a90d83a5768e733b25668182aec02d30bddbbfbc",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In the paper authors study universal consistency results for Wolverton, Wagner as well as Devroye, Wagner kernel type estimates of a regression function. There are proved sufficient conditions for weak and strong pointwise convergence under no assumptions on underlying distribution."
            },
            "slug": "Almost-Everywhere-Convergence-of-Recursive-Kernel-Krzy\u017cak-Pawlak",
            "title": {
                "fragments": [],
                "text": "Almost Everywhere Convergence of Recursive Kernel Regression Function Estimates"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755694"
                        ],
                        "name": "G. Lugosi",
                        "slug": "G.-Lugosi",
                        "structuredName": {
                            "firstName": "G\u00e1bor",
                            "lastName": "Lugosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lugosi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122658486,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dd58c309f6401ff8b180b786226b0569da77c588",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Improved-upper-bounds-for-probabilities-of-uniform-Lugosi",
            "title": {
                "fragments": [],
                "text": "Improved upper bounds for probabilities of uniform deviations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150444582"
                        ],
                        "name": "David S. Johnson",
                        "slug": "David-S.-Johnson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Johnson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David S. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145695738"
                        ],
                        "name": "F. Preparata",
                        "slug": "F.-Preparata",
                        "structuredName": {
                            "firstName": "Franco",
                            "lastName": "Preparata",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Preparata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 39933168,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b83151fcd9264ce85feeeeb9707b3655ecbe6dc9",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Densest-Hemisphere-Problem-Johnson-Preparata",
            "title": {
                "fragments": [],
                "text": "The Densest Hemisphere Problem"
            },
            "venue": {
                "fragments": [],
                "text": "Theor. Comput. Sci."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684300"
                        ],
                        "name": "W. Stuetzle",
                        "slug": "W.-Stuetzle",
                        "structuredName": {
                            "firstName": "Werner",
                            "lastName": "Stuetzle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Stuetzle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052409300"
                        ],
                        "name": "A. Schroeder",
                        "slug": "A.-Schroeder",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Schroeder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Schroeder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9170233,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0b7db4faa23eb52920d420bd20a91393c50fa0e2",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The projection pursuit methodology is applied to the multivariate density estimation problem. The resulting nonparametric procedure is often less biased than the kernel and near-neighbor methods. In addition, graphical information is produced that can be used to help gain geometric insight into the multivariate data distribution."
            },
            "slug": "PROJECTION-PURSUIT-DENSITY-ESTIMATION-Friedman-Stuetzle",
            "title": {
                "fragments": [],
                "text": "PROJECTION PURSUIT DENSITY ESTIMATION"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781982"
                        ],
                        "name": "D. Hand",
                        "slug": "D.-Hand",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hand",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hand"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 109708213,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5198930f72be1882fbf37e2bc4b544d7f60a6b89",
            "isKey": false,
            "numCitedBy": 1194,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents different approaches to discrimination and classification problems from a statistical perspective. Provides computer projects concentrating on the most widely used and important algorithms, numerical examples, and theoretical questions reinforce to further develop the ideas introduced in the text."
            },
            "slug": "Discrimination-and-Classification-Hand",
            "title": {
                "fragments": [],
                "text": "Discrimination and Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "Presents different approaches to discrimination and classification problems from a statistical perspective and provides computer projects concentrating on the most widely used and important algorithms, numerical examples, and theoretical questions to further develop the ideas introduced in the text."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683946"
                        ],
                        "name": "A. Ehrenfeucht",
                        "slug": "A.-Ehrenfeucht",
                        "structuredName": {
                            "firstName": "Andrzej",
                            "lastName": "Ehrenfeucht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ehrenfeucht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1925579,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b83396caf4762c906530c9219a9e4dd0658232b0",
            "isKey": false,
            "numCitedBy": 499,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-general-lower-bound-on-the-number-of-examples-for-Ehrenfeucht-Haussler",
            "title": {
                "fragments": [],
                "text": "A general lower bound on the number of examples needed for learning"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3303987"
                        ],
                        "name": "J. V. Campenhout",
                        "slug": "J.-V.-Campenhout",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Campenhout",
                            "middleNames": [
                                "M.",
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Campenhout"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20060045,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "244b25c97bd53a235a1fca458c410a81c95f019d",
            "isKey": false,
            "numCitedBy": 284,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "An aspect of the measurement selection problem\u00bfthe existence of anomalous orderings on the probability of error obtained by selected subsets of measurements\u00bfis discussed. It is shown that for any ordering on the probability of error as a function of the subset of measurements (subject to an obvious set monotonicity condition), there exists a multivariate normal two-hypothesis problem N(\u00bf,K) versus N(\u00bf\u00bf,K) that exhibits this ordering. Thus no known nonexhaustive sequential k-measurement selection procedure is optimal, even for jointly normal measurements."
            },
            "slug": "On-the-Possible-Orderings-in-the-Measurement-Cover-Campenhout",
            "title": {
                "fragments": [],
                "text": "On the Possible Orderings in the Measurement Selection Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "It is shown that for any ordering on the probability of error as a function of the subset of measurements (subject to an obvious set monotonicity condition), there exists a multivariate normal two-hypothesis problem N(K) versus N(\u00bf\u00bf,K) that exhibits this ordering."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102559951"
                        ],
                        "name": "Lucien Birg\u00e9",
                        "slug": "Lucien-Birg\u00e9",
                        "structuredName": {
                            "firstName": "Lucien",
                            "lastName": "Birg\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucien Birg\u00e9"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120591644,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "be2e2c9b892ddc62436c75fe0f84dc4390989bbb",
            "isKey": false,
            "numCitedBy": 287,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "SummaryWe investigate the relations between the speed of estimation and the metric structure of the parameter space \u0398, especially in the case when its metric dimension is infinite. Given some distance d on \u0398 (generally Hellinger distance in the case of n i.i.d. variables), we consider the minimax risk for n observations: \n% MathType!MTEF!2!1!+-% feaafiart1ev1aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn% hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr% 4rNCHbGeaGqiVu0Je9sqqrpepC0xbbL8F4rqqrFfpeea0xe9qq-Jar% pepeea0xd9q8as0-LqLs-Jirpepeea0-as0Fb9pgea0db9fr-xfr-x% frpeWZqaaeaabiGaciaacaqabeaadaqaaqaaaOqaaiaadkfadaWgaa% WcbaGaamOBaaqabaGccaGGOaGaamyCaiaacMcacqGH9aqpdaWfqaqa% aiGacMgacaGGUbGaaiOzaGqaciaa-bcaciGGZbGaaiyDaiaacchaaS% qaaiaadsfadaWgaaadbaGaamOBaiaa-bcaaeqaaSGaeqiUdeNaeyic% I4SaeuiMdefabeaakiaabMeacaqGfbWaaSbaaSqaaiabeI7aXbqaba% GccaGGBbGaamizamaaCaaaleqabaGaamyCaaaakiaacIcacqaH4oqC% caGGSaGaa8hiaiaadsfadaWgaaWcbaGaamOBaaqabaGccaGGPaGaai% yxaiaacYcaaaa!5A70!\n\n$$R_n (q) = \\mathop {\\inf \\sup }\\limits_{T_{n } \\theta \\in \\Theta } {\\text{IE}}_\\theta [d^q (\\theta , T_n )],$$\n, Tn being any estimate of \u03b8. We shall look for functions r such that for positive constants C1(q) and C2(q) C1rq(n)\u2266Rn(q)\u2266C2rq(n). r(n) is the speed of estimation and we shall show under fairly general conditions (including i.i.d. variables and regular cases of Markov chains and stationnary gaussian processes) that r(n) is determined, up to multiplicative constants, by the metric structure of \u0398. We shall also give a construction for some sort of \u201cuniversal\u201d estimates the risk of which is bounded by C2rq(n) in all cases where the preceding theory applies."
            },
            "slug": "Approximation-dans-les-espaces-m\u00e9triques-et-th\u00e9orie-Birg\u00e9",
            "title": {
                "fragments": [],
                "text": "Approximation dans les espaces m\u00e9triques et th\u00e9orie de l'estimation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143689789"
                        ],
                        "name": "D. Pollard",
                        "slug": "D.-Pollard",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pollard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pollard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44766883,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4adbee9540612ce25e1c5e31b6bd29c42bf1f8d",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Asymptotic results from the statistical theory of k -means clustering are applied to problems of vector quantization. The behavior of quantizers constructed from long training sequences of data is analyzed by relating it to the consistency problem for k -means."
            },
            "slug": "Quantization-and-the-method-of-k-means-Pollard",
            "title": {
                "fragments": [],
                "text": "Quantization and the method of k -means"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Asymptotic results from the statistical theory of k -means clustering are applied to problems of vector quantization and the behavior of quantizers constructed from long training sequences of data is analyzed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145472944"
                        ],
                        "name": "H. Fuchs",
                        "slug": "H.-Fuchs",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Fuchs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Fuchs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144027436"
                        ],
                        "name": "G. Abram",
                        "slug": "G.-Abram",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Abram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Abram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2429063"
                        ],
                        "name": "E. Grant",
                        "slug": "E.-Grant",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Grant",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Grant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2348321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67bbdee32d888ea46660662118f165d91563194f",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Described is a visible surface algorithm and an implementation that generates shaded display of objects with hundreds of polygons rapidly enough for interactive use \u2014 several images per second. The basic algorithm, introduced in [Fuchs, Kedem and Naylor, 1980], is designed to handle rigid objects and scenes by preprocessing the object data base to minimize visibility computation cost. The speed of the algorithm is further enhanced by its simplicity, which allows it to be implemented within the internal graphics processor of a general purpose raster system."
            },
            "slug": "Near-real-time-shaded-display-of-rigid-objects-Fuchs-Abram",
            "title": {
                "fragments": [],
                "text": "Near real-time shaded display of rigid objects"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A visible surface algorithm and an implementation that generates shaded display of objects with hundreds of polygons rapidly enough for interactive use \u2014 several images per second."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764952"
                        ],
                        "name": "K. Hornik",
                        "slug": "K.-Hornik",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Hornik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hornik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2964655"
                        ],
                        "name": "M. Stinchcombe",
                        "slug": "M.-Stinchcombe",
                        "structuredName": {
                            "firstName": "Maxwell",
                            "lastName": "Stinchcombe",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stinchcombe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149702798"
                        ],
                        "name": "H. White",
                        "slug": "H.-White",
                        "structuredName": {
                            "firstName": "Halbert",
                            "lastName": "White",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. White"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2757547,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "f22f6972e66bdd2e769fa64b0df0a13063c0c101",
            "isKey": false,
            "numCitedBy": 17353,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multilayer-feedforward-networks-are-universal-Hornik-Stinchcombe",
            "title": {
                "fragments": [],
                "text": "Multilayer feedforward networks are universal approximators"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103024388"
                        ],
                        "name": "Kazuoki Azuma",
                        "slug": "Kazuoki-Azuma",
                        "structuredName": {
                            "firstName": "Kazuoki",
                            "lastName": "Azuma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuoki Azuma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 120707243,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "08f186c9dba4e25c9d91e64d88d9bf9512da8230",
            "isKey": false,
            "numCitedBy": 1014,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Let be a probability space and,be an increasing family of sub o'-fields of(we put(c) Let (xn)n=1, 2, \u2022c be a sequence of bounded martingale differences on , that is,xn(\u0192\u00d6) is bounded almost surely (a.s.) ands. for n =1, 2,.... It is easily seen that this sequence has the following properties[G] and [M], which have been introduced by Y. S. Chow ([1]) in an analogous form and by G. Alexits ([4]), respectively, and may be of independent interest."
            },
            "slug": "WEIGHTED-SUMS-OF-CERTAIN-DEPENDENT-RANDOM-VARIABLES-Azuma",
            "title": {
                "fragments": [],
                "text": "WEIGHTED SUMS OF CERTAIN DEPENDENT RANDOM VARIABLES"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149702798"
                        ],
                        "name": "H. White",
                        "slug": "H.-White",
                        "structuredName": {
                            "firstName": "Halbert",
                            "lastName": "White",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. White"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17450563,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dd8bae7027cc2f0976ae1801d8432c5637b89db9",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We establish the consistency of nonparametric conditional quantile estimators based on artificial neural networks. The results follow from general results on sieve estimation for dependent processes. We also show that conditional quantiles can be learned to any pre-specified accuracy using approximate rather than exact network optimization."
            },
            "slug": "Nonparametric-Estimation-of-Conditional-Quantiles-White",
            "title": {
                "fragments": [],
                "text": "Nonparametric Estimation of Conditional Quantiles Using Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144522912"
                        ],
                        "name": "R. Durrett",
                        "slug": "R.-Durrett",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Durrett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Durrett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 157
                            }
                        ],
                        "text": "Most proofs are omitted as they may be found in standard textbooks on probability, such as Feller [1], Ash [2], Shiryayev [3], Chow and Teicher [4], Durrett [5], Grimmett and Stirzaker [6], and Zygmund [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16740132,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "aaaae6628c9c33e165e5cd5538b27d9275c24347",
            "isKey": false,
            "numCitedBy": 5163,
            "numCiting": 167,
            "paperAbstract": {
                "fragments": [],
                "text": "This book is an introduction to probability theory covering laws of large numbers, central limit theorems, random walks, martingales, Markov chains, ergodic theorems, and Brownian motion. It is a comprehensive treatment concentrating on the results that are the most useful for applications. Its philosophy is that the best way to learn probability is to see it in action, so there are 200 examples and 450 problems."
            },
            "slug": "Probability:-Theory-and-Examples-Durrett",
            "title": {
                "fragments": [],
                "text": "Probability: Theory and Examples"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719385"
                        ],
                        "name": "H. Samet",
                        "slug": "H.-Samet",
                        "structuredName": {
                            "firstName": "Hanan",
                            "lastName": "Samet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Samet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5147638,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "7de7722b368930284d53a059ac387c7aa9d59c76",
            "isKey": false,
            "numCitedBy": 3001,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "the design and analysis of spatial data structures addison the design and analysis of spatial data structures addison the design and analysis of spatial data structures addison the design and analysis of spatial data structures addison the design and analysis of spatial data structures addison applications of spatial data structures: computer graphics the design and analysis of spatial data structures (pdf editor: andrew s. glassner computer foundations of mathematics 10 by addison wesley bing the value of social media for predicting stock returns landscape architecture fourth edition a manual of land portland writing units grade 5 ekpbs samsung odin manual pdf pdf duckshost wheres the bee wire o journal wmcir document about oae special education 043 secrets study chapter 15 section 2 guided reading a worldwide depression private lemonade nfcqr songs made famous by tammy wynette mandv chapter 22 the great depression begins test answers shamrock cargo a story of the irish pota ekpbs tlia2050a learner guide ramonapropertymanagers 12. greene n., kass m., miller g. \u201chierarchical zbuffer the encyclopedia of the novel vmnlaw remembering and imagining palestine identity and service manual tc21da jupw websters new world basic dictionary of american english workshop manual for mercedes benz oligra"
            },
            "slug": "The-Design-and-Analysis-of-Spatial-Data-Structures-Samet",
            "title": {
                "fragments": [],
                "text": "The Design and Analysis of Spatial Data Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The design and analysis of spatial data structures and applications for predicting stock returns and remembering and imagining palestine identity and service manual are studied."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064710801"
                        ],
                        "name": "A. F. Mitchell",
                        "slug": "A.-F.-Mitchell",
                        "structuredName": {
                            "firstName": "Ann",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "F.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. F. Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642550"
                        ],
                        "name": "W. Krzanowski",
                        "slug": "W.-Krzanowski",
                        "structuredName": {
                            "firstName": "Wojtek",
                            "lastName": "Krzanowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Krzanowski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121285625,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d8d13aa2e6652c9adea47a41f3c6f0d958e1a786",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY The Mahalanobis distance is shown to be an appropriate measure of distance between two elliptic distributions having different locations but a common shape. This extends a result long familiar in multivariate analysis to a class of nonnormal distributions. It can also be used to show that the sample version of the Mahalanobis distance is appropriate under both estimative and predictive approaches to estimation for the family of multivariate normal distributions differing only in location."
            },
            "slug": "The-Mahalanobis-distance-and-elliptic-distributions-Mitchell-Krzanowski",
            "title": {
                "fragments": [],
                "text": "The Mahalanobis distance and elliptic distributions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2363971"
                        ],
                        "name": "J. Hertz",
                        "slug": "J.-Hertz",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hertz",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hertz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46486898"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50760571"
                        ],
                        "name": "R. Palmer",
                        "slug": "R.-Palmer",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Palmer",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Palmer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38623065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c0cbbd275bb43e09f0527a31ddd61824eca295b",
            "isKey": false,
            "numCitedBy": 6517,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis book is a comprehensive introduction to the neural network models currently under intensive study for computational applications. It is a detailed, logically-developed treatment that covers the theory and uses of collective computational networks, including associative memory, feed forward networks, and unsupervised learning. It also provides coverage of neural network applications in a variety of problems of both theoretical and practical interest."
            },
            "slug": "Introduction-to-the-theory-of-neural-computation-Hertz-Krogh",
            "title": {
                "fragments": [],
                "text": "Introduction to the theory of neural computation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This book is a detailed, logically-developed treatment that covers the theory and uses of collective computational networks, including associative memory, feed forward networks, and unsupervised learning."
            },
            "venue": {
                "fragments": [],
                "text": "The advanced book program"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719385"
                        ],
                        "name": "H. Samet",
                        "slug": "H.-Samet",
                        "structuredName": {
                            "firstName": "Hanan",
                            "lastName": "Samet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Samet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10319214,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c2e776fb40667fde3ece360cb829f717ce5daf9",
            "isKey": false,
            "numCitedBy": 2313,
            "numCiting": 293,
            "paperAbstract": {
                "fragments": [],
                "text": "Apercu sur les quadarbres et les structures de donnees hierarchiques. Elles sont basees sur le principe de decomposition recursive. L'accentuation est mise sur la representation de donnees dans les applications de traitement d'images, d'infographie, les systemes d'informations geographiques et la robotique. On examine en detail un certain nombre d'operations dans lesquelles de telles structures de donnees trouvent leur utilisation"
            },
            "slug": "The-Quadtree-and-Related-Hierarchical-Data-Samet",
            "title": {
                "fragments": [],
                "text": "The Quadtree and Related Hierarchical Data Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "L'accentuation est mise sur la representation de donnees dans les applications de traitement d'images, d'infographie, les systemes d'informations geographiques and the robotique."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48420398"
                        ],
                        "name": "C. Goffman",
                        "slug": "C.-Goffman",
                        "structuredName": {
                            "firstName": "Casper",
                            "lastName": "Goffman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Goffman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 471291,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "32da9dfc2224bc4e932b987836d604d16a5fe932",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The density theorem of Lebesgue [I ] may be stated in the following form: If S is a measurable linear point set, the metric density of S exists and is equal to 0 or 1 almost everywhere. We prove the converse that for every set Z of measure 0 there is a measurable set S whose metric density does not exist at any point of Z. We note, however, that in order for Z to be the set of points for which the metric density of some set S exists but is different from 0 or 1, Z must be both of measure 0 and of first category. As a converse, we show that for every F, type set Z of measure 0, thus of first category, there is a measurable set S whose metric density exists but is different from 0 or 1 at every point of Z."
            },
            "slug": "On-Lebesgue\u2019s-density-theorem-Goffman",
            "title": {
                "fragments": [],
                "text": "On Lebesgue\u2019s density theorem"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1950
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940156"
                        ],
                        "name": "T. Wagner",
                        "slug": "T.-Wagner",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Wagner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wagner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18051841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae46caa3db61087e27d970997b27f1ccb52622ea",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that distribution-free confidence intervals can be placed about the resubstitution estimate of the probability of error of any linear discrimination procedure."
            },
            "slug": "A-distribution-free-performance-bound-in-error-Devroye-Wagner",
            "title": {
                "fragments": [],
                "text": "A distribution-free performance bound in error estimation (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "It is shown that distribution-free confidence intervals can be placed about the resubstitution estimate of the probability of error of any linear discrimination procedure."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881615"
                        ],
                        "name": "R. Dudley",
                        "slug": "R.-Dudley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dudley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dudley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697413"
                        ],
                        "name": "S. Kulkarni",
                        "slug": "S.-Kulkarni",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Kulkarni",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kulkarni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056772431"
                        ],
                        "name": "T. Richardson",
                        "slug": "T.-Richardson",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Richardson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Richardson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795344"
                        ],
                        "name": "O. Zeitouni",
                        "slug": "O.-Zeitouni",
                        "structuredName": {
                            "firstName": "Ofer",
                            "lastName": "Zeitouni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Zeitouni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13800701,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "285fa8b9f8243fecae27f57ae27e9779941df3c2",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors prove by means of a counterexample that it is not sufficient, for probably approximately correct (PAC) learning under a class of distributions, to have a uniform bound on the metric entropy of the class of concepts to be learned. This settles a conjecture of Benedek and Itai (1991). >"
            },
            "slug": "A-metric-entropy-bound-is-not-sufficient-for-Dudley-Kulkarni",
            "title": {
                "fragments": [],
                "text": "A metric entropy bound is not sufficient for learnability"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "It is proved by means of a counterexample that it is not sufficient, for probably approximately correct (PAC) learning under a class of distributions, to have a uniform bound on the metric entropy of the class of concepts to be learned."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2856152"
                        ],
                        "name": "E. Parzen",
                        "slug": "E.-Parzen",
                        "structuredName": {
                            "firstName": "Emanuel",
                            "lastName": "Parzen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Parzen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122932724,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "de28c165623adabcdba0fdb18b65eba685aaf31d",
            "isKey": false,
            "numCitedBy": 9493,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Given a sequence of independent identically distributed random variables with a common probability density function, the problem of the estimation of a probability density function and of determining the mode of a probability function are discussed. Only estimates which are consistent and asymptotically normal are constructed. (Author)"
            },
            "slug": "On-Estimation-of-a-Probability-Density-Function-and-Parzen",
            "title": {
                "fragments": [],
                "text": "On Estimation of a Probability Density Function and Mode"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781982"
                        ],
                        "name": "D. Hand",
                        "slug": "D.-Hand",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hand",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hand"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26393105,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12bd94c631b4751439cb17012feca227d6fb15c2",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recent-advances-in-error-rate-estimation-Hand",
            "title": {
                "fragments": [],
                "text": "Recent advances in error rate estimation"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51083130"
                        ],
                        "name": "F. Rosenblatt",
                        "slug": "F.-Rosenblatt",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Rosenblatt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Rosenblatt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62710001,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "9b486c647916df9f8be0f8d4fc5c94c493bfaa80",
            "isKey": false,
            "numCitedBy": 1904,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Part I attempts to review the background, basic sources of data, concepts, and methodology to be employed in the study of perceptrons. In Chapter 2, a brief review of the main alternative approaches to the development of brain models is presented. Chapter 3 considers the physiological and psychological criteria for a suitable model, and attempts to evaluate the empirical evidence which is available on several important issues. Chapter 4 contains basic definitions and some of the notation to be used in later sections are presented. Parts II and III are devoted to a summary of the established theoretical results obtained to date. Part II (Chapters 5 through 14) deals with the theory of three-layer series-coupled perceptrons, on which most work has been done to date. Part III (Chapters 15 through 20) deals with the theory of multi-layer and cross-coupled perceptrons. Part IV is concerned with more speculative models and problems for future analysis. Of necessity, the final chapters become increasingly heuristic in character, as the theory of perceptrons is not yet complete, and new possibilities are continually coming to light."
            },
            "slug": "PRINCIPLES-OF-NEURODYNAMICS.-PERCEPTRONS-AND-THE-OF-Rosenblatt",
            "title": {
                "fragments": [],
                "text": "PRINCIPLES OF NEURODYNAMICS. PERCEPTRONS AND THE THEORY OF BRAIN MECHANISMS"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The background, basic sources of data, concepts, and methodology to be employed in the study of perceptrons are reviewed, and some of the notation to be used in later sections are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1460233548"
                        ],
                        "name": "Saab Abou-Jaoud\u00e9",
                        "slug": "Saab-Abou-Jaoud\u00e9",
                        "structuredName": {
                            "firstName": "Saab",
                            "lastName": "Abou-Jaoud\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saab Abou-Jaoud\u00e9"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 126522644,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "cc0f725c08f016ed505b0bc28f2a7b131c7c93d4",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "\u00a9 Gauthier-Villars, 1976, tous droits r\u00e9serv\u00e9s. L\u2019acc\u00e8s aux archives de la revue \u00ab Annales de l\u2019I. H. P., section B \u00bb (http://www.elsevier.com/locate/anihpb) implique l\u2019accord avec les conditions g\u00e9n\u00e9rales d\u2019utilisation (http://www.numdam.org/conditions). Toute utilisation commerciale ou impression syst\u00e9matique est constitutive d\u2019une infraction p\u00e9nale. Toute copie ou impression de ce fichier doit contenir la pr\u00e9sente mention de copyright."
            },
            "slug": "Conditions-n\u00e9cessaires-et-suffisantes-de-L1-en-de-Abou-Jaoud\u00e9",
            "title": {
                "fragments": [],
                "text": "Conditions n\u00e9cessaires et suffisantes de convergence L1 en probabilit\u00e9 de l'histogramme pour une densit\u00e9"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751700"
                        ],
                        "name": "T. Hagerup",
                        "slug": "T.-Hagerup",
                        "structuredName": {
                            "firstName": "Torben",
                            "lastName": "Hagerup",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hagerup"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3163970"
                        ],
                        "name": "Christine R\u00fcb",
                        "slug": "Christine-R\u00fcb",
                        "structuredName": {
                            "firstName": "Christine",
                            "lastName": "R\u00fcb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christine R\u00fcb"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40984617,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1d0c7472515c632130d5593dfb05458c09af2b76",
            "isKey": false,
            "numCitedBy": 519,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Guided-Tour-of-Chernoff-Bounds-Hagerup-R\u00fcb",
            "title": {
                "fragments": [],
                "text": "A Guided Tour of Chernoff Bounds"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Lett."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145159156"
                        ],
                        "name": "J. Steele",
                        "slug": "J.-Steele",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Steele",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Steele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121551850,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7ceb6dd86e22d5c20b4c131c1af31ef7205695ce",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "On etablit l'analogue d'un resultat d'Efron et Stein (1981) que l'on demontre a l'aide d'une technique d'espace de Hilbert introduite par Vitale (1984)"
            },
            "slug": "An-Efron-Stein-inequality-for-nonsymmetric-Steele",
            "title": {
                "fragments": [],
                "text": "An Efron-Stein inequality for nonsymmetric statistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2015030"
                        ],
                        "name": "W. H\u00e4rdle",
                        "slug": "W.-H\u00e4rdle",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "H\u00e4rdle",
                            "middleNames": [
                                "Karl"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. H\u00e4rdle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145956495"
                        ],
                        "name": "J. Marron",
                        "slug": "J.-Marron",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Marron",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Marron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 121537808,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c840211e9dc9d0083821f5d33188f7d2e76c3803",
            "isKey": false,
            "numCitedBy": 430,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "On considere des estimateurs du noyau d'une fonction de regression multivariable et une regle de selection selon la largeur de bande formulee en terme de validation croisee"
            },
            "slug": "Optimal-Bandwidth-Selection-in-Nonparametric-H\u00e4rdle-Marron",
            "title": {
                "fragments": [],
                "text": "Optimal Bandwidth Selection in Nonparametric Regression Function Estimation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648880"
                        ],
                        "name": "Jooyoung Park",
                        "slug": "Jooyoung-Park",
                        "structuredName": {
                            "firstName": "Jooyoung",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jooyoung Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2493659"
                        ],
                        "name": "I. Sandberg",
                        "slug": "I.-Sandberg",
                        "structuredName": {
                            "firstName": "Irwin",
                            "lastName": "Sandberg",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Sandberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27785042,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "140715a56da820314480efc37bd3d5b46963efbe",
            "isKey": false,
            "numCitedBy": 811,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper concerns conditions for the approximation of functions in certain general spaces using radial-basis-function networks. It has been shown in recent papers that certain classes of radial-basis-function networks are broad enough for universal approximation. In this paper these results are considerably extended and sharpened."
            },
            "slug": "Approximation-and-Radial-Basis-Function-Networks-Park-Sandberg",
            "title": {
                "fragments": [],
                "text": "Approximation and Radial-Basis-Function Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "It has been shown in recent papers that certain classes of radial-basis-function networks are broad enough for universal approximation, and results are considerably extended and sharpened."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145822375"
                        ],
                        "name": "G. Toussaint",
                        "slug": "G.-Toussaint",
                        "structuredName": {
                            "firstName": "Godfried",
                            "lastName": "Toussaint",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Toussaint"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9833144,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0508318a2363a7a2c7fd4dd8fed20891ec879c4",
            "isKey": false,
            "numCitedBy": 334,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "Articles, books, and technical reports on the theoretical and experimental estimation of probability of misclassification are listed for the case of correctly labeled or preclassified training data. By way of introduction, the problem of estimating the probability of misclassification is discussed in order to characterize the contributions of the literature."
            },
            "slug": "Bibliography-on-estimation-of-misclassification-Toussaint",
            "title": {
                "fragments": [],
                "text": "Bibliography on estimation of misclassification"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Articles, books, and technical reports on the theoretical and experimental estimation of probability of misclassification are listed for the case of correctly labeled or preclassified training data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144120350"
                        ],
                        "name": "J. Spencer",
                        "slug": "J.-Spencer",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Spencer",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Spencer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118848374,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "40d51dd0958a4324db60e867cb5183e43f069f31",
            "isKey": false,
            "numCitedBy": 481,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This is an examination of what is known about the probabilistic method. Based on the notes from the author's 1986 series of ten lectures, this edition features an additional lecture: The Janson Inequalities. These inequalities allow accurate approximation of extremely small probabilities."
            },
            "slug": "Ten-lectures-on-the-probabilistic-method-Spencer",
            "title": {
                "fragments": [],
                "text": "Ten lectures on the probabilistic method"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47161902"
                        ],
                        "name": "P. K. Bhattacharya",
                        "slug": "P.-K.-Bhattacharya",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Bhattacharya",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. K. Bhattacharya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144483119"
                        ],
                        "name": "Y. Mack",
                        "slug": "Y.-Mack",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Mack",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Mack"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120691341,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "425aa40a98e42046e18255aa39370c4434e04ad5",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "On considere le probleme sous une condition de lissite du second ordre dans le cas unidimensionnel"
            },
            "slug": "Weak-Convergence-of-$k$-NN-Density-and-Regression-Bhattacharya-Mack",
            "title": {
                "fragments": [],
                "text": "Weak Convergence of $k$-NN Density and Regression Estimators with Varying $k$ and Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2106531491"
                        ],
                        "name": "Q. Shi",
                        "slug": "Q.-Shi",
                        "structuredName": {
                            "firstName": "Qing-Yun",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97306284"
                        ],
                        "name": "K. Fu",
                        "slug": "K.-Fu",
                        "structuredName": {
                            "firstName": "King-Sun",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26551887,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "006daab0313fd348cd3b968a1f3eda8f2d14fc09",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-method-for-the-design-of-binary-tree-classifiers-Shi-Fu",
            "title": {
                "fragments": [],
                "text": "A method for the design of binary tree classifiers"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3228428"
                        ],
                        "name": "Y. Horibe",
                        "slug": "Y.-Horibe",
                        "structuredName": {
                            "firstName": "Yasuichi",
                            "lastName": "Horibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Horibe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44878081,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69ec1ae8f1a4ac2d61f9ab4e336bcc9467c979f3",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "In view of a certain randomized decision scheme, we simplify Renyi's result that concerns the conditions that a changing situation for binary decision must satisfy in order that the probability of decision errors tend to zero. We give its possible interpretation for a communication channel that has a tendency to become useless with time."
            },
            "slug": "On-zero-error-probability-of-binary-decisions-Horibe",
            "title": {
                "fragments": [],
                "text": "On zero error probability of binary decisions (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "This work simplify Renyi's result that concerns the conditions that a changing situation for binary decision must satisfy in order that the probability of decision errors tend to zero and gives its possible interpretation for a communication channel that has a tendency to become useless with time."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2016914"
                        ],
                        "name": "J. Tukey",
                        "slug": "J.-Tukey",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tukey",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tukey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7997450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e12d7b5498d251692d87abc3ee983c078fee7f5f",
            "isKey": false,
            "numCitedBy": 1652,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for the analysis of multivariate data is presented and is discussed in terms of specific examples. The algorithm seeks to find one-and two-dimensional linear projections of multivariate data that are relatively highly revealing."
            },
            "slug": "A-Projection-Pursuit-Algorithm-for-Exploratory-Data-Friedman-Tukey",
            "title": {
                "fragments": [],
                "text": "A Projection Pursuit Algorithm for Exploratory Data Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "An algorithm for the analysis of multivariate data is presented and is discussed in terms of specific examples to find one-and two-dimensional linear projections of multivariable data that are relatively highly revealing."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101269777"
                        ],
                        "name": "H. Carnal",
                        "slug": "H.-Carnal",
                        "structuredName": {
                            "firstName": "Henri",
                            "lastName": "Carnal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Carnal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119659937,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "eceb31b97df51b7bbc7ac255bb6003adc83d6032",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "SummaryThe number of edges An, the length ln and the surface Fn of the convex hull of n independent, identically distributed random points in the plane are considered under the assumption of rotational symmetry. The asymptotic behaviour of the expectations E(An), E(ln) and E(Fn) is studied according to the behaviour of the function Pr(\n$$Pr{\\text{(}}\\overline {OP} > x{\\text{) as }}x \\to {\\text{1}}$$\n as x \u2192 1 (distributions on the unit disc) or x\u2192\u221e (distributions on the whole plane)."
            },
            "slug": "Die-konvexe-H\u00fclle-von-n-rotationssymmetrisch-Carnal",
            "title": {
                "fragments": [],
                "text": "Die konvexe H\u00fclle von n rotationssymmetrisch verteilten Punkten"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087528"
                        ],
                        "name": "L. Gy\u00f6rfi",
                        "slug": "L.-Gy\u00f6rfi",
                        "structuredName": {
                            "firstName": "L\u00e1szl\u00f3",
                            "lastName": "Gy\u00f6rfi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gy\u00f6rfi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15581123,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ccbbdc0544103e8be83171b2c29537252b6b9952",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "For any sequence of empirical probability measures {\u03bc n } on the Borel sets of the real line and any \u03b4>0, there exists a singular continuous probability measure \u03bc such that inf \u2265sup n 9m n (A)-\u03bc(A)| A 1/2-\u03b4 almost surely"
            },
            "slug": "No-Empirical-Probability-Measure-can-Converge-in-Devroye-Gy\u00f6rfi",
            "title": {
                "fragments": [],
                "text": "No Empirical Probability Measure can Converge in the Total Variation Sense for all Distributions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723095"
                        ],
                        "name": "H. Simon",
                        "slug": "H.-Simon",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Simon",
                            "middleNames": [
                                "Ulrich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Simon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 205000337,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ff84d09533e797cf1e84fb5002beed8f480e5bb",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Vapnik-Chervonenkis-Dimension-of-Decision-Trees-Simon",
            "title": {
                "fragments": [],
                "text": "The Vapnik-Chervonenkis Dimension of Decision Trees with Bounded Rank"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Lett."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922810"
                        ],
                        "name": "P. Devijver",
                        "slug": "P.-Devijver",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Devijver",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Devijver"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34553053,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4218db9fcb4473f3601624214379b3b3b08680a2",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-note-on-ties-in-voting-with-the-k-NN-rule-Devijver",
            "title": {
                "fragments": [],
                "text": "A note on ties in voting with the k-NN rule"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49800308"
                        ],
                        "name": "B. Silverman",
                        "slug": "B.-Silverman",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Silverman",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Silverman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17174876,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "f9c35f35308d78650fc928720009e5c7039b9bd9",
            "isKey": false,
            "numCitedBy": 444,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "A simple method is presented for fitting regression models that are nonlinear in the explanatory variables. Despite its simplicity\u2014or perhaps because of it\u2014the method has some powerful characteristics that cause it to be competitive with and often superior to more sophisticated techniques, especially for small data sets in the presence of high noise."
            },
            "slug": "FLEXIBLE-PARSIMONIOUS-SMOOTHING-AND-ADDITIVE-Friedman-Silverman",
            "title": {
                "fragments": [],
                "text": "FLEXIBLE PARSIMONIOUS SMOOTHING AND ADDITIVE MODELING"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3120865"
                        ],
                        "name": "R. Baran",
                        "slug": "R.-Baran",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Baran",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Baran"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36106588,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "03ba214a649d7bdf44af864f5cc7192a0e0ead9b",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Comments-on-\"A-new-theoretical-and-algorithmical-by-Baran",
            "title": {
                "fragments": [],
                "text": "Comments on \"A new theoretical and algorithmical basis for estimation, identification and control\" by P. Kovanic"
            },
            "venue": {
                "fragments": [],
                "text": "Autom."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102530367"
                        ],
                        "name": "Adam Krzy ak",
                        "slug": "Adam-Krzy-ak",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "ak",
                            "middleNames": [
                                "Krzy"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Krzy ak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120802489,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "db02be358319004dba81adf704bde0560db2da51",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-equivalence-theorem-for-L1-convergence-of-the-Devroye-ak",
            "title": {
                "fragments": [],
                "text": "An equivalence theorem for L1 convergence of the kernel regression estimate"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48801723"
                        ],
                        "name": "F. Downton",
                        "slug": "F.-Downton",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Downton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Downton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4224834,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "555a7921231b86464a8db34ada9edade765bf8f0",
            "isKey": false,
            "numCitedBy": 439,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Stochastic ApproximationBy M. T. Wasan. (Cambridge Tracts in Mathematics and Mathematical Physics, No. 58.) Pp. x + 202. (Cambridge University Press: London, June 1969.) 70s; $9.50."
            },
            "slug": "Stochastic-Approximation-Downton",
            "title": {
                "fragments": [],
                "text": "Stochastic Approximation"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087528"
                        ],
                        "name": "L. Gy\u00f6rfi",
                        "slug": "L.-Gy\u00f6rfi",
                        "structuredName": {
                            "firstName": "L\u00e1szl\u00f3",
                            "lastName": "Gy\u00f6rfi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gy\u00f6rfi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44381087,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "172ca6eb468732fb335d3c893728aa8dd4cace46",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Under mild conditions on the observation processes the almost sure convergence properties of linear stochastic approximation are summarized for least squares and for some of its applications: adaptive filtering, echo cancellation, detection of binary data in Gaussian noise, identification, and linear classification."
            },
            "slug": "Adaptive-linear-procedures-under-general-conditions-Gy\u00f6rfi",
            "title": {
                "fragments": [],
                "text": "Adaptive linear procedures under general conditions"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Under mild conditions on the observation processes the almost sure convergence properties of linear stochastic approximation are summarized for least squares and for some of its applications: adaptive filtering, echo cancellation, detection of binary data in Gaussian noise, identification, and linear classification."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40763602"
                        ],
                        "name": "T. Broadbent",
                        "slug": "T.-Broadbent",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Broadbent",
                            "middleNames": [
                                "Andrew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Broadbent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4246815,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "009d7ec7b72cce6fc4227c1a189742bf2dedcc6a",
            "isKey": false,
            "numCitedBy": 542,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Mass und Integral und ihre AlgebraisierungVon Prof. C. Carath\u00e9odory. Herausgegeben von P. Finsler, A. Rosenthal und R. Steuerwald. (Lehrb\u00fccher und Monographien aus dem Gebiete der Exakten Wissenschaften. Mathematische Reihe, Band 10.) Pp. 337. (Basel und Stuttgart: Birkh\u00e4user Verlag, 1956.) 38.50 francs; 38.50 D.M."
            },
            "slug": "Measure-and-Integral-Broadbent",
            "title": {
                "fragments": [],
                "text": "Measure and Integral"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1957
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33406517"
                        ],
                        "name": "M. Goldstein",
                        "slug": "M.-Goldstein",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Goldstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Goldstein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41986962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45b067f826817e1bf87c01b976da2837250dfca9",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A two-group classification procedure for multivariate binary data is presented and discussed for the case of independent samples. The rule utilizes an orthogonal series expansion for state probabilities and introduces a method to achieve parsimony in modeling in accordance with a condition of optimality. In addition, the classification procedure gives a method for dealing with the difficult problem of sparseness, a condition which frequently causes problems in applying discrete methods to frequency data."
            },
            "slug": "A-Two-Group-Classification-Procedure-For-Responses.-Goldstein",
            "title": {
                "fragments": [],
                "text": "A Two-Group Classification Procedure For Multivariate Dichotomous Responses."
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A two-group classification procedure for multivariate binary data is presented and discussed for the case of independent samples and gives a method for dealing with the difficult problem of sparseness."
            },
            "venue": {
                "fragments": [],
                "text": "Multivariate behavioral research"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145004630"
                        ],
                        "name": "M. Anthony",
                        "slug": "M.-Anthony",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Anthony",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Anthony"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10570532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "306c40863d0c9d57b238b980bb288b008425b475",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Result-of-Vapnik-with-Applications-Anthony-Shawe-Taylor",
            "title": {
                "fragments": [],
                "text": "A Result of Vapnik with Applications"
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Appl. Math."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1847175"
                        ],
                        "name": "M. Minsky",
                        "slug": "M.-Minsky",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Minsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Minsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2434678"
                        ],
                        "name": "S. Papert",
                        "slug": "S.-Papert",
                        "structuredName": {
                            "firstName": "Seymour",
                            "lastName": "Papert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Papert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5400596,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f74ded11f72099d16591a1191d72262ae6b5f14a",
            "isKey": false,
            "numCitedBy": 3040,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Cambridge, Mass.: MIT Press, 1972. 2nd. ed. The book's aim is to seek general results from the close study of abstract version of devices known as perceptrons"
            },
            "slug": "Perceptrons-an-introduction-to-computational-Minsky-Papert",
            "title": {
                "fragments": [],
                "text": "Perceptrons - an introduction to computational geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The aim of this book is to seek general results from the close study of abstract version of devices known as perceptrons."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145695738"
                        ],
                        "name": "F. Preparata",
                        "slug": "F.-Preparata",
                        "structuredName": {
                            "firstName": "Franco",
                            "lastName": "Preparata",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Preparata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1890127"
                        ],
                        "name": "M. Shamos",
                        "slug": "M.-Shamos",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Shamos",
                            "middleNames": [
                                "Ian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shamos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120573598,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "fd9c5c52a26e99e6bc3155db67cb94efe6054e04",
            "isKey": false,
            "numCitedBy": 6837,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the reviews: \"This book offers a coherent treatment, at the graduate textbook level, of the field that has come to be known in the last decade or so as computational geometry...The book is well organized and lucidly written; a timely contribution by two founders of the field. It clearly demonstrates that computational geometry in the plane is now a fairly well-understood branch of computer science and mathematics. It also points the way to the solution of the more challenging problems in dimensions higher than two.\""
            },
            "slug": "Computational-geometry:-an-introduction-Preparata-Shamos",
            "title": {
                "fragments": [],
                "text": "Computational geometry: an introduction"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This book offers a coherent treatment, at the graduate textbook level, of the field that has come to be known in the last decade or so as computational geometry."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143945533"
                        ],
                        "name": "R. Kemp",
                        "slug": "R.-Kemp",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Kemp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kemp"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34423727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a16264103bcae03977d63daf794fc9ce54129a3f",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A careful and cogent analysis of the average-case behavior of a variety of algorithms accompanied by mathematical calculations. The analysis consists of determining the behavior of an algorithm in the best, worst, and average case. Material is outlined in various exercises and problems."
            },
            "slug": "Fundamentals-of-the-average-case-analysis-of-Kemp",
            "title": {
                "fragments": [],
                "text": "Fundamentals of the average case analysis of particular algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A careful and cogent analysis of the average-case behavior of a variety of algorithms accompanied by mathematical calculations is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Wiley-Teubner series in computer science"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144018201"
                        ],
                        "name": "G. Forney",
                        "slug": "G.-Forney",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Forney",
                            "middleNames": [
                                "David"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Forney"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28736014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90a565559dcb438e24db4bd9fc53b38f30cad267",
            "isKey": false,
            "numCitedBy": 322,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "By an extension of Gallager's bounding methods, exponential error bounds applicable to coding schemes involving erasures, variable-size lists, and decision feedback are obtained. The bounds are everywhere the tightest known."
            },
            "slug": "Exponential-error-bounds-for-erasure,-list,-and-Forney",
            "title": {
                "fragments": [],
                "text": "Exponential error bounds for erasure, list, and decision feedback schemes"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "By an extension of Gallager's bounding methods, exponential error bounds applicable to coding schemes involving erasures, variable-size lists, and decision feedback are obtained, which are everywhere the tightest known."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3123130"
                        ],
                        "name": "G. Stengle",
                        "slug": "G.-Stengle",
                        "structuredName": {
                            "firstName": "Gilbert",
                            "lastName": "Stengle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Stengle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145535366"
                        ],
                        "name": "J. Yukich",
                        "slug": "J.-Yukich",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Yukich",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yukich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121950838,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4ce8c4020286ffde7da6ead8f641000a0aff04ce",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "On utilise la theorie des ensembles semi-algebriques pour creer de nouvelles classes de Vapnik-Chervonenkis (VC) d'ensembles de positivite. Il est montre aussi que certaines familles analytiques d'ensembles de positivite sont VC"
            },
            "slug": "Some-new-Vapnik-Chervonenkis-classes-Stengle-Yukich",
            "title": {
                "fragments": [],
                "text": "Some new Vapnik-Chervonenkis classes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2346824"
                        ],
                        "name": "J. Morgan",
                        "slug": "J.-Morgan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Morgan",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10775760"
                        ],
                        "name": "J. Sonquist",
                        "slug": "J.-Sonquist",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Sonquist",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sonquist"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1825515,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "957728a4244d3b323e98e351098a0125382f1199",
            "isKey": false,
            "numCitedBy": 1193,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Most of the problems of analyzing survey data have been reasonably well handled, except those revolving around the existence of interaction effects. Indeed, increased efficiency in handling multivariate analyses even with non-numerical variables, has been achieved largely by assuming additivity. An approach to survey data is proposed which imposes no restrictions on interaction effects, focuses on Importance in reducing predictive error, operates sequentially, and is independent of the extent of linearity in the classifications or the order in which the explanatory factors are introduced."
            },
            "slug": "Problems-in-the-Analysis-of-Survey-Data,-and-a-Morgan-Sonquist",
            "title": {
                "fragments": [],
                "text": "Problems in the Analysis of Survey Data, and a Proposal"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30821484"
                        ],
                        "name": "E. Nadaraya",
                        "slug": "E.-Nadaraya",
                        "structuredName": {
                            "firstName": "Elizbar",
                            "lastName": "Nadaraya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Nadaraya"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120067924,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "05175204318c3c01e3301fd864553071039605d2",
            "isKey": false,
            "numCitedBy": 3287,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A study is made of certain properties of an approximation to the regression line on the basis of sampling data when the sample size increases unboundedly."
            },
            "slug": "On-Estimating-Regression-Nadaraya",
            "title": {
                "fragments": [],
                "text": "On Estimating Regression"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1958412,
            "fieldsOfStudy": [
                "Education",
                "Mathematics"
            ],
            "id": "274ba2f97f4ee527997cd5cd7080ffe600bd8264",
            "isKey": false,
            "numCitedBy": 257,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Consider an item that belongs to one of two classes, ? = 0 or ? = 1, with equal probability. Suppose also that there are two measurement experiments E1 and E2 that can be performed, and suppose that the outcomes are independent (given ?). Let Ei? denote an independent performance of experiment Ei. Let Pe(E) denote the probability of error resulting from the performance of experiment E. Elashoff [1] gives an example of three experiments E1,E2,E3 such that Pe(E1) < Pe(E2) < Pe(E3), but Pe(E1,E3) < Pe(E1,E2). Toussaint [2] exhibits binary valued experiments satisfying Pe(E1) < Pe(E2) < Pe(E3), such that Pe(E2,E3) < Pe(E1,E3) < Pe(E1,E2). We shall give an example of binary valued experiments E1 and E2 such that Pe(E1) < Pe(E2), but Pe(E2,E2?) < Pe(E1,E2) < Pe(E1,E1?). Thus if one observation is allowed, E1 is the best experiment. If two observations are allowed, then two independent copies of the ``worst'' experiment E2 are preferred. This is true despite the conditional independence of the observations."
            },
            "slug": "The-Best-Two-Independent-Measurements-Are-Not-the-Cover",
            "title": {
                "fragments": [],
                "text": "The Best Two Independent Measurements Are Not the Two Best"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "If two observations are allowed, then two independent copies of the ``worst'' experiment E2 are preferred, and if one observation is allowed, E1 is the best experiment."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19355,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144336939"
                        ],
                        "name": "D. Nolan",
                        "slug": "D.-Nolan",
                        "structuredName": {
                            "firstName": "Deborah",
                            "lastName": "Nolan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nolan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143689789"
                        ],
                        "name": "D. Pollard",
                        "slug": "D.-Pollard",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pollard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pollard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120790247,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c200a40faccb0d6e4557b8e93ba6cf020b5cc702",
            "isKey": false,
            "numCitedBy": 405,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "On introduit un nouveau processus stochastique, une collection de statistiques U indicees par une famille de noyaux symetriques. On obtient des conditions pour la convergence presque sure uniforme d'une suite de tels processus"
            },
            "slug": "$U$-Processes:-Rates-of-Convergence-Nolan-Pollard",
            "title": {
                "fragments": [],
                "text": "$U$-Processes: Rates of Convergence"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2692987"
                        ],
                        "name": "Huaiyu Zhu",
                        "slug": "Huaiyu-Zhu",
                        "structuredName": {
                            "firstName": "Huaiyu",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huaiyu Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 116908168,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "87cbed883368d4a9efd42fdd91f47038f8d8fbe6",
            "isKey": false,
            "numCitedBy": 6004,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The information deviation between any two finite measures cannot be increased by any statistical operations (Markov morphisms). It is invarient if and only if the morphism is sufficient for these two measures"
            },
            "slug": "On-Information-and-Sufficiency-Zhu",
            "title": {
                "fragments": [],
                "text": "On Information and Sufficiency"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881615"
                        ],
                        "name": "R. Dudley",
                        "slug": "R.-Dudley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dudley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dudley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122435010,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "445d61a1a1d12ceb0f9b5deea0a7bada2979bdfe",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Balls-in-Rk-do-not-cut-all-subsets-of-k-+-2-points-Dudley",
            "title": {
                "fragments": [],
                "text": "Balls in Rk do not cut all subsets of k + 2 points"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14942773"
                        ],
                        "name": "M. Stone",
                        "slug": "M.-Stone",
                        "structuredName": {
                            "firstName": "Mervyn",
                            "lastName": "Stone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62698647,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "7b28610d2d681a11398eb614de0d70d7de41c20c",
            "isKey": false,
            "numCitedBy": 7501,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY A generalized form of the cross-validation criterion is applied to the choice and assessment of prediction using the data-analytic concept of a prescription. The examples used to illustrate the application are drawn from the problem areas of univariate estimation, linear regression and analysis of variance."
            },
            "slug": "Cross\u2010Validatory-Choice-and-Assessment-of-Stone",
            "title": {
                "fragments": [],
                "text": "Cross\u2010Validatory Choice and Assessment of Statistical Predictions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2707896"
                        ],
                        "name": "B. Logan",
                        "slug": "B.-Logan",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Logan",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Logan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118455418,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2574d411fbd5851dc760f6fa97383d7f62db486a",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-uncertainty-principle-in-reconstructing-from-Logan",
            "title": {
                "fragments": [],
                "text": "The uncertainty principle in reconstructing functions from projections"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2545803"
                        ],
                        "name": "M. Aizerman",
                        "slug": "M.-Aizerman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Aizerman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Aizerman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60493317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3caf34c1c86633b6e80dca29e3cb2b6367a0f93",
            "isKey": false,
            "numCitedBy": 1692,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Theoretical-Foundations-of-the-Potential-Function-Aizerman",
            "title": {
                "fragments": [],
                "text": "Theoretical Foundations of the Potential Function Method in Pattern Recognition Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103166785"
                        ],
                        "name": "Mikhail Borisovich Nevel\u02b9son",
                        "slug": "Mikhail-Borisovich-Nevel\u02b9son",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Nevel\u02b9son",
                            "middleNames": [
                                "Borisovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikhail Borisovich Nevel\u02b9son"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103118521"
                        ],
                        "name": "R. Z. Khas\u02b9minski\u012d",
                        "slug": "R.-Z.-Khas\u02b9minski\u012d",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Khas\u02b9minski\u012d",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Z. Khas\u02b9minski\u012d"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117764225,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "5d51d19d4f62a90677c4630603507cd873d7a5cb",
            "isKey": false,
            "numCitedBy": 408,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An extrusion head for an extrudable material, such as a food product dough, which is to be formed into a special shape, such as a pretzel configuration. The head includes a die and associated parts which are of such character and construction that portions of the extruded material will differ in width and thickness from other portions."
            },
            "slug": "Stochastic-Approximation-and-Recursive-Estimation-Nevel\u02b9son-Khas\u02b9minski\u012d",
            "title": {
                "fragments": [],
                "text": "Stochastic Approximation and Recursive Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "An extrusion head for an extrudable material, such as a food product dough, which is to be formed into a special shape,such as a pretzel configuration, includes a die and associated parts which are of such character and construction that portions of the extruded material will differ in width and thickness from other portions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105353"
                        ],
                        "name": "K. Narendra",
                        "slug": "K.-Narendra",
                        "structuredName": {
                            "firstName": "Kumpati",
                            "lastName": "Narendra",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Narendra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62742604,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "624d7d56f98f29e96c36493b2a9e1820ec53725d",
            "isKey": false,
            "numCitedBy": 365,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Concrete"
            },
            "slug": "Adaptation-and-learning-in-automatic-systems-Narendra",
            "title": {
                "fragments": [],
                "text": "Adaptation and learning in automatic systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1460233548"
                        ],
                        "name": "Saab Abou-Jaoud\u00e9",
                        "slug": "Saab-Abou-Jaoud\u00e9",
                        "structuredName": {
                            "firstName": "Saab",
                            "lastName": "Abou-Jaoud\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saab Abou-Jaoud\u00e9"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 230002328,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ec0cd1dedf700c7a75e1681c354176e3dd5297ac",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Sur-la-convergence-L1-et-L\u221e-de-l'estimateur-de-la-Abou-Jaoud\u00e9",
            "title": {
                "fragments": [],
                "text": "Sur la convergence L1 et L\u221e de l'estimateur de la partition al\u00e9atoire pour une densit\u00e9"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3061715"
                        ],
                        "name": "J. Fritz",
                        "slug": "J.-Fritz",
                        "structuredName": {
                            "firstName": "J\u00f3zsef",
                            "lastName": "Fritz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fritz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087528"
                        ],
                        "name": "L. Gy\u00f6rfi",
                        "slug": "L.-Gy\u00f6rfi",
                        "structuredName": {
                            "firstName": "L\u00e1szl\u00f3",
                            "lastName": "Gy\u00f6rfi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gy\u00f6rfi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 202768219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0dc9acbd4f3b35d4dd3bb83fb7b1384f0bb890e3",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "ON-THE-MINIMIZATION-OF-CLASSIFICATION-ERROR-IN-Fritz-Gy\u00f6rfi",
            "title": {
                "fragments": [],
                "text": "ON THE MINIMIZATION OF CLASSIFICATION ERROR PROBABILITY IN STATISTICAL PATTERN RECOGNITION."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2662980"
                        ],
                        "name": "R. Winder",
                        "slug": "R.-Winder",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Winder",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Winder"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 196170972,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e771dc88fc0da0d48b48f875eb7de4c192d1e4f",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "THRESHOLD-LOGIC-IN-ARTIFICIAL-INTELLIGENCE-Winder",
            "title": {
                "fragments": [],
                "text": "THRESHOLD LOGIC IN ARTIFICIAL INTELLIGENCE"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12481981"
                        ],
                        "name": "P. Mahalanobis",
                        "slug": "P.-Mahalanobis",
                        "structuredName": {
                            "firstName": "Prasanta",
                            "lastName": "Mahalanobis",
                            "middleNames": [
                                "Chandra"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mahalanobis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 156177326,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "2295d1be48d0af087c563965588ac6ff837b36a8",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Method-of-Fractile-Graphical-Analysis-Mahalanobis",
            "title": {
                "fragments": [],
                "text": "A Method of Fractile Graphical Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1960
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39784561"
                        ],
                        "name": "M. Hills",
                        "slug": "M.-Hills",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Hills",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hills"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 126107402,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5f9d8d34e734e3f26adb79bedfba673d5e4a20ce",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Allocation-Rules-and-Their-Error-Rates-Hills",
            "title": {
                "fragments": [],
                "text": "Allocation Rules and Their Error Rates"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3331395"
                        ],
                        "name": "G. Rota",
                        "slug": "G.-Rota",
                        "structuredName": {
                            "firstName": "Gian-Carlo",
                            "lastName": "Rota",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Rota"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 126074139,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "ca58e0ead1a5cd6915e718ed0f7c554f5c6bbab0",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Basic-Concepts-in-Information-Theory-and-A.M.-P.N.-Rota",
            "title": {
                "fragments": [],
                "text": "Basic Concepts in Information Theory and Statistics, A.M. Mathai, P.N. Rathie. Wiley (1975), 137 pp"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1477347096"
                        ],
                        "name": "Abdel Hamid Ben-Tchikou",
                        "slug": "Abdel-Hamid-Ben-Tchikou",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Ben-Tchikou",
                            "middleNames": [
                                "Hamid"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel Hamid Ben-Tchikou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 125968547,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fd872d0a3f8ec16b63cfd2abeb4739b21fdc10a7",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-Karhunen-Loeve-expansion-/-Ben-Tchikou",
            "title": {
                "fragments": [],
                "text": "On the Karhunen-Loeve expansion /"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2815634"
                        ],
                        "name": "E. Sampathkumar",
                        "slug": "E.-Sampathkumar",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Sampathkumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sampathkumar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 126220495,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "969ace3ca9725d6c282dd13690a243e7cf1ed320",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-a-class-of-sets\u2014I-Sampathkumar",
            "title": {
                "fragments": [],
                "text": "On a class of sets\u2014I"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059644254"
                        ],
                        "name": "P. Deheuvels",
                        "slug": "P.-Deheuvels",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Deheuvels",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Deheuvels"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125892039,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f2f205a296a1051ce9d9a2a3c5dff58a044ddc88",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Estimation-non-param\u00e9trique-de-la-densit\u00e9-par-Deheuvels",
            "title": {
                "fragments": [],
                "text": "Estimation non param\u00e9trique de la densit\u00e9 par histogrammes g\u00e9n\u00e9ralis\u00e9s"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143929773"
                        ],
                        "name": "M. C. Jones",
                        "slug": "M.-C.-Jones",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Jones",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. C. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33734211"
                        ],
                        "name": "R. Sibson",
                        "slug": "R.-Sibson",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Sibson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sibson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125481163,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "1ebb53a7e5cff86b2b42d1108a0fa81f571d8894",
            "isKey": false,
            "numCitedBy": 1404,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "What-is-projection-pursuit-Jones-Sibson",
            "title": {
                "fragments": [],
                "text": "What is projection pursuit"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2679330"
                        ],
                        "name": "J. Burbea",
                        "slug": "J.-Burbea",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Burbea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burbea"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123979739,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "68a3ddf38d06cdd153813b9012fb24d4f5c63b3e",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-convexity-with-respect-to-Gaussian-of-of-order-Burbea",
            "title": {
                "fragments": [],
                "text": "The convexity with respect to Gaussian distributions of divergences of order a"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145913258"
                        ],
                        "name": "N. Glick",
                        "slug": "N.-Glick",
                        "structuredName": {
                            "firstName": "Ned",
                            "lastName": "Glick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Glick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124920677,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f543f3f5c1c66c2293dc7030a80327af42555e8c",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Sample-Based-Multinomial-Classification-Glick",
            "title": {
                "fragments": [],
                "text": "Sample-Based Multinomial Classification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "89017381"
                        ],
                        "name": "G. Collomb",
                        "slug": "G.-Collomb",
                        "structuredName": {
                            "firstName": "G\u00e9rard",
                            "lastName": "Collomb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Collomb"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124916545,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7be697e236cc8d372c0e1d1a9d16d1e412a185d2",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Estimation-Non-param\u00e9trique-de-la-R\u00e9gression:-Revue-Collomb",
            "title": {
                "fragments": [],
                "text": "Estimation Non-param\u00e9trique de la R\u00e9gression: Revue Bibliographique@@@Estimation Non-parametrique de la Regression: Revue Bibliographique"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145217017"
                        ],
                        "name": "J. Habbema",
                        "slug": "J.-Habbema",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Habbema",
                            "middleNames": [
                                "Dik",
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Habbema"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123794032,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7aa756c56be7039add7a07227a470d8b33842732",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-stepwise-discriminant-analysis-program-using-Habbema",
            "title": {
                "fragments": [],
                "text": "A stepwise discriminant analysis program using density estimetion"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48566708"
                        ],
                        "name": "G. S. Watson",
                        "slug": "G.-S.-Watson",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Watson",
                            "middleNames": [
                                "Stuart"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. S. Watson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124218927,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "14821ac1bf09890a857fca2a6c324e8c85f2c0d0",
            "isKey": false,
            "numCitedBy": 2957,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Smooth-regression-analysis-Watson",
            "title": {
                "fragments": [],
                "text": "Smooth regression analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259965"
                        ],
                        "name": "D. Matula",
                        "slug": "D.-Matula",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Matula",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Matula"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5967937"
                        ],
                        "name": "R. Sokal",
                        "slug": "R.-Sokal",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Sokal",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sokal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122528297,
            "fieldsOfStudy": [
                "Geography",
                "Mathematics"
            ],
            "id": "76b7cb1607a3abc0a50aaa722ffef927705aa434",
            "isKey": false,
            "numCitedBy": 379,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Properties-of-Gabriel-Graphs-Relevant-to-Geographic-Matula-Sokal",
            "title": {
                "fragments": [],
                "text": "Properties of Gabriel Graphs Relevant to Geographic Variation Research and the Clustering of Points in the Plane"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102877553"
                        ],
                        "name": "R. Rao",
                        "slug": "R.-Rao",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Rao",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 123302743,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "bd8fd8075999a20633f4d81c69d91ccb30c3e033",
            "isKey": false,
            "numCitedBy": 323,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Relations-between-Weak-and-Uniform-Convergence-of-Rao",
            "title": {
                "fragments": [],
                "text": "Relations between Weak and Uniform Convergence of Measures with Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143689789"
                        ],
                        "name": "D. Pollard",
                        "slug": "D.-Pollard",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pollard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pollard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 123267550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8ec24ca66b81fee9f03f34e8552647f612817fb",
            "isKey": false,
            "numCitedBy": 461,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Strong-Consistency-of-$K$-Means-Clustering-Pollard",
            "title": {
                "fragments": [],
                "text": "Strong Consistency of $K$-Means Clustering"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73756592"
                        ],
                        "name": "M. Gessaman",
                        "slug": "M.-Gessaman",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "Gessaman",
                            "middleNames": [
                                "Palmer"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gessaman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122866693,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d4a45ef9bc8a92f63207e062b025fbcb937fcf4d",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Consistent-Nonparametric-Multivariate-Density-on-Gessaman",
            "title": {
                "fragments": [],
                "text": "A Consistent Nonparametric Multivariate Density Estimator Based on Statistically Equivalent Blocks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145024674"
                        ],
                        "name": "R. Beran",
                        "slug": "R.-Beran",
                        "structuredName": {
                            "firstName": "Rudolf",
                            "lastName": "Beran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Beran"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122903622,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3de8bb30ea70431e772fc47d3cc796e0cc92c591",
            "isKey": false,
            "numCitedBy": 658,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Minimum-Hellinger-distance-estimates-for-parametric-Beran",
            "title": {
                "fragments": [],
                "text": "Minimum Hellinger distance estimates for parametric models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753450"
                        ],
                        "name": "D. Burshtein",
                        "slug": "D.-Burshtein",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Burshtein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burshtein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749064"
                        ],
                        "name": "D. Kanevsky",
                        "slug": "D.-Kanevsky",
                        "structuredName": {
                            "firstName": "Dimitri",
                            "lastName": "Kanevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kanevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150023694"
                        ],
                        "name": "A. N\u00e1das",
                        "slug": "A.-N\u00e1das",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "N\u00e1das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. N\u00e1das"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122380821,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dfb22c62984f86c3604082d6265146da206ba510",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Minimum-Impurity-Partitions-Burshtein-Pietra",
            "title": {
                "fragments": [],
                "text": "Minimum Impurity Partitions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14616530"
                        ],
                        "name": "L. Lecam",
                        "slug": "L.-Lecam",
                        "structuredName": {
                            "firstName": "Lucien",
                            "lastName": "Lecam",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lecam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122957559,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "60cd5b24efafa4fcdbef0fd968ce95f76947c550",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-Assumptions-Used-to-Prove-Asymptotic-of-Lecam",
            "title": {
                "fragments": [],
                "text": "On the Assumptions Used to Prove Asymptotic Normality of Maximum Likelihood Estimates"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122615695,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6b570e21aaa810a821f25da5044f07c501ca2b86",
            "isKey": false,
            "numCitedBy": 528,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Course-in-Density-Estimation-Devroye",
            "title": {
                "fragments": [],
                "text": "A Course in Density Estimation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102383712"
                        ],
                        "name": "K. Matusita",
                        "slug": "K.-Matusita",
                        "structuredName": {
                            "firstName": "Kameo",
                            "lastName": "Matusita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Matusita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122556114,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77942a84bae63a2789d71531c34ce3f06e50051d",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Decision-rule,-based-on-the-distance,-for-the-Matusita",
            "title": {
                "fragments": [],
                "text": "Decision rule, based on the distance, for the classification problem"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1956
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72927011"
                        ],
                        "name": "H. Cram\u00e9r",
                        "slug": "H.-Cram\u00e9r",
                        "structuredName": {
                            "firstName": "Harald",
                            "lastName": "Cram\u00e9r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Cram\u00e9r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145870717"
                        ],
                        "name": "H. Wold",
                        "slug": "H.-Wold",
                        "structuredName": {
                            "firstName": "Herman",
                            "lastName": "Wold",
                            "middleNames": [
                                "O.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wold"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122761325,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fb22bcd5b3432b5ca19177b13e52b0c7ede6bcca",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Some-Theorems-on-Distribution-Functions-Cram\u00e9r-Wold",
            "title": {
                "fragments": [],
                "text": "Some Theorems on Distribution Functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1936
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153166837"
                        ],
                        "name": "W. Rogers",
                        "slug": "W.-Rogers",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Rogers",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Rogers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940156"
                        ],
                        "name": "T. Wagner",
                        "slug": "T.-Wagner",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Wagner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wagner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121351100,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7f28e8a42978eb3a20fadf42594fa94fff67015d",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Finite-Sample-Distribution-Free-Performance-Bound-Rogers-Wagner",
            "title": {
                "fragments": [],
                "text": "A Finite Sample Distribution-Free Performance Bound for Local Discrimination Rules"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2658455"
                        ],
                        "name": "E. Gin\u00e9",
                        "slug": "E.-Gin\u00e9",
                        "structuredName": {
                            "firstName": "Eva",
                            "lastName": "Gin\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gin\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715480"
                        ],
                        "name": "J. Zinn",
                        "slug": "J.-Zinn",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Zinn",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zinn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121441769,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c3c298fe9558b2157c56b5940f3d742f45b1a360",
            "isKey": false,
            "numCitedBy": 434,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Some-Limit-Theorems-for-Empirical-Processes-Gin\u00e9-Zinn",
            "title": {
                "fragments": [],
                "text": "Some Limit Theorems for Empirical Processes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2706323"
                        ],
                        "name": "H. Chernoff",
                        "slug": "H.-Chernoff",
                        "structuredName": {
                            "firstName": "Herman",
                            "lastName": "Chernoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Chernoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122118814,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "bc22d1610ce680c91b4323a1899b1f22cfdf533f",
            "isKey": false,
            "numCitedBy": 3428,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Measure-of-Asymptotic-Efficiency-for-Tests-of-a-Chernoff",
            "title": {
                "fragments": [],
                "text": "A Measure of Asymptotic Efficiency for Tests of a Hypothesis Based on the sum of Observations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1952
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2837737"
                        ],
                        "name": "M. Talagrand",
                        "slug": "M.-Talagrand",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Talagrand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Talagrand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121540156,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "debfa130d31d4fee331519472a305ccb00c303b0",
            "isKey": false,
            "numCitedBy": 517,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Sharper-Bounds-for-Gaussian-and-Empirical-Processes-Talagrand",
            "title": {
                "fragments": [],
                "text": "Sharper Bounds for Gaussian and Empirical Processes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72811536"
                        ],
                        "name": "T. Cacoullos",
                        "slug": "T.-Cacoullos",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Cacoullos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cacoullos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 120806240,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "37259a2ae44002790febdc7aa07fbb260f5d2eee",
            "isKey": false,
            "numCitedBy": 659,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Estimation-of-a-multivariate-density-Cacoullos",
            "title": {
                "fragments": [],
                "text": "Estimation of a multivariate density"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102553534"
                        ],
                        "name": "W. Grassman",
                        "slug": "W.-Grassman",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grassman",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grassman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121204099,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6dbe876353c0cc2890b682bc26ac36b475139fec",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Approximation-and-Weak-Convergence-Methods-for-with-Grassman",
            "title": {
                "fragments": [],
                "text": "Approximation and Weak Convergence Methods for Random Processes with Applications to Stochastic Systems Theory (Harold J. Kushner)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47267396"
                        ],
                        "name": "A. Dvoretzky",
                        "slug": "A.-Dvoretzky",
                        "structuredName": {
                            "firstName": "Aryeh",
                            "lastName": "Dvoretzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dvoretzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227161"
                        ],
                        "name": "J. Kiefer",
                        "slug": "J.-Kiefer",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Kiefer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kiefer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50226899"
                        ],
                        "name": "J. Wolfowitz",
                        "slug": "J.-Wolfowitz",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Wolfowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wolfowitz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122299729,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "00936a6bb9d35908640da9043b3f5a955014d478",
            "isKey": false,
            "numCitedBy": 880,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Asymptotic-Minimax-Character-of-the-Sample-Function-Dvoretzky-Kiefer",
            "title": {
                "fragments": [],
                "text": "Asymptotic Minimax Character of the Sample Distribution Function and of the Classical Multinomial Estimator"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1956
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41192545"
                        ],
                        "name": "H. Scheff\u00e9",
                        "slug": "H.-Scheff\u00e9",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Scheff\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Scheff\u00e9"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121470890,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1af659ab86ff70db471554a1e2ac0a1899c99853",
            "isKey": false,
            "numCitedBy": 262,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Useful-Convergence-Theorem-for-Probability-Scheff\u00e9",
            "title": {
                "fragments": [],
                "text": "A Useful Convergence Theorem for Probability Distributions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1947
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785855"
                        ],
                        "name": "W. Greblicki",
                        "slug": "W.-Greblicki",
                        "structuredName": {
                            "firstName": "W\u0142odzimierz",
                            "lastName": "Greblicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Greblicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9745969"
                        ],
                        "name": "A. Krzy\u017cak",
                        "slug": "A.-Krzy\u017cak",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Krzy\u017cak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krzy\u017cak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143803534"
                        ],
                        "name": "M. Pawlak",
                        "slug": "M.-Pawlak",
                        "structuredName": {
                            "firstName": "Miroslaw",
                            "lastName": "Pawlak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pawlak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121908610,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ded1167ddd247aaaa3e7621f30e8ea27799a7d8e",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Distribution-Free-Pointwise-Consistency-of-Kernel-Greblicki-Krzy\u017cak",
            "title": {
                "fragments": [],
                "text": "Distribution-Free Pointwise Consistency of Kernel Regression Estimate"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48982805"
                        ],
                        "name": "M. Okamoto",
                        "slug": "M.-Okamoto",
                        "structuredName": {
                            "firstName": "Masashi",
                            "lastName": "Okamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Okamoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122049911,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "08d7af5882105cce38342c73f872d7f2a04de541",
            "isKey": false,
            "numCitedBy": 199,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Some-inequalities-relating-to-the-partial-sum-of-Okamoto",
            "title": {
                "fragments": [],
                "text": "Some inequalities relating to the partial sum of binomial probabilities"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2008035"
                        ],
                        "name": "W. Stute",
                        "slug": "W.-Stute",
                        "structuredName": {
                            "firstName": "Winfried",
                            "lastName": "Stute",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Stute"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121102443,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4c90858e5afcf06ffbd64c04c92e7239f333117e",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Asymptotic-Normality-of-Nearest-Neighbor-Regression-Stute",
            "title": {
                "fragments": [],
                "text": "Asymptotic Normality of Nearest Neighbor Regression Function Estimates"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227161"
                        ],
                        "name": "J. Kiefer",
                        "slug": "J.-Kiefer",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Kiefer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kiefer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50226899"
                        ],
                        "name": "J. Wolfowitz",
                        "slug": "J.-Wolfowitz",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Wolfowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wolfowitz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122078986,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f4e3738a90f9cc806a25c8739e0d8b892ee7d1ff",
            "isKey": false,
            "numCitedBy": 1841,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Stochastic-Estimation-of-the-Maximum-of-a-Function-Kiefer-Wolfowitz",
            "title": {
                "fragments": [],
                "text": "Stochastic Estimation of the Maximum of a Regression Function"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1952
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000820"
                        ],
                        "name": "E. Slud",
                        "slug": "E.-Slud",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Slud",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Slud"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120792465,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "97df7de2caa03d74b142a1ceb24157d3fe39e155",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Distribution-Inequalities-for-the-Binomial-Law-Slud",
            "title": {
                "fragments": [],
                "text": "Distribution Inequalities for the Binomial Law"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14616530"
                        ],
                        "name": "L. Lecam",
                        "slug": "L.-Lecam",
                        "structuredName": {
                            "firstName": "Lucien",
                            "lastName": "Lecam",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lecam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120275951,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a6a60904cf306f7a464b45d5be34894ad6d3254a",
            "isKey": false,
            "numCitedBy": 428,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Convergence-of-Estimates-Under-Dimensionality-Lecam",
            "title": {
                "fragments": [],
                "text": "Convergence of Estimates Under Dimensionality Restrictions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73497302"
                        ],
                        "name": "J. E. Jackson",
                        "slug": "J.-E.-Jackson",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Jackson",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. E. Jackson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120938046,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1ffff8805a93f3d4b3ea85faed08c8e94db93000",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Discrete-discriminant-analysis-Jackson",
            "title": {
                "fragments": [],
                "text": "Discrete discriminant analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732346"
                        ],
                        "name": "S. Schwartz",
                        "slug": "S.-Schwartz",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Schwartz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120011872,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2e5229a295a6e9c81a3396358e84a69d820bd136",
            "isKey": false,
            "numCitedBy": 222,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Estimation-of-Probability-Density-by-an-Orthogonal-Schwartz",
            "title": {
                "fragments": [],
                "text": "Estimation of Probability Density by an Orthogonal Series"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1834278"
                        ],
                        "name": "A. Chervonenkis",
                        "slug": "A.-Chervonenkis",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Chervonenkis",
                            "middleNames": [
                                "Ya."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chervonenkis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120020259,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1861a3dcc41bbab284766d57e19accc2a86eadbc",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Necessary-and-Sufficient-Conditions-for-the-Uniform-Vapnik-Chervonenkis",
            "title": {
                "fragments": [],
                "text": "Necessary and Sufficient Conditions for the Uniform Convergence of Means to their Expectations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102818203"
                        ],
                        "name": "Hirosi Hudimoto",
                        "slug": "Hirosi-Hudimoto",
                        "structuredName": {
                            "firstName": "Hirosi",
                            "lastName": "Hudimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hirosi Hudimoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120694535,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "72f77280c51dffae002933055c15dc28e760e391",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Note-on-the-probability-of-the-correct-when-the-Hudimoto",
            "title": {
                "fragments": [],
                "text": "A Note on the probability of the correct classification when the distributions are not specified"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737945"
                        ],
                        "name": "H. Akaike",
                        "slug": "H.-Akaike",
                        "structuredName": {
                            "firstName": "Hirotugu",
                            "lastName": "Akaike",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Akaike"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120904654,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d37a13aca0b22dac2117342448da9b916b92d8a7",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-approximation-to-the-density-function-Akaike",
            "title": {
                "fragments": [],
                "text": "An approximation to the density function"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1954
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34716098"
                        ],
                        "name": "M. Tarter",
                        "slug": "M.-Tarter",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Tarter",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tarter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11827568"
                        ],
                        "name": "R. Kronmal",
                        "slug": "R.-Kronmal",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Kronmal",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kronmal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120165289,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c4ee11c483e9199f4c89f5f961a4d49224140e29",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-Multivariate-Density-Estimates-Based-on-Tarter-Kronmal",
            "title": {
                "fragments": [],
                "text": "On Multivariate Density Estimates Based on Orthogonal Expansions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2707896"
                        ],
                        "name": "B. Logan",
                        "slug": "B.-Logan",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Logan",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Logan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108020"
                        ],
                        "name": "L. Shepp",
                        "slug": "L.-Shepp",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Shepp",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Shepp"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 120789266,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9c575d4c6a794fcd7b8304dee42ef2d469502ee4",
            "isKey": false,
            "numCitedBy": 235,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimal-reconstruction-of-a-function-from-its-Logan-Shepp",
            "title": {
                "fragments": [],
                "text": "Optimal reconstruction of a function from its projections"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738371"
                        ],
                        "name": "R. Serfling",
                        "slug": "R.-Serfling",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Serfling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Serfling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120916609,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "78278335d5d264d01809621824f7060435899769",
            "isKey": false,
            "numCitedBy": 272,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probability-Inequalities-for-the-Sum-in-Sampling-Serfling",
            "title": {
                "fragments": [],
                "text": "Probability Inequalities for the Sum in Sampling without Replacement"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90661057"
                        ],
                        "name": "L. Gordon",
                        "slug": "L.-Gordon",
                        "structuredName": {
                            "firstName": "Louis",
                            "lastName": "Gordon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gordon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378652"
                        ],
                        "name": "R. Olshen",
                        "slug": "R.-Olshen",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Olshen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Olshen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 119801174,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5b144e17e08b14a3b43b38064d730cd6868f6099",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Asymptotically-Efficient-Solutions-to-the-Problem-Gordon-Olshen",
            "title": {
                "fragments": [],
                "text": "Asymptotically Efficient Solutions to the Classification Problem"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101113860"
                        ],
                        "name": "P. Gaenssler",
                        "slug": "P.-Gaenssler",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Gaenssler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gaenssler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2008035"
                        ],
                        "name": "W. Stute",
                        "slug": "W.-Stute",
                        "structuredName": {
                            "firstName": "Winfried",
                            "lastName": "Stute",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Stute"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120853452,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "de907ebc11eadf0954a1a5e1481b8e528a47cf43",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Empirical-Processes:-A-Survey-of-Results-for-and-Gaenssler-Stute",
            "title": {
                "fragments": [],
                "text": "Empirical Processes: A Survey of Results for Independent and Identically Distributed Random Variables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40369383"
                        ],
                        "name": "R. Fefferman",
                        "slug": "R.-Fefferman",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Fefferman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fefferman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 117987903,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "beef56a85ffcbb162e07973c4f6f368443dc0bf1",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Review:-Miguel-de-Guzm\u00e1n,-Differentiation-of-in-Fefferman",
            "title": {
                "fragments": [],
                "text": "Review: Miguel de Guzm\u00e1n, Differentiation of integrals in $R^n$"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680998"
                        ],
                        "name": "I. Vajda",
                        "slug": "I.-Vajda",
                        "structuredName": {
                            "firstName": "Igor",
                            "lastName": "Vajda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Vajda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118701673,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "e125512dbae9f76dfdfe9bf7db709dd10370076f",
            "isKey": false,
            "numCitedBy": 504,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Theory-of-statistical-inference-and-information-Vajda",
            "title": {
                "fragments": [],
                "text": "Theory of statistical inference and information"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740147"
                        ],
                        "name": "Takao Nishizeki",
                        "slug": "Takao-Nishizeki",
                        "structuredName": {
                            "firstName": "Takao",
                            "lastName": "Nishizeki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takao Nishizeki"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117828187,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "82c958eae746e18e7538d369c220a353f2fe17f0",
            "isKey": false,
            "numCitedBy": 292,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Planar-Graphs:-Theory-and-Algorithms-Nishizeki",
            "title": {
                "fragments": [],
                "text": "Planar Graphs: Theory and Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679035"
                        ],
                        "name": "C. McDiarmid",
                        "slug": "C.-McDiarmid",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "McDiarmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. McDiarmid"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116663483,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6bbb79cc026ecca4264d95c4551fc58205b09533",
            "isKey": false,
            "numCitedBy": 1710,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Surveys-in-Combinatorics,-1989:-On-the-method-of-McDiarmid",
            "title": {
                "fragments": [],
                "text": "Surveys in Combinatorics, 1989: On the method of bounded differences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690163"
                        ],
                        "name": "G. McLachlan",
                        "slug": "G.-McLachlan",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "McLachlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. McLachlan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116275925,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c4c6750ff1e07960fe8c8bd5215d1d4c6f4ddfd7",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Bias-of-Apparent-Error-Rate-in-McLachlan",
            "title": {
                "fragments": [],
                "text": "Bias of Apparent Error Rate in Discriminant-Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39396458"
                        ],
                        "name": "Thomas A. Bailey",
                        "slug": "Thomas-A.-Bailey",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Bailey",
                            "middleNames": [
                                "A."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas A. Bailey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50658921"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117482922,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43d479131e08b1befadad638f73419c8676d4598",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "NOTE-ON-DISTANCE-WEIGHTED-k-NEAREST-NEIGHBOR-RULES.-Bailey-Jain",
            "title": {
                "fragments": [],
                "text": "NOTE ON DISTANCE-WEIGHTED k-NEAREST NEIGHBOR RULES."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50760334"
                        ],
                        "name": "C. George",
                        "slug": "C.-George",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "George",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. George"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117618111,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "def4744dd1109a1b001221af5d048d81847b1025",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Fubini\u2019s-Theorem-George",
            "title": {
                "fragments": [],
                "text": "Fubini\u2019s Theorem"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46470918"
                        ],
                        "name": "W. Fischer",
                        "slug": "W.-Fischer",
                        "structuredName": {
                            "firstName": "Werner",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1995628713"
                        ],
                        "name": "Marburg",
                        "slug": "Marburg",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Marburg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marburg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 95373079,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9d6f5e7a5ea7156aa8c2a11c0b9b613af44e910a",
            "isKey": false,
            "numCitedBy": 1942,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Sphere-Packings,-Lattices-and-Groups-Fischer-Marburg",
            "title": {
                "fragments": [],
                "text": "Sphere Packings, Lattices and Groups"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1849084"
                        ],
                        "name": "H. Warner",
                        "slug": "H.-Warner",
                        "structuredName": {
                            "firstName": "Homer",
                            "lastName": "Warner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Warner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 196069644,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "fc9fe5385f5a40c990bb5050b62a441b29c03211",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Mathematical-Approach-to-Medical-Diagnosis-Warner",
            "title": {
                "fragments": [],
                "text": "A Mathematical Approach to Medical Diagnosis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122942"
                        ],
                        "name": "B. Ripley",
                        "slug": "B.-Ripley",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Ripley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ripley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62205368,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "797542750c72908d5acff9e70b08d42302f0a54b",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Potential-pattern-recognition-in-chemical-and-Ripley",
            "title": {
                "fragments": [],
                "text": "Potential pattern recognition in chemical and medical decision making"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16685021"
                        ],
                        "name": "G. Sebestyen",
                        "slug": "G.-Sebestyen",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Sebestyen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sebestyen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62226288,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0217065021a8166e88dbcdf60f23f2222c6338bc",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Decision-making-processes-in-pattern-recognition-Sebestyen",
            "title": {
                "fragments": [],
                "text": "Decision-making processes in pattern recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059457908"
                        ],
                        "name": "M. R. Kaplan",
                        "slug": "M.-R.-Kaplan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kaplan",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. R. Kaplan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60879050,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cddd3b44b689fa5fc0b502b62095706057fce116",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Use-of-Spatial-Coherence-in-Ray-Tracing-Kaplan",
            "title": {
                "fragments": [],
                "text": "The Use of Spatial Coherence in Ray Tracing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145700185"
                        ],
                        "name": "S. Weiss",
                        "slug": "S.-Weiss",
                        "structuredName": {
                            "firstName": "Sholom",
                            "lastName": "Weiss",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weiss"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57100530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e70b4af0c13eac9bbb4445b9822350a60aad15b3",
            "isKey": false,
            "numCitedBy": 1244,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-Systems-That-Learn-Weiss",
            "title": {
                "fragments": [],
                "text": "Computer Systems That Learn"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122942"
                        ],
                        "name": "B. Ripley",
                        "slug": "B.-Ripley",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Ripley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ripley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 56833645,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8c4869392e5a52c3511fb907bd719391d9b9726",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 119,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-aspects-of-neural-networks-Ripley",
            "title": {
                "fragments": [],
                "text": "Statistical aspects of neural networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2550392"
                        ],
                        "name": "B. Efron",
                        "slug": "B.-Efron",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Efron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Efron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144294100"
                        ],
                        "name": "C. Stein",
                        "slug": "C.-Stein",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Stein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Stein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 120445519,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "af67eba4bb789b20fbf3abb94713606a9344f27d",
            "isKey": false,
            "numCitedBy": 1261,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Jackknife-Estimate-of-Variance-Efron-Stein",
            "title": {
                "fragments": [],
                "text": "The Jackknife Estimate of Variance"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144497046"
                        ],
                        "name": "N. Nilsson",
                        "slug": "N.-Nilsson",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Nilsson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nilsson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 54132942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d725045ed29d69b7a503896841ef637383376043",
            "isKey": false,
            "numCitedBy": 445,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-Machines:-Foundations-of-Trainable-Systems-Nilsson",
            "title": {
                "fragments": [],
                "text": "Learning Machines: Foundations of Trainable Pattern-Classifying Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719385"
                        ],
                        "name": "H. Samet",
                        "slug": "H.-Samet",
                        "structuredName": {
                            "firstName": "Hanan",
                            "lastName": "Samet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Samet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53756177,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4cc860a624927d94dc326b00ef23161ce88143e",
            "isKey": false,
            "numCitedBy": 740,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Applications-of-spatial-data-structures-Samet",
            "title": {
                "fragments": [],
                "text": "Applications of spatial data structures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102088724"
                        ],
                        "name": "D. Sprecher",
                        "slug": "D.-Sprecher",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Sprecher",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sprecher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52217396,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b98c8948cb54384e4ef6e864cad1cc704251e516",
            "isKey": false,
            "numCitedBy": 240,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-structure-of-continuous-functions-of-several-Sprecher",
            "title": {
                "fragments": [],
                "text": "On the structure of continuous functions of several variables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16697360"
                        ],
                        "name": "J. Elashoff",
                        "slug": "J.-Elashoff",
                        "structuredName": {
                            "firstName": "Janet",
                            "lastName": "Elashoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elashoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4896963"
                        ],
                        "name": "R. Elashoff",
                        "slug": "R.-Elashoff",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Elashoff",
                            "middleNames": [
                                "M."
                            ],
                            "suffix": "PhD"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Elashoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073652790"
                        ],
                        "name": "G. E. Goldman",
                        "slug": "G.-E.-Goldman",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Goldman",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. E. Goldman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43416772,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ca75d71e39d230a41c269e702731a33c93c21256",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-choice-of-variables-in-classification-with-Elashoff-Elashoff",
            "title": {
                "fragments": [],
                "text": "On the choice of variables in classification problems with dichotomous variables."
            },
            "venue": {
                "fragments": [],
                "text": "Biometrika"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143644543"
                        ],
                        "name": "N. Day",
                        "slug": "N.-Day",
                        "structuredName": {
                            "firstName": "Nicholas E.",
                            "lastName": "Day",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Day"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145619679"
                        ],
                        "name": "D. Kerridge",
                        "slug": "D.-Kerridge",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Kerridge",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kerridge"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2149531,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "bfcd49a84ed755242d89a0d1af44d775376db9b4",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY A method of discrimination, based on maximum likelihood estimation, is described. On a variety of mathematical models, including and extending the models most commonly assumed in discriminant theory, the discriminant reduces to multivariate logistic analysis. Even when no simple model can be assumed, other considerations show that this method should work well in practice, and should be very robust with respect to departures from the theoretical assumptions. The method is compared with others in its application to a diagnostic problem."
            },
            "slug": "A-general-maximum-likelihood-discriminant.-Day-Kerridge",
            "title": {
                "fragments": [],
                "text": "A general maximum likelihood discriminant."
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A method of discrimination, based on maximum likelihood estimation, which reduces to multivariate logistic analysis on a variety of mathematical models, including and extending the models most commonly assumed in discriminant theory."
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6324626"
                        ],
                        "name": "P. Lachenbruch",
                        "slug": "P.-Lachenbruch",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Lachenbruch",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lachenbruch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35796889,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "cb9488ce6e8c46ccddcb0f6f876dd39fe4a4046a",
            "isKey": false,
            "numCitedBy": 506,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-almost-unbiased-method-of-obtaining-confidence-Lachenbruch",
            "title": {
                "fragments": [],
                "text": "An almost unbiased method of obtaining confidence intervals for the probability of misclassification in discriminant analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115715700"
                        ],
                        "name": "A. E. Bostwick",
                        "slug": "A.-E.-Bostwick",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Bostwick",
                            "middleNames": [
                                "Elmore"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. E. Bostwick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5224243,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6a45bc7826bf2928850c61844b53f1dc5b9bb739",
            "isKey": false,
            "numCitedBy": 251,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "THE-THEORY-OF-PROBABILITIES.-Bostwick",
            "title": {
                "fragments": [],
                "text": "THE THEORY OF PROBABILITIES."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1896
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39445973"
                        ],
                        "name": "P. Heywood",
                        "slug": "P.-Heywood",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Heywood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Heywood"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 202
                            }
                        ],
                        "text": "Most proofs are omitted as they may be found in standard textbooks on probability, such as Feller [1], Ash [2], Shiryayev [3], Chow and Teicher [4], Durrett [5], Grimmett and Stirzaker [6], and Zygmund [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4223331,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6eaf5031155bac21557abf215e884fffb1b881ac",
            "isKey": false,
            "numCitedBy": 2462,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Trigonometric-Series-Heywood",
            "title": {
                "fragments": [],
                "text": "Trigonometric Series"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4299218,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "2b02dfc5cfd4b6e1d097f4f4b4a69e0fbf64ba67",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-National-Institute-of-Sciences-of-India",
            "title": {
                "fragments": [],
                "text": "The National Institute of Sciences of India"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3312665"
                        ],
                        "name": "O. Nurmi",
                        "slug": "O.-Nurmi",
                        "structuredName": {
                            "firstName": "Otto",
                            "lastName": "Nurmi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Nurmi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42741983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59e4d9874e49d3884e7590880432840c7acf784d",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algorithms-for-computational-geometry-Nurmi",
            "title": {
                "fragments": [],
                "text": "Algorithms for computational geometry"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821511"
                        ],
                        "name": "Gyora M. Benedek",
                        "slug": "Gyora-M.-Benedek",
                        "structuredName": {
                            "firstName": "Gyora",
                            "lastName": "Benedek",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gyora M. Benedek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736744"
                        ],
                        "name": "A. Itai",
                        "slug": "A.-Itai",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Itai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Itai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 6815721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe9c43c67cd2bac32aeb0a7e9f44e5f2a5b444a6",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Nonuniform-Learnability-Benedek-Itai",
            "title": {
                "fragments": [],
                "text": "Nonuniform Learnability"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2748598"
                        ],
                        "name": "S. Kullback",
                        "slug": "S.-Kullback",
                        "structuredName": {
                            "firstName": "Solomon",
                            "lastName": "Kullback",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kullback"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39207065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "392afef3b7d06d1498ac02b8d681905f06e878fd",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Correction-to-A-Lower-Bound-for-Discrimination-in-Kullback",
            "title": {
                "fragments": [],
                "text": "Correction to A Lower Bound for Discrimination Information in Terms of Variation"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145768864"
                        ],
                        "name": "D. Broomhead",
                        "slug": "D.-Broomhead",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Broomhead",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Broomhead"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144159852"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3686496,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "b08ba914037af6d88d16e2657a65cd9dc5cf5da1",
            "isKey": false,
            "numCitedBy": 2307,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multivariable-Functional-Interpolation-and-Adaptive-Broomhead-Lowe",
            "title": {
                "fragments": [],
                "text": "Multivariable Functional Interpolation and Adaptive Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2650569"
                        ],
                        "name": "A. Klopf",
                        "slug": "A.-Klopf",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Klopf",
                            "middleNames": [
                                "Harry"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Klopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3079244"
                        ],
                        "name": "E. Gose",
                        "slug": "E.-Gose",
                        "structuredName": {
                            "firstName": "Earl",
                            "lastName": "Gose",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gose"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32233940,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "166b790f182be2678e80b2fd1eab3615ca87a571",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recursive-Estimates-of-Probability-Densities-Klopf-Gose",
            "title": {
                "fragments": [],
                "text": "Recursive Estimates of Probability Densities"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Sci. Cybern."
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103556459"
                        ],
                        "name": "C. J. Stone",
                        "slug": "C.-J.-Stone",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Stone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Stone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43491035,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "072f3eba9251c60e21935821a2410e77492fb93a",
            "isKey": false,
            "numCitedBy": 1199,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Additive-Regression-and-Other-Nonparametric-Models-Stone",
            "title": {
                "fragments": [],
                "text": "Additive Regression and Other Nonparametric Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49353544"
                        ],
                        "name": "R. Fisher",
                        "slug": "R.-Fisher",
                        "structuredName": {
                            "firstName": "Rory",
                            "lastName": "Fisher",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29084021,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "ab21376e43ac90a4eafd14f0f02a0c87502b6bbf",
            "isKey": false,
            "numCitedBy": 13267,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "THE-USE-OF-MULTIPLE-MEASUREMENTS-IN-TAXONOMIC-Fisher",
            "title": {
                "fragments": [],
                "text": "THE USE OF MULTIPLE MEASUREMENTS IN TAXONOMIC PROBLEMS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1936
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103556459"
                        ],
                        "name": "C. J. Stone",
                        "slug": "C.-J.-Stone",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Stone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Stone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 120511992,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2f0be7ef09295368bb1b1f01945ff337e0d44b39",
            "isKey": false,
            "numCitedBy": 1407,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimal-Global-Rates-of-Convergence-for-Regression-Stone",
            "title": {
                "fragments": [],
                "text": "Optimal Global Rates of Convergence for Nonparametric Regression"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702517"
                        ],
                        "name": "I. Sethi",
                        "slug": "I.-Sethi",
                        "structuredName": {
                            "firstName": "Ishwar",
                            "lastName": "Sethi",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Sethi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36533620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f759d3e4662ead14435c262a39ef76e490770191",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Fast-Algorithm-for-Recognizing-Nearest-Neighbors-Sethi",
            "title": {
                "fragments": [],
                "text": "A Fast Algorithm for Recognizing Nearest Neighbors"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144102674"
                        ],
                        "name": "C. Papadimitriou",
                        "slug": "C.-Papadimitriou",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Papadimitriou",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papadimitriou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696575"
                        ],
                        "name": "J. Bentley",
                        "slug": "J.-Bentley",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Bentley",
                            "middleNames": [
                                "Louis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bentley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39670719,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f896738b9d622dd694777ef0ef4d3aea0b500cb",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The nearest neighbor searching problem (also called the post office problem) calls for organizing the set P of N points in k-space so that the nearest neighbor in P to a new point can be quickly found. Friedman, Baskett and Shustek describe an algorithm for nearest neighbor searching based on projecting the points onto the various coordinate axes; their analysis of this method shows that a nearest neighbor search can be performed in O(N1\u22121/k) expected time, for any fixed dimension k>1 under a variety of probability distributions. In this paper we shall prove the stronger (worst-case) result that the total time required by (an extension of) their method to find the nearest neighbor of every point in any fixed k-dimensional point set is O(N2\u22121/k), which immediately implies a result similar to theirs. The above results hold only for the L\u221e metric; we also investigate the Euclidean (L2) metric. Our first result for that metric shows that the above analysis does not hold in general, and our second result then goes on to show that the analysis does in fact apply in practice, because of the finite word-length restrictions of real computers."
            },
            "slug": "A-Worst-Case-Analysis-of-Nearest-Neighbor-Searching-Papadimitriou-Bentley",
            "title": {
                "fragments": [],
                "text": "A Worst-Case Analysis of Nearest Neighbor Searching by Projection"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper proves the stronger (worst-case) result that the total time required by (an extension of) Friedman, Baskett and Shustek's method to find the nearest neighbor of every point in any fixed k-dimensional point set is O(N2\u22121/k), which immediately implies a result similar to theirs."
            },
            "venue": {
                "fragments": [],
                "text": "ICALP"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821511"
                        ],
                        "name": "Gyora M. Benedek",
                        "slug": "Gyora-M.-Benedek",
                        "structuredName": {
                            "firstName": "Gyora",
                            "lastName": "Benedek",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gyora M. Benedek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736744"
                        ],
                        "name": "A. Itai",
                        "slug": "A.-Itai",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Itai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Itai"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5260687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c23ed6b3bf16778c9f2a6a5b6b0b629e9b1b0af1",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learnability-by-fixed-distributions-Benedek-Itai",
            "title": {
                "fragments": [],
                "text": "Learnability by fixed distributions"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103556459"
                        ],
                        "name": "C. J. Stone",
                        "slug": "C.-J.-Stone",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Stone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Stone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18029871,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "165b1cc83a14a7b05c3f95e8e58a0bf5a25367f5",
            "isKey": false,
            "numCitedBy": 1671,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Consistent-Nonparametric-Regression-Stone",
            "title": {
                "fragments": [],
                "text": "Consistent Nonparametric Regression"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14523865"
                        ],
                        "name": "D. Loftsgaarden",
                        "slug": "D.-Loftsgaarden",
                        "structuredName": {
                            "firstName": "Don",
                            "lastName": "Loftsgaarden",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Loftsgaarden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80011542"
                        ],
                        "name": "C. Quesenberry",
                        "slug": "C.-Quesenberry",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Quesenberry",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Quesenberry"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 121666889,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "83a5c430e65fe74d8905c7e81a8aeaf11aead8e2",
            "isKey": false,
            "numCitedBy": 770,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-nonparametric-estimate-of-a-multivariate-density-Loftsgaarden-Quesenberry",
            "title": {
                "fragments": [],
                "text": "A nonparametric estimate of a multivariate density function"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61480753,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "edb62d05f8eeaa7e1921c6c25c544935a2b6b131",
            "isKey": false,
            "numCitedBy": 415,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Theory-of-Pattern-Recognition-Amari",
            "title": {
                "fragments": [],
                "text": "A Theory of Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145956495"
                        ],
                        "name": "J. Marron",
                        "slug": "J.-Marron",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Marron",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Marron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17522755,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4c573eae6b2d1b68886cb7a94c61243f90f628e3",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimal-Rates-of-Convergence-to-Bayes-Risk-in-Marron",
            "title": {
                "fragments": [],
                "text": "Optimal Rates of Convergence to Bayes Risk in Nonparametric Discrimination"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3023298"
                        ],
                        "name": "I. Tomek",
                        "slug": "I.-Tomek",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Tomek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Tomek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17939071,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "090a6772a1d69f07bfe7e89f99934294a0dac1b9",
            "isKey": false,
            "numCitedBy": 906,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Two-Modifications-of-CNN-Tomek",
            "title": {
                "fragments": [],
                "text": "Two Modifications of CNN"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vitesse de convergence dans le theor\u00e9me de la limite centrale pour le processus empirique"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "n) n-th shatter coefficient of the class of classifiers C"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nonparametric classification rules"
            },
            "venue": {
                "fragments": [],
                "text": "Sankhya Series A"
            },
            "year": 1964
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Approximate error bounds in pattern recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Intelligence"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nearest Neighbor Pattern Classification Techniques"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Les meilleures constantes de l'in\u00e9galite de Khintchine. Comptes Rendus de l'Acad\u00e9mie des"
            },
            "venue": {
                "fragments": [],
                "text": "Sciences de Paris A"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The thirteenth problem of Hilbert"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Symposia in Pure Mathematics"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Contribution to the discussion of a paper by P. Diaconis and Freeman"
            },
            "venue": {
                "fragments": [],
                "text": "Annals of Statistics"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "x) conditional densities of X given Y = 0 and Y = 1, respectively (if they exist"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic Analysis of Algorithms. Class Notes, University of California"
            },
            "venue": {
                "fragments": [],
                "text": "Submitted to the ACM Symposium on Theory of Computing"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "(x) = I {x\u2208B} indicator function of a set B"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Radon-Nikodym derivative"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Y n+m )) testing data, sequence of i.i.d. pairs that are independent of (X, Y ) and D n , and have the same distribution as that of"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Density estimation and pattern classification. Problems of Control and Information Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The estimation of minimal error probability for testing finite or countable number of hypotheses"
            },
            "venue": {
                "fragments": [],
                "text": "Problemy Peredaci Informacii"
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fourier series classifier"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speakerindependent recognition of isolated words using clustering techniques"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Acoustics, Speech, and Signal Processing"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Potential function algorithms for pattern recognition learning machines. Automation and Remote Control"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Approximations by superpositions of sigmoidal functions"
            },
            "venue": {
                "fragments": [],
                "text": "Math. Control, Signals, Systems"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hamming distance, 474, 477 ham-sandwich theorem"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The exponential rate of convergence of error for kn-nn nonparametric regression and decision. Problems of Control and Information Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "The expectation of X is\nE{X} = \u2211\nx\nxP{X = x} = \u2211\nx>0\nxP{X = x} + \u2211\nx 0\nxP{X = x},\nif at least one term on the right-hand side is finite."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "R d observation, vector-valued random variable"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Parsimony in neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Applications of Characteristic Functions in Probability Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Class Notes for Transmission of Information. Course 6.574"
            },
            "venue": {
                "fragments": [],
                "text": "MIT"
            },
            "year": 1952
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sur une condition n\u00e9cessaire et suffisante de L1-convergence presque compl\u00e8te de l'estimateur de la partition fixe pour une densit\u00e9"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "510 of complexity regularization, 293 definition of, 3, 92 of generalized linear rules"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminatory analysis: small sample performance"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1952
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the divergence between two distributions and the probability of misclassification of several decision rules"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Joint Conference on Pattern Recognition"
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Applications of Characteristic Functions in Probability Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generation of polynomial discriminant functions for pattern classification"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Electronic Computers"
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ordered risk minimization. II. Automation and Remote Control"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "382 outer layer, see monotone layer overfitting"
            },
            "venue": {
                "fragments": [],
                "text": "order statistics"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the edited nearest neighbor rule"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fifth International Conference on Pattern Recognition"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rates of uniform almost sure convergence for empirical processes indexed by unbounded classes of functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the divergence between two distributions and the probability of misclassification of several decision rules"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Joint Conference on Pattern Recognition"
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Logically smooth density estimation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Y n )) training data, sequence of i.i.d. pairs that are independent of (X, Y ), and have the same distribution as that of"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "573 fingering, 191, 192, 277 fingering dimension"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Voronoi partition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classification using the Fourier series estimate of multivariate density functions"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man and Cybernetics"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian decision with rejection. Problems of Control and Information Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An upper bound of error probabilities for multihypothesis testing and its application in adaptive pattern recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Problems of Control and Information Theory"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An overview of asymptotic properties of nearest neighbor rules"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition in Practice"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nonparametric Density Estimation: The L1 View"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalized entropy and quantization problems"
            },
            "venue": {
                "fragments": [],
                "text": "Transactions of the Sixth Prague Conference on Information Theory, Statistical Decision Functions, Random Processes"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nonparametric Density Estimation: The L1 View"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "446 star-shaped, 432 uniform, see na\u00efve kernel window, see na\u00efve kernel kernel complexity"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pattern recognition procedures with nonparametric density estimates"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man and Cybernetics"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On characterization of J-divergence and its generalizations"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Combinatorics, Information and System Sciences"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Introduction to the performance of distribution-free conditional risk learning systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hellinger distance"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Grenander's method of sieves, 527, 540 grid complexity, 357 group method of data handling"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fourier series density estimation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Radial basis functions for multivariable interpolation: a review. Algorithms for Approximation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Grenander's method of sieves, 527, 540 grid complexity, 357 group method of data handling"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fourier series density estimation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Some nonparametric multivariate procedures based on statistically equivalent blocks"
            },
            "venue": {
                "fragments": [],
                "text": "Multivariate Analysis"
            },
            "year": 1966
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayes risk, see Bayes error Bennett's inequality"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayes risk, the error probability of the Bayes i=1 I {Xi\u2208A} empirical measure corresponding to X 1"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "X (k) k-th nearest neighbor of x among X 1"
            },
            "venue": {
                "fragments": [],
                "text": "\u2022 X (k) (x)"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A universal k-nearest neighbor procedure in discrimination"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1978 IEEE Computer Society Conference on Pattern Recognition and Image Processing"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "U -method, see leave-one-out estimate estimation error"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "classes of classification functions. \u2022 s(A, n) n-th shatter coefficient of the class of sets A"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Voronoi cell"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Steps towards artificial intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IRE"
            },
            "year": 1961
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "classes of classification functions. \u2022 s(A, n) n-th shatter coefficient of the class of sets A"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Voronoi cell"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "permutation-optimized chronological"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "358 recursive kernel rule, 160, 161, 166 regression function"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the amount of a priori information in designing the classification algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Entropy nets: from decision trees to neural nets. Proceedings of the IEEE"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "y \u2212 x \u2264 r} closed Euclidean ball in R d centered at x \u2208 R d"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "H\u00f6lder's inequality, 108, 582 hypergeometric distribution, 589 imperfect training, 89, 109 impurity function"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Simple and compound processes in iterative machine learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Khinchine's inequality, 410, 588 k-local rule"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Simple and compound processes in iterative machine learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "585 bracketing metric entropy, 253, 254, 262 branch-and-bound method, 563 bsp tree, see binary space partition tree cart"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Class of Nonparametric Estimators of a Smooth Regression Function"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On a measure of divergence between two multinomial populations"
            },
            "venue": {
                "fragments": [],
                "text": "Sankhya, Series A"
            },
            "year": 1946
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "380 local average estimator, 98 logistic discrimination, 259 log-linear model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Remarks on nonparametric estimates for density functions and regression curves. Theory of Probability and its Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic programming as applied to feature selection in pattern recognition systems"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ordered risk minimization. I. Automation and Remote Control"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural Pattern Classifying Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning networks improve computer-aided prediction and control"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Design"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u2022 x integer part of the real number x. \u2022 x upper integer part of the real number x. \u2022 X L = Z if X and Z have the same distribution"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the optimality of the sigmoid perceptron"
            },
            "venue": {
                "fragments": [],
                "text": "International Joint Conference on Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robbins-Monroe procedures in a Hilbert space and its application in the theory of learning processes"
            },
            "venue": {
                "fragments": [],
                "text": "Studia Scientiarium Mathematicarum Hungarica"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The method of potential functions for the problem of restoring the characteristic of a function converter from randomly observed points. Automation and Remote Control"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An analysis of random ddimensional quadtrees"
            },
            "venue": {
                "fragments": [],
                "text": "SIAM Journal on Computing"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Piecewise linear discriminant functions in pattern recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Systems-Computers-Controls"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Almost sure Lr-norm convergence for data-based histogram estimates"
            },
            "venue": {
                "fragments": [],
                "text": "Theory of Probability and its Applications"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Combinatorial entropy and uniform limit laws"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Patterns in pattern recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Patterns in pattern recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The method of potential functions. Automation and Remote Control"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kolmogorov's mapping network existence theorem"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE First International Conference on Neural Networks"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "396 cross validated, see leave-one-out estimate deleted, see leave-one-out estimate double bootstrap, 557 E0 estimator"
            },
            "venue": {
                "fragments": [],
                "text": "entropy"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Euler's theorem, 380 exponential distribution, 361, 590 exponential family"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Note on optimal selection of independent binaryvalued features for pattern recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chernoff's bounding method"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Universal consistency results for Wolverton-Wagner regression function estimate with application in discrimination"
            },
            "venue": {
                "fragments": [],
                "text": "Problems of Control and Information Theory"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the nonparametric estimate of a posteriori probabilities of simple statistical hypotheses"
            },
            "venue": {
                "fragments": [],
                "text": "Colloquia Mathematica Societatis J\u00e1nos Bolyai: Topics in Information Theory"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Orthogonal Functions. Interscience"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The probability problem of pattern recognition learning and the method of potential functions. Automation and Remote Control"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Extrapolative problems in automatic control and the method of potential functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Upper bound on the error probability of detection in non-gaussian noise. Problems of Control and Information Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Orthogonal Functions. Interscience"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Densit\u00e9 et dimension. Annales de l'Institut Fourier"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluation of attributes obtained in statistical decision rules"
            },
            "venue": {
                "fragments": [],
                "text": "Engineering Cybernetics"
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information-type measures of difference of probability distributions and indirect observations"
            },
            "venue": {
                "fragments": [],
                "text": "Studia Scientiarium Mathematicarum Hungarica"
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Asymptotically optimal probabilistic algorithms for pattern recognition and identification"
            },
            "venue": {
                "fragments": [],
                "text": "Prace Naukowe Instytutu Cybernetyki Technicznej Politechniki Wroclawsjiej No"
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u2022 I A indicator of an event A"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Estimation de la regression par la m\u00e9thode des k points les plus proches: propri\u00e9t\u00e9s de convergence ponctuelle"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On dimensionality, learning sample size and complexity of classification algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 3rd International Conference on Pattern Recognition"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Khinchine's, 410, 588 large deviation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distribution-free minimum conditional risk learning systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chervonenkis dimension of the class of sets A"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kolmogorov-Lorentz representation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Estimation of the rate of convergence of algorithms based on the potential function method. Automation and Remote Control"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Deux remarques sur l'estimation. Comptes Rendus de l'Acad\u00e9mie des Sciences de Paris"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rates of convergence for nearest neighbor procedures"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Hawaii International Conference on Systems Sciences"
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The group method of data handling-a rival of the method of stochastic approximation"
            },
            "venue": {
                "fragments": [],
                "text": "Soviet Automatic Control"
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Let X have support on the surface of a ball of R d centered at the origin of unknown radius. Find a sufficient statistic for discrimination of dimension smaller than d"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Estimation de la regression par la m\u00e9thode des k points les plus proches avec noyau"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Mathematics"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Abstract Inference"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bernstein's inequality, 124, 130, 210, 494 beta distribution"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "420 -effective cardinality of, 144 family of"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Logistic discrimination"
            },
            "venue": {
                "fragments": [],
                "text": "Handbook of Statistics"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Using indicators as a base for estimating optimal decision functions"
            },
            "venue": {
                "fragments": [],
                "text": "Colloquia Mathematica Societatis J\u00e1nos Bolyai: Topics in Information Theory"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u2022 |A| cardinality of a finite set A. \u2022 A c complement of a set A. \u2022 A B symmetric difference of sets A, B. \u2022 f \u2022 g composition of functions f, g. \u2022 log natural logarithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Asymptotic behavior of the aid method"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The absolute -entropy of metric spaces. Translations of the"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the oscillation of the expected number of points on a random convex hull"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics and Probability Letters"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "433 de la Vall\u00e9e-Poussin, 446 devilish"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distribution-free exponential bound on the L1 error of partitioning estimates of a regression function"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth Pannonian Symposium on Mathematical Statistics"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Asymptotic behavior of the aid method"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayes risk consistency of classification procedures using density estimation"
            },
            "venue": {
                "fragments": [],
                "text": "Sankhya Series A"
            },
            "year": 1966
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chervonenkis dimension of the class of classifiers C"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Local properties of k-nearest neighbor regression estimates"
            },
            "venue": {
                "fragments": [],
                "text": "SIAM Journal on Algebraic and Discrete Methods"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "418 rotation invariance, see transformation invariance Royall's rule"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluation of an unknown distribution density from observations"
            },
            "venue": {
                "fragments": [],
                "text": "Soviet Math. Doklady"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "590 gaussian distribution, see normal distribution gaussian noise, 57, 285 geometric distribution"
            },
            "venue": {
                "fragments": [],
                "text": "Gabriel neighbor, 90 gamma distribution"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recent results on nonparametric regression estimate and multiple classification. Problems of Control and Information Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fano's inequality"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probability Theory, Independence, Interchangeability, Martingales. Springer Texts in Statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Probability Theory, Independence, Interchangeability, Martingales. Springer Texts in Statistics"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Estimation of the performance of partitioning algorithms in pattern classification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Decision tree design from a communication theory viewpoint"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A gmdh algorithm with random selection of pairs"
            },
            "venue": {
                "fragments": [],
                "text": "Soviet Automatic Control"
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On uniform laws of averages"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical learning networks: a unifying view"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 20th Symposium on the Interface: Computing Science and Statistics"
            },
            "year": 1988
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 557,
        "totalPages": 56
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Probabilistic-Theory-of-Pattern-Recognition-Devroye-Gy\u00f6rfi/43fcdee6c6d885ac2bd32e122dbf282f93720c22?sort=total-citations"
}