{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144007105"
                        ],
                        "name": "Philip M. Long",
                        "slug": "Philip-M.-Long",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Long",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip M. Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15409710,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "da32da04a554a226ef1efc9a906018d324f44359",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we study the performance of gradient descent when applied to the problem of on-line linear prediction in arbitrary inner product spaces. We show worst-case bounds on the sum of the squared prediction errors under various assumptions concerning the amount of a priori information about the sequence to predict. The algorithms we use are variants and extensions of on-line gradient descent. Whereas our algorithms always predict using linear functions as hypotheses, none of our results requires the data to be linearly related. In fact, the bounds proved on the total prediction loss are typically expressed as a function of the total loss of the best fixed linear predictor with bounded norm. All the upper bounds are tight to within constants. Matching lower bounds are provided in some cases. Finally, we apply our results to the problem of on-line prediction for classes of smooth functions."
            },
            "slug": "WORST-CASE-QUADRATIC-LOSS-BOUNDS-FOR-ON-LINE-OF-BY-Cesa-Bianchi-Long",
            "title": {
                "fragments": [],
                "text": "WORST-CASE QUADRATIC LOSS BOUNDS FOR ON-LINE PREDICTION OF LINEAR FUNCTIONS BY GRADIENT DESCENT"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "The performance of gradient descent when applied to the problem of on-line linear prediction in arbitrary inner product spaces is studied and worst-case bounds on the sum of the squared prediction errors under various assumptions concerning the amount of a priori information about the sequence to predict are shown."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700597"
                        ],
                        "name": "Jyrki Kivinen",
                        "slug": "Jyrki-Kivinen",
                        "structuredName": {
                            "firstName": "Jyrki",
                            "lastName": "Kivinen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jyrki Kivinen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 136
                            }
                        ],
                        "text": "Some of these results assumedthat the outcomes yt must be in f 0; 1 g and were generalized for continuous-valued outcomesyt 2 [0; 1] by Haussler, Kivinen, and Warmuth (1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9426152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14658bf6b693af9f30920c70fad14563f6b0cc10",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider on-line algorithms for predicting binary or continuous-valued outcomes, when the algorithm has available the predictions made by N experts. For a sequence of trials, we compute total losses for both the algorithm and the experts under a loss function. At the end of the trial sequence, we compare the total loss of the algorithm to the total loss of the best expert, i.e., the expert with the least loss on the particular trial sequence. We show that for a large class of loss functions, with binary outcomes the total loss of the algorithm proposed by Vovk exceeds the total loss of the best expert at most by the amount c ln N, where c is a constant determined by the loss function. This upper bound does not depend on any assumptions on how the experts'' predictions or the outcomes are generated, and the trial sequence can be arbitrarily long. We give a straightforward method for finding the correct value c and show by a lower bound that for this value of c, the upper bound is asymptotically tight. The lower bound is based on a probabilistic adversary argument. The class of loss functions for which the c ln N upper bound holds includes the square loss, the logarithmic loss, and the Hellinger loss. We also consider another class of loss functions, including the absolute loss, for which we have an Omega((l log N)^(1/2)) lower bound, where l is the number of trials. We show that for the square and logarithmic loss functions, Vovk''s algorithm achieves the same worst-case upper bounds with continuous-valued outcomes as with binary outcomes. For the absolute loss, we show how bounds earlier achieved for binary outcomes can be achieved with continuous-valued outcomes using a slightly more complicated algorithm."
            },
            "slug": "Tight-worst-case-loss-bounds-for-predicting-with-Haussler-Kivinen",
            "title": {
                "fragments": [],
                "text": "Tight worst-case loss bounds for predicting with expert advice"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work considers on-line algorithms for predicting binary or continuous-valued outcomes, when the algorithm has available the predictions made by N experts, and shows that for a large class of loss functions, with binary outcomes the total loss of the algorithm proposed by Vovk exceeds the total losses of the best expert at most by the amount c ln N, where c is a constant determined by the loss function."
            },
            "venue": {
                "fragments": [],
                "text": "EuroCOLT"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772099"
                        ],
                        "name": "D. Helmbold",
                        "slug": "D.-Helmbold",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Helmbold",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Helmbold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 33
                            }
                        ],
                        "text": "Littlestone, N., and Warmuth, M. K. (1994), The weighted majority algorithm, Informationand Computation 108, 212{261."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 93
                            }
                        ],
                        "text": "Cesa-Bianchi, N., Freund, Y., Haussler, D., Helmbold, D. P., Schapire, R. E., and Warmuth,M. K. (1994), \\How to use expert advice,\" Technical Report UCSC-CRL-94-33, Univer-sity of California, Santa Cruz, Computer Research Laboratory."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 33
                            }
                        ],
                        "text": "Schapire, R. E., and Warmuth, M. K. (1994), On the worst-case analysis of temporal-di erencelearing algorithms, in \\Proceddings, 11th International Conference on Machine Learning,\"pp. 266{274, Morgan Kaufmann, San Francisco, CA."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 43
                            }
                        ],
                        "text": "Haussler, D., Kivinen, J., and Warmuth, M. K. (1994), \\Tight worst-case loss bounds forpredicting with expert advice,\" Technical Report UCSC-CRL-94-36, University of Cali-fornia, Santa Cruz, Computer Research Laboratory."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 124263,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "239ae23dc2f934cfa005261ade01023fe7950b82",
            "isKey": false,
            "numCitedBy": 624,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze algorithms that predict a binary value by combining the predictions of several prediction strategies, called `experts''. Our analysis is for worst-case situations, i.e., we make no assumptions about the way the sequence of bits to be predicted is generated. We measure the performance of the algorithm by the difference between the expected number of mistakes it makes on the bit sequence and the expected number of mistakes made by the best expert on this sequence, where the expectation is taken with respect to the randomization in the predictions. We show that the minimum achievable difference is on the order of the square root of the number of mistakes of the best expert, and we give efficient algorithms that achieve this. Our upper and lower bounds have matching leading constants in most cases. We then show how this leads to certain kinds of pattern recognition/learning algorithms with performance bounds that improve on the best results currently known in this context. We also extend our analysis to the case in which log loss is used instead of the expected number of mistakes."
            },
            "slug": "How-to-use-expert-advice-Cesa-Bianchi-Freund",
            "title": {
                "fragments": [],
                "text": "How to use expert advice"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This work analyzes algorithms that predict a binary value by combining the predictions of several prediction strategies, called `experts', and shows how this leads to certain kinds of pattern recognition/learning algorithms with performance bounds that improve on the best results currently known in this context."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 52
                            }
                        ],
                        "text": "The research reported in this paper was inspired by Littlestone (1989b, 1988), who provedworst-case bounds for the case when the comparison class consists of Boolean monomials, ormore generally linear threshold functions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 107
                            }
                        ],
                        "text": "Littlestone, N. (1991), Redundant noisy attributes, attribute errors, and linear threshold learn-ing using Winnow, in \\Proceedings, 4th Annual Workshop on Computational LearningTheory,\" pp. 147{156, Morgan Kaufmann, San Mateo, CA.\nExponentiated gradient 57Littlestone, N., Long, P. M., and Warmuth, M. K. (1995), On-line learning of linear functions,Journal of Computational Complexity 5, 1{23."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 118
                            }
                        ],
                        "text": "This use of a distance measure for obtaining worst-case loss boundswas pioneered by Littlestone's analysis of Winnow (Littlestone, 1989b), which also employs avariant of the relative entropy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 81
                            }
                        ],
                        "text": "Moresophisticated conversion methods are given by Cesa-Bianchi et al. (1994) and Littlestone (1989).9 Experimental and theoretical comparison of the algorithms9."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 60
                            }
                        ],
                        "text": "The method is an abstraction of the proof methodemployed by Littlestone (1989b, 1990) and others (Littlestone et al., 1995; Cesa-Bianchi et al.,1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 42
                            }
                        ],
                        "text": "The new family includes,respectively, the Winnow algorithm (Littlestone, 1988), the EG algorithm, the exponentiatedback-propagation algorithm, and an algorithm for tting a line to data points so that therelative entropy of the coe cient vector is minimized."
                    },
                    "intents": []
                }
            ],
            "corpusId": 19753387,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2606d97cf80839e7d223a0769529e2cc51a95bf",
            "isKey": true,
            "numCitedBy": 155,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "From-on-line-to-batch-learning-Littlestone",
            "title": {
                "fragments": [],
                "text": "From on-line to batch learning"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '89"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 52
                            }
                        ],
                        "text": "The research reported in this paper was inspired by Littlestone (1989b, 1988), who provedworst-case bounds for the case when the comparison class consists of Boolean monomials, ormore generally linear threshold functions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 107
                            }
                        ],
                        "text": "Littlestone, N. (1991), Redundant noisy attributes, attribute errors, and linear threshold learn-ing using Winnow, in \\Proceedings, 4th Annual Workshop on Computational LearningTheory,\" pp. 147{156, Morgan Kaufmann, San Mateo, CA.\nExponentiated gradient 57Littlestone, N., Long, P. M., and Warmuth, M. K. (1995), On-line learning of linear functions,Journal of Computational Complexity 5, 1{23."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 118
                            }
                        ],
                        "text": "This use of a distance measure for obtaining worst-case loss boundswas pioneered by Littlestone's analysis of Winnow (Littlestone, 1989b), which also employs avariant of the relative entropy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 81
                            }
                        ],
                        "text": "Moresophisticated conversion methods are given by Cesa-Bianchi et al. (1994) and Littlestone (1989).9 Experimental and theoretical comparison of the algorithms9."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 60
                            }
                        ],
                        "text": "The method is an abstraction of the proof methodemployed by Littlestone (1989b, 1990) and others (Littlestone et al., 1995; Cesa-Bianchi et al.,1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 42
                            }
                        ],
                        "text": "The new family includes,respectively, the Winnow algorithm (Littlestone, 1988), the EG algorithm, the exponentiatedback-propagation algorithm, and an algorithm for tting a line to data points so that therelative entropy of the coe cient vector is minimized."
                    },
                    "intents": []
                }
            ],
            "corpusId": 122204757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbda209682dd2b1b1d0006a41cf84ca1b2487c71",
            "isKey": true,
            "numCitedBy": 185,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider a problem of learning from examples. In each of a sequence of trials the learner observes an instance to be classified and must respond with a prediction of its correct classification. Following the prediction the learner is told the correct response. We consider the two category case, and work for the most part with instances composed of a number of Boolean attributes or, more generally, chosen from (0, 1) $\\sp{n}$. Initially, we assume that the correct response in each trial is a function of the corresponding instance, this target function being chosen from some target class of $\\{0,1\\}$-valued functions. We relax this assumption somewhat later. \nWe focus on evaluation of on-line predictive performance, counting the number of mistakes made by the learner during the learning process. For certain target classes we have found algorithms for which we can prove excellent mistake bounds, using no probabilistic assumptions. In the first part of the dissertation we study the properties of such worst-case mistake bounds. \nIn the central part of this dissertation, we present a group of linear-threshold algorithms that are particularly well suited to circumstances in which most of the attributes of the instances are irrelevant to determining the correct predictions. For target classes that can be handled by these algorithms, we show that the worst-case mistake bounds grow only logarithmically with the number of irrelevant attributes. We demonstrate that these algorithms have some measure of robustness in the face of anomalies in the training data caused, for example, by noise. \nWe also consider the implications of on-line, worst-case mistake bounds for learning in a batch setting with probabilistic assumptions, making use of the probabilistic PAC-learning model introduced by Valiant (Va184). We present an analysis that shows that a straightforward transformation applied to mistake bounded algorithms, consisting of adding a hypothesis testing phase, produces algorithms that have asymptotically optimal PAC-learning bounds for certain target classes."
            },
            "slug": "Mistake-bounds-and-logarithmic-linear-threshold-Littlestone",
            "title": {
                "fragments": [],
                "text": "Mistake bounds and logarithmic linear-threshold learning algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "An analysis that shows that a straightforward transformation applied to mistake bounded algorithms, consisting of adding a hypothesis testing phase, produces algorithms that have asymptotically optimal PAC-learning bounds for certain target classes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144007105"
                        ],
                        "name": "Philip M. Long",
                        "slug": "Philip-M.-Long",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Long",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip M. Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13012680,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ed6f52a5a6ec4f30eecc35035078b5d673748528",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm for the on-line learning of linear functions which is optimal to within a constant factor with respect to bounds on the sum of squared errors for a worst case sequence of trials. The bounds are logarithmic in the number of variables. Furthermore, the algorithm is shown to be optimally robust with respect to noise in the data (again to within a constant factor)."
            },
            "slug": "On-line-learning-of-linear-functions-Littlestone-Long",
            "title": {
                "fragments": [],
                "text": "On-line learning of linear functions"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An algorithm for the on-line learning of linear functions which is optimal to within a constant factor with respect to bounds on the sum of squared errors for a worst case sequence of trials is presented."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '91"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772099"
                        ],
                        "name": "D. Helmbold",
                        "slug": "D.-Helmbold",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Helmbold",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Helmbold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16694241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c58afc1b7fd284351d6897f315617084087d4340",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm is a weak learning algorithm if with some small probability it outputs a hypothesis with error slightly below 50%. This paper presents relationships between weak learning, weak prediction (where the probability of being correct is slightly larger than 50%), and consistency oracles (which decide whether or not a given set of examples is consistent with a concept in the class). Our main result is a simple polynomial prediction algorithm which makes only a single query to a consistency oracle and whose predictions have a polynomial edge over random guessing. We compare this prediction algorithm with several of the standard prediction techniques, deriving an improved worst case bound on Gibbs algorithm in the process. We use our algorithm to show that a concept class is polynomially learnable if and only if there is a polynomial probabilistic consistency oracle for the class. Since strong learning algorithms can be built from weak learning algorithms, our results also characterizes strong learnability."
            },
            "slug": "On-Weak-Learning-Helmbold-Warmuth",
            "title": {
                "fragments": [],
                "text": "On Weak Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents relationships between weak learning, weak prediction, and consistency oracles and uses an algorithm to show that a concept class is polynomially learnable if and only if there is a polynomial probabilistic consistency oracle for the class."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35643382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba51a954699dd2df2c89c4972411a6f18235b81d",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Redundant-noisy-attributes,-attribute-errors,-and-Littlestone",
            "title": {
                "fragments": [],
                "text": "Redundant noisy attributes, attribute errors, and linear-threshold learning using winnow"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '91"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 52
                            }
                        ],
                        "text": "The research reported in this paper was inspired by Littlestone (1989b, 1988), who provedworst-case bounds for the case when the comparison class consists of Boolean monomials, ormore generally linear threshold functions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 60
                            }
                        ],
                        "text": "The new family includes,respectively, the Winnow algorithm (Littlestone, 1988), the EG algorithm, the exponentiatedback-propagation algorithm, and an algorithm for tting a line to data points so that therelative entropy of the coe cient vector is minimized."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 60
                            }
                        ],
                        "text": "The new family includes, respectively, the Winnow algorithm (Littlestone, 1988), the EG algorithm, the exponentiated back-propagation algorithm, and an algorithm for tting a line to data points so that the relative entropy of the coe cient vector is minimized."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6334230,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1dace286582d91916fe470d08f30381cf453f20",
            "isKey": false,
            "numCitedBy": 1612,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Valiant (1984) and others have studied the problem of learning various classes of Boolean functions from examples. Here we discuss incremental learning of these functions. We consider a setting in which the learner responds to each example according to a current hypothesis. Then the learner updates the hypothesis, if necessary, based on the correct classification of the example. One natural measure of the quality of learning in this setting is the number of mistakes the learner makes. For suitable classes of functions, learning algorithms are available that make a bounded number of mistakes, with the bound independent of the number of examples seen by the learner. We present one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions. The basic method can be expressed as a linear-threshold algorithm. A primary advantage of this algorithm is that the number of mistakes grows only logarithmically with the number of irrelevant attributes in the examples. At the same time, the algorithm is computationally efficient in both time and space."
            },
            "slug": "Learning-Quickly-When-Irrelevant-Attributes-Abound:-Littlestone",
            "title": {
                "fragments": [],
                "text": "Learning Quickly When Irrelevant Attributes Abound: A New Linear-Threshold Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions."
            },
            "venue": {
                "fragments": [],
                "text": "28th Annual Symposium on Foundations of Computer Science (sfcs 1987)"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 15
                            }
                        ],
                        "text": "Vovk(1990) and Littlestone and Warmuth (1994) had bounds of the form (1.1) for the absolute loss."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 124
                            }
                        ],
                        "text": "Thus, if the same instance and outcome wereto be observed again, the loss L(y;w x) of the algorithm with the new weight vector shouldbe smaller than the loss L(y; s x) with the old weight vector."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12843330,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35582a30685083c62dca992553eec44123be9d07",
            "isKey": false,
            "numCitedBy": 1675,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The construction of prediction algorithms in a situation in which a learner faces a sequence of trials, with a prediction to be made in each, and the goal of the learner is to make few mistakes is studied. It is assumed that the learner has reason to believe that one of some pool of known algorithms will perform well but does not know which one. A simple and effective method, based on weighted voting, is introduced for constructing a compound algorithm in such a circumstance. It is called the weighted majority algorithm and is shown to be robust with respect to errors in the data. Various versions of the weighted majority algorithm are discussed, and error bounds for them that are closely related to the error bounds of the best algorithms of the pool are proved.<<ETX>>"
            },
            "slug": "The-weighted-majority-algorithm-Littlestone-Warmuth",
            "title": {
                "fragments": [],
                "text": "The Weighted Majority Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A simple and effective method, based on weighted voting, is introduced for constructing a compound algorithm in a situation in which a learner faces a sequence of trials, and the goal of the learner is to make few mistakes."
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Comput."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18487371,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84b32dc90e10bbf1ee5f8ab8063981e2169a025d",
            "isKey": false,
            "numCitedBy": 331,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Information-geometry-of-the-EM-and-em-algorithms-Amari",
            "title": {
                "fragments": [],
                "text": "Information geometry of the EM and em algorithms for neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6298480,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a769ec3a8fb442548beeafa9b5e0d71661b195ac",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we initiate an investigation of generalizations of the Probably Approximately Correct (PAC) learning model that attempt to signi cantly weaken the target function assumptions. The ultimate goal in this direction is informally termed agnostic learning, in which we make virtually no assumptions on the target function. The name derives from the fact that as designers of learning algorithms, we give up the belief that Nature (as represented by the target function) has a simple or succinct explanation. We give a number of positive and negative results that provide an initial outline of the possibilities for agnostic learning. Our results include hardness results for the most obvious generalization of the PAC model to an agnostic setting, an e cient and general agnostic learning method based on dynamic programming, relationships between loss functions for agnostic learning, and an algorithm for a learning problem that involves hidden variables."
            },
            "slug": "Toward-Eecient-Agnostic-Learning-Schapire",
            "title": {
                "fragments": [],
                "text": "Toward Eecient Agnostic Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Results include hardness results for the most obvious generalization of the PAC model to an agnostic setting, an e cient and general agnostic learning method based on dynamic programming, relationships between loss functions for agnosticLearning, and an algorithm for a learning problem that involves hidden variables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207165665,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2599131a4bc2fa957338732a37c744cfe3e17b24",
            "isKey": false,
            "numCitedBy": 10843,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms."
            },
            "slug": "A-training-algorithm-for-optimal-margin-classifiers-Boser-Guyon",
            "title": {
                "fragments": [],
                "text": "A training algorithm for optimal margin classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented, applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2865619"
                        ],
                        "name": "Linda Sellie",
                        "slug": "Linda-Sellie",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Sellie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Linda Sellie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Obviously, if no assumptions are made concerning the relation between the instances and outcomes, there is not much a prediction algorithm can do. To set a reasonable goal, we measure the performance of the algorithm against the performances of predictors from some fixed comparison class P. (The comparison class is analogous to the touchstone class of the agnostic PAC model of learning ( Kearns et al., 1994 ).) The algorithm is required to ..."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 53249028,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14b99f9a9ddb35477982b0bc28da2468863977a3",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we initiate an investigation of generalizations of the Probably Approximately Correct (PAC) learning model that attempt to significantly weaken the target function assumptions. The ultimate goal in this direction is informally termed agnostic learning, in which we make virtually no assumptions on the target function. The name derives from the fact that as designers of learning algorithms, we give up the belief that Nature (as represented by the target function) has a simple or succinct explanation. We give a number of positive and negative results that provide an initial outline of the possibilities for agnostic learning. Our results include hardness results for the most obvious generalization of the PAC model to an agnostic setting, an efficient and general agnostic learning method based on dynamic programming, relationships between loss functions for agnostic learning, and an algorithm for a learning problem that involves hidden variables."
            },
            "slug": "Toward-Efficient-Agnostic-Learning-Kearns-Schapire",
            "title": {
                "fragments": [],
                "text": "Toward Efficient Agnostic Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "An investigation of generalizations of the Probably Approximately Correct (PAC) learning model that attempt to significantly weaken the target function assumptions is initiated, providing an initial outline of the possibilities for agnostic learning."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772099"
                        ],
                        "name": "D. Helmbold",
                        "slug": "D.-Helmbold",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Helmbold",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Helmbold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 41
                            }
                        ],
                        "text": "This framework hasbeen adapted recently (Helmbold et al., 1996b and 1996c) to an unsupervised setting.3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 75
                            }
                        ],
                        "text": "We apply the bound ln(1 q(1 ep)) pq+ p2=8, whichholds for 0 q 1 and p 2 R (Helmbold et al., 1996b, Lemma 1)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 121
                            }
                        ],
                        "text": "It has also been noticed that in applying the exponenti-ated gradient update to a certain unsupervised learning problem (Helmbold et al., 1996b and1996c) the approximation given here leads to a generalization of the Expectation Maximizationalgorithm (Dempster et al., 1977)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 227
                            }
                        ],
                        "text": "In a simple unsupervisedlearning problem for learning mixture coe cients it has been noticed that the distance mea-sure d 2 can also be used to motivate a generalization of the Expectation Maximization (EM)optimization method (Helmbold et al., 1996b and 1996c)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 4
                            }
                        ],
                        "text": "See Helmbold et al. (1996b) for some plots thatvisualize the distance measures for probability vectors in the three-dimensional case.3 The main algorithmsIn this section we introduce the main on-line prediction algorithms we consider in this paper."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 0
                            }
                        ],
                        "text": "Helmbold et al. (1996b, 1996c) give an alternative motivation for (4.3)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10662553,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c67c60a5f5cc76cb664660cdbeacc7201f28d83e",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an on\u2010line investment algorithm that achieves almost the same wealth as the best constant\u2010rebalanced portfolio determined in hindsight from the actual market outcomes. The algorithm employs a multiplicative update rule derived using a framework introduced by Kivinen and Warmuth. Our algorithm is very simple to implement and requires only constant storage and computing time per stock in each trading period. We tested the performance of our algorithm on real stock data from the New York Stock Exchange accumulated during a 22\u2010year period. On these data, our algorithm clearly outperforms the best single stock as well as Cover's universal portfolio selection algorithm. We also present results for the situation in which the investor has access to additional \u201cside information.\u201d"
            },
            "slug": "On\u2010Line-Portfolio-Selection-Using-Multiplicative-Helmbold-Schapire",
            "title": {
                "fragments": [],
                "text": "On\u2010Line Portfolio Selection Using Multiplicative Updates"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An on\u2010line investment algorithm that achieves almost the same wealth as the best constant\u2010rebalanced portfolio determined in hindsight from the actual market outcomes is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772099"
                        ],
                        "name": "D. Helmbold",
                        "slug": "D.-Helmbold",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Helmbold",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Helmbold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5141514,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2caa093420807f92045a826e4027426ff2dc098a",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm is a weak learner if with some small probability itoutputs a hypothesis with error slightly below 50%. This paper presentssufficient conditions for weak learning.\nOur main result requires a \u201cconsistency oracle\u201d for theconcept class <inline-equation><f><ge>F</ge></f></inline-equation> which decides for a given set of examples whetherthere is a concept in <inline-equation><f><ge>F</ge></f></inline-equation> consistent with the examples. We show that such anoracle can be used to construct a computationally efficient weaklearning algorithm for <inline-equation><f><rm><ge>F</ge></rm></f></inline-equation> if<inline-equation><f><ge>F</ge></f><?Pub Caret></inline-equation> is learnable at all. We considerconsistency oracles which are allowed to give wrong answers anddiscusses how the number of incorrect answers effects the oracle's usein computationally efficient weak learning algorihms.\nWe also define \u201cweak Occam algorithms\u201d which, when given a set of <?Pub Fmt italic>m<?Pub Fmt /italic> examples, select aconsistent hypothesis from some class of2<?Pub Fmt italic><supscrpt>m-(1/p(m))</supscrpt><?Pub Fmt /italic>possible hypotheses. We show that these weak Occam algorithms are alsoweak learners. In contrast, we show that an Occam style algorithm whichselects a consistent hypothesis from a class of2<?Pub Fmt italic><supscrpt>m+1</supscrpt><?Pub Fmt /italic>-2hypotheses is not a weak learner."
            },
            "slug": "Some-weak-learning-results-Helmbold-Warmuth",
            "title": {
                "fragments": [],
                "text": "Some weak learning results"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "sufficient conditions for weak learning are presented and consistency oracles which are allowed to give wrong answers are considered and how the number of incorrect answers effects the oracle's use in computationally efficient weak learning algorihms are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144007105"
                        ],
                        "name": "Philip M. Long",
                        "slug": "Philip-M.-Long",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Long",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip M. Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 148
                            }
                        ],
                        "text": "\u2026we call the EGM algorithm, has the updaterule wt+1;i = wt;irt;i=(Pj wt;jrt;j) wherert;i = exp ( 2 (y\u0302 yt) Mt;i) : (7:3)It has been previously shown (Cesa-Bianchi et al., 1996; Schapire and Warmuth, 1994) thatthe GDM algorithm has a loss bound similar to that of GD. Recall that the norm jjAjj2\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 41
                            }
                        ],
                        "text": "The analysis was originally presented by Cesa-Bianchi et al. (1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 178
                            }
                        ],
                        "text": "However, if such estimates are not known before the trial sequence begins, it is in some situations possible to use an iterative method, commonly known as the doubling technique (Cesa-Bianchi et al., 1994; Cesa-Bianchi et al., 1996), for obtaining increasingly accurate estimates as the trial sequence proceeds and modifying the learning rate accordingly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 111
                            }
                        ],
                        "text": "If only one of the parameters is unknown, there are strategies for guessing its value with increasing accuracy (Cesa-Bianchi et al., 1994; Cesa-Bianchi et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 37
                            }
                        ],
                        "text": "The following lower bound, also from Cesa-Bianchi et al. (1996), shows that if the number N of dimensions can be arbitrarily large, thenagain the loss bound for GD is the best possible, even if range of the outcomes is restricted."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 549,
                                "start": 494
                            }
                        ],
                        "text": "In the updates, we replace the derivatives @L(yt;wt xt) @wt;i = Lyt(wt xt)xt;i (7:1) by @L(yt;Mtwt) @wt;i = @L(yt; z) @z z=Mtwt Mt;i : (7:2) In particular, for the square loss the generalization of the GD algorithm, which we call the GDM algorithm, has the update rule wt+1 = wt 2 MT t (\u0177 yt) and the generalization for the EG algorithm, which we call the EGM algorithm, has the update rule wt+1;i = wt;irt;i=(Pj wt;jrt;j) where rt;i = exp ( 2 (\u0177 yt) Mt;i) : (7:3) It has been previously shown (Cesa-Bianchi et al., 1996; Schapire and Warmuth, 1994) that the GDM algorithm has a loss bound similar to that of GD."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 114
                            }
                        ],
                        "text": "The algorithm GD(s; ) has many names, including the Widrow-Ho algorithm and the Least Mean Square (LMS) algorithm (Cesa-Bianchi et al., 1996; Widrow and Stearns, 1985)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 113
                            }
                        ],
                        "text": "The algorithm GD(s; )has many names, including the Widrow-Ho algorithm and the Least Mean Square (LMS)algorithm (Cesa-Bianchi et al., 1996; Widrow and Stearns, 1985)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 64
                            }
                        ],
                        "text": "2The special case p = q = 2 of Theorem 6.1 was noted already by Cesa-Bianchi et al. (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 63
                            }
                        ],
                        "text": "For the GD algorithm, the bounds we cite were already given by Cesa-Bianchi et al. (1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 149
                            }
                        ],
                        "text": "For the GD algorithm, setting the learning rate suitably results in the bound Loss(GD; S) 2 Loss(u; S) + jjujj22X2 that holds for all vectors u 2 RN (Cesa-Bianchi et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 98
                            }
                        ],
                        "text": "The method is an abstraction of the proof method employed by Littlestone (1989b, 1990) and others (Littlestone et al., 1995; Cesa-Bianchi et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 147
                            }
                        ],
                        "text": "\u2026sequence begins, it is in some situations possible touse an iterative method, commonly known as the doubling technique (Cesa-Bianchi et al., 1994;Cesa-Bianchi et al., 1996), for obtaining increasingly accurate estimates as the trial sequenceproceeds and modifying the learning rate accordingly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 47
                            }
                        ],
                        "text": "3) but has slightly larger constant coe cients (Cesa-Bianchi et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 149
                            }
                        ],
                        "text": "For the GD algorithm, setting the learning rate suitably resultsin the bound Loss(GD; S) 2 Loss(u; S) + jjujj22X2 that holds for all vectors u 2 RN (Cesa-Bianchi et al., 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 91
                            }
                        ],
                        "text": "This leads to a bound thatis similar to (1.3) but has slightly larger constant coe cients (Cesa-Bianchi et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 138
                            }
                        ],
                        "text": "If only one of the parameters is unknown, there are strategiesfor guessing its value with increasing accuracy (Cesa-Bianchi et al., 1994; Cesa-Bianchi et al.,1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 124
                            }
                        ],
                        "text": "The method is an abstraction of the proof methodemployed by Littlestone (1989b, 1990) and others (Littlestone et al., 1995; Cesa-Bianchi et al.,1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 58
                            }
                        ],
                        "text": "The immediate predecessors of this work are the papers by Cesa-Bianchi et al. (1996)and Littlestone et al. (1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12379829,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "985abb957e4b3a153e6c8c66853713684ab7bed4",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We prove worst-case bounds on the sum of squared errors incurred by a generalization of the classical Widrow-Hoff algorithm to inner product spaces. We describe applications of this result to obtain worst-case agnostic learning results for classes of smooth functions and of linear functions."
            },
            "slug": "Worst-case-quadratic-loss-bounds-for-a-of-the-rule-Cesa-Bianchi-Long",
            "title": {
                "fragments": [],
                "text": "Worst-case quadratic loss bounds for a generalization of the Widrow-Hoff rule"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "It is proved that worst-case bounds on the sum of squared errors incurred by a generalization of the classical Widrow-Hoff algorithm to inner product spaces are correct."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 81
                            }
                        ],
                        "text": "Thisapproach to updating a weight vector is similar to the methods introduced by Amari (1994,1995) for more general neural network learning problems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 49741517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0885ae2f0e47d7ff572a54f9022d1a62aa91b47",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden units play an important role in neural networks, although their activation values are unknown in many learning situations. The EM algorithm (statistical algorithm) and the em algorithm (information-geometric one) have been proposed so far in this connection, and the effectiveness of such algorithms is recognized in many areas of research. The present note points out that these two algorithms are equivalent under a certain condition, although they are different in general."
            },
            "slug": "The-EM-Algorithm-and-Information-Geometry-in-Neural-Amari",
            "title": {
                "fragments": [],
                "text": "The EM Algorithm and Information Geometry in Neural Network Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The present note points out that these two algorithms are equivalent under a certain condition, although they are different in general."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "0 50 100 150 200 250 300 0\n50\n100\n150\n200\n250\n300\ntrials\ncu m\nul at\niv e\nlo ss\nEG+-\nGDFigure 8: Cumulative losses of GD and EGV , with their upper bounds, for target u = (1; : : : ; 1)and instances from the 20-dimensional unit sphere."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 251
                            }
                        ],
                        "text": "It has also been noticed that in applying the exponenti-ated gradient update to a certain unsupervised learning problem (Helmbold et al., 1996b and1996c) the approximation given here leads to a generalization of the Expectation Maximizationalgorithm (Dempster et al., 1977)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055575683"
                        ],
                        "name": "Steve Rogers",
                        "slug": "Steve-Rogers",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Rogers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steve Rogers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 251
                            }
                        ],
                        "text": "This is in contrast to more common approaches where statistical assumptions about the distribution of the instances and the dependence of the outcomes on the instances are used in order to derive probabilistic loss bounds for the prediction algorithm (Widrow and Stearns, 1985; Haykin, 1991)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 275
                            }
                        ],
                        "text": "This is in contrast tomore common approaches where statistical assumptions about the distribution of the instancesand the dependence of the outcomes on the instances are used in order to derive probabilisticloss bounds for the prediction algorithm (Widrow and Stearns, 1985; Haykin, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 109523942,
            "fieldsOfStudy": [
                "Engineering",
                "Biology"
            ],
            "id": "6b2abc90dffc1a434f49881b1468aaf896f7923a",
            "isKey": false,
            "numCitedBy": 2039,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Adaptive-Filter-Theory-Rogers",
            "title": {
                "fragments": [],
                "text": "Adaptive Filter Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69924093"
                        ],
                        "name": "S. Hyakin",
                        "slug": "S.-Hyakin",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Hyakin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hyakin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60577818,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "045310b06e8a3983a363a118cc9dcc3f292970b4",
            "isKey": false,
            "numCitedBy": 9899,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Simon Haykin Neural Networks A Comprehensive Foundation. Neural Networks A Comprehensive Foundation Simon S. Neural Networks A Comprehensive Foundation Simon S. Neural Networks A Comprehensive Foundation. Neural Networks Association for Computing Machinery. Book Review Neural Networks A Comprehensive Foundation. Neural Networks A Comprehensive Foundation Pearson. Neural networks a comprehensive foundation. Neural Networks a Comprehensive Foundation AbeBooks. Neural networks a comprehensive foundation solutions. cdn preterhuman net. Neural Networks A Comprehensive Foundation Goodreads. Neural Networks A Comprehensive Foundation Amazon it. Neural Networks A Comprehensive Foundation Amazon co uk. Neural Networks A Comprehensive Foundation 3rd Edition. Neural Networks A Comprehensive Foundation Simon. Neural Networks A Comprehensive Foundation amazon com. Neural networks a comprehensive foundation Academia edu. Neural Networks A Comprehensive Foundation Amazon. neural networks a comprehensive foundation simon haykin. Simon Haykin Neural Networks A Comprehensive Foundation. Neural Networks A comprehensive Foundation 2 ed. Simon haykin neural networks a comprehensive foundation pdf. Buy Neural Networks A Comprehensive Foundation Book. Neural networks a comprehensive foundation 2e book. Neural Networks A Comprehensive Foundation. NEURAL NETWORKS A COMPREHENSIVE FOUNDATION SIMON. Neural Networks a Comprehensive Foundation by Haykin Simon. Neural Networks A Comprehensive Foundation pdf PDF Drive. Neural Networks A Comprehensive Foundation amazon ca. Simon Haykin Neural Networks A Comprehensive Foundation. NEURAL NETWORKS A Comprehensive Foundation PDF. Neural Networks A Comprehensive Foundation pdf PDF Drive. Neural Networks A Comprehensive Foundation by Haykin. Neural Networks A Comprehensive Foundation 3rd Edition. Neural Networks A Comprehensive Foundation Simon S. Neural Networks A Comprehensive Foundation. Neural networks a comprehensive foundation Book 1994. Neural Networks A Comprehensive Foundation 2nd Edition. Neural Networks A Comprehensive Foundation S S Haykin. Neural Networks A Comprehensive Foundation International. Neural Networks A Comprehensive Foundation 2 e Pearson. Download Neural Networks A Comprehensive Foundation 2Nd. Neural Networks A comprehensive foundation Aalto"
            },
            "slug": "Neural-Networks:-A-Comprehensive-Foundation-Hyakin",
            "title": {
                "fragments": [],
                "text": "Neural Networks: A Comprehensive Foundation"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "Simon Haykin Neural Networks A Comprehensive Foundation Simon S. Haykin neural networks a comprehensive foundation pdf PDF Drive."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69508860"
                        ],
                        "name": "J. N. Kapur",
                        "slug": "J.-N.-Kapur",
                        "structuredName": {
                            "firstName": "Jagat",
                            "lastName": "Kapur",
                            "middleNames": [
                                "Narain"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. N. Kapur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143860677"
                        ],
                        "name": "H. Kesavan",
                        "slug": "H.-Kesavan",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Kesavan",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kesavan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 100
                            }
                        ],
                        "text": "The use of this distance measure is motivated by the Minimum Relative Entropy Principle of Kullback (Kapur and Kesavan, 1992; Jumarie, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 99
                            }
                        ],
                        "text": "The use of this distance measure is motivated by theMinimum RelativeEntropy Principle of Kullback (Kapur and Kesavan, 1992; Jumarie, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 101
                            }
                        ],
                        "text": "These fundamental principles have many applications in InformationTheory, Physics and Economics (See Kapur and Kesavan (1992) and Jumarie (1990) for anoverview)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 167
                            }
                        ],
                        "text": "The use of the relative entropy as a distance measure is motivatedby the Maximum Entropy Principle of Jaynes and the more general Minimum Relative EntropyPrinciple of Kullback."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 77
                            }
                        ],
                        "text": "The EG algorithm results from using for d the relative entropy, alsoknown as Kullback-Leibler divergence,dre(w; s) = NXi=1wi ln wisi :This assumes that all the components si and wi are positive, and the constraints Pi si =Piwi = 1 are maintained."
                    },
                    "intents": []
                }
            ],
            "corpusId": 118787942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b027d77a20e713e7244db0f92e73dc5370e94a82",
            "isKey": true,
            "numCitedBy": 1051,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Entropy optimization principles Jaynes' maximum entropy principle applications of Jaynes' maximum entropy principle Kullback's minimum cross-entropy principle further applications of MaxEnt and MinEnt new entropy optimization principles generalized principles of maximum entropy the four inverse maximum entropy principles."
            },
            "slug": "Entropy-optimization-principles-with-applications-Kapur-Kesavan",
            "title": {
                "fragments": [],
                "text": "Entropy optimization principles with applications"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "Applications of Jaynes' maximum entropy principle and Kullback's minimum cross-entropy principle are applied to develop new entropy optimization principles generalized principles of maximum entropy the four inverse maximum entropy principles."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702312"
                        ],
                        "name": "G. Jumarie",
                        "slug": "G.-Jumarie",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Jumarie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Jumarie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119023126,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "e8a4a6b19423ec44bae53951fd769837824b06b4",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This introductory chapter gives a brief description of the main ideas that motivated this book."
            },
            "slug": "Relative-Information-\u2014-What-For-Jumarie",
            "title": {
                "fragments": [],
                "text": "Relative Information \u2014 What For?"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This introductory chapter gives a brief description of the main ideas that motivated this book."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143188751"
                        ],
                        "name": "H. Johnson",
                        "slug": "H.-Johnson",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "Johnson",
                            "middleNames": [
                                "Louise"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 41
                            }
                        ],
                        "text": "This framework hasbeen adapted recently (Helmbold et al., 1996b and 1996c) to an unsupervised setting.3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 75
                            }
                        ],
                        "text": "We apply the bound ln(1 q(1 ep)) pq+ p2=8, whichholds for 0 q 1 and p 2 R (Helmbold et al., 1996b, Lemma 1)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 121
                            }
                        ],
                        "text": "It has also been noticed that in applying the exponenti-ated gradient update to a certain unsupervised learning problem (Helmbold et al., 1996b and1996c) the approximation given here leads to a generalization of the Expectation Maximizationalgorithm (Dempster et al., 1977)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 227
                            }
                        ],
                        "text": "In a simple unsupervisedlearning problem for learning mixture coe cients it has been noticed that the distance mea-sure d 2 can also be used to motivate a generalization of the Expectation Maximization (EM)optimization method (Helmbold et al., 1996b and 1996c)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 4
                            }
                        ],
                        "text": "See Helmbold et al. (1996b) for some plots thatvisualize the distance measures for probability vectors in the three-dimensional case.3 The main algorithmsIn this section we introduce the main on-line prediction algorithms we consider in this paper."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 0
                            }
                        ],
                        "text": "Helmbold et al. (1996b, 1996c) give an alternative motivation for (4.3)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 116096508,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "78f749705501e89fd953e9683f7cee464caca687",
            "isKey": true,
            "numCitedBy": 4866,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Turkish Ministry of National Education established special field competencies for secondary education teachers in 2011. Special field competences are field-specific knowledge, skills, and attitudes necessary for effective and productive conduct of teaching profession. The aim of the present article is to compare the opinions of Geography Education Department, and Geography Department students regarding the field knowledge, one of the special field competences of geography teaching. The study was based on survey method aimed to reveal an existing situation. However, face-to-face interviews were conducted with 20 students from the Faculty of Education in order to find the origin of results. The study was performed in the spring semester of 2014-2015 academic year with a total of 160 students from 3rd, 4th, and 5th grades of Geography Education Department and 3rd and 4th grades of Geography Department. Significant differences between the opinions of students were compared by ChiSquare analysis by their educational programs. The expressions of Faculty of Education students suggested that they were competent in 7 out of 13 fields, creating a significant difference. There was no significant difference in the opinions of Geography Department students regarding the geography field competences."
            },
            "slug": "A-Comparison-of-the-Johnson",
            "title": {
                "fragments": [],
                "text": "A Comparison of the"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1949
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 284
                            }
                        ],
                        "text": "In a simpler situation, where the learner is not trying to learn a linear function but merely to pick out the best single component of the instances for predicting the outcomes, it has been possible to use a similar approach to prove bounds for a very general class of loss functions (Vovk, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "Vovk (1990) proved that for a large class of loss functions,a simple algorithm achieves bounds of the form LossL(A; S) infu2U LossL(u; S) + c logN ,where the constant c depends only on the loss function."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Vovk(1990) and Littlestone and Warmuth (1994) had bounds of the form (1.1) for the absolute loss."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 282
                            }
                        ],
                        "text": "In a simplersituation, where the learner is not trying to learn a linear function but merely to pick out thebest single component of the instances for predicting the outcomes, it has been possible touse a similar approach to prove bounds for a very general class of loss functions (Vovk, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Aggregating strategies, in \\Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "3rd Annual Workshop on Compu-"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 41
                            }
                        ],
                        "text": "This framework hasbeen adapted recently (Helmbold et al., 1996b and 1996c) to an unsupervised setting.3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 75
                            }
                        ],
                        "text": "We apply the bound ln(1 q(1 ep)) pq+ p2=8, whichholds for 0 q 1 and p 2 R (Helmbold et al., 1996b, Lemma 1)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 121
                            }
                        ],
                        "text": "It has also been noticed that in applying the exponenti-ated gradient update to a certain unsupervised learning problem (Helmbold et al., 1996b and1996c) the approximation given here leads to a generalization of the Expectation Maximizationalgorithm (Dempster et al., 1977)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 227
                            }
                        ],
                        "text": "In a simple unsupervisedlearning problem for learning mixture coe cients it has been noticed that the distance mea-sure d 2 can also be used to motivate a generalization of the Expectation Maximization (EM)optimization method (Helmbold et al., 1996b and 1996c)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 4
                            }
                        ],
                        "text": "See Helmbold et al. (1996b) for some plots thatvisualize the distance measures for probability vectors in the three-dimensional case.3 The main algorithmsIn this section we introduce the main on-line prediction algorithms we consider in this paper."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 0
                            }
                        ],
                        "text": "Helmbold et al. (1996b, 1996c) give an alternative motivation for (4.3)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Worst-case loss bounds for sigmoided linear neurons"
            },
            "venue": {
                "fragments": [],
                "text": "\\Advances in Neural Information Processing Systems"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 111
                            }
                        ],
                        "text": "If only one of the parameters is unknown, there are strategiesfor guessing its value with increasing accuracy (Cesa-Bianchi et al., 1994; Cesa-Bianchi et al.,1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 148
                            }
                        ],
                        "text": "\u2026not known before the trial sequence begins, it is in some situations possible touse an iterative method, commonly known as the doubling technique (Cesa-Bianchi et al., 1994;Cesa-Bianchi et al., 1996), for obtaining increasingly accurate estimates as the trial sequenceproceeds and modifying the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 6
                            }
                        ],
                        "text": "Later Cesa-Bianchi et al. (1994) showed how these bounds could be improved to the form (1.2)by a careful choice of certain parameters in Vovk's algorithm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 50
                            }
                        ],
                        "text": "Moresophisticated conversion methods are given by Cesa-Bianchi et al. (1994) and Littlestone (1989).9 Experimental and theoretical comparison of the algorithms9."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "How to Use Expert Advice An extended abstract appeared inin"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings , 25th Annual ACM Symposium on the Theory of Computing"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 148
                            }
                        ],
                        "text": "\u2026not known before the trial sequence begins, it is in some situations possible touse an iterative method, commonly known as the doubling technique (Cesa-Bianchi et al., 1994;Cesa-Bianchi et al., 1996), for obtaining increasingly accurate estimates as the trial sequenceproceeds and modifying the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 178
                            }
                        ],
                        "text": "However, if such estimates are not known before the trial sequence begins, it is in some situations possible to use an iterative method, commonly known as the doubling technique (Cesa-Bianchi et al., 1994; Cesa-Bianchi et al., 1996), for obtaining increasingly accurate estimates as the trial sequence proceeds and modifying the learning rate accordingly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 111
                            }
                        ],
                        "text": "If only one of the parameters is unknown, there are strategies for guessing its value with increasing accuracy (Cesa-Bianchi et al., 1994; Cesa-Bianchi et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 56
                            }
                        ],
                        "text": "Predictors from a finite class are often called experts (Cesa-Bianchi et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 50
                            }
                        ],
                        "text": "Moresophisticated conversion methods are given by Cesa-Bianchi et al. (1994) and Littlestone (1989).9 Experimental and theoretical comparison of the algorithms9."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 111
                            }
                        ],
                        "text": "If only one of the parameters is unknown, there are strategiesfor guessing its value with increasing accuracy (Cesa-Bianchi et al., 1994; Cesa-Bianchi et al.,1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 6
                            }
                        ],
                        "text": "Later Cesa-Bianchi et al. (1994) showed how these bounds could be improved to the form (1.2)by a careful choice of certain parameters in Vovk's algorithm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "``How to Use Expert Advice,'' Technical Report UCSC-CRL-94-33, Univ. of California, Santa Cruz, Computer Research Laboratory. An extended abstract appeared in ``Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "25th Annual ACM Symposium on the Theory of Computing,''"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 41
                            }
                        ],
                        "text": "This framework hasbeen adapted recently (Helmbold et al., 1996b and 1996c) to an unsupervised setting.3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 75
                            }
                        ],
                        "text": "We apply the bound ln(1 q(1 ep)) pq+ p2=8, whichholds for 0 q 1 and p 2 R (Helmbold et al., 1996b, Lemma 1)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 121
                            }
                        ],
                        "text": "It has also been noticed that in applying the exponenti-ated gradient update to a certain unsupervised learning problem (Helmbold et al., 1996b and1996c) the approximation given here leads to a generalization of the Expectation Maximizationalgorithm (Dempster et al., 1977)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 227
                            }
                        ],
                        "text": "In a simple unsupervisedlearning problem for learning mixture coe cients it has been noticed that the distance mea-sure d 2 can also be used to motivate a generalization of the Expectation Maximization (EM)optimization method (Helmbold et al., 1996b and 1996c)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 4
                            }
                        ],
                        "text": "See Helmbold et al. (1996b) for some plots thatvisualize the distance measures for probability vectors in the three-dimensional case.3 The main algorithmsIn this section we introduce the main on-line prediction algorithms we consider in this paper."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 0
                            }
                        ],
                        "text": "Helmbold et al. (1996b, 1996c) give an alternative motivation for (4.3)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Worst-case loss bounds for sigmoided linear neurons, in ``Advances in Neural Information Processing Systems 8,'"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 41
                            }
                        ],
                        "text": "This framework hasbeen adapted recently (Helmbold et al., 1996b and 1996c) to an unsupervised setting.3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 75
                            }
                        ],
                        "text": "We apply the bound ln(1 q(1 ep)) pq+ p2=8, whichholds for 0 q 1 and p 2 R (Helmbold et al., 1996b, Lemma 1)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 121
                            }
                        ],
                        "text": "It has also been noticed that in applying the exponenti-ated gradient update to a certain unsupervised learning problem (Helmbold et al., 1996b and1996c) the approximation given here leads to a generalization of the Expectation Maximizationalgorithm (Dempster et al., 1977)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 227
                            }
                        ],
                        "text": "In a simple unsupervisedlearning problem for learning mixture coe cients it has been noticed that the distance mea-sure d 2 can also be used to motivate a generalization of the Expectation Maximization (EM)optimization method (Helmbold et al., 1996b and 1996c)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 4
                            }
                        ],
                        "text": "See Helmbold et al. (1996b) for some plots thatvisualize the distance measures for probability vectors in the three-dimensional case.3 The main algorithmsIn this section we introduce the main on-line prediction algorithms we consider in this paper."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 0
                            }
                        ],
                        "text": "Helmbold et al. (1996b, 1996c) give an alternative motivation for (4.3)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Worst-case loss bounds for sig"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144323963"
                        ],
                        "name": "S. Alexander",
                        "slug": "S.-Alexander",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Alexander",
                            "middleNames": [
                                "Thomas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Alexander"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 251
                            }
                        ],
                        "text": "This is in contrast to more common approaches where statistical assumptions about the distribution of the instances and the dependence of the outcomes on the instances are used in order to derive probabilistic loss bounds for the prediction algorithm (Widrow and Stearns, 1985; Haykin, 1991)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 140
                            }
                        ],
                        "text": "The algorithm GD(s; )has many names, including the Widrow-Ho algorithm and the Least Mean Square (LMS)algorithm (Cesa-Bianchi et al., 1996; Widrow and Stearns, 1985)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 249
                            }
                        ],
                        "text": "This is in contrast tomore common approaches where statistical assumptions about the distribution of the instancesand the dependence of the outcomes on the instances are used in order to derive probabilisticloss bounds for the prediction algorithm (Widrow and Stearns, 1985; Haykin, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 117
                            }
                        ],
                        "text": "The algorithm GD(s, ') has many names, including the Widrow Hoff algorithm and the Least Mean Square (LMS) algorithm (Cesa-Bianchi et al., 1996; Widrow and Stearns, 1985)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12374910,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7d78b005150b873a1b72423cdc045267e03daa7",
            "isKey": true,
            "numCitedBy": 3372,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Adaptive-Signal-Processing-Alexander",
            "title": {
                "fragments": [],
                "text": "Adaptive Signal Processing"
            },
            "venue": {
                "fragments": [],
                "text": "Texts and Monographs in Computer Science"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 148
                            }
                        ],
                        "text": "\u2026has the updaterule wt+1;i = wt;irt;i=(Pj wt;jrt;j) wherert;i = exp ( 2 (y\u0302 yt) Mt;i) : (7:3)It has been previously shown (Cesa-Bianchi et al., 1996; Schapire and Warmuth, 1994) thatthe GDM algorithm has a loss bound similar to that of GD. Recall that the norm jjAjj2 for amatrix A is de ned as\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 57
                            }
                        ],
                        "text": "The upper bound of Theorem 7.1 can be shown to be tight (Schapire and Warmuth, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the worst-case analysis of temporal-difference learing algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings , 11 th International Conference on Machine Learning"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 99
                            }
                        ],
                        "text": "The use of this distance measure is motivated by theMinimum Relative Entropy Principle of Kullback (Kapur and Kesavan, 1992; Jumarie, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 124
                            }
                        ],
                        "text": "The use of this distance measure is motivated by theMinimum RelativeEntropy Principle of Kullback (Kapur and Kesavan, 1992; Jumarie, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 130
                            }
                        ],
                        "text": "These fundamental principles have many applications in InformationTheory, Physics and Economics (See Kapur and Kesavan (1992) and Jumarie (1990) for anoverview)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 167
                            }
                        ],
                        "text": "The use of the relative entropy as a distance measure is motivatedby the Maximum Entropy Principle of Jaynes and the more general Minimum Relative EntropyPrinciple of Kullback."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 77
                            }
                        ],
                        "text": "The EG algorithm results from using for d the relative entropy, alsoknown as Kullback-Leibler divergence,dre(w; s) = NXi=1wi ln wisi :This assumes that all the components si and wi are positive, and the constraints Pi si =Piwi = 1 are maintained."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Relative information,\" Springer, New York"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 549,
                                "start": 494
                            }
                        ],
                        "text": "In the updates, we replace the derivatives @L(yt;wt xt) @wt;i = Lyt(wt xt)xt;i (7:1) by @L(yt;Mtwt) @wt;i = @L(yt; z) @z z=Mtwt Mt;i : (7:2) In particular, for the square loss the generalization of the GD algorithm, which we call the GDM algorithm, has the update rule wt+1 = wt 2 MT t (\u0177 yt) and the generalization for the EG algorithm, which we call the EGM algorithm, has the update rule wt+1;i = wt;irt;i=(Pj wt;jrt;j) where rt;i = exp ( 2 (\u0177 yt) Mt;i) : (7:3) It has been previously shown (Cesa-Bianchi et al., 1996; Schapire and Warmuth, 1994) that the GDM algorithm has a loss bound similar to that of GD."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 148
                            }
                        ],
                        "text": "\u2026has the updaterule wt+1;i = wt;irt;i=(Pj wt;jrt;j) wherert;i = exp ( 2 (y\u0302 yt) Mt;i) : (7:3)It has been previously shown (Cesa-Bianchi et al., 1996; Schapire and Warmuth, 1994) thatthe GDM algorithm has a loss bound similar to that of GD. Recall that the norm jjAjj2 for amatrix A is de ned as\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 57
                            }
                        ],
                        "text": "The upper bound of Theorem 7.1 can be shown to be tight (Schapire and Warmuth, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the worst-case analysis of temporal-di"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 99
                            }
                        ],
                        "text": "The use of this distance measure is motivated by theMinimum Relative Entropy Principle of Kullback (Kapur and Kesavan, 1992; Jumarie, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 99
                            }
                        ],
                        "text": "The use of this distance measure is motivated by theMinimum RelativeEntropy Principle of Kullback (Kapur and Kesavan, 1992; Jumarie, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 101
                            }
                        ],
                        "text": "These fundamental principles have many applications in InformationTheory, Physics and Economics (See Kapur and Kesavan (1992) and Jumarie (1990) for anoverview)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 167
                            }
                        ],
                        "text": "The use of the relative entropy as a distance measure is motivatedby the Maximum Entropy Principle of Jaynes and the more general Minimum Relative EntropyPrinciple of Kullback."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 77
                            }
                        ],
                        "text": "The EG algorithm results from using for d the relative entropy, alsoknown as Kullback-Leibler divergence,dre(w; s) = NXi=1wi ln wisi :This assumes that all the components si and wi are positive, and the constraints Pi si =Piwi = 1 are maintained."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Entropy Optimization Principles with Applica"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 281
                            }
                        ],
                        "text": "\u2026is given a parameter K, then it achieves the boundLoss(EG ; S) Loss(u; S) + 2pK ln 2NUX + 2U2X2 ln 2N (1:4)for all comparison vectors u and trial sequences S such that jjujj1 U and Loss(u; S) Khold and jjxtjj1 X holds for all t.Note that Lp and Lq are dual norms if 1=p+ 1=q = 1 (Royden, 1963)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 146
                            }
                        ],
                        "text": "If the norms Lp and Lq are dual, then the Cauchy Schwartz Inequality can be generalized to show that &u& p U and &x&q X together imply |u } x| UX (Royden, 1963)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 146
                            }
                        ],
                        "text": "If the norms Lp and Lq are dual, then theCauchy-Schwartz Inequality can be generalized to show that jjujjp U and jjxjjq X togetherimply ju xj UX (Royden, 1963)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 48
                            }
                        ],
                        "text": "Note that Lp and Lq are dual norms if 1 p+1 q=1 (Royden, 1963)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "``Real Analysis,'' Macmillan, New York"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 148
                            }
                        ],
                        "text": "\u2026has the updaterule wt+1;i = wt;irt;i=(Pj wt;jrt;j) wherert;i = exp ( 2 (y\u0302 yt) Mt;i) : (7:3)It has been previously shown (Cesa-Bianchi et al., 1996; Schapire and Warmuth, 1994) thatthe GDM algorithm has a loss bound similar to that of GD. Recall that the norm jjAjj2 for amatrix A is de ned as\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 57
                            }
                        ],
                        "text": "The upper bound of Theorem 7.1 can be shown to be tight (Schapire and Warmuth, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the worst-case analysis of temporal-diierence learing algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "\\Proceddings, 11th International Conference on Machine Learning"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 29
                            }
                        ],
                        "text": "It has been previously shown (Cesa-Bianchi et al., 1996; Schapire and Warmuth, 1994) that the GDM algorithm has a loss bound similar to that of GD."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 148
                            }
                        ],
                        "text": "\u2026has the updaterule wt+1;i = wt;irt;i=(Pj wt;jrt;j) wherert;i = exp ( 2 (y\u0302 yt) Mt;i) : (7:3)It has been previously shown (Cesa-Bianchi et al., 1996; Schapire and Warmuth, 1994) thatthe GDM algorithm has a loss bound similar to that of GD. Recall that the norm jjAjj2 for amatrix A is de ned as\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 57
                            }
                        ],
                        "text": "The upper bound of Theorem 7.1 can be shown to be tight (Schapire and Warmuth, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the worst-case analysis of temporal-difference learing algorithms, in ``Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "11th International Conference on Machine Learning,'' pp"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 100
                            }
                        ],
                        "text": "The use of this distance measure is motivated by the Minimum Relative Entropy Principle of Kullback (Kapur and Kesavan, 1992; Jumarie, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 124
                            }
                        ],
                        "text": "The use of this distance measure is motivated by theMinimum RelativeEntropy Principle of Kullback (Kapur and Kesavan, 1992; Jumarie, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 130
                            }
                        ],
                        "text": "These fundamental principles have many applications in InformationTheory, Physics and Economics (See Kapur and Kesavan (1992) and Jumarie (1990) for anoverview)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 167
                            }
                        ],
                        "text": "The use of the relative entropy as a distance measure is motivatedby the Maximum Entropy Principle of Jaynes and the more general Minimum Relative EntropyPrinciple of Kullback."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 77
                            }
                        ],
                        "text": "The EG algorithm results from using for d the relative entropy, alsoknown as Kullback-Leibler divergence,dre(w; s) = NXi=1wi ln wisi :This assumes that all the components si and wi are positive, and the constraints Pi si =Piwi = 1 are maintained."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "``Relative Information,'' Springer, New York"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 281
                            }
                        ],
                        "text": "\u2026is given a parameter K, then it achieves the boundLoss(EG ; S) Loss(u; S) + 2pK ln 2NUX + 2U2X2 ln 2N (1:4)for all comparison vectors u and trial sequences S such that jjujj1 U and Loss(u; S) Khold and jjxtjj1 X holds for all t.Note that Lp and Lq are dual norms if 1=p+ 1=q = 1 (Royden, 1963)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 51
                            }
                        ],
                        "text": "Note that Lp and Lq are dual norms if 1=p+ 1=q = 1 (Royden, 1963)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 147
                            }
                        ],
                        "text": "If the norms Lp and Lq are dual, then the Cauchy-Schwartz Inequality can be generalized to show that jjujjp U and jjxjjq X together imply ju xj UX (Royden, 1963)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 146
                            }
                        ],
                        "text": "If the norms Lp and Lq are dual, then theCauchy-Schwartz Inequality can be generalized to show that jjujjp U and jjxjjq X togetherimply ju xj UX (Royden, 1963)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Real Analysis,\" Macmillan, New York"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700597"
                        ],
                        "name": "Jyrki Kivinen",
                        "slug": "Jyrki-Kivinen",
                        "structuredName": {
                            "firstName": "Jyrki",
                            "lastName": "Kivinen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jyrki Kivinen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60798959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78fa2bef9cca6a6b1c11e7bd50631618d0660260",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Using-experts-for-predicting-continuous-outcomes-Kivinen-Warmuth",
            "title": {
                "fragments": [],
                "text": "Using experts for predicting continuous outcomes"
            },
            "venue": {
                "fragments": [],
                "text": "EuroCOLT"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53796860,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ade4934db522fe6d634ff6f48887da46eedb4d1",
            "isKey": false,
            "numCitedBy": 902,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-distributed-representations-of-concepts.-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning distributed representations of concepts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145675281"
                        ],
                        "name": "V. Vovk",
                        "slug": "V.-Vovk",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vovk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vovk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5226318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f80ae7531ae8c8e06f53ca78d5ad8a2dfbc8697",
            "isKey": false,
            "numCitedBy": 714,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Aggregating-strategies-Vovk",
            "title": {
                "fragments": [],
                "text": "Aggregating strategies"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '90"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A training algorithm for optimal margin classiiers Learning Theory, pages 144{152 How to use expert advice"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 5th Annu. Workshop on Comput"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 97
                            }
                        ],
                        "text": "(The comparison class is analogous to the touchstone class of theagnostic PAC model of learning (Kearns et al., 1994).)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 41
                            }
                        ],
                        "text": "Based on the instance xt and information receivedin the previous trials, the learner makes its real-valued prediction y\u0302t."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Toward eecient agnostic learning, Machine Learning 17"
            },
            "venue": {
                "fragments": [],
                "text": "Toward eecient agnostic learning, Machine Learning 17"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 251
                            }
                        ],
                        "text": "This is in contrast to more common approaches where statistical assumptions about the distribution of the instances and the dependence of the outcomes on the instances are used in order to derive probabilistic loss bounds for the prediction algorithm (Widrow and Stearns, 1985; Haykin, 1991)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 275
                            }
                        ],
                        "text": "This is in contrast tomore common approaches where statistical assumptions about the distribution of the instancesand the dependence of the outcomes on the instances are used in order to derive probabilisticloss bounds for the prediction algorithm (Widrow and Stearns, 1985; Haykin, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adaptive Filter Theory,\" Prentice-Hall, Englewood Cli s, NJ"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural Networks: a Comprehensive Foundation,\" Macmillan, New York"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 150
                            }
                        ],
                        "text": "Thisclass of algorithms also includes a basic variant of weight decay, where an additional jjwtjj22error term is used as a penalty for large weights (Hinton, 1986)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning distributed representations of concepts, in \\Proceedings, 8th Annual Conference of the Cognitive Science Society"
            },
            "venue": {
                "fragments": [],
                "text": "Learning distributed representations of concepts, in \\Proceedings, 8th Annual Conference of the Cognitive Science Society"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Real Analysis On the worst-case analysis of temporaldiierence learing algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 11th International Conf. on Machine Learning"
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "``Neural Networks: A Comprehensive Foundation,'' Macmillan, New York"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum-likelihood estimation of mixture proportions using penalty functions"
            },
            "venue": {
                "fragments": [],
                "text": "Maximum-likelihood estimation of mixture proportions using penalty functions"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Relative information Entropy Optimization Principles with Applications"
            },
            "venue": {
                "fragments": [],
                "text": "Relative information Entropy Optimization Principles with Applications"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On weak learning Learning distributed representations of concepts"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 8th Annual Conf. of the Cognitive Science Society"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 150
                            }
                        ],
                        "text": "Thisclass of algorithms also includes a basic variant of weight decay, where an additional jjwtjj22error term is used as a penalty for large weights (Hinton, 1986)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 151
                            }
                        ],
                        "text": "This class of algorithms also includes a basic variant of weight decay, where an additional jjwtjj22 error term is used as a penalty for large weights (Hinton, 1986)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning distributed representations of concepts, in \\Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Worst-case loss bounds for sigmoided linear neurons"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 251
                            }
                        ],
                        "text": "It has also been noticed that in applying the exponenti-ated gradient update to a certain unsupervised learning problem (Helmbold et al., 1996b and1996c) the approximation given here leads to a generalization of the Expectation Maximizationalgorithm (Dempster et al., 1977)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximumlikelihood from incomplete data via the EM algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Royal Statistical Society"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 116
                            }
                        ],
                        "text": ", 1996b and 1996c) the approximation given here leads to a generalization of the Expectation Maximization algorithm (Dempster et al., 1977)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 251
                            }
                        ],
                        "text": "It has also been noticed that in applying the exponenti-ated gradient update to a certain unsupervised learning problem (Helmbold et al., 1996b and1996c) the approximation given here leads to a generalization of the Expectation Maximizationalgorithm (Dempster et al., 1977)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum-likelihood from incomplete"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 25,
            "methodology": 28,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 57,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Exponentiated-Gradient-Versus-Gradient-Descent-for-Kivinen-Warmuth/98eed3f082351c4821d1edb315846207a8fefbe9?sort=total-citations"
}