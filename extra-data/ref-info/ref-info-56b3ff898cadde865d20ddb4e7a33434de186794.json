{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2397422"
                        ],
                        "name": "Joseph Tighe",
                        "slug": "Joseph-Tighe",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Tighe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph Tighe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 51694943,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "914f6db28db0de5f439e891dac38f09bbdc5a452",
            "isKey": false,
            "numCitedBy": 713,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a simple and effective nonparametric approach to the problem of image parsing, or labeling image regions (in our case, superpixels produced by bottom-up segmentation) with their categories. This approach requires no training, and it can easily scale to datasets with tens of thousands of images and hundreds of labels. It works by scene-level matching with global image descriptors, followed by superpixel-level matching with local features and efficient Markov random field (MRF) optimization for incorporating neighborhood context. Our MRF setup can also compute a simultaneous labeling of image regions into semantic classes (e.g., tree, building, car) and geometric classes (sky, vertical, ground). Our system outperforms the state-of-the-art non-parametric method based on SIFT Flow on a dataset of 2,688 images and 33 labels. In addition, we report per-pixel rates on a larger dataset of 15,150 images and 170 labels. To our knowledge, this is the first complete evaluation of image parsing on a dataset of this size, and it establishes a new benchmark for the problem."
            },
            "slug": "Superparsing-Scalable-Nonparametric-Image-Parsing-Tighe-Lazebnik",
            "title": {
                "fragments": [],
                "text": "Superparsing - Scalable Nonparametric Image Parsing with Superpixels"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "This paper presents a simple and effective nonparametric approach to the problem of image parsing, or labeling image regions (in this case, superpixels produced by bottom-up segmentation) with their categories, and establishes a new benchmark for the problem."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Comput. Vis."
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728641"
                        ],
                        "name": "Lubor Ladicky",
                        "slug": "Lubor-Ladicky",
                        "structuredName": {
                            "firstName": "Lubor",
                            "lastName": "Ladicky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lubor Ladicky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145485799"
                        ],
                        "name": "Chris Russell",
                        "slug": "Chris-Russell",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Russell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143967473"
                        ],
                        "name": "Pushmeet Kohli",
                        "slug": "Pushmeet-Kohli",
                        "structuredName": {
                            "firstName": "Pushmeet",
                            "lastName": "Kohli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pushmeet Kohli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635540"
                        ],
                        "name": "Philip H. S. Torr",
                        "slug": "Philip-H.-S.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip H. S. Torr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Like us, a number of authors have used trees to generate candidate segments by aggregating elementary segments, as in [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Many methods rely on MRFs, CRFs, or other types of graphical models to ensure the consistency of the labeling and to account for context [9, 22, 6, 13, 17, 24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2068733,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e796ec9be0009b8f6ae7b1ccba1c9c055328d14",
            "isKey": false,
            "numCitedBy": 682,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Most methods for object class segmentation are formulated as a labelling problem over a single choice of quantisation of an image space - pixels, segments or group of segments. It is well known that each quantisation has its fair share of pros and cons; and the existence of a common optimal quantisation level suitable for all object categories is highly unlikely. Motivated by this observation, we propose a hierarchical random field model, that allows integration of features computed at different levels of the quantisation hierarchy. MAP inference in this model can be performed efficiently using powerful graph cut based move making algorithms. Our framework generalises much of the previous work based on pixels or segments. We evaluate its efficiency on some of the most challenging data-sets for object class segmentation, and show it obtains state-of-the-art results."
            },
            "slug": "Associative-hierarchical-CRFs-for-object-class-Ladicky-Russell",
            "title": {
                "fragments": [],
                "text": "Associative hierarchical CRFs for object class image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a hierarchical random field model, that allows integration of features computed at different levels of the quantisation hierarchy, and evaluates its efficiency on some of the most challenging data-sets for object class segmentation, and shows it obtains state-of-the-art results."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681442"
                        ],
                        "name": "Ce Liu",
                        "slug": "Ce-Liu",
                        "structuredName": {
                            "firstName": "Ce",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ce Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143738177"
                        ],
                        "name": "Jenny Yuen",
                        "slug": "Jenny-Yuen",
                        "structuredName": {
                            "firstName": "Jenny",
                            "lastName": "Yuen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jenny Yuen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 566387,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef2448cf2eae2bc2fc1d83f1da0fbaba188ecec7",
            "isKey": false,
            "numCitedBy": 361,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose a novel nonparametric approach for object recognition and scene parsing using dense scene alignment. Given an input image, we retrieve its best matches from a large database with annotated images using our modified, coarse-to-fine SIFT flow algorithm that aligns the structures within two images. Based on the dense scene correspondence obtained from the SIFT flow, our system warps the existing annotations, and integrates multiple cues in a Markov random field framework to segment and recognize the query image. Promising experimental results have been achieved by our nonparametric scene parsing system on a challenging database. Compared to existing object recognition approaches that require training for each object category, our system is easy to implement, has few parameters, and embeds contextual information naturally in the retrieval/alignment procedure."
            },
            "slug": "Nonparametric-scene-parsing:-Label-transfer-via-Liu-Yuen",
            "title": {
                "fragments": [],
                "text": "Nonparametric scene parsing: Label transfer via dense scene alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Compared to existing object recognition approaches that require training for each object category, the proposed nonparametric scene parsing system is easy to implement, has few parameters, and embeds contextual information naturally in the retrieval/alignment procedure."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3717791"
                        ],
                        "name": "M. P. Kumar",
                        "slug": "M.-P.-Kumar",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Kumar",
                            "middleNames": [
                                "Pawan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. P. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 137
                            }
                        ],
                        "text": "Many methods rely on MRFs, CRFs, or other types of graphical models to ensure the consistency of the labeling and to account for context [9, 22, 6, 13, 17, 24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 86
                            }
                        ],
                        "text": "Most methods rely on a pre-segmentation into super-pixels or other segment candidates [6, 13, 17, 24], and extract features and categories from individual segments and from various combinations of neighboring segments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10699029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05d0340695c89384ebfd929c6fe46dc6023a0238",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent advances in scene understanding and related tasks have highlighted the importance of using regions to reason about high-level scene structure. Typically, the regions are selected beforehand and then an energy function is defined over them. This two step process suffers from the following deficiencies: (i) the regions may not match the boundaries of the scene entities, thereby introducing errors; and (ii) as the regions are obtained without any knowledge of the energy function, they may not be suitable for the task at hand. We address these problems by designing an efficient approach for obtaining the best set of regions in terms of the energy function itself. Each iteration of our algorithm selects regions from a large dictionary by solving an accurate linear programming relaxation via dual decomposition. The dictionary of regions is constructed by merging and intersecting segments obtained from multiple bottom-up over-segmentations. To demonstrate the usefulness of our algorithm, we consider the task of scene segmentation and show significant improvements over state of the art methods."
            },
            "slug": "Efficiently-selecting-regions-for-scene-Kumar-Koller",
            "title": {
                "fragments": [],
                "text": "Efficiently selecting regions for scene understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work designs an efficient approach for obtaining the best set of regions in terms of the energy function itself and demonstrates the usefulness of the algorithm on the task of scene segmentation and shows significant improvements over state of the art methods."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145273587"
                        ],
                        "name": "Stephen Gould",
                        "slug": "Stephen-Gould",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Gould",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Gould"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97911988"
                        ],
                        "name": "Richard Fulton",
                        "slug": "Richard-Fulton",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Fulton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Fulton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 87
                            }
                        ],
                        "text": "A classical technique to reduce the set of components is to consider a hierarchy of segmentations [18, 1, 8], that can be represented as a tree T ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 47
                            }
                        ],
                        "text": "The goal of that first step is to produce features (F)F\u2208F that are maximally discriminative for pixelwise classification."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17448963,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc08847b65953ef2ae3542e47b08b57a46b5ba34",
            "isKey": false,
            "numCitedBy": 709,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "High-level, or holistic, scene understanding involves reasoning about objects, regions, and the 3D relationships between them. This requires a representation above the level of pixels that can be endowed with high-level attributes such as class of object/region, its orientation, and (rough 3D) location within the scene. Towards this goal, we propose a region-based model which combines appearance and scene geometry to automatically decompose a scene into semantically meaningful regions. Our model is defined in terms of a unified energy function over scene appearance and structure. We show how this energy function can be learned from data and present an efficient inference technique that makes use of multiple over-segmentations of the image to propose moves in the energy-space. We show, experimentally, that our method achieves state-of-the-art performance on the tasks of both multi-class image segmentation and geometric reasoning. Finally, by understanding region classes and geometry, we show how our model can be used as the basis for 3D reconstruction of the scene."
            },
            "slug": "Decomposing-a-scene-into-geometric-and-semantically-Gould-Fulton",
            "title": {
                "fragments": [],
                "text": "Decomposing a scene into geometric and semantically consistent regions"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A region-based model which combines appearance and scene geometry to automatically decompose a scene into semantically meaningful regions and which achieves state-of-the-art performance on the tasks of both multi-class image segmentation and geometric reasoning."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740145"
                        ],
                        "name": "V. Lempitsky",
                        "slug": "V.-Lempitsky",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lempitsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lempitsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "4% / - < 600s Lempitsky et al. (2011) 81."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "(2009); Lempitsky et al. (2011). These approaches rely on inference algorithms based on Graph Cuts or other methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Many methods rely on MRFs, CRFs, or other types of graphical models to ensure the consistency of the labeling and to account for context (He & Zemel, 2008; Russell et al., 2009; Gould et al., 2009; Kumar & Koller, 2010; Munoz et al., 2010; Tighe & Lazebnik, 2010; Lempitsky et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Methods of (Kumar & Koller, 2010; Lempitsky et al., 2011) achieve similar or better performances on this particular dataset but to the price of several minutes to parse one image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2121251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b65891fde65045c86d71e6577f44b2dcbf43b9f4",
            "isKey": true,
            "numCitedBy": 157,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Graph cut optimization is one of the standard workhorses of image segmentation since for binary random field representations of the image, it gives globally optimal results and there are efficient polynomial time implementations. Often, the random field is applied over a flat partitioning of the image into non-intersecting elements, such as pixels or super-pixels. In the paper we show that if, instead of a flat partitioning, the image is represented by a hierarchical segmentation tree, then the resulting energy combining unary and boundary terms can still be optimized using graph cut (with all the corresponding benefits of global optimality and efficiency). As a result of such inference, the image gets partitioned into a set of segments that may come from different layers of the tree. \n \nWe apply this formulation, which we call the pylon model, to the task of semantic segmentation where the goal is to separate an image into areas belonging to different semantic classes. The experiments highlight the advantage of inference on a segmentation tree (over a flat partitioning) and demonstrate that the optimization in the pylon model is able to flexibly choose the level of segmentation across the image. Overall, the proposed system has superior segmentation accuracy on several datasets (Graz-02, Stanford background) compared to previously suggested approaches."
            },
            "slug": "Pylon-Model-for-Semantic-Segmentation-Lempitsky-Vedaldi",
            "title": {
                "fragments": [],
                "text": "Pylon Model for Semantic Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper shows that if, instead of a flat partitioning, the image is represented by a hierarchical segmentation tree, then the resulting energy combining unary and boundary terms can still be optimized using graph cut (with all the corresponding benefits of global optimality and efficiency)."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51505748"
                        ],
                        "name": "Daniel Munoz",
                        "slug": "Daniel-Munoz",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Munoz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Munoz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756566"
                        ],
                        "name": "J. Bagnell",
                        "slug": "J.-Bagnell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Bagnell",
                            "middleNames": [
                                "Andrew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bagnell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 34
                            }
                        ],
                        "text": "A simple attention function a is used to mask the feature vector map with each component Ck, producing a set of K masked feature vector patterns {F \u22c2 Ck}, \u2200k \u2208 {1, . . . ,K}."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15601601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "370308ad57aa43a29df1a9500c813c13254e16cd",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we propose a hierarchical approach for labeling semantic objects and regions in scenes. Our approach is reminiscent of early vision literature in that we use a decomposition of the image in order to encode relational and spatial information. In contrast to much existing work on structured prediction for scene understanding, we bypass a global probabilistic model and instead directly train a hierarchical inference procedure inspired by the message passing mechanics of some approximate inference procedures in graphical models. This approach mitigates both the theoretical and empirical difficulties of learning probabilistic models when exact inference is intractable. In particular, we draw from recent work in machine learning and break the complex inference process into a hierarchical series of simple machine learning subproblems. Each subproblem in the hierarchy is designed to capture the image and contextual statistics in the scene. This hierarchy spans coarse-to-fine regions and explicitly models the mixtures of semantic labels that may be present due to imperfect segmentation. To avoid cascading of errors and overfitting, we train the learning problems in sequence to ensure robustness to likely errors earlier in the inference sequence and leverage the stacking approach developed by Cohen et al."
            },
            "slug": "Stacked-Hierarchical-Labeling-Munoz-Bagnell",
            "title": {
                "fragments": [],
                "text": "Stacked Hierarchical Labeling"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work bypasses a global probabilistic model and instead directly train a hierarchical inference procedure inspired by the message passing mechanics of some approximate inference procedures in graphical models, which mitigates both the theoretical and empirical difficulties of learning Probabilistic models when exact inference is intractable."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2529182"
                        ],
                        "name": "David Grangier",
                        "slug": "David-Grangier",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Grangier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Grangier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The system yields record accuracies on the Stanford Background Dataset (8 classes), the Sift Flow Dataset (33 classes) and the Barcelona Dataset (170 classes) while being an order of magnitude faster than competing approaches, producing a 320 \u00d7 240 image labeling in less than 1 second."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7296318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ecc15c576b54d17f7900b073e19edb2db2554f1",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a deep learning strategy for scene parsing, i.e. to asssign a class label to each pixel of an image. We investigate the use of deep convolutional network for modeling the complex scene label structures, relying on a supervised greedy learning strategy. Compared to standard approaches based on CRFs, our strategy does not need hand-crafted features, allows modeling more complex spatial dependencies and has a lower inference cost. Experiments over the MSRC benchmark and the LabelMe dataset show the effectiveness of our approach."
            },
            "slug": "Deep-Convolutional-Networks-for-Scene-Parsing-Grangier-Bottou",
            "title": {
                "fragments": [],
                "text": "Deep Convolutional Networks for Scene Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work proposes a deep learning strategy for scene parsing, i.e. to asssign a class label to each pixel of an image, which does not need hand-crafted features, allows modeling more complex spatial dependencies and has a lower inference cost."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3178417"
                        ],
                        "name": "Srinivas C. Turaga",
                        "slug": "Srinivas-C.-Turaga",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Turaga",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Srinivas C. Turaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1997979"
                        ],
                        "name": "K. Briggman",
                        "slug": "K.-Briggman",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Briggman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Briggman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2495450"
                        ],
                        "name": "M. Helmstaedter",
                        "slug": "M.-Helmstaedter",
                        "structuredName": {
                            "firstName": "Moritz",
                            "lastName": "Helmstaedter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Helmstaedter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144922222"
                        ],
                        "name": "W. Denk",
                        "slug": "W.-Denk",
                        "structuredName": {
                            "firstName": "Winfried",
                            "lastName": "Denk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Denk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The system yields record accuracies on the Stanford Background Dataset (8 classes), the Sift Flow Dataset (33 classes) and the Barcelona Dataset (170 classes) while being an order of magnitude faster than competing approaches, producing a 320 \u00d7 240 image labeling in less than 1 second."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2891518,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07ef1b52b9fbb25cec28f65d030e44237c8f3f5b",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Images can be segmented by first using a classifier to predict an affinity graph that reflects the degree to which image pixels must be grouped together and then partitioning the graph to yield a segmentation. Machine learning has been applied to the affinity classifier to produce affinity graphs that are good in the sense of minimizing edge misclassification rates. However, this error measure is only indirectly related to the quality of segmentations produced by ultimately partitioning the affinity graph. We present the first machine learning algorithm for training a classifier to produce affinity graphs that are good in the sense of producing segmentations that directly minimize the Rand index, a well known segmentation performance measure. The Rand index measures segmentation performance by quantifying the classification of the connectivity of image pixel pairs after segmentation. By using the simple graph partitioning algorithm of finding the connected components of the thresholded affinity graph, we are able to train an affinity classifier to directly minimize the Rand index of segmentations resulting from the graph partitioning. Our learning algorithm corresponds to the learning of maximin affinities between image pixel pairs, which are predictive of the pixel-pair connectivity."
            },
            "slug": "Maximin-affinity-learning-of-image-segmentation-Turaga-Briggman",
            "title": {
                "fragments": [],
                "text": "Maximin affinity learning of image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This work presents the first machine learning algorithm for training a classifier to produce affinity graphs that are good in the sense of producing segmentations that directly minimize the Rand index, a well known segmentation performance measure."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077257730"
                        ],
                        "name": "Kevin Jarrett",
                        "slug": "Kevin-Jarrett",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Jarrett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Jarrett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The system yields record accuracies on the Stanford Background Dataset (8 classes), the Sift Flow Dataset (33 classes) and the Barcelona Dataset (170 classes) while being an order of magnitude faster than competing approaches, producing a 320 \u00d7 240 image labeling in less than 1 second."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206769720,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f88427d7aa8225e47f946ac41a0667d7b69ac52",
            "isKey": false,
            "numCitedBy": 2085,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on NORB dataset (5.6%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 (\u226b 65%), and the lowest known error rate on the undistorted, unprocessed MNIST dataset (0.53%)."
            },
            "slug": "What-is-the-best-multi-stage-architecture-for-Jarrett-Kavukcuoglu",
            "title": {
                "fragments": [],
                "text": "What is the best multi-stage architecture for object recognition?"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks and that two stages of feature extraction yield better accuracy than one."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681442"
                        ],
                        "name": "Ce Liu",
                        "slug": "Ce-Liu",
                        "structuredName": {
                            "firstName": "Ce",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ce Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[24], is derived from the LabelMe subset used in [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15871069,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2809f3a7f192f617a5cdf4c4e6b0fa84fb95aa50",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Current object recognition systems can only recognize a limited number of object categories; scaling up to many categories is the next challenge. We seek to build a system to recognize and localize many different object categories in complex scenes. We achieve this through a simple approach: by matching the input image, in an appropriate representation, to images in a large training set of labeled images. Due to regularities in object identities across similar scenes, the retrieved matches provide hypotheses for object identities and locations. We build a probabilistic model to transfer the labels from the retrieval set to the input image. We demonstrate the effectiveness of this approach and study algorithm component contributions using held-out test sets from the LabelMe database."
            },
            "slug": "Object-Recognition-by-Scene-Alignment-Russell-Torralba",
            "title": {
                "fragments": [],
                "text": "Object Recognition by Scene Alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work builds a probabilistic model to transfer the labels from the retrieval set to the input image, and demonstrates the effectiveness of this approach and study algorithm component contributions using held-out test sets from the LabelMe database."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2585821"
                        ],
                        "name": "Cliff Chiung-Yu Lin",
                        "slug": "Cliff-Chiung-Yu-Lin",
                        "structuredName": {
                            "firstName": "Cliff",
                            "lastName": "Lin",
                            "middleNames": [
                                "Chiung-Yu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cliff Chiung-Yu Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 92
                            }
                        ],
                        "text": "The feature vectors associated with the segments covered by each node in the tree are aggregated and fed to a classifier which produces an estimate of the distribution of object categories contained in the segment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18690358,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c0ddf74f87d154db88d79c640578c1610451eec",
            "isKey": false,
            "numCitedBy": 1320,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Recursive structure is commonly found in the inputs of different modalities such as natural scene images or natural language sentences. Discovering this recursive structure helps us to not only identify the units that an image or sentence contains but also how they interact to form a whole. We introduce a max-margin structure prediction architecture based on recursive neural networks that can successfully recover such structure both in complex scene images as well as sentences. The same algorithm can be used both to provide a competitive syntactic parser for natural language sentences from the Penn Treebank and to outperform alternative approaches for semantic scene segmentation, annotation and classification. For segmentation and annotation our algorithm obtains a new level of state-of-the-art performance on the Stanford background dataset (78.1%). The features from the image parse tree outperform Gist descriptors for scene classification by 4%."
            },
            "slug": "Parsing-Natural-Scenes-and-Natural-Language-with-Socher-Lin",
            "title": {
                "fragments": [],
                "text": "Parsing Natural Scenes and Natural Language with Recursive Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A max-margin structure prediction architecture based on recursive neural networks that can successfully recover such structure both in complex scene images as well as sentences is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35086944"
                        ],
                        "name": "Viren Jain",
                        "slug": "Viren-Jain",
                        "structuredName": {
                            "firstName": "Viren",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Viren Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31052092"
                        ],
                        "name": "J. Murray",
                        "slug": "J.-Murray",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Murray",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061202596"
                        ],
                        "name": "Fabian Roth",
                        "slug": "Fabian-Roth",
                        "structuredName": {
                            "firstName": "Fabian",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabian Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3178417"
                        ],
                        "name": "Srinivas C. Turaga",
                        "slug": "Srinivas-C.-Turaga",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Turaga",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Srinivas C. Turaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2666090"
                        ],
                        "name": "V. Zhigulin",
                        "slug": "V.-Zhigulin",
                        "structuredName": {
                            "firstName": "Valentin",
                            "lastName": "Zhigulin",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zhigulin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1997979"
                        ],
                        "name": "K. Briggman",
                        "slug": "K.-Briggman",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Briggman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Briggman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2495450"
                        ],
                        "name": "M. Helmstaedter",
                        "slug": "M.-Helmstaedter",
                        "structuredName": {
                            "firstName": "Moritz",
                            "lastName": "Helmstaedter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Helmstaedter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144922222"
                        ],
                        "name": "W. Denk",
                        "slug": "W.-Denk",
                        "structuredName": {
                            "firstName": "Winfried",
                            "lastName": "Denk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Denk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The system yields record accuracies on the Stanford Background Dataset (8 classes), the Sift Flow Dataset (33 classes) and the Barcelona Dataset (170 classes) while being an order of magnitude faster than competing approaches, producing a 320 \u00d7 240 image labeling in less than 1 second."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11306857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f566b1f24e63151ddae652826638af054973a27f",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional networks have achieved a great deal of success in high-level vision problems such as object recognition. Here we show that they can also be used as a general method for low-level image processing. As an example of our approach, convolutional networks are trained using gradient learning to solve the problem of restoring noisy or degraded images. For our training data, we have used electron microscopic images of neural circuitry with ground truth restorations provided by human experts. On this dataset, Markov random field (MRF), conditional random field (CRF), and anisotropic diffusion algorithms perform about the same as simple thresholding, but superior performance is obtained with a convolutional network containing over 34,000 adjustable parameters. When restored by this convolutional network, the images are clean enough to be used for segmentation, whereas the other approaches fail in this respect. We do not believe that convolutional networks are fundamentally superior to MRFs as a representation for image processing algorithms. On the contrary, the two approaches are closely related. But in practice, it is possible to train complex convolutional networks, while even simple MRF models are hindered by problems with Bayesian learning and inference procedures. Our results suggest that high model complexity is the single most important factor for good performance, and this is possible with convolutional networks."
            },
            "slug": "Supervised-Learning-of-Image-Restoration-with-Jain-Murray",
            "title": {
                "fragments": [],
                "text": "Supervised Learning of Image Restoration with Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work shows that convolutional networks can be used as a general method for low-level image processing and suggests that high model complexity is the single most important factor for good performance."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9739979"
                        ],
                        "name": "P. Arbel\u00e1ez",
                        "slug": "P.-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Arbel\u00e1ez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1505240324"
                        ],
                        "name": "C. Fowlkes",
                        "slug": "C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charlotte",
                            "lastName": "Fowlkes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787589"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026net to learn good features for region classification; 2) using a class purity criterion to decide if a segment contains a single objet, as opposed to several objects, or part of an object; 3) an efficient procedure to obtain a cover that optimizes the overall class purity of a segmentation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206764694,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e5a262bf59b68ba8a7a1103d16fa33a9f5ffc28",
            "isKey": false,
            "numCitedBy": 4197,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates two fundamental problems in computer vision: contour detection and image segmentation. We present state-of-the-art algorithms for both of these tasks. Our contour detector combines multiple local cues into a globalization framework based on spectral clustering. Our segmentation algorithm consists of generic machinery for transforming the output of any contour detector into a hierarchical region tree. In this manner, we reduce the problem of image segmentation to that of contour detection. Extensive experimental evaluation demonstrates that both our contour detection and segmentation methods significantly outperform competing algorithms. The automatically generated hierarchical segmentations can be interactively refined by user-specified annotations. Computation at multiple image resolutions provides a means of coupling our system to recognition applications."
            },
            "slug": "Contour-Detection-and-Hierarchical-Image-Arbel\u00e1ez-Maire",
            "title": {
                "fragments": [],
                "text": "Contour Detection and Hierarchical Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper investigates two fundamental problems in computer vision: contour detection and image segmentation and presents state-of-the-art algorithms for both of these tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721510"
                        ],
                        "name": "J. Cousty",
                        "slug": "J.-Cousty",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Cousty",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cousty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688714"
                        ],
                        "name": "Laurent Najman",
                        "slug": "Laurent-Najman",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Najman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurent Najman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 158
                            }
                        ],
                        "text": "In this paper, the hierarchy used to find the optimal cover is a simple hierarchy constructed on the raw image gradient, based on a standard volume criterion [16, 4], completed by a removal of non-informative small components (less than 100 pixels)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15929371,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6eb41e6970aa41e605945bcfd03466983c1273e3",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We study hierarchical segmentations that are optimal in the sense of minimal spanning forests of the original image. We introduce a region-merging operation called uprooting, and we prove that optimal hierarchical segmentations are equivalent to the ones given by uprooting a watershed-cut based segmentation. Based on those theoretical results, we propose an efficient algorithm to compute such hierarchies, as well as the first saliency map algorithm compatible with the morphological filtering framework."
            },
            "slug": "Incremental-Algorithm-for-Hierarchical-Minimum-and-Cousty-Najman",
            "title": {
                "fragments": [],
                "text": "Incremental Algorithm for Hierarchical Minimum Spanning Forests and Saliency of Watershed Cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "An efficient algorithm to compute hierarchical segmentations that are optimal in the sense of minimal spanning forests of the original image is proposed, as well as the first saliency map algorithm compatible with the morphological filtering framework."
            },
            "venue": {
                "fragments": [],
                "text": "ISMM"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688714"
                        ],
                        "name": "Laurent Najman",
                        "slug": "Laurent-Najman",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Najman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurent Najman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862326"
                        ],
                        "name": "M. Schmitt",
                        "slug": "M.-Schmitt",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Schmitt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schmitt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026net to learn good features for region classification; 2) using a class purity criterion to decide if a segment contains a single objet, as opposed to several objects, or part of an object; 3) an efficient procedure to obtain a cover that optimizes the overall class purity of a segmentation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11219068,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b894683d59ef6d671d98387a7b9dc86212c02d8c",
            "isKey": false,
            "numCitedBy": 541,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The watershed is one of the latest segmentation tools developed in mathematical morphology. In order to prevent its oversegmentation, the notion of dynamics of a minimum, based on geodesic reconstruction, has been proposed. In this paper, we extend the notion of dynamics to the contour arcs. This notion acts as a measure of the saliency of the contour. Contrary to the dynamics of minima, our concept reflects the extension and shape of the corresponding object in the image. This representation is also much more natural, because it is expressed in terms of partitions of the plane, i.e., segmentations. A hierarchical segmentation process is then derived, which gives a compact description of the image, containing all the segmentations one can obtain by the notion of dynamics, by means of a simple thresholding. Finally, efficient algorithms for computing the geodesic reconstruction as well as the dynamics of contours are presented."
            },
            "slug": "Geodesic-Saliency-of-Watershed-Contours-and-Najman-Schmitt",
            "title": {
                "fragments": [],
                "text": "Geodesic Saliency of Watershed Contours and Hierarchical Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A hierarchical segmentation process is derived, which gives a compact description of the image, containing all the segmentations one can obtain by the notion of dynamics, by means of a simple thresholding."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33913193"
                        ],
                        "name": "Xuming He",
                        "slug": "Xuming-He",
                        "structuredName": {
                            "firstName": "Xuming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 137
                            }
                        ],
                        "text": "Many methods rely on MRFs, CRFs, or other types of graphical models to ensure the consistency of the labeling and to account for context [9, 22, 6, 13, 17, 24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16610128,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01e50d0d08c26c639d377b27bd63e717a842db34",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Extensive labeled data for image annotation systems, which learn to assign class labels to image regions, is difficult to obtain. We explore a hybrid model framework for utilizing partially labeled data that integrates a generative topic model for image appearance with discriminative label prediction. We propose three alternative formulations for imposing a spatial smoothness prior on the image labels. Tests of the new models and some baseline approaches on three real image datasets demonstrate the effectiveness of incorporating the latent structure."
            },
            "slug": "Learning-Hybrid-Models-for-Image-Annotation-with-He-Zemel",
            "title": {
                "fragments": [],
                "text": "Learning Hybrid Models for Image Annotation with Partially Labeled Data"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A hybrid model framework for utilizing partially labeled data that integrates a generative topic model for image appearance with discriminative label prediction is explored and three alternative formulations for imposing a spatial smoothness prior on the image labels are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2896380"
                        ],
                        "name": "L. Guigues",
                        "slug": "L.-Guigues",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Guigues",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guigues"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722115"
                        ],
                        "name": "J. Cocquerez",
                        "slug": "J.-Cocquerez",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Cocquerez",
                            "middleNames": [
                                "Pierre"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cocquerez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085238846"
                        ],
                        "name": "H. L. Men",
                        "slug": "H.-L.-Men",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Men",
                            "middleNames": [
                                "Le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. L. Men"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A classical technique to reduce the set of components is to consider a hierarchy of segmentations [18, 1, 8], that can be represented as a tree T ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7221441,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "71fb695ecd9a6ddedf85bdf7c56efd847612aea3",
            "isKey": false,
            "numCitedBy": 242,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a multi-scale theory of piecewise image modelling, called the scale-sets theory, and which can be regarded as a region-oriented scale-space theory. The first part of the paper studies the general structure of a geometrically unbiased region-oriented multi-scale image description and introduces the scale-sets representation, a representation which allows to handle such a description exactly. The second part of the paper deals with the way scale-sets image analyses can be built according to an energy minimization principle. We consider a rather general formulation of the partitioning problem which involves minimizing a two-term-based energy, of the form \u03bb C + D, where D is a goodness-of-fit term and C is a regularization term. We describe the way such energies arise from basic principles of approximate modelling and we relate them to operational rate/distorsion problems involved in lossy compression problems. We then show that an important subset of these energies constitutes a class of multi-scale energies in that the minimal cut of a hierarchy gets coarser and coarser as parameter \u03bb increases. This allows us to devise a fast dynamic-programming procedure to find the complete scale-sets representation of this family of minimal cuts. Considering then the construction of the hierarchy from which the minimal cuts are extracted, we end up with an exact and parameter-free algorithm to build scale-sets image descriptions whose sections constitute a monotone sequence of upward global minima of a multi-scale energy, which is called the \u201cscale climbing\u201d algorithm. This algorithm can be viewed as a continuation method along the scale dimension or as a minimum pursuit along the operational rate/distorsion curve. Furthermore, the solution verifies a linear scale invariance property which allows to completely postpone the tuning of the scale parameter to a subsequent stage. For computational reasons, the scale climbing algorithm is approximated by a pair-wise region merging scheme: however the principal properties of the solutions are kept. Some results obtained with Mumford-Shah\u2019s piece-wise constant model and a variant are provided and different applications of the proposed multi-scale analyses are finally sketched."
            },
            "slug": "Scale-Sets-Image-Analysis-Guigues-Cocquerez",
            "title": {
                "fragments": [],
                "text": "Scale-Sets Image Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An exact and parameter-free algorithm to build scale-sets image descriptions whose sections constitute a monotone sequence of upward global minima of a multi-scale energy, which is called the \u201cscale climbing\u201d algorithm is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2003 International Conference on Image Processing (Cat. No.03CH37429)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2341378"
                        ],
                        "name": "C. Couprie",
                        "slug": "C.-Couprie",
                        "structuredName": {
                            "firstName": "Camille",
                            "lastName": "Couprie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Couprie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750819"
                        ],
                        "name": "L. Grady",
                        "slug": "L.-Grady",
                        "structuredName": {
                            "firstName": "Leo",
                            "lastName": "Grady",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Grady"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688714"
                        ],
                        "name": "Laurent Najman",
                        "slug": "Laurent-Najman",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Najman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurent Najman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144662687"
                        ],
                        "name": "Hugues Talbot",
                        "slug": "Hugues-Talbot",
                        "structuredName": {
                            "firstName": "Hugues",
                            "lastName": "Talbot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hugues Talbot"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We experimented with a number of graph cut methods to do so, including graph-cuts [5, 2], Kruskal [12] and Power Watersheds [3], but the results were systematically worse than with our optimal cover method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3016320,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27d73a8963e299e55f3e2ac8b60f60cebbbe49d6",
            "isKey": false,
            "numCitedBy": 322,
            "numCiting": 102,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, we extend a common framework for graph-based image segmentation that includes the graph cuts, random walker, and shortest path optimization algorithms. Viewing an image as a weighted graph, these algorithms can be expressed by means of a common energy function with differing choices of a parameter q acting as an exponent on the differences between neighboring nodes. Introducing a new parameter p that fixes a power for the edge weights allows us to also include the optimal spanning forest algorithm for watershed in this same framework. We then propose a new family of segmentation algorithms that fixes p to produce an optimal spanning forest but varies the power q beyond the usual watershed algorithm, which we term the power watershed. In particular, when q=2, the power watershed leads to a multilabel, scale and contrast invariant, unique global optimum obtained in practice in quasi-linear time. Placing the watershed algorithm in this energy minimization framework also opens new possibilities for using unary terms in traditional watershed segmentation and using watershed to optimize more general models of use in applications beyond image segmentation."
            },
            "slug": "Power-Watershed:-A-Unifying-Graph-Based-Framework-Couprie-Grady",
            "title": {
                "fragments": [],
                "text": "Power Watershed: A Unifying Graph-Based Optimization Framework"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work extends a common framework for graph-based image segmentation that includes the graph cuts, random walker, and shortest path optimization algorithms and proposes a new family of segmentation algorithms that fixes p to produce an optimal spanning forest but varies the power q beyond the usual watershed algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735300"
                        ],
                        "name": "S. Haykin",
                        "slug": "S.-Haykin",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Haykin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Haykin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713858"
                        ],
                        "name": "B. Kosko",
                        "slug": "B.-Kosko",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Kosko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kosko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "C\nV ]\n1 3\nwise feature aggregation: for each node in the tree, the corresponding image segment is encoded by a 5\u00d7 5 spatial grid of aggregated feature vectors."
                    },
                    "intents": []
                }
            ],
            "corpusId": 64294544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f42b865e20e61a954239f421b42007236e671f19",
            "isKey": false,
            "numCitedBy": 3516,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer Neural Networks trained with the backpropagation algorithm constitute the best example of a successful Gradient-Based Learning technique. Given an appropriate network architecture, Gradient-Based Learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional Neural Networks, that are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation, recognition, and language modeling. A new learning paradigm, called Graph Transformer Networks (GTN), allows such multi-module systems to be trained globally using Gradient-Based methods so as to minimize an overall performance measure. Two systems for on-line handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of Graph Transformer Networks. A Graph Transformer Network for reading bank check is also described. It uses Convolutional Neural Network character recognizers combined with global training techniques to provides record accuracy on business and personal checks. It is deployed commercially and reads several million checks per day."
            },
            "slug": "GradientBased-Learning-Applied-to-Document-Haykin-Kosko",
            "title": {
                "fragments": [],
                "text": "GradientBased Learning Applied to Document Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Various methods applied to handwritten character recognition are reviewed and compared and Convolutional Neural Networks, that are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144197071"
                        ],
                        "name": "M. Jolly",
                        "slug": "M.-Jolly",
                        "structuredName": {
                            "firstName": "Marie-Pierre",
                            "lastName": "Jolly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jolly"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the next two sections we describe these two steps."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2245438,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d3b177e8d027d44c191e739a3a70ccacc2eac82",
            "isKey": false,
            "numCitedBy": 4175,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new technique for general purpose interactive segmentation of N-dimensional images. The user marks certain pixels as \"object\" or \"background\" to provide hard constraints for segmentation. Additional soft constraints incorporate both boundary and region information. Graph cuts are used to find the globally optimal segmentation of the N-dimensional image. The obtained solution gives the best balance of boundary and region properties among all segmentations satisfying the constraints. The topology of our segmentation is unrestricted and both \"object\" and \"background\" segments may consist of several isolated parts. Some experimental results are presented in the context of photo/video editing and medical image segmentation. We also demonstrate an interesting Gestalt example. A fast implementation of our segmentation method is possible via a new max-flow algorithm."
            },
            "slug": "Interactive-graph-cuts-for-optimal-boundary-&-of-in-Boykov-Jolly",
            "title": {
                "fragments": [],
                "text": "Interactive graph cuts for optimal boundary & region segmentation of objects in N-D images"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A new technique for general purpose interactive segmentation of N-dimensional images where the user marks certain pixels as \"object\" or \"background\" to provide hard constraints for segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The system yields record accuracies on the Stanford Background Dataset (8 classes), the Sift Flow Dataset (33 classes) and the Barcelona Dataset (170 classes) while being an order of magnitude faster than competing approaches, producing a 320 \u00d7 240 image labeling in less than 1 second."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35270,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700737"
                        ],
                        "name": "Margarita Osadchy",
                        "slug": "Margarita-Osadchy",
                        "structuredName": {
                            "firstName": "Margarita",
                            "lastName": "Osadchy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Margarita Osadchy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111207598"
                        ],
                        "name": "Matthew L. Miller",
                        "slug": "Matthew-L.-Miller",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Miller",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew L. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The system yields record accuracies on the Stanford Background Dataset (8 classes), the Sift Flow Dataset (33 classes) and the Barcelona Dataset (170 classes) while being an order of magnitude faster than competing approaches, producing a 320 \u00d7 240 image labeling in less than 1 second."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 688047,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b728a7442ca158f895d07c11c77d302269a832d",
            "isKey": false,
            "numCitedBy": 409,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel method for real-time, simultaneous multi-view face detection and facial pose estimation. The method employs a convolutional network to map face images to points on a manifold, parametrized by pose, and non-face images to points far from that manifold. This network is trained by optimizing a loss function of three variables: image, pose, and face/non-face label. We test the resulting system, in a single configuration, on three standard data sets - one for frontal pose, one for rotated faces, and one for profiles - and find that its performance on each set is comparable to previous multi-view face detectors that can only handle one form of pose variation. We also show experimentally that the system's accuracy on both face detection and pose estimation is improved by training for the two tasks together."
            },
            "slug": "Synergistic-Face-Detection-and-Pose-Estimation-with-Osadchy-LeCun",
            "title": {
                "fragments": [],
                "text": "Synergistic Face Detection and Pose Estimation with Energy-Based Models"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A novel method for real-time, simultaneous multi-view face detection and facial pose estimation that employs a convolutional network to map face images to points on a manifold, parametrized by pose, and non-face images to Points far from that manifold is described."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064414118"
                        ],
                        "name": "F. Ning",
                        "slug": "F.-Ning",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Ning",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3252902"
                        ],
                        "name": "D. Delhomme",
                        "slug": "D.-Delhomme",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Delhomme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Delhomme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1453335150"
                        ],
                        "name": "F. Piano",
                        "slug": "F.-Piano",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Piano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Piano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2622897"
                        ],
                        "name": "P. Barbano",
                        "slug": "P.-Barbano",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Barbano",
                            "middleNames": [
                                "Emilio"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Barbano"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The system yields record accuracies on the Stanford Background Dataset (8 classes), the Sift Flow Dataset (33 classes) and the Barcelona Dataset (170 classes) while being an order of magnitude faster than competing approaches, producing a 320 \u00d7 240 image labeling in less than 1 second."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7801317,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "c029513aef54460ef6a468ff83f549d7ffbb646b",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a trainable system for analyzing videos of developing C. elegans embryos. The system automatically detects, segments, and locates cells and nuclei in microscopic images. The system was designed as the central component of a fully automated phenotyping system. The system contains three modules 1) a convolutional network trained to classify each pixel into five categories: cell wall, cytoplasm, nucleus membrane, nucleus, outside medium; 2) an energy-based model, which cleans up the output of the convolutional network by learning local consistency constraints that must be satisfied by label images; 3) a set of elastic models of the embryo at various stages of development that are matched to the label images."
            },
            "slug": "Toward-automatic-phenotyping-of-developing-embryos-Ning-Delhomme",
            "title": {
                "fragments": [],
                "text": "Toward automatic phenotyping of developing embryos from videos"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A trainable system for analyzing videos of developing C. elegans embryos that automatically detects, segments, and locates cells and nuclei in microscopic images and contains a set of elastic models of the embryo at various stages of development that are matched to the label images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143765825"
                        ],
                        "name": "F. Meyer",
                        "slug": "F.-Meyer",
                        "structuredName": {
                            "firstName": "Fernand",
                            "lastName": "Meyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Meyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688714"
                        ],
                        "name": "Laurent Najman",
                        "slug": "Laurent-Najman",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Najman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurent Najman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In this paper, the hierarchy used to find the optimal cover is a simple hierarchy constructed on the raw image gradient, based on a standard volume criterion [16, 4], completed by a removal of non-informative small components (less than 100 pixels)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118039989,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8691e8f38569d8bca4051b0ff61b77290549ae6f",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Contains sections titled Preamble: watersheds, floodings and plateaus Hierarchies of segmentations Computing contours saliency maps Using hierarchies for segmentation Lattice of hierarchies"
            },
            "slug": "Segmentation,-Minimum-Spanning-Tree-and-Hierarchies-Meyer-Najman",
            "title": {
                "fragments": [],
                "text": "Segmentation, Minimum Spanning Tree and Hierarchies"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Contains sections titled Preamble: watersheds, floodings and plateaus Hierarchies of segmentations Computing contours saliency maps Using hierarchies for segmentation Lattice of hierarchies."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2458887"
                        ],
                        "name": "L. R. Ford",
                        "slug": "L.-R.-Ford",
                        "structuredName": {
                            "firstName": "Lester",
                            "lastName": "Ford",
                            "middleNames": [
                                "Randolph"
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. R. Ford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093820"
                        ],
                        "name": "D. R. Fulkerson",
                        "slug": "D.-R.-Fulkerson",
                        "structuredName": {
                            "firstName": "Delbert",
                            "lastName": "Fulkerson",
                            "middleNames": [
                                "Ray"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. R. Fulkerson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the next two sections we describe these two steps."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7144560,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fb65127948c879108eca9d90f6f85dd55ee4ed83",
            "isKey": false,
            "numCitedBy": 295,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The network-flow problem, originally posed by T. Harris of the Rand Corporation, has been discussed from various viewpoints in (1; 2; 7; 16). The problem arises naturally in the study of transportation networks; it may be stated in the following way. One is given a network of directed arcs and nodes with two distinguished nodes, called source and sink, respectively. All other nodes are called intermediate. Each directed arc in the network has associated with it a nonnegative integer, its flow capacity. Source arcs may be assumed to be directed away from the source, sink arcs into the sink. Subject to the conditions that the flow in an arc is in the direction of the arc and does not exceed its capacity, and that the total flow into any intermediate node is equal to the flow out of it, it is desired to find a maximal flow from source to sink in the network, i.e., a flow which maximizes the sum of the flows in source (or sink) arcs. Thus, if we let P 1 be the source, P n the sink, we are required to find x ij (i,j =1, . . . , w) which maximize"
            },
            "slug": "A-Simple-Algorithm-for-Finding-Maximal-Network-and-Ford-Fulkerson",
            "title": {
                "fragments": [],
                "text": "A Simple Algorithm for Finding Maximal Network Flows and an Application to the Hitchcock Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A very simple algorithm for finding a maximal flow and minimal cut in a transportation network is described and then applied to obtain an efficient computational routine for the Hitchcock distribution problem."
            },
            "venue": {
                "fragments": [],
                "text": "Canadian Journal of Mathematics"
            },
            "year": 1957
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10398168"
                        ],
                        "name": "J. Kruskal",
                        "slug": "J.-Kruskal",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Kruskal",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kruskal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We experimented with a number of graph cut methods to do so, including graph-cuts [5, 2], Kruskal [12] and Power Watersheds [3], but the results were systematically worse than with our optimal cover method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120068278,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a6547a35e3a87a65347e2cf077ef6f1aac278a39",
            "isKey": false,
            "numCitedBy": 4804,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "7. A. Kurosh, Ringtheoretische Probleme die mit dem Burnsideschen Problem uber periodische Gruppen in Zussammenhang stehen, Bull. Acad. Sei. URSS, Ser. Math. vol. 5 (1941) pp. 233-240. 8. J. Levitzki, On the radical of a general ring, Bull. Amer. Math. Soc. vol. 49 (1943) pp. 462^66. 9. -, On three problems concerning nil rings, Bull. Amer. Math. Soc. vol. 49 (1943) pp. 913-919. 10. -, On the structure of algebraic algebras and related rings, Trans. Amer. Math. Soc. vol. 74 (1953) pp. 384-409."
            },
            "slug": "On-the-shortest-spanning-subtree-of-a-graph-and-the-Kruskal",
            "title": {
                "fragments": [],
                "text": "On the shortest spanning subtree of a graph and the traveling salesman problem"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1956
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34782608"
                        ],
                        "name": "G. Orr",
                        "slug": "G.-Orr",
                        "structuredName": {
                            "firstName": "Genevieve",
                            "lastName": "Orr",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Orr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026net to learn good features for region classification; 2) using a class purity criterion to decide if a segment contains a single objet, as opposed to several objects, or part of an object; 3) an efficient procedure to obtain a cover that optimizes the overall class purity of a segmentation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 20158889,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b87274e6d9aa4e6ba5148898aa92941617d2b6ed",
            "isKey": false,
            "numCitedBy": 2631,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Efficient-BackProp-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Efficient BackProp"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks: Tricks of the Trade"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scene Parsing with Multiscale Feature Learning, Purity Trees, and Optimal Covers Figure 4. Typical results achieved on the SIFT Flow dataset"
            },
            "venue": {
                "fragments": [],
                "text": "Scene Parsing with Multiscale Feature Learning, Purity Trees, and Optimal Covers Figure 4. Typical results achieved on the SIFT Flow dataset"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stacked hierarchical label"
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Figure 4. Typical results achieved on the SIFT Flow dataset"
            },
            "venue": {
                "fragments": [],
                "text": "Figure 4. Typical results achieved on the SIFT Flow dataset"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5,
            "methodology": 23
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Scene-parsing-with-Multiscale-Feature-Learning,-and-Farabet-Couprie/56b3ff898cadde865d20ddb4e7a33434de186794?sort=total-citations"
}