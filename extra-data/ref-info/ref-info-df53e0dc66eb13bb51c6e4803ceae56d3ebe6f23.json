{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2727234"
                        ],
                        "name": "Y. Chow",
                        "slug": "Y.-Chow",
                        "structuredName": {
                            "firstName": "Yen-lu",
                            "lastName": "Chow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46924970"
                        ],
                        "name": "Salim Roukos",
                        "slug": "Salim-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Salim Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4953636"
                        ],
                        "name": "M. Krasner",
                        "slug": "M.-Krasner",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Krasner",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krasner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206729551,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2dfb0028fbbb19ae86d751cc7bc4e9c749206a7",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses the use of the Hidden Markov Model (HMM) in phonetic recognition. In particular, we present improvements that deal with the problems of modeling the effect of phonetic context and the problem of robust pdf estimation. The effect of phonetic context is taken into account by conditioning the probability density functions (pdfs) of the acoustic parameters on the adjacent phonemes, only to the extent that there are sufficient tokens of the phoneme in that context. This partial conditioning is achieved by combining the conditioned and unconditioned pdfs models with weights that depend on the confidence in each pdf estimate. This combination is shown to result in better performance than either model by itself. We also show that it is possible to obtain the computational advantages of using discrete probability densities without the usual requirement for large amounts of training data."
            },
            "slug": "Improved-hidden-Markov-modeling-of-phonemes-for-Schwartz-Chow",
            "title": {
                "fragments": [],
                "text": "Improved hidden Markov modeling of phonemes for continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "Improvements are presented that deal with the problems of modeling the effect of phonetic context and the problem of robust pdf estimation and are shown to result in better performance than either model by itself."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710543"
                        ],
                        "name": "V. Zue",
                        "slug": "V.-Zue",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Zue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zue"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19355239,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "9512a2cb0d5f24424cd4b02ca0164724776d92d1",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the acoustic-phonetic analysis of continuous speech in a complete speech understanding system. The system accepts various parameters derived from the digital waveform and short-time spectra, and produces a segment lattice where segments can have overlapping boundaries and the description of segments is a list of labels. Acoustic-Phonetic as well as phonological knowledge of English is employed extensively in labeling the segments. Each label also has associated with it a score, reflecting the confidence in its identity. A description of the acoustic-phonetic analyzer, as well as statistics related to its performance will be presented in detail."
            },
            "slug": "Acoustic-phonetic-recognition-in-BBN-SPEECHLIS-Schwartz-Zue",
            "title": {
                "fragments": [],
                "text": "Acoustic-phonetic recognition in BBN SPEECHLIS"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "The acoustic-phonetic analysis of continuous speech in a complete speech understanding system accepts various parameters derived from the digital waveform and short-time spectra, and produces a segment lattice where segments can have overlapping boundaries and the description of segments is a list of labels."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14789841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4775e2f0d27e8be4aae7b5b5c2560b96ce2eb58",
            "isKey": false,
            "numCitedBy": 1403,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech recognition is formulated as a problem of maximum likelihood decoding. This formulation requires statistical models of the speech production process. In this paper, we describe a number of statistical models for use in speech recognition. We give special attention to determining the parameters for such models from sparse data. We also describe two decoding methods, one appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks. To illustrate the usefulness of the methods described, we review a number of decoding results that have been obtained with them."
            },
            "slug": "A-Maximum-Likelihood-Approach-to-Continuous-Speech-Bahl-Jelinek",
            "title": {
                "fragments": [],
                "text": "A Maximum Likelihood Approach to Continuous Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper describes a number of statistical models for use in speech recognition, with special attention to determining the parameters for such models from sparse data, and describes two decoding methods appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22827917,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "4d09358aefbe0c1fea2b8157bd2ef7c0e81b68c6",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "While gathering acoustic data for the acoustic-phonetic analysis of speech, it is necessary to consider many different sounds in varying phonetic environments to assure that the results are statistically significant. In order to reduce the amount of time required to test hypotheses, a facility has been developed which provides an interactive environment for performing a wide variety of acoustic-phonetic experiments on a large data base of continuous speech. Using this facility, one can formulate an experiment, run it on selected portions (or all) of the data base, and display or tabulate the results in a meaningful way. Another experiment may then be run based on the results. CPU time required to run an experiment on the entire data base is between 5 and 20 seconds, depending on the complexity of the experiment. Due to the ease of interactions, formulating or revising an experiment, running it, and displaying the results normally takes less than 5 minutes. This facility has been used in combination with a data base of 69 hand-labeled sentences to develop algorithms for acoustic-phonetic segmentation and labeling in a speech understanding system. Several examples of its use and the results obtained will be presented."
            },
            "slug": "Acoustic-phonetic-experiment-facility-for-the-study-Schwartz",
            "title": {
                "fragments": [],
                "text": "Acoustic-phonetic experiment facility for the study of continuous speech"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A facility has been developed which provides an interactive environment for performing a wide variety of acoustic-phonetic experiments on a large data base of continuous speech to reduce the amount of time required to test hypotheses."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685310"
                        ],
                        "name": "F. Itakura",
                        "slug": "F.-Itakura",
                        "structuredName": {
                            "firstName": "Fumitada",
                            "lastName": "Itakura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Itakura"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61601418,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbf2b0948ec73e21f6d5a67b22a31a20d503cc9e",
            "isKey": false,
            "numCitedBy": 1241,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A computer system is described in which isolated words, spoken by a designated talker, are recognized through calculation of a minimum prediction residual. A reference pattern for each word to be recognized is stored as a time pattern of linear prediction coefficients (LPC). The total log prediction residual of an input signal is minimized by optimally registering the reference LPC onto the input autocorrelation coefficients using the dynamic programming algorithm (DP). The input signal is recognized as the reference word which produces the minimum prediction residual. A sequential decision procedure is used to reduce the amount of computation in DP. A frequency normalization with respect to the long-time spectral distribution is used to reduce effects of variations in the frequency response of telephone connections. The system has been implemented on a DDP-516 computer for the 200-word recognition experiment. The recognition rate for a designated male talker is 97.3 percent for telephone input, and the recognition time is about 22 times real time."
            },
            "slug": "Minimum-prediction-residual-principle-applied-to-Itakura",
            "title": {
                "fragments": [],
                "text": "Minimum prediction residual principle applied to speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A computer system is described in which isolated words, spoken by a designated talker, are recognized through calculation of a minimum prediction residual through optimally registering the reference LPC onto the input autocorrelation coefficients using the dynamic programming algorithm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144153201"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Baker",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61904772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c180f387357d9302a558bcd643209831744c639b",
            "isKey": false,
            "numCitedBy": 604,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper briefly describes the major features of the DRAGON speech understanding system. DRAGON makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech. The model--that of a probabilistic function of a Markov process--is very flexible and leads to features which allow DRAGON to function despite high error rates from individual knowledge sources. Repeated use of a simple abstract model produces a system which is simple in structure, but powerful in capabilities."
            },
            "slug": "The-DRAGON-system--An-overview-Baker",
            "title": {
                "fragments": [],
                "text": "The DRAGON system--An overview"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper briefly describes the major features of the DRAGON speech understanding system, which makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 6,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Context-dependent-modeling-for-acoustic-phonetic-of-Schwartz-Chow/df53e0dc66eb13bb51c6e4803ceae56d3ebe6f23?sort=total-citations"
}