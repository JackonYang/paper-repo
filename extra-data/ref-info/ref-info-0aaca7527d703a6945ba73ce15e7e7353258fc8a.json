{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107824420"
                        ],
                        "name": "C. Garcia",
                        "slug": "C.-Garcia",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Garcia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Garcia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3346037"
                        ],
                        "name": "X. Apostolidis",
                        "slug": "X.-Apostolidis",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Apostolidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Apostolidis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "The second comparison is performed with the algorithm of Garcia and Apostolidis [10], which uses Euclidean-based color clustering in the HSV color space."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "and Apostolidis [10] performed text extraction with a 4means clustering on already detected text areas as in our text extraction algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "Table 2 Precision and Recall measures for text extraction evaluation between Garcia and Apostolidis\u2019s algorithm [10] (G and A) and our proposed SMC method"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 37
                            }
                        ],
                        "text": "For comparison with the algorithm of Garcia and Apostolidis [10], Precision and Recall are defined enabling evaluation of text extraction quality\nPrecision \u00bc Correctly extracted characters Total of extracted characters\n\u00f010\u00de\nRecall \u00bc Correctly extracted characters Total number of characters\n\u00f011\u00de\nPrecision measures the quality of extraction while Recall measures the quantity of high quality extraction."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Garcia\nand Apostolidis [10] performed text extraction with a 4- means clustering on already detected text areas as in our text extraction algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "For comparison with the algorithm of Garcia and Apostolidis [10], Precision and Recall are defined enabling evaluation of text extraction quality"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46620452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57930a675de539c59bc33f56d9894c999d264f72",
            "isKey": true,
            "numCitedBy": 113,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Text is a very powerful index in content-based image and video indexing. We propose a new text detection and segmentation algorithm that is especially designed for being applied to color images with complicated background. Our goal is to minimize the number of false alarms and to binarize efficiently the detected text areas so that they can be processed by standard OCR software. First, potential areas of text are detected by enhancement and clustering processes, considering most of constraints related to the texture of words. Then, classification and binarization of potential text areas are achieved in a single scheme performing color quantization and characters periodicity analysis. We report a high rate of good detection results with very few false alarms and reliable text binarization."
            },
            "slug": "Text-detection-and-segmentation-in-complex-color-Garcia-Apostolidis",
            "title": {
                "fragments": [],
                "text": "Text detection and segmentation in complex color images"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A new text detection and segmentation algorithm that is especially designed for being applied to color images with complicated background and to binarize efficiently the detected text areas so that they can be processed by standard OCR software."
            },
            "venue": {
                "fragments": [],
                "text": "2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.00CH37100)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108073159"
                        ],
                        "name": "Yangxing Liu",
                        "slug": "Yangxing-Liu",
                        "structuredName": {
                            "firstName": "Yangxing",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangxing Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144149214"
                        ],
                        "name": "S. Goto",
                        "slug": "S.-Goto",
                        "structuredName": {
                            "firstName": "Satoshi",
                            "lastName": "Goto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Goto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758094"
                        ],
                        "name": "T. Ikenaga",
                        "slug": "T.-Ikenaga",
                        "structuredName": {
                            "firstName": "Takeshi",
                            "lastName": "Ikenaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ikenaga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6] experimented a mixture model of Gaussians with parameters tuned by the expectation\u2013maximization algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12013005,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7f05ec14d51906c44814ef74777750f697746d2",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Text detection in color images has become an active research area since recent decades. In this paper, we present a novel approach to accurately detect text in color images possibly with a complex background. First, we use an elaborate edge detection algorithm to extract all possible text edge pixels. Second connected component analysis is employed to construct text candidate region and classify part non-text regions. Third each text candidate region is verified with texture features derived from wavelet domain. Finally, the expectation maximization algorithm is introduced to binarize text regions to prepare data for recognition. In contrast to previous approach, our algorithm combines both the efficiency of connected component based method and robustness of texture based analysis. Experimental results show that our algorithm is robust in text detection with respect to different character size, orientation, color and language and can provide reliable text binarization result."
            },
            "slug": "A-robust-algorithm-for-text-detection-in-color-Liu-Goto",
            "title": {
                "fragments": [],
                "text": "A robust algorithm for text detection in color images"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A novel approach to accurately detect text in color images possibly with a complex background is presented and is robust in text detection with respect to different character size, orientation, color and language and can provide reliable text binarization result."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403970934"
                        ],
                        "name": "C. Mancas-Thillou",
                        "slug": "C.-Mancas-Thillou",
                        "structuredName": {
                            "firstName": "C\u00e9line",
                            "lastName": "Mancas-Thillou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mancas-Thillou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50276543"
                        ],
                        "name": "B. Gosselin",
                        "slug": "B.-Gosselin",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Gosselin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gosselin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 12
                            }
                        ],
                        "text": "Thillou and Gosselin [11] segmented color text with a 3- means clustering algorithm in the RGB color space, where discrimination on clean and complex backgrounds was previously done to merge clusters more efficiently."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "Nevertheless, Mancas-Thillou and Gosselin [18] previously explained why RGB color space handles variability of natural scenes better than most other spaces; it is general enough to support all degradations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11571951,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c78b93a9a4fcf27945cd982c59f29b59f4a53a53",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Character recognition has a continuous importance for several years and recently, new challenges appeared with camera-based pictures. This paper deals with text extraction for color natural scenes images. Many papers try to combine several color spaces or to choose the best one for a particular database. We show that the main problem is not in the choice of color spaces for generic text extraction but in the choice of clustering distances to handle alt degradations present in this kind of images. Comparative results are given using a public database."
            },
            "slug": "Color-text-extraction-from-camera-based-images:-the-Mancas-Thillou-Gosselin",
            "title": {
                "fragments": [],
                "text": "Color text extraction from camera-based images: the impact of the choice of the clustering distance"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that the main problem is not in the choice of color spaces for generic text extraction but in the decision of clustering distances to handle alt degradations present in this kind of images."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40340264"
                        ],
                        "name": "Bin Wang",
                        "slug": "Bin-Wang",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108309754"
                        ],
                        "name": "Xiang-Feng Li",
                        "slug": "Xiang-Feng-Li",
                        "structuredName": {
                            "firstName": "Xiang-Feng",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiang-Feng Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47185791"
                        ],
                        "name": "Feng Liu",
                        "slug": "Feng-Liu",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30564880"
                        ],
                        "name": "Fu-Qiao Hu",
                        "slug": "Fu-Qiao-Hu",
                        "structuredName": {
                            "firstName": "Fu-Qiao",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fu-Qiao Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[9] used dimensionality reduction and graph theoretical clustering to segment text and to define the number of clusters dynamically."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9560812,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd8f6e83b1807000a3bd36f35ca552e8265af00f",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a novel binarization algorithm for color text images is presented. This algorithm effectively integrates color clustering and binary texture analysis, and is capable of handling situations with complex backgrounds. In this algorithm, dimensionality reduction and graph theoretical clustering are first employed. As a result, binary images related to clusters can be obtained. Binary texture analysis is then performed on each candidate binary image. Two kinds of effective texture features, run-length histogram and spatial-size distribution related, respectively, are extracted and explored. Cooperating with a linear discriminant analysis classifier, the optimal candidate for the best binarization effect is obtained. Experiments with images collected from the Internet have been carried out and compared with existing techniques. Both show the effectiveness of the algorithm."
            },
            "slug": "Color-text-image-binarization-based-on-binary-Wang-Li",
            "title": {
                "fragments": [],
                "text": "Color text image binarization based on binary texture analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A novel binarization algorithm for color text images is presented that effectively integrates color clustering and binary texture analysis, and is capable of handling situations with complex backgrounds."
            },
            "venue": {
                "fragments": [],
                "text": "2004 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403970934"
                        ],
                        "name": "C. Mancas-Thillou",
                        "slug": "C.-Mancas-Thillou",
                        "structuredName": {
                            "firstName": "C\u00e9line",
                            "lastName": "Mancas-Thillou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mancas-Thillou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50276543"
                        ],
                        "name": "B. Gosselin",
                        "slug": "B.-Gosselin",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Gosselin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gosselin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Thillou and Gosselin [11] segmented color text with a 3- means clustering algorithm in the RGB color space, where discrimination on clean and complex backgrounds was previously done to merge clusters more efficiently."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 21
                            }
                        ],
                        "text": "Nevertheless, Mancas-Thillou and Gosselin [18] previously explained why RGB color space handles variability of natural scenes better than most other spaces; it is general enough to support all degradations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Thillou and Gosselin [11] segmented color text with a 3means clustering algorithm in the RGB color space, where discrimination on clean and complex backgrounds was previously done to merge clusters more efficiently."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13125782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "780a963fc1e104fc21d352fa1be43206a546baab",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new automatic color thresholding based on wavelet denoising and color clustering with K-means in order to segment text information in a camera-based image. Several parameters bring different information and this paper tries to explain how to use this complementarity. It is mainly based on the discrimination between two kinds of backgrounds: clean or complex. On one hand, this separation is useful to apply a particular algorithm on each of these cases and on the other hand to decrease the computation time for clean cases for which a faster method could be considered. Finally, several experiments were done to discuss results and to conclude that the use of a discrimination between kinds of backgrounds gives better results in terms of Precision and Recall."
            },
            "slug": "Color-binarization-for-complex-camera-based-images-Mancas-Thillou-Gosselin",
            "title": {
                "fragments": [],
                "text": "Color binarization for complex camera-based images"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A new automatic color thresholding based on wavelet denoising and color clustering with K-means is described in order to segment text information in a camera-based image to conclude that the use of a discrimination between kinds of backgrounds gives better results in terms of Precision and Recall."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738017"
                        ],
                        "name": "S. Wesolkowski",
                        "slug": "S.-Wesolkowski",
                        "structuredName": {
                            "firstName": "Slawomir",
                            "lastName": "Wesolkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wesolkowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 94
                            }
                        ],
                        "text": "Cosine-based similarity has been previously used for edge detection and color segmentation by Wesolkowski and Jernigan [20,21], color classification by Hild [22] and vector directional filtering by Lukac et al. [23], for example."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 119
                            }
                        ],
                        "text": "Cosine-based similarity has been previously used for edge detection and color segmentation by Wesolkowski and Jernigan [20,21], color classification by Hild [22] and vector directional filtering by Lukac et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26969321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e48adbe72960e376a2afeee05d5dbfa807f5fae1",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A new color image segmentation algorithm is presented in this paper. This algorithm is invariant to highlights and shading. This is accomplished in two steps. First, the average pixel intensity is removed from each RGB coordinate. This transformation mitigates the effects of highlights. Next, the Mixture of Principal Components algorithm is used to perform the segmentation. The MPC is implicitly invariant to shading due to the inner vector product or vector angle being used as similarity measure. Since the new coordinate system contains negative numbers, it is necessary to modify the MPC algorithm since in its original form it does not distinguish between positive and negative color space coordinates. Results on artificial and real images illustrate the effectiveness of the method. Finally, the use of the total within-cluster variance is investigated as possible criterion for selecting the number of clusters for the new algorithm. Note: This report is an overview of the work published in [16] which was carried out while I was a Foreign Researcher in Prof. Tominaga\u2019s lab at the Osaka Electro-Communications University on an IEEE NNC scholarship. PROBLEM STATEMENT In recent years, color constancy the perception of objects in the real world without illumination effects has been a major concern in the research community of image science and technology. Humans perceive object surfaces in a scene in spite of shading and highlight effects. Can machines do a similar feat?"
            },
            "slug": "Shading-and-Highlight-Invariant-Color-Image-Wesolkowski",
            "title": {
                "fragments": [],
                "text": "Shading and Highlight Invariant Color Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A new color image segmentation algorithm is presented that is invariant to highlights and shading and the use of the total within-cluster variance is investigated as possible criterion for selecting the number of clusters for the new algorithm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121267347"
                        ],
                        "name": "K. Jung",
                        "slug": "K.-Jung",
                        "structuredName": {
                            "firstName": "Keechul",
                            "lastName": "Jung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Jung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144602022"
                        ],
                        "name": "K. Kim",
                        "slug": "K.-Kim",
                        "structuredName": {
                            "firstName": "Kwang",
                            "lastName": "Kim",
                            "middleNames": [
                                "In"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5999466,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cedf72be1fe814ef2ee9d65633dc3226f80f0785",
            "isKey": false,
            "numCitedBy": 936,
            "numCiting": 100,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Text-information-extraction-in-images-and-video:-a-Jung-Kim",
            "title": {
                "fragments": [],
                "text": "Text information extraction in images and video: a survey"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2821130"
                        ],
                        "name": "David J. Crandall",
                        "slug": "David-J.-Crandall",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Crandall",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Crandall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721328"
                        ],
                        "name": "Sameer Kiran Antani",
                        "slug": "Sameer-Kiran-Antani",
                        "structuredName": {
                            "firstName": "Sameer",
                            "lastName": "Antani",
                            "middleNames": [
                                "Kiran"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sameer Kiran Antani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[8] for extraction of caption texts, but without color information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18084231,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37903a00047e1cf377408ca4119b48f2bfab89c4",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. The popularity of digital video is increasing rapidly. To help users navigate libraries of video, algorithms that automatically index video based on content are needed. One approach is to extract text appearing in video, which often reflects a scene's semantic content. This is a difficult problem due to the unconstrained nature of general-purpose video. Text can have arbitrary color, size, and orientation. Backgrounds may be complex and changing. Most work so far has made restrictive assumptions about the nature of text occurring in video. Such work is therefore not directly applicable to unconstrained, general-purpose video. In addition, most work so far has focused only on detecting the spatial extent of text in individual video frames. However, text occurring in video usually persists for several seconds. This constitutes a text event that should be entered only once in the video index. Therefore it is also necessary to determine the temporal extent of text events. This is a non-trivial problem because text may move, rotate, grow, shrink, or otherwise change over time. Such text effects are common in television programs and commercials but so far have received little attention in the literature. This paper discusses detecting, binarizing, and tracking caption text in general-purpose MPEG-1 video. Solutions are proposed for each of these problems and compared with existing work found in the literature."
            },
            "slug": "Extraction-of-special-effects-caption-text-events-Crandall-Antani",
            "title": {
                "fragments": [],
                "text": "Extraction of special effects caption text events from digital video"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper discusses detecting, binarizing, and tracking caption text in general-purpose MPEG-1 video, and solutions are proposed for each of these problems and compared with existing work found in the literature."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2530942"
                        ],
                        "name": "H. Hase",
                        "slug": "H.-Hase",
                        "structuredName": {
                            "firstName": "Hiroyuki",
                            "lastName": "Hase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3188516"
                        ],
                        "name": "T. Shinokawa",
                        "slug": "T.-Shinokawa",
                        "structuredName": {
                            "firstName": "Toshiyuki",
                            "lastName": "Shinokawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Shinokawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71114145"
                        ],
                        "name": "M. Yoneda",
                        "slug": "M.-Yoneda",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Yoneda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Yoneda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3] used the CIE L*a*b* color space and a histogram analysis to define the number of colors by frequency occurrences."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40333068,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b24ea59f58374750894ad050dbafe88c81ed54f",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Character-string-extraction-from-color-documents-Hase-Shinokawa",
            "title": {
                "fragments": [],
                "text": "Character string extraction from color documents"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748249"
                        ],
                        "name": "I. Pratikakis",
                        "slug": "I.-Pratikakis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Pratikakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pratikakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097431961"
                        ],
                        "name": "K. Kepene",
                        "slug": "K.-Kepene",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Kepene",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kepene"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2397702"
                        ],
                        "name": "S. Perantonis",
                        "slug": "S.-Perantonis",
                        "structuredName": {
                            "firstName": "Stavros",
                            "lastName": "Perantonis",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Perantonis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[1] may be observed with a decrease in error rate of around 43%."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[1] first extracted text with the luminance component only, then binarized the gray-level image and the inverted image with an adaptive thresholding algorithm, and finally, they chose the optimum between both binarizations by estimating the background surface."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[1], we compute the Levenshtein distance on the same images (from the public ICDAR 2003 database, as well), as displayed in Table 1, with the same commercial OCR."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[1] which uses background surface thresholding with an adaptive binarization, followed by an image upsampling to improve quality."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18567098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28f3869f2868e2b39a2fe7f069c1907e29f17764",
            "isKey": true,
            "numCitedBy": 52,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel methodology for text detection in indoor/outdoor scene images. The proposed methodology is based on an efficient binarization and enhancement technique followed by a suitable connected component analysis procedure. Image binarization successfully process indoor/ outdoor scene images having shadows, non-uniform illumination, low contrast and large signal-depended noise. Connected component analysis is used to define the final binary images that mainly consist of text regions. The proposed methodology leads in increased success rates at commercial OCR engines. Experimental results based on the public database of the ICDAR2003 Robust Reading Competition prove the efficiency of the proposed approach."
            },
            "slug": "Detection-in-Indoor-/-Outdoor-Scene-Images-Gatos-Pratikakis",
            "title": {
                "fragments": [],
                "text": "Detection in Indoor / Outdoor Scene Images"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A novel methodology for text detection in indoor/outdoor scene images based on an efficient binarization and enhancement technique followed by a suitable connected component analysis procedure that leads in increased success rates at commercial OCR engines."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792593"
                        ],
                        "name": "W. Skarbek",
                        "slug": "W.-Skarbek",
                        "structuredName": {
                            "firstName": "Wladyslaw",
                            "lastName": "Skarbek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Skarbek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761601"
                        ],
                        "name": "A. Koschan",
                        "slug": "A.-Koschan",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Koschan",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Koschan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 46
                            }
                        ],
                        "text": "For more information, the reader may refer to [15,17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5835459,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa4dce7d484da0d91d872261e0c41006521e732f",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 121,
            "paperAbstract": {
                "fragments": [],
                "text": "Image segmentation, i.e., identi cation of homogeneous regions in the image, has been the subject of considerable research activity over the last three decades. Many algorithms have been elaborated for gray scale images. However, the problem of segmentation for colour images, which convey much more information about objects in scenes, has received much less attention of scienti c community. While several surveys of monochrome image segmentation techniques were published, similar comprehensive surveys for colour images, to our knowledge, did not emerge. This report contains: an extensive survey of algorithms for colour image segmentation, a categorization of them according well de ned list of attributes, suggestions for their improvements, and descriptions of few novel approaches."
            },
            "slug": "Colour-Image-Segmentation:-A-Survey-Skarbek-Koschan",
            "title": {
                "fragments": [],
                "text": "Colour Image Segmentation: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An extensive survey of algorithms for colour image segmentation, a categorization of them according to list of attributes, suggestions for their improvements, and descriptions of few novel approaches are included."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2713739"
                        ],
                        "name": "M. Hild",
                        "slug": "M.-Hild",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Hild",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hild"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 196
                            }
                        ],
                        "text": "The authors wish to sincerely thank researchers in color vision and physical-based segmentation who kindly gave time and sent papers to make their field less opaque and more particularly Prof. M. Hild from Osaka University, Japan."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "Cosine-based similarity has been previously used for edge detection and color segmentation by Wesolkowski and Jernigan [20,21], color classification by Hild [22] and vector directional filtering by Lukac et al. [23], for example."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "Cosine-based similarity has been previously used for edge detection and color segmentation by Wesolkowski and Jernigan [20,21], color classification by Hild [22] and vector directional filtering by Lukac et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 99661046,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aae11a1e8e9dce74236b283d9e2efb517f867419",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the efficiency of color similarity measures in the context of color classification tasks. Color similarity measures are categorized into three major types: Point-type CSMs for classifying colors by absolutevalue, diffuse reflection component based CSMs for classifying \"body colors\" of object surfaces made of dielectric materials, and dichromatic reflection component based CSMs for classifying colors that include both the diffuse and the specular reflection component. First, the results of an evaluation of existing color similarity measures with regard to their ability to separate color classes using more than hundred test cases of the background-frame-differencing type are reported. It was found that especially two of the existing color similarity measures (S 7 and S 8 ) have good properties with respect to brightness, saturation and hue changes, and that they have a compact scalar field structure in RGB space. In addition, they have the largest margin for class separation. Second, we propose several new color similarity measures of the diffuse reflection component based color similarity type and report on the results of an evaluation regarding their class separation ability using more than 50 test images (for facial skin color classification). It was found that two color similarity measures (S 1 3 and S 1 4 ) perform best for separating color classes when the colors are treated as body color reflections. The properties of these measures with respect to brightness, saturation and hue changes are not perfect, but nonetheless reasonably good, and they have a compact scalar field structure in RGB space. Third, we propose a new color similarity measure of the dichromatic reflection component based type and discuss the problems associated with it. Finally, we introduce a shifted reference color similarity measure which can be used to compute the similarity between colors that may be the result of a systematic shift due to some physical phenomenon."
            },
            "slug": "Color-similarity-measures-for-efficient-color-Hild",
            "title": {
                "fragments": [],
                "text": "Color similarity measures for efficient color classification"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A shifted reference color similarity measure is introduced which can be used to compute the similarity between colors that may be the result of a systematic shift due to some physical phenomenon."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738017"
                        ],
                        "name": "S. Wesolkowski",
                        "slug": "S.-Wesolkowski",
                        "structuredName": {
                            "firstName": "Slawomir",
                            "lastName": "Wesolkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wesolkowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143981269"
                        ],
                        "name": "E. Jernigan",
                        "slug": "E.-Jernigan",
                        "structuredName": {
                            "firstName": "Ed",
                            "lastName": "Jernigan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Jernigan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 94
                            }
                        ],
                        "text": "Cosine-based similarity has been previously used for edge detection and color segmentation by Wesolkowski and Jernigan [20,21], color classification by Hild [22] and vector directional filtering by Lukac et al. [23], for example."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 119
                            }
                        ],
                        "text": "Cosine-based similarity has been previously used for edge detection and color segmentation by Wesolkowski and Jernigan [20,21], color classification by Hild [22] and vector directional filtering by Lukac et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "Inside the RGB color space, a reliable and simple method to obtain hue information is through a cosine-based similarity [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16697129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97998fd3f092c50a66edab6e91456b0a8cb761a8",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Typically, the edge detection problem in color images has been addressed using the Euclidean Distance or similar metrics. Recently, the Vector Angle metric was introduced to use the hue and saturation components in a color image in order to capture more accurate edge data. However, both the Euclidean Distance and Vector Angle metrics have some limitations. Two methods which combine both metrics are introduced. They try to leverage the advantages of each metric to better detect edges in complex color images. The edge detection operators used are based on the Vector Gradient and the Difference Vector operators. Preliminary results are presented and discussed."
            },
            "slug": "Color-edge-detection-in-RGB-using-jointly-euclidean-Wesolkowski-Jernigan",
            "title": {
                "fragments": [],
                "text": "Color edge detection in RGB using jointly euclidean distance and vector angle"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two methods which combine both the Euclidean Distance and Vector Angle metrics try to leverage the advantages of each metric to better detect edges in complex color images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12290634"
                        ],
                        "name": "S. Shafer",
                        "slug": "S.-Shafer",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Shafer",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shafer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "The dichromatic reflection model, introduced by Shafer [14], states that light is reflected on inhomogeneous dielectric materials in diffuse and specular reflection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 48
                            }
                        ],
                        "text": "The dichromatic reflection model, introduced by Shafer [14], states that light is reflected on inhomogeneous dielectric\nmaterials in diffuse and specular reflection."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60519493,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "5e3ab08e93e5eb529692825cfedf6d3b6763bd76",
            "isKey": false,
            "numCitedBy": 1343,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : This paper presents an algorithm for analyzing a standard color image to determine intrinsic images of the amount of interface (specular) and body (diffuse) reflection at each pixel. The interface reflection represents the highlights from the original image, and the body reflection represents the original image with highlights removed. Such intrinsic images are of interest because the geometric properties of each type of reflection are simpler than the geometric properties of intensity in a black-and-white image. The algorithm is based upon a physical model of reflection which states that two distinct types of reflection--interface and body reflection--occur, and that each type can be decomposed into a relative spectral distribution and a geometric scale factor. This model is far more general than typical models used in computer vision and computer graphics, and includes most such models as special cases. In addition, the model does not assume a point light source or uniform illumination distribution over the scene. The properties of spectral projection into color space are used to derive a new model of pixel-value color distribution, and this model is exploited in an algorithm to derive the intrinsic images. Suggestions are provided for extending the model to deal with diffuse illumination and for analyzing the intrinsic images of reflection. Additional keywords: Dischromatic reflection model. (Author)"
            },
            "slug": "Using-color-to-separate-reflection-components-Shafer",
            "title": {
                "fragments": [],
                "text": "Using color to separate reflection components"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This paper presents an algorithm for analyzing a standard color image to determine intrinsic images of the amount of interface (specular) and body (diffuse) reflection at each pixel, based upon a physical model of reflection."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815031"
                        ],
                        "name": "S. Lucas",
                        "slug": "S.-Lucas",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lucas",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87531536"
                        ],
                        "name": "A. Panaretos",
                        "slug": "A.-Panaretos",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Panaretos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Panaretos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073684197"
                        ],
                        "name": "Luis Sosa",
                        "slug": "Luis-Sosa",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Sosa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luis Sosa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052189571"
                        ],
                        "name": "Anthony Tang",
                        "slug": "Anthony-Tang",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anthony Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108862960"
                        ],
                        "name": "Shirley Wong",
                        "slug": "Shirley-Wong",
                        "structuredName": {
                            "firstName": "Shirley",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shirley Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114080648"
                        ],
                        "name": "Robert Young",
                        "slug": "Robert-Young",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065499715"
                        ],
                        "name": "Kazuki Ashida",
                        "slug": "Kazuki-Ashida",
                        "structuredName": {
                            "firstName": "Kazuki",
                            "lastName": "Ashida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuki Ashida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055905787"
                        ],
                        "name": "Hiroki Nagai",
                        "slug": "Hiroki-Nagai",
                        "structuredName": {
                            "firstName": "Hiroki",
                            "lastName": "Nagai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hiroki Nagai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47471571"
                        ],
                        "name": "Masayuki Okamoto",
                        "slug": "Masayuki-Okamoto",
                        "structuredName": {
                            "firstName": "Masayuki",
                            "lastName": "Okamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masayuki Okamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152933693"
                        ],
                        "name": "Hiroaki Yamamoto",
                        "slug": "Hiroaki-Yamamoto",
                        "structuredName": {
                            "firstName": "Hiroaki",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hiroaki Yamamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34593830"
                        ],
                        "name": "H. Miyao",
                        "slug": "H.-Miyao",
                        "structuredName": {
                            "firstName": "Hidetoshi",
                            "lastName": "Miyao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Miyao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146280843"
                        ],
                        "name": "JunMin Zhu",
                        "slug": "JunMin-Zhu",
                        "structuredName": {
                            "firstName": "JunMin",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "JunMin Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2873679"
                        ],
                        "name": "WuWen Ou",
                        "slug": "WuWen-Ou",
                        "structuredName": {
                            "firstName": "WuWen",
                            "lastName": "Ou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "WuWen Ou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144899680"
                        ],
                        "name": "Christian Wolf",
                        "slug": "Christian-Wolf",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680935"
                        ],
                        "name": "J. Jolion",
                        "slug": "J.-Jolion",
                        "structuredName": {
                            "firstName": "Jean-Michel",
                            "lastName": "Jolion",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jolion"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1844464"
                        ],
                        "name": "L. Todoran",
                        "slug": "L.-Todoran",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Todoran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Todoran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717056"
                        ],
                        "name": "M. Worring",
                        "slug": "M.-Worring",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Worring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Worring"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46520089"
                        ],
                        "name": "Xiaofan Lin",
                        "slug": "Xiaofan-Lin",
                        "structuredName": {
                            "firstName": "Xiaofan",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofan Lin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2250003,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a01deac56a81646e8d84cb7bf2d905714ff00808",
            "isKey": false,
            "numCitedBy": 235,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.This paper describes the robust reading competitions for ICDAR 2003. With the rapid growth in research over the last few years on recognizing text in natural scenes, there is an urgent need to establish some common benchmark datasets and gain a clear understanding of the current state of the art. We use the term \u2018robust reading\u2019 to refer to text images that are beyond the capabilities of current commercial OCR packages. We chose to break down the robust reading problem into three subproblems and run competitions for each stage, and also a competition for the best overall system. The subproblems we chose were text locating, character recognition and word recognition. By breaking down the problem in this way, we hoped to gain a better understanding of the state of the art in each of the subproblems. Furthermore, our methodology involved storing detailed results of applying each algorithm to each image in the datasets, allowing researchers to study in depth the strengths and weaknesses of each algorithm. The text-locating contest was the only one to have any entries. We give a brief description of each entry and present the results of this contest, showing cases where the leading entries succeed and fail. We also describe an algorithm for combining the outputs of the individual text locators and show how the combination scheme improves on any of the individual systems."
            },
            "slug": "ICDAR-2003-robust-reading-competitions:-entries,-Lucas-Panaretos",
            "title": {
                "fragments": [],
                "text": "ICDAR 2003 robust reading competitions: entries, results, and future directions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper broke down the robust reading problem into three subproblems and run competitions for each stage, and also a competition for the best overall system, and described an algorithm for combining the outputs of the individual text locators and showed how the combination scheme improves on any of theindividual systems."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144117646"
                        ],
                        "name": "Jiang Gao",
                        "slug": "Jiang-Gao",
                        "structuredName": {
                            "firstName": "Jiang",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiang Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118579343"
                        ],
                        "name": "Jie Yang",
                        "slug": "Jie-Yang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153391519"
                        ],
                        "name": "Ying Zhang",
                        "slug": "Ying-Zhang",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[7] used the same algorithm but determined the number of Gaussian mixtures by taking advantage of the text layout syntax."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10228582,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5c6eaa32e741fcc5e401b2ef3b06077b0fa98ac",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The authors present a system for automatic extraction and interpretation of signs from a natural scene. The system is capable of capturing images, detecting and recognizing signs, and translating them into a target language. The translation can be displayed on a hand-held wearable display or a head-mounted display. It can also be synthesized as a voice output message over the earphones. The paper addresses challenges in automatic sign extraction and translation, describes methods for automatic sign extraction, and extends example-based machine translation technology for sign translation. The authors use a user-centered approach in system development that takes advantage of human intelligence and leverages human capabilities. They are currently working on Chinese sign translation. So far, they have developed a prototype system that can recognize Chinese signs from a video camera and then translate them either into English text or a voice stream. They have built a database containing about 800 Chinese signs for development and evaluation. The authors hope that the sign translation, in conjunction with spoken language translation, will help international tourists overcome language barriers. The technology could also help a visually handicapped person increase his or her environmental awareness."
            },
            "slug": "Text-Detection-and-Translation-from-Natural-Scenes-Gao-Yang",
            "title": {
                "fragments": [],
                "text": "Text Detection and Translation from Natural Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A system for automatic extraction and interpretation of signs from a natural scene capable of capturing images, detecting and recognizing signs, and translating them into a target language, which will help international tourists overcome language barriers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145621177"
                        ],
                        "name": "Gaurav Sharma",
                        "slug": "Gaurav-Sharma",
                        "structuredName": {
                            "firstName": "Gaurav",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gaurav Sharma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "As stated in [13], natural light has a diffuse behavior in which rays do not have a privileged orientation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 191228051,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "8986e5363a9205e4be3bd53ab2920fcf4e3c938f",
            "isKey": false,
            "numCitedBy": 560,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Color Fundamentals for Digital Imaging, Gaurav Sharma, Xerox Corporation Visual Psychophysics and Color Appearance, Garrett M. Johnson and Mark D. Fairchild, Rochester Institute of Technology Physical Models for Color Prediction, Patrick Emmel, Clariant International Color Management for Digital Imaging Systems, Edward J. Giorgianni, Thomas E. Madden and Kevin E. Spaulding, Eastman Kodak Company Device Characterization, Raja Bala, Xerox Corporation Digital Color Halftones, Charles M Hains, Shen-ge Wang, and Keith T. Knox, Xerox Corporation Human Visual Model Based Color Halftoning, A. Ufuk Agar, Hewlett Packard Company, Farhan A. Baqai, Sony Electronics, and Jan P. Allebach, Purdue University Compression of Color Images, Ricardo de Queiroz, Xerox Corporation Color Quantization, Luc Brun, Universite Reims, Champagne Ardenne and Alain Tremeau, Universite Jean Monnet de Saint-Etienne Gamut Mapping, Jan Morovic, University of Derby Efficient Color Transformation Implementation, Raja Bala and R. Victor Klassen, Xerox Corporation Color Image Processing for Digital Cameras, Ken Parulski and Kevin E. Spaulding, Eastman Kodak Company"
            },
            "slug": "Digital-Color-Imaging-Handbook-Sharma",
            "title": {
                "fragments": [],
                "text": "Digital Color Imaging Handbook"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809629"
                        ],
                        "name": "N. Otsu",
                        "slug": "N.-Otsu",
                        "structuredName": {
                            "firstName": "Nobuyuki",
                            "lastName": "Otsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Otsu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "The choice of inversion is based on a quick global image thresholding such as the well-known Otsu method [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15326934,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "1d4816c612e38dac86f2149af667a5581686cdef",
            "isKey": false,
            "numCitedBy": 32882,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A nonparametric and unsupervised method ofautomatic threshold selection for picture segmentation is presented. An optimal threshold is selected by the discriminant criterion, namely, so as to maximize the separability of the resultant classes in gray levels. The procedure is very simple, utilizing only the zerothand the first-order cumulative moments of the gray-level histogram. It is straightforward to extend the method to multithreshold problems. Several experimental results are also presented to support the validity of the method."
            },
            "slug": "A-threshold-selection-method-from-gray-level-Otsu",
            "title": {
                "fragments": [],
                "text": "A threshold selection method from gray level histograms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403970934"
                        ],
                        "name": "C. Mancas-Thillou",
                        "slug": "C.-Mancas-Thillou",
                        "structuredName": {
                            "firstName": "C\u00e9line",
                            "lastName": "Mancas-Thillou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mancas-Thillou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145260622"
                        ],
                        "name": "Silvio Ferreira",
                        "slug": "Silvio-Ferreira",
                        "structuredName": {
                            "firstName": "Silvio",
                            "lastName": "Ferreira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Silvio Ferreira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50276543"
                        ],
                        "name": "B. Gosselin",
                        "slug": "B.-Gosselin",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Gosselin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gosselin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "Performance of word extraction is measured by a home-made OCR algorithm [29], dedicated to natural scene images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "To choose the bandwidth for filters, we use a home-made OCR algorithm composed of a multi-layer perceptron with geometrical features to recognize characters [29]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15162456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40e34038d358c4487c86fba6adb91d6e8dc9e57e",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a mobile device which tries to give the blind or visually impaired access to text information. Three key technologies are required for this system: text detection, optical character recognition, and speech synthesis. Blind users and the mobile environment imply two strong constraints. First, pictures will be taken without control on camera settings and a priori information on text (font or size) and background. The second issue is to link several techniques together with an optimal compromise between computational constraints and recognition efficiency. We will present the overall description of the system from text detection to OCR error correction."
            },
            "slug": "An-Embedded-Application-for-Degraded-Text-Mancas-Thillou-Ferreira",
            "title": {
                "fragments": [],
                "text": "An Embedded Application for Degraded Text Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper describes a mobile device which tries to give the blind or visually impaired access to text information and presents the overall description of the system from text detection to OCR error correction."
            },
            "venue": {
                "fragments": [],
                "text": "EURASIP J. Adv. Signal Process."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716010"
                        ],
                        "name": "R. Lukac",
                        "slug": "R.-Lukac",
                        "structuredName": {
                            "firstName": "Rastislav",
                            "lastName": "Lukac",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lukac"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705037"
                        ],
                        "name": "K. Plataniotis",
                        "slug": "K.-Plataniotis",
                        "structuredName": {
                            "firstName": "Konstantinos",
                            "lastName": "Plataniotis",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Plataniotis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710961"
                        ],
                        "name": "B. Smolka",
                        "slug": "B.-Smolka",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Smolka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Smolka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707519"
                        ],
                        "name": "A. Venetsanopoulos",
                        "slug": "A.-Venetsanopoulos",
                        "structuredName": {
                            "firstName": "Anastasios",
                            "lastName": "Venetsanopoulos",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Venetsanopoulos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "Additional information on this issue can be found in [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 23875548,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "4070ad41f4608172b185af6791524d6f2a41d9fe",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a class of nonlinear multichannel filters capable of removing impulsive noise in color images. The here-proposed generalized selection weighted vector filter class constitutes a powerful filtering framework for multichannel signal processing. Previously defined multichannel filters such as vector median filter, basic vector directional filter, directional-distance filter, weighted vector median filters, and weighted vector directional filters are treated from a global viewpoint using the proposed framework. Robust order-statistic concepts and increased degree of freedom in filter design make the proposed method attractive for a variety of applications. Introduced multichannel sigmoidal adaptation of the filter parameters and its modifications allow to accommodate the filter parameters to varying signal and noise statistics. Simulation studies reported in this paper indicate that the proposed filter class is computationally attractive, yields excellent performance, and is able to preserve fine details and color information while efficiently suppressing impulsive noise. This paper is an extended version of the paper by Lukac et al. presented at the 2003 IEEE-EURASIP Workshop on Nonlinear Signal and Image Processing (NSIP '03) in Grado, Italy."
            },
            "slug": "Generalized-Selection-Weighted-Vector-Filters-Lukac-Plataniotis",
            "title": {
                "fragments": [],
                "text": "Generalized Selection Weighted Vector Filters"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "Simulation studies reported in this paper indicate that the proposed generalized selection weighted vector filter class is computationally attractive, yields excellent performance, and is able to preserve fine details and color information while efficiently suppressing impulsive noise."
            },
            "venue": {
                "fragments": [],
                "text": "EURASIP J. Adv. Signal Process."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "Field [28] proposed an alternative function called Log\u2013Gabor which lets us choose a larger bandwidth without producing a continuous component."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "In this paper, we opt for Log\u2013Gabor filters proposed by Field [28], because they have an extended tail in high frequencies as required for natural scene images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1600874,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aeb37769d72999bcbfb0582b73607fd8d23f4545",
            "isKey": false,
            "numCitedBy": 3273,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "The relative efficiency of any particular image-coding scheme should be defined only in relation to the class of images that the code is likely to encounter. To understand the representation of images by the mammalian visual system, it might therefore be useful to consider the statistics of images from the natural environment (i.e., images with trees, rocks, bushes, etc). In this study, various coding schemes are compared in relation to how they represent the information in such natural images. The coefficients of such codes are represented by arrays of mechanisms that respond to local regions of space, spatial frequency, and orientation (Gabor-like transforms). For many classes of image, such codes will not be an efficient means of representing information. However, the results obtained with six natural images suggest that the orientation and the spatial-frequency tuning of mammalian simple cells are well suited for coding the information in such images if the goal of the code is to convert higher-order redundancy (e.g., correlation between the intensities of neighboring pixels) into first-order redundancy (i.e., the response distribution of the coefficients). Such coding produces a relatively high signal-to-noise ratio and permits information to be transmitted with only a subset of the total number of cells. These results support Barlow's theory that the goal of natural vision is to represent the information in the natural environment with minimal redundancy."
            },
            "slug": "Relations-between-the-statistics-of-natural-images-Field",
            "title": {
                "fragments": [],
                "text": "Relations between the statistics of natural images and the response properties of cortical cells."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The results obtained with six natural images suggest that the orientation and the spatial-frequency tuning of mammalian simple cells are well suited for coding the information in such images if the goal of the code is to convert higher-order redundancy into first- order redundancy."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2951740"
                        ],
                        "name": "Bui Tuong Phong",
                        "slug": "Bui-Tuong-Phong",
                        "structuredName": {
                            "firstName": "Bui",
                            "lastName": "Phong",
                            "middleNames": [
                                "Tuong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bui Tuong Phong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "Specular reflection defined by Phong\u2019s model [16]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Phong\u2019s model [16] describes the geometry of image formation for computer generated images and eases our understanding of color variations in an image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1439868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90189b948a37477938a8d83d81b6737f930d7997",
            "isKey": false,
            "numCitedBy": 3298,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The quality of computer generated images of three-dimensional scenes depends on the shading technique used to paint the objects on the cathode-ray tube screen. The shading algorithm itself depends in part on the method for modeling the object, which also determines the hidden surface algorithm. The various methods of object modeling, shading, and hidden surface removal are thus strongly interconnected. Several shading techniques corresponding to different methods of object modeling and the related hidden surface algorithms are presented here. Human visual perception and the fundamental laws of optics are considered in the development of a shading rule that provides better quality and increased realism in generated images."
            },
            "slug": "Illumination-for-computer-generated-pictures-Phong",
            "title": {
                "fragments": [],
                "text": "Illumination for computer generated pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Human visual perception and the fundamental laws of optics are considered in the development of a shading rule that provides better quality and increased realism in generated images."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403970934"
                        ],
                        "name": "C. Mancas-Thillou",
                        "slug": "C.-Mancas-Thillou",
                        "structuredName": {
                            "firstName": "C\u00e9line",
                            "lastName": "Mancas-Thillou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mancas-Thillou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728108"
                        ],
                        "name": "M. Mirmehdi",
                        "slug": "M.-Mirmehdi",
                        "structuredName": {
                            "firstName": "Majid",
                            "lastName": "Mirmehdi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mirmehdi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "5, various preprocessing steps [25] such as denoising and resolution enhancement are often used prior to the essential analysis step."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8021225,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "078da887d298a56257a8c94136fd2a0ab351da25",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a super-resolution technique specifically aimed at enhancing low-resolution text images from handheld devices. The Teager filter, a quadratic unsharp masking filter, is used to highlight high frequencies which are then combined with the warped and interpolated image sequence following motion estimation using Taylor series decomposition. Comparative performance evaluation is presented in the form of OCR results of the super-resolution"
            },
            "slug": "Super-Resolution-Text-using-the-Teager-Filter-Mancas-Thillou-Mirmehdi",
            "title": {
                "fragments": [],
                "text": "Super-Resolution Text using the Teager Filter"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The Teager filter, a quadratic unsharp masking filter, is used to highlight high frequencies which are then combined with the warped and interpolated image sequence following motion estimation using Taylor series decomposition to create a super-resolution image."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716010"
                        ],
                        "name": "R. Lukac",
                        "slug": "R.-Lukac",
                        "structuredName": {
                            "firstName": "Rastislav",
                            "lastName": "Lukac",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lukac"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710961"
                        ],
                        "name": "B. Smolka",
                        "slug": "B.-Smolka",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Smolka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Smolka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145320019"
                        ],
                        "name": "K. Martin",
                        "slug": "K.-Martin",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Martin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "151079410"
                        ],
                        "name": "K. Plataniotis",
                        "slug": "K.-Plataniotis",
                        "structuredName": {
                            "firstName": "Kostas",
                            "lastName": "Plataniotis",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Plataniotis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707519"
                        ],
                        "name": "A. Venetsanopoulos",
                        "slug": "A.-Venetsanopoulos",
                        "structuredName": {
                            "firstName": "Anastasios",
                            "lastName": "Venetsanopoulos",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Venetsanopoulos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 38356356,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "aaf0a8925f8564e904abc46b3ad1f9aa2b120cf6",
            "isKey": false,
            "numCitedBy": 358,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Vector processing operations use essential spectral and spatial information to remove noise and localize microarray spots. The proposed fully automated vector technique can be easily implemented in either hardware or software; and incorporated in any existing microarray image analysis and gene expression tool."
            },
            "slug": "Vector-filtering-for-color-imaging-Lukac-Smolka",
            "title": {
                "fragments": [],
                "text": "Vector filtering for color imaging"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The proposed fully automated vector technique can be easily implemented in either hardware or software; and incorporated in any existing microarray image analysis and gene expression tool."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Processing Magazine"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815031"
                        ],
                        "name": "S. Lucas",
                        "slug": "S.-Lucas",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lucas",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086769895"
                        ],
                        "name": "Carlos R. Jaimez Gonz\u00e1lez",
                        "slug": "Carlos-R.-Jaimez-Gonz\u00e1lez",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Gonz\u00e1lez",
                            "middleNames": [
                                "R.",
                                "Jaimez"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlos R. Jaimez Gonz\u00e1lez"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "Several techniques, based on edges, colors or textures, are available [26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16077217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26a05f21fc509874aade78a04f738834c579cb27",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a simple yet novel approach to the web-based deployment and evaluation of text locating algorithms. Web-based deployment allows algorithms to be evaluated by end users or researchers, without the need to install the algorithm. This is a major advantage both for the end user, and for the algorithm developer. The end user is protected from lengthy installation procedures, which may also leave one\u2019s machine in a corrupted state. The algorithm developer is protected from theft of software or intellectual property. Our system provides access to a deployed algorithm in two ways: interactive mode via a web browser, and program access mode via a special kind of web service architecture. The system is demonstrated with the deployment and testing of one of the entries for the ICDAR 2005 text locating competition."
            },
            "slug": "Web-Based-Deployment-of-Text-Locating-Algorithms-Lucas-Gonz\u00e1lez",
            "title": {
                "fragments": [],
                "text": "Web-Based Deployment of Text Locating Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This paper describes a simple yet novel approach to the web-based deployment and evaluation of text locating algorithms, which provides access to a deployed algorithm in two ways: interactive mode via a web browser, and program access mode through a special kind of web service architecture."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145353422"
                        ],
                        "name": "A. Hadi",
                        "slug": "A.-Hadi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Hadi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hadi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "In order to assess the use of spatial information to choose between the two distances, the silhouette Sil [32]\u2014which can be seen as a measure of how well clusters are separated\u2014is calculated as follows:\nSil \u00bc min\u00f0meanbetween\u00f0i; k\u00de\u00de meanwithin\u00f0i\u00de max\u00f0meanwithin\u00f0i\u00de;min\u00f0meanbetween\u00f0i; k\u00de\u00de\u00de\n\u00f012\u00de\nResults G and A\u2019s [10] SMC\nPrecision 0.64 0.93 Recall 0.56 0.91\nwhere meanwithin(i) is the average distance from the ith point to other points in the same cluster and meanbetween(i,k) is the average distance from the ith point to points in another cluster k."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "In order to assess the use of spatial information to choose between the two distances, the silhouette Sil [32]\u2014which can be seen as a measure of how well clusters are separated\u2014is calculated as follows:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5340931,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2d758b667092bb483c18cd86e661460b84386cb",
            "isKey": true,
            "numCitedBy": 7837,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The Wiley-Interscience Paperback Series consists of selected books that have been made more accessible to consumers in an effort to increase In both the increasingly important and distribution we show how these methods. Our experiments demonstrate that together can deal with most applications technometrics. In an appropriate visualization technique is to these new. The well written and efficiently finds accurate clusters in data including. Of applied value for several preprocessing tasks discontinuity preserving smoothing feature clusters! However the model based notion of domain knowledge from real data repositories in data. Discusses various types of study the user set explicitly but also propose another. This book make understandable the cluster analysis is based notion of starsmodern treatment."
            },
            "slug": "Finding-Groups-in-Data:-An-Introduction-to-Chster-Hadi",
            "title": {
                "fragments": [],
                "text": "Finding Groups in Data: An Introduction to Chster Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This book make understandable the cluster analysis is based notion of starsmodern treatment, which efficiently finds accurate clusters in data and discusses various types of study the user set explicitly but also proposes another."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33587489"
                        ],
                        "name": "Yingzi Du",
                        "slug": "Yingzi-Du",
                        "structuredName": {
                            "firstName": "Yingzi",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yingzi Du"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785977"
                        ],
                        "name": "Chein-I. Chang",
                        "slug": "Chein-I.-Chang",
                        "structuredName": {
                            "firstName": "Chein-I.",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chein-I. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769970"
                        ],
                        "name": "P. D. Thouin",
                        "slug": "P.-D.-Thouin",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Thouin",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Thouin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[5] applied entropy-based thresholding on each of the R, G, and B channels."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 121221251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "395a6ecbfffc287bf47322e8e5a8bf0970b0e76f",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Thresholding of video images is a great challenge because of their low spatial resolution and complex background. We investigate the issue of thresholding these images by reducing the number of colors to improve automated text detection and recognition. We develop an unsupervised approach to video images, which can be considered as an RGB color thresholding method. It applies a gray-level thresholding method to a video image in the (R, G, B) color space to produce a single threshold value for each domain. The three (R, G, B)-generated values will be subsequently processed by an effective unsupervised clustering algorithm that is based on a between-class/within-class criterion suggested by Otsu's method. Since thresholding methods designed for document images may not work effectively for video images in many applications, our proposed RGB color thresholding method has shown to be particularly effective in improvement on text detection and recognition, because it can reduce the background complexity while retaining the important text character pixels. Experiments also show that thresholding video images is far more difficult than thresholding document images, and the RGB color thresholding presented performs significantly better than simple histogram-based methods, which generally do not produce satisfactory results."
            },
            "slug": "Unsupervised-approach-to-color-video-thresholding-Du-Chang",
            "title": {
                "fragments": [],
                "text": "Unsupervised approach to color video thresholding"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An unsupervised approach to video images is developed, which can be considered as an RGB color thresholding method, which applies a gray-level thresholded method to a video image in the (R, G, B) color space to produce a single threshold value for each domain."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2154179"
                        ],
                        "name": "V. Levenshtein",
                        "slug": "V.-Levenshtein",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Levenshtein",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Levenshtein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "The Levenshtein distance [31] between two strings is given by the minimum number of operations needed to transform one string into the other, where an operation is an insertion, deletion, or substitution of a single character."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60827152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2f8876482c97e804bb50a5e2433881ae31d0cdd",
            "isKey": false,
            "numCitedBy": 10964,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Binary-codes-capable-of-correcting-deletions,-and-Levenshtein",
            "title": {
                "fragments": [],
                "text": "Binary codes capable of correcting deletions, insertions, and reversals"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716010"
                        ],
                        "name": "R. Lukac",
                        "slug": "R.-Lukac",
                        "structuredName": {
                            "firstName": "Rastislav",
                            "lastName": "Lukac",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lukac"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705037"
                        ],
                        "name": "K. Plataniotis",
                        "slug": "K.-Plataniotis",
                        "structuredName": {
                            "firstName": "Konstantinos",
                            "lastName": "Plataniotis",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Plataniotis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 193
                            }
                        ],
                        "text": "The most known cosine-based similarity is defined by\nScosoriginal\u00f0xi; xj\u00de \u00bc xi:xj\nkxik:kxjk \u00f06\u00de\nHowever, several cosine-based similarities have been designed and can be found in the tutorial work of Lukac and Plataniotis [19]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "However, several cosine-based similarities have been designed and can be found in the tutorial work of Lukac and Plataniotis [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18587239,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14ccd1dc2a6bf7111715941b01ac23aae7de06f2",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 119,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Taxonomy-of-Color-Image-Filtering-and-Enhancement-Lukac-Plataniotis",
            "title": {
                "fragments": [],
                "text": "A Taxonomy of Color Image Filtering and Enhancement Solutions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695527"
                        ],
                        "name": "T. Gevers",
                        "slug": "T.-Gevers",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Gevers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gevers"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 46
                            }
                        ],
                        "text": "For more information, the reader may refer to [15,17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Gevers [15] concluded that a uniform colored surface which is curved returns different intensity values to the camera."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 941604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "030d1f0a8ca5997f230173a215b67f0e44d26186",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Color-in-Image-Databases-Gevers",
            "title": {
                "fragments": [],
                "text": "Color in Image Databases"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 13,
            "methodology": 16
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 30,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Color-text-extraction-with-selective-metric-based-Mancas-Thillou-Gosselin/0aaca7527d703a6945ba73ce15e7e7353258fc8a?sort=total-citations"
}