{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110287333"
                        ],
                        "name": "Ching-Wen Chen",
                        "slug": "Ching-Wen-Chen",
                        "structuredName": {
                            "firstName": "Ching-Wen",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ching-Wen Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793389"
                        ],
                        "name": "Chung-Lin Huang",
                        "slug": "Chung-Lin-Huang",
                        "structuredName": {
                            "firstName": "Chung-Lin",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung-Lin Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 228
                            }
                        ],
                        "text": "There have been several feature geometry approaches, beginning with the seminal work of Kanade[21], and including Kaya and Kobayashi[22], Craw and Cameron[13], Wong, Law, and Tsang[41], Brunelli and Poggio[7], and Chen and Huang[10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 222
                            }
                        ],
                        "text": "In one parameterized model approach, deformable template models of individual facial features are t to the image by minimizing an energy functional (Yuille, Hallinan, and Cohen[43], Hallinan[18], Shackleton and Welsh[34], Huang and Chen[20])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 360,
                                "start": 355
                            }
                        ],
                        "text": "Examples include autocorrelation (Kurita, Otsu and Sato[25]), Singular Value Decomposition (Cheng, et al.[11] and Hong[19]), and vector quantization (Ramsay, et al.[31])\nConnectionist approaches to face recognition also use pictorial representations for faces (Kohonen[24], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun[15], Weng, Ahuja, and Huang[40], Fuchs and Haken[17], Stonham[36])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 19798622,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a4080cac9ff36593d9b2c491f8f6f1c029b215c",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a face recognition system which can identify the unknown identity effectively using the front-view facial features. In front-view facial feature extractions, we can capture the contours of eyes and mouth by the deformable template model because of their analytically describable shapes. However, the shapes of eyebrows, nostrils and face are difficult to model using a deformable template. We extract them by using the active contour model (snake). After the contours of all facial features have been captured, we calculate effective feature values from these extracted contours and construct databases for unknown identities classification. In the database generation phase, 12 models are photographed, and feature vectors are calculated for each portrait. In the identification phase if any one of these 12 persons has his picture taken again, the system can recognize his identity."
            },
            "slug": "Human-Face-Recognition-from-A-Single-Front-View-Chen-Huang",
            "title": {
                "fragments": [],
                "text": "Human Face Recognition from A Single Front View"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A face recognition system which can identify the unknown identity effectively using the front-view facial features and calculate effective feature values from these extracted contours and construct databases for unknown identities classification."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 122
                            }
                        ],
                        "text": "Principal components analysis has been explored as a means for both recognizing and reconstructing face images (Kirby and Sirovich[23], Turk and Pentland[38],\nAkamatsu, et al.[1], Craw and Cameron[13], Dalla Serra and Brunelli[33])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "[9] report a 96% recognition rate on a library of 50, and Turk and Pentland[38] report a 96% recognition rate when their system, which uses a library of only 16 people, is tested under varying lighting conditions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "Principal components analysis has been explored as a means for both recognizing and reconstructing face images (Kirby and Sirovich[23], Turk and Pentland[38], Akamatsu, et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 72
                            }
                        ],
                        "text": "Cannon, et al.[9] report a 96% recognition rate on a library of 50, and Turk and Pentland[38] report a 96% recognition rate when their system, which uses a library of only 16 people, is tested under varying lighting conditions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "As mentioned in the introduction, template-based face recognizers have been quite successful on frontal views of the face (Baron[3], Turk and Pentland[38], Brunelli and Poggio[7])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": true,
            "numCitedBy": 14955,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36427051"
                        ],
                        "name": "Peter W. Hallinan",
                        "slug": "Peter-W.-Hallinan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hallinan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter W. Hallinan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 190
                            }
                        ],
                        "text": "In one parameterized model approach, deformable template models of individual facial features are t to the image by minimizing an energy functional (Yuille, Hallinan, and Cohen[43], Hallinan[18], Shackleton and Welsh[34], Huang and Chen[20])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 121453877,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fa0f72bef8474a76c3f4e67e00f2784ff0f9b20",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Steps are taken toward the automatic, intensity-based recognition of human faces by constructing a vision system to automatically detect frontally-viewed human eyes in real data. The eye is modeled using a deformable template that specifies a parameterized geometry and an intensity model. The fit of the template is measured by a cost-functional employing robust estimators, i.e., (alpha) -trimmed means and variances, to overcome highlights, shadows, nonrigid boundaries, noise, and other such difficulties. Recognition proceeds in three stages. First, candidate eyes are located by matching a simplified eye model against the responses of a robust, general purpose detector of intensity valleys and peaks. Second, the best fit of each candidate eye is found by minimizing the energy of a cost functional. Third, each candidate is accepted or rejected based on the amount of variance in the image data it explains."
            },
            "slug": "Recognizing-human-eyes-Hallinan",
            "title": {
                "fragments": [],
                "text": "Recognizing human eyes"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "Steps are taken toward the automatic, intensity-based recognition of human faces by constructing a vision system to automatically detect frontally-viewed human eyes in real data using a deformable template using a parameterized geometry and an intensity model."
            },
            "venue": {
                "fragments": [],
                "text": "Optics & Photonics"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331213"
                        ],
                        "name": "S. Edelman",
                        "slug": "S.-Edelman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Edelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Edelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2037776"
                        ],
                        "name": "D. Reisfeld",
                        "slug": "D.-Reisfeld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Reisfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Reisfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47620675"
                        ],
                        "name": "Y. Yeshurun",
                        "slug": "Y.-Yeshurun",
                        "structuredName": {
                            "firstName": "Yehezkel",
                            "lastName": "Yeshurun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yeshurun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 34105594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7382437ce90d46a19cb4c07defdddacac07b52c6",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an implemented system that learns to recognize human faces under varying pose and illumination conditions. The system relies on symmetry operations to detect the eyes and the mouth in a face image, uses the locations of these features to normalize the appearance of the face, performs simple but effective dimensionality reduction by a convolution with a set of Gaussian receptive fields, and subjects the vector of activities of the receptive fields to a Radial Basis Function interpolating classifier. The performance of the system compares favorably with the state of the art in machine recognition of faces."
            },
            "slug": "Learning-to-Recognize-Faces-from-Examples-Edelman-Reisfeld",
            "title": {
                "fragments": [],
                "text": "Learning to Recognize Faces from Examples"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An implemented system that learns to recognize human faces under varying pose and illumination conditions that relies on symmetry operations to detect the eyes and the mouth in a face image, and performs simple but effective dimensionality reduction by a convolution."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98283779"
                        ],
                        "name": "Y. Kaya",
                        "slug": "Y.-Kaya",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Kaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Kaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107806977"
                        ],
                        "name": "K. Kobayashi",
                        "slug": "K.-Kobayashi",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Kobayashi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kobayashi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 132
                            }
                        ],
                        "text": "There have been several feature geometry approaches, beginning with the seminal work of Kanade[21], and including Kaya and Kobayashi[22], Craw and Cameron[13], Wong, Law, and Tsang[41], Brunelli and Poggio[7], and Chen and Huang[10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 140862871,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "5f6dbef77693ffa0785af3ddcfa1ce50db340a70",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-BASIC-STUDY-ON-HUMAN-FACE-RECOGNITION-Kaya-Kobayashi",
            "title": {
                "fragments": [],
                "text": "A BASIC STUDY ON HUMAN FACE RECOGNITION"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "There are exceptions, however, as some systems have employed multiple views ([1], [25]) and exible matching strategies ([27], [26]) to deal with some degree of expression and out-of-plane rotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "While there is no consensus on the su cient size of the model database, some of the more recent approaches ([25], [6], [27]) have used libraries on the order of 70 people or more."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "[26] and Manjunath, Chellappa, and von der Malsburg[27] represent faces as elastic graphs of local textural features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 242
                            }
                        ],
                        "text": "Instead, the features are de ned by the local grey level structure of the image, such as corners (Azarbayejani, et al. [2]), symmetry (Reisfeld and Yeshurun[32]), or the \\end-inhibition\" features of Manjunath, Shekhar, Chellappa, and von der Malsburg[28], which are extracted from a wavelet decomposition of the image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 83
                            }
                        ],
                        "text": "In another hybrid approach, Lades et al.[26] and Manjunath, Chellappa, and von der Malsburg[27] represent faces as elastic graphs of local textural features."
                    },
                    "intents": []
                }
            ],
            "corpusId": 46325945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a735c80fd1a467d82efb3960faf88a522f690be2",
            "isKey": true,
            "numCitedBy": 393,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A feature-based approach to face recognition in which the features are derived from the intensity data without assuming any knowledge of the face structure is presented. The feature extraction model is biologically motivated, and the locations of the features often correspond to salient facial features such as the eyes, nose, etc. Topological graphs are used to represent relations between features, and a simple deterministic graph-matching scheme that exploits the basic structure is used to recognize familiar faces from a database. Each of the stages in the system can be fully implemented in parallel to achieve real-time recognition. Experimental results for a 128*128 image with very little noise are evaluated.<<ETX>>"
            },
            "slug": "A-feature-based-approach-to-face-recognition-Manjunath-Chellappa",
            "title": {
                "fragments": [],
                "text": "A feature based approach to face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A feature-based approach to face recognition in which the features are derived from the intensity data without assuming any knowledge of the face structure is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121478544"
                        ],
                        "name": "M. Shackleton",
                        "slug": "M.-Shackleton",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Shackleton",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shackleton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50748720"
                        ],
                        "name": "W. Welsh",
                        "slug": "W.-Welsh",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Welsh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Welsh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 216
                            }
                        ],
                        "text": "In one parameterized model approach, deformable template models of individual facial features are t to the image by minimizing an energy functional (Yuille, Hallinan, and Cohen[43], Hallinan[18], Shackleton and Welsh[34], Huang and Chen[20])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11500685,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a78236ff0815f2ccbc465f7fb23a7d827a670906",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A facial feature classification technique that independently captures both the geometric configuration and the image detail of a particular feature is described. The geometric configuration is first extracted by fitting a deformable template to the shape of the feature (for example, an eye) in the image. This information is then used to geometrically normalize the image in such a way that the feature in the image attains a standard shape. The normalized image of the facial feature is then classified in terms of a set of principal components previously obtained from a representative set of training images of similar features. This classification stage yields a representation vector which can be used for recognition matching of the feature in terms of image detail alone without the complication of changes in facial expression. Implementation of the system is described and results are given for its application to a set of test faces. These results show that features can be reliably recognized using the representation vectors obtained.<<ETX>>"
            },
            "slug": "Classification-of-facial-features-for-recognition-Shackleton-Welsh",
            "title": {
                "fragments": [],
                "text": "Classification of facial features for recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A facial feature classification technique that independently captures both the geometric configuration and the image detail of a particular feature is described and results show that features can be reliably recognized using the representation vectors obtained."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086700338"
                        ],
                        "name": "J. M. Gilbert",
                        "slug": "J.-M.-Gilbert",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Gilbert",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. M. Gilbert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157814340"
                        ],
                        "name": "W. Yang",
                        "slug": "W.-Yang",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6551109,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62f46db7bf0ad47c8c06f5196596ac7518e13e61",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A real-time face recognition system has been implemented on an IBM compatible personal computer with a video camera, image digitizer, and custom VLSI image correlator chip. With a single frontal facial image under semicontrolled lighting conditions, the system performs (i) image preprocessing and template extraction, (ii) template correlation with a database of 173 images, and (iii) postprocessing of correlation results to identify the user. System performance issues including image preprocessing, face recognition algorithm, software development, and VLSI hardware implementation are addressed. In particular, the parallel, fully pipelined VLSI image correlator is able to perform 340 Mop/second and achieve a speed up of 20 over optimized assembly code on a 80486/66DX2. The complete system is able to identify a user from a database of 173 images of 34 persons in approximately two to three seconds. While the recognition performance of the system is difficult to quantify simply, the system achieves a very conservative 88% recognition rate using cross-validation on the moderately varied database."
            },
            "slug": "A-real-time-face-recognition-system-using-custom-Gilbert-Yang",
            "title": {
                "fragments": [],
                "text": "A real-time face recognition system using custom VLSI hardware"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A real-time face recognition system has been implemented on an IBM compatible personal computer with a video camera, image digitizer, and custom VLSI image correlator chip that achieves a very conservative 88% recognition rate using cross-validation on the moderately varied database."
            },
            "venue": {
                "fragments": [],
                "text": "1993 Computer Architectures for Machine Perception"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8259585"
                        ],
                        "name": "Yong-Qing Cheng",
                        "slug": "Yong-Qing-Cheng",
                        "structuredName": {
                            "firstName": "Yong-Qing",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong-Qing Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48087772"
                        ],
                        "name": "Ke Liu",
                        "slug": "Ke-Liu",
                        "structuredName": {
                            "firstName": "Ke",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ke Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47988123"
                        ],
                        "name": "Jingyu Yang",
                        "slug": "Jingyu-Yang",
                        "structuredName": {
                            "firstName": "Jingyu",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingyu Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144232065"
                        ],
                        "name": "Huan Wang",
                        "slug": "Huan-Wang",
                        "structuredName": {
                            "firstName": "Huan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huan Wang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "Examples include autocorrelation (Kurita, Otsu and Sato[25]), Singular Value Decomposition (Cheng, et al.[11] and Hong[19]), and vector quantization (Ramsay, et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118334007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed2ed1deff9ccf0c9c720a67c8da51a339744ac4",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The feature image and projective image are first proposed to describe the human face, and a new method for human face recognition in which projective images are used for classification is presented. The projective coordinates of projective image on feature images are used as the feature vectors which represent the inherent attributes of human faces. Finally, the feature extraction method of human face images is derived and a hierarchical distance classifier for human face recognition is constructed. The experiments have shown that the recognition method based on the coordinate feature vector is a powerful method for recognizing human face images, and recognition accuracies of 100 percent are obtained for all 64 facial images in eight classes of human faces.<<ETX>>"
            },
            "slug": "A-robust-algebraic-method-for-human-face-Cheng-Liu",
            "title": {
                "fragments": [],
                "text": "A robust algebraic method for human face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The experiments have shown that the recognition method based on the coordinate feature vector is a powerful method for recognizing human face images, and recognition accuracies of 100 percent are obtained for all 64 facial images in eight classes of human faces."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47246616"
                        ],
                        "name": "R. Brunelli",
                        "slug": "R.-Brunelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Brunelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brunelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 28
                            }
                        ],
                        "text": "Brunelli and Poggio's system[7] achieved a recognition rate of 100% on frontal views of 47 people."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 232
                            }
                        ],
                        "text": "In template-based systems, the simplest pictorial representation, faces are represented either by images of the whole face or by subimages of the major facial features such as the eyes, nose, and mouth (Baron[3], Brunelli and Poggio[7], Yang and Gilbert[42], Burt[8], Bichsel[6])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 117
                            }
                        ],
                        "text": "This representation may be templates of the major facial features (Bichsel[6], Baron[3], Burt[8], Poggio and Brunelli[7]) or the weights of hidden layer nodes in neural networks (Vincent, Waite and Myers[39])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "Building on successful template-based systems (especially Brunelli and Poggio[7]), our basic approach is to represent faces with templates from multiple model views that cover di erent poses from the viewing sphere."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 156
                            }
                        ],
                        "text": "As mentioned in the introduction, template-based face recognizers have been quite successful on frontal views of the face (Baron[3], Turk and Pentland[38], Brunelli and Poggio[7])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 215
                            }
                        ],
                        "text": "4 Face recognition using multiple views As mentioned in the introduction, template-based face recognizers have been quite successful on frontal views of the face (Baron[3], Turk and Pentland[38], Brunelli and Poggio[7])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 205
                            }
                        ],
                        "text": "There have been several feature geometry approaches, beginning with the seminal work of Kanade[21], and including Kaya and Kobayashi[22], Craw and Cameron[13], Wong, Law, and Tsang[41], Brunelli and Poggio[7], and Chen and Huang[10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16859093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "239beb3861ceceb4c7c7f229234d97198d5c7697",
            "isKey": true,
            "numCitedBy": 2828,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching, are presented. The results obtained for the testing sets show about 90% correct recognition using geometrical features and perfect recognition using template matching. >"
            },
            "slug": "Face-Recognition:-Features-Versus-Templates-Brunelli-Poggio",
            "title": {
                "fragments": [],
                "text": "Face Recognition: Features Versus Templates"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058909458"
                        ],
                        "name": "M. Fleming",
                        "slug": "M.-Fleming",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Fleming",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fleming"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48524582"
                        ],
                        "name": "G. Cottrell",
                        "slug": "G.-Cottrell",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Cottrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cottrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "Di erent pixel-based representations have been used, with [24], [16], [17] using the original grey level images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "[31]) Connectionist approaches to face recognition also use pictorial representations for faces (Kohonen[24], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun[15], Weng, Ahuja, and Huang[40], Fuchs and Haken[17], Stonham[36])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 274
                            }
                        ],
                        "text": "Examples include autocorrelation (Kurita, Otsu and Sato[25]), Singular Value Decomposition (Cheng, et al.[11] and Hong[19]), and vector quantization (Ramsay, et al.[31])\nConnectionist approaches to face recognition also use pictorial representations for faces (Kohonen[24], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun[15], Weng, Ahuja, and Huang[40], Fuchs and Haken[17], Stonham[36])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10008013,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09c96918f4e6bb4b00e4fd2608f934f9577528b4",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The proposal of G. Cottrell et al. (1987) that their image compression network might be used to extract image features for pattern recognition automatically, is tested by training a neural network to compress 64 face images, spanning 11 subjects, and 13 nonface images. Features extracted in this manner (the output of the hidden units) are given as input to a one-layer network trained to distinguish faces from nonfaces and to attach a name and sex to the face images. The network successfully recognizes new images of familiar faces, categorizes novel images as to their `faceness' and, to a great extent, gender, and exhibits continued accuracy over a considerable range of partial or shifted input"
            },
            "slug": "Categorization-of-faces-using-unsupervised-feature-Fleming-Cottrell",
            "title": {
                "fragments": [],
                "text": "Categorization of faces using unsupervised feature extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The proposal of G. Cottrell et al. (1987) that their image compression network might be used to extract image features for pattern recognition automatically, is tested by training a neural network to compress 64 face images, spanning 11 subjects, and 13 nonface images."
            },
            "venue": {
                "fragments": [],
                "text": "1990 IJCNN International Joint Conference on Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144986880"
                        ],
                        "name": "I. Craw",
                        "slug": "I.-Craw",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Craw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Craw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066105510"
                        ],
                        "name": "Peter Cameron",
                        "slug": "Peter-Cameron",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Cameron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Cameron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 154
                            }
                        ],
                        "text": "There have been several feature geometry approaches, beginning with the seminal work of Kanade[21], and including Kaya and Kobayashi[22], Craw and Cameron[13], Wong, Law, and Tsang[41], Brunelli and Poggio[7], and Chen and Huang[10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 180
                            }
                        ],
                        "text": "Principal components analysis has been explored as a means for both recognizing and reconstructing face images (Kirby and Sirovich[23], Turk and Pentland[38],\nAkamatsu, et al.[1], Craw and Cameron[13], Dalla Serra and Brunelli[33])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "[1], Craw and Cameron[13], Dalla Serra and Brunelli[33])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8657476,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c66dcbbfbe7414ae9fcd769fc72fd2c2123f471d",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a coding scheme to index face images for subsequent retrieval, which seems effective, under some conditions, at coding the faces themselves, rather than particular face images, and uses typically 100 bytes. We report tests searching a pool of 100 faces, using as cue a different image of a face in the pool, taken 10 years later. In two of three tests with different faces, the target face best matches the corresponding cue."
            },
            "slug": "Face-Recognition-by-Computer-Craw-Cameron",
            "title": {
                "fragments": [],
                "text": "Face Recognition by Computer"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A coding scheme to index face images for subsequent retrieval seems effective, under some conditions, at coding the faces themselves, rather than particular face images, and uses typically 100 bytes."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13728253"
                        ],
                        "name": "C. Shekhar",
                        "slug": "C.-Shekhar",
                        "structuredName": {
                            "firstName": "Chandra",
                            "lastName": "Shekhar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Shekhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69416958"
                        ],
                        "name": "Ramalingam Chellappa",
                        "slug": "Ramalingam-Chellappa",
                        "structuredName": {
                            "firstName": "Ramalingam",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ramalingam Chellappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "[2]), symmetry (Reisfeld and Yeshurun[32]), or the \\end-inhibition\" features of Manjunath, Shekhar, Chellappa, and von der Malsburg[28], which are extracted from a wavelet decomposition of the image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 242
                            }
                        ],
                        "text": "Instead, the features are de ned by the local grey level structure of the image, such as corners (Azarbayejani, et al. [2]), symmetry (Reisfeld and Yeshurun[32]), or the \\end-inhibition\" features of Manjunath, Shekhar, Chellappa, and von der Malsburg[28], which are extracted from a wavelet decomposition of the image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 83
                            }
                        ],
                        "text": "In another hybrid approach, Lades et al.[26] and Manjunath, Chellappa, and von der Malsburg[27] represent faces as elastic graphs of local textural features."
                    },
                    "intents": []
                }
            ],
            "corpusId": 62007863,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8faa7d5ad6a64c029705eb722369a673113db65a",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present an approach to feature detection, which is a fundamental issue in many intermediate-level vision problems such as stereo, motion correspondence, image registration, etc. The approach is based on a scale-interaction model of the end-inhibition property exhibited by certain cells in the visual- cortex of mammals. These feature detector cells are responsive to short lines, line endings, corners and other such sharp changes in curvature. In addition, this method also provides a compact representation of feature information which is useful in shape recognition problems. Application to face recognition and motion correspondence are illustrated.<<ETX>>"
            },
            "slug": "A-robust-method-for-detecting-image-features-with-Manjunath-Shekhar",
            "title": {
                "fragments": [],
                "text": "A robust method for detecting image features with application to face recognition and motion correspondence"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "The authors present an approach to feature detection, which is a fundamental issue in many intermediate-level vision problems such as stereo, motion correspondence, image registration, etc, based on a scale-interaction model of the end-inhibition property exhibited by certain cells in the visual- cortex of mammals."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3206744"
                        ],
                        "name": "Zi-Quan Hong",
                        "slug": "Zi-Quan-Hong",
                        "structuredName": {
                            "firstName": "Zi-Quan",
                            "lastName": "Hong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zi-Quan Hong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "[11] and Hong[19]), and vector quantization (Ramsay, et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "Examples include autocorrelation (Kurita, Otsu and Sato[25]), Singular Value Decomposition (Cheng, et al.[11] and Hong[19]), and vector quantization (Ramsay, et al.[31])\nConnectionist approaches to face recognition also use pictorial representations for faces (Kohonen[24], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun[15], Weng, Ahuja, and Huang[40], Fuchs and Haken[17], Stonham[36])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 27187290,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26d172f0a4d7e903ce388f3159059f9c5463e5c5",
            "isKey": false,
            "numCitedBy": 324,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algebraic-feature-extraction-of-image-for-Hong",
            "title": {
                "fragments": [],
                "text": "Algebraic feature extraction of image for recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35146156"
                        ],
                        "name": "M. Lades",
                        "slug": "M.-Lades",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Lades",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3189439"
                        ],
                        "name": "J. Vorbr\u00fcggen",
                        "slug": "J.-Vorbr\u00fcggen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Vorbr\u00fcggen",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vorbr\u00fcggen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075388397"
                        ],
                        "name": "J. Lange",
                        "slug": "J.-Lange",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Lange",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lange"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038814"
                        ],
                        "name": "R. W\u00fcrtz",
                        "slug": "R.-W\u00fcrtz",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "W\u00fcrtz",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. W\u00fcrtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34993891"
                        ],
                        "name": "W. Konen",
                        "slug": "W.-Konen",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Konen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Konen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "There are exceptions, however, as some systems have employed multiple views ([1], [25]) and exible matching strategies ([27], [26]) to deal with some degree of expression and out-of-plane rotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "In another hybrid approach, Lades et al.[26] and Manjunath, Chellappa, and von der Malsburg[27] represent faces as elastic graphs of local textural features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1266405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fb52984078d75ec5655962dc94dc7848182286b",
            "isKey": false,
            "numCitedBy": 2072,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented. The dynamic link architecture exploits correlations in the fine-scale temporal structure of cellular signals to group neurons dynamically into higher-order entities. These entities represent a rich structure and can code for high-level objects. To demonstrate the capabilities of the dynamic link architecture, a program was implemented that can recognize human faces and other objects from video images. Memorized objects are represented by sparse graphs, whose vertices are labeled by a multiresolution description in terms of a local power spectrum, and whose edges are labeled by geometrical distance vectors. Object recognition can be formulated as elastic graph matching, which is performed here by stochastic optimization of a matching cost function. The implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images. The performance of the program is evaluated by a statistical analysis of recognition results from a portrait gallery comprising images of 87 persons. >"
            },
            "slug": "Distortion-Invariant-Object-Recognition-in-the-Link-Lades-Vorbr\u00fcggen",
            "title": {
                "fragments": [],
                "text": "Distortion Invariant Object Recognition in the Dynamic Link Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented and the implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Computers"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793389"
                        ],
                        "name": "Chung-Lin Huang",
                        "slug": "Chung-Lin-Huang",
                        "structuredName": {
                            "firstName": "Chung-Lin",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung-Lin Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110287333"
                        ],
                        "name": "Ching-Wen Chen",
                        "slug": "Ching-Wen-Chen",
                        "structuredName": {
                            "firstName": "Ching-Wen",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ching-Wen Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 214
                            }
                        ],
                        "text": "There have been several feature geometry approaches, beginning with the seminal work of Kanade[21], and including Kaya and Kobayashi[22], Craw and Cameron[13], Wong, Law, and Tsang[41], Brunelli and Poggio[7], and Chen and Huang[10]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 236
                            }
                        ],
                        "text": "In one parameterized model approach, deformable template models of individual facial features are t to the image by minimizing an energy functional (Yuille, Hallinan, and Cohen[43], Hallinan[18], Shackleton and Welsh[34], Huang and Chen[20])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "Examples include autocorrelation (Kurita, Otsu and Sato[25]), Singular Value Decomposition (Cheng, et al.[11] and Hong[19]), and vector quantization (Ramsay, et al.[31])\nConnectionist approaches to face recognition also use pictorial representations for faces (Kohonen[24], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun[15], Weng, Ahuja, and Huang[40], Fuchs and Haken[17], Stonham[36])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 20479780,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7be6e3d9f410c9ea1d72b51a7897b9063fc8623",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents facial features extraction algorithms which can be used for automated visual interpretation and recognition of human faces. It is possible to capture the contours of eye and mouth by deformable template model because of their analytically describable shapes. However, the shapes of eyebrow, nostril and face are difficult to model using a deformable template. They are extracted by using an active contour model, the snake.<<ETX>>"
            },
            "slug": "Human-facial-feature-extraction-for-face-and-Huang-Chen",
            "title": {
                "fragments": [],
                "text": "Human facial feature extraction for face interpretation and recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "Facial features extraction algorithms which can be used for automated visual interpretation and recognition of human faces and shapes of eyebrow, nostril and face are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49052113"
                        ],
                        "name": "S. Akamatsu",
                        "slug": "S.-Akamatsu",
                        "structuredName": {
                            "firstName": "Shigeru",
                            "lastName": "Akamatsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Akamatsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110791903"
                        ],
                        "name": "Tsutomu Sasaki",
                        "slug": "Tsutomu-Sasaki",
                        "structuredName": {
                            "firstName": "Tsutomu",
                            "lastName": "Sasaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsutomu Sasaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143906699"
                        ],
                        "name": "H. Fukamachi",
                        "slug": "H.-Fukamachi",
                        "structuredName": {
                            "firstName": "Hideo",
                            "lastName": "Fukamachi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Fukamachi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49721559"
                        ],
                        "name": "Nobuhiko Masui",
                        "slug": "Nobuhiko-Masui",
                        "structuredName": {
                            "firstName": "Nobuhiko",
                            "lastName": "Masui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nobuhiko Masui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34857543"
                        ],
                        "name": "Y. Suenaga",
                        "slug": "Y.-Suenaga",
                        "structuredName": {
                            "firstName": "Yasuhito",
                            "lastName": "Suenaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Suenaga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61857749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f762055c98ad8fb93719471302c41d468fed0369",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Proposes a scheme that offers accurate and robust identification of human faces. The scheme is characterized by four aspects: facial feature detection using color image segmentation; target image extraction using a sub-space classification method; robust feature extraction based on K-L expansion of an invariant feature space; and face classifier training based on 3D CG modeling of the human face. The scheme's flexibility under a wide range of image acquisition conditions has been confirmed through the assessment of an experimental face identification system.<<ETX>>"
            },
            "slug": "An-accurate-and-robust-face-identification-scheme-Akamatsu-Sasaki",
            "title": {
                "fragments": [],
                "text": "An accurate and robust face identification scheme"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "The proposed scheme is characterized by four aspects: facial feature detection using color image segmentation; target image extraction using a sub-space classification method; robust feature extraction based on K-L expansion of an invariant feature space; and face classifier training based on 3D CG modeling of the human face."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145926447"
                        ],
                        "name": "J. Weng",
                        "slug": "J.-Weng",
                        "structuredName": {
                            "firstName": "Juyang",
                            "lastName": "Weng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 222
                            }
                        ],
                        "text": "In one parameterized model approach, deformable template models of individual facial features are t to the image by minimizing an energy functional (Yuille, Hallinan, and Cohen[43], Hallinan[18], Shackleton and Welsh[34], Huang and Chen[20])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[40] uses directional edge maps, [36] uses a thresholded binary image, and [15] uses Gaussian units applied to the grey level image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 360,
                                "start": 324
                            }
                        ],
                        "text": "Examples include autocorrelation (Kurita, Otsu and Sato[25]), Singular Value Decomposition (Cheng, et al.[11] and Hong[19]), and vector quantization (Ramsay, et al.[31])\nConnectionist approaches to face recognition also use pictorial representations for faces (Kohonen[24], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun[15], Weng, Ahuja, and Huang[40], Fuchs and Haken[17], Stonham[36])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 196
                            }
                        ],
                        "text": "[31]) Connectionist approaches to face recognition also use pictorial representations for faces (Kohonen[24], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun[15], Weng, Ahuja, and Huang[40], Fuchs and Haken[17], Stonham[36])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 223
                            }
                        ],
                        "text": "There have been several feature geometry approaches, beginning with the seminal work of Kanade[21], and including Kaya and Kobayashi[22], Craw and Cameron[13], Wong, Law, and Tsang[41], Brunelli and Poggio[7], and Chen and Huang[10]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8619176,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86b516616f11ce76ce12eef2b51a4cfa8b9c538c",
            "isKey": true,
            "numCitedBy": 110,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A framework called Cresceptron is introduced for automatic algorithm design through learning of concepts and rules, thus deviating from the traditional mode in which humans specify the rules constituting a vision algorithm. With the Cresceptron, humans as designers need only to provide a good structure for learning, but they are relieved of most design details. The Cresceptron has been tested on the task of visual recognition by recognizing 3-D general objects from 2-D photographic images of natural scenes and segmenting the recognized objects from the cluttered image background. The Cresceptron uses a hierarchical structure to grow networks automatically, adaptively, and incrementally through learning. The Cresceptron makes it possible to generalize training exemplars to other perceptually equivalent items. Experiments with a variety of real-world images are reported to demonstrate the feasibility of learning in the Cresceptron.<<ETX>>"
            },
            "slug": "Learning-recognition-and-segmentation-of-3-D-from-Weng-Ahuja",
            "title": {
                "fragments": [],
                "text": "Learning recognition and segmentation of 3-D objects from 2-D images"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The Cresceptron uses a hierarchical structure to grow networks automatically, adaptively, and incrementally through learning, and makes it possible to generalize training exemplars to other perceptually equivalent items."
            },
            "venue": {
                "fragments": [],
                "text": "1993 (4th) International Conference on Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2160942"
                        ],
                        "name": "R. Baron",
                        "slug": "R.-Baron",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Baron",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Baron"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 208
                            }
                        ],
                        "text": "In template-based systems, the simplest pictorial representation, faces are represented either by images of the whole face or by subimages of the major facial features such as the eyes, nose, and mouth (Baron[3], Brunelli and Poggio[7], Yang and Gilbert[42], Burt[8], Bichsel[6])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "For example, Baron[3] reached an impressive 100% recognition rate on a library of 42 people and a false access rate of 0% on 108 images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 84
                            }
                        ],
                        "text": "This representation may be templates of the major facial features (Bichsel[6], Baron[3], Burt[8], Poggio and Brunelli[7]) or the weights of hidden layer nodes in neural networks (Vincent, Waite and Myers[39])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 128
                            }
                        ],
                        "text": "As mentioned in the introduction, template-based face recognizers have been quite successful on frontal views of the face (Baron[3], Turk and Pentland[38], Brunelli and Poggio[7])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29658209,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "0fb4d98ac0a2f3c6f058ec4b2c25835ee8a24fcc",
            "isKey": true,
            "numCitedBy": 226,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Mechanisms-of-Human-Facial-Recognition-Baron",
            "title": {
                "fragments": [],
                "text": "Mechanisms of Human Facial Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Man Mach. Stud."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3893740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82962da5c273a9e6627a040d56c8a7973fe22440",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In this note we discuss how recognition can be achieved from a single 2D model view exploiting prior knowledge of an object''s structure (e.g. symmetry). We prove that for any bilaterally symmetric 3D object one non- accidental 2D model view is sufficient for recognition. Symmetries of higher order allow the recovery of structure from one 2D view. Linear transformations can be learned exactly from a small set of examples in the case of \"linear object classes\" and used to produce new views of an object from a single view."
            },
            "slug": "Recognition-and-Structure-from-one-2D-Model-View:-Poggio-Vetter",
            "title": {
                "fragments": [],
                "text": "Recognition and Structure from one 2D Model View: Observations on Prototypes, Object Classes and Symmetries"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is proved that for any bilaterally symmetric 3D object one non- accidental 2D model view is sufficient for recognition and linear transformations can be learned exactly from a small set of examples in the case of \"linear object classes\"."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2037776"
                        ],
                        "name": "D. Reisfeld",
                        "slug": "D.-Reisfeld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Reisfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Reisfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47620675"
                        ],
                        "name": "Y. Yeshurun",
                        "slug": "Y.-Yeshurun",
                        "structuredName": {
                            "firstName": "Yehezkel",
                            "lastName": "Yeshurun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yeshurun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "[2]), symmetry (Reisfeld and Yeshurun[32]), or the \\end-inhibition\" features of Manjunath, Shekhar, Chellappa, and von der Malsburg[28], which are extracted from a wavelet decomposition of the image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 148
                            }
                        ],
                        "text": "Instead, the features are de ned by the local grey level structure of the image, such as corners (Azarbayejani, et al. [2]), symmetry (Reisfeld and Yeshurun[32]), or the \\end-inhibition\" features of Manjunath, Shekhar, Chellappa, and von der Malsburg[28], which are extracted from a wavelet decomposition of the image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 332,
                                "start": 324
                            }
                        ],
                        "text": "Examples include autocorrelation (Kurita, Otsu and Sato[25]), Singular Value Decomposition (Cheng, et al.[11] and Hong[19]), and vector quantization (Ramsay, et al.[31])\nConnectionist approaches to face recognition also use pictorial representations for faces (Kohonen[24], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun[15], Weng, Ahuja, and Huang[40], Fuchs and Haken[17], Stonham[36])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 62756592,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2118c6e85f68a08c3bfe08aa05006c5db0564ca8",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Locating facial features is crucial for various face recognition schemes. The authors suggest a robust facial feature detector based on a generalized symmetry interest operator. No special tuning is required if the face occupies 15-60% of the image. The operator was tested on a large face data base with a success rate of over 95%.<<ETX>>"
            },
            "slug": "Robust-detection-of-facial-features-by-generalized-Reisfeld-Yeshurun",
            "title": {
                "fragments": [],
                "text": "Robust detection of facial features by generalized symmetry"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A robust facial feature detector based on a generalized symmetry interest operator that was tested on a large face data base with a success rate of over 95%."
            },
            "venue": {
                "fragments": [],
                "text": "[1992] Proceedings. 11th IAPR International Conference on Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 204
                            }
                        ],
                        "text": "Given this dense set of correspondences, the a ne transformed input can be brought into pixel-level correspondence with the model by applying a 2D warp operation driven by the optical ow (also see Shashua[35])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 21
                            }
                        ],
                        "text": "Thanks also to Amnon Shashua for our many discussions and for his suggestion that I use optical ow in the geometrical alignment step."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15785342,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6726e2264c3a35c6a4b4da88520706665005835a",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents a simple model for recovering affine shape and correspondence from two orthographic views of a 3D object. It is shown that four corresponding points along two orthographic views, taken under similar illumination conditions, determine affine shape and correspondence for all other points. The scheme is useful for purposes of visual recognition by generating novel views of an object given two model views. It is also shown that the scheme can handle objects with smooth boundaries, to a good approximation, without introducing any modifications or additional model views."
            },
            "slug": "Correspondence-and-Affine-Shape-from-Two-Views:-and-Shashua",
            "title": {
                "fragments": [],
                "text": "Correspondence and Affine Shape from Two Orthographic Views: Motion and Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "It is shown that four corresponding points along two orthographic views, taken under similar illumination conditions, determine affine shape and correspondence for all other points and the scheme is useful for purposes of visual recognition by generating novel views of an object given two model views."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144986880"
                        ],
                        "name": "I. Craw",
                        "slug": "I.-Craw",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Craw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Craw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3263505"
                        ],
                        "name": "D. Tock",
                        "slug": "D.-Tock",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Tock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056963263"
                        ],
                        "name": "Alan Bennett",
                        "slug": "Alan-Bennett",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Bennett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alan Bennett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 110
                            }
                        ],
                        "text": "A related model-based approach ts a global head model constructed from tens of feature locations (Bennett and Craw[4], Craw, Tock, and Bennett[14], Cootes, et al.[12]) to the image by varying individual feature locations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "A related model-based approach ts a global head model constructed from tens of feature locations (Bennett and Craw[4], Craw, Tock, and Bennett[14], Cootes, et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17481367,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2e6bc4db498566a9f95f122970fb4488eaf3392",
            "isKey": false,
            "numCitedBy": 332,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a computer program which understands a greyscale image of a face well enough to locate individual face features such as eyes and mouth. The program has two distinct components: modules designed to locate particular face features, usually in a restricted area; and the overall control strategy which activates modules on the basis of the current solution state, and assesses and integrates the results of each module."
            },
            "slug": "Finding-Face-Features-Craw-Tock",
            "title": {
                "fragments": [],
                "text": "Finding Face Features"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A computer program which understands a greyscale image of a face well enough to locate individual face features such as eyes and mouth is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145375983"
                        ],
                        "name": "T. Kurita",
                        "slug": "T.-Kurita",
                        "structuredName": {
                            "firstName": "Takio",
                            "lastName": "Kurita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kurita"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809629"
                        ],
                        "name": "N. Otsu",
                        "slug": "N.-Otsu",
                        "structuredName": {
                            "firstName": "Nobuyuki",
                            "lastName": "Otsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Otsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157807492"
                        ],
                        "name": "T. Sato",
                        "slug": "T.-Sato",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Sato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sato"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "Examples include autocorrelation (Kurita, Otsu and Sato[25]), Singular Value Decomposition (Cheng, et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "[1]) or autocorrelation (Kurita, Otsu and Sato[25])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 42
                            }
                        ],
                        "text": "Examples include autocorrelation (Kurita, Otsu and Sato[25]), Singular Value Decomposition (Cheng, et al.[11] and Hong[19]), and vector quantization (Ramsay, et al.[31])\nConnectionist approaches to face recognition also use pictorial representations for faces (Kohonen[24], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun[15], Weng, Ahuja, and Huang[40], Fuchs and Haken[17], Stonham[36])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "There are exceptions, however, as some systems have employed multiple views ([1], [25]) and exible matching strategies ([27], [26]) to deal with some degree of expression and out-of-plane rotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "While there is no consensus on the su cient size of the model database, some of the more recent approaches ([25], [6], [27]) have used libraries on the order of 70 people or more."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 148
                            }
                        ],
                        "text": "To provide shift invariance, some systems preprocess images using the Fourier transform magnitude (Akamatsu, et al.[1]) or autocorrelation (Kurita, Otsu and Sato[25])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16863319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f8b451125a704d348b47ba32017c1c078c7c0b2",
            "isKey": true,
            "numCitedBy": 140,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Proposes a face recognition method which is characterized by structural simplicity, trainability and high speed. The method consists of two stages of feature extractions: first, higher order local autocorrelation features which are shift-invariant and additive are extracted from an input image; then those features are linearly combined on the basis of multivariate analysis methods so as to provide new effective features for face recognition in learning from examples.<<ETX>>"
            },
            "slug": "A-face-recognition-method-using-higher-order-local-Kurita-Otsu",
            "title": {
                "fragments": [],
                "text": "A face recognition method using higher order local autocorrelation and multivariate analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This paper proposes a face recognition method which is characterized by structural simplicity, trainability and high speed, and linearly combined on the basis of multivariate analysis methods to provide new effective features for face recognition in learning from examples."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564802"
                        ],
                        "name": "T. Stonham",
                        "slug": "T.-Stonham",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Stonham",
                            "middleNames": [
                                "John"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Stonham"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "[40] uses directional edge maps, [36] uses a thresholded binary image, and [15] uses Gaussian units applied to the grey level image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 230
                            }
                        ],
                        "text": "[31]) Connectionist approaches to face recognition also use pictorial representations for faces (Kohonen[24], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun[15], Weng, Ahuja, and Huang[40], Fuchs and Haken[17], Stonham[36])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 394,
                                "start": 355
                            }
                        ],
                        "text": "Examples include autocorrelation (Kurita, Otsu and Sato[25]), Singular Value Decomposition (Cheng, et al.[11] and Hong[19]), and vector quantization (Ramsay, et al.[31])\nConnectionist approaches to face recognition also use pictorial representations for faces (Kohonen[24], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun[15], Weng, Ahuja, and Huang[40], Fuchs and Haken[17], Stonham[36])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 57422487,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "406200622d3a470e07b67bec7c8c93b8521003ed",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "WISARD (Wilkie, Aleksander, and Stonham\u2019s Recognition Device) is a general purpose pattern recognition machine with a special semi-parallel structure unlike that of conventional single instruction single data computers. The machine is self-adapting. It does not require programming where an explict set of rules, defining the operations to be performed on the data, have to be supplied. The behaviour of the system is established by a learning process whereby a representative set of patterns from the class of data to be recognised, is input to the machine. A wide range of pattern recognition problems can be solved with this approach, they include industrial inspection, speech recognition, medical pattern recognition and artificial vision."
            },
            "slug": "Practical-Face-Recognition-and-Verification-with-Stonham",
            "title": {
                "fragments": [],
                "text": "Practical Face Recognition and Verification with Wisard"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A wide range of pattern recognition problems can be solved with this approach, they include industrial inspection, speech recognition, medical pattern recognition and artificial vision."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302358"
                        ],
                        "name": "P. Burt",
                        "slug": "P.-Burt",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Burt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Burt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62620841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "047758b902fcbd0df055f930426bd0edadfb5216",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Important new techniques for representing and analyzing image data at multiple resolutions have been developed over the past several years. Closely related multiresolution structures and procedures have been developed more or less independently in diverse scientific fields. For example, pyramid and subband representations have been applied to image compression, and promise excellent performance and flexibility. Similar pyramid structures have been developed as models for the neural coding of images within the human visual system. The pyramid has been developed in the computer vision field as a general framework for implementing highly efficient algorithms, including algorithms for motion analysis and object recognition. In this paper I review these multiresolution techniques and discuss how they may be usefully combined in the future. Methods used in image compression, for example, should match the requirements of human perception, and future 'smart' transmission systems will need to perform rapid analysis in order to selectively encode the most critical information in a scene."
            },
            "slug": "Multiresolution-Techniques-For-Image-Analysis,-And-Burt",
            "title": {
                "fragments": [],
                "text": "Multiresolution Techniques For Image Representation, Analysis, And 'Smart' Transmission"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper reviews these multiresolution techniques and discusses how they may be usefully combined in the future to match the requirements of human perception."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750924"
                        ],
                        "name": "Demetri Terzopoulos",
                        "slug": "Demetri-Terzopoulos",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Terzopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Demetri Terzopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398261"
                        ],
                        "name": "K. Waters",
                        "slug": "K.-Waters",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Waters",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Waters"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "Terzopoulos and Waters [37] have used the active contour model of snakes to track facial features in image sequences."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46283468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d0a6188890f378e4d18f4580cdb7a1801b17200",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel approach is presented to the analysis of dynamic facial images. The approach exploits a realistic model of the human face. The face model, which may be simulated and rendered at interactive rates on a graphics workstation, incorporates a physically-based approximation to facial tissue and a set of anatomically-motivated facial muscle actuators. The authors consider the estimation of dynamic facial muscle contractions from video sequences of expressive human faces. They develop an estimation technique that uses deformable contour models to track the nonrigid motions of facial features in images. The technique computes robust muscle actuator controls, enabling the face model to resynthesize transient expressions accurately.<<ETX>>"
            },
            "slug": "Analysis-of-facial-images-using-physical-and-models-Terzopoulos-Waters",
            "title": {
                "fragments": [],
                "text": "Analysis of facial images using physical and anatomical models"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The authors consider the estimation of dynamic facial muscle contractions from video sequences of expressive human faces and develop an estimation technique that uses deformable contour models to track the nonrigid motions of facial features in images."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153789765"
                        ],
                        "name": "C. S. Ramsay",
                        "slug": "C.-S.-Ramsay",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Ramsay",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. S. Ramsay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3469976"
                        ],
                        "name": "K. Sutherland",
                        "slug": "K.-Sutherland",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Sutherland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sutherland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144373796"
                        ],
                        "name": "D. Renshaw",
                        "slug": "D.-Renshaw",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Renshaw",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Renshaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49766078"
                        ],
                        "name": "P. Denyer",
                        "slug": "P.-Denyer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Denyer",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Denyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "[11] and Hong[19]), and vector quantization (Ramsay, et al.[31]) Connectionist approaches to face recognition also use pictorial representations for faces (Kohonen[24], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun[15], Weng, Ahuja, and Huang[40], Fuchs and Haken[17], Stonham[36])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6295814,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdff1f5d0d4e12058f4e0615f575f261eefdd4dd",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic facial recognition is an attractive solution to the problem of computerised personal identification. In order to facilitate a cost effective solution, high levels of data reduction are required when storing the facial information. Vector Quantization has previously been used as a data reduction technique for the encoding of facial images."
            },
            "slug": "A-Comparison-of-Vector-Quantization-Codebook-to-Ramsay-Sutherland",
            "title": {
                "fragments": [],
                "text": "A Comparison of Vector Quantization Codebook Generation Algorithms Applied to Automatic Face Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Vector Quantization has previously been used as a data reduction technique for the encoding of facial images for automatic facial recognition."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056963263"
                        ],
                        "name": "Alan Bennett",
                        "slug": "Alan-Bennett",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Bennett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alan Bennett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144986880"
                        ],
                        "name": "I. Craw",
                        "slug": "I.-Craw",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Craw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Craw"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 138
                            }
                        ],
                        "text": "There have been several feature geometry approaches, beginning with the seminal work of Kanade[21], and including Kaya and Kobayashi[22], Craw and Cameron[13], Wong, Law, and Tsang[41], Brunelli and Poggio[7], and Chen and Huang[10]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 180
                            }
                        ],
                        "text": "Principal components analysis has been explored as a means for both recognizing and reconstructing face images (Kirby and Sirovich[23], Turk and Pentland[38],\nAkamatsu, et al.[1], Craw and Cameron[13], Dalla Serra and Brunelli[33])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "A related model-based approach ts a global head model constructed from tens of feature locations (Bennett and Craw[4], Craw, Tock, and Bennett[14], Cootes, et al.[12]) to the image by varying individual feature locations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 114
                            }
                        ],
                        "text": "A related model-based approach ts a global head model constructed from tens of feature locations (Bennett and Craw[4], Craw, Tock, and Bennett[14], Cootes, et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10762508,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d806730418d4f7866be4915b52a6179a12134bda",
            "isKey": true,
            "numCitedBy": 19,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Much work in image processing has been devoted to generating filters to detect low level image features, e.g. edges, peaks, valleys. Objects are then located or recognised in the image by using the output from these filters."
            },
            "slug": "Finding-Image-Features-Using-Deformable-Templates-Bennett-Craw",
            "title": {
                "fragments": [],
                "text": "Finding Image Features Using Deformable Templates and Detailed Prior Statistical Knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This chapter discusses filters used to detect low level image features, e.g. edges, peaks, valleys, which are then located or recognised in the image by using the output from these filters."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053520352"
                        ],
                        "name": "M. Kirby",
                        "slug": "M.-Kirby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kirby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kirby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49555086"
                        ],
                        "name": "L. Sirovich",
                        "slug": "L.-Sirovich",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Sirovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sirovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 223
                            }
                        ],
                        "text": "Pictorial approaches, representing faces by using ltered images of model faces, include template-based systems ([2], [6], [13], [7], and [5]), systems using principal components analysis to derive a pictorial \\face space\" ([15], [20], [1], [9]), and connectionist approaches ([16], [11], [10], [21], and [12])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 570648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66d75a5fe9e1b6511c5135d68e9ce8c0da5a7374",
            "isKey": false,
            "numCitedBy": 2853,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion. This results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix, without increasing the complexity of the calculation. The resulting approximation of faces projected from outside of the data set onto this optimal basis is improved on average. >"
            },
            "slug": "Application-of-the-Karhunen-Loeve-Procedure-for-the-Kirby-Sirovich",
            "title": {
                "fragments": [],
                "text": "Application of the Karhunen-Loeve Procedure for the Characterization of Human Faces"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion, which results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807633"
                        ],
                        "name": "A. Fuchs",
                        "slug": "A.-Fuchs",
                        "structuredName": {
                            "firstName": "Armin",
                            "lastName": "Fuchs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fuchs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2625886"
                        ],
                        "name": "H. Haken",
                        "slug": "H.-Haken",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Haken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Haken"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7565076,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "8dd183acc59483760b36e510df4aa9aa1ad8c2e1",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider a model for associative memory and pattern recognition which was devised by Haken (1987b). This model treats the activity of the neurons as continuous variables and exploits an analogy with pattern formation in synergetic systems. The capability of such a system to act as associative memory is demonstrated by the reconstruction of faces which are partially offered to the system, and which are restored by the corresponding dynamical process. We demonstrate how this model can be cast into a form which is translation invariant and how partially hidden faces in scenes can be recognized by means of the control of attention parameters of specific patterns."
            },
            "slug": "Pattern-recognition-and-associative-memory-as-in-a-Fuchs-Haken",
            "title": {
                "fragments": [],
                "text": "Pattern recognition and associative memory as dynamical processes in a synergetic system. I. Translational invariance, selective attention, and decomposition of scenes."
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "It is demonstrated how this model for associative memory and pattern recognition can be cast into a form which is translation invariant and how partially hidden faces in scenes can be recognized by means of the control of attention parameters of specific patterns."
            },
            "venue": {
                "fragments": [],
                "text": "Biological cybernetics"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830709"
                        ],
                        "name": "A. Lanitis",
                        "slug": "A.-Lanitis",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lanitis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lanitis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32250556"
                        ],
                        "name": "D. H. Cooper",
                        "slug": "D.-H.-Cooper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cooper",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. H. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47581828"
                        ],
                        "name": "J. Graham",
                        "slug": "J.-Graham",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Graham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Graham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 162
                            }
                        ],
                        "text": "A related model-based approach ts a global head model constructed from tens of feature locations (Bennett and Craw[4], Craw, Tock, and Bennett[14], Cootes, et al.[12]) to the image by varying individual feature locations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 36445761,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a041199f33d69a949d9bd889068187ffe4140cc7",
            "isKey": false,
            "numCitedBy": 113,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors describe a technique for building compact models of the shape and appearance of flexible objects seen in 2-D images. The models are derived from the statistics of sets of labeled images of example objects. Each model consists of a flexible shape template, describing how important points of the object can vary, and a statistical model of the expected grey levels in regions around each model point. Such models have proved useful in a wide variety of applications. A description is given on how the models can be used in local image search, and examples of their application are included.<<ETX>>"
            },
            "slug": "Building-and-using-flexible-models-incorporating-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Building and using flexible models incorporating grey-level information"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A technique for building compact models of the shape and appearance of flexible objects seen in 2-D images derived from the statistics of sets of labeled images of example objects, which have proved useful in a wide variety of applications."
            },
            "venue": {
                "fragments": [],
                "text": "1993 (4th) International Conference on Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145271456"
                        ],
                        "name": "A. Azarbayejani",
                        "slug": "A.-Azarbayejani",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Azarbayejani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Azarbayejani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738894"
                        ],
                        "name": "T. Starner",
                        "slug": "T.-Starner",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Starner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Starner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144152544"
                        ],
                        "name": "B. Horowitz",
                        "slug": "B.-Horowitz",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Horowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[2]), symmetry (Reisfeld and Yeshurun[32]), or the \\end-inhibition\" features of Manjunath, Shekhar, Chellappa, and von der Malsburg[28], which are extracted from a wavelet decomposition of the image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10074380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7bfa4190f8e4b746855adf8da214d5fdad8ede2",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Interactive graphics systems that are driven by visual input are discussed. The underlying computer vision techniques and a theoretical formulation that addresses issues of accuracy, computational efficiency, and compensation for display latency are presented. Experimental results quantitatively compare the accuracy of the visual technique with traditional sensing. An extension to the basic technique to include structure recovery is discussed. >"
            },
            "slug": "Visually-Controlled-Graphics-Azarbayejani-Starner",
            "title": {
                "fragments": [],
                "text": "Visually Controlled Graphics"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "Interactive graphics systems that are driven by visual input and an extension to the basic technique to include structure recovery is discussed, quantitatively comparing the accuracy of the visual technique with traditional sensing."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "Di erent pixel-based representations have been used, with [24], [16], [17] using the original grey level images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "[31]) Connectionist approaches to face recognition also use pictorial representations for faces (Kohonen[24], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun[15], Weng, Ahuja, and Huang[40], Fuchs and Haken[17], Stonham[36])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 222292199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10055eb6f2f711a36d9aa8f759d3b3f01ebddb5d",
            "isKey": false,
            "numCitedBy": 6561,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Various Aspects of Memory.- 1.1 On the Purpose and Nature of Biological Memory.- 1.1.1 Some Fundamental Concepts.- 1.1.2 The Classical Laws of Association.- 1.1.3 On Different Levels of Modelling.- 1.2 Questions Concerning the Fundamental Mechanisms of Memory.- 1.2.1 Where Do the Signals Relating to Memory Act Upon?.- 1.2.2 What Kind of Encoding is Used for Neural Signals?.- 1.2.3 What are the Variable Memory Elements?.- 1.2.4 How are Neural Signals Addressed in Memory?.- 1.3 Elementary Operations Implemented by Associative Memory.- 1.3.1 Associative Recall.- 1.3.2 Production of Sequences from the Associative Memory.- 1.3.3 On the Meaning of Background and Context.- 1.4 More Abstract Aspects of Memory.- 1.4.1 The Problem of Infinite-State Memory.- 1.4.2 Invariant Representations.- 1.4.3 Symbolic Representations.- 1.4.4 Virtual Images.- 1.4.5 The Logic of Stored Knowledge.- 2. Pattern Mathematics.- 2.1 Mathematical Notations and Methods.- 2.1.1 Vector Space Concepts.- 2.1.2 Matrix Notations.- 2.1.3 Further Properties of Matrices.- 2.1.4 Matrix Equations.- 2.1.5 Projection Operators.- 2.1.6 On Matrix Differential Calculus.- 2.2 Distance Measures for Patterns.- 2.2.1 Measures of Similarity and Distance in Vector Spaces.- 2.2.2 Measures of Similarity and Distance Between Symbol Strings.- 2.2.3 More Accurate Distance Measures for Text.- 3. Classical Learning Systems.- 3.1 The Adaptive Linear Element (Adaline).- 3.1.1 Description of Adaptation by the Stochastic Approximation.- 3.2 The Perceptron.- 3.3 The Learning Matrix.- 3.4 Physical Realization of Adaptive Weights.- 3.4.1 Perceptron and Adaline.- 3.4.2 Classical Conditioning.- 3.4.3 Conjunction Learning Switches.- 3.4.4 Digital Representation of Adaptive Circuits.- 3.4.5 Biological Components.- 4. A New Approach to Adaptive Filters.- 4.1 Survey of Some Necessary Functions.- 4.2 On the \"Transfer Function\" of the Neuron.- 4.3 Models for Basic Adaptive Units.- 4.3.1 On the Linearization of the Basic Unit.- 4.3.2 Various Cases of Adaptation Laws.- 4.3.3 Two Limit Theorems.- 4.3.4 The Novelty Detector.- 4.4 Adaptive Feedback Networks.- 4.4.1 The Autocorrelation Matrix Memory.- 4.4.2 The Novelty Filter.- 5. Self-Organizing Feature Maps.- 5.1 On the Feature Maps of the Brain.- 5.2 Formation of Localized Responses by Lateral Feedback.- 5.3 Computational Simplification of the Process.- 5.3.1 Definition of the Topology-Preserving Mapping.- 5.3.2 A Simple Two-Dimensional Self-Organizing System.- 5.4 Demonstrations of Simple Topology-Preserving Mappings.- 5.4.1 Images of Various Distributions of Input Vectors.- 5.4.2 \"The Magic TV\".- 5.4.3 Mapping by a Feeler Mechanism.- 5.5 Tonotopic Map.- 5.6 Formation of Hierarchical Representations.- 5.6.1 Taxonomy Example.- 5.6.2 Phoneme Map.- 5.7 Mathematical Treatment of Self-Organization.- 5.7.1 Ordering of Weights.- 5.7.2 Convergence Phase.- 5.8 Automatic Selection of Feature Dimensions.- 6. Optimal Associative Mappings.- 6.1 Transfer Function of an Associative Network.- 6.2 Autoassociative Recall as an Orthogonal Projection.- 6.2.1 Orthogonal Projections.- 6.2.2 Error-Correcting Properties of Projections.- 6.3 The Novelty Filter.- 6.3.1 Two Examples of Novelty Filter.- 6.3.2 Novelty Filter as an Autoassociative Memory.- 6.4 Autoassociative Encoding.- 6.4.1 An Example of Autoassociative Encoding.- 6.5 Optimal Associative Mappings.- 6.5.1 The Optimal Linear Associative Mapping.- 6.5.2 Optimal Nonlinear Associative Mappings.- 6.6 Relationship Between Associative Mapping, Linear Regression, and Linear Estimation.- 6.6.1 Relationship of the Associative Mapping to Linear Regression.- 6.6.2 Relationship of the Regression Solution to the Linear Estimator.- 6.7 Recursive Computation of the Optimal Associative Mapping.- 6.7.1 Linear Corrective Algorithms.- 6.7.2 Best Exact Solution (Gradient Projection).- 6.7.3 Best Approximate Solution (Regression).- 6.7.4 Recursive Solution in the General Case.- 6.8 Special Cases.- 6.8.1 The Correlation Matrix Memory.- 6.8.2 Relationship Between Conditional Averages and Optimal Estimator.- 7. Pattern Recognition.- 7.1 Discriminant Functions.- 7.2 Statistical Formulation of Pattern Classification.- 7.3 Comparison Methods.- 7.4 The Subspace Methods of Classification.- 7.4.1 The Basic Subspace Method.- 7.4.2 The Learning Subspace Method (LSM).- 7.5 Learning Vector Quantization.- 7.6 Feature Extraction.- 7.7 Clustering.- 7.7.1 Simple Clustering (Optimization Approach).- 7.7.2 Hierarchical Clustering (Taxonomy Approach).- 7.8 Structural Pattern Recognition Methods.- 8. More About Biological Memory.- 8.1 Physiological Foundations of Memory.- 8.1.1 On the Mechanisms of Memory in Biological Systems.- 8.1.2 Structural Features of Some Neural Networks.- 8.1.3 Functional Features of Neurons.- 8.1.4 Modelling of the Synaptic Plasticity.- 8.1.5 Can the Memory Capacity Ensue from Synaptic Changes?.- 8.2 The Unified Cortical Memory Model.- 8.2.1 The Laminar Network Organization.- 8.2.2 On the Roles of Interneurons.- 8.2.3 Representation of Knowledge Over Memory Fields.- 8.2.4 Self-Controlled Operation of Memory.- 8.3 Collateral Reading.- 8.3.1 Physiological Results Relevant to Modelling.- 8.3.2 Related Modelling.- 9. Notes on Neural Computing.- 9.1 First Theoretical Views of Neural Networks.- 9.2 Motives for the Neural Computing Research.- 9.3 What Could the Purpose of the Neural Networks be?.- 9.4 Definitions of Artificial \"Neural Computing\" and General Notes on Neural Modelling.- 9.5 Are the Biological Neural Functions Localized or Distributed?.- 9.6 Is Nonlinearity Essential to Neural Computing?.- 9.7 Characteristic Differences Between Neural and Digital Computers.- 9.7.1 The Degree of Parallelism of the Neural Networks is Still Higher than that of any \"Massively Parallel\" Digital Computer.- 9.7.2 Why the Neural Signals Cannot be Approximated by Boolean Variables.- 9.7.3 The Neural Circuits do not Implement Finite Automata.- 9.7.4 Undue Views of the Logic Equivalence of the Brain and Computers on a High Level.- 9.8 \"Connectionist Models\".- 9.9 How can the Neural Computers be Programmed?.- 10. Optical Associative Memories.- 10.1 Nonholographic Methods.- 10.2 General Aspects of Holographic Memories.- 10.3 A Simple Principle of Holographic Associative Memory.- 10.4 Addressing in Holographic Memories.- 10.5 Recent Advances of Optical Associative Memories.- Bibliography on Pattern Recognition.- References."
            },
            "slug": "Self-Organization-and-Associative-Memory-Kohonen",
            "title": {
                "fragments": [],
                "text": "Self-Organization and Associative Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The purpose and nature of Biological Memory, as well as some of the aspects of Memory Aspects, are explained."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 194
                            }
                        ],
                        "text": "The key to making this work will be an example-based learning system that uses multiple images of prototype faces undergoing changes in pose to \\learn\" what it means to rotate a face (see Poggio[29], Poggio and Vetter[30])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 13
                            }
                        ],
                        "text": "Brunelli and Poggio's system[7] achieved a recognition rate of 100% on frontal views of 47 people."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 226
                            }
                        ],
                        "text": "In template-based systems, the simplest pictorial representation, faces are represented either by images of the whole face or by subimages of the major facial features such as the eyes, nose, and mouth (Baron[3], Brunelli and Poggio[7], Yang and Gilbert[42], Burt[8], Bichsel[6])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 98
                            }
                        ],
                        "text": "This representation may be templates of the major facial features (Bichsel[6], Baron[3], Burt[8], Poggio and Brunelli[7]) or the weights of hidden layer nodes in neural networks (Vincent, Waite and Myers[39])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 169
                            }
                        ],
                        "text": "As mentioned in the introduction, template-based face recognizers have been quite successful on frontal views of the face (Baron[3], Turk and Pentland[38], Brunelli and Poggio[7])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 41
                            }
                        ],
                        "text": "I would like to thank my advisor, Tomaso Poggio, for his support and encouragement to use the template-based approach."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 199
                            }
                        ],
                        "text": "There have been several feature geometry approaches, beginning with the seminal work of Kanade[21], and including Kaya and Kobayashi[22], Craw and Cameron[13], Wong, Law, and Tsang[41], Brunelli and Poggio[7], and Chen and Huang[10]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3D object recognition and prototypes: one 2D view may be su cient"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report 9107{02,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 175
                            }
                        ],
                        "text": "Principal components analysis has been explored as a means for both recognizing and reconstructing face images (Kirby and Sirovich[23], Turk and Pentland[38], Akamatsu, et al.[1], Craw and Cameron[13], Dalla Serra and Brunelli[33])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 115
                            }
                        ],
                        "text": "To provide shift invariance, some systems preprocess images using the Fourier transform magnitude (Akamatsu, et al.[1]) or autocorrelation (Kurita, Otsu and Sato[25])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "There are exceptions, however, as some systems have employed multiple views ([1], [25]) and exible matching strategies ([27], [26]) to deal with some degree of expression and out-of-plane rotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 145
                            }
                        ],
                        "text": "Principal components analysis has been explored as a means for both recognizing and reconstructing face images (Kirby and Sirovich[23], Turk and Pentland[38],\nAkamatsu, et al.[1], Craw and Cameron[13], Dalla Serra and Brunelli[33])."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An  accurate and robust face identi cation scheme"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Int. Conf. on Pattern Recognition,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "There are exceptions, however, as some systems have employed multiple views ([1], [25]) and exible matching strategies ([27], [26]) to deal with some degree of expression and out-of-plane rotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "While there is no consensus on the su cient size of the model database, some of the more recent approaches ([25], [6], [27]) have used libraries on the order of 70 people or more."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "[26] and Manjunath, Chellappa, and von der Malsburg[27] represent faces as elastic graphs of local textural features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 242
                            }
                        ],
                        "text": "Instead, the features are de ned by the local grey level structure of the image, such as corners (Azarbayejani, et al. [2]), symmetry (Reisfeld and Yeshurun[32]), or the \\end-inhibition\" features of Manjunath, Shekhar, Chellappa, and von der Malsburg[28], which are extracted from a wavelet decomposition of the image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 83
                            }
                        ],
                        "text": "In another hybrid approach, Lades et al.[26] and Manjunath, Chellappa, and von der Malsburg[27] represent faces as elastic graphs of local textural features."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A feature based approach to face recog-  nition"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings IEEE Conf. on Computer Vi-  sion and Pattern Recognition,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 189
                            }
                        ],
                        "text": "Principal components analysis has been explored as a means for both recognizing and reconstructing face images (Kirby and Sirovich[23], Turk and Pentland[38],\nAkamatsu, et al.[1], Craw and Cameron[13], Dalla Serra and Brunelli[33])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "Brunelli and Poggio's system[7] achieved a recognition rate of 100% on frontal views of 47 people."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 213
                            }
                        ],
                        "text": "In template-based systems, the simplest pictorial representation, faces are represented either by images of the whole face or by subimages of the major facial features such as the eyes, nose, and mouth (Baron[3], Brunelli and Poggio[7], Yang and Gilbert[42], Burt[8], Bichsel[6])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 109
                            }
                        ],
                        "text": "This representation may be templates of the major facial features (Bichsel[6], Baron[3], Burt[8], Poggio and Brunelli[7]) or the weights of hidden layer nodes in neural networks (Vincent, Waite and Myers[39])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 156
                            }
                        ],
                        "text": "As mentioned in the introduction, template-based face recognizers have been quite successful on frontal views of the face (Baron[3], Turk and Pentland[38], Brunelli and Poggio[7])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "[1], Craw and Cameron[13], Dalla Serra and Brunelli[33])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 127
                            }
                        ],
                        "text": "Preprocessing with the gradient magnitude performs nearly as well, a result in agreement with the preprocessing experiments of Brunelli and Pogggio[7]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 186
                            }
                        ],
                        "text": "There have been several feature geometry approaches, beginning with the seminal work of Kanade[21], and including Kaya and Kobayashi[22], Craw and Cameron[13], Wong, Law, and Tsang[41], Brunelli and Poggio[7], and Chen and Huang[10]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the use of the Karhunen-Loeve expansion for face recognition"
            },
            "venue": {
                "fragments": [],
                "text": "I.R.S.T"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1893129"
                        ],
                        "name": "M. Bichsel",
                        "slug": "M.-Bichsel",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Bichsel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bichsel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 275
                            }
                        ],
                        "text": "In template-based systems, the simplest pictorial representation, faces are represented either by images of the whole face or by subimages of the major facial features such as the eyes, nose, and mouth (Baron[3], Brunelli and Poggio[7], Yang and Gilbert[42], Burt[8], Bichsel[6])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "This representation may be templates of the major facial features (Bichsel[6], Baron[3], Burt[8], Poggio and Brunelli[7]) or the weights of hidden layer nodes in neural networks (Vincent, Waite and Myers[39])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 114
                            }
                        ],
                        "text": "While there is no consensus on the su cient size of the model database, some of the more recent approaches ([25], [6], [27]) have used libraries on the order of 70 people or more."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 142804056,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9373c1a890f9d4d1847d602d6e14df00e1bd0115",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Strategies-of-robust-object-recognition-for-the-of-Bichsel",
            "title": {
                "fragments": [],
                "text": "Strategies of robust object recognition for the automatic identification of human faces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Beymer . Face recognition under varying pose"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 263
                            }
                        ],
                        "text": "In template-based systems, the simplest pictorial representation, faces are represented either by images of the whole face or by subimages of the major facial features such as the eyes, nose, and mouth (Baron[3], Brunelli and Poggio[7], Yang and Gilbert[42], Burt[8], Bichsel[6])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 93
                            }
                        ],
                        "text": "This representation may be templates of the major facial features (Bichsel[6], Baron[3], Burt[8], Poggio and Brunelli[7]) or the weights of hidden layer nodes in neural networks (Vincent, Waite and Myers[39])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multiresolution techniques for im-  age representation, analysis, and 'smart' transmis-  sion"
            },
            "venue": {
                "fragments": [],
                "text": "In SPIE"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 180
                            }
                        ],
                        "text": "There have been several feature geometry approaches, beginning with the seminal work of Kanade[21], and including Kaya and Kobayashi[22], Craw and Cameron[13], Wong, Law, and Tsang[41], Brunelli and Poggio[7], and Chen and Huang[10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A system for recognizing human faces"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the International Conference o n A coustics, Speech, and Signal Processing"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Human face recognition from a single front view Jing-Yu Yang, and Hua- Feng Wang. A robust algebraic method for human face recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Int. Conf. on Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 203
                            }
                        ],
                        "text": "This representation may be templates of the major facial features (Bichsel[6], Baron[3], Burt[8], Poggio and Brunelli[7]) or the weights of hidden layer nodes in neural networks (Vincent, Waite and Myers[39])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Location of feature points in images using neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "BT Technology Journal"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3D object recognition and prototypes: one 2D view may be suucient"
            },
            "venue": {
                "fragments": [],
                "text": "I.R.S.T"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "There are exceptions, however, as some systems have used multiple views ([1], [17]) and exible matching strategies [18] to handle some degree of expression and out-of-plane rotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[18] explores an interesting hybrid representation that combines the geometrical and pictorial approaches, representing faces as elastic graphs of local textural features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A fea-  ture based approach to face recognition"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings IEEE  Conf. on Computer Vision and Pattern Recognition,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "can be provided by using the Fourier transform magnitude [1] or autocorrelation [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "There are exceptions, however, as some systems have used multiple views ([1], [17]) and exible matching strategies [18] to handle some degree of expression and out-of-plane rotations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 235
                            }
                        ],
                        "text": "Pictorial approaches, representing faces by using ltered images of model faces, include template-based systems ([2], [6], [13], [7], and [5]), systems using principal components analysis to derive a pictorial \\face space\" ([15], [20], [1], [9]), and connectionist approaches ([16], [11], [10], [21], and [12])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An accurate and robust face iden-  ti cation scheme"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings Int. Conf. on Pattern Recog-  nition,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "There have been several feature geometry approaches, beginning with the seminal work of Kanade[21], and including Kaya and Kobayashi[22], Craw and Cameron[13], Wong, Law, and Tsang[41], Brunelli and Poggio[7], and Chen and Huang[10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "While the earliest work in automatic face recognition dates back two decades (Kanade[21]), the topic has seen renewed interest in the last few years."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Picture processing by computer complex and recognition of human faces"
            },
            "venue": {
                "fragments": [],
                "text": "Picture processing by computer complex and recognition of human faces"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "Di erent pixel-based representations have been used, with [24], [16], [17] using the original grey level images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "[31]) Connectionist approaches to face recognition also use pictorial representations for faces (Kohonen[24], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun[15], Weng, Ahuja, and Huang[40], Fuchs and Haken[17], Stonham[36])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 274
                            }
                        ],
                        "text": "Examples include autocorrelation (Kurita, Otsu and Sato[25]), Singular Value Decomposition (Cheng, et al.[11] and Hong[19]), and vector quantization (Ramsay, et al.[31])\nConnectionist approaches to face recognition also use pictorial representations for faces (Kohonen[24], Fleming and Cottrell [16], Edelman, Reisfeld, and Yeshurun[15], Weng, Ahuja, and Huang[40], Fuchs and Haken[17], Stonham[36])."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cat-  egorization of faces using unsupervised feature ex-  traction"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the International Joint  Conference on Neural Networks,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An accurate and robust face identiication scheme"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Int. Conf. on Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 118
                            }
                        ],
                        "text": "A dense set of pixelwise correspondence between the a ne transformed input and the model is computed using optical ow [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 146
                            }
                        ],
                        "text": "First, the optical ow is measured between the input features and the template using the hierarchical gradient-based scheme of Bergen and Hingorani[5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical motionbased frame rate conversion"
            },
            "venue": {
                "fragments": [],
                "text": "Hierarchical motionbased frame rate conversion"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face recognition under varying pose. A.I. Memo No"
            },
            "venue": {
                "fragments": [],
                "text": "Face recognition under varying pose. A.I. Memo No"
            },
            "year": 1461
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 94
                            }
                        ],
                        "text": "Space limitations in these proceedings prevent a more detailed presentation; for details, see [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 120
                            }
                        ],
                        "text": "Since our current implementation of the pose estimator can only distinguish between looking left and looking right (see [4]), the poses selected by the recognizer for comparison are either the left three columns or right three columns of gure 1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face recognition under varying pose. A.I. Memo  No. 1461"
            },
            "venue": {
                "fragments": [],
                "text": "Arti cial Intelligence Laboratory, Massachusetts Insti-  tute of Technology,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A computer vision system for identiication of individuals"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IECON"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Picture processing by computer complex and recogniton of human faces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "Cannon, et al.[9] report a 96% recognition rate on a library of 50, and Turk and Pentland[38] report a 96% recognition rate when their system, which uses a library of only 16 people, is tested under varying lighting conditions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 118
                            }
                        ],
                        "text": "Hybrid representations that combine the geometrical and pictorial approaches have been explored, such as Cannon et al.[9], whose feature vector face representation includes geometrical and template-based information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A computer vision  system for identi cation of individuals"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc.  IECON,"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gilbert and Woody Yang . A real - time face recognitionsystem using custom VLSI hardware"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Workshop onComputer Architectures for Machine Perception , pages 58 { 66 , December"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 118
                            }
                        ],
                        "text": "A dense set of pixelwise correspondence between the a ne transformed input and the model is computed using optical ow [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 146
                            }
                        ],
                        "text": "First, the optical ow is measured between the input features and the template using the hierarchical gradient-based scheme of Bergen and Hingorani[5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical motion-  based frame rate conversion"
            },
            "venue": {
                "fragments": [],
                "text": "Technical report,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Human face recognition from a single front view Jing-Yu Y ang, and Hua- Feng Wang. A robust algebraic method for human face recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Int. Conf. on Pattern Recognition"
            },
            "year": 1992
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 24,
            "methodology": 30
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 59,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Face-recognition-under-varying-pose-Beymer/9e5949d95c53dd041c721bf40e67b3966805e385?sort=total-citations"
}