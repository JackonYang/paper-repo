{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49247959"
                        ],
                        "name": "Min-Zhi Shao",
                        "slug": "Min-Zhi-Shao",
                        "structuredName": {
                            "firstName": "Min-Zhi",
                            "lastName": "Shao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min-Zhi Shao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1872163"
                        ],
                        "name": "T. Simchony",
                        "slug": "T.-Simchony",
                        "structuredName": {
                            "firstName": "Tal",
                            "lastName": "Simchony",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Simchony"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Shape fr om shading [7] offers another method for monocular depth reconstruction, but is difficult to apply to scenes that do not have fairly uniform color and texture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5095516,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56db421f242551f6ef5ecffb0f0f962d7e03cc0b",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms are developed to recover the depth and orientation maps of a surface from its image intensities. They combine the advantages of stereo vision and shape-from-shading (SFS) methods. These algorithms generate dense surface depth and orientation maps accurately and unambiguously. Previous SFS algorithms can not be directly extended to combine stereo images because the recovery of surface depth and that of orientation are separated in these formulations. A novel SFS algorithm is proposed to couple the generation of the depth and orientation maps. The formulation also ensures that the reconstructed surface depth and its orientation are consistent. The SFS algorithm for a single image is next extended to utilize stereo images. The correspondence over stereo images is established simultaneously with the generation of surface depth and orientation. An alternative approach is also suggested from combining stereo and SFS techniques. The use of embedding techniques to combine sparse depth measurements is discussed.<<ETX>>"
            },
            "slug": "New-algorithms-from-reconstruction-of-a-3-D-depth-Shao-Simchony",
            "title": {
                "fragments": [],
                "text": "New algorithms from reconstruction of a 3-D depth map from one or more images"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A novel SFS algorithm is proposed to couple the generation of the depth and orientation maps of a surface from its image intensities and ensures that the reconstructed surface depth and its orientation are consistent."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70664821"
                        ],
                        "name": "T. Nagai",
                        "slug": "T.-Nagai",
                        "structuredName": {
                            "firstName": "Takayuki",
                            "lastName": "Nagai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Nagai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718652"
                        ],
                        "name": "M. Ikehara",
                        "slug": "M.-Ikehara",
                        "structuredName": {
                            "firstName": "Masaaki",
                            "lastName": "Ikehara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ikehara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704648"
                        ],
                        "name": "A. Kurematsu",
                        "slug": "A.-Kurematsu",
                        "structuredName": {
                            "firstName": "Akira",
                            "lastName": "Kurematsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kurematsu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "Nagai et al. [5] performed surface reconstruction from single images for known, fixed, objects such as hands and faces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34095402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0200679f3219066be7c54a5bd7df17c33f3f2224",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a novel method of the surface reconstruction from a single monocular image is proposed. Our proposed approach (called shape from knowledge) is based on the knowledge of objects, which is acquired by learning from a number of samples. To achieve this, we investigate making use of the hidden Markov model (HMM) framework, which models the correspondence between an intensity image an its depth information. We have applied our algorithm to the 3-D face and 3-D hand reconstruction from single images, and the results show the effectiveness of the proposed method."
            },
            "slug": "HMM-based-surface-reconstruction-from-single-images-Nagai-Ikehara",
            "title": {
                "fragments": [],
                "text": "HMM-based surface reconstruction from single images"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A novel method of the surface reconstruction from a single monocular image is proposed, based on the knowledge of objects, which is acquired by learning from a number of samples, making use of the hidden Markov model (HMM) framework."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. International Conference on Image Processing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145349582"
                        ],
                        "name": "Sanjiv Kumar",
                        "slug": "Sanjiv-Kumar",
                        "structuredName": {
                            "firstName": "Sanjiv",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjiv Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "To model spatial dependencies in images, Kumar and Hebert\u2019s Discriminative Random Fields algorithm [11] uses logistic regression to identify man-made structures in natural imag es."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1282113,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "015293bf7c4cf7ce50a01ce1ceb11f584d123d25",
            "isKey": false,
            "numCitedBy": 257,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present Discriminative Random Fields (DRF), a discriminative framework for the classification of natural image regions by incorporating neighborhood spatial dependencies in the labels as well as the observed data. The proposed model exploits local discriminative models and allows to relax the assumption of conditional independence of the observed data given the labels, commonly used in the Markov Random Field (MRF) framework. The parameters of the DRF model are learned using penalized maximum pseudo-likelihood method. Furthermore, the form of the DRF model allows the MAP inference for binary classification problems using the graph min-cut algorithms. The performance of the model was verified on the synthetic as well as the real-world images. The DRF model outperforms the MRF model in the experiments."
            },
            "slug": "Discriminative-Fields-for-Modeling-Spatial-in-Kumar-Hebert",
            "title": {
                "fragments": [],
                "text": "Discriminative Fields for Modeling Spatial Dependencies in Natural Images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed DRF model exploits local discriminative models and allows to relax the assumption of conditional independence of the observed data given the labels, commonly used in the Markov Random Field (MRF) framework."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 63
                            }
                        ],
                        "text": "E xamples include text segmentation [8], object classification [9], and image labeling [1 0]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 419324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a4300efb6895695205dfc1b74e124f9fea6aff2",
            "isKey": false,
            "numCitedBy": 413,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard approaches to object detection focus on local patches of the image, and try to classify them as background or not. We propose to use the scene context (image as a whole) as an extra source of (global) information, to help resolve local ambiguities. We present a conditional random field for jointly solving the tasks of object detection and scene classification."
            },
            "slug": "Using-the-Forest-to-See-the-Trees:-A-Graphical-and-Murphy-Torralba",
            "title": {
                "fragments": [],
                "text": "Using the Forest to See the Trees: A Graphical Model Relating Features, Objects, and Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a conditional random field for jointly solving the tasks of object detection and scene classification, and proposes to use the scene context as an extra source of (global) information, to help resolve local ambiguities."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47638823"
                        ],
                        "name": "J. Michels",
                        "slug": "J.-Michels",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Michels",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Michels"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681995"
                        ],
                        "name": "Ashutosh Saxena",
                        "slug": "Ashutosh-Saxena",
                        "structuredName": {
                            "firstName": "Ashutosh",
                            "lastName": "Saxena",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashutosh Saxena"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 103
                            }
                        ],
                        "text": "Texture information is mostly contained within the image in tensity channel, 2 so we apply Laws\u2019 masks [15, 4] to this channel to compute the texture ene rgy (Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "In related work, Michels, Saxena & Ng [4] used supervised lea rning to estimate 1-D distances to obstacles, for the application of driving a remote c ntrol car autonomously."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2035627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "421e6c7247f41c419a46212477d7b29540cbf7b1",
            "isKey": false,
            "numCitedBy": 427,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the task of driving a remote control car at high speeds through unstructured outdoor environments. We present an approach in which supervised learning is first used to estimate depths from single monocular images. The learning algorithm can be trained either on real camera images labeled with ground-truth distances to the closest obstacles, or on a training set consisting of synthetic graphics images. The resulting algorithm is able to learn monocular vision cues that accurately estimate the relative depths of obstacles in a scene. Reinforcement learning/policy search is then applied within a simulator that renders synthetic scenes. This learns a control policy that selects a steering direction as a function of the vision system's output. We present results evaluating the predictive ability of the algorithm both on held out test data, and in actual autonomous driving experiments."
            },
            "slug": "High-speed-obstacle-avoidance-using-monocular-and-Michels-Saxena",
            "title": {
                "fragments": [],
                "text": "High speed obstacle avoidance using monocular vision and reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An approach in which supervised learning is first used to estimate depths from single monocular images, which is able to learn monocular vision cues that accurately estimate the relative depths of obstacles in a scene is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33913193"
                        ],
                        "name": "Xuming He",
                        "slug": "Xuming-He",
                        "structuredName": {
                            "firstName": "Xuming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400347470"
                        ],
                        "name": "M. A. Carreira-Perpi\u00f1\u00e1n",
                        "slug": "M.-A.-Carreira-Perpi\u00f1\u00e1n",
                        "structuredName": {
                            "firstName": "Miguel",
                            "lastName": "Carreira-Perpi\u00f1\u00e1n",
                            "middleNames": [
                                "\u00c1."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Carreira-Perpi\u00f1\u00e1n"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "Examples include text segmentation [8], object classification [9], and image labeling [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11859305,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "363b56f85e12389017ba8894056a1b309e46a5f7",
            "isKey": false,
            "numCitedBy": 933,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach to include contextual features for labeling images, in which each pixel is assigned to one of a finite set of labels. The features are incorporated into a probabilistic framework, which combines the outputs of several components. Components differ in the information they encode. Some focus on the image-label mapping, while others focus solely on patterns within the label field. Components also differ in their scale, as some focus on fine-resolution patterns while others on coarser, more global structure. A supervised version of the contrastive divergence algorithm is applied to learn these features from labeled image data. We demonstrate performance on two real-world image databases and compare it to a classifier and a Markov random field."
            },
            "slug": "Multiscale-conditional-random-fields-for-image-He-Zemel",
            "title": {
                "fragments": [],
                "text": "Multiscale conditional random fields for image labeling"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "An approach to include contextual features for labeling images, in which each pixel is assigned to one of a finite set of labels, are incorporated into a probabilistic framework, which combines the outputs of several components."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709053"
                        ],
                        "name": "Daniel Scharstein",
                        "slug": "Daniel-Scharstein",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Scharstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Scharstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "D reconstruction has focused on binocular vision (stereopsis) [1] and on other algorithms that require multiple images, such as structure from motion [2] and depth from defocus [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195859047,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2f78c2b2b325d72f359d4c797c9aab6a8e60942",
            "isKey": false,
            "numCitedBy": 3006,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively little work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods. Our taxonomy is designed to assess the different components and design decisions made in individual stereo algorithms. Using this taxonomy, we compare existing stereo methods and present experiments evaluating the performance of many different variants. In order to establish a common software platform and a collection of data sets for easy evaluation, we have designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can easily be extended to include new algorithms. We have also produced several new multi-frame stereo data sets with ground truth and are making both the code and data sets available on the Web. Finally, we include a comparative evaluation of a large set of today's best-performing stereo algorithms."
            },
            "slug": "A-Taxonomy-and-Evaluation-of-Dense-Two-Frame-Stereo-Scharstein-Szeliski",
            "title": {
                "fragments": [],
                "text": "A taxonomy and evaluation of dense two-frame stereo correspondence algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper has designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can easily be extended to include new algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Workshop on Stereo and Multi-Baseline Vision (SMBV 2001)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803890"
                        ],
                        "name": "G. Gini",
                        "slug": "G.-Gini",
                        "structuredName": {
                            "firstName": "Giuseppina",
                            "lastName": "Gini",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27042479"
                        ],
                        "name": "A. Marchi",
                        "slug": "A.-Marchi",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Marchi",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Marchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "Gini & Marchi [6] used single-camera vision to drive an indoor robot, but relied heavily on known ground colors and textures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5337835,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c0da270b43528ae400beb993e1bbb8aacb3f23a",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In the large area of autonomous robot navigation, encompassing map creation, path planning, and self-localization, we develop the idea of a simple autonomous agent relying only on vision information. Our integrated navigation system replicates some functions of natural systems, as using little a-priori knowledge, on board computation, no omni-directional vision. Since our goal is essentially to move the robot on a floor, avoiding obstacles and people, the camera is on top of the robot and in fixed orientation to look ahead at the floor. After a simplified calibration, floor images are taken and positions of obstacles detected New images dynamically grow a grid map, constructed with simple mathematics and heuristics. For path planning obstacles are enlarged in minimum way, and path computed."
            },
            "slug": "Indoor-Robot-Navigation-With-Single-Camera-Vision-Gini-Marchi",
            "title": {
                "fragments": [],
                "text": "Indoor Robot Navigation With Single Camera Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work develops the idea of a simple autonomous agent relying only on vision information, using little a-priori knowledge, on board computation, no omni-directional vision in the large area of autonomous robot navigation."
            },
            "venue": {
                "fragments": [],
                "text": "PRIS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 150
                            }
                        ],
                        "text": "D reconstruction has focused on binocular vision (stereopsis) [1] and on other algorithms that require multiple images, such as structure from motion [2] and depth from defocus [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 53924538,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "787827850b614135f6b432603afc90b58a8cc665",
            "isKey": false,
            "numCitedBy": 4098,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThe accessible presentation of this book gives both a general view of the entire computer vision enterprise and also offers sufficient detail to be able to build useful applications. Users learn techniques that have proven to be useful by first-hand experience and a wide range of mathematical methods. A CD-ROM with every copy of the text contains source code for programming practice, color images, and illustrative movies. Comprehensive and up-to-date, this book includes essential topics that either reflect practical significance or are of theoretical importance. Topics are discussed in substantial and increasing depth. Application surveys describe numerous important application areas such as image based rendering and digital libraries. Many important algorithms broken down and illustrated in pseudo code. Appropriate for use by engineers as a comprehensive reference to the computer vision enterprise."
            },
            "slug": "Computer-Vision:-A-Modern-Approach-Forsyth-Ponce",
            "title": {
                "fragments": [],
                "text": "Computer Vision: A Modern Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Comprehensive and up-to-date, this book includes essential topics that either reflect practical significance or are of theoretical importance and describes numerous important application areas such as image based rendering and digital libraries."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144758613"
                        ],
                        "name": "Bing Wu",
                        "slug": "Bing-Wu",
                        "structuredName": {
                            "firstName": "Bing",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bing Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39681370"
                        ],
                        "name": "T. Ooi",
                        "slug": "T.-Ooi",
                        "structuredName": {
                            "firstName": "Teng",
                            "lastName": "Ooi",
                            "middleNames": [
                                "Leng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ooi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144808834"
                        ],
                        "name": "Zijiang J He",
                        "slug": "Zijiang-J-He",
                        "structuredName": {
                            "firstName": "Zijiang",
                            "lastName": "He",
                            "middleNames": [
                                "J"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zijiang J He"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[4, 13, 14]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 4317907,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8cf5a9cc93f89097eaf4c75871c02173bcdbd2ef",
            "isKey": false,
            "numCitedBy": 221,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "By itself, the absolute distance of an object cannot be accurately judged beyond 2\u20133\u2009m (refs 1\u20133). Yet, when it is viewed with reference to a flat terrain, humans accurately judge the absolute distance of the object up to 20\u2009m, an ability that is important for various actions. Here we provide evidence that this is accomplished by integrating local patches of ground information into a global surface reference frame. We first show that restricting an observer's visual field of view to the local ground area around the target leads to distance underestimation, indicating that a relatively wide expanse of the ground surface is required for accurate distance judgement. Second, as proof of surface integration, we show that even with the restricted view, the observer can accurately judge absolute distance by scanning local patches of the ground surface, bit by bit, from near to far, but not in the reverse direction. This finding also reveals that the surface integration process uses the near-ground-surface information as a foundation for surface representation, and extrapolation to the far ground surface around the target for accurate absolute distance computation."
            },
            "slug": "Perceiving-distance-accurately-by-a-directional-of-Wu-Ooi",
            "title": {
                "fragments": [],
                "text": "Perceiving distance accurately by a directional process of integrating ground information"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that restricting an observer's visual field of view to the local ground area around the target leads to distance underestimation, indicating that a relatively wide expanse of the ground surface is required for accurate distance judgement."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109618694"
                        ],
                        "name": "Subhodev Das",
                        "slug": "Subhodev-Das",
                        "structuredName": {
                            "firstName": "Subhodev",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Subhodev Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14970839,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6d55eded5f145f553c7c5c63aec793257eb8a54e",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper compares the performances of the binocular cues of stereo and vergence, and the monocular cue of focus for range estimation using an active vision system. The performance of each cue is characterized in terms of sensitivity to errors in the imaging parameters. The effects of random, quantization errors are expressed in terms of the standard deviation of the resulting depth error. The effect of systematic, calibration errors on estimation using each cue is also studied. Performance characterization of each cue is utilized to evaluate the relative performance of the cues. Also discussed, based on such characterization, are ways to select a cue taking into account the computational and reliability aspects of the corresponding estimation process."
            },
            "slug": "Performance-Analysis-of-Stereo,-Vergence,-and-Focus-Das-Ahuja",
            "title": {
                "fragments": [],
                "text": "Performance Analysis of Stereo, Vergence, and Focus as Depth Cues for Active Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper compares the performances of the binocular cues of stereo and vergence, and the monocular cue of focus for range estimation using an active vision system and suggests ways to select a cue taking into account the computational and reliability aspects of the corresponding estimation process."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "\u2026depths exhibit very different behaviors at different resolutions, and using multiscale features allows us to capture these variations [16].3 In addition to capturing more global information, computing features at multiple spatial scales also help accounts for different relative sizes of\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122692461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a5e6244b225845766921da4bf3147e7dc5e2cc5",
            "isKey": false,
            "numCitedBy": 329,
            "numCiting": 431,
            "paperAbstract": {
                "fragments": [],
                "text": "Reviews a significant component of the rich field of statistical multiresolution (MR) modeling and processing. These MR methods have found application and permeated the literature of a widely scattered set of disciplines, and one of our principal objectives is to present a single, coherent picture of this framework. A second goal is to describe how this topic fits into the even larger field of MR methods and concepts-in particular, making ties to topics such as wavelets and multigrid methods. A third goal is to provide several alternate viewpoints for this body of work, as the methods and concepts we describe intersect with a number of other fields. The principle focus of our presentation is the class of MR Markov processes defined on pyramidally organized trees. The attractiveness of these models stems from both the very efficient algorithms they admit and their expressive power and broad applicability. We show how a variety of methods and models relate to this framework including models for self-similar and 1/f processes. We also illustrate how these methods have been used in practice."
            },
            "slug": "Multiresolution-Markov-models-for-signal-and-image-Willsky",
            "title": {
                "fragments": [],
                "text": "Multiresolution Markov models for signal and image processing"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This presentation reviews a significant component of the rich field of statistical multiresolution (MR) modeling and processing, and shows how a variety of methods and models relate to this framework including models for self-similar and 1/f processes."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5107846"
                        ],
                        "name": "I. B\u00fclthoff",
                        "slug": "I.-B\u00fclthoff",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "B\u00fclthoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. B\u00fclthoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747836"
                        ],
                        "name": "H. B\u00fclthoff",
                        "slug": "H.-B\u00fclthoff",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "B\u00fclthoff",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. B\u00fclthoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[4, 13, 14]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13998226,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2f8f6dd86252ebc85081c4d8053f4a0ef6b125ea",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The interaction between depth perception and object recognition has important implications for the nature of mental object representations and models of hierarchical organization of visual processing. It is often believed that the computation of depth influences subsequent high-level object recognition processes, and that depth processing is an early vision task that is largely immune to 'top-down' object-specific influences, such as object recognition. Here we present experimental evidence that challenges both these assumptions in the specific context of stereoscopic depth-perception. We have found that observers' recognition of familiar dynamic three-dimensional (3D) objects is unaffected even when the objects' depth structure is scrambled, as long as their two-dimensional (2D) projections are unchanged. Furthermore, the observers seem perceptually unaware of the depth anomalies introduced by scrambling. We attribute the latter result to a top-down recognition-based influence whereby expectations about a familiar object's 3D structure override the true stereoscopic information."
            },
            "slug": "Top-down-influences-on-stereoscopic-B\u00fclthoff-B\u00fclthoff",
            "title": {
                "fragments": [],
                "text": "Top-down influences on stereoscopic depth-perception"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Experimental evidence is presented that it is found that observers' recognition of familiar dynamic three-dimensional objects is unaffected even when the objects' depth structure is scrambled, as long as their two-dimensional projections are unchanged."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2386187"
                        ],
                        "name": "J. Loomis",
                        "slug": "J.-Loomis",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Loomis",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Loomis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[12] This is done using monocular cues such as texture variations, texture gradients, occlusion, known object sizes, haze, defocus, etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5130060,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "f46d387ae28fe61e2e40b2fe012327e9c4b42c03",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "How do we perceive distance using only one eye? A neat variation on existing methods of measuring visually perceived distance highlights the importance of 'angular declination', a cue long thought to be involved."
            },
            "slug": "Looking-down-is-looking-up-Loomis",
            "title": {
                "fragments": [],
                "text": "Looking down is looking up"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A neat variation on existing methods of measuring visually perceived distance highlights the importance of 'angular declination', a cue long thought to be involved."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[5] performed surface reconstruction from single ima ges for known fixed objects like hands and faces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34365153,
            "fieldsOfStudy": [],
            "id": "d4f7673a97213c3a0e69b64fa06cb82ec8aeec86",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "HMM-based surface reconstruction from single images"
            },
            "venue": {
                "fragments": [],
                "text": "Systems and Computers in Japan"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 101
                            }
                        ],
                        "text": "Texture information is mostly contained within the image intensity channel,2 so we apply Laws\u2019 masks [15, 4] to this channel to compute the texture energy (Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Laws' texture energy in TEXTURE"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Vision: Theory, Algorithms, Practicalities 2nd Edition"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 162
                            }
                        ],
                        "text": "Objects at different depths exhibit very diffe rent behaviors across different resolutions, and using multi-scale features allows us to ca pture these variations [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multiresolution markov models for signal and image pro  cessing.IEEE"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 17,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-Depth-from-Single-Monocular-Images-Saxena-Chung/cddd92203c8deb022a29b512b11050da531c5f3b?sort=total-citations"
}