{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758056"
                        ],
                        "name": "A. Stein",
                        "slug": "A.-Stein",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Stein",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 201
                            }
                        ],
                        "text": "\u2026can be done based on the local surface near the boundary (Vaillant and Faugeras 1992), the difference of the motion estimates on either sides of the boundary (Black and Fleet 2000; Smith et al. 2004; Stein et al. 2007), or the responses of spatio-temporal filters (Stein and Hebert 2006a, 2006b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 163
                            }
                        ],
                        "text": "This can be done based on the local surface near the boundary (Vaillant and Faugeras 1992), the difference of the motion estimates on either sides of the boundary (Black and Fleet 2000; Smith et al. 2004; Stein et al. 2007), or the responses of spatio-temporal filters (Stein and Hebert 2006a, 2006b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14327177,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f904b4cd514a3b7e49a73f25ca246b831d85601",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "While great strides have been made in detecting and localizing specific objects in natural images, the bottom-up segmentation of unknown, generic objects remains a difficult challenge. We believe that occlusion can provide a strong cue for object segmentation and \"pop-out\", but detecting an object's occlusion boundaries using appearance alone is a difficult problem in itself. If the camera or the scene is moving, however, that motion provides an additional powerful indicator of occlusion. Thus, we use standard appearance cues (e.g. brightness/color gradient) in addition to motion cues that capture subtle differences in the relative surface motion (i.e. parallax) on either side of an occlusion boundary. We describe a learned local classifier and global inference approach which provide a frame-work for combining and reasoning about these appearance and motion cues to estimate which region boundaries of an initial over-segmentation correspond to object/occlusion boundaries in the scene. Through results on a dataset which contains short videos with labeled boundaries, we demonstrate the effectiveness of motion cues for this task."
            },
            "slug": "Learning-to-Find-Object-Boundaries-Using-Motion-Stein-Hoiem",
            "title": {
                "fragments": [],
                "text": "Learning to Find Object Boundaries Using Motion Cues"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A learned local classifier and global inference approach is described which provides a frame-work for combining and reasoning about appearance and motion cues to estimate which region boundaries of an initial over-segmentation correspond to object/occlusion boundaries in the scene."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758056"
                        ],
                        "name": "A. Stein",
                        "slug": "A.-Stein",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Stein",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 266
                            }
                        ],
                        "text": "\u2026can be done based on the local surface near the boundary (Vaillant and Faugeras 1992), the difference of the motion estimates on either sides of the boundary (Black and Fleet 2000; Smith et al. 2004; Stein et al. 2007), or the responses of spatio-temporal filters (Stein and Hebert 2006a, 2006b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 196
                            }
                        ],
                        "text": "This can be done based on the local surface near the boundary [73], the difference of the motion estimates on either sides of the boundary [8, 66, 70], or the responses of spatio-temporal filters [68, 69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11694972,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c60ad7cfa0b137b54602ff59e36cb8f04628645",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Local-detection-of-occlusion-boundaries-in-video-Stein-Hebert",
            "title": {
                "fragments": [],
                "text": "Local Detection of Occlusion Boundaries in Video"
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3717791"
                        ],
                        "name": "M. P. Kumar",
                        "slug": "M.-P.-Kumar",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Kumar",
                            "middleNames": [
                                "Pawan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. P. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 104545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b1fca32958cb821794105a0fb2e9c856f9c67e5",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a probabilistic method for segmenting instances of a particular object category within an image. Our approach overcomes the deficiencies of previous segmentation techniques based on traditional grid conditional random fields (CRF), namely that 1) they require the user to provide seed pixels for the foreground and the background and 2) they provide a poor prior for specific shapes due to the small neighborhood size of grid CRF. Specifically, we automatically obtain the pose of the object in a given image instead of relying on manual interaction. Furthermore, we employ a probabilistic model which includes shape potentials for the object to incorporate top-down information that is global across the image, in addition to the grid clique potentials which provide the bottom-up information used in previous approaches. The shape potentials are provided by the pose of the object obtained using an object category model. We represent articulated object categories using a novel layered pictorial structures model. Nonarticulated object categories are modeled using a set of exemplars. These object category models have the advantage that they can handle large intraclass shape, appearance, and spatial variation. We develop an efficient method, OBJCUT, to obtain segmentations using our probabilistic framework. Novel aspects of this method include: 1) efficient algorithms for sampling the object category models of our choice and 2) the observation that a sampling-based approximation of the expected log-likelihood of the model can be increased by a single graph cut. Results are presented on several articulated (e.g., animals) and nonarticulated (e.g., fruits) object categories. We provide a favorable comparison of our method with the state of the art in object category specific image segmentation, specifically the methods of Leibe and Schiele and Schoenemann and Cremers."
            },
            "slug": "OBJCUT:-Efficient-Segmentation-Using-Top-Down-and-Kumar-Torr",
            "title": {
                "fragments": [],
                "text": "OBJCUT: Efficient Segmentation Using Top-Down and Bottom-Up Cues"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A probabilistic method for segmenting instances of a particular object category within an image and provides a favorable comparison of the method with the state of the art in object category specific image segmentation, specifically the methods of Leibe and Schiele and Schoenemann and Cremers."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 151
                            }
                        ],
                        "text": "Although coarse and defined up to a scale, these estimates can provide a good qualitative sense of depth (Figure 15) and convincing 3D reconstructions [26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 74
                            }
                        ],
                        "text": "Boundaries for detectable objects can be improved with simple mechanisms (Hoiem et al. 2008)\nknow how these features impact performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 115
                            }
                        ],
                        "text": "By explicitly reasoning about occlusions, we enable much more accurate and detailed 3D models of cluttered scenes (Hoiem et al. 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "In other work [26], we show that the occlusion boundaries are helpful for single-view 3D reconstruction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "The algorithm could be improved by incorporating object detectors, as in [26], or, more interestingly, developing a object localization and segmentation algorithms that apply within some broader domain [17], such as animals or vehicles."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "By explicitly reasoning about occlusions, we enable much more accurate and detailed 3D models of cluttered scenes [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 15
                            }
                        ],
                        "text": "In other work (Hoiem et al. 2008), we show that the occlusion boundaries are helpful for single-view 3D reconstruction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "Boundaries for detectable objects can be improved with simple mechanisms [26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 73
                            }
                        ],
                        "text": "The algorithm could be improved by incorporating object detectors, as in Hoiem et al. (2008), or, more interestingly, developing a object localization and segmentation algorithms that apply within some broader domain (Farhadi et al. 2010), such as animals or vehicles."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 39
                            }
                        ],
                        "text": "15) and convincing 3D reconstructions (Hoiem et al. 2008)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5763563,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7d60c907426cc69f9db7472df063c6de10f1a2d",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Image understanding involves analyzing many different aspects of the scene. In this paper, we are concerned with how these tasks can be combined in a way that improves the performance of each of them. Inspired by Barrow and Tenenbaum, we present a flexible framework for interfacing scene analysis processes using intrinsic images. Each intrinsic image is a registered map describing one characteristic of the scene. We apply this framework to develop an integrated 3D scene understanding system with estimates of surface orientations, occlusion boundaries, objects, camera viewpoint, and relative depth. Our experiments on a set of 300 outdoor images demonstrate that these tasks reinforce each other, and we illustrate a coherent scene understanding with automatically reconstructed 3D models."
            },
            "slug": "Closing-the-loop-in-scene-interpretation-Hoiem-Efros",
            "title": {
                "fragments": [],
                "text": "Closing the loop in scene interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents a flexible framework for interfacing scene analysis processes using intrinsic images, and applies this framework to develop an integrated 3D scene understanding system with estimates of surface orientations, occlusion boundaries, objects, camera viewpoint, and relative depth."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 203
                            }
                        ],
                        "text": "\u2026where an object region is adjacent to a ground or sky region, and inference on our CRF model helps to propagate the label into less obvious boundaries\n4.3 Surface Layout Cues\nThe surface estimates from Hoiem et al. (2007) are highly predictive of occlusion boundaries and figure/ground labels."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "We train and test our method on our Geometric Context dataset [25], consisting of a wide variety of scenes including beaches, fields, forests, hills, suburbs, and urban streets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Our surface estimates [25] can sometimes be used to reconstruct a coarse 3D model of a scene [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 63
                            }
                        ],
                        "text": "We train and test our method on our Geometric Context dataset (Hoiem et al. 2007), consisting of a wide variety of\nscenes including beaches, fields, forests, hills, suburbs, and urban streets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 109
                            }
                        ],
                        "text": "1This paper offers a more complete understanding of the algorithm first described in the conference version (Hoiem et al. 2007), providing further background, description, insight, analysis, and evaluation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 23
                            }
                        ],
                        "text": "Our surface estimates (Hoiem et al. 2007) can sometimes be used to reconstruct a coarse 3D model of a scene (Hoiem et al. 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 37
                            }
                        ],
                        "text": "We can take advantage of our work in Hoiem et al. (2007) to recover surface information, which we represent as the average confidence (S1-S4) for each geometric class (horizontal support, vertical planar, vertical solid nonplanar, vertical porous, and sky) over each region."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 137
                            }
                        ],
                        "text": "These difficulties and successes can be partly explained as a heavy reliance on surface layout features, though we show in earlier work (Hoiem et al. 2007) that segmentation purely based on surface layout performs relatively poorly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 41
                            }
                        ],
                        "text": "We previously proposed a surface layout (Hoiem et al. 2007), that labels pixels according to surface geometry, such as \u201csupport\u201d (e.g., road, grass), \u201cvertical planar\u201d (e.g., a building wall), \u201cvertical non-planar porous\u201d (e.g., vegetation or a mesh), \u201cvertical non-planar solid\u201d (e.g., a person or\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 127
                            }
                        ],
                        "text": "However, our ideal segmentation into objects and major surfaces is different from a segmentation into the geometric classes of Hoiem et al. (2007), and we use no object-specific models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 167
                            }
                        ],
                        "text": "\u2026our experiments, we set the surface factor unary term by combining, in a linear logistic model, two likelihood estimates: (1) the multiple segmentation estimate from Hoiem et al. (2007); and (2) an estimate using the same cues as (1) but using the current segmentation from our occlusion algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 138
                            }
                        ],
                        "text": "Our physical definition of boundaries provides a more concrete objective and allows us to build on the 3D surface estimation described in Hoiem et al. (2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "However, our ideal segmentation into objects and major surfaces is different from a segmentation into the geometric classes of [25], and we use no objectspecific models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 138
                            }
                        ],
                        "text": "Our physical definition of boundaries provides a more concrete objective and allows us to build on the 3D surface estimation described in [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "\u201d We previously proposed a surface layout [25], that labels pixels according to surface geometry, such as \u201csupport\u201d (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "We can take advantage of our work in [25] to recover surface information, which we represent as the average confidence (S1-S4) for each geometric class (horizontal support, vertical planar, vertical solid non-planar, vertical porous, and sky) over each region."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 32
                            }
                        ],
                        "text": "In an earlier conference paper (Hoiem et al. 2007), we provide further analysis of segmentation accuracy and show that segmentations compare favorably to normalized cuts (Cour et al.\n2005) or using the surface layout labels as a segmentation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 168
                            }
                        ],
                        "text": "In our experiments, we set the surface factor unary term by combining, in a linear logistic model, two likelihood estimates: 1) the multiple segmentation estimate from [25]; and 2) an estimate using the same cues as (1) but using the current segmentation from our occlusion algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "The surface estimates from [25] are highly predictive of occlusion boundaries and figure/ground labels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "The method in [25] provides pixel confidences for \u201csupport\u201d, \u201cvertical planar\u201d, \u201cvertical non-planar porous\u201d, \u201cvertical non-planar solid\u201d, and \u201csky\u201d."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 14
                            }
                        ],
                        "text": "The method in Hoiem et al. (2007) provides pixel confidences for \u201csupport\u201d, \u201cvertical planar\u201d, \u201cvertical non-planar porous\u201d, \u201cvertical nonplanar solid\u201d, and \u201csky\u201d."
                    },
                    "intents": []
                }
            ],
            "corpusId": 37206,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5276705d71e3dac961ab5d06b86a7b806cc9af64",
            "isKey": false,
            "numCitedBy": 718,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans have an amazing ability to instantly grasp the overall 3D structure of a scene\u2014ground orientation, relative positions of major landmarks, etc.\u2014even from a single image. This ability is completely missing in most popular recognition algorithms, which pretend that the world is flat and/or view it through a patch-sized peephole. Yet it seems very likely that having a grasp of this \u201csurface layout\u201d of a scene should be of great assistance for many tasks, including recognition, navigation, and novel view synthesis.In this paper, we take the first step towards constructing the surface layout, a labeling of the image intogeometric classes. Our main insight is to learn appearance-based models of these geometric classes, which coarsely describe the 3D scene orientation of each image region. Our multiple segmentation framework provides robust spatial support, allowing a wide variety of cues (e.g., color, texture, and perspective) to contribute to the confidence in each geometric label. In experiments on a large set of outdoor images, we evaluate the impact of the individual cues and design choices in our algorithm. We further demonstrate the applicability of our method to indoor images, describe potential applications, and discuss extensions to a more complete notion of surface layout."
            },
            "slug": "Recovering-Surface-Layout-from-an-Image-Hoiem-Efros",
            "title": {
                "fragments": [],
                "text": "Recovering Surface Layout from an Image"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper takes the first step towards constructing the surface layout, a labeling of the image intogeometric classes, to learn appearance-based models of these geometric classes, which coarsely describe the 3D scene orientation of each image region."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144891282"
                        ],
                        "name": "David R. Martin",
                        "slug": "David-R.-Martin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Martin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 141
                            }
                        ],
                        "text": "The speed of the algorithm might be improved by: using a simpler initial boundary detector\n(e.g., pre-thresholded Canny 1986, rather than Pb Martin et al. 2004); by dropping some of the more computationally expensive and marginally useful features, such as the depth and geometric T-junction cues;\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 129
                            }
                        ],
                        "text": "We can see that for both classifiers, the region and boundary features lead to a better classifier than using only Pb estimates (Martin et al. 2004), and including features based on surface layout predictions gives a substantial improvement."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 40
                            }
                        ],
                        "text": "Finally, we compare our algorithm to Pb (Martin et al. 2004) and Global Pb (Maire et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 41
                            }
                        ],
                        "text": "Finally, we compare our algorithm to Pb (Martin et al. 2004) and Global Pb (Maire et al. 2008) on several external datasets (Sect."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8165754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33a7a59f785ef46091c30c4c85ef88c6bdabab51",
            "isKey": true,
            "numCitedBy": 2381,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this work is to accurately detect and localize boundaries in natural scenes using local image measurements. We formulate features that respond to characteristic changes in brightness, color, and texture associated with natural boundaries. In order to combine the information from these features in an optimal way, we train a classifier using human labeled images as ground truth. The output of this classifier provides the posterior probability of a boundary at each image location and orientation. We present precision-recall curves showing that the resulting detector significantly outperforms existing approaches. Our two main results are 1) that cue combination can be performed adequately with a simple linear model and 2) that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "slug": "Learning-to-detect-natural-image-boundaries-using-Martin-Fowlkes",
            "title": {
                "fragments": [],
                "text": "Learning to detect natural image boundaries using local brightness, color, and texture cues"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The two main results are that cue combination can be performed adequately with a simple linear model and that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114833718"
                        ],
                        "name": "Xiaofeng Ren",
                        "slug": "Xiaofeng-Ren",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 95
                            }
                        ],
                        "text": "This may partially explain why recent methods to infer figure/ground labels in natural images (Ren et al. 2006; Leichter and Lindenbaum 2009) tend to work much better for manually-provided boundaries than automatically detected boundaries."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11043721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6aaa3d8f1990fc3d4c97f9b012dd11a4344b4869",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Figure/ground assignment is a key step in perceptual organization which assigns contours to one of the two abutting regions, providing information about occlusion and allowing high-level processing to focus on non-accidental shapes of figural regions. In this paper, we develop a computational model for figure/ground assignment in complex natural scenes. We utilize a large dataset of images annotated with human-marked segmentations and figure/ground labels for training and quantitative evaluation. \n \nWe operationalize the concept of familiar configuration by constructing prototypical local shapes, i.e. shapemes, from image data. Shapemes automatically encode mid-level visual cues to figure/ground assignment such as convexity and parallelism. Based on the shapeme representation, we train a logistic classifier to locally predict figure/ground labels. We also consider a global model using a conditional random field (CRF) to enforce global figure/ground consistency at T-junctions. We use loopy belief propagation to perform approximate inference on this model and learn maximum likelihood parameters from ground-truth labels. \n \nWe find that the local shapeme model achieves an accuracy of 64% in predicting the correct figural assignment. This compares favorably to previous studies using classical figure/ground cues [1]. We evaluate the global model using either a set of contours extracted from a low-level edge detector or the set of contours given by human segmentations. The global CRF model significantly improves the performance over the local model, most notably when using human-marked boundaries (78%). These promising experimental results show that this is a feasible approach to bottom-up figure/ground assignment in natural images."
            },
            "slug": "Figure/Ground-Assignment-in-Natural-Images-Ren-Fowlkes",
            "title": {
                "fragments": [],
                "text": "Figure/Ground Assignment in Natural Images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A computational model for figure/ground assignment in complex natural scenes based on the shapeme representation, which achieves an accuracy of 64% in predicting the correct figural assignment and considers a global model using a conditional random field (CRF) to enforce global figure/Ground consistency at T-junctions."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681995"
                        ],
                        "name": "Ashutosh Saxena",
                        "slug": "Ashutosh-Saxena",
                        "structuredName": {
                            "firstName": "Ashutosh",
                            "lastName": "Saxena",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashutosh Saxena"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112610462"
                        ],
                        "name": "Sung H. Chung",
                        "slug": "Sung-H.-Chung",
                        "structuredName": {
                            "firstName": "Sung",
                            "lastName": "Chung",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sung H. Chung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Saxena et al. (2005, 2007) train with range images to estimate depth from the image features directly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[62, 63] train with range images to estimate depth from the image features directly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10748875,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cddd92203c8deb022a29b512b11050da531c5f3b",
            "isKey": false,
            "numCitedBy": 981,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the task of depth estimation from a single monocular image. We take a supervised learning approach to this problem, in which we begin by collecting a training set of monocular images (of unstructured outdoor environments which include forests, trees, buildings, etc.) and their corresponding ground-truth depthmaps. Then, we apply supervised learning to predict the depthmap as a function of the image. Depth estimation is a challenging problem, since local features alone are insufficient to estimate depth at a point, and one needs to consider the global context of the image. Our model uses a discriminatively-trained Markov Random Field (MRF) that incorporates multiscale local- and global-image features, and models both depths at individual points as well as the relation between depths at different points. We show that, even on unstructured scenes, our algorithm is frequently able to recover fairly accurate depthmaps."
            },
            "slug": "Learning-Depth-from-Single-Monocular-Images-Saxena-Chung",
            "title": {
                "fragments": [],
                "text": "Learning Depth from Single Monocular Images"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This work begins by collecting a training set of monocular images (of unstructured outdoor environments which include forests, trees, buildings, etc.) and their corresponding ground-truth depthmaps, and applies supervised learning to predict the depthmap as a function of the image."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3141988"
                        ],
                        "name": "Fuxin Li",
                        "slug": "Fuxin-Li",
                        "structuredName": {
                            "firstName": "Fuxin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fuxin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35681810"
                        ],
                        "name": "Jo\u00e3o Carreira",
                        "slug": "Jo\u00e3o-Carreira",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Carreira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00e3o Carreira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 40
                            }
                        ],
                        "text": "Recent work in generic object detection (Li et al. 2010; Alexe et al. 2010; Endres and Hoiem 2010) may also be useful for finding boundaries of individ-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 41
                            }
                        ],
                        "text": "Recent work in generic object detection (Li et al. 2010; Alexe et al. 2010; Endres and Hoiem 2010) may also be useful for finding boundaries of individual objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7625628,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ec1f8cbe8c9da709d519f99fc670604c268742f",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach to visual object-class recognition and segmentation based on a pipeline that combines multiple, holistic figure-ground hypotheses generated in a bottom-up, object independent process. Decisions are performed based on continuous estimates of the spatial overlap between image segment hypotheses and each putative class. We differ from existing approaches not only in our seemingly unreasonable assumption that good object-level segments can be obtained in a feed-forward fashion, but also in framing recognition as a regression problem. Instead of focusing on a one-vs-all winning margin that can scramble ordering inside the non-maximum (non-winning) set, learning produces a globally consistent ranking with close ties to segment quality, hence to the extent entire object or part hypotheses spatially overlap with the ground truth. We demonstrate results beyond the current state of the art for image classification, object detection and semantic segmentation, in a number of challenging datasets including Caltech-101, ETHZ-Shape and PASCAL VOC 2009."
            },
            "slug": "Object-recognition-as-ranking-holistic-hypotheses-Li-Carreira",
            "title": {
                "fragments": [],
                "text": "Object recognition as ranking holistic figure-ground hypotheses"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Results are demonstrated beyond the current state of the art for image classification, object detection and semantic segmentation, in a number of challenging datasets including Caltech-101, ETHZ-Shape and PASCAL VOC 2009."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778133"
                        ],
                        "name": "Pablo Arbel\u00e1ez",
                        "slug": "Pablo-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pablo Arbel\u00e1ez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4474066,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8463e6acd5b03dc6f4c13858a8aed980cf2fed31",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a low-level system for boundary extraction and segmentation of natural images and the evaluation of its performance. We study the problem in the framework of hierarchical classification, where the geometric structure of an image can be represented by an ultrametric contour map, the soft boundary image associated to a family of nested segmentations. We define generic ultrametric distances by integrating local contour cues along the regions boundaries and combining this information with region attributes. Then, we evaluate quantitatively our results with respect to ground-truth segmentation data, proving that our system outperforms significantly two widely used hierarchical segmentation techniques, as well as the state of the art in local edge detection."
            },
            "slug": "Boundary-Extraction-in-Natural-Images-Using-Contour-Arbel\u00e1ez",
            "title": {
                "fragments": [],
                "text": "Boundary Extraction in Natural Images Using Ultrametric Contour Maps"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper presents a low-level system for boundary extraction and segmentation of natural images and the evaluation of its performance proves that this system outperforms significantly two widely used hierarchical segmentation techniques, as well as the state of the art in local edge detection."
            },
            "venue": {
                "fragments": [],
                "text": "2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681995"
                        ],
                        "name": "Ashutosh Saxena",
                        "slug": "Ashutosh-Saxena",
                        "structuredName": {
                            "firstName": "Ashutosh",
                            "lastName": "Saxena",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashutosh Saxena"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112610462"
                        ],
                        "name": "Sung H. Chung",
                        "slug": "Sung-H.-Chung",
                        "structuredName": {
                            "firstName": "Sung",
                            "lastName": "Chung",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sung H. Chung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Saxena et al. (2005, 2007) train with range images to estimate depth from the image features directly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[62, 63] train with range images to estimate depth from the image features directly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9620866,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3635881d5632816df7762f2c588138c0baa339ef",
            "isKey": false,
            "numCitedBy": 621,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nWe consider the task of 3-d depth estimation from a single still image. We take a supervised learning approach to this problem, in which we begin by collecting a training set of monocular images (of unstructured indoor and outdoor environments which include forests, sidewalks, trees, buildings, etc.) and their corresponding ground-truth depthmaps. Then, we apply supervised learning to predict the value of the depthmap as a function of the image. Depth estimation is a challenging problem, since local features alone are insufficient to estimate depth at a point, and one needs to consider the global context of the image. Our model uses a hierarchical, multiscale Markov Random Field (MRF) that incorporates multiscale local- and global-image features, and models the depths and the relation between depths at different points in the image. We show that, even on unstructured scenes, our algorithm is frequently able to recover fairly accurate depthmaps. We further propose a model that incorporates both monocular cues and stereo (triangulation) cues, to obtain significantly more accurate depth estimates than is possible using either monocular or stereo cues alone.\n"
            },
            "slug": "3-D-Depth-Reconstruction-from-a-Single-Still-Image-Saxena-Chung",
            "title": {
                "fragments": [],
                "text": "3-D Depth Reconstruction from a Single Still Image"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a model that incorporates both monocular cues and stereo (triangulation) cues, to obtain significantly more accurate depth estimates than is possible using either monocular or stereo cues alone."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 132
                            }
                        ],
                        "text": "Some segmentation methods rely on 2D brightness, color, or texture cues to group the image pixels into perceptually similar regions [64, 50, 58, 18, 5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 193
                            }
                        ],
                        "text": "Some segmentation methods rely on 2D brightness, color, or texture cues to group the image pixels into perceptually similar regions (Shi and Malik 2000; Martin et al. 2001; Ren and Malik 2003; Felzenszwalb and Huttenlocher 2004; Arbelaez 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207663697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aeeffe327e6c93e9010c7b1e401caa9113723851",
            "isKey": false,
            "numCitedBy": 3751,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of segmenting an image into regions. We define a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image. We then develop an efficient segmentation algorithm based on this predicate, and show that although this algorithm makes greedy decisions it produces segmentations that satisfy global properties. We apply the algorithm to image segmentation using two different kinds of local neighborhoods in constructing the graph, and illustrate the results with both real and synthetic images. The algorithm runs in time nearly linear in the number of graph edges and is also fast in practice. An important characteristic of the method is its ability to preserve detail in low-variability image regions while ignoring detail in high-variability regions."
            },
            "slug": "Efficient-Graph-Based-Image-Segmentation-Felzenszwalb-Huttenlocher",
            "title": {
                "fragments": [],
                "text": "Efficient Graph-Based Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An efficient segmentation algorithm is developed based on a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image and it is shown that although this algorithm makes greedy decisions it produces segmentations that satisfy global properties."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 91
                            }
                        ],
                        "text": "Without retraining either algorithm, we compare on three datasets: BSDS test set, LabelMe (Russell et al. 2006), and the PASCAL VOC 2008 segmentation set (Everingham et al. 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 90
                            }
                        ],
                        "text": "Without retraining either algorithm, we compare on three datasets: BSDS test set, LabelMe (Russell et al. 2006), and the PASCAL VOC 2008 segmentation set (Everingham et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2066830,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56766bab76cdcd541bf791730944a5e453006239",
            "isKey": false,
            "numCitedBy": 740,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a large dataset of images, we seek to automatically determine the visually similar object and scene classes together with their image segmentation. To achieve this we combine two ideas: (i) that a set of segmented objects can be partitioned into visual object classes using topic discovery models from statistical text analysis; and (ii) that visual object classes can be used to assess the accuracy of a segmentation. To tie these ideas together we compute multiple segmentations of each image and then: (i) learn the object classes; and (ii) choose the correct segmentations. We demonstrate that such an algorithm succeeds in automatically discovering many familiar objects in a variety of image datasets, including those from Caltech, MSRC and LabelMe."
            },
            "slug": "Using-Multiple-Segmentations-to-Discover-Objects-in-Russell-Freeman",
            "title": {
                "fragments": [],
                "text": "Using Multiple Segmentations to Discover Objects and their Extent in Image Collections"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work compute multiple segmentations of each image and then learns the object classes and chooses the correct segmentations, demonstrating that such an algorithm succeeds in automatically discovering many familiar objects in a variety of image datasets, including those from Caltech, MSRC and LabelMe."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 133
                            }
                        ],
                        "text": "Some segmentation methods rely on 2D brightness, color, or texture cues to group the image pixels into perceptually similar regions (Shi and Malik 2000; Martin et al. 2001; Ren and Malik 2003; Felzenszwalb and Huttenlocher 2004; Arbelaez 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 84
                            }
                        ],
                        "text": "Though this grouping is sometimes performed based on pre-computed affinities (e.g., Shi and Malik 2000), others advocate a gradual approach, such as the hierarchical segmentation techniques developed by Ahuja (1996) and Arbelaez (2006), Arbelaez et al. (2009), which we follow in our approach."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14848918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b94c7ff9532ab26c3aedbee3988ec4c7a237c173",
            "isKey": false,
            "numCitedBy": 12815,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging."
            },
            "slug": "Normalized-cuts-and-image-segmentation-Shi-Malik",
            "title": {
                "fragments": [],
                "text": "Normalized cuts and image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work treats image segmentation as a graph partitioning problem and proposes a novel global criterion, the normalized cut, for segmenting the graph, which measures both the total dissimilarity between the different groups as well as the total similarity within the groups."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144042261"
                        ],
                        "name": "Mark Nitzberg",
                        "slug": "Mark-Nitzberg",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Nitzberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Nitzberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082087031"
                        ],
                        "name": "David Mumford",
                        "slug": "David-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Mumford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 49
                            }
                        ],
                        "text": "Following similar strategies to the 2.1D work of Nitzberg and Mumford (1990), they approach the problem in two stages: (1) segment the image, (2) assign a figure/ground label to each boundary fragment according to local image evidence and global MRF-learned constraints."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "1D work of Nitzberg and Mumford [54], they approach the problem in two stages: 1) segment the image, 2) assign a figure/ground label to each boundary fragment according to local image evidence and global MRFlearned constraints."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33373361,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "321a32929fb7d83fa84b043ba475c8342f0cc62f",
            "isKey": false,
            "numCitedBy": 164,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A model is described for image segmentation that tries to capture the low-level depth reconstruction exhibited in early human vision, giving an important role to edge terminations. The problem is to find a decomposition of the domain D of an image that has a minimum of disrupted edges-junctions of edges, crack tips, corners, and cusps-by creating suitable continuations for the disrupted edges behind occluding regions. The result is a decomposition of D into overlapping regions R/sub 1/ union . . . union R/sub n/ ordered by occlusion, which is called the 2.1-D sketch. Expressed as a minimization problem, the model gives rise to a family of optimal contours, called nonlinear splines, that minimize length and the square of curvature. These are essential in the construction of the 2.1-D sketch of an image, as the continuations of disrupted edges. An algorithm is described that constructs the 2.1-D sketch of an image, and gives results for several example images. The algorithm yields the same interpretations of optical illusions as the human visual system.<<ETX>>"
            },
            "slug": "The-2.1-D-sketch-Nitzberg-Mumford",
            "title": {
                "fragments": [],
                "text": "The 2.1-D sketch"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A model is described for image segmentation that tries to capture the low-level depth reconstruction exhibited in early human vision, giving an important role to edge terminations, which gives rise to a family of optimal contours, called nonlinear splines, that minimize length and the square of curvature."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778133"
                        ],
                        "name": "Pablo Arbel\u00e1ez",
                        "slug": "Pablo-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pablo Arbel\u00e1ez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15291355,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "779dea9b105d8f48c9bc86f479b91f9c1d3c5963",
            "isKey": false,
            "numCitedBy": 286,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a generic grouping algorithm that constructs a hierarchy of regions from the output of any contour detector. Our method consists of two steps, an oriented watershed transform (OWT) to form initial regions from contours, followed by construction of an ultra-metric contour map (UCM) defining a hierarchical segmentation. We provide extensive experimental evaluation to demonstrate that, when coupled to a high-performance contour detector, the OWT-UCM algorithm produces state-of-the-art image segmentations. These hierarchical segmentations can optionally be further refined by user-specified annotations."
            },
            "slug": "From-contours-to-regions:-An-empirical-evaluation-Arbel\u00e1ez-Maire",
            "title": {
                "fragments": [],
                "text": "From contours to regions: An empirical evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work provides extensive experimental evaluation to demonstrate that, when coupled to a high-performance contour detector, the OWT-UCM algorithm produces state-of-the-art image segmentations."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1814318"
                        ],
                        "name": "S. Mahamud",
                        "slug": "S.-Mahamud",
                        "structuredName": {
                            "firstName": "Shyjan",
                            "lastName": "Mahamud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mahamud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2955375"
                        ],
                        "name": "L. Williams",
                        "slug": "L.-Williams",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Williams",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31373813"
                        ],
                        "name": "K. Thornber",
                        "slug": "K.-Thornber",
                        "structuredName": {
                            "firstName": "Karvel",
                            "lastName": "Thornber",
                            "middleNames": [
                                "K."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Thornber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2421148"
                        ],
                        "name": "Kanglin Xu",
                        "slug": "Kanglin-Xu",
                        "structuredName": {
                            "firstName": "Kanglin",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kanglin Xu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 194
                            }
                        ],
                        "text": "Alternatively, a global solution can be reached by finding a dominant component in the graph with spectral methods (Sarkar and Soundararajan 2000; Perona and Freeman 1998; Leung and Malik 1998; Mahamud et al. 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15205495,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c07958ce81bc3295c8a56e57b6dec5421214921f",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Using a saliency measure based on the global property of contour closure, we have developed a segmentation method which identifies smooth closed contours bounding objects of unknown shape in real images. The saliency measure incorporates the Gestalt principles of proximity and good continuity that previous methods have also exploited. Unlike previous methods, we incorporate contour closure by finding the eigenvector with the largest positive real eigenvalue of a transition matrix for a Markov process where edges from the image serve as states. Element (i, j) of the transition matrix is the conditional probability that a contour which contains edge j will also contain edge i. We show how the saliency measure, defined for individual edges, can be used to derive a saliency relation, defined for pairs of edges, and further show that strongly-connected components of the graph representing the saliency relation correspond to smooth closed contours in the image. Finally, we report for the first time, results on large real images for which segmentation takes an average of about 10 seconds per object on a general-purpose workstation."
            },
            "slug": "Segmentation-of-Multiple-Salient-Closed-Contours-Mahamud-Williams",
            "title": {
                "fragments": [],
                "text": "Segmentation of Multiple Salient Closed Contours from Real Images"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A segmentation method which identifies smooth closed contours bounding objects of unknown shape in real images by incorporating contour closure by finding the eigenvector with the largest positive real eigenvalue of a transition matrix for a Markov process where edges from the image serve as states."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144430305"
                        ],
                        "name": "Jean-Fran\u00e7ois Lalonde",
                        "slug": "Jean-Fran\u00e7ois-Lalonde",
                        "structuredName": {
                            "firstName": "Jean-Fran\u00e7ois",
                            "lastName": "Lalonde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Fran\u00e7ois Lalonde"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716777"
                        ],
                        "name": "A. Criminisi",
                        "slug": "A.-Criminisi",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Criminisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Criminisi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12312803,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ddf7f6917a3b81f0ba45dba96e60d96a452b5c38",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for inserting new objects into existing photographs by querying a vast image-based object library, pre-computed using a publicly available Internet object database. The central goal is to shield the user from all of the arduous tasks typically involved in image compositing. The user is only asked to do two simple things: 1) pick a 3D location in the scene to place a new object; 2) select an object to insert using a hierarchical menu. We pose the problem of object insertion as a data-driven, 3D-based, context-sensitive object retrieval task. Instead of trying to manipulate the object to change its orientation, color distribution, etc. to fit the new image, we simply retrieve an object of a specified class that has all the required properties (camera pose, lighting, resolution, etc) from our large object library. We present new automatic algorithms for improving object segmentation and blending, estimating true 3D object size and orientation, and estimating scene lighting conditions. We also present an intuitive user interface that makes object insertion fast and simple even for the artistically challenged."
            },
            "slug": "Photo-clip-art-Lalonde-Hoiem",
            "title": {
                "fragments": [],
                "text": "Photo clip art"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A system for inserting new objects into existing photographs by querying a vast image-based object library, pre-computed using a publicly available Internet object database, to shield the user from all of the arduous tasks typically involved in image compositing."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118147655"
                        ],
                        "name": "Paul Smith",
                        "slug": "Paul-Smith",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418842"
                        ],
                        "name": "T. Drummond",
                        "slug": "T.-Drummond",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Drummond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Drummond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 182
                            }
                        ],
                        "text": "\u2026can be done based on the local surface near the boundary (Vaillant and Faugeras 1992), the difference of the motion estimates on either sides of the boundary (Black and Fleet 2000; Smith et al. 2004; Stein et al. 2007), or the responses of spatio-temporal filters (Stein and Hebert 2006a, 2006b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 163
                            }
                        ],
                        "text": "This can be done based on the local surface near the boundary (Vaillant and Faugeras 1992), the difference of the motion estimates on either sides of the boundary (Black and Fleet 2000; Smith et al. 2004; Stein et al. 2007), or the responses of spatio-temporal filters (Stein and Hebert 2006a, 2006b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5664641,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "451f54475bcf0d50279387f55cab2f0f571a13ab",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new Bayesian framework for motion segmentation /sub i/viding a frame from an image sequence into layers representing different moving objects - by tracking edges between frames. Edges are found using the Canny edge detector, and the expectation-maximization algorithm is then used to fit motion models to these edges and also to calculate the probabilities of the edges obeying each motion model. The edges are also used to segment the image into regions of similar color. The most likely labeling for these regions is then calculated by using the edge probabilities, in association with a Markov random field-style prior. The identification of the relative depth ordering of the different motion layers is also determined, as an integral part of the process. An efficient implementation of this framework is presented for segmenting two motions (foreground and background) using two frames. It is then demonstrated how, by tracking the edges into further frames, the probabilities may be accumulated to provide an even more accurate and robust estimate, and segment an entire sequence. Further extensions are then presented to address the segmentation of more than two motions. Here, a hierarchical method of initializing the expectation-maximization algorithm is described, and it is demonstrated that the minimum description length principle may be used to automatically select the best number of motion layers. The results from over 30 sequences (demonstrating both two and three motions) are presented and discussed."
            },
            "slug": "Layered-motion-segmentation-and-depth-ordering-by-Smith-Drummond",
            "title": {
                "fragments": [],
                "text": "Layered motion segmentation and depth ordering by tracking edges"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A hierarchical method of initializing the expectation-maximization algorithm is described, and it is demonstrated that the minimum description length principle may be used to automatically select the best number of motion layers."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145273587"
                        ],
                        "name": "Stephen Gould",
                        "slug": "Stephen-Gould",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Gould",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Gould"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2381913"
                        ],
                        "name": "Tianshi Gao",
                        "slug": "Tianshi-Gao",
                        "structuredName": {
                            "firstName": "Tianshi",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianshi Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6467749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ca434a6eaf5cf4d6e86aca524e753fadb607979",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Object identification and multi-object picture separation are two firmly related processes and it can be enhanced when understood jointly by supporting data from one assignment to the next. Be that as it may, current best in object models are different portrayal for each space creation joint objects and leaving the categorization of numerous part of the scene uncertain. Picture element appearance highlights enable us to do well on classifying formless foundation classes, while the express portrayal of districts encourage the calculation of increasingly complex highlights essential for object detection. Vitally, our model gives a solitary bound together portrayal of the scene we clarify each picture elements of image and authorize it contains in the web between every random variable in our model."
            },
            "slug": "Region-based-Segmentation-and-Object-Detection-Gould-Gao",
            "title": {
                "fragments": [],
                "text": "Region-based Segmentation and Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a hierarchical region-based approach to joint object detection and image segmentation that simultaneously reasons about pixels, regions and objects in a coherent probabilistic model and gives a single unified description of the scene."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2365442"
                        ],
                        "name": "B. Alexe",
                        "slug": "B.-Alexe",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Alexe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Alexe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879646"
                        ],
                        "name": "Thomas Deselaers",
                        "slug": "Thomas-Deselaers",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Deselaers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Deselaers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 57
                            }
                        ],
                        "text": "Recent work in generic object detection (Li et al. 2010; Alexe et al. 2010; Endres and Hoiem 2010) may also be useful for finding boundaries of individual objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 40
                            }
                        ],
                        "text": "Recent work in generic object detection [42, 2, 4] may also be useful for finding boundaries of individual objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11515509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dd55b3bcaf50c1228569d0efe5620a910c1cd07",
            "isKey": false,
            "numCitedBy": 933,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a generic objectness measure, quantifying how likely it is for an image window to contain an object of any class. We explicitly train it to distinguish objects with a well-defined boundary in space, such as cows and telephones, from amorphous background elements, such as grass and road. The measure combines in a Bayesian framework several image cues measuring characteristics of objects, such as appearing different from their surroundings and having a closed boundary. This includes an innovative cue measuring the closed boundary characteristic. In experiments on the challenging PASCAL VOC 07 dataset, we show this new cue to outperform a state-of-the-art saliency measure [17], and the combined measure to perform better than any cue alone. Finally, we show how to sample windows from an image according to their objectness distribution and give an algorithm to employ them as location priors for modern class-specific object detectors. In experiments on PASCAL VOC 07 we show this greatly reduces the number of windows evaluated by class-specific object detectors."
            },
            "slug": "What-is-an-object-Alexe-Deselaers",
            "title": {
                "fragments": [],
                "text": "What is an object?"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A generic objectness measure, quantifying how likely it is for an image window to contain an object of any class, is presented, combining in a Bayesian framework several image cues measuring characteristics of objects, such as appearing different from their surroundings and having a closed boundary."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763321"
                        ],
                        "name": "E. Saund",
                        "slug": "E.-Saund",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Saund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Saund"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 214
                            }
                        ],
                        "text": "This line labeling paradigm has been very influential over the years, with extensions to handle curved objects (e.g., Jain and Aggarwal 1979; Malik 1987) as well as algebraic (Sugihara 1984a, 1984b) and MRF-based (Saund 2006) reformulations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 97
                            }
                        ],
                        "text": ", Jain and Aggarwal 1979; Malik 1987) as well as algebraic (Sugihara 1984a, 1984b) and MRF-based (Saund 2006) reformulations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12264002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "970cd816243f207ff86d7f0aed31bd13643e85dd",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents representation and logic for labeling contrast edges and ridges in visual scenes in terms of both surface occlusion (border ownership) and thinline objects. In natural scenes, thinline objects include sticks and wires, while in human graphical communication thin-lines include connectors, dividers, and other abstract devices. Our analysis is directed at both natural and graphical domains. The basic problem is to formulate the logic of the interactions among local image events, specifically contrast edges, ridges, junctions, and alignment relations, such as to encode the natural constraints among these events in visual scenes. In a sparse heterogeneous Markov Random Field framework, we define a set of interpretation nodes and energy/potential functions among them. The minimum energy configuration found by Loopy Belief Propagation is shown to correspond to preferred human interpretation across a wide range of prototypical examples including important illusory contour figures such as the Kanizsa Triangle, as well as more difficult examples. In practical terms, the approach delivers correct interpretations of inherently ambiguous hand-drawn box-and-connector diagrams at low computational cost."
            },
            "slug": "Logic-and-MRF-Circuitry-for-Labeling-Occluding-and-Saund",
            "title": {
                "fragments": [],
                "text": "Logic and MRF Circuitry for Labeling Occluding and Thinline Visual Contours"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The minimum energy configuration found by Loopy Belief Propagation is shown to correspond to preferred human interpretation across a wide range of prototypical examples including important illusory contour figures such as the Kanizsa Triangle, as well as more difficult examples."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 203
                            }
                        ],
                        "text": "Though this grouping is sometimes performed based on pre-computed affinities (e.g., Shi and Malik 2000), others advocate a gradual approach, such as the hierarchical segmentation techniques developed by Ahuja (1996) and Arbelaez (2006), Arbelaez et al. (2009), which we follow in our approach."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 42408532,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "922224add217ed1400f700459c396575f264e340",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Describes a transform to extract image regions at all geometric and photometric scales. It is argued that linear approaches have the shortcoming that they require a priori models of region shape. The proposed transform avoids this by letting the structure emerge, bottom-up, from interactions among pixels. The transform involves global computations on pairs of pixels followed by vector integration of the results. An attraction force field is computed over the image in which pixels belonging to the same region are mutually attracted and the region is characterized by a convergent flow. It is shown that the transform possesses properties that allow multiscale segmentation, or extraction of original, unblurred structure at all different geometric and photometric scales present. This is in contrast with much previous work wherein multiscale structure is viewed as the smoothed structure in a multiscale signal decimation. Scale is an integral parameter of the force computation, and the number and values of scale parameters associated with the image can be estimated automatically. Regions are detected at all a priori unknown scales resulting in automatic construction of a segmentation tree, in which each pixel is annotated with descriptions of all the regions it belongs to. Transform properties are presented for piecewise-constant images but hold for more general ones. Thus the proposed method is intended as a solution to the problem of multiscale, integrated edge and region detection, or low-level image segmentation. Experimental results are given."
            },
            "slug": "A-Transform-for-Multiscale-Image-Segmentation-by-Ahuja",
            "title": {
                "fragments": [],
                "text": "A Transform for Multiscale Image Segmentation by Integrated Edge and Region Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that the transform possesses properties that allow multiscale segmentation, or extraction of original, unblurred structure at all different geometric and photometric scales present, in contrast with much previous work whereinMultiscale structure is viewed as the smoothed structure in a multiscales signal decimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778133"
                        ],
                        "name": "Pablo Arbel\u00e1ez",
                        "slug": "Pablo-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pablo Arbel\u00e1ez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 47
                            }
                        ],
                        "text": "Our occlusion algorithm outperforms\nGlobal Pb (Maire et al. 2008; Arbelaez et al. 2009) in this task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 76
                            }
                        ],
                        "text": "Finally, we compare our algorithm to Pb (Martin et al. 2004) and Global Pb (Maire et al. 2008) on several external datasets (Sect."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 20
                            }
                        ],
                        "text": "2004) and Global Pb (Maire et al. 2008) on several external datasets (Sect."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 46
                            }
                        ],
                        "text": "Our occlusion algorithm outperforms Global Pb (Maire et al. 2008; Arbelaez et al. 2009) in this task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 62
                            }
                        ],
                        "text": "Comparison algorithms are Pb (Martin et al. 2002), Global Pb (Maire et al. 2008), and an extension of global Pb to an ultrametric contour map (UCM) (Arbelaez et al. 2009), with each trained on BSDS."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 91
                            }
                        ],
                        "text": "By comparison, the full Pb algorithm takes about 660 seconds, and the Global Pb algorithm (Maire et al. 2008) takes 480 seconds per image on the same processor for the same images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 17
                            }
                        ],
                        "text": "2002), Global Pb (Maire et al. 2008), and an extension of global Pb to an ultrametric contour map (UCM) (Arbelaez et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7002261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bb0f3a570936826401b4d1d322725bec3267dce",
            "isKey": true,
            "numCitedBy": 467,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Contours and junctions are important cues for perceptual organization and shape recognition. Detecting junctions locally has proved problematic because the image intensity surface is confusing in the neighborhood of a junction. Edge detectors also do not perform well near junctions. Current leading approaches to junction detection, such as the Harris operator, are based on 2D variation in the intensity signal. However, a drawback of this strategy is that it confuses textured regions with junctions. We believe that the right approach to junction detection should take advantage of the contours that are incident at a junction; contours themselves can be detected by processes that use more global approaches. In this paper, we develop a new high-performance contour detector using a combination of local and global cues. This contour detector provides the best performance to date (F=0.70) on the Berkeley Segmentation Dataset (BSDS) benchmark. From the resulting contours, we detect and localize candidate junctions, taking into account both contour salience and geometric configuration. We show that improvements in our contour model lead to better junctions. Our contour and junction detectors both provide state of the art performance."
            },
            "slug": "Using-contours-to-detect-and-localize-junctions-in-Maire-Arbel\u00e1ez",
            "title": {
                "fragments": [],
                "text": "Using contours to detect and localize junctions in natural images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new high-performance contour detector using a combination of local and global cues that provides the best performance to date on the Berkeley Segmentation Dataset (BSDS) benchmark and shows that improvements in the contour model lead to better junctions."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114833718"
                        ],
                        "name": "Xiaofeng Ren",
                        "slug": "Xiaofeng-Ren",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 173
                            }
                        ],
                        "text": "Some segmentation methods rely on 2D brightness, color, or texture cues to group the image pixels into perceptually similar regions (Shi and Malik 2000; Martin et al. 2001; Ren and Malik 2003; Felzenszwalb and Huttenlocher 2004; Arbelaez 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13571735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a9049a50dfe94fa4473880a9b60c99333ade685",
            "isKey": false,
            "numCitedBy": 1644,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a two-class classification model for grouping. Human segmented natural images are used as positive examples. Negative examples of grouping are constructed by randomly matching human segmentations and images. In a preprocessing stage an image is over-segmented into super-pixels. We define a variety of features derived from the classical Gestalt cues, including contour, texture, brightness and good continuation. Information-theoretic analysis is applied to evaluate the power of these grouping cues. We train a linear classifier to combine these features. To demonstrate the power of the classification model, a simple algorithm is used to randomly search for good segmentations. Results are shown on a wide range of images."
            },
            "slug": "Learning-a-classification-model-for-segmentation-Ren-Malik",
            "title": {
                "fragments": [],
                "text": "Learning a classification model for segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A two-class classification model for grouping is proposed that defines a variety of features derived from the classical Gestalt cues, including contour, texture, brightness and good continuation, and trains a linear classifier to combine these features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4373221"
                        ],
                        "name": "Mukta Prasad",
                        "slug": "Mukta-Prasad",
                        "structuredName": {
                            "firstName": "Mukta",
                            "lastName": "Prasad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mukta Prasad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47139824"
                        ],
                        "name": "A. Fitzgibbon",
                        "slug": "A.-Fitzgibbon",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Fitzgibbon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fitzgibbon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3717791"
                        ],
                        "name": "M. P. Kumar",
                        "slug": "M.-P.-Kumar",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Kumar",
                            "middleNames": [
                                "Pawan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. P. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635540"
                        ],
                        "name": "Philip H. S. Torr",
                        "slug": "Philip-H.-S.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip H. S. Torr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 118
                            }
                        ],
                        "text": "In using surface label classifier outputs as features, we relate to other works on object-based segmentation, such as [56, 36, 20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 118
                            }
                        ],
                        "text": "In using surface label classifier outputs as features, we relate to other works on object-based segmentation, such as Prasad et al. (2006), Kumar et al. (2010), Gould et al. (2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14744188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "484c3bdbd51997344db47517caf61c5e83b13d91",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent research into recognizing object classes (such as humans, cows and hands) has made use of edge features to hypothesize and localize class instances. However, for the most part, these edge-based methods operate solely on the geometric shape of edges, treating them equally and ignoring the fact that for certain object classes, the appearance of the object on the \u201cinside\u201d of the edge may provide valuable recognition cues. \n \nWe show how, for such object classes, small regions around edges can be used to classify the edge into object or non-object. This classifier may then be used to prune edges which are not relevant to the object class, and thereby improve the performance of subsequent processing. We demonstrate learning class specific edges for a number of object classes \u2014 oranges, bananas and bottles \u2014 under challenging scale and illumination variation. \n \nBecause class-specific edge classification provides a low-level analysis of the image it may be integrated into any edge-based recognition strategy without significant change in the high-level algorithms. We illustrate its application to two algorithms: (i) chamfer matching for object detection, and (ii) modulating contrast terms in MRF based object-specific segmentation. We show that performance of both algorithms (matching and segmentation) is considerably improved by the class-specific edge labelling."
            },
            "slug": "Learning-Class-Specific-Edges-for-Object-Detection-Prasad-Zisserman",
            "title": {
                "fragments": [],
                "text": "Learning Class-Specific Edges for Object Detection and Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown how, for certain object classes, small regions around edges can be used to classify the edge into object or non-object, and performance of both algorithms (matching and segmentation) is considerably improved by the class-specific edge labelling."
            },
            "venue": {
                "fragments": [],
                "text": "ICVGIP"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1878233,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "576f7e5b6face59552cacf038ac929f77ddf5bdd",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a Bayesian framework for representing and recognizing local image motion in terms of two primitive models: translation and motion discontinuity. Motion discontinuities are represented using a nonlinear generative model that explicitly encodes the orientation of the boundary, the velocities on either side, the motion of the occluding edge over time, and the appearance/disappearance of pixels at the boundary. We represent the posterior distribution over the model parameters given the image data using discrete samples. This distribution is propagated over time using the Condensation algorithm. To efficiently represent such a high-dimensional space we initialize samples using the responses of a low-level motion discontinuity detector."
            },
            "slug": "Probabilistic-detection-and-tracking-of-motion-Black-Fleet",
            "title": {
                "fragments": [],
                "text": "Probabilistic detection and tracking of motion discontinuities"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A Bayesian framework for representing and recognizing local image motion in terms of two primitive models: translation and motion discontinuity is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143787583"
                        ],
                        "name": "Ali Farhadi",
                        "slug": "Ali-Farhadi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Farhadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Farhadi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831988"
                        ],
                        "name": "Ian Endres",
                        "slug": "Ian-Endres",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Endres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian Endres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14171860,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "5d33a10752af9ea30993139ac6e3a323992a5831",
            "isKey": false,
            "numCitedBy": 212,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach to find and describe objects within broad domains. We introduce a new dataset that provides annotation for sharing models of appearance and correlation across categories. We use it to learn part and category detectors. These serve as the visual basis for an integrated model of objects. We describe objects by the spatial arrangement of their attributes and the interactions between them. Using this model, our system can find animals and vehicles that it has not seen and infer attributes, such as function and pose. Our experiments demonstrate that we can more reliably locate and describe both familiar and unfamiliar objects, compared to a baseline that relies purely on basic category detectors."
            },
            "slug": "Attribute-centric-recognition-for-cross-category-Farhadi-Endres",
            "title": {
                "fragments": [],
                "text": "Attribute-centric recognition for cross-category generalization"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work introduces a new dataset that provides annotation for sharing models of appearance and correlation across categories and uses it to learn part and category detectors that serve as the visual basis for an integrated model of objects."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401830631"
                        ],
                        "name": "A. Guzm\u00e1n-Arenas",
                        "slug": "A.-Guzm\u00e1n-Arenas",
                        "structuredName": {
                            "firstName": "Adolfo",
                            "lastName": "Guzm\u00e1n-Arenas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Guzm\u00e1n-Arenas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409105282"
                        ],
                        "name": "Adolfo Guzmaan",
                        "slug": "Adolfo-Guzmaan",
                        "structuredName": {
                            "firstName": "Adolfo",
                            "lastName": "Guzmaan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adolfo Guzmaan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 125
                            }
                        ],
                        "text": "T-junctions, which occur when one boundary ends on another boundary, have long been used as evidence for an occlusion event (Guzman 1968)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "T-junctions, which occur when one boundary ends on another boundary, have long been used as evidence for an occlusion event [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 138
                            }
                        ],
                        "text": "In the domain of simple polyhedral objects, Guzman in 1968 proposed an elegant algorithm for assigning occlusion labels to line segments (Guzman 1968)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "In the domain of simple polyhedral objects, Guzman in 1968 proposed an elegant algorithm for assigning occlusion labels to line segments [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61206632,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "bce627694465755be2f107c1a53e5b6a9515f417",
            "isKey": true,
            "numCitedBy": 172,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Methods are presented 1) to partition or decompose a visual scene into the bodies forming it; 2) to position these bodies in three-dimensional space, by combining two scenes that make a stereoscopic pair; 3) to find the regions or zones of a visual scene that belong to its background; 4) to carry out the isolation of the objects in 1) when the input has inaccuracies. Running computer programs implement the methods and many examples illustrate their behavior. The input is a two-dimensional line-drawing of the scene, assumed to contain three-dimensional bodies possessing flat faces (polyhedra); some of them may be partially occluded. Suggestions are made for extending the work to curved objects. Some comparisons are made with human visual perception. The main conclusion is that it is possible to separate a picture or scene into the constituent objects exclusively on the basis of monocular geometric properties (on the basis of pure form); in fact, successful methods are shown."
            },
            "slug": "COMPUTER-RECOGNITION-OF-THREE-DIMENSIONAL-OBJECTS-A-Guzm\u00e1n-Arenas-Guzmaan",
            "title": {
                "fragments": [],
                "text": "COMPUTER RECOGNITION OF THREE-DIMENSIONAL OBJECTS IN A VISUAL SCENE"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The main conclusion is that it is possible to separate a picture or scene into the constituent objects exclusively on the basis of monocular geometric properties (onThe basis of pure form); in fact, successful methods are shown."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 160
                            }
                        ],
                        "text": "\u2026can be done based on the local surface near the boundary (Vaillant and Faugeras 1992), the difference of the motion estimates on either sides of the boundary (Black and Fleet 2000; Smith et al. 2004; Stein et al. 2007), or the responses of spatio-temporal filters (Stein and Hebert 2006a, 2006b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14328363,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11498be697a1ed7c78b5369c6326f5fa2ac77ddb",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a Bayesian framework for representing and recognizing local image motion in terms of two basic models: translational motion and motion boundaries. Motion boundaries are represented using a non-linear generative model that explicitly encodes the orientation of the boundary, the velocities on either side, the motion of the occluding edge over time, and the appearance/disappearance of pixels at the boundary. We represent the posterior probability distribution over the model parameters given the image data using discrete samples. This distribution is propagated over time using a particle filtering algorithm. To efficiently represent such a high-dimensional space we initialize samples using the responses of a low-level motion discontinuity detector. The formulation and computational model provide a general probabilistic framework for motion estimation with multiple, non-linear, models."
            },
            "slug": "Probabilistic-Detection-and-Tracking-of-Motion-Black-Fleet",
            "title": {
                "fragments": [],
                "text": "Probabilistic Detection and Tracking of Motion Boundaries"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A Bayesian framework for representing and recognizing local image motion in terms of translational motion and motion boundaries is proposed, which provides a general probabilistic framework for motion estimation with multiple, non-linear, models."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 55
                            }
                        ],
                        "text": "The approach, fully developed by Waltz [75] and others [11, 28, 29, 34, 14], defines a set of possible line labels (convex, concave, and occluding) and a set of allowed vertex types (T-junctions, L-junctions, etc)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 91
                            }
                        ],
                        "text": "The approach, fully developed by Waltz (1975) and others (Clowes 1971; Huffman 1971, 1977; Kanade 1980; Draper 1981), defines a set of possible line labels (convex, concave, and occluding) and a set of allowed vertex types (T-junctions, L-junctions, etc.)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6117451,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5732ad4b2e63b4bc322d2893188fba8728fd61b4",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Theory-of-Origami-World-Kanade",
            "title": {
                "fragments": [],
                "text": "A Theory of Origami World"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792404"
                        ],
                        "name": "J. Elder",
                        "slug": "J.-Elder",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Elder",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698824"
                        ],
                        "name": "S. Zucker",
                        "slug": "S.-Zucker",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Zucker",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Zucker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2944269,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "018a317f615c51e060ab3dc330e282eed917c8d5",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Existing methods for grouping edges on the basis of local smoothness measures fail to compute complete contours in natural images: it appears that a stronger global constraint is required. Motivated by growing evidence that the human visual system exploits contour closure for the purposes of perceptual grouping [6, 7, 14, 15, 25], we present an algorithm for computing highly closed bounding contours from images. Unlike previous algorithms [11, 18, 26], no restrictions are placed on the type of structure bounded or its shape. Contours are represented locally by tangent vectors, augmented by image intensity estimates. A Bayesian model is developed for the likelihood that two tangent vectors form contiguous components of the same contour. Based on this model, a sparsely-connected graph is constructed, and the problem of computing closed contours is posed as the computation of shortest-path cycles in this graph. We show that simple tangent cycles can be efficiently computed in natural images containing many local ambiguities, and that these cycles generally correspond to bounding contours in the image. These closure computations can potentially complement region-grouping methods by extending the class of structures segmented to include heterogeneous structures."
            },
            "slug": "Computing-Contour-Closure-Elder-Zucker",
            "title": {
                "fragments": [],
                "text": "Computing Contour Closure"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that simple tangent cycles can be efficiently computed in natural images containing many local ambiguities, and that these cycles generally correspond to bounding contours in the image."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48749954"
                        ],
                        "name": "Liangliang Cao",
                        "slug": "Liangliang-Cao",
                        "structuredName": {
                            "firstName": "Liangliang",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liangliang Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7137861"
                        ],
                        "name": "Jianzhuang Liu",
                        "slug": "Jianzhuang-Liu",
                        "structuredName": {
                            "firstName": "Jianzhuang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianzhuang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50295995"
                        ],
                        "name": "Xiaoou Tang",
                        "slug": "Xiaoou-Tang",
                        "structuredName": {
                            "firstName": "Xiaoou",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoou Tang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6371621,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7295677681bf0b56305964fac000fc4fda6ab21",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The human vision system can interpret a single 2D line drawing as a 3D object without much difficulty even if the hidden lines of the object are invisible. Several reconstruction approaches have tried to emulate this ability, but they cannot recover the complete object if the hidden lines of the object are not shown. This paper proposes a novel approach for reconstructing complete 3D objects from line drawings without hidden lines. First, we develop some constraints and properties for the inference of the topology of the invisible edges and vertices of an object. Then we present a reconstruction method based on perceptual symmetry and planarity of the object. We give a number of examples to demonstrate the ability of our approach."
            },
            "slug": "3D-object-reconstruction-from-a-single-2D-line-Cao-Liu",
            "title": {
                "fragments": [],
                "text": "3D object reconstruction from a single 2D line drawing without hidden lines"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "First, some constraints and properties for the inference of the topology of the invisible edges and vertices of an object are developed, and then a reconstruction method based on perceptual symmetry and planarity of the object is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751698"
                        ],
                        "name": "K. Sugihara",
                        "slug": "K.-Sugihara",
                        "structuredName": {
                            "firstName": "Kokichi",
                            "lastName": "Sugihara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sugihara"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35814199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3662ee5c687d85164eeac402da7258a633dca948",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Algebraic-Approach-to-Shape-from-Image-Problems-Sugihara",
            "title": {
                "fragments": [],
                "text": "An Algebraic Approach to Shape-from-Image Problems"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32235446,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "af7b47f8fd7a97a39df2442f45dd4b2a36b9c1d1",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm is presented that finds all convex sets of line segments in an image, such that the length of the line segments account for at least some fixed proportion of the length of the convex hull. This enables the algorithm to find convex groups whose contours are partially occluded or missing due to noise. An expected time analysis of the algorithm's performance is performed, together with experiments on real images that show that the algorithm is efficient and that tell when the groups found are unlikely to occur at random, and are likely to capture the underlying structure of a scene.<<ETX>>"
            },
            "slug": "Robust-and-efficient-detection-of-convex-groups-Jacobs",
            "title": {
                "fragments": [],
                "text": "Robust and efficient detection of convex groups"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An algorithm is presented that finds all convex sets of line segments in an image, such that the length of the line segments account for at least some fixed proportion of thelength of the convex hull, which enables the algorithm to find convex groups whose contours are partially occluded or missing due to noise."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 142
                            }
                        ],
                        "text": "This line labeling paradigm has been very influential over the years, with extensions to handle curved objects (e.g., Jain and Aggarwal 1979; Malik 1987) as well as algebraic (Sugihara 1984a, 1984b) and MRF-based (Saund 2006) reformulations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11045251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4f8599c040dfd4876d9a5d99545b35b6a4e7a57",
            "isKey": false,
            "numCitedBy": 199,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we study the problem of interpreting line drawings of scenes composed of opaque regular solid objects bounded by piecewise smooth surfaces with no markings or texture on them. It is assumed that the line drawing has been formed by orthographic projection of such a scene under general viewpoint, that the line drawing is error free, and that there are no lines due to shadows or specularities. Our definition implicitly excludes laminae, wires, and the apices of cones.A major component of the interpretation of line drawings is line labelling. By line labelling we mean (a) classification of each image curve as corresponding to either a depth or orientation discontinuity in the scene, and (b) further subclassification of each kind of discontinuity. For a depth discontinuity we determine whether it is a limb\u2014a locus of points on the surface where the line of sight is tangent to the surface\u2014or an occluding edge\u2014a tangent plane discontinuity of the surface. For an orientation discontinuity, we determine whether it corresponds to a convex or concave edge. This paper presents the first mathematically rigorous scheme for labelling line drawings of the class of scenes described. Previous schemes for labelling line drawings of scenes containing curved objects were heuristic, incomplete, and lacked proper mathematical justification.By analyzing the projection of the neighborhoods of different kinds of points on a piecewise smooth surface, we are able to catalog all local labelling possibilities for the different types of junctions in a line drawing. An algorithm is developed which utilizes this catalog to determine all legal labellings of the line drawing. A local minimum complexity rule\u2014at each vertex select those labellings which correspond to the minimum number of faces meeting at the vertex\u2014is used in order to prune highly counter-intuitive interpretations. The labelling scheme was implemented and tested on a number of line drawings. The labellings obtained are few and by and large in accordance with human interpretations."
            },
            "slug": "Interpreting-line-drawings-of-curved-objects-Malik",
            "title": {
                "fragments": [],
                "text": "Interpreting line drawings of curved objects"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents the first mathematically rigorous scheme for labelling line drawings of the class of scenes described, which is able to catalog all local labelling possibilities for the different types of junctions in a line drawing."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938732"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705627"
                        ],
                        "name": "J. Aggarwal",
                        "slug": "J.-Aggarwal",
                        "structuredName": {
                            "firstName": "Jake",
                            "lastName": "Aggarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aggarwal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9681477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9f33fce77bc4c73f6644f6cc3a50f1facf7845c",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Most research efforts in scene analysis have concentrated on the analysis of block-world scenes. Having developed a good understanding of this limited world of computer vision, researchers are now trying to make computers see curved objects also. This paper presents an overview of the techniques developed for segmentation, representation, and recognition of curved objects in two-dimensional images and in three-dimensional scenes. The possible future directions of research are also discussed."
            },
            "slug": "Computer-analysis-of-scenes-with-curved-objects-Jain-Aggarwal",
            "title": {
                "fragments": [],
                "text": "Computer analysis of scenes with curved objects"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An overview of the techniques developed for segmentation, representation, and recognition of curved objects in two-dimensional images and in three-dimensional scenes is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 120
                            }
                        ],
                        "text": "The affinities are based on computational realizations of the Gestalt principles of continuation, proximity and closure [76, 44, 15, 22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 138
                            }
                        ],
                        "text": "The affinities are based on computational realizations of the Gestalt principles of continuation, proximity and closure (Wertheimer 1938; Lowe 1985; Elder and Zucker 1996; Herault and Horaud 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60449135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27ce5a120a86632dd56f869ee65656b7d7312a3a",
            "isKey": false,
            "numCitedBy": 846,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A computational model is presented for the visual recognition of three-dimensional objects based upon their spatial correspondence with two-dimensional features in an image. A number of components of this model are developed in further detail and implemented as computer algorithms. At the highest level, a verification process has been developed which can determine exact values of viewpoint and object parameters from hypothesized matches between three-dimensional object features and two-dimensional image features. This provides a reliable quantitative procedure for evaluating the correctness of an interpretation, even in the presence of noise or occlusion. Given a reliable method for final evaluation of correspondence, the remaining components of the system are aimed at reducing the size of the search space which must be covered. Unlike many previous approaches, this recognition process does not assume that it is possible to directly derive depth information from the image. Instead, the primary descriptive component is a process of perceptual organization, in which spatial relations are detected directly among two-dimensional image features. A basic requirement of the recognition process is that perceptual organization should accurately distinguish meaningful groupings from those which arise by accident of viewpoint or position. This requirement is used to derive a number of further constraints which must be satisfied by algorithms for perceptual grouping. A specific algorithm is presented for the problem of segmenting curves into natural descriptions. Methods are also presented for using the viewpoint-invariance properties of the perceptual groupings to infer three-dimensional relations directly from the image. The search process itself is described, both for covering the range of possible viewpoints and the range of possible objects. A method is presented for using evidential reasoning to combine information from multiple sources to determine the most efficient ordering for the search. This use of evidential reasoning allows a system to automatically improve its performance as it gains visual experience. In summary, spatial organization and recognition are shown to be a practical basis for current systems and to provide a promising path for further development of improved visual capabilities."
            },
            "slug": "Perceptual-Organization-and-Visual-Recognition-Lowe",
            "title": {
                "fragments": [],
                "text": "Perceptual Organization and Visual Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Spatial organization and recognition are shown to be a practical basis for current systems and to provide a promising path for further development of improved visual capabilities."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144891282"
                        ],
                        "name": "David R. Martin",
                        "slug": "David-R.-Martin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Martin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082299938"
                        ],
                        "name": "D. Tal",
                        "slug": "D.-Tal",
                        "structuredName": {
                            "firstName": "Doron",
                            "lastName": "Tal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 153
                            }
                        ],
                        "text": "Some segmentation methods rely on 2D brightness, color, or texture cues to group the image pixels into perceptually similar regions (Shi and Malik 2000; Martin et al. 2001; Ren and Malik 2003; Felzenszwalb and Huttenlocher 2004; Arbelaez 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 276
                            }
                        ],
                        "text": "\u2026rely on 2D perceptual grouping cues, the boundaries of such segmentations could be due to reflectance, illumination or material discontinuities, as well as occlusions, and resulting regions often do not correspond to actual objects (see Berkeley Segmentation Dataset (BSDS), Martin et al. 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 64193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a1ed876196ec9733acb1daa6d65e35ff0414291",
            "isKey": false,
            "numCitedBy": 6039,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a database containing 'ground truth' segmentations produced by humans for images of a wide variety of natural scenes. We define an error measure which quantifies the consistency between segmentations of differing granularities and find that different human segmentations of the same image are highly consistent. Use of this dataset is demonstrated in two applications: (1) evaluating the performance of segmentation algorithms and (2) measuring probability distributions associated with Gestalt grouping factors as well as statistics of image region properties."
            },
            "slug": "A-database-of-human-segmented-natural-images-and-to-Martin-Fowlkes",
            "title": {
                "fragments": [],
                "text": "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A database containing 'ground truth' segmentations produced by humans for images of a wide variety of natural scenes is presented and an error measure is defined which quantifies the consistency between segmentations of differing granularities."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758056"
                        ],
                        "name": "A. Stein",
                        "slug": "A.-Stein",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Stein",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 266
                            }
                        ],
                        "text": "\u2026can be done based on the local surface near the boundary (Vaillant and Faugeras 1992), the difference of the motion estimates on either sides of the boundary (Black and Fleet 2000; Smith et al. 2004; Stein et al. 2007), or the responses of spatio-temporal filters (Stein and Hebert 2006a, 2006b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 196
                            }
                        ],
                        "text": "This can be done based on the local surface near the boundary [73], the difference of the motion estimates on either sides of the boundary [8, 66, 70], or the responses of spatio-temporal filters [68, 69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1959254,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "309fa13708c2d9e11b546ef359c12b789f96dbcb",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an extension to ordinary patch-based edge detection in images using spatio-temporal volumetric patches from video. The inclusion of temporal information enables us to estimate motion normal to edges in addition to edge strength and spatial orientation. The method can handle complex edges in clutter by comparing distributions of data on either half of an extracted patch, rather than modeling the intensity profile of the edge. An efficient approach is provided for building the necessary histograms which samples candidate edge orientations and motions. Results are compared to classical spatio-temporal filtering techniques."
            },
            "slug": "Using-Spatio-Temporal-Patches-for-Simultaneous-of-Stein-Hebert",
            "title": {
                "fragments": [],
                "text": "Using Spatio-Temporal Patches for Simultaneous Estimation of Edge Strength, Orientation, and Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An extension to ordinary patch-based edge detection in images using spatio-temporal volumetric patches from video that can handle complex edges in clutter by comparing distributions of data on either half of an extracted patch, rather than modeling the intensity profile of the edge."
            },
            "venue": {
                "fragments": [],
                "text": "2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47953439"
                        ],
                        "name": "R\u00e9gis Vaillant",
                        "slug": "R\u00e9gis-Vaillant",
                        "structuredName": {
                            "firstName": "R\u00e9gis",
                            "lastName": "Vaillant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9gis Vaillant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 63
                            }
                        ],
                        "text": "This can be done based on the local surface near the boundary (Vaillant and Faugeras 1992), the difference of the motion estimates on either sides of the boundary (Black and Fleet 2000; Smith et al. 2004; Stein et al. 2007), or the responses of spatio-temporal filters (Stein and Hebert 2006a,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 62
                            }
                        ],
                        "text": "This can be done based on the local surface near the boundary (Vaillant and Faugeras 1992), the difference of the motion estimates on either sides of the boundary (Black and Fleet 2000; Smith et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27552136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f1ca567b810781ef129e2a382ccbb5c09fea7a5",
            "isKey": false,
            "numCitedBy": 235,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The extremal boundaries, of 3-D curved objects are the images of special curves drawn on the object and are called rims. They are viewpoint dependent and characterized by the fact that the optical rays of their points are tangential to the surface of the object. The mathematics of the relationship between the extremal boundaries and the surface of the object is studied. This study makes it possible to design an algorithm for detecting those boundaries in the images that are likely to be extremal. Once this has been done, one can reconstruct the rims and compute the differential properties of the surface of the object along them up to the second order. If a qualitative description is sufficient, the sign of the Gaussian curvature of the surface along the rim can be computed in a much simpler way. Experimental results are presented on synthetic and real images. The work provides a better understanding of the relationship between the apparent and real shape of a 3-D object as well as algorithms for reconstructing the local shape of such an object along the rims. >"
            },
            "slug": "Using-Extremal-Boundaries-for-3-D-Object-Modeling-Vaillant-Faugeras",
            "title": {
                "fragments": [],
                "text": "Using Extremal Boundaries for 3-D Object Modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This study makes it possible to design an algorithm for detecting boundaries in the images that are likely to be extremal, and provides a better understanding of the relationship between the apparent and real shape of a 3-D object as well as algorithms for reconstructing the local shape of such an object along the rims."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4246903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82635fb63640ae95f90ee9bdc07832eb461ca881",
            "isKey": false,
            "numCitedBy": 11693,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection.This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension."
            },
            "slug": "The-Pascal-Visual-Object-Classes-(VOC)-Challenge-Everingham-Gool",
            "title": {
                "fragments": [],
                "text": "The Pascal Visual Object Classes (VOC) Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The state-of-the-art in evaluated methods for both classification and detection are reviewed, whether the methods are statistically different, what they are learning from the images, and what the methods find easy or confuse."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2324658"
                        ],
                        "name": "Josh H. McDermott",
                        "slug": "Josh-H.-McDermott",
                        "structuredName": {
                            "firstName": "Josh",
                            "lastName": "McDermott",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josh H. McDermott"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "In fact, recent psychophysics experiments [52] suggest that T-junctions may not be the cause of occlusion percepts, but rather their byproduct."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 43
                            }
                        ],
                        "text": "In fact, recent psychophysics experiments (McDermott 2004) suggest that T-junctions may not be the cause of occlusion percepts, but rather their byproduct."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16339187,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "45e394ca6bd6485a0cd69ca01e4a6724d4a24aac",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Junctions, formed at the intersection of image contours, are thought to play an important and early role in vision. The interest in junctions can be attributed in part to the notion that they are local image features that are easy to detect but that nonetheless provide valuable information about important events in the world, such as occlusion and transparency. Here I test the notion that there are locally defined junctions in real images that might be detected with simple, early visual mechanisms. Human observers were used as a tool to measure the visual information available in local regions of real images. One set of observers was made to label all the points in a set of real images where one edge occluded another. A second set of observers was presented with variable-size circular subregions of these images, and was asked to judge whether the regions were centered on an occlusion point. This task is easy if junctions are visible, but I found performance to be poor for small regions, not approaching ceiling levels until observers were given fairly large (approximately 50 pixels in diameter) regions over which to make the judgment. Control experiments ruled out the possibility that the effects are just due to junctions at multiple scales. Experiments reported here suggest that, although some junctions in real images are locally defined and can be detected with simple mechanisms, a substantial fraction necessitate the use of more complex and global processes. This raises the possibility that junctions in such cases may not be detected prior to scene interpretation."
            },
            "slug": "Psychophysics-with-junctions-in-real-images.-McDermott",
            "title": {
                "fragments": [],
                "text": "Psychophysics with junctions in real images."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experiments reported here suggest that, although some junctions in real images are locally defined and can be detected with simple mechanisms, a substantial fraction necessitate the use of more complex and global processes, and raises the possibility that junications in such cases may not be detected prior to scene interpretation."
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831988"
                        ],
                        "name": "Ian Endres",
                        "slug": "Ian-Endres",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Endres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian Endres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 76
                            }
                        ],
                        "text": "Recent work in generic object detection (Li et al. 2010; Alexe et al. 2010; Endres and Hoiem 2010) may also be useful for finding boundaries of individual objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 697224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0640da2565bad7037d969e9f07276c10102083d",
            "isKey": false,
            "numCitedBy": 495,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a category-independent method to produce a bag of regions and rank them, such that top-ranked regions are likely to be good segmentations of different objects. Our key objectives are completeness and diversity: every object should have at least one good proposed region, and a diverse set should be top-ranked. Our approach is to generate a set of segmentations by performing graph cuts based on a seed region and a learned affinity function. Then, the regions are ranked using structured learning based on various cues. Our experiments on BSDS and PASCAL VOC 2008 demonstrate our ability to find most objects within a small bag of proposed regions."
            },
            "slug": "Category-Independent-Object-Proposals-Endres-Hoiem",
            "title": {
                "fragments": [],
                "text": "Category Independent Object Proposals"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A category-independent method to produce a bag of regions and rank them, such that top-ranked regions are likely to be good segmentations of different objects, and the ability to find most objects within a small bag of proposed regions is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 147
                            }
                        ],
                        "text": "Alternatively, a global solution can be reached by finding a dominant component in the graph with spectral methods (Sarkar and Soundararajan 2000; Perona and Freeman 1998; Leung and Malik 1998; Mahamud et al. 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12973477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23d31d6c75a3c62ee2cedd22308c5c0ba34217e7",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The foreground group in a scene may be \u2018discovered\u2019 and computed as a factorized approximation to the pairwise affinity of the elements in the scene. A pointwise approximation of the pairwise affinity information may in fact be interpreted as a \u2018saliency\u2019 index, and the foreground of the scene may be obtained by thresholding it. An algorithm called \u2018affinity factorization\u2019 is thus obtained which may be used for grouping."
            },
            "slug": "A-Factorization-Approach-to-Grouping-Perona-Freeman",
            "title": {
                "fragments": [],
                "text": "A Factorization Approach to Grouping"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "The foreground group in a scene may be \u2018discovered\u2019 and computed as a factorized approximation to the pairwise affinity of the elements in the scene, and an algorithm called \u2018affinity factorization\u2019 is obtained which may be used for grouping."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807482"
                        ],
                        "name": "Timoth\u00e9e Cour",
                        "slug": "Timoth\u00e9e-Cour",
                        "structuredName": {
                            "firstName": "Timoth\u00e9e",
                            "lastName": "Cour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timoth\u00e9e Cour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2475859"
                        ],
                        "name": "F. B\u00e9n\u00e9zit",
                        "slug": "F.-B\u00e9n\u00e9zit",
                        "structuredName": {
                            "firstName": "Florence",
                            "lastName": "B\u00e9n\u00e9zit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. B\u00e9n\u00e9zit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6830366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b820164b7597c186232e90f076b95382a36ed0c",
            "isKey": false,
            "numCitedBy": 615,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a multiscale spectral image segmentation algorithm. In contrast to most multiscale image processing, this algorithm works on multiple scales of the image in parallel, without iteration, to capture both coarse and fine level details. The algorithm is computationally efficient, allowing to segment large images. We use the normalized cut graph partitioning framework of image segmentation. We construct a graph encoding pairwise pixel affinity, and partition the graph for image segmentation. We demonstrate that large image graphs can be compressed into multiple scales capturing image structure at increasingly large neighborhood. We show that the decomposition of the image segmentation graph into different scales can be determined by ecological statistics on the image grouping cues. Our segmentation algorithm works simultaneously across the graph scales, with an inter-scale constraint to ensure communication and consistency between the segmentations at each scale. As the results show, we incorporate long-range connections with linear-time complexity, providing high-quality segmentations efficiently. Images that previously could not be processed because of their size have been accurately segmented thanks to this method."
            },
            "slug": "Spectral-segmentation-with-multiscale-graph-Cour-B\u00e9n\u00e9zit",
            "title": {
                "fragments": [],
                "text": "Spectral segmentation with multiscale graph decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The segmentation algorithm works simultaneously across the graph scales, with an inter-scale constraint to ensure communication and consistency between the segmentations at each scale, and incorporates long-range connections with linear-time complexity, providing high-quality segmentations efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98095377"
                        ],
                        "name": "Ian H. Jermyn",
                        "slug": "Ian-H.-Jermyn",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Jermyn",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian H. Jermyn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66193516"
                        ],
                        "name": "H. Ishikawa",
                        "slug": "H.-Ishikawa",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Ishikawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ishikawa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3557447,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a156e15812ab648e0f455f08dbe50c3cdffade48",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new form of energy functional for the modeling and identification of regions in images. The energy is defined on the space of boundaries in the image domain and can incorporate very general combinations of modeling information both from the boundary (intensity gradients, etc.) and from the interior of the region (texture, homogeneity, etc.). We describe two polynomial-time digraph algorithms for finding the global minima of this energy. One of the algorithms is completely general, minimizing the functional for any choice of modeling information. It runs in a few seconds on a 256/spl times/256 image. The other algorithm applies to a subclass of functionals, but has the advantage of being extremely parallelizable. Neither algorithm requires initialization."
            },
            "slug": "Globally-Optimal-Regions-and-Boundaries-as-Minimum-Jermyn-Ishikawa",
            "title": {
                "fragments": [],
                "text": "Globally Optimal Regions and Boundaries as Minimum Ratio Weight Cycles"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new form of energy functional is described that is defined on the space of boundaries in the image domain and can incorporate very general combinations of modeling information both from the boundary and from the interior of the region."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 275
                            }
                        ],
                        "text": "\u2026iterations, we set the threshold for the hierarchical segmentation to a conservative value corresponding to an \u201cacceptable\u201d level of pixel error in the training set (1.5%, 2%, respectively), as is typically done in cascade algorithms such as Viola and Jones object detection (Viola and Jones 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 107
                            }
                        ],
                        "text": "5%, 2%, respectively), as is typically done in cascade algorithms such as Viola and Jones object detection (Viola and Jones 2004)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2796017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b09ec0b350f8352bce46a2f5bf7ae97c83a7b9ca",
            "isKey": true,
            "numCitedBy": 11227,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second."
            },
            "slug": "Robust-Real-Time-Face-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-Time Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new image representation called the \u201cIntegral Image\u201d is introduced which allows the features used by the detector to be computed very quickly and a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393626964"
                        ],
                        "name": "I. Kov\u00e1cs",
                        "slug": "I.-Kov\u00e1cs",
                        "structuredName": {
                            "firstName": "Ilona",
                            "lastName": "Kov\u00e1cs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kov\u00e1cs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326400"
                        ],
                        "name": "B. Julesz",
                        "slug": "B.-Julesz",
                        "structuredName": {
                            "firstName": "B\u00e9la",
                            "lastName": "Julesz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Julesz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "Early computer vision successes in image understanding, such as Roberts\u2019 blocks world (Roberts 1965), encouraged interest in occlusion reasoning as a key component for a complete scene analysis system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 117
                            }
                        ],
                        "text": "Other segmentation methods are based on the observation that many objects are delineated by closed, smooth contours (Kovacs and Julesz 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 189925,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "8f28efa8aefbe0ac8592199e1e9a530f3d7b1f2c",
            "isKey": false,
            "numCitedBy": 548,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Detection of fragmented closed contours against a cluttered background occurs much beyond the local coherence distance (maximal separation between segments) of nonclosed contours. This implies that the extent of interaction between locally connected detectors is boosted according to the global stimulus structure. We further show that detection of a target probe is facilitated when the probe is positioned inside a closed circle. To explain the striking contour segregation ability found here, and performance enhancement inside closed boundaries, we propose the existence of a synergetic process in early vision."
            },
            "slug": "A-closed-curve-is-much-more-than-an-incomplete-one:-Kov\u00e1cs-Julesz",
            "title": {
                "fragments": [],
                "text": "A closed curve is much more than an incomplete one: effect of closure in figure-ground segmentation."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The existence of a synergetic process in early vision is proposed, and the striking contour segregation ability found here, and performance enhancement inside closed boundaries are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 172
                            }
                        ],
                        "text": "Alternatively, a global solution can be reached by finding a dominant component in the graph with spectral methods (Sarkar and Soundararajan 2000; Perona and Freeman 1998; Leung and Malik 1998; Mahamud et al. 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12168498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1ca62714f8086af1d7be12aa0cb6d9c25bf4bcd",
            "isKey": false,
            "numCitedBy": 189,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Region-based image segmentation techniques make use of similarity in intensity, color and texture to determine the partitioning of an image. The powerful cue of contour continuity is not exploited at all. In this paper, we provide a way of incorporating curvilinear grouping into region-based image segmentation. Soft contour information is obtained through orientation energy. Weak contrast gaps and subjective contours are completed by contour propagation. The normalized cut approach proposed by Shi and Malik is used for the segmentation. Results on a large variety of images are shown."
            },
            "slug": "Contour-Continuity-in-Region-Based-Image-Leung-Malik",
            "title": {
                "fragments": [],
                "text": "Contour Continuity in Region Based Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A way of incorporating curvilinear grouping into region-based image segmentation through normalized cut approach and results on a large variety of images are shown."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145306925"
                        ],
                        "name": "Sudeep Sarkar",
                        "slug": "Sudeep-Sarkar",
                        "structuredName": {
                            "firstName": "Sudeep",
                            "lastName": "Sarkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sudeep Sarkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47007842"
                        ],
                        "name": "P. Soundararajan",
                        "slug": "P.-Soundararajan",
                        "structuredName": {
                            "firstName": "Padmanabhan",
                            "lastName": "Soundararajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Soundararajan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 115
                            }
                        ],
                        "text": "Alternatively, a global solution can be reached by finding a dominant component in the graph with spectral methods [67, 55, 41, 45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15510471,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d35466e273e481364f07028d0cc5f89d8d176956",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "Perceptual organization offers an elegant framework to group low-level features that are likely to come from a single object. We offer a novel strategy to adapt this grouping process to objects in a domain. Given a set of training images of objects in context, the associated learning process decides on the relative importance of the basic salient relationships such as proximity, parallelness, continuity, junctions, and common region toward segregating the objects from the background. The parameters of the grouping process are cast as probabilistic specifications of Bayesian networks that need to be learned. This learning is accomplished using a team of stochastic automata in an N-player cooperative game framework. The grouping process, which is based on graph partitioning is able to form large groups from relationships defined over a small set of primitives and is fast. We statistically demonstrate the robust performance of the grouping and the learning frameworks on a variety of real images. Among the interesting conclusions is the significant role of photometric attributes in grouping and the ability to form large salient groups from a set of local relations, each defined over a small number of primitives."
            },
            "slug": "Supervised-Learning-of-Large-Perceptual-Graph-and-Sarkar-Soundararajan",
            "title": {
                "fragments": [],
                "text": "Supervised Learning of Large Perceptual Organization: Graph Spectral Partitioning and Learning Automata"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel strategy to adapt this grouping process to objects in a domain and the significant role of photometric attributes in grouping and the ability to form large salient groups from a set of local relations, each defined over a small number of primitives are offered."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747909"
                        ],
                        "name": "Hod Lipson",
                        "slug": "Hod-Lipson",
                        "structuredName": {
                            "firstName": "Hod",
                            "lastName": "Lipson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hod Lipson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807416"
                        ],
                        "name": "M. Shpitalni",
                        "slug": "M.-Shpitalni",
                        "structuredName": {
                            "firstName": "Moshe",
                            "lastName": "Shpitalni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shpitalni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 247
                            }
                        ],
                        "text": "\u2026can mimic human 3D interpretation of line drawings, motivating others to formulate the 3D interpretation problem as optimization over an objective function that favors planarity, symmetry, and other \u201cnatural\u201d properties (Leclerc and Fischler 1992; Lipson and Shpitalni 1996; Shoji et al. 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 366,
                                "start": 293
                            }
                        ],
                        "text": "Marill (1991) observes that optimization of a global numerical criterion can mimic human 3D interpretation of line drawings, motivating others to formulate the 3D interpretation problem as optimization over an objective function that favors planarity, symmetry, and other \u201cnatural\u201d properties (Leclerc and Fischler 1992; Lipson and Shpitalni 1996; Shoji et al. 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11640214,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe24cdb641d70b2f39a18b8945dcd5647216f7b0",
            "isKey": false,
            "numCitedBy": 189,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimization-based-reconstruction-of-a-3D-object-a-Lipson-Shpitalni",
            "title": {
                "fragments": [],
                "text": "Optimization-based reconstruction of a 3D object from a single freehand line drawing"
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729041"
                        ],
                        "name": "J. Canny",
                        "slug": "J.-Canny",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Canny",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Canny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13284142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcf9fc4e23b45345c2404ce7d6cb0fc9dea2c9ec",
            "isKey": false,
            "numCitedBy": 27662,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge."
            },
            "slug": "A-Computational-Approach-to-Edge-Detection-Canny",
            "title": {
                "fragments": [],
                "text": "A Computational Approach to Edge Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "There is a natural uncertainty principle between detection and localization performance, which are the two main goals, and with this principle a single operator shape is derived which is optimal at any scale."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076198688"
                        ],
                        "name": "Y. G. Leclerc",
                        "slug": "Y.-G.-Leclerc",
                        "structuredName": {
                            "firstName": "Yvan",
                            "lastName": "Leclerc",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. G. Leclerc"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 220
                            }
                        ],
                        "text": "\u2026can mimic human 3D interpretation of line drawings, motivating others to formulate the 3D interpretation problem as optimization over an objective function that favors planarity, symmetry, and other \u201cnatural\u201d properties (Leclerc and Fischler 1992; Lipson and Shpitalni 1996; Shoji et al. 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 303,
                                "start": 291
                            }
                        ],
                        "text": "Marill [48] observes that optimization of a global numerical criterion can mimic human 3D interpretation of line drawings, motivating others to formulate the 3D interpretation problem as optimization over an objective function that favors planarity, symmetry, and other \u201cnatural\u201d properties [38, 43, 65]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15801297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1da27f6a312d795db4d4652d5584f2516bf2128a",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Line drawings provide an effective means of communication about the geometry of 3D objects. An understanding of how to duplicate the way humans interpret line drawings is extremely important in enabling man-machine communication with respect to images, diagrams, and spatial constructs. In particular, such an understanding could be used to provide the human with the capability to create a line-drawing sketch of a polyhedral object that the machine can automatically convert into the intended 3D model.A recently published paper (Marill 1991) presented a simple optimization procedure supposedly able to duplicate human judgment in recovering the 3D \u201cwire frame\u201d geometry of objects depicted in line drawings. Marill provided some impressive examples, but no theoretical justification for his approach. Here, we introduce our own work by first critically examining Marill's algorithm. We provide an explanation for why Marill's algorithm was able to perform as well as it did on the examples he presented, discuss its weaknesses, and show very simple examples where it fails. We then provide an algorithm that improves on Marill's results. In particular, we show that an effective objective function must favor both symmetry and planarity-Marill deals only with the symmetry issue. By modifying Marill's objective function to explicitly favor planar-faced solutions, and by using a more competent optimization technique, we were able to demonstrate significantly improved performance in all of the examples Marill provided and those additional ones we constructed ourselves. Finally, we examine some questions relevant to the implications of this work for understanding the human ability to interpret line drawings."
            },
            "slug": "An-optimization-based-approach-to-the-of-single-as-Leclerc-Fischler",
            "title": {
                "fragments": [],
                "text": "An optimization-based approach to the interpretation of single line drawings as 3D wire frames"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "By modifying Marill's objective function to explicitly favor planar-faced solutions, and by using a more competent optimization technique, this work was able to demonstrate significantly improved performance in all of the examples Marill provided and those additional ones the authors constructed ourselves."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14457342"
                        ],
                        "name": "K. Shoji",
                        "slug": "K.-Shoji",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Shoji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shoji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110056387"
                        ],
                        "name": "Kazunori Kato",
                        "slug": "Kazunori-Kato",
                        "structuredName": {
                            "firstName": "Kazunori",
                            "lastName": "Kato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazunori Kato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1885811"
                        ],
                        "name": "Fubito Toyama",
                        "slug": "Fubito-Toyama",
                        "structuredName": {
                            "firstName": "Fubito",
                            "lastName": "Toyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fubito Toyama"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 274
                            }
                        ],
                        "text": "\u2026can mimic human 3D interpretation of line drawings, motivating others to formulate the 3D interpretation problem as optimization over an objective function that favors planarity, symmetry, and other \u201cnatural\u201d properties (Leclerc and Fischler 1992; Lipson and Shpitalni 1996; Shoji et al. 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 366,
                                "start": 293
                            }
                        ],
                        "text": "Marill (1991) observes that optimization of a global numerical criterion can mimic human 3D interpretation of line drawings, motivating others to formulate the 3D interpretation problem as optimization over an objective function that favors planarity, symmetry, and other \u201cnatural\u201d properties (Leclerc and Fischler 1992; Lipson and Shpitalni 1996; Shoji et al. 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 40017612,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eefaaf5e80699f10752c4d1244d6392699112cdb",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The human visual system can interpret two-dimensional (2-D) line drawings like the Necker cube as three-dimensional (3-D) wire frames. On this human ability Thomas Marill presented two important papers. First one proposed the 3-D interpretation model based on the principle to minimize the standard deviation of the angles between line segments in 3-D wire frame (MSDA), and reported the results of simulation experiments. Second one proposed the principle to minimize the description length on the internal representation in visual system. Motivated by Marill's principle to minimize the description length, we propose a principle to minimize the entropy of angle distribution between line segments in a 3-D wire frame (MEAD), which is more general than the MSDA one. And we implement the principle MEAD using a genetic algorithm (GA) as a simulation program. The results of simulation experiments show that the proposed principle of MEAD is more appropriate than the MSDA and another principle."
            },
            "slug": "3-D-interpretation-of-single-line-drawings-based-on-Shoji-Kato",
            "title": {
                "fragments": [],
                "text": "3-D interpretation of single line drawings based on entropy minimization principle"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A principle to minimize the entropy of angle distribution between line segments in a 3-D wire frame (MEAD), which is more general than the MSDA one, is proposed and implemented using a genetic algorithm as a simulation program."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2628885"
                        ],
                        "name": "L. H\u00e9rault",
                        "slug": "L.-H\u00e9rault",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "H\u00e9rault",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. H\u00e9rault"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794229"
                        ],
                        "name": "R. Horaud",
                        "slug": "R.-Horaud",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Horaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Horaud"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 263009,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cefa7d030a3fa0710132a7c6b56a97412bc74878",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The figure-ground discrimination problem is considered from a combinatorial optimization perspective. A mathematical model encoding the figure-ground discrimination problem that makes explicit a definition of shape based on cocircularity, smoothness, proximity, and contrast is presented. This model consists of building a cost function on the basis of image element interactions. This cost function fits the constraints of an interacting spin system that, in turn, is a well suited physical model that solves hard combinatorial optimization problems. Two combinatorial optimization methods for solving the figure-ground problem, namely mean field annealing, which combines mean field approximation theory and annealing, and microcanonical annealing, are discussed. Mean field annealing may be viewed as a deterministic approximation of stochastic methods such as simulated annealing. The theoretical bases of these methods are described, and the computational models are derived. The efficiencies of mean field annealing, simulated annealing, and microcanonical annealing algorithms are compared. Within the framework of such a comparison, the figure-ground problem may be viewed as a benchmark. >"
            },
            "slug": "Figure-Ground-Discrimination:-A-Combinatorial-H\u00e9rault-Horaud",
            "title": {
                "fragments": [],
                "text": "Figure-Ground Discrimination: A Combinatorial Optimization Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A mathematical model encoding the figure-ground discrimination problem that makes explicit a definition of shape based on cocircularity, smoothness, proximity, and contrast is presented and may be viewed as a benchmark."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4885998"
                        ],
                        "name": "J. Bakin",
                        "slug": "J.-Bakin",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Bakin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bakin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728376"
                        ],
                        "name": "K. Nakayama",
                        "slug": "K.-Nakayama",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Nakayama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nakayama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32056095"
                        ],
                        "name": "C. Gilbert",
                        "slug": "C.-Gilbert",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Gilbert",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gilbert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 160
                            }
                        ],
                        "text": "\u2026can be done based on the local surface near the boundary (Vaillant and Faugeras 1992), the difference of the motion estimates on either sides of the boundary (Black and Fleet 2000; Smith et al. 2004; Stein et al. 2007), or the responses of spatio-temporal filters (Stein and Hebert 2006a, 2006b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18533210,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "b3c8513bd3806766837541dc3b0d9d39e15d082e",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 97,
            "paperAbstract": {
                "fragments": [],
                "text": "The visual system uses information about the relative depth of contours and surfaces to link and segment elements of visual scenes. The integration of form and depth information was studied in areas V1 and V2 of the alert macaque. Neurons in area V2 used contextual depth information to integrate occluded contours, signal the presence of object boundaries, and segment surfaces: (1) Amodal contour completion occurs when a contour passes behind an occluder. The basis of contour completion, the facilitation of neuronal responses to stimuli located within their receptive fields (RFs) by contextual lines lying outside their RFs, was blocked by orthogonal lines intersecting the contours but was recovered when the orthogonal line was placed in the near depth plane. (2) An illusory contour will modally complete separated elements located across an isoluminant field if the elements are placed in the near depth plane. V2 neurons responded when line segments were placed outside the RF in the near depth plane and a field of uniform luminance covered the RF. (3) Texture elements within a surface will \u201ccapture\u201d the perceived depth consistent with the disparity of the surface's boundary, even when given no disparity themselves. V2 neurons responded to the center elements of a grating as if they contained disparity, even though disparity was present only for the grating's end elements located beyond the RF borders. These results, which were more common in V2 than in V1, demonstrate a role for V2 in the three-dimensional representation of surfaces in space."
            },
            "slug": "Visual-Responses-in-Monkey-Areas-V1-and-V2-to-Bakin-Nakayama",
            "title": {
                "fragments": [],
                "text": "Visual Responses in Monkey Areas V1 and V2 to Three-Dimensional Surface Configurations"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A role for V2 in the three-dimensional representation of surfaces in space is demonstrated in areas V1 and V2 of the alert macaque, demonstrating the importance of contextual depth information in the integration of form and depth information."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of Neuroscience"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46426221"
                        ],
                        "name": "Ido Leichter",
                        "slug": "Ido-Leichter",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Leichter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Leichter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727935"
                        ],
                        "name": "M. Lindenbaum",
                        "slug": "M.-Lindenbaum",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lindenbaum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lindenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 112
                            }
                        ],
                        "text": "This may partially explain why recent methods to infer figure/ground labels in natural images (Ren et al. 2006; Leichter and Lindenbaum 2009) tend to work much better for manually-provided boundaries than automatically detected boundaries."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1003812,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad0e387a3914176fe0b5ddbb7f4a8ef355c98696",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the \u201cboundary ownership\u201d problem, also known as the figure/ground assignment problem. Estimating boundary ownerships is a key step in perceptual organization: it allows higher-level processing to be applied on non-accidental shapes corresponding to figural regions. Existing methods for estimating the boundary ownerships for a given set of boundary curves model the probability distribution function (PDF) of the binary figure/ground random variables associated with the curves. Instead of modeling this PDF directly, the proposed method uses the 2.1D model: it models the PDF of the ordinal depths of the image segments enclosed by the curves. After this PDF is maximized, the boundary ownership of a curve is determined according to the ordinal depths of the two image segments it abuts. This method has two advantages: first, boundary ownership configurations inconsistent with every depth ordering (and thus very likely to be incorrect) are eliminated from consideration; second, it allows for the integration of cues related to image segments (not necessarily adjacent) in addition to those related to the curves. The proposed method models the PDF as a conditional random field (CRF) conditioned on cues related to the curves, T-junctions, and image segments. The CRF is formulated using learnt non-parametric distributions of the cues. The method significantly improves the currently achieved figure/ ground assignment accuracy, with 20.7% fewer errors in the Berkeley Segmentation Dataset."
            },
            "slug": "Boundary-ownership-by-lifting-to-2.1D-Leichter-Lindenbaum",
            "title": {
                "fragments": [],
                "text": "Boundary ownership by lifting to 2.1D"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The proposed method significantly improves the currently achieved figure/ ground assignment accuracy, with 20.7% fewer errors in the Berkeley Segmentation Dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6190636"
                        ],
                        "name": "Kwangmoo Koh",
                        "slug": "Kwangmoo-Koh",
                        "structuredName": {
                            "firstName": "Kwangmoo",
                            "lastName": "Koh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kwangmoo Koh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2695019"
                        ],
                        "name": "Seung-Jean Kim",
                        "slug": "Seung-Jean-Kim",
                        "structuredName": {
                            "firstName": "Seung-Jean",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seung-Jean Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843103"
                        ],
                        "name": "Stephen P. Boyd",
                        "slug": "Stephen-P.-Boyd",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Boyd",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen P. Boyd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 88
                            }
                        ],
                        "text": "16, we also describe a more detailed analysis using L1 regularized logistic regression (Kim et al. 2007) on standardized (zero mean, unit norm) features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "In Figure 16, we also describe a more detailed analysis using L1 regularized logistic regression [32] on standardized (zero mean, unit norm) features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6543419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7f716ab4e23cfb423a4f6b19363678d922a76f3",
            "isKey": false,
            "numCitedBy": 653,
            "numCiting": 115,
            "paperAbstract": {
                "fragments": [],
                "text": "Logistic regression with l1 regularization has been proposed as a promising method for feature selection in classification problems. In this paper we describe an efficient interior-point method for solving large-scale l1-regularized logistic regression problems. Small problems with up to a thousand or so features and examples can be solved in seconds on a PC; medium sized problems, with tens of thousands of features and examples, can be solved in tens of seconds (assuming some sparsity in the data). A variation on the basic method, that uses a preconditioned conjugate gradient method to compute the search step, can solve very large problems, with a million features and examples (e.g., the 20 Newsgroups data set), in a few minutes, on a PC. Using warm-start techniques, a good approximation of the entire regularization path can be computed much more efficiently than by solving a family of problems independently."
            },
            "slug": "An-Interior-Point-Method-for-Large-Scale-Logistic-Koh-Kim",
            "title": {
                "fragments": [],
                "text": "An Interior-Point Method for Large-Scale l1-Regularized Logistic Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This paper describes an efficient interior-point method for solving large-scale l1-regularized logistic regression problems, and shows how a good approximation of the entire regularization path can be computed much more efficiently than by solving a family of problems independently."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2180463"
                        ],
                        "name": "Su-In Lee",
                        "slug": "Su-In-Lee",
                        "structuredName": {
                            "firstName": "Su-In",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Su-In Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1981419"
                        ],
                        "name": "Varun Ganapathi",
                        "slug": "Varun-Ganapathi",
                        "structuredName": {
                            "firstName": "Varun",
                            "lastName": "Ganapathi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Varun Ganapathi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 116
                            }
                        ],
                        "text": "This is a linear classifier that can be used for feature selection (Ng 2004) or learning Markov network structures (Lee et al. 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "fier that can be used for feature selection [53] or learning Markov network structures [39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2712572,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f08dbceec9b790e73139c39681768ffb2ce5eef6",
            "isKey": false,
            "numCitedBy": 246,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Markov networks are commonly used in a wide variety of applications, ranging from computer vision, to natural language, to computational biology. In most current applications, even those that rely heavily on learned models, the structure of the Markov network is constructed by hand, due to the lack of effective algorithms for learning Markov network structure from data. In this paper, we provide a computationally efficient method for learning Markov network structure from data. Our method is based on the use of L1 regularization on the weights of the log-linear model, which has the effect of biasing the model towards solutions where many of the parameters are zero. This formulation converts the Markov network learning problem into a convex optimization problem in a continuous space, which can be solved using efficient gradient methods. A key issue in this setting is the (unavoidable) use of approximate inference, which can lead to errors in the gradient computation when the network structure is dense. Thus, we explore the use of different feature introduction schemes and compare their performance. We provide results for our method on synthetic data, and on two real world data sets: pixel values in the MNIST data, and genetic sequence variations in the human HapMap data. We show that our L1 -based method achieves considerably higher generalization performance than the more standard L2-based method (a Gaussian parameter prior) or pure maximum-likelihood learning. We also show that we can learn MRF network structure at a computational cost that is not much greater than learning parameters alone, demonstrating the existence of a feasible method for this important problem."
            },
            "slug": "Efficient-Structure-Learning-of-Markov-Networks-Lee-Ganapathi",
            "title": {
                "fragments": [],
                "text": "Efficient Structure Learning of Markov Networks using L1-Regularization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper provides a computationally efficient method for learning Markov network structure from data based on the use of L1 regularization on the weights of the log-linear model, which achieves considerably higher generalization performance than the more standard L2-based method (a Gaussian parameter prior or pure maximum-likelihood learning)."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064786620"
                        ],
                        "name": "D. A. Huffman",
                        "slug": "D.-A.-Huffman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Huffman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. A. Huffman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 55
                            }
                        ],
                        "text": "The approach, fully developed by Waltz [75] and others [11, 28, 29, 34, 14], defines a set of possible line labels (convex, concave, and occluding) and a set of allowed vertex types (T-junctions, L-junctions, etc)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 71
                            }
                        ],
                        "text": "The approach, fully developed by Waltz (1975) and others (Clowes 1971; Huffman 1971, 1977; Kanade 1980; Draper 1981), defines a set of possible line labels (convex, concave, and occluding) and a set of allowed vertex types (T-junctions, L-junctions, etc.)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 59644197,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "d17ae64c1765bbe60f1d725359cc76bfc3f76ac1",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "To every 3-dimensional scene there correspond as many 2-dimensional pictures as there are possible vantage points for the camera. It is, however, possible to construct pictures for which there is no corresponding scene containing physically-realizable objects. Pictures of such 'impossible objects' can be useful in giving insight into the constraints or grammatical rules associated with the 'language' of pictures, just as nonsense sentences can be useful in illustrating the rules of other languages. Impossible objects have been used by psychologists (Penrose and Penrose 1958) to create visual illusions which successfully challenge the ability of our perceptual systems to synthesize a 3-dimensional world from 2-dimensional information. The incompatibilities among the various portions of pictures of these objects are a novel way of testing our picture analysis procedures. The purpose of this paper is to demonstrate some possible decision procedures and to test them on pictures of both possible and impossible objects."
            },
            "slug": "Impossible-Objects-as-Nonsense-Sentences-Huffman",
            "title": {
                "fragments": [],
                "text": "Impossible Objects as Nonsense Sentences"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The purpose of this paper is to demonstrate some possible decision procedures and to test them on pictures of both possible and impossible objects, a novel way of testing picture analysis procedures."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767364"
                        ],
                        "name": "A. Amir",
                        "slug": "A.-Amir",
                        "structuredName": {
                            "firstName": "Arnon",
                            "lastName": "Amir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Amir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727935"
                        ],
                        "name": "M. Lindenbaum",
                        "slug": "M.-Lindenbaum",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lindenbaum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lindenbaum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17716019,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "c29e178718c0438eafd5bc31b66814db42303f1c",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a generic method for perceptual grouping and an analysis of its expected grouping quality. The grouping method is fairly general: It may be used for the grouping of various types of data features, and to incorporate different grouping cues operating over feature sets of different sizes. The proposed method is divided into two parts: constructing a graph representation of the available perceptual grouping evidence, and then finding the \"best\" partition of the graph into groups. The first stage includes a cue enhancement procedure, which integrates the information available from multifeature cues into very reliable bifeature cues. Both stages are implemented using known statistical tools such as Wald's SPRT algorithm (1952) and the maximum likelihood criterion. The accompanying theoretical analysis of this grouping criterion quantifies intuitive expectations and predicts that the expected grouping quality increases with cue reliability. It also shows that investing more computational effort in the grouping algorithm leads to better grouping results. This analysis, which quantifies the grouping power of the maximum likelihood criterion, is independent of the grouping domain. To our best knowledge, such an analysis of a grouping process is given here for the first time. Three grouping algorithms, in three different domains, are synthesized as instances of the generic method. They demonstrate the applicability and generality of this grouping method."
            },
            "slug": "A-Generic-Grouping-Algorithm-and-Its-Quantitative-Amir-Lindenbaum",
            "title": {
                "fragments": [],
                "text": "A Generic Grouping Algorithm and Its Quantitative Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A generic method for perceptual grouping and an analysis of its expected grouping quality, which quantifies the grouping power of the maximum likelihood criterion, is presented and shown that investing more computational effort in the grouping algorithm leads to better grouping results."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145039030"
                        ],
                        "name": "J. Platt",
                        "slug": "J.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Platt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153379696"
                        ],
                        "name": "T. Hofmann",
                        "slug": "T.-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hofmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 116
                            }
                        ],
                        "text": "This is a linear classifier that can be used for feature selection (Ng 2004) or learning Markov network structures (Lee et al. 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 63936062,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6b80923dd30f920234a1ac965bea768062882f8",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Markov networks are commonly used in a wide variety of applications, ranging from computer vision, to natural language, to computational biology. In most current applications, even those that rely heavily on learned models, the structure of the Markov network is constructed by hand, due to the lack of effective algorithms for learning Markov network structure from data. In this paper, we provide a computationally efficient method for learning Markov network structure from data. Our method is based on the use of L1 regularization on the weights of the log-linear model, which has the effect of biasing the model towards solutions wheremany of the parameters are zero. This formulation converts theMarkov network learning problem into a convex optimization problem in a continuous space, which can be solved using efficient gradient methods. A key issue in this setting is the (unavoidable) use of approximate inference, which can lead to errors in the gradient computation when the network structure is dense. Thus, we explore the use of different feature introduction schemes and compare their performance. We provide results for our method on synthetic data, and on two real world data sets: pixel values in the MNIST data, and genetic sequence variations in the human HapMap data. We show that our L1-based method achieves considerably higher generalization performance than the more standard L2-based method (a Gaussian parameter prior) or pure maximum-likelihood learning. We also show that we can learn MRF network structure at a computational cost that is not much greater than learning parameters alone, demonstrating the existence of a feasible method for this important problem."
            },
            "slug": "Efficient-Structure-Learning-of-Markov-Networks-Sch\u00f6lkopf-Platt",
            "title": {
                "fragments": [],
                "text": "Efficient Structure Learning of Markov Networks using L1-Regularization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper provides a computationally efficient method for learning Markov network structure from data based on the use of L1 regularization on the weights of the log-linear model, which achieves considerably higher generalization performance than the more standard L2-based method (a Gaussian parameter prior) or pure maximum-likelihood learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073374"
                        ],
                        "name": "T. Marill",
                        "slug": "T.-Marill",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Marill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Marill"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "As the regions grow, spatial support for computing features improves, and certain features become much more useful."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Marill (1991) observes that optimization of a global numerical criterion can mimic human 3D interpretation of line drawings, motivating others to formulate the 3D interpretation problem as optimization over an objective function that favors planarity, symmetry, and other \u201cnatural\u201d properties\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1120613,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "62aea6755c24680b6911c70b205cb3c0a8b511a8",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The human vision system has the ability to interpret two-dimensional images as three-dimensional objects. In this article, we present a program that emulates this ability for the case of images consisting of line-drawings. As a by-product of the approach, we provide an explanation of the Necker cube illusion."
            },
            "slug": "Emulating-the-human-interpretation-of-line-drawings-Marill",
            "title": {
                "fragments": [],
                "text": "Emulating the human interpretation of line-drawings as three-dimensional objects"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A program is presented that emulates the human vision system's ability to interpret two-dimensional images as three-dimensional objects for the case of images consisting of line-drawings and provides an explanation of the Necker cube illusion."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61615905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a2ed19ac684022aa3186887cd4893484ab8f80c",
            "isKey": false,
            "numCitedBy": 2169,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006). Details of the challenge, data, and evaluation are presented. Participants in the challenge submitted descriptions of their methods, and these have been included verbatim. This document should be considered preliminary, and subject to change."
            },
            "slug": "The-PASCAL-visual-object-classes-challenge-2006-Everingham-Zisserman",
            "title": {
                "fragments": [],
                "text": "The PASCAL visual object classes challenge 2006 (VOC2006) results"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 68
                            }
                        ],
                        "text": "This is a linear classifier that can be used for feature selection (Ng 2004) or learning Markov network structures (Lee et al. 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 67
                            }
                        ],
                        "text": "This is a linear classifier that can be used for feature selection (Ng 2004) or learning Markov network structures (Lee et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11258400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee6275a84962a0ffd6212585e4f7ee7ffb2b068a",
            "isKey": false,
            "numCitedBy": 1636,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider supervised learning in the presence of very many irrelevant features, and study two different regularization methods for preventing overfitting. Focusing on logistic regression, we show that using L1 regularization of the parameters, the sample complexity (i.e., the number of training examples required to learn \"well,\") grows only logarithmically in the number of irrelevant features. This logarithmic rate matches the best known bounds for feature selection, and indicates that L1 regularized logistic regression can be effective even if there are exponentially many irrelevant features as there are training examples. We also give a lower-bound showing that any rotationally invariant algorithm---including logistic regression with L2 regularization, SVMs, and neural networks trained by backpropagation---has a worst case sample complexity that grows at least linearly in the number of irrelevant features."
            },
            "slug": "Feature-selection,-L1-vs.-L2-regularization,-and-Ng",
            "title": {
                "fragments": [],
                "text": "Feature selection, L1 vs. L2 regularization, and rotational invariance"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A lower-bound is given showing that any rotationally invariant algorithm---including logistic regression with L1 regularization, SVMs, and neural networks trained by backpropagation---has a worst case sample complexity that grows at least linearly in the number of irrelevant features."
            },
            "venue": {
                "fragments": [],
                "text": "Twenty-first international conference on Machine learning  - ICML '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790356"
                        ],
                        "name": "T. Heskes",
                        "slug": "T.-Heskes",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Heskes",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Heskes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073572"
                        ],
                        "name": "K. Albers",
                        "slug": "K.-Albers",
                        "structuredName": {
                            "firstName": "Kees",
                            "lastName": "Albers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Albers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792269"
                        ],
                        "name": "H. Kappen",
                        "slug": "H.-Kappen",
                        "structuredName": {
                            "firstName": "Hilbert",
                            "lastName": "Kappen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kappen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6845974,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c09ff975d5ed65512a9c89e7216320ae64cd786c",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Loopy and generalized belief propagation are popular algorithms for approximate inference in Markov random fields and Bayesian networks. Fixed points of these algorithms correspond to extrema of the Bethe and Kikuchi free energy (Yedidia et al., 2001). However, belief propagation does not always converge, which motivates approaches that explicitly minimize the Kikuchi/Bethe free energy, such as CCCP (Yuille, 2002) and UPS (Teh and Welling, 2002). Here we describe a class of algorithms that solves this typically non-convex constrained minimization problem through a sequence of convex constrained minimizations of upper bounds on the Kikuchi free energy. Intuitively one would expect tighter bounds to lead to faster algorithms, which is indeed convincingly demonstrated in our simulations. Several ideas are applied to obtain tight convex bounds that yield dramatic speed-ups over CCCP."
            },
            "slug": "Approximate-Inference-and-Constrained-Optimization-Heskes-Albers",
            "title": {
                "fragments": [],
                "text": "Approximate Inference and Constrained Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "A class of algorithms is described that solves this typically non-convex constrained minimization problem through a sequence of conveX constrained minimizations of upper bounds on the Kikuchi free energy."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207651918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b54c9359e8858842d1b1b744ac5ca573b8031dcc",
            "isKey": false,
            "numCitedBy": 662,
            "numCiting": 103,
            "paperAbstract": {
                "fragments": [],
                "text": "We give a unified account of boosting and logistic regression in which each learning problem is cast in terms of optimization of Bregman distances. The striking similarity of the two problems in this framework allows us to design and analyze algorithms for both simultaneously, and to easily adapt algorithms designed for one problem to the other. For both problems, we give new algorithms and explain their potential advantages over existing methods. These algorithms are iterative and can be divided into two types based on whether the parameters are updated sequentially (one at a time) or in parallel (all at once). We also describe a parameterized family of algorithms that includes both a sequential- and a parallel-update algorithm as special cases, thus showing how the sequential and parallel approaches can themselves be unified. For all of the algorithms, we give convergence proofs using a general formalization of the auxiliary-function proof technique. As one of our sequential-update algorithms is equivalent to AdaBoost, this provides the first general proof of convergence for AdaBoost. We show that all of our algorithms generalize easily to the multiclass case, and we contrast the new algorithms with the iterative scaling algorithm. We conclude with a few experimental results with synthetic data that highlight the behavior of the old and newly proposed algorithms in different settings."
            },
            "slug": "Logistic-Regression,-AdaBoost-and-Bregman-Distances-Collins-Schapire",
            "title": {
                "fragments": [],
                "text": "Logistic Regression, AdaBoost and Bregman Distances"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A unified account of boosting and logistic regression in which each learning problem is cast in terms of optimization of Bregman distances, and a parameterized family of algorithms that includes both a sequential- and a parallel-update algorithm as special cases are described, thus showing how the sequential and parallel approaches can themselves be unified."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788375"
                        ],
                        "name": "D. Waltz",
                        "slug": "D.-Waltz",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Waltz",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Waltz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "Our representation includes: color, position, and alignment of regions; strength and length of boundaries; 3D surface orientation estimates; and depth estimates."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 124
                            }
                        ],
                        "text": "The reasoning over junctions and the definition of valid junctions is reminiscent of the much earlier line labeling work of Waltz (1975)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 33
                            }
                        ],
                        "text": "The approach, fully developed by Waltz (1975) and others (Clowes 1971; Huffman 1971, 1977; Kanade 1980; Draper 1981), defines a set of possible line labels (convex, concave, and occluding) and a set of allowed vertex types (T-junctions, L-junctions, etc.)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61975913,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "b3fba1e0774e98a4e0db83a3a0f0aeb18a8d052b",
            "isKey": false,
            "numCitedBy": 1233,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A detailed discussion of the standard approach to computer interpretation of line drawings as three-dimensional scenes"
            },
            "slug": "Understanding-Line-drawings-of-Scenes-with-Shadows-Waltz",
            "title": {
                "fragments": [],
                "text": "Understanding Line drawings of Scenes with Shadows"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A detailed discussion of the standard approach to computer interpretation of line drawings as three-dimensional scenes as well as some alternative approaches to this approach are discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708138"
                        ],
                        "name": "S. Draper",
                        "slug": "S.-Draper",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Draper",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Draper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6759618,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "37af6d3287c06735be49ad519ebe1f7019f68336",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Use-of-Gradient-and-Dual-Space-in-Line-Drawing-Draper",
            "title": {
                "fragments": [],
                "text": "The Use of Gradient and Dual Space in Line-Drawing Interpretation"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751698"
                        ],
                        "name": "K. Sugihara",
                        "slug": "K.-Sugihara",
                        "structuredName": {
                            "firstName": "Kokichi",
                            "lastName": "Sugihara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sugihara"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15049476,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a17cc01c8ce63f6f0ef8249ac5d9a3031a27b1be",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "As Shapira pointed out, a theorem by the author on line drawings of polyhedral scenes was not accurate. The present paper shows that the validity of the theorem is attained by a slight revision of the formulation."
            },
            "slug": "A-Necessary-and-Sufficient-Condition-for-a-Picture-Sugihara",
            "title": {
                "fragments": [],
                "text": "A Necessary and Sufficient Condition for a Picture to Represent a Polyhedral Scene"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The present paper shows that the validity of the theorem is attained by a slight revision of the formulation, which was pointed out by the author on line drawings of polyhedral scenes was not accurate."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 233
                            }
                        ],
                        "text": "\u2026due to the high closure penalties, but the Heskes et al. (2003) Kikuchi free energy-based sum-product algorithm, combined with the mean field approximation of raising factors to the 1/T (T = 0.5 in our experiments), as suggested by Yuille (2002) efficiently provides \u201csoft-max\u201d likelihood estimates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "as suggested by Yuille [77] efficiently provides \u201csoft-max\u201d likelihood estimates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 307,
                                "start": 301
                            }
                        ],
                        "text": "Even approximate max-product inference over our model is intractable due to the high closure penalties, but the Heskes et al. (2003) Kikuchi free energy-based sum-product algorithm, combined with the mean field approximation of raising factors to the 1/T (T = 0.5 in our experiments), as suggested by Yuille (2002) efficiently provides \u201csoft-max\u201d likelihood estimates."
                    },
                    "intents": []
                }
            ],
            "corpusId": 782136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "974fee9c3836d91aee9492c07379898ccc2c3a85",
            "isKey": true,
            "numCitedBy": 235,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This article introduces a class of discrete iterative algorithms that are provably convergent alternatives to belief propagation (BP) and generalized belief propagation (GBP). Our work builds on recent results by Yedidia, Freeman, and Weiss (2000), who showed that the fixed points of BP and GBP algorithms correspond to extrema of the Bethe and Kikuchi free energies, respectively. We obtain two algorithms by applying CCCP to the Bethe and Kikuchi free energies, respectively (CCCP is a procedure, introduced here, for obtaining discrete iterative algorithms by decomposing a cost function into a concave and a convex part). We implement our CCCP algorithms on two- and three-dimensional spin glasses and compare their results to BP and GBP. Our simulations show that the CCCP algorithms are stable and converge very quickly (the speed of CCCP is similar to that of BP and GBP). Unlike CCCP, BP will often not converge for these problems (GBP usually, but not always, converges). The results found by CCCP applied to the Bethe or Kikuchi free energies are equivalent, or slightly better than, those found by BP or GBP, respectively (when BP and GBP converge). Note that for these, and other problems, BP and GBP give very accurate results (see Yedidia et al., 2000), and failure to converge is their major error mode. Finally, we point out that our algorithms have a large range of inference and learning applications."
            },
            "slug": "CCCP-Algorithms-to-Minimize-the-Bethe-and-Kikuchi-Yuille",
            "title": {
                "fragments": [],
                "text": "CCCP Algorithms to Minimize the Bethe and Kikuchi Free Energies: Convergent Alternatives to Belief Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A class of discrete iterative algorithms that are provably convergent alternatives to believe propagation (BP) and generalized belief propagation (GBP) and are pointed out that have a large range of inference and learning applications."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144806578"
                        ],
                        "name": "M. Wertheimer",
                        "slug": "M.-Wertheimer",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Wertheimer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wertheimer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 121
                            }
                        ],
                        "text": "The affinities are based on computational realizations of the Gestalt principles of continuation, proximity and closure (Wertheimer 1938; Lowe 1985; Elder and Zucker 1996; Herault and Horaud 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 143283358,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "43a0503e38b4c47a5b794c04439299bd78310189",
            "isKey": false,
            "numCitedBy": 1467,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Theoretically I might say there were 327 brightnesses and nuances of colour. Do I have \"327\"? No. I have sky, house, and trees. It is impossible to achieve \"327 \" as such. And yet even though such droll calculation were possible and implied, say, for the house 120, the trees 90, the sky 117 -I should at least have this arrangement and division of the total, and not, say, 127 and 100 and 100; or 150 and 177."
            },
            "slug": "Laws-of-organization-in-perceptual-forms.-Wertheimer",
            "title": {
                "fragments": [],
                "text": "Laws of organization in perceptual forms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1938
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11079833"
                        ],
                        "name": "S. Sutherland",
                        "slug": "S.-Sutherland",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Sutherland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sutherland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 58
                            }
                        ],
                        "text": "The approach, fully developed by Waltz (1975) and others (Clowes 1971; Huffman 1971, 1977; Kanade 1980; Draper 1981), defines a set of possible line labels (convex, concave, and occluding) and a set of allowed vertex types (T-junctions, L-junctions, etc.)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 57
                            }
                        ],
                        "text": "The approach, fully developed by Waltz (1975) and others (Clowes 1971; Huffman 1971, 1977; Kanade 1980; Draper 1981), defines a set of possible line labels (convex, concave, and occluding) and a set of allowed vertex types (T-junctions, L-junctions, etc."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5479823,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b3464fb194e5dc5ee6786136aaad08763a700549",
            "isKey": false,
            "numCitedBy": 331,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual Processing: Computational, Psychophysical and Cognitive Research.By Roger Watt. Lawrence Erlbaum: 1988. Pp. 152. \u00a314.95, $26.95.Visual Cognition: Computational, Experimental and Neuropsychological Perspectives. By Glyn W. Humphreys and Vicki Bruce. Lawrence Erlbaum: 1989. Pp.330. Hbk \u00a319.95, $37.95; pbk \u00a39.95, $16.95."
            },
            "slug": "Seeing-things-Sutherland",
            "title": {
                "fragments": [],
                "text": "Seeing things"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722524"
                        ],
                        "name": "E. Dassau",
                        "slug": "E.-Dassau",
                        "structuredName": {
                            "firstName": "Eyal",
                            "lastName": "Dassau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Dassau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66055904"
                        ],
                        "name": "Christian Lowe",
                        "slug": "Christian-Lowe",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Lowe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37970172"
                        ],
                        "name": "C. Barr",
                        "slug": "C.-Barr",
                        "structuredName": {
                            "firstName": "Cameron",
                            "lastName": "Barr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Barr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39423582"
                        ],
                        "name": "E. Atlas",
                        "slug": "E.-Atlas",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Atlas",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Atlas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152962700"
                        ],
                        "name": "M. Phillip",
                        "slug": "M.-Phillip",
                        "structuredName": {
                            "firstName": "Moshe",
                            "lastName": "Phillip",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Phillip"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 74
                            }
                        ],
                        "text": "Boundaries for detectable objects can be improved with simple mechanisms (Hoiem et al. 2008)\nknow how these features impact performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 115
                            }
                        ],
                        "text": "By explicitly reasoning about occlusions, we enable much more accurate and detailed 3D models of cluttered scenes (Hoiem et al. 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 73
                            }
                        ],
                        "text": "Boundaries for detectable objects can be improved with simple mechanisms (Hoiem et al. 2008)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 15
                            }
                        ],
                        "text": "In other work (Hoiem et al. 2008), we show that the occlusion boundaries are helpful for single-view 3D reconstruction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 73
                            }
                        ],
                        "text": "The algorithm could be improved by incorporating object detectors, as in Hoiem et al. (2008), or, more interestingly, developing a object localization and segmentation algorithms that apply within some broader domain (Farhadi et al. 2010), such as animals or vehicles."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 39
                            }
                        ],
                        "text": "15) and convincing 3D reconstructions (Hoiem et al. 2008)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9107847,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "810fbf0d35b45d7749b7c36c0be54225bfcc206e",
            "isKey": true,
            "numCitedBy": 100,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Closing the loop Eyal Dassau, Christian Lowe, Cameron Barr, Eran Atlas, Moshe Phillip University of California at Santa Barbara, Santa Barbara, CA, USA Sansum Diabetes Research Institute, Santa Barbara, CA, USA Diabetes Technolgies Center, Jesse Z and Sara Lea Shafer Institute for Endocrinology and Diabetes, Schneider Children\u2019s Medical Center of Israel, Petah Tikva, Israel Sackler Faculty of Medicine, Tel-Aviv University, Tel-Aviv, Israel"
            },
            "slug": "Closing-the-loop-Dassau-Lowe",
            "title": {
                "fragments": [],
                "text": "Closing the loop"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "This research aims to provide real-time information about the immune system\u2019s response to insulin and its role in the development of type 2 diabetes."
            },
            "venue": {
                "fragments": [],
                "text": "International journal of clinical practice. Supplement"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 66
                            }
                        ],
                        "text": "Our occlusion algorithm outperforms\nGlobal Pb (Maire et al. 2008; Arbelaez et al. 2009) in this task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 42
                            }
                        ],
                        "text": "In doing so, we follow the methodology of Arbelaez et al. (2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 259,
                                "start": 237
                            }
                        ],
                        "text": "Though this grouping is sometimes performed based on pre-computed affinities (e.g., Shi and Malik 2000), others advocate a gradual approach, such as the hierarchical segmentation techniques developed by Ahuja (1996) and Arbelaez (2006), Arbelaez et al. (2009), which we follow in our approach."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 117
                            }
                        ],
                        "text": "Comparison algorithms are Pb [49], Global Pb [46], and an extension of global Pb to an ultrametric contour map (UCM) [6], with each trained on BSDS."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 124
                            }
                        ],
                        "text": "Likewise, we generate regions for Pb and Global Pb using the hierarchical segmentation with oriented watershed described in [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 193
                            }
                        ],
                        "text": "The initial boundaries are created using watershed segmentation with the soft boundary map provided by the pB algorithm of Martin et al. (2002) (without non-maxima suppression, as suggested by Arbelaez 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 46
                            }
                        ],
                        "text": "Our occlusion algorithm outperforms Global Pb [46, 6] in this task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 124
                            }
                        ],
                        "text": "Likewise, we generate regions for Pb and Global Pb using the hierarchical segmentation with oriented watershed described in Arbelaez et al. (2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 129
                            }
                        ],
                        "text": "Our definition of total boundary strength as the maximum of the two estimates ensures that our merging metric is an ultrametric (Arbelaez 2006), guaranteeing a true hierarchy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 225
                            }
                        ],
                        "text": "Our algorithm is trained on 50 images from the Geometric Context dataset, while the Pb algorithms are trained on 200 images from the BSDS dataset\nLM Scorearea LM Scoreunweighted VOC2008 Scorearea VOC2008 Scoreunweighted\nPb + UCM 0.602 0.426 \u2013 \u2013 Global Pb + UCM 0.712 0.588 0.620 0.616 Occlusion iter 1 0.753 0.593 0.635 0.629\nOcclusion final 0.769 0.613 0.671 0.665\ngions with the given minimum area."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 182
                            }
                        ],
                        "text": "Our results, shown in Table 4 and Figure 19, indicate that our algorithm outperforms Global Pb in both datasets, which was previously reported to be the best algorithm for this task [6]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 149
                            }
                        ],
                        "text": "Comparison algorithms are Pb (Martin et al. 2002), Global Pb (Maire et al. 2008), and an extension of global Pb to an ultrametric contour map (UCM) (Arbelaez et al. 2009), with each trained on BSDS."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 229
                            }
                        ],
                        "text": "Some segmentation methods rely on 2D brightness, color, or texture cues to group the image pixels into perceptually similar regions (Shi and Malik 2000; Martin et al. 2001; Ren and Malik 2003; Felzenszwalb and Huttenlocher 2004; Arbelaez 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 130
                            }
                        ],
                        "text": ", [64]), others advocate a gradual approach, such as the hierarchical segmentation techniques developed by Ahuja [1] and Arbelaez [5, 6], which we follow in our approach."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 15
                            }
                        ],
                        "text": "Global Pb with UCM achieves the best results for perceptual boundaries in BSDS, while our algorithm provides the best performance on object boundaries in LabelMe\nLabelMe(AP) LabelMe (Rank1) BSDS (AP) BSDS (F)\nPb 0.388 3.7% 0.689 0.656\nGlobal Pb 0.441 4.7% 0.744 0.697 Global Pb + UCM 0.474 22.5% 0.765 0.702 Occlusion iter 1 0.504 20.6% 0.708 0.656\nOcclusion final 0.522 48.6% 0.698 0.653\nFig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 142
                            }
                        ],
                        "text": "19, indicate that our algorithm outperforms Global Pb in both datasets, which was previously reported to be the best algorithm for this task (Arbelaez et al. 2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62591426,
            "fieldsOfStudy": [],
            "id": "83d312b9f4ccb3b6005b4ffee9a706e222e8484e",
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "From contours to regions: An empirical evaluation"
            },
            "venue": {
                "fragments": [],
                "text": "CVPR"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 203
                            }
                        ],
                        "text": "\u2026where an object region is adjacent to a ground or sky region, and inference on our CRF model helps to propagate the label into less obvious boundaries\n4.3 Surface Layout Cues\nThe surface estimates from Hoiem et al. (2007) are highly predictive of occlusion boundaries and figure/ground labels."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "In an earlier conference paper [27], we provide further analysis of segmentation accuracy and show that segmentations compare favorably to normalized cuts [13] or using the surface layout labels as a segmentation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 63
                            }
                        ],
                        "text": "We train and test our method on our Geometric Context dataset (Hoiem et al. 2007), consisting of a wide variety of\nscenes including beaches, fields, forests, hills, suburbs, and urban streets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 109
                            }
                        ],
                        "text": "1This paper offers a more complete understanding of the algorithm first described in the conference version (Hoiem et al. 2007), providing further background, description, insight, analysis, and evaluation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 23
                            }
                        ],
                        "text": "Our surface estimates (Hoiem et al. 2007) can sometimes be used to reconstruct a coarse 3D model of a scene (Hoiem et al. 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 37
                            }
                        ],
                        "text": "We can take advantage of our work in Hoiem et al. (2007) to recover surface information, which we represent as the average confidence (S1-S4) for each geometric class (horizontal support, vertical planar, vertical solid nonplanar, vertical porous, and sky) over each region."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 137
                            }
                        ],
                        "text": "These difficulties and successes can be partly explained as a heavy reliance on surface layout features, though we show in earlier work (Hoiem et al. 2007) that segmentation purely based on surface layout performs relatively poorly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 41
                            }
                        ],
                        "text": "We previously proposed a surface layout (Hoiem et al. 2007), that labels pixels according to surface geometry, such as \u201csupport\u201d (e.g., road, grass), \u201cvertical planar\u201d (e.g., a building wall), \u201cvertical non-planar porous\u201d (e.g., vegetation or a mesh), \u201cvertical non-planar solid\u201d (e.g., a person or\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "1This paper offers a more complete understanding of the algorithm first described in the conference version [27], providing further background, description, insight, analysis, and evaluation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "These difficulties and successes can be partly explained as a heavy reliance on surface layout features, though we show in earlier work [27] that segmentation purely based on surface layout performs relatively poorly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 127
                            }
                        ],
                        "text": "However, our ideal segmentation into objects and major surfaces is different from a segmentation into the geometric classes of Hoiem et al. (2007), and we use no object-specific models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 167
                            }
                        ],
                        "text": "\u2026our experiments, we set the surface factor unary term by combining, in a linear logistic model, two likelihood estimates: (1) the multiple segmentation estimate from Hoiem et al. (2007); and (2) an estimate using the same cues as (1) but using the current segmentation from our occlusion algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 138
                            }
                        ],
                        "text": "Our physical definition of boundaries provides a more concrete objective and allows us to build on the 3D surface estimation described in Hoiem et al. (2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 32
                            }
                        ],
                        "text": "In an earlier conference paper (Hoiem et al. 2007), we provide further analysis of segmentation accuracy and show that segmentations compare favorably to normalized cuts (Cour et al.\n2005) or using the surface layout labels as a segmentation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 14
                            }
                        ],
                        "text": "The method in Hoiem et al. (2007) provides pixel confidences for \u201csupport\u201d, \u201cvertical planar\u201d, \u201cvertical non-planar porous\u201d, \u201cvertical nonplanar solid\u201d, and \u201csky\u201d."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recovering occlusion boundaries from an image"
            },
            "venue": {
                "fragments": [],
                "text": "ICCV,"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 27
                            }
                        ],
                        "text": "Shown are results using Pb (Martin et al. 2002), boundary/region cues only (R1-R5, B1-B6 in Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 43
                            }
                        ],
                        "text": "93 GHz, including about 215 seconds for Pb (Martin et al. 2002) without non-maximum suppression, 10 seconds for our surface estimation algorithm, and 235 seconds for the occlusion algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 123
                            }
                        ],
                        "text": "The initial boundaries are created using watershed segmentation with the soft boundary map provided by the pB algorithm of Martin et al. (2002) (without non-maxima suppression, as suggested by Arbelaez 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 29
                            }
                        ],
                        "text": "Comparison algorithms are Pb (Martin et al. 2002), Global Pb (Maire et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 58
                            }
                        ],
                        "text": "To represent boundary strength (B1), we take the mean Pb (Martin et al. 2002) (probability of boundary) value along the boundary pixels, without applying non-maxima suppression."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 144
                            }
                        ],
                        "text": "\u2026takes about 460 seconds for a 600\u00d7800 image, running on a single thread of a 64-bit Intel core i7 2.93 GHz, including about 215 seconds for Pb (Martin et al. 2002) without non-maximum suppression, 10 seconds for our surface estimation algorithm, and 235 seconds for the occlusion algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 30
                            }
                        ],
                        "text": "Comparison algorithms are Pb (Martin et al. 2002), Global Pb (Maire et al. 2008), and an extension of global Pb to an ultrametric contour map (UCM) (Arbelaez et al. 2009), with each trained on BSDS."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to find brightness and texture boundaries in natural images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30457331"
                        ],
                        "name": "J. Gibson",
                        "slug": "J.-Gibson",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Gibson",
                            "middleNames": [
                                "Jerome"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gibson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 35
                            }
                        ],
                        "text": "In Perception of the Visual World (Gibson 1950), Gibson declares, \u201cThe elementary impressions of a visual world are those of surface and edge.\u201d"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "In Perception of the Visual World [19], Gibson declares, \u201cThe elementary impressions of a visual world are those of surface and edge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195034367,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "fc0d34992ba4c2c68806eb52c096749f847f5424",
            "isKey": false,
            "numCitedBy": 2204,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-perception-of-the-visual-world-Gibson",
            "title": {
                "fragments": [],
                "text": "The perception of the visual world"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1950
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141732326"
                        ],
                        "name": "Jianguo Zhang",
                        "slug": "Jianguo-Zhang",
                        "structuredName": {
                            "firstName": "Jianguo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianguo Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 155
                            }
                        ],
                        "text": "Without retraining either algorithm, we compare on three datasets: BSDS test set, LabelMe (Russell et al. 2006), and the PASCAL VOC 2008 segmentation set (Everingham et al. 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "Without retraining either algorithm, we compare on three datasets: BSDS test set, LabelMe [60], and the PASCAL VOC 2008 segmentation set [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 63925014,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "0ec48ac86456cea3d6d6172ca81ef68e98b21a61",
            "isKey": false,
            "numCitedBy": 3322,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-PASCAL-Visual-Object-Classes-Challenge-Zhang",
            "title": {
                "fragments": [],
                "text": "The PASCAL Visual Object Classes Challenge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 145
                            }
                        ],
                        "text": "We estimate the ground-vertical contact points using a decision tree classifier based on the shape of the perimeter of a region, as described by Lalonde et al. (2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 53249564,
            "fieldsOfStudy": [],
            "id": "6d1677b22c407b87d6216284988a9ae7603eb97f",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Photo clip art"
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH 2007"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 86
                            }
                        ],
                        "text": "Early computer vision successes in image understanding, such as Roberts\u2019 blocks world (Roberts 1965), encouraged interest in occlusion reasoning as a key component for a complete scene analysis system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Machine perception of 3-D solids"
            },
            "venue": {
                "fragments": [],
                "text": "In OEOIP,"
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 118
                            }
                        ],
                        "text": "This line labeling paradigm has been very influential over the years, with extensions to handle curved objects (e.g., Jain and Aggarwal 1979; Malik 1987) as well as algebraic (Sugihara 1984a, 1984b) and MRF-based (Saund 2006) reformulations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computer analysis of scenes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An interiorpoint method for large - scale l 1regularized logistic regression"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Machine Learning Research"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recov - ering occlusion boundaries from an image Impossible objects as nonsense sentences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 132
                            }
                        ],
                        "text": "The graph can be used directly through graph-based search techniques (Elder and Zucker 1996; Jacobs 1993; Amir and Lindenbaum 1998; Jermyn and Ishikawa 2001) to find the contours."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Globally optimal regions"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE,"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A factorization approach to group"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 43
                            }
                        ],
                        "text": "In fact, recent psychophysics experiments (McDermott 2004) suggest that T-junctions may not be the cause of occlusion percepts, but rather their byproduct."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Psychophysics with junctions"
            },
            "venue": {
                "fragments": [],
                "text": "in real images. Perception,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kovacs and B . Julesz . A closed curve is much more than an incomplete one : Effect of closure in figure - ground discrimination"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . Nat \u2019 l Academy of Science USA"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 138
                            }
                        ],
                        "text": "The affinities are based on computational realizations of the Gestalt principles of continuation, proximity and closure (Wertheimer 1938; Lowe 1985; Elder and Zucker 1996; Herault and Horaud 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perceptual organization and visual recognition. Kluwer Academic: Norwell"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Clowes . On seeing things"
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "anon placeholder. submitted"
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 176
                            }
                        ],
                        "text": "This line labeling paradigm has been very influential over the years, with extensions to handle curved objects (e.g., Jain and Aggarwal 1979; Malik 1987) as well as algebraic (Sugihara 1984a, 1984b) and MRF-based (Saund 2006) reformulations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An algebraic approach to the shape-from-imageproblem"
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence,"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Category independent object propos"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 116
                            }
                        ],
                        "text": "This is a linear classifier that can be used for feature selection (Ng 2004) or learning Markov network structures (Lee et al. 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient structure"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 68
                            }
                        ],
                        "text": "This is a linear classifier that can be used for feature selection (Ng 2004) or learning Markov network structures (Lee et al. 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "fier that can be used for feature selection [53] or learning Markov network structures [39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Feature selection, L1 vs"
            },
            "venue": {
                "fragments": [],
                "text": "L2 regularization, and rotational invariance. In ICML,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 220
                            }
                        ],
                        "text": "\u2026can mimic human 3D interpretation of line drawings, motivating others to formulate the 3D interpretation problem as optimization over an objective function that favors planarity, symmetry, and other \u201cnatural\u201d properties (Leclerc and Fischler 1992; Lipson and Shpitalni 1996; Shoji et al. 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An optimizationbased approach to the interpretation of single line drawings as 3 D wire frames"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 176
                            }
                        ],
                        "text": "This line labeling paradigm has been very influential over the years, with extensions to handle curved objects (e.g., Jain and Aggarwal 1979; Malik 1987) as well as algebraic (Sugihara 1984a, 1984b) and MRF-based (Saund 2006) reformulations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "Our strategy is to begin with a conservative oversegmentation into thousands of regions and slowly remove boundaries based on predictions from learned models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An algebraic approach to the shape-fromimage-problem"
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recovering occlusion boundaries from an image"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 45,
            "methodology": 34,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 99,
        "totalPages": 10
    },
    "page_url": "https://www.semanticscholar.org/paper/Recovering-Occlusion-Boundaries-from-an-Image-Hoiem-Efros/d6d7dcdcf66fe83e49d175cd9d8ac0b507d0e9d8?sort=total-citations"
}