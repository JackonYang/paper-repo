{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16462148,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19908640236767427ebf0524dc3a4bb09d65145e",
            "isKey": false,
            "numCitedBy": 1774,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, researchers have demonstrated that \"loopy belief propagation\" -- the use of Pearl's polytree algorithm in a Bayesian network with loops -- can perform well in the context of error-correcting codes. The most dramatic instance of this is the near Shannon-limit performance of \"Turbo Codes\" -- codes whose decoding algorithm is equivalent to loopy belief propagation in a chain-structured Bayesian network. \n \nIn this paper we ask: is there something special about the error-correcting code context, or does loopy propagation work as an approximate inference scheme in a more general setting? We compare the marginals computed using loopy propagation to the exact ones in four Bayesian network architectures, including two real-world networks: ALARM and QMR. We find that the loopy beliefs often converge and when they do, they give a good approximation to the correct marginals. However, on the QMR network, the loopy beliefs oscillated and had no obvious relationship to the correct posteriors. We present some initial investigations into the cause of these oscillations, and show that some simple methods of preventing them lead to the wrong results."
            },
            "slug": "Loopy-Belief-Propagation-for-Approximate-Inference:-Murphy-Weiss",
            "title": {
                "fragments": [],
                "text": "Loopy Belief Propagation for Approximate Inference: An Empirical Study"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper compares the marginals computed using loopy propagation to the exact ones in four Bayesian network architectures, including two real-world networks: ALARM and QMR, and finds that the loopy beliefs often converge and when they do, they give a good approximation to the correct marginals."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9011563,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15c10ae31b039fe50d5cb51f7dbac6cbc3e4102c",
            "isKey": false,
            "numCitedBy": 1657,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new deterministic approximation technique in Bayesian networks. This method, \"Expectation Propagation,\" unifies two previous techniques: assumed-density filtering, an extension of the Kalman filter, and loopy belief propagation, an extension of belief propagation in Bayesian networks. Loopy belief propagation, because it propagates exact belief states, is useful for a limited class of belief networks, such as those which are purely discrete. Expectation Propagation approximates the belief states by only retaining expectations, such as mean and varitmce, and iterates until these expectations are consistent throughout the network. This makes it applicable to hybrid networks with discrete and continuous nodes. Experiments with Gaussian mixture models show Expectation Propagation to be donvincingly better than methods with similar computational cost: Laplace's method, variational Bayes, and Monte Carlo. Expectation Propagation also provides an efficient algorithm for training Bayes point machine classifiers."
            },
            "slug": "Expectation-Propagation-for-approximate-Bayesian-Minka",
            "title": {
                "fragments": [],
                "text": "Expectation Propagation for approximate Bayesian inference"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Expectation Propagation approximates the belief states by only retaining expectations, such as mean and varitmce, and iterates until these expectations are consistent throughout the network, which makes it applicable to hybrid networks with discrete and continuous nodes."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3175219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "973cd47a48c79209aac17b24594636361941a051",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel inference algorithm for arbitrary, binary, undirected graphs. Unlike loopy belief propagation, which iterates fixed point equations, we directly descend on the Bethe free energy. The algorithm consists of two phases, first we update the pairwise probabilities, given the marginal probabilities at each unit, using an analytic expression. Next, we update the marginal probabilities, by following the negative gradient of the Bethe free energy. Both steps are guaranteed to decrease the Bethe free energy, and since it is lower bounded, the algorithm is guaranteed to converge to a local minimum. We also show that the Bethe free energy is equal to the TAP free energy up to second order in the weights. In experiments we confirm that when belief propagation converges it usually finds identical solutions as our belief optimization method. The stable nature of belief optimization makes it ideally suited for learning graphical models from data."
            },
            "slug": "Belief-Optimization-for-Binary-Networks:-A-Stable-Welling-Teh",
            "title": {
                "fragments": [],
                "text": "Belief Optimization for Binary Networks: A Stable Alternative to Loopy Belief Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A novel inference algorithm for arbitrary, binary, undirected graphs that directly descend on the Bethe free energy, which is ideally suited for learning graphical models from data."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3198578"
                        ],
                        "name": "J. Yedidia",
                        "slug": "J.-Yedidia",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Yedidia",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yedidia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 141225804,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "91699ea4bec60d4d47ca3db8c8d1e035d069d9e4",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "I try to clarify the relationships between different ways of deriving or correcting mean field theory, and present \u201dtranslations\u201d between the language of physicists and that of computer scientists. The connecting thread between the different methods described here is the Gibbs free energy. After introducing the inference problem we are interested in analyzing, I will define the Gibbs free energy, and describe how to derive a mean field approximation to it using a variational approach. I will then explain how one might re-derive and correct the mean field and TAP free energies using high temperature expansions with constrained one-node beliefs. I will explore the relationships between the high-temperature expansion approach, the Bethe approximation, and the belief propagation algorithm, and point out in particular the equivalence of the Bethe approximation and belief propagation. Finally, I will describe Kikuchi approximations to the Gibbs Free energy and advertise new belief propagation algorithms that efficiently compute beliefs equivalent to those obtained from the Kikuchi free energy. To appear as a chapter in \u201cAdvanced Mean Field Methods Theory and Practice\u201d, eds. D. Saad and M. Opper, MIT Press, 2000. This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Information Technology Center America; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Information Technology Center America. All rights reserved. Copyright c Mitsubishi Electric Information Technology Center America, 2000 201 Broadway, Cambridge, Massachusetts 02139 Publication History:\u2013 1. First printing, TR-2000-27, June 2000 ! \" # %$& ' () * ,+ .-0/ 1 2 314#57698#5 4;:= A@CB#DEB#DE5 F < F G 4,69H 3IB J#KL6MDE314 NPORQTS UWV)XYS'ZL[7Q]\\_^`NAabUdcec QT^]fgQ]hiXjcWZL^]UlkmfnQTS \\o^T\\9cdZLQTUdhpO VTS Ud[ Vrq1\\jQsat\\_\\9Ovu7Ulw,\\_^]\\_O Q atZxf7V)hLkyu7\\9^TUdzCUeO {nhp^|Xjh ^T^]\\9XjQTUdO {i}|\\9ZpO\u007f~ \\9cduvQTS \\9hp^]fp\u0080 \u0081 S \\\"\u0082y\\MXj\\_})q'\\9^0\u0083M\u0084p\u0084 \u0084 \u0085\u0086Ns\u0087 \u0088nathp^]\u00897V\u008aS h [ih O!\u008b]\u008cyu7z ZpO Xj\\Mun\u008d\u008e\\MZLO\u007f\u008f#Ue\\9cduR\u008d\u008e\\_QTS h7u V]\u0090\u008eVT\u0091 X_X_\\_\\9u \\9u O UWXj\\_cdf UeO q ^]UeO { UeO {\u0092Q]hp{p\\_QTS \\9^A[ SCfCVTUWXjUWVsQYV\u0093ZpO u Xjhp}|[ \u0091 QT\\_^rV]XjUd\\_O QTUWV\u008aQ]V9\u0094 abS h0O h atZ u Zxf7V hLk\u0095QT\\9O0athp^]\u0089|hpO0[ ^T\\MXjUWV\u008a\\9cef\u0096Q]S \\rVTZp}\u0096\\\u0097[ ^]hpq cd\\_}\u0098V9\u0094 q \u00917Q\u0086Xjhp}|\\\u0097QTh)QTS \\MV\u008a\\\u0093[ ^]hpq cd\\_}\u0098V abUlQ]S%u7Uew1\\9^T\\9O Qn['\\9^]VT['\\MX\u0099Q]Uez \\9V9\u0094y}|\\jQ]S h7u V_\u0094\u0093O Zp}\u0096\\MViZpO u O hLQYZ Q]Ueh O V_\u0080\u0093\u0088Chp}|\\\u009ahpk QTS UWV\u0086XYS Zp[7QT\\9^bUdVtQ]S \\_^]\\jkmh ^T\\ru7\\9zphLQ]\\9u\u0092QTh|[ ^]\\9VT\\_O QTUdO {\u0096QT^YZLO'V\u008acWZ Q]Ueh O Vtq'\\_Qsa \\9\\_O0QTS \\ cdZpO {p\u0091 Zp{p\\0hLkyQ]S \\\"[ SCf7V\u008aUWXjUWVsQ\u0098ZLO'uvQ]S \\\"cdZpO {p\u0091 Zp{p\\0hLk\u0086Q]S \\\u008eXjhp}|[ \u0091 QT\\_^oV]XjUd\\_O Q]UdV\u008aQ9\u0094 ZLceQTS h \u0091 {pSvN`Zp}\u009bV\u008a\u0091 ^]\\oQ]S Z Q\u0096}\u009cfRhp^]Ud{pUdO ZLc QT^YZLUdO UeO {nZpV)Zg[ SCf7VTUdX_UdV\u008aQ)abUdcec VTS h a QTS ^]hp\u0091 { SI\u0080 N abUecdc hpO cef\u009cX_h zp\\9^#}|\\_QTS h7u V?Q]S Z Q N#S Zxzp\\t[1\\_^YV\u008ah O ZLcdcefr\u0091'V\u008a\\Mu \u0094pVTh\u0097Q]S UWV XYS ZL[7Q]\\_^ u7hC\\9V\u007fO hpQ\u009aZ QTQT\\_}|[7Q\u009aQTh\u009dq1\\\u009eZ!QTS h ^Th \u0091 {pS\u009fVT\u0091 ^Tz \\_f.hpk UeQ]V\u009aV\u008a\u0091 q is\\9X\u0099QM\u0080)\u00a2b\\MZpu7\\9^]V UeO QT\\9^T\\MVsQ]\\9uRUdOv}|hp^]\\oq Z XY\u0089 { ^Th \u0091 O u hpORQ]S \\0V\u008aQ]ZLQTUWVsQ]UdX9ZLc [ SCfCVTUWX_V`hpkyu7UWV\u008ah ^]u7\\9^T\\Mu V\u008af7V\u008aQT\\_}\u0098V \u00a3m[ Zp^\u008aQ]UdX_\u0091 cWZL^]cef\u00a4abUeQTS\u009e^]\\_{ ZL^Yu\u00a5QTh\u009aQTS \\nQT\\MXYS O UW\u00a6 \u0091 \\nhpk)Zxzp\\9^]Zp{pUdO {Rh zp\\_^ u7UdVThp^Yu7\\9^ \u0091 V\u008aUdO {rQ]S \\\u0086^]\\_[ cdUWX_Z\u0093}|\\jQTS hCu'\u00a7 }|Ue{ S Q ZLcWV\u008ahra ZLO Q QTh`X_hpO VT\u0091 ceQ ^]\\jkm\\_^]\\_O'Xj\\9V \u00a3s\u00839\u0084 \u00a7\u0099\u0094)\u00a3 L\u00a9 \u00a7\u0099\u0094\u0097ZpO u\u009f\u00a3Ea \u0083M\u00a7\u0099\u0094\u0097abS Udce\\RQ]S h VT\\vUdO Q]\\_^]\\9V\u008aQT\\Mu;UdO QTS \\\u009aXjh }\u0096[ \u00917QT\\9^iVTX_Ue\\9O Xj\\ ceUeQT\\9^]ZLQT\u0091 ^]\\\u0098hpO\u007f{ ^]Zp[ S UWX_ZLc }\u0096h7u7\\9cdV\u009c}|Ue{ S Q\u009cX_hpO VT\u0091 ceQ\u009c^]\\jkm\\_^]\\_O'Xj\\9V\u0092\u00a3* La \u00a7\u0099\u0094t\u00a3s\u0083p\u0083M\u00a7`ZLO'u \u00a3 \u00abL\u00a7j\u0080 \u0081 S \\\u0086X_hpO O \\9X\u0099Q]UeO {\u0097Q]S ^]\\9Zpu\u0096q1\\jQsat\\_\\9O)Q]S \\\u0086u7Uew1\\9^T\\9O Q=}\u0096\\_QTS h7u V u7\\9V]Xj^]Ueq1\\9u\u0096S \\9^T\\ UdV QTS \\r\u00ac\u0093Udq q V km^T\\9\\y\\_O \\_^]{pfp\u0080C\u008cbk\u0095Q]\\_^tUeO Q]^Th7u7\u0091 X_UeO {`QTS \\\u0097UdO7km\\_^]\\_O'Xj\\y[ ^Th q ce\\9}\u009fa \\yZp^T\\ UeO QT\\9^T\\MVsQ]\\9u\u0092UeO ZLO ZpcefC\u00ad_UdO {'\u0094 N=abUdcdcIu7\\j~ O \\yQ]S \\`\u00ac\u0093Ueq q'V km^]\\_\\\u0093\\_O \\_^]{pfp\u0094CZLO'u\u0092u7\\MVTX_^TUdq'\\ S h a\u009dQTh\u008eu7\\9^TUdzp\\\u0096Z\u0092}|\\MZLOn~ \\_cWunZp[ [ ^]hx\u00ae7Ue}\u0098Z Q]Ueh O\"QTh\"UeQA\u0091'V\u008aUdO {\"Z\u0092z ZL^]UWZ QTUdhpO'ZLc?ZL[7 [ ^Th ZpXYSI\u0080MNIabUdcecCQ]S \\_O\u0096\\j\u00ae7[ cWZLUdO\u009cS h avhpO \\t}|Ue{ S Q#^]\\j Pu7\\_^]Udzp\\ ZpO u\u009cX_hp^]^T\\MX\u0099Q QTS \\ }|\\9ZpO ~ \\_cWu)ZpO u\u0096\u0081 \u008c\u0097\u0087gkm^]\\_\\ \\_O \\_^]{pUd\\9V \u0091 V\u008aUdO {AS Ud{pS\u009cQT\\_}|[1\\_^YZ Q]\u0091 ^T\\ \\_\u00aeC['ZLO VTUeh O V abUlQ]S\u0096X_hpO7 VsQ]^]ZpUeO \\Mu\u007fhpO \\j \u00b0O h7u7\\\u0092q1\\_cdUe\\_kEV_\u0080 N\u009cabUecdc \\j\u00ae7[ cdhp^]\\\u0098QTS \\\"^]\\_cWZ Q]Ueh O V\u008aS Ue[ V\u009cq'\\_Qsa \\9\\_O\u009aQTS \\ S Ue{ S7 QT\\_}|[1\\_^YZ Q]\u0091 ^T\\i\\j\u00ae7[ ZLO'V\u008aUdhpO\u00b1Zp[ [ ^]h ZpXYS \u0094 QTS \\R2t\\jQ]S \\nZp[ [ ^]hx\u00aeCUd}\u0098Z Q]Ueh OI\u0094 ZLO'u QTS \\Aq1\\_cdUe\\_k#[ ^]hp['ZL{ ZLQTUdhpO\u0092Zpce{ hp^]UlQ]S }\"\u00947ZLO u\u0092['h UeO Qbhp\u00917QbUdO0['ZL^TQTUWXj\u0091 cWZL^tQTS \\\u0093\\M\u00a6 \u0091 Uez ZLcd\\_O X_\\bhLk1QTS \\y2t\\_QTS \\yZp[ [ ^]hx\u00ae7Ue}\u0098Z Q]Ueh O)ZpO u|q'\\9ceUd\\jk [ ^]hp['ZL{ ZLQTUdhpOI\u0080 \u008f#UdO ZLcdcef \u0094pN#abUecdc u7\\9V]Xj^]Ueq1\\o3AUd\u0089 \u0091'XYS U ZL[ [ ^Thx\u00ae7Ud}\u0098Z QTUdhpO'V\u0093QTh\"QTS \\0\u00ac\u0093Ueq q V\u009c\u008f ^T\\9\\\u0098\\_O \\9^T{ fnZLO'u Z u7zp\\9^\u008a QTUWV\u008a\\0O \\_a q1\\_cdUe\\_k\u0086[ ^]hp[ Zp{ Z Q]Ueh O Zpce{ hp^]UlQ]S }\u0098VrQ]S Z Q\u0096\\j\u03bcoXjUd\\_O QTcdfRXjhp}|[ \u0091 QT\\\u0092q1\\_cdUd\\jkEV \\9\u00a6 \u0091 UdzxZpce\\9O QtQ]h|QTS h V\u008a\\Ah q7Q]ZpUeO \\Mu0km^Th } QTS \\`3AUd\u0089C\u0091 XYS U,km^]\\_\\A\\_O \\_^]{pfp\u0080 \u00b6A\u00b7\u0095 \u008e11o \u00bbs1\u20444*1\u20444 \u00b6r1\u20442]3\u20444*? AYA#\u00c2jAYA\u0099A\u0099A\u0099AjAYA\u0099AjA9AEsCxEEAE\u008aEME E\u0099II1'1\u20442YI\u0099\u00bb AE"
            },
            "slug": "An-Idiosyncratic-Journey-Beyond-Mean-Field-Theory-Yedidia",
            "title": {
                "fragments": [],
                "text": "An Idiosyncratic Journey Beyond Mean Field Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3231485"
                        ],
                        "name": "S. Aji",
                        "slug": "S.-Aji",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Aji",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Aji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8543612,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0a2c4d26f8279eefdec9f46466da8e6812f649e9",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In an important recent paper, Yedidia, Freeman, and Weiss [7] showed that there is a close connection between the belief propagation algorithm for probabilistic inference and the Bethe-Kikuchi approximation to the variational free energy in statistical physics. In this paper, we will recast the YFW results in the context of the \u201cgeneralized distributive law\u201d [1] formulation of belief propagation. Our main result is that if the GDL is applied to junction graph, the fixed points of the algorithm are in one-to-one correspondence with the stationary points of a certain Bethe-Kikuchi free energy. If the junction graph has no cycles, the BK free energy is convex and has a unique stationary point, which is a global minimum. On the other hand, if the junction graph has cycles, the main result at least shows that the GDL is trying to do something sensible."
            },
            "slug": "The-Generalized-Distributive-Law-and-Free-Energy-Aji-McEliece",
            "title": {
                "fragments": [],
                "text": "The Generalized Distributive Law and Free Energy Minimization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157745208"
                        ],
                        "name": "Jung-Fu Cheng",
                        "slug": "Jung-Fu-Cheng",
                        "structuredName": {
                            "firstName": "Jung-Fu",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jung-Fu Cheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14553992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26d953005dd08a863c157b528bbabdf5671d18b6",
            "isKey": false,
            "numCitedBy": 1004,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the close connection between the now celebrated iterative turbo decoding algorithm of Berrou et al. (1993) and an algorithm that has been well known in the artificial intelligence community for a decade, but which is relatively unknown to information theorists: Pearl's (1982) belief propagation algorithm. We see that if Pearl's algorithm is applied to the \"belief network\" of a parallel concatenation of two or more codes, the turbo decoding algorithm immediately results. Unfortunately, however, this belief diagram has loops, and Pearl only proved that his algorithm works when there are no loops, so an explanation of the experimental performance of turbo decoding is still lacking. However, we also show that Pearl's algorithm can be used to routinely derive previously known iterative, but suboptimal, decoding algorithms for a number of other error-control systems, including Gallager's (1962) low-density parity-check codes, serially concatenated codes, and product codes. Thus, belief propagation provides a very attractive general methodology for devising low-complexity iterative decoding algorithms for hybrid coded systems."
            },
            "slug": "Turbo-Decoding-as-an-Instance-of-Pearl's-\"Belief-McEliece-Mackay",
            "title": {
                "fragments": [],
                "text": "Turbo Decoding as an Instance of Pearl's \"Belief Propagation\" Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that Pearl's algorithm can be used to routinely derive previously known iterative, but suboptimal, decoding algorithms for a number of other error-control systems, including Gallager's low-density parity-check codes, serially concatenated codes, and product codes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE J. Sel. Areas Commun."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": false,
            "numCitedBy": 18710,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1889982"
                        ],
                        "name": "F. Kschischang",
                        "slug": "F.-Kschischang",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Kschischang",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kschischang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143681410"
                        ],
                        "name": "H. Loeliger",
                        "slug": "H.-Loeliger",
                        "structuredName": {
                            "firstName": "Hans-Andrea",
                            "lastName": "Loeliger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Loeliger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14394619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08c370eb9ba13bfb836349e7f3ea428be4697818",
            "isKey": false,
            "numCitedBy": 4132,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms that must deal with complicated global functions of many variables often exploit the manner in which the given functions factor as a product of \"local\" functions, each of which depends on a subset of the variables. Such a factorization can be visualized with a bipartite graph that we call a factor graph, In this tutorial paper, we present a generic message-passing algorithm, the sum-product algorithm, that operates in a factor graph. Following a single, simple computational rule, the sum-product algorithm computes-either exactly or approximately-various marginal functions derived from the global function. A wide variety of algorithms developed in artificial intelligence, signal processing, and digital communications can be derived as specific instances of the sum-product algorithm, including the forward/backward algorithm, the Viterbi algorithm, the iterative \"turbo\" decoding algorithm, Pearl's (1988) belief propagation algorithm for Bayesian networks, the Kalman filter, and certain fast Fourier transform (FFT) algorithms."
            },
            "slug": "Factor-graphs-and-the-sum-product-algorithm-Kschischang-Frey",
            "title": {
                "fragments": [],
                "text": "Factor graphs and the sum-product algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A generic message-passing algorithm, the sum-product algorithm, that operates in a factor graph, that computes-either exactly or approximately-various marginal functions derived from the global function."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3231485"
                        ],
                        "name": "S. Aji",
                        "slug": "S.-Aji",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Aji",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Aji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11355291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e8933300a20f3d799dc9f19e352967f41d8efcc",
            "isKey": false,
            "numCitedBy": 773,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss a general message passing algorithm, which we call the generalized distributive law (GDL). The GDL is a synthesis of the work of many authors in information theory, digital communications, signal processing, statistics, and artificial intelligence. It includes as special cases the Baum-Welch algorithm, the fast Fourier transform (FFT) on any finite Abelian group, the Gallager-Tanner-Wiberg decoding algorithm, Viterbi's algorithm, the BCJR algorithm, Pearl's \"belief propagation\" algorithm, the Shafer-Shenoy probability propagation algorithm, and the turbo decoding algorithm. Although this algorithm is guaranteed to give exact answers only in certain cases (the \"junction tree\" condition), unfortunately not including the cases of GTW with cycles or turbo decoding, there is much experimental evidence, and a few theorems, suggesting that it often works approximately even when it is not supposed to."
            },
            "slug": "The-generalized-distributive-law-Aji-McEliece",
            "title": {
                "fragments": [],
                "text": "The generalized distributive law"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Although this algorithm is guaranteed to give exact answers only in certain cases (the \"junction tree\" condition), unfortunately not including the cases of GTW with cycles or turbo decoding, there is much experimental evidence, and a few theorems, suggesting that it often works approximately even when it is not supposed to."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891751"
                        ],
                        "name": "E. Pasztor",
                        "slug": "E.-Pasztor",
                        "structuredName": {
                            "firstName": "Egon",
                            "lastName": "Pasztor",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Pasztor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2575670"
                        ],
                        "name": "Owen Carmichael",
                        "slug": "Owen-Carmichael",
                        "structuredName": {
                            "firstName": "Owen",
                            "lastName": "Carmichael",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Owen Carmichael"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1414109,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "861897df39716877fb1e03a7d09a234faca076e9",
            "isKey": false,
            "numCitedBy": 1220,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a learning-based method for low-level vision problems\u2014estimating scenes from images. We generate a synthetic world of scenes and their corresponding rendered images, modeling their relationships with a Markov network. Bayesian belief propagation allows us to efficiently find a local maximum of the posterior probability for the scene, given an image. We call this approach VISTA\u2014Vision by Image/Scene TrAining.We apply VISTA to the \u201csuper-resolution\u201d problem (estimating high frequency details from a low-resolution image), showing good results. To illustrate the potential breadth of the technique, we also apply it in two other problem domains, both simplified. We learn to distinguish shading from reflectance variations in a single image under particular lighting conditions. For the motion estimation problem in a \u201cblobs world\u201d, we show figure/ground discrimination, solution of the aperture problem, and filling-in arising from application of the same probabilistic machinery."
            },
            "slug": "Learning-Low-Level-Vision-Freeman-Pasztor",
            "title": {
                "fragments": [],
                "text": "Learning Low-Level Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A learning-based method for low-level vision problems\u2014estimating scenes from images with Bayesian belief propagation, applied to the \u201csuper-resolution\u201d problem (estimating high frequency details from a low-resolution image), showing good results."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 32583695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70ef29e6f0ce082bb8a47fd85b9bfb7cc0f20c93",
            "isKey": false,
            "numCitedBy": 18218,
            "numCiting": 230,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nProbabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty\u0097and offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognition\u0097in short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. \nProbabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability."
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-of-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems - networks of plausible inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic."
            },
            "venue": {
                "fragments": [],
                "text": "Morgan Kaufmann series in representation and reasoning"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6518359,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8871254256b95f52fe6a2c0edeee0fa706c1117",
            "isKey": false,
            "numCitedBy": 370,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Until recently, artificial intelligence researchers have frowned upon the application of probability propagation in Bayesian belief networks that have cycles. The probability propagation algorithm is only exact in networks that are cycle-free. However, it has recently been discovered that the two best error-correcting decoding algorithms are actually performing probability propagation in belief networks with cycles."
            },
            "slug": "A-Revolution:-Belief-Propagation-in-Graphs-with-Frey-Mackay",
            "title": {
                "fragments": [],
                "text": "A Revolution: Belief Propagation in Graphs with Cycles"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "Until recently, artificial intelligence researchers have frowned upon the application of probability propagation in Bayesian belief networks that have cycles, but it has recently been discovered that the two best error-correcting decoding algorithms are actually performing probability propagation with cycles."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3637824"
                        ],
                        "name": "R. M. Tanner",
                        "slug": "R.-M.-Tanner",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tanner",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. M. Tanner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 754232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "157218bae792b6ef550dfd0f73e688d83d98b3d7",
            "isKey": false,
            "numCitedBy": 2971,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is described for constructing long error-correcting codes from one or more shorter error-correcting codes, referred to as subcodes, and a bipartite graph. A graph is shown which specifies carefully chosen subsets of the digits of the new codes that must be codewords in one of the shorter subcodes. Lower bounds to the rate and the minimum distance of the new code are derived in terms of the parameters of the graph and the subeodes. Both the encoders and decoders proposed are shown to take advantage of the code's explicit decomposition into subcodes to decompose and simplify the associated computational processes. Bounds on the performance of two specific decoding algorithms are established, and the asymptotic growth of the complexity of decoding for two types of codes and decoders is analyzed. The proposed decoders are able to make effective use of probabilistic information supplied by the channel receiver, e.g., reliability information, without greatly increasing the number of computations required. It is shown that choosing a transmission order for the digits that is appropriate for the graph and the subcodes can give the code excellent burst-error correction abilities. The construction principles"
            },
            "slug": "A-recursive-approach-to-low-complexity-codes-Tanner",
            "title": {
                "fragments": [],
                "text": "A recursive approach to low complexity codes"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that choosing a transmission order for the digits that is appropriate for the graph and the subcodes can give the code excellent burst-error correction abilities."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103572659"
                        ],
                        "name": "R. Kikuchi",
                        "slug": "R.-Kikuchi",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Kikuchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kikuchi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119505101,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "aa59898d5d643aec5cc523523f07b42452cd514e",
            "isKey": false,
            "numCitedBy": 1426,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method of approximation for order-disorder phenomena is developed. In Sec. A, the method is explained for the one-dimensional Ising lattice. Sections B and C cover the approximations already known, such as those of Bethe (Sec. B) and of Kramers-Wannier (Sec. C), which are shown to be derived as special cases of the method with suitable choices of variables. In Sec. D, an improved treatment is explained for the three-dimensional simple cubic Ising lattice. This approximation is found to agree with the rigorous expansion of the partition function up to the fourth moment by Kirkwood's moment method, so far as the disordered state is concerned. In Sec. E the general formula for the entropy is given. In Sec. H an improved treatment of the face-centered lattice (Ising model) is given."
            },
            "slug": "A-Theory-of-Cooperative-Phenomena-Kikuchi",
            "title": {
                "fragments": [],
                "text": "A Theory of Cooperative Phenomena"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1951
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66269502"
                        ],
                        "name": "R. Baxter",
                        "slug": "R.-Baxter",
                        "structuredName": {
                            "firstName": "Rodney",
                            "lastName": "Baxter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Baxter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 117867044,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "5e6a4eda0a3d0d3a8c2864fd3afee4e67026bd40",
            "isKey": false,
            "numCitedBy": 5490,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "exactly solved models in statistical mechanics exactly solved models in statistical mechanics rodney j baxter exactly solved models in statistical mechanics exactly solved models in statistical mechanics flae exactly solved models in statistical mechanics dover books exactly solved models in statistical mechanics dover books exactly solved models in statistical mechanics dover books hatsutori in size 15 gvg7bzbookyo.qhigh literature cited r. j. baxter, exactly solved models in exactly solvable models in statistical mechanics exactly solved models in statistical mechanics dover books okazaki in size 24 vk19j3book.buncivy exactly solved models of statistical mechanics valerio nishizawa in size 11 b4zntdbookntey fukuda in size 13 33oloxbooknhuy yamada in size 19 x6g84ybook.zolay in honour of r j baxter\u2019s 75th birthday arxiv:1608.04899v2 statistical mechanics, threedimensionality and np beautiful models: 70 years of exactly solved quantum many exactly solved models in statistical mechanics (dover solved lattice models: 1944 2010 university of melbourne exactly solved models and beyond: a special issue in the statistical mechanics of the classical two-dimensional faculty of science, p. j. saf \u0301arik university in ko?sice? a one-dimensional statistical mechanics model with exact statistical mechanics department of physics and astronomy statistical mechanics principles and selected applications graph theory and statistical physics yaroslavvb chapter 4 methods of statistical mechanics ijs thermodynamics and an introduction to thermostatistics potts models and related problems in statistical mechanics methods of quantum field theory in statistical physics statistical mechanics: theory and molecular simulation exactly solvable su(n) mixed spin ladders springer statistical field theory : an introduction to exactly"
            },
            "slug": "Exactly-solved-models-in-statistical-mechanics-Baxter",
            "title": {
                "fragments": [],
                "text": "Exactly solved models in statistical mechanics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58792451,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0a3767909649cf31d32e087693d93171af28ebe0",
            "isKey": false,
            "numCitedBy": 4303,
            "numCiting": 126,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Local-computations-with-probabilities-on-graphical-Lauritzen-Spiegelhalter",
            "title": {
                "fragments": [],
                "text": "Local computations with probabilities on graphical structures and their application to expert systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144572614"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16406992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01c3188460d25219433c2dc28629d61b18970d54",
            "isKey": false,
            "numCitedBy": 2319,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "We report theoretical and empirical properties of Gallager's (1963) low density parity check codes on Gaussian channels. It can be proved that, given an optimal decoder, these codes asymptotically approach the Shannon limit. With a practical 'belief propagation' decoder, performance substantially better than that of standard convolutional and concatenated codes can be achieved; indeed the performance is almost as close to the Shannon limit as that of turbo codes."
            },
            "slug": "Good-error-correcting-codes-based-on-very-sparse-Mackay",
            "title": {
                "fragments": [],
                "text": "Good Error-Correcting Codes Based on Very Sparse Matrices"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "It can be proved that, given an optimal decoder, Gallager's low density parity check codes asymptotically approach the Shannon limit."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35191477"
                        ],
                        "name": "F. V. Jensen",
                        "slug": "F.-V.-Jensen",
                        "structuredName": {
                            "firstName": "Finn",
                            "lastName": "Jensen",
                            "middleNames": [
                                "Verner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. V. Jensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61412478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3febde16cb99b8107fecff79905ca61a5e8cd170",
            "isKey": false,
            "numCitedBy": 1493,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Computational modelling of probability has become a major part of automated decision support systems. In this book, the principal ideas of probabilistic reasoning - known as Bayesian networks - are outlined and their practical implications illustrated. The book is intended for MSc students in knowledge-based systems, artificial intelligence and statistics, and for professionals in decision support systems applications and research."
            },
            "slug": "An-introduction-to-Bayesian-networks-Jensen",
            "title": {
                "fragments": [],
                "text": "An introduction to Bayesian networks"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The principal ideas of probabilistic reasoning - known as Bayesian networks - are outlined and their practical implications illustrated and are intended for MSc students in knowledge-based systems, artificial intelligence and statistics, and for professionals in decision support systems applications and research."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770859"
                        ],
                        "name": "R. Gallager",
                        "slug": "R.-Gallager",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gallager",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gallager"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12709402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "206f827fad201506c315d40c1469b41a45141893",
            "isKey": false,
            "numCitedBy": 10568,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A low-density parity-check code is a code specified by a parity-check matrix with the following properties: each column contains a small fixed number j \\geq 3 of l's and each row contains a small fixed number k > j of l's. The typical minimum distance of these codes increases linearly with block length for a fixed rate and fixed j . When used with maximum likelihood decoding on a sufficiently quiet binary-input symmetric channel, the typical probability of decoding error decreases exponentially with block length for a fixed rate and fixed j . A simple but nonoptimum decoding scheme operating directly from the channel a posteriori probabilities is described. Both the equipment complexity and the data-handling capacity in bits per second of this decoder increase approximately linearly with block length. For j > 3 and a sufficiently low rate, the probability of error using this decoder on a binary symmetric channel is shown to decrease at least exponentially with a root of the block length. Some experimental results show that the actual probability of decoding error is much smaller than this theoretical bound."
            },
            "slug": "Low-density-parity-check-codes-Gallager",
            "title": {
                "fragments": [],
                "text": "Low-density parity-check codes"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A simple but nonoptimum decoding scheme operating directly from the channel a posteriori probabilities is described and the probability of error using this decoder on a binary symmetric channel is shown to decrease at least exponentially with a root of the block length."
            },
            "venue": {
                "fragments": [],
                "text": "IRE Trans. Inf. Theory"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770859"
                        ],
                        "name": "R. Gallager",
                        "slug": "R.-Gallager",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gallager",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gallager"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121902258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eff026fee8b554a445ac881e5ffa899688e799a6",
            "isKey": false,
            "numCitedBy": 4192,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Communication Systems and Information Theory. A Measure of Information. Coding for Discrete Sources. Discrete Memoryless Channels and Capacity. The Noisy-Channel Coding Theorem. Techniques for Coding and Decoding. Memoryless Channels with Discrete Time. Waveform Channels. Source Coding with a Fidelity Criterion. Index."
            },
            "slug": "Information-Theory-and-Reliable-Communication-Gallager",
            "title": {
                "fragments": [],
                "text": "Information Theory and Reliable Communication"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This chapter discusses Coding for Discrete Sources, Techniques for Coding and Decoding, and Source Coding with a Fidelity Criterion."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1833925"
                        ],
                        "name": "C. Berrou",
                        "slug": "C.-Berrou",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "Berrou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Berrou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1870588"
                        ],
                        "name": "A. Glavieux",
                        "slug": "A.-Glavieux",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Glavieux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Glavieux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2952051"
                        ],
                        "name": "P. Thitimajshima",
                        "slug": "P.-Thitimajshima",
                        "structuredName": {
                            "firstName": "Punya",
                            "lastName": "Thitimajshima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Thitimajshima"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17770377,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "3ba9baa534a8ea39a31c69e72ada959aaa6a4dc1",
            "isKey": false,
            "numCitedBy": 8239,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "A new class of convolutional codes called turbo-codes, whose performances in terms of bit error rate (BER) are close to the Shannon limit, is discussed. The turbo-code encoder is built using a parallel concatenation of two recursive systematic convolutional codes, and the associated decoder, using a feedback decoding rule, is implemented as P pipelined identical elementary decoders.<<ETX>>"
            },
            "slug": "Near-Shannon-limit-error-correcting-coding-and-1-Berrou-Glavieux",
            "title": {
                "fragments": [],
                "text": "Near Shannon limit error-correcting coding and decoding: Turbo-codes. 1"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A new class of convolutional codes called turbo-codes, whose performances in terms of bit error rate (BER) are close to the Shannon limit, is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ICC '93 - IEEE International Conference on Communications"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62488180,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "629cc74dcaf655feea40f64cd74617ac884ed0f8",
            "isKey": false,
            "numCitedBy": 621,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Probabilistic inference in graphical models pattern classification unsupervised learning data compression channel coding future research directions."
            },
            "slug": "Graphical-Models-for-Machine-Learning-and-Digital-Frey",
            "title": {
                "fragments": [],
                "text": "Graphical Models for Machine Learning and Digital Communication"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "Probabilistic inference in graphical models pattern classification unsupervised learning data compression channel coding future research directions and how this affects research directions is investigated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45232003,
            "fieldsOfStudy": [],
            "id": "a57520b68e73b5e1fc3668b443daf74ebe957cc7",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast Approximate Energy Minimization via Graph Cuts"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 23,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Understanding-belief-propagation-and-its-Yedidia-Freeman/05a281df21f4cb2b01e7751c50a4cba3ae0b992f?sort=total-citations"
}