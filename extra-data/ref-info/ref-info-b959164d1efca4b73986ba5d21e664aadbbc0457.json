{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8992604"
                        ],
                        "name": "E. Levin",
                        "slug": "E.-Levin",
                        "structuredName": {
                            "firstName": "Esther",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Levin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759839"
                        ],
                        "name": "S. Solla",
                        "slug": "S.-Solla",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Solla",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Solla"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15012839,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b10440620da8a43a1b97e3da4b1ff13746306475",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of learning a general input-output relation using a layered neural network is discussed in a statistical framework. By imposing the consistency condition that the error minimization be equivalent to a likelihood maximization for training the network, the authors arrive at a Gibbs distribution on a canonical ensemble of networks with the same architecture. This statistical description enables them to evaluate the probability of a correct prediction of an independent example, after training the network on a given training set. The prediction probability is highly correlated with the generalization ability of the network, as measured outside the training set. This suggests a general and practical criterion for training layered networks by minimizing prediction errors. The authors demonstrate the utility of this criterion for selecting the optimal architecture in the continuity problem. As a theoretical application of the statistical formalism, they discuss the question of learning curves and estimate the sufficient training size needed for correct generalization, in a simple example.<<ETX>>"
            },
            "slug": "Consistent-inference-of-probabilities-in-layered-Tishby-Levin",
            "title": {
                "fragments": [],
                "text": "Consistent inference of probabilities in layered networks: predictions and generalizations"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The problem of learning a general input-output relation using a layered neural network is discussed in a statistical framework and the authors arrive at a Gibbs distribution on a canonical ensemble of networks with the same architecture."
            },
            "venue": {
                "fragments": [],
                "text": "International 1989 Joint Conference on Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8992604"
                        ],
                        "name": "E. Levin",
                        "slug": "E.-Levin",
                        "structuredName": {
                            "firstName": "Esther",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Levin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759839"
                        ],
                        "name": "S. Solla",
                        "slug": "S.-Solla",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Solla",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Solla"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5254307,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0658717c77b812cab5943f13564e1aa2f06f6e71",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A general statistical description of the problem of learning from examples is presented. Learning in layered networks is posed as a search in the network parameter space for a network that minimizes an additive error function of a statistically independent examples. By imposing the equivalence of the minimum error and the maximum likelihood criteria for training the network, the Gibbs distribution on the ensemble of networks with a fixed architecture is derived. The probability of correct prediction of a novel example can be expressed using the ensemble, serving as a measure to the network's generalization ability. The entropy of the prediction distribution is shown to be a consistent measure of the network's performance. The proposed formalism is applied to the problems of selecting an optimal architecture and the prediction of learning curves. >"
            },
            "slug": "A-statistical-approach-to-learning-and-in-layered-Levin-Tishby",
            "title": {
                "fragments": [],
                "text": "A statistical approach to learning and generalization in layered neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The proposed formalism is applied to the problems of selecting an optimal architecture and the prediction of learning curves and the Gibbs distribution on the ensemble of networks with a fixed architecture is derived."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '89"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 43
                            }
                        ],
                        "text": "[All the interpolation models discussed in MacKay (1992a) can be interpreted as two-layer networks with a fixed nonlinear first layer and adaptive linear second layer.]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 83
                            }
                        ],
                        "text": "Review of Bayesian Regularization and Model Comparison ___ In the companion paper (MacKay 1992a) it was demonstrated how the control parameters a and /3 are assigned by Bayes, and how alternative interpolation models can be compared."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "MacKay (1992a) also reviewed how the Bayesian choice of a and , B is neatly expressed in terms of a measure of the number of well-determined parameters in a model, y."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 130
                            }
                        ],
                        "text": "We need to evaluate or approximate the inverse Hessian of M, and we need to evaluate or approximate its determinant and/or trace (MacKay 1992a). for the purpose of evaluating weight saliency and for assigning error bars to weights and network outputs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 49
                            }
                        ],
                        "text": "Figure 5 introduces the quantity y, discussed in MacKay (1992a), the number of well-measured parameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6530745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7abda1941534d3bb558dd959025d67f1df526303",
            "isKey": false,
            "numCitedBy": 792,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Three Bayesian ideas are presented for supervised adaptive classifiers. First, it is argued that the output of a classifier should be obtained by marginalizing over the posterior distribution of the parameters; a simple approximation to this integral is proposed and demonstrated. This involves a \"moderation\" of the most probable classifier's outputs, and yields improved performance. Second, it is demonstrated that the Bayesian framework for model comparison described for regression models in MacKay (1992a,b) can also be applied to classification problems. This framework successfully chooses the magnitude of weight decay terms, and ranks solutions found using different numbers of hidden units. Third, an information-based data selection criterion is derived and demonstrated within this framework."
            },
            "slug": "The-Evidence-Framework-Applied-to-Classification-Mackay",
            "title": {
                "fragments": [],
                "text": "The Evidence Framework Applied to Classification Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is demonstrated that the Bayesian framework for model comparison described for regression models in MacKay (1992a,b) can also be applied to classification problems and an information-based data selection criterion is derived and demonstrated within this framework."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 43
                            }
                        ],
                        "text": "[All the interpolation models discussed in MacKay (1992a) can be interpreted as two-layer networks with a fixed nonlinear first layer and adaptive linear second layer.]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 197
                            }
                        ],
                        "text": "What obstacles remain to prevent us from evaluating the local Z t ? We need to evaluate or approximate the inverse Hessian of M, and we need to evaluate or approximate its determinant and/or trace (MacKay 1992a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 145
                            }
                        ],
                        "text": "This paper makes use of the Bayesian framework for regularization and model comparison described in the companion paper \u201cBayesian Interpolation\u201d (MacKay 1992a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 83
                            }
                        ],
                        "text": "Review of Bayesian Regularization and Model Comparison ___ In the companion paper (MacKay 1992a) it was demonstrated how the control parameters a and /3 are assigned by Bayes, and how alternative interpolation models can be compared."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 23
                            }
                        ],
                        "text": "In the companion paper (MacKay 1992a) it was demonstrated how the control parameters a and /3 are assigned by Bayes, and how alternative interpolation models can be compared."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "MacKay (1992a) also reviewed how the Bayesian choice of a and , B is neatly expressed in terms of a measure of the number of well-determined parameters in a model, y."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 130
                            }
                        ],
                        "text": "We need to evaluate or approximate the inverse Hessian of M, and we need to evaluate or approximate its determinant and/or trace (MacKay 1992a). for the purpose of evaluating weight saliency and for assigning error bars to weights and network outputs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 49
                            }
                        ],
                        "text": "Figure 5 introduces the quantity y, discussed in MacKay (1992a), the number of well-measured parameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1762283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e68c54f39e87daf3a8bdc0ee005aece3c652d11",
            "isKey": false,
            "numCitedBy": 3960,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Although Bayesian analysis has been in use since Laplace, the Bayesian method of model-comparison has only recently been developed in depth. In this paper, the Bayesian approach to regularization and model-comparison is demonstrated by studying the inference problem of interpolating noisy data. The concepts and methods described are quite general and can be applied to many other data modeling problems. Regularizing constants are set by examining their posterior probability distribution. Alternative regularizers (priors) and alternative basis sets are objectively compared by evaluating the evidence for them. Occam's razor is automatically embodied by this process. The way in which Bayes infers the values of regularizing constants and noise levels has an elegant interpretation in terms of the effective number of parameters determined by the data set. This framework is due to Gull and Skilling."
            },
            "slug": "Bayesian-Interpolation-Mackay",
            "title": {
                "fragments": [],
                "text": "Bayesian Interpolation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The Bayesian approach to regularization and model-comparison is demonstrated by studying the inference problem of interpolating noisy data by examining the posterior probability distribution of regularizing constants and noise levels."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802785"
                        ],
                        "name": "S. Nowlan",
                        "slug": "S.-Nowlan",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Nowlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nowlan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 6
                            }
                        ],
                        "text": "1990; Nowlan 1991; Rumelhart 1987; Weigend et al. 1991)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60866167,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59fa47fc237a0781b4bf1c84fedb728d20db26a1",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In this thesis, we consider learning algorithms for neural networks which are based on fitting a mixture probability density to a set of data. \nWe begin with an unsupervised algorithm which is an alternative to the classical winner-take-all competitive algorithms. Rather than updating only the parameters of the \"winner\" on each case, the parameters of all competitors are updated in proportion to their relative responsibility for the case. Use of such a \"soft\" competitive algorithm is shown to give better performance than the more traditional algorithms, with little additional cost. \nWe then consider a supervised modular architecture in which a number of simple \"expert\" networks compete to solve distinct pieces of a large task. A soft competitive mechanism is used to determine how much an expert learns on a case, based on how well the expert performs relative to the other expert networks. At the same time, a separate gating network learns to weight the output of each expert according to a prediction of its relative performance based on the input to the system. Experiments on a number of tasks illustrate that this architecture is capable of uncovering interesting task decompositions and of generalizing better than a single network with small training sets. \nFinally, we consider learning algorithms in which we assume that the actual output of the network should fall into one of a small number of classes or clusters. The objective of learning is to make the variance of these classes as small as possible. In the classical decision-directed algorithm, we decide that an output belongs to the class it is closest to and minimize the squared distance between the output and the center (mean) of this closest class. In the \"soft\" version of this algorithm, we minimize the squared distance between the actual output and a weighted average of the means of all of the classes. The weighting factors are the relative probability that the output belongs to each class. This idea may also be used to model the weights of a network, to produce networks which generalize better from small training sets."
            },
            "slug": "Soft-competitive-adaptation:-neural-network-based-Nowlan",
            "title": {
                "fragments": [],
                "text": "Soft competitive adaptation: neural network learning algorithms based on fitting statistical mixtures"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An unsupervised algorithm which is an alternative to the classical winner-take-all competitive algorithms and a supervised modular architecture in which a number of simple \"expert\" networks compete to solve distinct pieces of a large task are considered."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145016534"
                        ],
                        "name": "J. Moody",
                        "slug": "J.-Moody",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Moody",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Moody"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60756461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d6d0053f5f32ef87b60435e04ea5e0d81fad4ec",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The author proposes a new estimate of generalization performance for nonlinear learning systems called the generalized prediction error (GPE) which is based upon the notion of the effective number of parameters p/sub eff/( lambda ). GPE does not require the use of a test set or computationally intensive cross validation and generalizes previously proposed model selection criteria (such as GCV, FPE, AIC, and PSE) in that it is formulated to include biased, nonlinear models (such as back propagation networks) which may incorporate weight decay or other regularizers. The effective number of parameters p/sub eff/( lambda ) depends upon the amount of bias and smoothness (as determined by the regularization parameter lambda ) in the model, but generally differs from the number of weights p. Construction of an optimal architecture thus requires not just finding the weights w/sub lambda /* which minimize the training function U( lambda , w) but also the lambda which minimizes GPE( lambda ).<<ETX>>"
            },
            "slug": "Note-on-generalization,-regularization-and-in-Moody",
            "title": {
                "fragments": [],
                "text": "Note on generalization, regularization and architecture selection in nonlinear learning systems"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The author proposes a new estimate of generalization performance for nonlinear learning systems called the generalized prediction error (GPE) which is based upon the notion of the effective number of parameters p/sub eff/( lambda )."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Signal Processing Proceedings of the 1991 IEEE Workshop"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1258314,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e4b370c1a04a8a6807bd73b6bbff5773e575fee7",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "(1) The outputs of a typical multi-output classification network do not satisfy the axioms of probability; probabilities should be positive and sum to one. This problem can be solved by treating the trained network as a preprocessor that produces a feature vector that can be further processed, for instance by classical statistical estimation techniques. (2) We present a method for computing the first two moments of the probability distribution indicating the range of outputs that are consistent with the input and the training data. It is particularly useful to combine these two ideas: we implement the ideas of section 1 using Parzen windows, where the shape and relative size of each window is computed using the ideas of section 2. This allows us to make contact between important theoretical ideas (e.g. the ensemble formalism) and practical techniques (e.g. back-prop). Our results also shed new light on and generalize the well-known \"softmax\" scheme."
            },
            "slug": "Transforming-Neural-Net-Output-Levels-to-Denker-LeCun",
            "title": {
                "fragments": [],
                "text": "Transforming Neural-Net Output Levels to Probability Distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A method for computing the first two moments of the probability distribution indicating the range of outputs that are consistent with the input and the training data is presented and shed new light on and generalize the well-known \"softmax\" scheme."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792884"
                        ],
                        "name": "Charles M. Bishop",
                        "slug": "Charles-M.-Bishop",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles M. Bishop"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16430409,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a1e1da81b535e1bead3fc2ab6af8b07877823b9",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The elements of the Hessian matrix consist of the second derivatives of the error measure with respect to the weights and thresholds in the network. They are needed in Bayesian estimation of network regularization parameters, for estimation of error bars on the network outputs, for network pruning algorithms, and for fast retraining of the network following a small change in the training data. In this paper we present an extended backpropagation algorithm that allows all elements of the Hessian matrix to be evaluated exactly for a feedforward network of arbitrary topology. Software implementation of the algorithm is straightforward."
            },
            "slug": "Exact-Calculation-of-the-Hessian-Matrix-for-the-Bishop",
            "title": {
                "fragments": [],
                "text": "Exact Calculation of the Hessian Matrix for the Multilayer Perceptron"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents an extended backpropagation algorithm that allows all elements of the Hessian matrix to be evaluated exactly for a feedforward network of arbitrary topology."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143791812"
                        ],
                        "name": "S. Gull",
                        "slug": "S.-Gull",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Gull",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gull"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 965,
                                "start": 5
                            }
                        ],
                        "text": "emphasized that \"the probability of the connections w\" is a measure of plausibility that the model's parameters should have a specified value w; this has nothing to do with the probability that a particular algorithm might converge to w. This framework offers some partial enhancements for backprop methods: The work of Levin et al. (1989) makes it possible to predict the average generalization ability of neural networks trained on one of a defined class of problems. However, it is not clear whether this will lead to a practical technique for choosing between alternative network architectures for real data sets. Le Cun ef al. (1990) have demonstrated how to estimate the \"saliency\" of a weight, which is the change in M when the weight is deleted. They have used this measure successfully to simplify large neural networks. However no stopping rule for weight deletion was offered other than measuring performance on a test set. Also Denker and Le Cun (1991) demonstrated how the Hessian of M can be used to assign error bars to the parameters of a network and to its outputs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 750,
                                "start": 43
                            }
                        ],
                        "text": "In the companion paper (MacKay 1992a) it was demonstrated how the control parameters a and /3 are assigned by Bayes, and how alternative interpolation models can be compared. It was noted there that it is not satisfactory to optimize a and p by finding the joint maximum likelihood value of w, a, p; the likelihood has a skew peak whose maximum is not located at the most probable values of the control parameters. MacKay (1992a) also reviewed how the Bayesian choice of a and ,B is neatly expressed in terms of a measure of the number of well-determined parameters in a model, y. However that paper assumed that M(w) has only one significant minimum that was well approximated as quadratic. [All the interpolation models discussed in MacKay (1992a) can be interpreted as two-layer networks with a fixed nonlinear first layer and adaptive linear second layer."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 430,
                                "start": 43
                            }
                        ],
                        "text": "In the companion paper (MacKay 1992a) it was demonstrated how the control parameters a and /3 are assigned by Bayes, and how alternative interpolation models can be compared. It was noted there that it is not satisfactory to optimize a and p by finding the joint maximum likelihood value of w, a, p; the likelihood has a skew peak whose maximum is not located at the most probable values of the control parameters. MacKay (1992a) also reviewed how the Bayesian choice of a and ,B is neatly expressed in terms of a measure of the number of well-determined parameters in a model, y."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 741,
                                "start": 43
                            }
                        ],
                        "text": "Figure 1: Typical neural network output (inset - training set). This is the output space (y,,yb) of the network. The target outputs are displayed as small x's, and the output of the network with 1u error bars is shown as a a dot surrounded by an ellipse. The network was trained on samples in two regions in the lower and upper half planes (inset). The outputs illustrated here are for inputs extending a short distance outside the training regions, and bridging the gap between them. Notice that the error bars get much larger around the perimeter. They also increase slightly in the gap between the training regions. These pleasing properties would not have been obtained had the diagonal Hessian approximation of Denker and Le Cun (1991) been used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2109,
                                "start": 3
                            }
                        ],
                        "text": "This demonstration examines the evidence for various neural net solutions to a small interpolation problem, the mapping for a two joint robot arm, (el, 0,) + (ya,yb) = rl cos 6J1 + r2 cos(O1 + 02), r1 sin B1 + r2 sin(& + 0,) For the training set I used rl = 2.0 and r;! = 1.3, random samples from a restricted range of (el, 0,) were made, and gaussian noise of magnitude 0.05 was added to the outputs. The neural nets used had one hidden layer of sigmoid units and linear output units. During optimization, the regularizer (equation 1.2) was used initially, and an alternative regularizer was introduced later; ,O was fixed to its true value (to enable demonstration of the properties of the quantity y), and a was allowed to adapt to its locally most probable value. Figure 1 illustrates the performance of a typical neural network trained in this way. Each output is accompanied by error bars evaluated using Denker et aZ.'s method, including of-diagonal Hessian terns. If ,O had not been known in advance, it could have been inferred from the data using equation 2.5. For the solution displayed, the model's estimate of ,O in fact differed negligibly from the true value, so the displayed error bars are the same as if ,O had been inferred from the data. Figure 2 shows the data misfit versus the n w b e r of hidden units. Notice that, as expected, the data error tends to decrease monotonically with increasing number of parameters. Figure 3 shows the error of these same solutions on an unseen test set, which does not show the same trend as the data error. The data misfit cannot serve as a criterion for choosing between solutions. Figure 4 shows the evidence for about 100 different solutions using different numbers of hidden units. Notice how the evidence maximum has the characteristic shape of an \"Occam hill\" - steep on the side with too few parameters, and shallow on the side with too many parameters. The quadratic approximations break down when the number of parameters becomes too big compared with the number of data points. Figure 5 introduces the quantity y, discussed in MacKay (1992a), the number of well-measured parameters."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 340,
                                "start": 5
                            }
                        ],
                        "text": "emphasized that \"the probability of the connections w\" is a measure of plausibility that the model's parameters should have a specified value w; this has nothing to do with the probability that a particular algorithm might converge to w. This framework offers some partial enhancements for backprop methods: The work of Levin et al. (1989) makes it possible to predict the average generalization ability of neural networks trained on one of a defined class of problems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 863,
                                "start": 15
                            }
                        ],
                        "text": "where A = VVM is the Hessian of M evaluated at w*. For general a and P this approximation is probably unacceptable; however, we need it only to be accurate for the small range of a and @ close to their most probable value. The regime in which this approximation will definitely break down is when the number of constraints, N , is small relative to the number of free parameters, k. For large N / k the central limit theorem encourages us to use the gaussian approximation (Walker 1967). It is a matter for further research to establish how large N / k must be for this approximation to be reliable. What obstacles remain to prevent us from evaluating the local Z t ? We need to evaluate or approximate the inverse Hessian of M, and we need to evaluate or approximate its determinant and/or trace (MacKay 1992a). Denker and Le Cun (1991) and Le Cun et aZ. (1990) have already discussed how to approximate the Hessian of ED for the purpose of evaluating weight saliency and for assigning error bars to weights and network outputs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 2
                            }
                        ],
                        "text": "Tishby et al. (1989) introduced a probabilistic view of learning that is an important step toward solving the problems listed above."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2757,
                                "start": 3
                            }
                        ],
                        "text": "This demonstration examines the evidence for various neural net solutions to a small interpolation problem, the mapping for a two joint robot arm, (el, 0,) + (ya,yb) = rl cos 6J1 + r2 cos(O1 + 02), r1 sin B1 + r2 sin(& + 0,) For the training set I used rl = 2.0 and r;! = 1.3, random samples from a restricted range of (el, 0,) were made, and gaussian noise of magnitude 0.05 was added to the outputs. The neural nets used had one hidden layer of sigmoid units and linear output units. During optimization, the regularizer (equation 1.2) was used initially, and an alternative regularizer was introduced later; ,O was fixed to its true value (to enable demonstration of the properties of the quantity y), and a was allowed to adapt to its locally most probable value. Figure 1 illustrates the performance of a typical neural network trained in this way. Each output is accompanied by error bars evaluated using Denker et aZ.'s method, including of-diagonal Hessian terns. If ,O had not been known in advance, it could have been inferred from the data using equation 2.5. For the solution displayed, the model's estimate of ,O in fact differed negligibly from the true value, so the displayed error bars are the same as if ,O had been inferred from the data. Figure 2 shows the data misfit versus the n w b e r of hidden units. Notice that, as expected, the data error tends to decrease monotonically with increasing number of parameters. Figure 3 shows the error of these same solutions on an unseen test set, which does not show the same trend as the data error. The data misfit cannot serve as a criterion for choosing between solutions. Figure 4 shows the evidence for about 100 different solutions using different numbers of hidden units. Notice how the evidence maximum has the characteristic shape of an \"Occam hill\" - steep on the side with too few parameters, and shallow on the side with too many parameters. The quadratic approximations break down when the number of parameters becomes too big compared with the number of data points. Figure 5 introduces the quantity y, discussed in MacKay (1992a), the number of well-measured parameters. In cases where the evaluation of the evidence proves difficult, it may be that y will serve as a useful tool. For example, sampling theory predicts that the addition of redundant parameters to a model should reduce x& by one unit per well-measured parameter; a stopping criterion could detect the point at which, as parameters are deleted, x; started to increase faster than with gradient l with decreasing y (Figure 6).* This use of y requires prior knowledge of the noise level P; that is why ,O was fixed to its known value for these demonstrations. 4This suggestion is closely related to Moody's (1991) \"generalized prediction error,\" GPE = (& + 2 7 ) / N ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 639,
                                "start": 5
                            }
                        ],
                        "text": "emphasized that \"the probability of the connections w\" is a measure of plausibility that the model's parameters should have a specified value w; this has nothing to do with the probability that a particular algorithm might converge to w. This framework offers some partial enhancements for backprop methods: The work of Levin et al. (1989) makes it possible to predict the average generalization ability of neural networks trained on one of a defined class of problems. However, it is not clear whether this will lead to a practical technique for choosing between alternative network architectures for real data sets. Le Cun ef al. (1990) have demonstrated how to estimate the \"saliency\" of a weight, which is the change in M when the weight is deleted."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118754484,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "82fa37d5be8e747131a5857992cc33bb95469ce3",
            "isKey": true,
            "numCitedBy": 316,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The Bayesian derivation of \u201cClassic\u201d MaxEnt image processing (Skilling 1989a) shows that exp(\u03b1S(f,m)), where S(f,m) is the entropy of image f relative to model m, is the only consistent prior probability distribution for positive, additive images. In this paper the derivation of \u201cClassic\u201d MaxEnt is completed, showing that it leads to a natural choice for the regularising parameter \u03b1, that supersedes the traditional practice of setting x2=N. The new condition is that the dimensionless measure of structure -2\u03b1S should be equal to the number of good singular values contained in the data. The performance of this new condition is discussed with reference to image deconvolution, but leads to a reconstruction that is visually disappointing. A deeper hypothesis space is proposed that overcomes these difficulties, by allowing for spatial correlations across the image."
            },
            "slug": "Developments-in-Maximum-Entropy-Data-Analysis-Gull",
            "title": {
                "fragments": [],
                "text": "Developments in Maximum Entropy Data Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205001834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "052b1d8ce63b07fec3de9dbb583772d860b7c769",
            "isKey": false,
            "numCitedBy": 20332,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal \u2018hidden\u2019 units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1."
            },
            "slug": "Learning-representations-by-back-propagating-errors-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning representations by back-propagating errors"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Back-propagation repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector, which helps to represent important features of the task domain."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1330691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f05520f728a890a5c806ad7f3b27e3144ecc4d6",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we study a Bayesian or average-case model of concept learning with a twofold goal: to provide more precise characterizations of learning curve (sample complexity) behavior that depend on properties of both the prior distribution over concepts and the sequence of instances seen by the learner, and to smoothly unite in a common framework the popular statistical physics and VC dimension theories of learning curves. To achieve this, we undertake a systematic investigation and comparison of two fundamental quantities in learning and information theory: the probability of an incorrect prediction for an optimal learning algorithm, and the Shannon information gain. This study leads to a new understanding of the sample complexity of learning in several existing models."
            },
            "slug": "Bounds-on-the-sample-complexity-of-Bayesian-using-Haussler-Kearns",
            "title": {
                "fragments": [],
                "text": "Bounds on the sample complexity of Bayesian learning using information theory and the VC dimension"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A systematic investigation and comparison of two fundamental quantities in learning and information theory: the probability of an incorrect prediction for an optimal learning algorithm, and the Shannon information gain is undertaken."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '91"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30320952"
                        ],
                        "name": "F. Pineda",
                        "slug": "F.-Pineda",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pineda",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Pineda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14595475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0a945cf025236264d3f8cf20c7851c1cedbb217",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Error backpropagation in feedforward neural network models is a popular learning algorithm that has its roots in nonlinear estimation and optimization. It is being used routinely to calculate error gradients in nonlinear systems with hundreds of thousands of parameters. However, the classical architecture for backpropagation has severe restrictions. The extension of backpropagation to networks with recurrent connections will be reviewed. It is now possible to efficiently compute the error gradients for networks that have temporal dynamics, which opens applications to a host of problems in systems identification and control."
            },
            "slug": "Recurrent-Backpropagation-and-the-Dynamical-to-Pineda",
            "title": {
                "fragments": [],
                "text": "Recurrent Backpropagation and the Dynamical Approach to Adaptive Neural Computation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is now possible to efficiently compute the error gradients for networks that have temporal dynamics, which opens applications to a host of problems in systems identification and control."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398965769"
                        ],
                        "name": "Y. Abu-Mostafa",
                        "slug": "Y.-Abu-Mostafa",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Abu-Mostafa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Abu-Mostafa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 23
                            }
                        ],
                        "text": "Some of the \"hints\" in Abu-Mostafa (1990b) also fall into the category of additive weight-dependent energies."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 319536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3cd36c092abd65d6ac8e648f3468eeee90ee1fc",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-from-hints-in-neural-networks-Abu-Mostafa",
            "title": {
                "fragments": [],
                "text": "Learning from hints in neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "J. Complex."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759839"
                        ],
                        "name": "S. Solla",
                        "slug": "S.-Solla",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Solla",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Solla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 3
                            }
                        ],
                        "text": "Le Cun ef al."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7785881,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7297db245c3feb1897720b173a59fe7e36babb7",
            "isKey": false,
            "numCitedBy": 3493,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We have used information-theoretic ideas to derive a class of practical and nearly optimal schemes for adapting the size of a neural network. By removing unimportant weights from a network, several improvements can be expected: better generalization, fewer training examples required, and improved speed of learning and/or classification. The basic idea is to use second-derivative information to make a tradeoff between network complexity and training set error. Experiments confirm the usefulness of the methods on a real-world application."
            },
            "slug": "Optimal-Brain-Damage-LeCun-Denker",
            "title": {
                "fragments": [],
                "text": "Optimal Brain Damage"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A class of practical and nearly optimal schemes for adapting the size of a neural network by using second-derivative information to make a tradeoff between network complexity and training set error is derived."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067844876"
                        ],
                        "name": "Robin Hanson",
                        "slug": "Robin-Hanson",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Hanson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robin Hanson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87277825"
                        ],
                        "name": "J. Stutz",
                        "slug": "J.-Stutz",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Stutz",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Stutz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40484982"
                        ],
                        "name": "P. Cheeseman",
                        "slug": "P.-Cheeseman",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Cheeseman",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cheeseman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14393184,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23e61f54b505c09c13e24101ccec44241be4725f",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The task of inferring a set of classes and class descriptions most likely to explain a given data set can be placed on a firm theoretical foundation using Bayesian statistics. Within this framework and using various mathematical and algorithmic approximations, the AutoClass system searches for the most probable classifications, automatically choosing the number of classes and complexity of class descriptions. A simpler version of AutoClass has been applied to many large real data sets, has discovered new independently-verified phenomena, and has been released as a robust software package. Recent extensions allow attributes to be selectively correlated within particular classes, and allow classes to inherit or share model parameters though a class hierarchy. We summarize the mathematical foundations of AutoClass."
            },
            "slug": "Bayesian-classification-theory-Hanson-Stutz",
            "title": {
                "fragments": [],
                "text": "Bayesian classification theory"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The mathematical foundations of AutoClass are summarized, which allow attributes to be selectively correlated within particular classes, and allow classes to inherit or share model parameters though a class hierarchy."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71659573"
                        ],
                        "name": "C. Ji",
                        "slug": "C.-Ji",
                        "structuredName": {
                            "firstName": "Chuanyi",
                            "lastName": "Ji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2802766"
                        ],
                        "name": "R. Snapp",
                        "slug": "R.-Snapp",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Snapp",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Snapp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784553"
                        ],
                        "name": "D. Psaltis",
                        "slug": "D.-Psaltis",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Psaltis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Psaltis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 227
                            }
                        ],
                        "text": "It is moderately common for extra regularizing terms Ew(w) to be added to ED; for example, terms that penalize large weights may be introduced, in the hope of achieving a smoother or simpler mapping (Hinton and Sejnowski 1986; Ji etal."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 118
                            }
                        ],
                        "text": "There are not yet established ways of objectively setting these parameters, though there are many rules of thumb (see Ji et al. 1990; Weigend et al. 1991, for examples)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 959488,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5d28b8b81207c0ff14a7b76d86f84f64b237ca8",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We study how certain smoothness constraints, for example, piecewise continuity, can be generalized from a discrete set of analog-valued data, by modifying the error backpropagation, learning algorithm. Numerical simulations demonstrate that by imposing two heuristic objectives (1) reducing the number of hidden units, and (2) minimizing the magnitudes of the weights in the network during the learning process, one obtains a network with a response function that smoothly interpolates between the training data."
            },
            "slug": "Generalizing-Smoothness-Constraints-from-Discrete-Ji-Snapp",
            "title": {
                "fragments": [],
                "text": "Generalizing Smoothness Constraints from Discrete Samples"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Numerical simulations demonstrate that by imposing two heuristic objectives, reducing the number of hidden units, and minimizing the magnitudes of the weights in the network during the learning process, one obtains a network with a response function that smoothly interpolates between the training data."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2024710"
                        ],
                        "name": "A. Weigend",
                        "slug": "A.-Weigend",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Weigend",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Weigend"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794321"
                        ],
                        "name": "B. Huberman",
                        "slug": "B.-Huberman",
                        "structuredName": {
                            "firstName": "Bernardo",
                            "lastName": "Huberman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Huberman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 217236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f707a81a278d1598cd0a4493ba73f22dcdf90639",
            "isKey": false,
            "numCitedBy": 655,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Inspired by the information theoretic idea of minimum description length, we add a term to the back propagation cost function that penalizes network complexity. We give the details of the procedure, called weight-elimination, describe its dynamics, and clarify the meaning of the parameters involved. From a Bayesian perspective, the complexity term can be usefully interpreted as an assumption about prior distribution of the weights. We use this procedure to predict the sunspot time series and the notoriously noisy series of currency exchange rates."
            },
            "slug": "Generalization-by-Weight-Elimination-with-to-Weigend-Rumelhart",
            "title": {
                "fragments": [],
                "text": "Generalization by Weight-Elimination with Application to Forecasting"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This work adds a term to the back propagation cost function that penalizes network complexity, called weight-elimination, and uses this procedure to predict the sunspot time series and the notoriously noisy series of currency exchange rates."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398965769"
                        ],
                        "name": "Y. Abu-Mostafa",
                        "slug": "Y.-Abu-Mostafa",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Abu-Mostafa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Abu-Mostafa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17945746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f027c678076d7f2fd817f081079a334466449b1",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "When feasible, learning is a very attractive alternative to explicit programming. This is particularly true in areas where the problems do not lend themselves to systematic programming, such as pattern recognition in natural environments. The feasibility of learning an unknown function from examples depends on two questions: 1. Do the examples convey enough information to determine the function? 2. Is there a speedy way of constructing the function from the examples? These questions contrast the roles of information and complexity in learning. While the two roles share some ground, they are conceptually and technically different. In the common language of learning, the information question is that of generalization and the complexity question is that of scaling. The work of Vapnik and Chervonenkis (1971) provides the key tools for dealing with the information issue. In this review, we develop the main ideas of this framework and discuss how complexity fits in."
            },
            "slug": "The-Vapnik-Chervonenkis-Dimension:-Information-in-Abu-Mostafa",
            "title": {
                "fragments": [],
                "text": "The Vapnik-Chervonenkis Dimension: Information versus Complexity in Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The work of Vapnik and Chervonenkis (1971) provides the key tools for dealing with the information issue and the main ideas are developed and how complexity fits in are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103265471"
                        ],
                        "name": "A. M. Walker",
                        "slug": "A.-M.-Walker",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Walker",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. M. Walker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 91
                            }
                        ],
                        "text": "For large N / k the central limit theorem encourages us to use the gaussian approximation (Walker 1967)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 116092200,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7b03fd5101079d47029bedd702fd2aff7cc00ebe",
            "isKey": false,
            "numCitedBy": 294,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY Let a random sample of size n be taken from a distribution having a density depending on a real parameter 0, and let 0 have an absolutely continuous prior distribution with density ir(G). We give a rigorous proof that, under suitable regularity conditions, the posterior distribution of 0 will, when n tends to infinity, be asymptotically normal with mean equal to the maximumlikelihood estimator and variance equal to the reciprocal of the second derivative of the logarithm of the likelihood function evaluated at the maximum-likelihood estimator, independently of the form of 7r(G)."
            },
            "slug": "On-the-Asymptotic-Behaviour-of-Posterior-Walker",
            "title": {
                "fragments": [],
                "text": "On the Asymptotic Behaviour of Posterior Distributions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 199
                            }
                        ],
                        "text": "It is moderately common for extra regularizing terms Ew(w) to be added to ED; for example, terms that penalize large weights may be introduced, in the hope of achieving a smoother or simpler mapping (Hinton and Sejnowski 1986; Ji etal. 1990; Nowlan 1991; Rumelhart 1987; Weigend et al. 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 200
                            }
                        ],
                        "text": "It is moderately common for extra regularizing terms Ew(w) to be added to ED; for example, terms that penalize large weights may be introduced, in the hope of achieving a smoother or simpler mapping (Hinton and Sejnowski 1986; Ji etal."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58779360,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8592e46a5435d18bba70557846f47290b34c1aa5",
            "isKey": false,
            "numCitedBy": 1336,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Relaxation Searches, Easy and Hard Learning, The Boltzmann Machine Learning Algorithm, An Example of Hard Learning, Achieving Reliable Computation with Unreliable Hardware, An Example of the Effects of Damage, Conclusion, Acknowledgments, Appendix: Derivation of the Learning Algorithm, References"
            },
            "slug": "Learning-and-relearning-in-Boltzmann-machines-Hinton-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Learning and relearning in Boltzmann machines"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This chapter contains sections titled: Relaxation Searches, Easy and Hard learning, The Boltzmann Machine Learning Algorithm, An Example of Hard Learning, Achieving Reliable Computation with Unreliable Hardware, and an Example of the Effects of Damage."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2010050"
                        ],
                        "name": "J. Skilling",
                        "slug": "J.-Skilling",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Skilling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Skilling"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "If this is the case, numerical methods are available to approximate the determinant or trace of a matrix in k2 time ( Skilling, 1989 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117844915,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3e9229dd827dda0d462dffbdec7fdf50b724d587",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Often, we need to know some integral property of the eigenvalues {x} of a large N \u00d7 N symmetric matrix A. For example, determinants det (A) = exp(\u2211 log (x)) play a role in the classic maximum entropy algorithm [Gull, 1988] . Likewise in physics, the specific heat of a system is a temperature- -dependent sum over the eigenvalues of the Hamiltonian matrix. However, the matrix may be so large that direct O (N 3 calculation of all N eigenvalues is prohibited. Indeed, if A is coded as a \u201cfast\u201d procedure, then O (N 2 operations may also be prohibited."
            },
            "slug": "The-Eigenvalues-of-Mega-dimensional-Matrices-Skilling",
            "title": {
                "fragments": [],
                "text": "The Eigenvalues of Mega-dimensional Matrices"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158231501"
                        ],
                        "name": "Wei-Tsih Lee",
                        "slug": "Wei-Tsih-Lee",
                        "structuredName": {
                            "firstName": "Wei-Tsih",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Tsih Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302921"
                        ],
                        "name": "M. Tenorio",
                        "slug": "M.-Tenorio",
                        "structuredName": {
                            "firstName": "Manoel",
                            "lastName": "Tenorio",
                            "middleNames": [
                                "Fernando"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tenorio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 69450273,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5b9a778045531091dce710143248fc43c914038",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-Optimal-Adaptive-Classifier-Design-Criterion-How-Lee-Tenorio",
            "title": {
                "fragments": [],
                "text": "On Optimal Adaptive Classifier Design Criterion- How many hidden units are necessary for an optimal neural network classifier?"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 220119561,
            "fieldsOfStudy": [],
            "id": "0a55b22bc98bc997bc31af0244038643e2bae74a",
            "isKey": false,
            "numCitedBy": 6373,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Received",
            "title": {
                "fragments": [],
                "text": "Received"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 4
                            }
                        ],
                        "text": "Neural Computation 4,448-472 (1992) @ 1992 Massachusetts Institute of Technology"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Predictions and generalization"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. IJCNN,"
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 134
                            }
                        ],
                        "text": "There are not yet established ways of objectively setting these parameters, though there are many rules of thumb (see Ji et al. 1990; Weigend et al. 1991, for examples)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 35
                            }
                        ],
                        "text": "1990; Nowlan 1991; Rumelhart 1987; Weigend et al. 1991)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalization by weight-elimination with applications to forecasting merical recipes in C"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems Cambridge. tions by back propagating errors"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 46
                            }
                        ],
                        "text": "Some papers advocate the use of V-C dimension (Abu-Mostafa 1990a) as a criterion for penalizing overcomplex models (Abu-Mostafa 1990b; Lee and Tenorio 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 23
                            }
                        ],
                        "text": "Some of the \"hints\" in Abu-Mostafa (1990b) also fall into the category of additive weight-dependent energies."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Vapnik-Chervonenkis dimension: Information Abu-Mostafa, Y"
            },
            "venue": {
                "fragments": [],
                "text": "S. 1990b. Learning from hints in neural networks. 1. Complex. Bishop, C. M. 1992. Exact calculation of the Hessian matrix for the multilayer"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 23
                            }
                        ],
                        "text": "Some of the \"hints\" in Abu-Mostafa (1990b) also fall into the category of additive weight-dependent energies."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Vapnik-Chervonenkis dimension: Information"
            },
            "venue": {
                "fragments": [],
                "text": "The Vapnik-Chervonenkis dimension: Information"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 199
                            }
                        ],
                        "text": "It is moderately common for extra regularizing terms Ew(w) to be added to ED; for example, terms that penalize large weights may be introduced, in the hope of achieving a smoother or simpler mapping (Hinton and Sejnowski 1986; Ji etal. 1990; Nowlan 1991; Rumelhart 1987; Weigend et al. 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 19
                            }
                        ],
                        "text": "1990; Nowlan 1991; Rumelhart 1987; Weigend et al. 1991)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cited in Ji et al"
            },
            "venue": {
                "fragments": [],
                "text": "1990. Skilling, J. 1989. The eigenvalues of mega-dimensional matrices. In Maximum Entropy and Bayesian Methods, Cambridge, 1988, J. Skilling, ed., pp. 45.5466. Kluwer, Dordrecht. Tishby, N., Levin, E., and Solla, S. A. 1989. Consistent inference of probabil-"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "versus complexity in learning"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Comp ."
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 29,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Practical-Bayesian-Framework-for-Backpropagation-Mackay/b959164d1efca4b73986ba5d21e664aadbbc0457?sort=total-citations"
}