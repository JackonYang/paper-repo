{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064718531"
                        ],
                        "name": "D. Cooper",
                        "slug": "D.-Cooper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cooper",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114973837"
                        ],
                        "name": "John H. Freeman",
                        "slug": "John-H.-Freeman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Freeman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John H. Freeman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 138
                            }
                        ],
                        "text": "In such situations unsupervised training with unlabeled training data can substantially reduce the amount of supervised training required [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12921101,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c90acb1f1d05b855bffbe956ecc4e859d6808465",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper treats an aspect of the learning or estimation phase of statistical pattern recognition (and adaptive statistical decision making in general). Simple mathematical expressions are derived for the improvement in supervised learning provided by additional nonsupervised learning when the number of learning samples is large so that asymptotic approximations are appropriate. The paper consists largely of the examination of a specific example, but, as is briefly discussed, the same procedure can be applied to other parametric problems and generalization to nonparametric problems seems possible. The example treated has the additional interesting aspect that the data does not have structure that would enable the machine to learn in the nonsupervised mode alone; but the additional nonsupervised learning can provide substantial improvement over the results obtainable by supervised learning alone. A second purpose of the paper is to suggest that a new fruitful area of research is the analytical study of the possible benefits of combining supervised and nonsupervised learning."
            },
            "slug": "On-the-Asymptotic-Improvement-in-the-Out-come-of-by-Cooper-Freeman",
            "title": {
                "fragments": [],
                "text": "On the Asymptotic Improvement in the Out- come of Supervised Learning Provided by Additional Nonsupervised Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Simple mathematical expressions are derived for the improvement in supervised learning provided by additional nonsupervised learning when the number of learning samples is large so that asymptotic approximations are appropriate."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145325516"
                        ],
                        "name": "I. Longstaff",
                        "slug": "I.-Longstaff",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Longstaff",
                            "middleNames": [
                                "Dennis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Longstaff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39853626"
                        ],
                        "name": "J. F. Cross",
                        "slug": "J.-F.-Cross",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cross",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. F. Cross"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 215
                            }
                        ],
                        "text": "Generative procedures demonstrate that such classifiers can form convex decision regions with two-layer perceptrons (one hidden layer) and arbitrary decision regions with three-layer perceptrons (two hidden layers) [7,2,9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 118
                            }
                        ],
                        "text": "form arbitrary decision regions and a two-layer perceptron (one hidden layer) can form single convex decision regions [7,2,9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9528733,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55dc465cea5676188ddc8893d5620c9283b0583f",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-pattern-recognition-approach-to-understanding-the-Longstaff-Cross",
            "title": {
                "fragments": [],
                "text": "A pattern recognition approach to understanding the multi-layer perception"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 242
                            }
                        ],
                        "text": "These and previous simulations [5,8] demonstrate that convergence time with back propagation can be excessive when complex decision regions are desired and performance is often no better than that obtained with k-nearest neighbor classifiers [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16928,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51083130"
                        ],
                        "name": "F. Rosenblatt",
                        "slug": "F.-Rosenblatt",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Rosenblatt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Rosenblatt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 259,
                                "start": 249
                            }
                        ],
                        "text": "In particular, multi-layer perceptron classifiers with continuous valued inputs trained with back propagation are robust, often train rapidly, and provide performance similar to that provided by Gaussian classifiers when decision regions are convex [12,7,5,8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62710001,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "9b486c647916df9f8be0f8d4fc5c94c493bfaa80",
            "isKey": false,
            "numCitedBy": 1904,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Part I attempts to review the background, basic sources of data, concepts, and methodology to be employed in the study of perceptrons. In Chapter 2, a brief review of the main alternative approaches to the development of brain models is presented. Chapter 3 considers the physiological and psychological criteria for a suitable model, and attempts to evaluate the empirical evidence which is available on several important issues. Chapter 4 contains basic definitions and some of the notation to be used in later sections are presented. Parts II and III are devoted to a summary of the established theoretical results obtained to date. Part II (Chapters 5 through 14) deals with the theory of three-layer series-coupled perceptrons, on which most work has been done to date. Part III (Chapters 15 through 20) deals with the theory of multi-layer and cross-coupled perceptrons. Part IV is concerned with more speculative models and problems for future analysis. Of necessity, the final chapters become increasingly heuristic in character, as the theory of perceptrons is not yet complete, and new possibilities are continually coming to light."
            },
            "slug": "PRINCIPLES-OF-NEURODYNAMICS.-PERCEPTRONS-AND-THE-OF-Rosenblatt",
            "title": {
                "fragments": [],
                "text": "PRINCIPLES OF NEURODYNAMICS. PERCEPTRONS AND THE THEORY OF BRAIN MECHANISMS"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The background, basic sources of data, concepts, and methodology to be employed in the study of perceptrons are reviewed, and some of the notation to be used in later sections are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "Results presented above and previous results [5] [8] demonstrate that multi-layer perceptron classifiers can take very long to converge for complex decision regions."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "COMPARATIVE RESULTS OF TWO-LAYERS VS. THREE-LAYERS Previous results [5] [8], as well as the weight interactions mentioned above, suggest that three-layer perceptrons may be able to form complex decision regions faster with back propagation than two-layer perceptrons."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 262
                            }
                        ],
                        "text": "In particular, multi-layer perceptron classifiers with continuous valued inputs trained with back propagation are robust, often train rapidly, and provide performance similar to that provided by Gaussian classifiers when decision regions are convex [12] [7] [5] [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 99
                            }
                        ],
                        "text": "The number6 a66igned to each ca6e are the \"ca6e\" number6 u6ed in the re6t of thi6 paper. as in [5] [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 35
                            }
                        ],
                        "text": "These and previous simulations [5] [8] demonstrate that convergence time with back propagation can be excessive when complex decision regions are desired and performance is often no better than that obtained with k-nearest neighbor classifiers [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural classifiers useful for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "1st International Conference on Neural Network"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 69
                            }
                        ],
                        "text": "ALTERNATIVE CLASSIFIERS Results presented above and previous results [5,8] demonstrate that multi-layer perceptron classifiers can take very long to converge for complex decision regions."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 30
                            }
                        ],
                        "text": "THREE-LAYERS Previous results [5,8], as well as the weight interactions mentioned above, suggest that three-layer perceptrons may be able to form complex decision regions faster with back propagation than two-layer perceptrons."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 31
                            }
                        ],
                        "text": "These and previous simulations [5,8] demonstrate that convergence time with back propagation can be excessive when complex decision regions are desired and performance is often no better than that obtained with k-nearest neighbor classifiers [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 259,
                                "start": 249
                            }
                        ],
                        "text": "In particular, multi-layer perceptron classifiers with continuous valued inputs trained with back propagation are robust, often train rapidly, and provide performance similar to that provided by Gaussian classifiers when decision regions are convex [12,7,5,8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Comparisons between conventional and neural net classifiers,"
            },
            "venue": {
                "fragments": [],
                "text": "in 1st International Conference on Neural Network,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 69
                            }
                        ],
                        "text": "ALTERNATIVE CLASSIFIERS Results presented above and previous results [5,8] demonstrate that multi-layer perceptron classifiers can take very long to converge for complex decision regions."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 30
                            }
                        ],
                        "text": "THREE-LAYERS Previous results [5,8], as well as the weight interactions mentioned above, suggest that three-layer perceptrons may be able to form complex decision regions faster with back propagation than two-layer perceptrons."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 31
                            }
                        ],
                        "text": "These and previous simulations [5,8] demonstrate that convergence time with back propagation can be excessive when complex decision regions are desired and performance is often no better than that obtained with k-nearest neighbor classifiers [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 259,
                                "start": 249
                            }
                        ],
                        "text": "In particular, multi-layer perceptron classifiers with continuous valued inputs trained with back propagation are robust, often train rapidly, and provide performance similar to that provided by Gaussian classifiers when decision regions are convex [12,7,5,8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural classifiers useful for speech"
            },
            "venue": {
                "fragments": [],
                "text": "recognition,\" in 1st International Conference on Neural Network,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62186699,
            "fieldsOfStudy": [],
            "id": "3302a19539ccfa8ed3a8361ace8947ddbba1acf5",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An introduction to computing with neural nets"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259367"
                        ],
                        "name": "J. Albus",
                        "slug": "J.-Albus",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Albus",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Albus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60845048,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b42c83364f2f31ac5c27ccf0bd560f1620583cfb",
            "isKey": false,
            "numCitedBy": 355,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Brains,-behavior,-and-robotics-Albus",
            "title": {
                "fragments": [],
                "text": "Brains, behavior, and robotics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145009419"
                        ],
                        "name": "T. W. Parsons",
                        "slug": "T.-W.-Parsons",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Parsons",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. W. Parsons"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "VOWEL CLASSIFICATION Multi layer perceptron, feature map, and traditional classifiers were tested with vowel formant data from Peterson and Barney [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "It is similar to histogram classifiers used in discrete observation hidden Markov models [11] and the classifier used in [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60933491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08f87f29233537e57c89f88d1d77b4bf47f3cf95",
            "isKey": false,
            "numCitedBy": 341,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Voice-and-Speech-Processing-Parsons",
            "title": {
                "fragments": [],
                "text": "Voice and Speech Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "A 1965 book by Nilson discusses this issue and contains a proof that two-layer nets can divide a finite number of points into two arbitrary sets ([10] page 89)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "N.Y"
            },
            "venue": {
                "fragments": [],
                "text": "N.Y"
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "One test for linear separability was presented in 1962 [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A test for linear separability as applied to self-organizing machines,\" in Self- Organization"
            },
            "venue": {
                "fragments": [],
                "text": "Spartan Books, Washington,"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 215
                            }
                        ],
                        "text": "Generative procedures demonstrate that such classifiers can form convex decision regions with two-layer perceptrons (one hidden layer) and arbitrary decision regions with three-layer perceptrons (two hidden layers) [7,2,9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 118
                            }
                        ],
                        "text": "form arbitrary decision regions and a two-layer perceptron (one hidden layer) can form single convex decision regions [7,2,9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A neural network digit recognizer,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the International Conference on Systems, Man, and Cybernetics,"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "One test for linear separability was presented in 1962 [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A test for linear separability as applied to self-organizing machines,\" in Self- Organization Systems"
            },
            "venue": {
                "fragments": [],
                "text": "A test for linear separability as applied to self-organizing machines,\" in Self- Organization Systems"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Phonotopic maps -insightful representation of phonological features for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 7th International Conference on Pattern Recognition"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "Recently, however, it has been demonstrated that two-layer perceptrons can form decision regions that are not simply convex [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Geometric analysis of neural network capabilities,"
            },
            "venue": {
                "fragments": [],
                "text": "in 1st International Conference on Neural Networks,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 121
                            }
                        ],
                        "text": "It is similar to histogram classifiers used in discrete observation hidden Markov models [11] and the classifier used in [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 121
                            }
                        ],
                        "text": "The first layer of this classifier forms a feature map using a self organizing clustering algorithm described by Kohonen [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Saramaki, \"Phonotopic maps - insightful representation of phonological features for speech"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 7th International Conference on Pattern Recognition,"
            },
            "year": 1984
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 3,
            "result": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 17,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Neural-Net-and-Traditional-Classifiers-Huang-Lippmann/d1382a29539b3de419d567f679b5f28cee459a49?sort=total-citations"
}