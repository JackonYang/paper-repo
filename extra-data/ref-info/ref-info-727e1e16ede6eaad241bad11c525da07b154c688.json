{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47392513"
                        ],
                        "name": "Jonathan Baxter",
                        "slug": "Jonathan-Baxter",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Baxter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Baxter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 21
                            }
                        ],
                        "text": "For more details see Baxter (1995b) and Baxter (1995a, chapter 4 ), where empirical results supporting the theoretical results presented here are also given."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 252
                            }
                        ],
                        "text": "\u2026distributions are identical and they only differ in the conditional probabilities they assign to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization and onenearest-neighbour classification (Baxter, 1995a, 1997b; Baxter & Bartlett, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 328,
                                "start": 108
                            }
                        ],
                        "text": "H owever, a model using a mixture of hierarchical Bayesian and information-theoretic ideas was presented in Baxter (1997a), with similar conclusions to those found here. An empirical s tudy showing the utility of the hierarchical Bayes approach in a domain containing a large n umber of related tasks was given in Heskes (1998)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 58
                            }
                        ],
                        "text": "The experiments reported in Baxter (1995a, chapter 4) and Baxter (1995b), Baxter and Bartlett (1998) are also of this nature."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 86
                            }
                        ],
                        "text": "Once the feature map is learnt (which can be achieved usingthe techniques outlined in Baxter, 1995b; Baxter & Bartlett, 1998; Baxter, 1995a, chapter 4), only the output weights have to be estimated to learn a novel task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 108
                            }
                        ],
                        "text": "H owever, a model using a mixture of hierarchical Bayesian and information-theoretic ideas was presented in Baxter (1997a), with similar conclusions to those found here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 21
                            }
                        ],
                        "text": "For more details see Baxter (1995b) and Baxter (1995a, chapter 4), where empirical results supporting the theoretical results presented here are also given."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 6211302,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a24508e65e599b5b20c33af96dbe7017d5caca37",
            "isKey": false,
            "numCitedBy": 343,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Probably the most important problem in machine learning is the preliminary biasing of a learner's hypothesis space so that it is small enough to ensure good generalisation from reasonable training sets, yet large enough that it contains a good solution to the problem being learnt. In this paper a mechanism for {\\em automatically} learning or biasing the learner's hypothesis space is introduced. It works by first learning an appropriate {\\em internal representation} for a learning environment and then using that representation to bias the learner's hypothesis space for the learning of future tasks drawn from the same environment. \nAn internal representation must be learnt by sampling from {\\em many similar tasks}, not just a single task as occurs in ordinary machine learning. It is proved that the number of examples $m$ {\\em per task} required to ensure good generalisation from a representation learner obeys $m = O(a+b/n)$ where $n$ is the number of tasks being learnt and $a$ and $b$ are constants. If the tasks are learnt independently ({\\em i.e.} without a common representation) then $m=O(a+b)$. It is argued that for learning environments such as speech and character recognition $b\\gg a$ and hence representation learning in these environments can potentially yield a drastic reduction in the number of examples required per task. It is also proved that if $n = O(b)$ (with $m=O(a+b/n)$) then the representation learnt will be good for learning novel tasks from the same environment, and that the number of examples required to generalise well on a novel task will be reduced to $O(a)$ (as opposed to $O(a+b)$ if no representation is used). \nIt is shown that gradient descent can be used to train neural network representations and experiment results are reported providing strong qualitative support for the theoretical results."
            },
            "slug": "Learning-internal-representations-Baxter",
            "title": {
                "fragments": [],
                "text": "Learning internal representations"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is proved that the number of examples required to ensure good generalisation from a representation learner obeys and that gradient descent can be used to train neural network representations and experiment results are reported providing strong qualitative support for the theoretical results."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2195972"
                        ],
                        "name": "P. Utgoff",
                        "slug": "P.-Utgoff",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Utgoff",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Utgoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7) \u201cVBMS\u201d or Variable Bias Management System was introduced as a mechanism for selecting amongst different learning algorithms when tackling a new learning problem. \u201cSTABB\u201d or Shift To a Better Bias (Utgoff, 1986) was another early scheme for adjusting bias, but unlike VBMS, STABB was not primarily focussed on searching for bias applicable to large problem domains. Our use of an \u201cenvironment of related tasks\u201d "
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 31
                            }
                        ],
                        "text": "\u201cSTABB\u201d orShift To a Better Bias(Utgoff, 1986) was another early scheme for adjusting bias, butunlike VBMS, STABB was not primarily focussed on searching for bias applicable to large problem domains."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61047266,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "f5157391985e1b8b451461f3350e9f91e697b76f",
            "isKey": false,
            "numCitedBy": 375,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We identify and examine the fundamental role that bias plays in inductive concept learning. Bias is the set of all influences, procedural or declarative, that causes a concept learner to prefer one hypothesis to another. Much of the success of concept learning programs to date results from the program's author having provided the learning program with appropriate bias. To date there has been no good mechanical method for shifting from one bias to another that is better. Instead, the author of a learning program has himself had to search for a better bias. The program author manually generates a bias, from scratch or by revising a previous bias, and then tests it in his program. If the author is not satisfied with the induced concepts, then he repeats the manual-generate and program-test cycle. If the author is satisfied, then he deems his program successful. Too often, he does not recognize his own role in the learning process. \nOur thesis is that search for appropriate bias is itself a major part of the learning task, and that we can create mechanical procedures for conducting a well-directed search for an appropriate bias. We would like to understand better how a program author goes about doing his search for appropriate bias. What insights does he have? What does he learn when he observes that a particular bias produces poor performance? What domain knowledge does he apply? \nWe explore the problem of mechanizing the search for appropriate bias. To that end, we develop a framework for a procedure that shifts bias. We then build two instantiations of the procedure in a program called STABB, which we then incorporate in the LEX learning program. One, called \"least disjunction\", uses simple syntactic manipulation, and the other, called \"constraint back propagation\" uses analytic deduction. We report experiments with the implementations that both demonstrate the usefulness of the framework, and uncover important issues for this kind of learning."
            },
            "slug": "Shift-of-bias-for-inductive-concept-learning-Utgoff",
            "title": {
                "fragments": [],
                "text": "Shift of bias for inductive concept learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that search for appropriate bias is itself a major part of the learning task, and that mechanical procedures for conducting a well-directed search for an appropriate bias can be created."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 159
                            }
                        ],
                        "text": "The bound onm in Theorem 8 states thatmn should beO(nk +W ), or proportional to the total number of parameters in the network, a result we would expect from6 (Haussler, 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 216
                            }
                        ],
                        "text": "In this paper we introduce and analyze a formal model ofbias learning that builds upon the PAC model of machine learning and its variants (Vapnik, 1982; Valiant, 1984; Blumer, Ehrenfeucht, Haussler, & Warmuth, 1989; Haussler, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 47
                            }
                        ],
                        "text": "Explicit bounds are also derived demonstratingthat learning multiple tasks within an environment of related tasks can potentially give much better generalization than learning a single task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 63
                            }
                        ],
                        "text": "I have also borrowed some ideas from the proof of Theorem 3 in Haussler (1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 43
                            }
                        ],
                        "text": "To obtain a more general result, we follow Haussler (1992) and introduce the following parameterized class of metrics onR+ :d [x; y\u2104 := jx yjx+ y + ; where > 0."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 107
                            }
                        ],
                        "text": "Equations (73) and (74) implyC(\";Gl) C \"2 ;G; L1 (75)CGl (\";F) C \"2b ;F ; L1 (76) Applying Theorem 11 from Haussler (1992), we findC \"2 ;Gl; L1 2eb\" 2k+2C \"2b ;F ; L1 2eb2\" 2W : Substituting these two expressions into (75) and (76) and applying Theorem 6 yields Theorem 7."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14921581,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "fedfc9fbcfe46d50b81078560bce724678f90176",
            "isKey": true,
            "numCitedBy": 979,
            "numCiting": 124,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Decision-Theoretic-Generalizations-of-the-PAC-Model-Haussler",
            "title": {
                "fragments": [],
                "text": "Decision Theoretic Generalizations of the PAC Model for Neural Net and Other Learning Applications"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Comput."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1873631"
                        ],
                        "name": "L. Rendell",
                        "slug": "L.-Rendell",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Rendell",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rendell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2719289"
                        ],
                        "name": "Raj Sheshu",
                        "slug": "Raj-Sheshu",
                        "structuredName": {
                            "firstName": "Raj",
                            "lastName": "Sheshu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raj Sheshu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2412244"
                        ],
                        "name": "D. Tcheng",
                        "slug": "D.-Tcheng",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Tcheng",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tcheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 3
                            }
                        ],
                        "text": "In Rendell, Seshu, and Tcheng (1987) \u201cVBMS\u201d orVariable Bias Management Systemwas introduced as a mechanism for selecting amongst different learning algorithms when tackling a new learning problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10111683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d24ffc3e48cab4b9271981ccf82bbd1838361daf",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Concept learning is inherently complex. Without severe constraint or inductive \"bias,\" the general problem is intractable. While most learning systems have been designed with built-in biases, these systems typically work well only in narrowly circumscribed problem domains. Here we present a model of concept formation that views learning as a simultaneous optimization problem at three different levels, with dynamically chosen biases guiding the search for satisfactory hypotheses. In this model, the partitioning of events into classes occurs through dynamic interactions among three layers: event space, hypothesis space, and bias space. This view of the induction process may help clarify the problem of learning and lead to more general and efficient induction systems. To test this model of meta-knowledge, a variable bias management system (VBMS) has been designed and partly implemented. The system will dynamically alter evolving hypotheses, concept representation languages, and concept formation algorithms by monitoring progress and selecting biases based on characteristics of the particular induction problems presented. VBMS is designed to learn the best biases for different types of induction problems. Thus it is robust (effective and efficient in many domains). The system can learn incrementally despite noisy data at any level."
            },
            "slug": "Layered-Concept-Learning-and-Dynamically-Variable-Rendell-Sheshu",
            "title": {
                "fragments": [],
                "text": "Layered Concept-Learning and Dynamically Variable Bias Management"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A model of concept formation is presented that views learning as a simultaneous optimization problem at three different levels, with dynamically chosen biases guiding the search for satisfactory hypotheses."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145727186"
                        ],
                        "name": "R. Caruana",
                        "slug": "R.-Caruana",
                        "structuredName": {
                            "firstName": "Rich",
                            "lastName": "Caruana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Caruana"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 192
                            }
                        ],
                        "text": "Grouping too large a subset of tasks together as related tasks could clearly have a detrimental impact on bias-learning or multi-task learning, and there is emprical evidence to support this (Caruana, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 18
                            }
                        ],
                        "text": "In thetheorem the hypothesis space family is required to bepermissible."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 21
                            }
                        ],
                        "text": "\u201cMulti-task learning\u201d (Caruana, 1997) trains extra neural network outputs to match related tasks in order to improve generalization performance on a fixed reference task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 45998148,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47aaeb6dc682162dfe5659c2cad64e5d825ad910",
            "isKey": true,
            "numCitedBy": 3259,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Multitask Learning is an approach to inductive transfer that improves generalization by using the domain information contained in the training signals of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better. This paper reviews prior work on MTL, presents new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals, and presents new results for MTL with k-nearest neighbor and kernel regression. In this paper we demonstrate multitask learning in three domains. We explain how multitask learning works, and show that there are many opportunities for multitask learning in real domains. We present an algorithm and results for multitask learning with case-based methods like k-nearest neighbor and kernel regression, and sketch an algorithm for multitask learning in decision trees. Because multitask learning works, can be applied to many different kinds of domains, and can be used with different learning algorithms, we conjecture there will be many opportunities for its use on real-world problems."
            },
            "slug": "Multitask-Learning-Caruana",
            "title": {
                "fragments": [],
                "text": "Multitask Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Prior work on MTL is reviewed, new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals is presented, and new results for MTL with k-nearest neighbor and kernel regression are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of Machine Learning and Data Mining"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790356"
                        ],
                        "name": "T. Heskes",
                        "slug": "T.-Heskes",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Heskes",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Heskes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 142
                            }
                        ],
                        "text": "An empirical study showing the utility of the hierarchical Bayes approach in a domain containing a large number of related tasks was given in Heskes (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1118769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ac52b7d8db223029388551b2db25657ed8c9852",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a machine-learning solution to problems consisting of many similar prediction tasks. Each of the individual tasks has a high risk of overrtting. We combine two types of knowledge transfer between tasks to reduce this risk: multi-task learning and hierarchical Bayesian modeling. Multi-task learning is based on the assumption that there exist features typical to the task at hand. To nd these features, we train a huge two-layered neural network. Each task has its own output, but shares the weights from the input to the hidden units with all other tasks. In this way a relatively large set of possible explanatory variables (the network inputs) is reduced to a smaller and easier to handle set of features (the hidden units). Given this set of features and after an appropriate scale transformation, we assume that the tasks are exchangeable. This assumption allows for a hierarchical Bayesian analysis in which the hyperparameters can be estimated from the data. EEectively, these hyperpa-rameters act as regularizers and prevent over-tting. We describe how to make the system robust against nonstationarities in the time series and give directions for further improvement. We illustrate our ideas on a database regarding the prediction of newspaper sales."
            },
            "slug": "Solving-a-Huge-Number-of-Similar-Tasks:-A-of-and-a-Heskes",
            "title": {
                "fragments": [],
                "text": "Solving a Huge Number of Similar Tasks: A Combination of Multi-Task Learning and a Hierarchical Bayesian Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A machine-learning solution to problems consisting of many similar prediction tasks, each of the individual tasks has a high risk of overrtting, that combines two types of knowledge transfer between tasks to reduce this risk: multi-task learning and hierarchical Bayesian modeling."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 35
                            }
                        ],
                        "text": "A similar approach is described in Thrun and Mitchell (1995), Thrun (1996), in which a neural network\u2019s output was trained to match labels on a novel task, while simultaneously being forced to match its gradient toderivativeinformation generated from a distance metric trained on previous, related\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6046155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b65b99e772727dadc1b5e50a9d83367a892ec28",
            "isKey": false,
            "numCitedBy": 157,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Most research on machine learning has focused on scenarios in which a learner faces a single, isolated learning task. The lifelong learning framework assumes instead that the learner encounters a multitude of related learning tasks over its lifetime, providing the opportunity for the transfer of knowledge. This paper studies lifelong learning in the context of binary classification. It presents the invariance approach, in which knowledge is transferred via a learned model of the invariances of the domain. Results on learning to recognize objects from color images demonstrate superior generalization capabilities if invariances are learned and used to bias subsequent learning."
            },
            "slug": "Learning-One-More-Thing-Thrun-Mitchell",
            "title": {
                "fragments": [],
                "text": "Learning One More Thing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results on learning to recognize objects from color images demonstrate superior generalization capabilities if invariances are learned and used to bias subsequent learning."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1395754302"
                        ],
                        "name": "Joseph O'Sullivan",
                        "slug": "Joseph-O'Sullivan",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "O'Sullivan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph O'Sullivan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A similar approach is described in  Thrun and Mitchell (1995) , Thrun (1996), in which a neural network\u2019s output was trained to match labels on a novel task, while simultaneously being forced to match its gradient to derivative information generated from a distance metric trained on previous, related tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10420876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f42a55da3a222184eee20c67d374a9134b77bdc",
            "isKey": false,
            "numCitedBy": 244,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, there has been an increased interest in \u201clifelong\u201d machine learning methods, that transfer knowledge across multiple learning tasks. Such methods have repeatedly been found to outperform conventional, single-task learning algorithms when the learning tasks are appropriately related. To increase robustness of such approaches, methods are desirable that can reason about the relatedness of individual learning tasks, in order to avoid the danger arising from tasks that are unrelated and thus potentially misleading. This paper describes the task-clustering (TC) algorithm. TC clusters learning tasks into classes of mutually related tasks. When facing a new learning task, TC first determines the most related task cluster, then exploits information selectively from this task cluster only. An empirical study carried out in a mobile robot domain shows that TC outperforms its non-selective counterpart in situations where only a small number of tasks is relevant."
            },
            "slug": "Discovering-Structure-in-Multiple-Learning-Tasks:-Thrun-O'Sullivan",
            "title": {
                "fragments": [],
                "text": "Discovering Structure in Multiple Learning Tasks: The TC Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The task-clustering algorithm TC clusters learning tasks into classes of mutually related tasks, and outperforms its non-selective counterpart in situations where only a small number of tasks is relevant."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072756801"
                        ],
                        "name": "Khalid Khan",
                        "slug": "Khalid-Khan",
                        "structuredName": {
                            "firstName": "Khalid",
                            "lastName": "Khan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Khalid Khan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145147566"
                        ],
                        "name": "S. Muggleton",
                        "slug": "S.-Muggleton",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Muggleton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Muggleton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16915942"
                        ],
                        "name": "R. Parson",
                        "slug": "R.-Parson",
                        "structuredName": {
                            "firstName": "Rupert",
                            "lastName": "Parson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Parson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Preliminary results with this approach on a chess domain are reported in  Khan, Muggleton, and Parson (1998) ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 141
                            }
                        ],
                        "text": "It would be interesting to investigate alternative methods, including decision tree approaches, approaches from Inductive Logic Programming (Khan et al., 1998), and whether more general learning techniquess ch as boosting can be applied in a bias learning setting."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 17
                            }
                        ],
                        "text": "Bias learning in Inductive Logic Programming (ILP)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 73
                            }
                        ],
                        "text": "Preliminary results with this approach on a chess domain are reported in Khan, Muggleton, and Parson (1998)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8911605,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0461781455a870c567e2752c7a4fda4f5a81dd15",
            "isKey": true,
            "numCitedBy": 27,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Most of machine learning is concerned with learning a single concept from a sequence of examples. In repeat learning the teacher chooses a series of related concepts randomly and independently from a distribution D. A finite sequence of examples is provided for each concept in the series. The learner does not initially know D, but progressively updates a posterior estimation of D as the series progresses. This paper considers predicate invention within Inductive Logic Programming as a mechanism for updating the learner's estimation of D. A new predicate invention mechanism implemented in Progol4.4 is used in repeat learning experiments within a chess domain. The results indicate that significant performance increases can be achieved. The paper develops a Bayesian framework and demonstrates initial theoretical results for repeat learning."
            },
            "slug": "Repeat-Learning-Using-Predicate-Invention-Khan-Muggleton",
            "title": {
                "fragments": [],
                "text": "Repeat Learning Using Predicate Invention"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new predicate invention mechanism implemented in Progol4.4 is used in repeat learning experiments within a chess domain and the results indicate that significant performance increases can be achieved."
            },
            "venue": {
                "fragments": [],
                "text": "ILP"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699645"
                        ],
                        "name": "R. Sutton",
                        "slug": "R.-Sutton",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sutton",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sutton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 255
                            }
                        ],
                        "text": "\u2026literature have proposed algorithms for both sharing the information in related tasks to improve average generalization performance across those tasks Singh (1992), Ring (1995), or learning bias from a set of tasks to improve performance on future tasks Sutton (1992), Thrun and Schwartz (1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 771841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2dd697bbe99c2ec71c807580a00f7e723cc20ae",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Appropriate bias is widely viewed as the key to efficient learning and generalization. I present a new algorithm, the Incremental Delta-Bar-Delta (IDBD) algorithm, for the learning of appropriate biases based on previous learning experience. The IDBD algorithm is developed for the case of a simple, linear learning system--the LMS or delta rule with a separate learning-rate parameter for each input. The IDBD algorithm adjusts the learning-rate parameters, which are an important form of bias for this system. Because bias in this approach is adapted based on previous learning experience, the appropriate test beds are drifting or non-stationary learning tasks. For particular tasks of this type, I show that the IDBD algorithm performs better than ordinary LMS and in fact finds the optimal learning rates. The IDBD algorithm extends and improves over prior work by Jacobs and by me in that it is fully incremental and has only a single free parameter. This paper also extends previous work by presenting a derivation of the IDBD algorithm as gradient descent in the space of learning-rate parameters. Finally, I offer a novel interpretation of the IDBD algorithm as an incremental form of hold-one-out cross validation."
            },
            "slug": "Adapting-Bias-by-Gradient-Descent:-An-Incremental-Sutton",
            "title": {
                "fragments": [],
                "text": "Adapting Bias by Gradient Descent: An Incremental Version of Delta-Bar-Delta"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A new algorithm, the Incremental Delta-Bar-Delta (IDBD) algorithm, for the learning of appropriate biases based on previous learning experience, and a novel interpretation of the IDBD algorithm as an incremental form of hold-one-out cross validation."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 153
                            }
                        ],
                        "text": "In this paper we introduce and analyze a formal model ofbias learning that builds upon the PAC model of machine learning and its variants (Vapnik, 1982; Valiant, 1984; Blumer, Ehrenfeucht, Haussler, & Warmuth, 1989; Haussler, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 247
                            }
                        ],
                        "text": "Under certain restrictions on the set of all hypothesis spaces available to the learner, we show that a hypothesis space that performs well on a sufficiently large number of training tasks will also perform well when learning novel tasks in the same environment."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10ddb646feddc12337b5a755c72e153e37088c02",
            "isKey": false,
            "numCitedBy": 4191,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans appear to be able to learn new concepts without needing to be programmed explicitly in any conventional sense. In this paper we regard learning as the phenomenon of knowledge acquisition in the absence of explicit programming. We give a precise methodology for studying this phenomenon from a computational viewpoint. It consists of choosing an appropriate information gathering mechanism, the learning protocol, and exploring the class of concepts that can be learnt using it in a reasonable (polynomial) number of steps. We find that inherent algorithmic complexity appears to set serious limits to the range of concepts that can be so learnt. The methodology and results suggest concrete principles for designing realistic learning systems."
            },
            "slug": "A-theory-of-the-learnable-Valiant",
            "title": {
                "fragments": [],
                "text": "A theory of the learnable"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper regards learning as the phenomenon of knowledge acquisition in the absence of explicit programming, and gives a precise methodology for studying this phenomenon from a computational viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '84"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 62
                            }
                        ],
                        "text": "A similar approach is described in Thrun and Mitchell (1995), Thrun (1996), in which a neural network\u2019s output was trained to match labels on a novel task, while simultaneously being forced to match its gradient toderivativeinformation generated from a distance metric trained on previous, related\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A similar approach is described in Thrun and Mitchell (1995),  Thrun (1996) , in which a neural network\u2019s output was trained to match labels on a novel task, while simultaneously being forced to match its gradient to derivative information generated from a distance metric trained on previous, related tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 95
                            }
                        ],
                        "text": "Similar results may be found in Intrator and Edelman (1996) and in the experiments reported in Thrun (1996) and Thrun andPratt (1997, chapter 8)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 1016169,
            "fieldsOfStudy": [
                "Computer Science",
                "Education"
            ],
            "id": "371c9dc680e916f79d9c78fcf6c894a2dd299095",
            "isKey": false,
            "numCitedBy": 685,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates learning in a lifelong context. Lifelong learning addresses situations in which a learner faces a whole stream of learning tasks. Such scenarios provide the opportunity to transfer knowledge across multiple learning tasks, in order to generalize more accurately from less training data. In this paper, several different approaches to lifelong learning are described, and applied in an object recognition domain. It is shown that across the board, lifelong learning approaches generalize consistently more accurately from less training data, by their ability to transfer knowledge across learning tasks."
            },
            "slug": "Is-Learning-The-n-th-Thing-Any-Easier-Than-Learning-Thrun",
            "title": {
                "fragments": [],
                "text": "Is Learning The n-th Thing Any Easier Than Learning The First?"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that across the board, lifelong learning approaches generalize consistently more accurately from less training data, by their ability to transfer knowledge across learning tasks."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 107
                            }
                        ],
                        "text": "If each example can be classified with a \u201clarge margin\u201d then naive parameter counting can be improved upon (Bartlett, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 132
                            }
                        ],
                        "text": "Bounds on the number of tasks and examples of each task required to ensure good performance on novel tasks were given in Baxter and Bartlett (1998), along with anexperiment in which a metric was successfully trained on examples of a subset of 400 Japanese characters and then used as a fixed\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 283
                            }
                        ],
                        "text": "\u2026distributions are identical and they only differ in the conditional probabilities they assign to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization and onenearest-neighbour classification (Baxter, 1995a, 1997b; Baxter & Bartlett, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 782,
                                "start": 437
                            }
                        ],
                        "text": "Using the model of the present paper, and under some extra ass umptions on the tasks in the environment (specifically, that their marginal input-s pace distributions are identical and they only differ in the conditional probabilities they assi gn to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization an d onenearest-neighbour classification (Baxter, 1995a, 1997b; B axter & Bartlett, 1998). This metric can be learnt by sampling from a subset of tasks from the envir o ment, and then used as a distance measure when learning novel tasks drawn from the sa m environment. Bounds on the number of tasks and examples of each task required to ensu re good performance on novel tasks were given in Baxter and Bartlett (1998), along with an experiment in which a metric was successfully trained on examples of a subset of 400 Japan ese characters and then used as a fixed distance measure when learning 2600 as yet unseen char acters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 370,
                                "start": 27
                            }
                        ],
                        "text": "For example, in Baxter and Bartlett (1 998) we reported experiments in which a set of neural network features learnt on a subset of on ly 400 Japanese characters turned out to be good enough for classifying some 2600 unseen character s, even though the features contained several hundred thousand parameters. Similar results may b e found in Intrator and Edelman (1996) and in the experiments reported in Thrun (1996) and Thrun and Pratt (1997, chapter 8)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1052,
                                "start": 437
                            }
                        ],
                        "text": "Using the model of the present paper, and under some extra ass umptions on the tasks in the environment (specifically, that their marginal input-s pace distributions are identical and they only differ in the conditional probabilities they assi gn to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization an d onenearest-neighbour classification (Baxter, 1995a, 1997b; B axter & Bartlett, 1998). This metric can be learnt by sampling from a subset of tasks from the envir o ment, and then used as a distance measure when learning novel tasks drawn from the sa m environment. Bounds on the number of tasks and examples of each task required to ensu re good performance on novel tasks were given in Baxter and Bartlett (1998), along with an experiment in which a metric was successfully trained on examples of a subset of 400 Japan ese characters and then used as a fixed distance measure when learning 2600 as yet unseen char acters. A similar approach is described in Thrun and Mitchell (1995) , Thrun (1996), in which a neural network\u2019s output was trained to match labels on a nove l task, while simultaneously being forced to match its gradient to derivativeinformation generated from a distance metric trained on previous, related tasks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 85
                            }
                        ],
                        "text": "The experiments reported in Baxter (1995a, chapter 4) and Baxter (1995b), Baxter and Bartlett (1998) are also of this nature."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 27
                            }
                        ],
                        "text": "For example, in Baxter and Bartlett (1998) we reported experiments in which a set of neural network features learnt on a subset of only 400 Japanese characters turned out to be good enough for classifying some 2600 unseen characters, even though the features contained several hundred thousand\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 110
                            }
                        ],
                        "text": "Once the feature map is learnt (which can be achieved usingthe techniques outlined in Baxter, 1995b; Baxter & Bartlett, 1998; Baxter, 1995a, chapter 4), only the output weights have to be estimated to learn a novel task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 20
                            }
                        ],
                        "text": "F rom Theorem 13 in Bartlett (1993), we have VCdim(H 1) dl + l(k 1) 2 + 1; which under the restrictions stated above is greater than W=2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 105
                            }
                        ],
                        "text": "If each example can be classified with a \u201clarge margin\u201d thennaive parameter counting can be improved upon (Bartlett, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2061,
                                "start": 437
                            }
                        ],
                        "text": "Using the model of the present paper, and under some extra ass umptions on the tasks in the environment (specifically, that their marginal input-s pace distributions are identical and they only differ in the conditional probabilities they assi gn to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization an d onenearest-neighbour classification (Baxter, 1995a, 1997b; B axter & Bartlett, 1998). This metric can be learnt by sampling from a subset of tasks from the envir o ment, and then used as a distance measure when learning novel tasks drawn from the sa m environment. Bounds on the number of tasks and examples of each task required to ensu re good performance on novel tasks were given in Baxter and Bartlett (1998), along with an experiment in which a metric was successfully trained on examples of a subset of 400 Japan ese characters and then used as a fixed distance measure when learning 2600 as yet unseen char acters. A similar approach is described in Thrun and Mitchell (1995) , Thrun (1996), in which a neural network\u2019s output was trained to match labels on a nove l task, while simultaneously being forced to match its gradient to derivativeinformation generated from a distance metric trained on previous, related tasks. Performance on the nove l tasks improved substantially with the use of the derivative information. Note that there are many other adaptive metric techniques us d in machine learning, but these all focus exclusively on adjusting the metric for a fixed set o f pr blems rather than learning a metric suitable for learning novel, related tasks (bias lea rning). Feature learning or learning internal representations. As with adaptive metric techniques, there are many approaches to feature learning that focus on a dapting features for a fixed task rather than learning features to be used in novel tasks. One o f the few cases where features have been learnt on a subset of tasks with the explicit aim of u sing them on novel tasks was Intrator and Edelman (1996) in which a low-dimensional repr esentation was learnt for a set of multiple related image-recognition tasks and then used t o successfully learn novel tasks of the same kind."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2310,
                                "start": 437
                            }
                        ],
                        "text": "Using the model of the present paper, and under some extra ass umptions on the tasks in the environment (specifically, that their marginal input-s pace distributions are identical and they only differ in the conditional probabilities they assi gn to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization an d onenearest-neighbour classification (Baxter, 1995a, 1997b; B axter & Bartlett, 1998). This metric can be learnt by sampling from a subset of tasks from the envir o ment, and then used as a distance measure when learning novel tasks drawn from the sa m environment. Bounds on the number of tasks and examples of each task required to ensu re good performance on novel tasks were given in Baxter and Bartlett (1998), along with an experiment in which a metric was successfully trained on examples of a subset of 400 Japan ese characters and then used as a fixed distance measure when learning 2600 as yet unseen char acters. A similar approach is described in Thrun and Mitchell (1995) , Thrun (1996), in which a neural network\u2019s output was trained to match labels on a nove l task, while simultaneously being forced to match its gradient to derivativeinformation generated from a distance metric trained on previous, related tasks. Performance on the nove l tasks improved substantially with the use of the derivative information. Note that there are many other adaptive metric techniques us d in machine learning, but these all focus exclusively on adjusting the metric for a fixed set o f pr blems rather than learning a metric suitable for learning novel, related tasks (bias lea rning). Feature learning or learning internal representations. As with adaptive metric techniques, there are many approaches to feature learning that focus on a dapting features for a fixed task rather than learning features to be used in novel tasks. One o f the few cases where features have been learnt on a subset of tasks with the explicit aim of u sing them on novel tasks was Intrator and Edelman (1996) in which a low-dimensional repr esentation was learnt for a set of multiple related image-recognition tasks and then used t o successfully learn novel tasks of the same kind. The experiments reported in Baxter (1995a, ch apter 4) and Baxter (1995b), Baxter and Bartlett (1998) are also of this nature."
                    },
                    "intents": []
                }
            ],
            "corpusId": 685382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "015999a72c70a960e59c51078b09c8f672af0d2c",
            "isKey": true,
            "numCitedBy": 1198,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Sample complexity results from computational learning theory, when applied to neural network learning for pattern classification problems, suggest that for good generalization performance the number of training examples should grow at least linearly with the number of adjustable parameters in the network. Results in this paper show that if a large neural network is used for a pattern classification problem and the learning algorithm finds a network with small weights that has small squared error on the training patterns, then the generalization performance depends on the size of the weights rather than the number of weights. For example, consider a two-layer feedforward network of sigmoid units, in which the sum of the magnitudes of the weights associated with each unit is bounded by A and the input dimension is n. We show that the misclassification probability is no more than a certain error estimate (that is related to squared error on the training set) plus A/sup 3/ /spl radic/((log n)/m) (ignoring log A and log m factors), where m is the number of training patterns. This may explain the generalization performance of neural networks, particularly when the number of training examples is considerably smaller than the number of weights. It also supports heuristics (such as weight decay and early stopping) that attempt to keep the weights small during training. The proof techniques appear to be useful for the analysis of other pattern classifiers: when the input domain is a totally bounded metric space, we use the same approach to give upper bounds on misclassification probability for classifiers with decision boundaries that are far from the training examples."
            },
            "slug": "The-Sample-Complexity-of-Pattern-Classification-The-Bartlett",
            "title": {
                "fragments": [],
                "text": "The Sample Complexity of Pattern Classification with Neural Networks: The Size of the Weights is More Important than the Size of the Network"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Results in this paper show that if a large neural network is used for a pattern classification problem and the learning algorithm finds a network with small weights that has small squared error on the training patterns, then the generalization performance depends on the size of the weights rather than the number of weights."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149607686"
                        ],
                        "name": "Anton Schwartz",
                        "slug": "Anton-Schwartz",
                        "structuredName": {
                            "firstName": "Anton",
                            "lastName": "Schwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anton Schwartz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 270
                            }
                        ],
                        "text": "\u2026literature have proposed algorithms for both sharing the information in related tasks to improve average generalization performance across those tasks Singh (1992), Ring (1995), or learning bias from a set of tasks to improve performance on future tasks Sutton (1992), Thrun and Schwartz (1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9569834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e41cda7b81cc49640210173fd45eb06cdbd6e824",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Reinforcement learning addresses the problem of learning to select actions in order to maximize one's performance in unknown environments. To scale reinforcement learning to complex real-world tasks, such as typically studied in AI, one must ultimately be able to discover the structure in the world, in order to abstract away the myriad of details and to operate in more tractable problem spaces. \n \nThis paper presents the SKILLS algorithm. SKILLS discovers skills, which are partially defined action policies that arise in the context of multiple, related tasks. Skills collapse whole action sequences into single operators. They are learned by minimizing the compactness of action policies, using a description length argument on their representation. Empirical results in simple grid navigation tasks illustrate the successful discovery of structure in reinforcement learning."
            },
            "slug": "Finding-Structure-in-Reinforcement-Learning-Thrun-Schwartz",
            "title": {
                "fragments": [],
                "text": "Finding Structure in Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "SKILLS discovers skills, which are partially defined action policies that arise in the context of multiple, related tasks, that are learned by minimizing the compactness of action policies, using a description length argument on their representation."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398965769"
                        ],
                        "name": "Y. Abu-Mostafa",
                        "slug": "Y.-Abu-Mostafa",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Abu-Mostafa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Abu-Mostafa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 604,
                                "start": 93
                            }
                        ],
                        "text": "Other similar approaches include Suddarth an d Kergosien (1990), Suddarth and Holden (1991), Abu-Mostafa (1993). Bias as computational complexity. In this paper we consider inductive bias from a samplecomplexity perspective: how does the learnt bias decrease t he number of examples required of novel tasks for good generalization? A natural alternative lin of enquiry is how the runningtime or computational complexity of a learning algorithm ma y be improved by training on related tasks. Some early algorithms for neural networks in this vein are contained in Sharkey and Sharkey (1993), Pratt (1992). Reinforcement Learning."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1050,
                                "start": 93
                            }
                        ],
                        "text": "Other similar approaches include Suddarth an d Kergosien (1990), Suddarth and Holden (1991), Abu-Mostafa (1993). Bias as computational complexity. In this paper we consider inductive bias from a samplecomplexity perspective: how does the learnt bias decrease t he number of examples required of novel tasks for good generalization? A natural alternative lin of enquiry is how the runningtime or computational complexity of a learning algorithm ma y be improved by training on related tasks. Some early algorithms for neural networks in this vein are contained in Sharkey and Sharkey (1993), Pratt (1992). Reinforcement Learning. Many control tasks can appropriately be viewed as elements o f sets of related tasks, such as learning to navigate to different g oal states, or learning a set of complex motor control tasks. A number of papers in the reinfo rcement learning literature have proposed algorithms for both sharing the information i n related tasks to improve average generalization performance across those tasks Singh (1992 ), Ring (1995), or learning bias from a set of tasks to improve performance on future tasks Sut ton (1992), Thrun and Schwartz (1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 92
                            }
                        ],
                        "text": "Other similar approaches include Suddarth and Kergosien (1990), Suddarth and Holden (1991), Abu-Mostafa (1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 590,
                                "start": 93
                            }
                        ],
                        "text": "Other similar approaches include Suddarth an d Kergosien (1990), Suddarth and Holden (1991), Abu-Mostafa (1993). Bias as computational complexity. In this paper we consider inductive bias from a samplecomplexity perspective: how does the learnt bias decrease t he number of examples required of novel tasks for good generalization? A natural alternative lin of enquiry is how the runningtime or computational complexity of a learning algorithm ma y be improved by training on related tasks. Some early algorithms for neural networks in this vein are contained in Sharkey and Sharkey (1993), Pratt (1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 93
                            }
                        ],
                        "text": "Other similar approaches include Suddarth an d Kergosien (1990), Suddarth and Holden (1991), Abu-Mostafa (1993). Bias as computational complexity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8479072,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b79a72a341c93f7e69b4d485dc75c6161331f0d2",
            "isKey": true,
            "numCitedBy": 84,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of learning an unknown function by putting together several pieces of information (hints) that we know about the function. We introduce a method that generalizes learning from examples to learning from hints. A canonical representation of hints is defined and illustrated for new types of hints. All the hints are represented to the learning process by examples, and examples of the function are treated on equal footing with the rest of the hints. During learning, examples from different hints are selected for processing according to a given schedule. We present two types of schedules; fixed schedules that specify the relative emphasis of each hint, and adaptive schedules that are based on how well each hint has been learned so far. Our learning method is compatible with any descent technique that we may choose to use."
            },
            "slug": "A-Method-for-Learning-From-Hints-Abu-Mostafa",
            "title": {
                "fragments": [],
                "text": "A Method for Learning From Hints"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work introduces a method that generalizes learning from examples to learning from hints, and presents two types of schedules; fixed schedules that specify the relative emphasis of each hint, and adaptive schedules based on how well each hint has been learned so far."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145004630"
                        ],
                        "name": "M. Anthony",
                        "slug": "M.-Anthony",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Anthony",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Anthony"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This proof follows a similar argument to the one presented in  Anthony and Bartlett (1999)  for ordinary Boolean function learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35737200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d2e0be460e0e3b2b74ec8260d886b2397f8f320",
            "isKey": false,
            "numCitedBy": 1580,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This important work describes recent theoretical advances in the study of artificial neural networks. It explores probabilistic models of supervised learning problems, and addresses the key statistical and computational questions. Chapters survey research on pattern classification with binary-output networks, including a discussion of the relevance of the Vapnik Chervonenkis dimension, and of estimates of the dimension for several neural network models. In addition, Anthony and Bartlett develop a model of classification by real-output networks, and demonstrate the usefulness of classification with a \"large margin.\" The authors explain the role of scale-sensitive versions of the Vapnik Chervonenkis dimension in large margin classification, and in real prediction. Key chapters also discuss the computational complexity of neural network learning, describing a variety of hardness results, and outlining two efficient, constructive learning algorithms. The book is self-contained and accessible to researchers and graduate students in computer science, engineering, and mathematics."
            },
            "slug": "Neural-Network-Learning-Theoretical-Foundations-Anthony-Bartlett",
            "title": {
                "fragments": [],
                "text": "Neural Network Learning - Theoretical Foundations"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The authors explain the role of scale-sensitive versions of the Vapnik Chervonenkis dimension in large margin classification, and in real prediction, and discuss the computational complexity of neural network learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11023955"
                        ],
                        "name": "Mark B. Ring",
                        "slug": "Mark-B.-Ring",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Ring",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark B. Ring"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 166
                            }
                        ],
                        "text": "\u2026literature have proposed algorithms for both sharing the information in related tasks to improve average generalization performance across those tasks Singh (1992), Ring (1995), or learning bias from a set of tasks to improve performance on future tasks Sutton (1992), Thrun and Schwartz (1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27150180,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "082b1f5c791cadef18c4920ecc1396615a3fe7cb",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 133,
            "paperAbstract": {
                "fragments": [],
                "text": "Continual learning is the constant development of complex behaviors with no nal end in mind. It is the process of learning ever more complicated skills by building on those skills already developed. In order for learning at one stage of development to serve as the foundation for later learning, a continual-learning agent should learn hierarchically. CHILD, an agent capable of Continual, Hierarchical, Incremental Learning and Development is proposed, described, tested, and evaluated in this dissertation. CHILD accumulates useful behaviors in reinforcement environments by using the Temporal Transition Hierarchies learning algorithm, also derived in the dissertation. This constructive algorithm generates a hierarchical, higher-order neural network that can be used for predicting context-dependent temporal sequences and can learn sequential-task benchmarks more than two orders of magnitude faster than competing neural-network systems. Consequently, CHILD can quickly solve complicated non-Markovian reinforcement-learning tasks and can then transfer its skills to similar but even more complicated tasks, learning these faster still. This continual-learning approach is made possible by the unique properties of Temporal Transition Hierarchies, which allow existing skills to be amended and augmented in precisely the same way that they were constructed in the rst place. Table of"
            },
            "slug": "Continual-learning-in-reinforcement-environments-Ring",
            "title": {
                "fragments": [],
                "text": "Continual learning in reinforcement environments"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "CHILD, an agent capable of Continual, Hierarchical, Incremental Learning and Development is proposed, described, tested, and evaluated in this dissertation and generates a hierarchical, higher-order neural network that can be used for predicting context-dependent temporal sequences and can learn sequential-task benchmarks more than two orders of magnitude faster than competing neural-network systems."
            },
            "venue": {
                "fragments": [],
                "text": "GMD-Bericht"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49601276"
                        ],
                        "name": "D. Silver",
                        "slug": "D.-Silver",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Silver",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Silver"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 21
                            }
                        ],
                        "text": "In this context, see Silver and Mercer (1996), Thrun and O\u2019Sullivan (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 527678,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "id": "cb48a7a46f9bc3ba74ecd728e91866d259a7982f",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "With a distinction made between two forms of task knowledge transfer, 'representational' and 'functional', eta MTL, a modified version of the multiple task learning (MTL) method of functional (parallel) transfer, is introduced. The eta MTL method employs a separate learning rate, etak, for each task output node k. etak varies as a function of a measure of relatedness, Rk, between the kth task and the primary task of interest. Results of experiments demonstrate the ability of eta MTL to dynamically select the most related source task(s) for the functional transfer of prior domain knowledge. The eta MTL method of learning is nearly equivalent to standard MTL when all parallel tasks are sufficiently related to the primary task, and is similar to single task learning when none of the parallel tasks are related to the primary task."
            },
            "slug": "The-Parallel-Transfer-of-Task-Knowledge-Using-Rates-Silver",
            "title": {
                "fragments": [],
                "text": "The Parallel Transfer of Task Knowledge Using Dynamic Learning Rates Based on a Measure of Relatedness"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results of experiments demonstrate the ability of eta MTL to dynamically select the most related source task(s) for the functional transfer of prior domain knowledge."
            },
            "venue": {
                "fragments": [],
                "text": "Connect. Sci."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980953"
                        ],
                        "name": "S. Suddarth",
                        "slug": "S.-Suddarth",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Suddarth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Suddarth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4449657"
                        ],
                        "name": "Y. Kergosien",
                        "slug": "Y.-Kergosien",
                        "structuredName": {
                            "firstName": "Yannick",
                            "lastName": "Kergosien",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Kergosien"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 33
                            }
                        ],
                        "text": "Other similar approaches include Suddarth and Kergosien (1990), Suddarth and Holden (1991), Abu-Mostafa (1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Other similar approaches include  Suddarth and Kergosien (1990) , Suddarth and Holden (1991), Abu-Mostafa (1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27857819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ffb199e36de4f34ea233a30d392fdcf0c3b25a14",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks can be given \u201chints\u201d by increasing the number of parameters learned to include parameters related to the original relationship. The effect of this hint, whether applied to back-propagation learning or to more general types of pattern associators is to reduce training time and improve generalization performance. A detailed vector field analysis of a hinted back-propagation network solving the XOR problem, shows that the hint is capable of eliminating pathological local minima. A set-theory/functional entropy analysis shows that the hint can be applied to any learning mechanism that has an internal (\u201chidden\u201d) layer of processing. These analyses and tests conducted on a variety of problems using different types of networks demonstrate the potential of the hint as a method of controlling training in order to predictably train systems to effectively model data."
            },
            "slug": "Rule-Injection-Hints-as-a-Means-of-Improving-and-Suddarth-Kergosien",
            "title": {
                "fragments": [],
                "text": "Rule-Injection Hints as a Means of Improving Network Performance and Learning Time"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The potential of the hint, whether applied to back-propagation learning or to more general types of pattern associators is to reduce training time and improve generalization performance."
            },
            "venue": {
                "fragments": [],
                "text": "EURASIP Workshop"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980953"
                        ],
                        "name": "S. Suddarth",
                        "slug": "S.-Suddarth",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Suddarth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Suddarth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24934793"
                        ],
                        "name": "A. Holden",
                        "slug": "A.-Holden",
                        "structuredName": {
                            "firstName": "Alistair",
                            "lastName": "Holden",
                            "middleNames": [
                                "D.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Holden"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 64
                            }
                        ],
                        "text": "Other similar approaches include Suddarth and Kergosien (1990), Suddarth and Holden (1991), Abu-Mostafa (1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Other similar approaches include Suddarth and Kergosien (1990),  Suddarth and Holden (1991) , Abu-Mostafa (1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 41080002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dfe7dbbd6e8d5d3720f58c2c9a0b9bec040a8ef8",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Symbolic-Neural-Systems-and-the-Use-of-Hints-for-Suddarth-Holden",
            "title": {
                "fragments": [],
                "text": "Symbolic-Neural Systems and the Use of Hints for Developing Complex Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Man Mach. Stud."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51378744"
                        ],
                        "name": "J. Lamperti",
                        "slug": "J.-Lamperti",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lamperti",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lamperti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ological space by equipping it with the topology of weak convergence. B ( P ) is then the  -algebra generated by this topology. The following two de\ufb01nitions are taken (with minor modi\ufb01cation s) from Pollard (1984). De\ufb01nition 8. A set H of [0 ; 1] -valued functions on Z is indexed by the set T if there exists a function f : Z T ! [0 ; 1] such that H = f ( ; t ) : t 2 T g : De\ufb01nition 9. The set H is permissible "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "1) follows from Lemma 31. (2) and (3) are immediate from the de\ufb01nitions. As H is permissible for all 2 , (4) can be proved by an identical argument to that used in the \u201cMeasurable Suprema\u201d section of Pollard (1984), appendix C. For (5), note that for any Borel-measurable h : Z ! [0 ; 1] , the function P de\ufb01ned by h ( P ) := R Z z dP is Borel measurable Kechris (1995, chapter 17). Now, permissibility of H automa"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ix D. Measurability In order for Theorems 2 and 18 to hold in full generality we had to impose a constraint called \u201cpermissibility\u201d on the hypothesis space family H . Permissibility was introduced by Pollard (1984) for ordinary hypothesis classes H . His de\ufb01nition is very similar to Dudley\u2019s \u201cimage admissibl e Suslin\u201d (Dudley, 1984). We will be extending this de\ufb01nition to cover hypothesis space families. Throug"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "t 2 T g : s S Let ( X ; ;  ) be a measure space and T be an analytic subset of a Polish space. Let A X denote the analytic subsets of X . The following three facts about analytic sets are taken from Pollard (1984), appendix C. (a) If ( X ; ;  ) is complete then A X  . (b) A ( X T ) contains the product  -algebra B . (c) For any set Y in A ( X T ) , the projection  X of onto is in . Recall De\ufb01nition 2 for t"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 246
                            }
                        ],
                        "text": "Under the same conditions as Theorem 18, ifm max( 8 2 n log 4C 8 ;H \u00c6 ; 2 2 ) ; (54) then Pr z 2 (X Y )(m;n) : supH d [e\u0302rz(h); erP(h)\u2104 > \u00c6 (55) A.1 Proof of Theorem 18\nThe proof is via a double symmetrization argument of the kindgiven in chapter 2 of Pollard (1984)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "; 2  ) (54) then Pr  z 2 ( X Y ) ( m;n ) : sup H d  er [ ^ z h ; er P )] &gt;    (55) A.1 Proof of Theorem 18 The proof is via a double symmetrization argument of the kind given in chapter 2 of Pollard (1984). I have also borrowed some ideas from the proof of Theorem 3 in Haussler (1992). 180 A MODEL OF INDUCTIVE BIAS LEARNING A.1.1 FIRST SYMMETRIZATION An extra piece of notation: for all z 2 ( X Y ) (2 m"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37016743,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f274a4cee19d93218c209aa07f47abea0598ae91",
            "isKey": true,
            "numCitedBy": 1027,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "It is clear that for given I,un } and t, the better theorem of this kind would be the one in which (2) is proved for the larger class of functions f. In this paper we shall show that certain known \"invariance principles\" can under some hypotheses be improved by considerably enlarging the class of functions for which (2) holds. This will be done by considering spaces S other than the customary ones. For example, in studying convergence to the Wiener process, it is usual to let S be the space (denoted e) of continuous functions with the uniform topology. However, this choice does not fully exploit the pleasant properties of the Wiener path-functions, which are not only continuous but also Holder continuous of any order up to 1/2. Therefore we shall attempt to use spaces Lip5 in place of e as the function-space S. When weak convergence can be established using such spaces, the class of functionals for which (2) is known to hold becomes much larger than before. To carry out the idea sketched above it is necessary to have a criterion which guarantees that the sample functions of a stochastic process are a.s."
            },
            "slug": "ON-CONVERGENCE-OF-STOCHASTIC-PROCESSES-Lamperti",
            "title": {
                "fragments": [],
                "text": "ON CONVERGENCE OF STOCHASTIC PROCESSES"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144442133"
                        ],
                        "name": "L. Pratt",
                        "slug": "L.-Pratt",
                        "structuredName": {
                            "firstName": "Lorien",
                            "lastName": "Pratt",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pratt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 99
                            }
                        ],
                        "text": "Some early algorithms for neural networks inthis vein are contained in Sharkey and Sharkey (1993), Pratt (1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 115
                            }
                        ],
                        "text": "This time, however, the learner is simply looking forn hypotheses(h1; : : : ; hn), all contained in the same hypothesis spaceH, such that the average generalization error of then hypotheses is minimal."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 147613,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b66fcdaca4c9e789bd4fae5dfd08a325bbb9fa48",
            "isKey": false,
            "numCitedBy": 309,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Previously, we have introduced the idea of neural network transfer, where learning on a target problem is sped up by using the weights obtained from a network trained for a related source task. Here, we present a new algorithm, called Discriminability-Based Transfer (DBT), which uses an information measure to estimate the utility of hyperplanes defined by source weights in the target network, and rescales transferred weight magnitudes accordingly. Several experiments demonstrate that target networks initialized via DBT learn significantly faster than networks initialized randomly."
            },
            "slug": "Discriminability-Based-Transfer-between-Neural-Pratt",
            "title": {
                "fragments": [],
                "text": "Discriminability-Based Transfer between Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new algorithm, called Discriminability-Based Transfer (DBT), is presented, which uses an information measure to estimate the utility of hyperplanes defined by source weights in the target network, and rescales transferred weight magnitudes accordingly."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145115302"
                        ],
                        "name": "N. Sauer",
                        "slug": "N.-Sauer",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Sauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sauer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 249
                            }
                        ],
                        "text": "\u2026functionof H is defined by H(m) := maxx2Xm Hjx : TheVapnik-Chervonenkis dimensionVCdim(H) is the size of the largest set shattered byH:VCdim(H) := maxfm : H(m) = 2mg: An important result in the theory of learning Boolean functions is Sauer\u2019s Lemma (Sauer, 1972), of which we will also make use."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 256,
                                "start": 244
                            }
                        ],
                        "text": "Thegrowth functionof H is defined by H(m) := maxx2Xm Hjx : TheVapnik-Chervonenkis dimensionVCdim(H) is the size of the largest set shattered byH:VCdim(H) := maxfm : H(m) = 2mg: An important result in the theory of learning Boolean functions is Sauer\u2019s Lemma (Sauer, 1972), of which we will also make use."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 9
                            }
                        ],
                        "text": "Lemma 9 (Sauer\u2019s Lemma)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 3
                            }
                        ],
                        "text": "By Sauer\u2019s Lemma, each node in the first hidden layer of the featur map computes at most(emn=(d+ 1))d+1 functions on thenm input vectors inx."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 82
                            }
                        ],
                        "text": "An important result in the theory of learning Boolean functi ons is Sauer\u2019s Lemma (Sauer, 1972), of which we will also make use."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7231983,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "788c6d1b1419a0f7b7695c0e7e9e41cf54fbfe1b",
            "isKey": true,
            "numCitedBy": 894,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-Density-of-Families-of-Sets-Sauer",
            "title": {
                "fragments": [],
                "text": "On the Density of Families of Sets"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comb. Theory, Ser. A"
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47392513"
                        ],
                        "name": "Jonathan Baxter",
                        "slug": "Jonathan-Baxter",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Baxter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Baxter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 121
                            }
                        ],
                        "text": "Bounds on the number of tasks and examples of each task required to ensure good performance on novel tasks were given in Baxter and Bartlett (1998), along with anexperiment in which a metric was successfully trained on examples of a subset of 400 Japanese characters and then used as a fixed\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 274
                            }
                        ],
                        "text": "\u2026distributions are identical and they only differ in the conditional probabilities they assign to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization and onenearest-neighbour classification (Baxter, 1995a, 1997b; Baxter & Bartlett, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The experiments reported in Baxter (1995a, chapter 4) and Baxter (1995b),  Baxter and Bartlett (1998)  are also of this nature."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 74
                            }
                        ],
                        "text": "The experiments reported in Baxter (1995a, chapter 4) and Baxter (1995b), Baxter and Bartlett (1998) are also of this nature."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 16
                            }
                        ],
                        "text": "For example, in Baxter and Bartlett (1998) we reported experiments in which a set of neural network features learnt on a subset of only 400 Japanese characters turned out to be good enough for classifying some 2600 unseen characters, even though the features contained several hundred thousand\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 101
                            }
                        ],
                        "text": "Once the feature map is learnt (which can be achieved usingthe techniques outlined in Baxter, 1995b; Baxter & Bartlett, 1998; Baxter, 1995a, chapter 4), only the output weights have to be estimated to learn a novel task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Bounds on the number of tasks and examples of each task required to ensure good performance on novel tasks were given in  Baxter and Bartlett (1998) , along with an experiment in which a metric was successfully trained on examples of a subset of 400 Japanese characters and then used as a fixed distance measure when learning 2600 as yet unseen characters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Using the model of the present paper, and under some extra assumptions on the tasks in the environment (specifically, that their marginal input-space distributions are identical and they only differ in the conditional probabilities they assign to class labels), it can be shown that there is an optimal metric or distance measure to use for vector quantization and onenearest-neighbour classification (Baxter, 1995a, 1997b;  Baxter & Bartlett, ..."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16859662,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "221869032f16286e93c5b91b396a466a22d7cf27",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We prove that the Canonical Distortion Measure (CDM) [2,3] is the optimal distance measure to use for 1 nearest-neighbour (1-NN) classification, and show that it reduces to squared Euclidean distance in feature space for function classes that can be expressed as linear combinations of a fixed set of features. PAC-like bounds are given on the sample-complexity required to learn the CDM. An experiment is presented in which a neural network CDM was learnt for a Japanese OCR environment and then used to do 1-NN classification."
            },
            "slug": "The-Canonical-Distortion-Measure-in-Feature-Space-Baxter-Bartlett",
            "title": {
                "fragments": [],
                "text": "The Canonical Distortion Measure in Feature Space and 1-NN Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "It is proved that the Canonical Distortion Measure (CDM) is the optimal distance measure to use for 1 nearest-neighbour (1-NN) classification, and it is shown that it reduces to squared Euclidean distance in feature space for function classes that can be expressed as linear combinations of a fixed set of features."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2647026"
                        ],
                        "name": "A. Blumer",
                        "slug": "A.-Blumer",
                        "structuredName": {
                            "firstName": "Anselm",
                            "lastName": "Blumer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blumer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683946"
                        ],
                        "name": "A. Ehrenfeucht",
                        "slug": "A.-Ehrenfeucht",
                        "structuredName": {
                            "firstName": "Andrzej",
                            "lastName": "Ehrenfeucht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ehrenfeucht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For Boolean learning problems (pattern classification) these parameters are the bias learning analogue of the Vapnik-Chervonenkis dimension (Vapnik, 1982;  Blumer et al., 1989 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 275
                            }
                        ],
                        "text": "\u2026is controlledby the size of certain covering numbers associated with the set of all hypothesis spaces available to the bias learner, in much the same way as the sample complexity in learning Boolean functions is controlled by theVapnik-Chervonenkis dimension (Vapnik, 1982; Blumer et al., 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Proofs of this result may be found in Vapnik (1982),  Blumer et al. (1989) , and will not be reproduced here."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In this paper we introduce and analyze a formal model of bias learning that builds upon the PAC model of machine learning and its variants (Vapnik, 1982; Valiant, 1984;  Blumer, Ehrenfeucht, Haussler, & Warmuth, 1989;  Haussler, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 153
                            }
                        ],
                        "text": "For Boolean learning problems (pattern classification) these parameters are the bias learning analogue of theVapnik-Chervonenkis dimension(Vapnik, 1982; Blumer et al., 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "These results show that the sample complexity is controlled by the size of certain covering numbers associated with the set of all hypothesis spaces available to the bias learner, in much the same way as the sample complexity in learning Boolean functions is controlled by the Vapnik-Chervonenkis dimension (Vapnik, 1982;  Blumer et al., 1989 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1138467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0b8fa3496283d4d808fba9ff62d5f024bcf23be",
            "isKey": true,
            "numCitedBy": 1909,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Valiant's learnability model is extended to learning classes of concepts defined by regions in Euclidean space En. The methods in this paper lead to a unified treatment of some of Valiant's results, along with previous results on distribution-free convergence of certain pattern recognition algorithms. It is shown that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned. Using this parameter, the complexity and closure properties of learnable classes are analyzed, and the necessary and sufficient conditions are provided for feasible learnability."
            },
            "slug": "Learnability-and-the-Vapnik-Chervonenkis-dimension-Blumer-Ehrenfeucht",
            "title": {
                "fragments": [],
                "text": "Learnability and the Vapnik-Chervonenkis dimension"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 19
                            }
                        ],
                        "text": "From Theorem 13 in Bartlett (1993), we have VCdim(H 1) dl + l(k 1)2 + 1; which under the restrictions stated above is greater thanW=2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6886185,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa9f34e869d7b8cca2f1cdcf4f79ee9a4478409b",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning in multilayer feed-forward networks of linear threshold units. We show that the Vapnik-Chervonenkis dimension of the class of functions that can be computed by a two-layer threshold network with real inputs is at least proportional to the number of weights in the network. This result also holds for a large class of twolayer networks with binary inputs, and a large class of three-layer networks with real inputs. In Valiant's probably approximately correct learning framework, this implies that the number of examples necessary for learning in these networks is at least linear in the number of weights. This bound is within a log factor of the upper bound."
            },
            "slug": "Lower-bounds-on-the-Vapnik-Chervonenkis-dimension-Bartlett",
            "title": {
                "fragments": [],
                "text": "Lower bounds on the Vapnik-Chervonenkis dimension of multi-layer threshold networks"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "It is shown that the Vapnik-Chervonenkis dimension of the class of functions that can be computed by a two-layer threshold network with real inputs is at least proportional to the number of weights in the network."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8909922"
                        ],
                        "name": "N. Intrator",
                        "slug": "N.-Intrator",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Intrator",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Intrator"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331213"
                        ],
                        "name": "S. Edelman",
                        "slug": "S.-Edelman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Edelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Edelman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One of the few cases where features have been learnt on a subset of tasks with the explicit aim of using them on novel tasks was  Intrator and Edelman (1996)  in which a low-dimensional representation was learnt for a set of multiple related image-recognition tasks and then used to successfully learn novel tasks of the same kind."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 32
                            }
                        ],
                        "text": "Similar results may be found in Intrator and Edelman (1996) and in the experiments reported in Thrun (1996) and Thrun andPratt (1997, chapter 8)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 129
                            }
                        ],
                        "text": "One of the few cases where features have been learnt on a subset of tasks with the explicit aim of using them on novel tasks was Intrator and Edelman (1996) in which a low-dimensional representation was learnt for a set of multiple related image-recognition tasks and then used to successfully learn\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60960922,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1203f7e9fc1427aae10214c04d62c4371c74d263",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider training classifiers for multiple tasks as a method for improving generalization and obtaining a better low-dimensional representation. To that end, we introduce a hybrid training methodology for MLP networks; the utility of the hidden-unit representation is assessed by embedding it into a 2D space using multidimensional scaling. The proposed methodology is tested on a highly nonlinear image classification task."
            },
            "slug": "How-to-Make-a-Low-Dimensional-Representation-for-Intrator-Edelman",
            "title": {
                "fragments": [],
                "text": "How to Make a Low-Dimensional Representation Suitable for Diverse Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A hybrid training methodology for MLP networks is introduced; the utility of the hidden-unit representation is assessed by embedding it into a 2D space using multidimensional scaling."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47392513"
                        ],
                        "name": "Jonathan Baxter",
                        "slug": "Jonathan-Baxter",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Baxter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Baxter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 252
                            }
                        ],
                        "text": "\u2026distributions are identical and they only differ in the conditional probabilities they assign to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization and onenearest-neighbour classification (Baxter, 1995a, 1997b; Baxter & Bartlett, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 106
                            }
                        ],
                        "text": "However, a model using a mixture of hierarchical Bayesian and information-theoretic ideaswas presented in Baxter (1997a), with similar conclusions to those found here."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2045411,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bb8ccbef10f3996cf6a17af689260b8291a8245",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "To measure the quality of a set of vector quantization points a means of measuring the distance between a random point and its quantization is required. Common metrics such as the Hamming and Euclidean metrics, while mathematically simple, are inappropriate for comparing natural signals such as speech or images. In this paper it is shown how an environment of functions on an input space X induces a canonical distortion measure (CDM) on X. The depiction \u201ccanonical\u201d is justified because it is shown that optimizing the reconstruction error of X with respect to the CDM gives rise to optimal piecewise constant approximations of the functions in the environment. The CDM is calculated in closed form for several different function classes. An algorithm for training neural networks to implement the CDM is presented along with some encouraging experimental results."
            },
            "slug": "The-Canonical-Distortion-Measure-for-Vector-and-Baxter",
            "title": {
                "fragments": [],
                "text": "The Canonical Distortion Measure for Vector Quantization and Function Approximation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown how an environment of functions on an input space X induces a canonical distortion measure (CDM) on X that gives rise to optimal piecewise constant approximations of the functions in the environment."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145179124"
                        ],
                        "name": "I. Good",
                        "slug": "I.-Good",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Good",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Good"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121270218,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "0e04161b26757f32a005635f46c66dcc05bc46d5",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "SummaryA standard technique in subjective \u201cBayesian\u201d methodology is for a subject (\u201cyou\u201d) to make judgements of the probabilities that a physical probability lies in various intervals. In the hierarchical Bayesian technique you make probability judgements (of a higher type, order, level, or stage) concerning the judgements of lower type. The paper will outlinesome of the history of this hierarchical technique with emphasis on the contributions by I. J. Good because I have read every word written by him."
            },
            "slug": "Some-history-of-the-hierarchical-Bayesian-Good",
            "title": {
                "fragments": [],
                "text": "Some history of the hierarchical Bayesian methodology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ral feature classes in Section 3.2. These bounds are applied to the problem of l learning a neural network feature set in Section 3.3. 3.1 The Feature Learning Model Consider the following quote from Vapnik (1996): The classical approach to estimating multidimensional functional dependencies is based on the following belief: Real-life problems are such that there exists a small numberof \u201cstrong features,\u201d simp"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 34
                            }
                        ],
                        "text": "Consider the following quote from Vapnik (1996):\nThe classical approach to estimating multidimensional functio al dependencies is based on the following belief:\nReal-life problems are such that there exists a small numberof \u201cstrong features,\u201d simple functions of which (say linear combinations)\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": true,
            "numCitedBy": 38756,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881615"
                        ],
                        "name": "R. Dudley",
                        "slug": "R.-Dudley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dudley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dudley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 116062098,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6c06333850b96721709b3162c6332939a2fdce31",
            "isKey": false,
            "numCitedBy": 2183,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Foundations: set theory 2. General topology 3. Measures 4. Integration 5. Lp spaces: introduction to functional analysis 6. Convex sets and duality of normed spaces 7. Measure, topology, and differentiation 8. Introduction to probability theory 9. Convergence of laws and central limit theorems 10. Conditional expectations and martingales 11. Convergence of laws on separable metric spaces 12. Stochastic processes 13. Measurability: Borel isomorphism and analytic sets Appendixes: A. Axiomatic set theory B. Complex numbers, vector spaces, and Taylor's theorem with remainder C. The problem of measure D. Rearranging sums of nonnegative terms E. Pathologies of compact nonmetric spaces Indices."
            },
            "slug": "Real-Analysis-and-Probability-Dudley",
            "title": {
                "fragments": [],
                "text": "Real Analysis and Probability"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477489"
                        ],
                        "name": "L. Devroye",
                        "slug": "L.-Devroye",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Devroye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devroye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087528"
                        ],
                        "name": "L. Gy\u00f6rfi",
                        "slug": "L.-Gy\u00f6rfi",
                        "structuredName": {
                            "firstName": "L\u00e1szl\u00f3",
                            "lastName": "Gy\u00f6rfi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gy\u00f6rfi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755694"
                        ],
                        "name": "G. Lugosi",
                        "slug": "G.-Lugosi",
                        "structuredName": {
                            "firstName": "G\u00e1bor",
                            "lastName": "Lugosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lugosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 116929976,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43fcdee6c6d885ac2bd32e122dbf282f93720c22",
            "isKey": false,
            "numCitedBy": 3565,
            "numCiting": 557,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface * Introduction * The Bayes Error * Inequalities and alternatedistance measures * Linear discrimination * Nearest neighbor rules *Consistency * Slow rates of convergence Error estimation * The regularhistogram rule * Kernel rules Consistency of the k-nearest neighborrule * Vapnik-Chervonenkis theory * Combinatorial aspects of Vapnik-Chervonenkis theory * Lower bounds for empirical classifier selection* The maximum likelihood principle * Parametric classification *Generalized linear discrimination * Complexity regularization *Condensed and edited nearest neighbor rules * Tree classifiers * Data-dependent partitioning * Splitting the data * The resubstitutionestimate * Deleted estimates of the error probability * Automatickernel rules * Automatic nearest neighbor rules * Hypercubes anddiscrete spaces * Epsilon entropy and totally bounded sets * Uniformlaws of large numbers * Neural networks * Other error estimates *Feature extraction * Appendix * Notation * References * Index"
            },
            "slug": "A-Probabilistic-Theory-of-Pattern-Recognition-Devroye-Gy\u00f6rfi",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Theory of Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Bayes Error and Vapnik-Chervonenkis theory are applied as guide for empirical classifier selection on the basis of explicit specification and explicit enforcement of the maximum likelihood principle."
            },
            "venue": {
                "fragments": [],
                "text": "Stochastic Modelling and Applied Probability"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39201543"
                        ],
                        "name": "J. Berger",
                        "slug": "J.-Berger",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Berger",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Berger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 96
                            }
                        ],
                        "text": "The earliest approaches to bias learning come from Hierarchical Bayesian\nmethods in statistics (Berger, 1985; Good, 1980; Gelman, Carlin, Stern, & Rubim, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 96
                            }
                        ],
                        "text": "The earliest approaches to bias learning come from Hierarch ical Bayesian methods in statistics (Berger, 1985; Good, 1980; Gelman, Ca rlin, Stern, & Rubim, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120366929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9dd05b69d6906fff6ea6c4ba3609a6d97c9b8a3",
            "isKey": false,
            "numCitedBy": 7326,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "An overview of statistical decision theory, which emphasizes the use and application of the philosophical ideas and mathematical structure of decision theory. The text assumes a knowledge of basic probability theory and some advanced calculus is also required."
            },
            "slug": "Statistical-Decision-Theory-and-Bayesian-Analysis-Berger",
            "title": {
                "fragments": [],
                "text": "Statistical Decision Theory and Bayesian Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An overview of statistical decision theory, which emphasizes the use and application of the philosophical ideas and mathematical structure of decision theory."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 24
                            }
                        ],
                        "text": "For example,in BaxterandBartlett (1998)we reportedexperimentsin whichasetof neuralnetwork featureslearntonasubsetof only 400Japanesecharactersturnedout to begoodenoughfor classifyingsome2600unseencharacters, eventhoughthefeaturescontained severalhundredthousandparameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 19
                            }
                        ],
                        "text": "From Theorem 13 in Bartlett (1993), we have VCdim(H 1) dl + l(k 1)2 + 1; which under the restrictions stated above is greater thanW=2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2096,
                                "start": 406
                            }
                        ],
                        "text": "Using the model of the presentpaper , and undersomeextra assumptionson the tasksin the environment(specifically, that their marginal input-spacedistributionsareidenticaland they only differ in theconditionalprobabilitiesthey assignto classlabels),it canbe shown that thereis an optimal metric or distancemeasureto usefor vectorquantizationandonenearest-neighbour classification(Baxter, 1995a,1997b;Baxter& Bartlett,1998).Thismetric canbe learntby samplingfrom a subsetof tasksfrom theenvironment,andthenusedasa distancemeasurewhenlearningnovel tasksdrawn from thesameenvironment. Boundson thenumberof tasksandexamplesof eachtaskrequiredto ensuregoodperformanceonnovel tasksweregiven in BaxterandBartlett (1998),alongwith an experimentin which a metric wassuccessfullytrainedonexamplesof asubsetof 400Japanesecharactersandthenusedas afixeddistancemeasurewhenlearning2600asyet unseencharacters. A similar approachis describedin Thrun and Mitchell (1995),Thrun (1996), in which a neuralnetwork\u2019s outputwastrainedto matchlabelson a novel task,while simultaneously beingforcedto matchits gradientto derivativeinformationgeneratedfrom adistancemetric trainedon previous, relatedtasks. Performanceon the novel tasksimproved substantially with theuseof thederivative information. Notethattherearemany otheradapti vemetrictechniquesusedin machinelearning,but these all focusexclusively onadjustingthemetricfor afixedsetof problemsratherthanlearninga metricsuitablefor learningnovel, relatedtasks(biaslearning). E Feature learning or learning internal representations.As with adapti ve metric techniques, therearemany approachesto featurelearningthatfocuson adaptingfeaturesfor a fixedtask ratherthanlearningfeaturesto beusedin novel tasks.Oneof the few caseswherefeatures have beenlearnton a subsetof taskswith theexplicit aim of usingthemon novel taskswas IntratorandEdelman(1996)in which a low-dimensionalrepresentationwaslearntfor a set of multiple relatedimage-recognitiontasksandthenusedto successfullylearnnovel tasksof the samekind. Theexperimentsreportedin Baxter(1995a,chapter4) andBaxter(1995b), BaxterandBartlett(1998)arealsoof thisnature."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 326,
                                "start": 24
                            }
                        ],
                        "text": "For example,in BaxterandBartlett (1998)we reportedexperimentsin whichasetof neuralnetwork featureslearntonasubsetof only 400Japanesecharactersturnedout to begoodenoughfor classifyingsome2600unseencharacters, eventhoughthefeaturescontained severalhundredthousandparameters. Similar resultsmaybefoundin IntratorandEdelman(1996) and in the experimentsreportedin Thrun (1996) andThrun and Pratt (1997,chapter8)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 952,
                                "start": 406
                            }
                        ],
                        "text": "Using the model of the presentpaper , and undersomeextra assumptionson the tasksin the environment(specifically, that their marginal input-spacedistributionsareidenticaland they only differ in theconditionalprobabilitiesthey assignto classlabels),it canbe shown that thereis an optimal metric or distancemeasureto usefor vectorquantizationandonenearest-neighbour classification(Baxter, 1995a,1997b;Baxter& Bartlett,1998).Thismetric canbe learntby samplingfrom a subsetof tasksfrom theenvironment,andthenusedasa distancemeasurewhenlearningnovel tasksdrawn from thesameenvironment. Boundson thenumberof tasksandexamplesof eachtaskrequiredto ensuregoodperformanceonnovel tasksweregiven in BaxterandBartlett (1998),alongwith an experimentin which a metric wassuccessfullytrainedonexamplesof asubsetof 400Japanesecharactersandthenusedas afixeddistancemeasurewhenlearning2600asyet unseencharacters. A similar approachis describedin Thrun and Mitchell (1995),Thrun (1996), in which a neuralnetwork\u2019s outputwastrainedto matchlabelson a novel task,while simultaneously beingforcedto matchits gradientto derivativeinformationgeneratedfrom adistancemetric trainedon previous, relatedtasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 711,
                                "start": 406
                            }
                        ],
                        "text": "Using the model of the presentpaper , and undersomeextra assumptionson the tasksin the environment(specifically, that their marginal input-spacedistributionsareidenticaland they only differ in theconditionalprobabilitiesthey assignto classlabels),it canbe shown that thereis an optimal metric or distancemeasureto usefor vectorquantizationandonenearest-neighbour classification(Baxter, 1995a,1997b;Baxter& Bartlett,1998).Thismetric canbe learntby samplingfrom a subsetof tasksfrom theenvironment,andthenusedasa distancemeasurewhenlearningnovel tasksdrawn from thesameenvironment. Boundson thenumberof tasksandexamplesof eachtaskrequiredto ensuregoodperformanceonnovel tasksweregiven in BaxterandBartlett (1998),alongwith an experimentin which a metric wassuccessfullytrainedonexamplesof asubsetof 400Japanesecharactersandthenusedas afixeddistancemeasurewhenlearning2600asyet unseencharacters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 16
                            }
                        ],
                        "text": "FromTheorem13in Bartlett(1993), we have \u0083\u0082\u0084\u0086\u0085=\u0087 \u0088 A \u0088 flU K U J :1\u20442\u00a4 \u00c2 K\u009a\u00a43 whichundertherestrictionsstatedabove is greaterthan U N \u00c2 ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1873,
                                "start": 406
                            }
                        ],
                        "text": "Using the model of the presentpaper , and undersomeextra assumptionson the tasksin the environment(specifically, that their marginal input-spacedistributionsareidenticaland they only differ in theconditionalprobabilitiesthey assignto classlabels),it canbe shown that thereis an optimal metric or distancemeasureto usefor vectorquantizationandonenearest-neighbour classification(Baxter, 1995a,1997b;Baxter& Bartlett,1998).Thismetric canbe learntby samplingfrom a subsetof tasksfrom theenvironment,andthenusedasa distancemeasurewhenlearningnovel tasksdrawn from thesameenvironment. Boundson thenumberof tasksandexamplesof eachtaskrequiredto ensuregoodperformanceonnovel tasksweregiven in BaxterandBartlett (1998),alongwith an experimentin which a metric wassuccessfullytrainedonexamplesof asubsetof 400Japanesecharactersandthenusedas afixeddistancemeasurewhenlearning2600asyet unseencharacters. A similar approachis describedin Thrun and Mitchell (1995),Thrun (1996), in which a neuralnetwork\u2019s outputwastrainedto matchlabelson a novel task,while simultaneously beingforcedto matchits gradientto derivativeinformationgeneratedfrom adistancemetric trainedon previous, relatedtasks. Performanceon the novel tasksimproved substantially with theuseof thederivative information. Notethattherearemany otheradapti vemetrictechniquesusedin machinelearning,but these all focusexclusively onadjustingthemetricfor afixedsetof problemsratherthanlearninga metricsuitablefor learningnovel, relatedtasks(biaslearning). E Feature learning or learning internal representations.As with adapti ve metric techniques, therearemany approachesto featurelearningthatfocuson adaptingfeaturesfor a fixedtask ratherthanlearningfeaturesto beusedin novel tasks.Oneof the few caseswherefeatures have beenlearnton a subsetof taskswith theexplicit aim of usingthemon novel taskswas IntratorandEdelman(1996)in which a low-dimensionalrepresentationwaslearntfor a set of multiple relatedimage-recognitiontasksandthenusedto successfullylearnnovel tasksof the samekind."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lower boundson the VC-dimensionof multi-layer thresholdnetworks"
            },
            "venue": {
                "fragments": [],
                "text": "In Proccedingsof the SixthACM Conferenceon ComputationalLearningTheory,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1391,
                                "start": 136
                            }
                        ],
                        "text": "It would be interestingto investigatealternati ve methods, including decisiontreeapproaches, approachesfrom Inductive Logic Programming(Khan et al., 1998),andwhethermoregenerallearningtechniquessuchasboostingcanbeapplied in abiaslearningsetting. E Algorithms for automatically determining the hypothesisspacefamily A . In our model the structureof A is fixed apriori and representsthe hyper-bias of the bias learner . It would beinterestingto seeto whatextentthis structurecanalsobelearnt. E Algorithms for automatically determining task relatedness.In ordinarylearningthereis usually little doubt whetheran individual examplebelongsto the samelearningtask or not. The analogousquestionin biaslearningis whetheran individual learningtaskbelongsto a givensetof relatedtasks,which in contrastto ordinarylearning,doesnot alwayshave such a clear-cut answer . For mostof the exampleswe have discussedhere,suchasspeechand facerecognition,the task-relatedness i not in question,but in othercasessuchasmedical problemsit is notsoclear. Groupingtoo largeasubsetof taskstogetherasrelatedtaskscould clearlyhave a detrimentalimpacton bias-learningor multi-tasklearning,andthereis empricalevidenceto supportthis (Caruana, 1997).Thus,algorithmsfor automaticallydetermining task-relatedness areapotentiallyusefulavenuefor furtherresearch. In thiscontext, seeSilver andMercer(1996),ThrunandO\u2019Sullivan(1996). Notethat thequestionof taskrelatedness is clearlyonly meaningfulrelativeto aparticularhypothesisspacefamily A (for example,all possiblecollectionsof tasksarerelatedif A containsevery possiblehypothesisspace)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 112
                            }
                        ],
                        "text": "It would be interesting to investigate alternative methods, including decision tree approaches, approaches from Inductive Logic Programming (Khan et al., 1998), and whether more general learning techniquess ch as boosting can be applied in a bias learning setting."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 17
                            }
                        ],
                        "text": "Bias learning in Inductive Logic Programming (ILP)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1366,
                                "start": 136
                            }
                        ],
                        "text": "It would be interestingto investigatealternati ve methods, including decisiontreeapproaches, approachesfrom Inductive Logic Programming(Khan et al., 1998),andwhethermoregenerallearningtechniquessuchasboostingcanbeapplied in abiaslearningsetting. E Algorithms for automatically determining the hypothesisspacefamily A . In our model the structureof A is fixed apriori and representsthe hyper-bias of the bias learner . It would beinterestingto seeto whatextentthis structurecanalsobelearnt. E Algorithms for automatically determining task relatedness.In ordinarylearningthereis usually little doubt whetheran individual examplebelongsto the samelearningtask or not. The analogousquestionin biaslearningis whetheran individual learningtaskbelongsto a givensetof relatedtasks,which in contrastto ordinarylearning,doesnot alwayshave such a clear-cut answer . For mostof the exampleswe have discussedhere,suchasspeechand facerecognition,the task-relatedness i not in question,but in othercasessuchasmedical problemsit is notsoclear. Groupingtoo largeasubsetof taskstogetherasrelatedtaskscould clearlyhave a detrimentalimpacton bias-learningor multi-tasklearning,andthereis empricalevidenceto supportthis (Caruana, 1997).Thus,algorithmsfor automaticallydetermining task-relatedness areapotentiallyusefulavenuefor furtherresearch. In thiscontext, seeSilver andMercer(1996),ThrunandO\u2019Sullivan(1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 229
                            }
                        ],
                        "text": "Often the hardestproblemin any machinelearningtaskis the initial choiceof hypothesisspace; it hasto be large enoughto containa solutionto theproblemat hand,yet smallenoughto ensure goodgeneralizationfrom a small numberof examples(Mitchell, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The needfor biasesin learninggeneralisations.In Dietterich,T"
            },
            "venue": {
                "fragments": [],
                "text": "J. (Eds.),Readingsin MachineLearning. MorganKaufmann"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 159
                            }
                        ],
                        "text": "The bound onm in Theorem 8 states thatmn should beO(nk +W ), or proportional to the total number of parameters in the network, a result we would expect from6 (Haussler, 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 216
                            }
                        ],
                        "text": "In this paper we introduce and analyze a formal model ofbias learning that builds upon the PAC model of machine learning and its variants (Vapnik, 1982; Valiant, 1984; Blumer, Ehrenfeucht, Haussler, & Warmuth, 1989; Haussler, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 139
                            }
                        ],
                        "text": "In this paper we introduce and analyze a formal model of bias learning that builds upon the PAC model of machine learning and its variants (Vapnik, 1 982; Valiant, 1984; Blumer, Ehrenfeucht, Haussler, & Warmuth, 1989; Haussler, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 162
                            }
                        ],
                        "text": "The bound on m in Theorem 8 states that mn should be O(nk +W ), or proportional to the total number of parameters in the net work, a result we would expect from6 (Haussler, 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 111
                            }
                        ],
                        "text": "Equations (73) and (74) imply C(\";Gl) C \" 2 ;G; L1 (75) CGl (\";F) C \" 2b ;F ; L1 (76) Applying Theorem 11 from Haussler (1992), we find C \" 2 ;Gl; L1 2eb \" 2k+2 C \" 2b ;F ; L1 2eb2 \" 2W : Substituting these two expressions into (75) and (76) and ap plying Theorem 6 yields Theorem 7."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 63
                            }
                        ],
                        "text": "I have also borrowed some ideas from the proof of Theorem 3 in Haussler (1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 43
                            }
                        ],
                        "text": "To obtain a more general result, we follow Haussler (1992) and introduce the following parameterized class of metrics onR+ :d [x; y\u2104 := jx yjx+ y + ; where > 0."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 107
                            }
                        ],
                        "text": "Equations (73) and (74) implyC(\";Gl) C \"2 ;G; L1 (75)CGl (\";F) C \"2b ;F ; L1 (76) Applying Theorem 11 from Haussler (1992), we findC \"2 ;Gl; L1 2eb\" 2k+2C \"2b ;F ; L1 2eb2\" 2W : Substituting these two expressions into (75) and (76) and applying Theorem 6 yields Theorem 7."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 43
                            }
                        ],
                        "text": "To obtain a more general result, we follow Haussler (1992) a nd introduce the following parameterized class of metrics on R+ : d [x; y\u2104 := jx yj x+ y + ; where > 0."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Decision theoretic generalizations o"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1101,
                                "start": 64
                            }
                        ],
                        "text": "Preliminaryresultswith thisapproachonachessdomainarereported in Khan,Muggleton,andParson(1998). E Impr oving performanceon a fixed referencetask. \u201cMulti-task learning\u201d (Caruana, 1997) trainsextra neuralnetwork outputsto matchrelatedtasksin orderto improve generalization performanceonafixedreferencetask.Althoughthisapproachdoesnotexplicitly identify the extra biasgeneratedby the relatedtasksin a way thatcanbeusedto learnnovel tasks,it is anexampleof exploiting thebiasprovidedby asetof relatedtasksto improve generalization performance. Othersimilarapproaches includeSuddarthandKergosien(1990),Suddarthand Holden(1991),Abu-Mostafa (1993). E Bias ascomputational complexity. In this paperwe considerinductive bias from a samplecomplexity perspecti ve: how doesthelearntbiasdecreasethenumberof examplesrequiredof novel tasksfor goodgeneralization?A naturalalternati ve line of enquiryis how therunningtime or computationalcomplexity of a learningalgorithmmay be improved by training on relatedtasks.Someearlyalgorithmsfor neuralnetworksin thisveinarecontainedin Sharkey andSharkey (1993),Pratt(1992). E ReinforcementLearning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1500,
                                "start": 64
                            }
                        ],
                        "text": "Preliminaryresultswith thisapproachonachessdomainarereported in Khan,Muggleton,andParson(1998). E Impr oving performanceon a fixed referencetask. \u201cMulti-task learning\u201d (Caruana, 1997) trainsextra neuralnetwork outputsto matchrelatedtasksin orderto improve generalization performanceonafixedreferencetask.Althoughthisapproachdoesnotexplicitly identify the extra biasgeneratedby the relatedtasksin a way thatcanbeusedto learnnovel tasks,it is anexampleof exploiting thebiasprovidedby asetof relatedtasksto improve generalization performance. Othersimilarapproaches includeSuddarthandKergosien(1990),Suddarthand Holden(1991),Abu-Mostafa (1993). E Bias ascomputational complexity. In this paperwe considerinductive bias from a samplecomplexity perspecti ve: how doesthelearntbiasdecreasethenumberof examplesrequiredof novel tasksfor goodgeneralization?A naturalalternati ve line of enquiryis how therunningtime or computationalcomplexity of a learningalgorithmmay be improved by training on relatedtasks.Someearlyalgorithmsfor neuralnetworksin thisveinarecontainedin Sharkey andSharkey (1993),Pratt(1992). E ReinforcementLearning. Many control taskscanappropriatelybe viewed aselementsof sets of relatedtasks,suchas learningto navigate to different goal states,or learninga set of complex motor control tasks. A numberof papersin the reinforcementlearningliterature haveproposedalgorithmsfor bothsharingtheinformationin relatedtasksto improveaverage generalizationperformanceacrossthosetasksSingh (1992),Ring (1995),or learningbias from asetof tasksto improveperformanceonfuturetasksSutton(1992),ThrunandSchwartz (1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 641,
                                "start": 64
                            }
                        ],
                        "text": "Preliminaryresultswith thisapproachonachessdomainarereported in Khan,Muggleton,andParson(1998). E Impr oving performanceon a fixed referencetask. \u201cMulti-task learning\u201d (Caruana, 1997) trainsextra neuralnetwork outputsto matchrelatedtasksin orderto improve generalization performanceonafixedreferencetask.Althoughthisapproachdoesnotexplicitly identify the extra biasgeneratedby the relatedtasksin a way thatcanbeusedto learnnovel tasks,it is anexampleof exploiting thebiasprovidedby asetof relatedtasksto improve generalization performance. Othersimilarapproaches includeSuddarthandKergosien(1990),Suddarthand Holden(1991),Abu-Mostafa (1993). E Bias ascomputational complexity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1089,
                                "start": 64
                            }
                        ],
                        "text": "Preliminaryresultswith thisapproachonachessdomainarereported in Khan,Muggleton,andParson(1998). E Impr oving performanceon a fixed referencetask. \u201cMulti-task learning\u201d (Caruana, 1997) trainsextra neuralnetwork outputsto matchrelatedtasksin orderto improve generalization performanceonafixedreferencetask.Althoughthisapproachdoesnotexplicitly identify the extra biasgeneratedby the relatedtasksin a way thatcanbeusedto learnnovel tasks,it is anexampleof exploiting thebiasprovidedby asetof relatedtasksto improve generalization performance. Othersimilarapproaches includeSuddarthandKergosien(1990),Suddarthand Holden(1991),Abu-Mostafa (1993). E Bias ascomputational complexity. In this paperwe considerinductive bias from a samplecomplexity perspecti ve: how doesthelearntbiasdecreasethenumberof examplesrequiredof novel tasksfor goodgeneralization?A naturalalternati ve line of enquiryis how therunningtime or computationalcomplexity of a learningalgorithmmay be improved by training on relatedtasks.Someearlyalgorithmsfor neuralnetworksin thisveinarecontainedin Sharkey andSharkey (1993),Pratt(1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 64
                            }
                        ],
                        "text": "Preliminaryresultswith thisapproachonachessdomainarereported in Khan,Muggleton,andParson(1998). E Impr oving performanceon a fixed referencetask."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 597,
                                "start": 64
                            }
                        ],
                        "text": "Preliminaryresultswith thisapproachonachessdomainarereported in Khan,Muggleton,andParson(1998). E Impr oving performanceon a fixed referencetask. \u201cMulti-task learning\u201d (Caruana, 1997) trainsextra neuralnetwork outputsto matchrelatedtasksin orderto improve generalization performanceonafixedreferencetask.Althoughthisapproachdoesnotexplicitly identify the extra biasgeneratedby the relatedtasksin a way thatcanbeusedto learnnovel tasks,it is anexampleof exploiting thebiasprovidedby asetof relatedtasksto improve generalization performance. Othersimilarapproaches includeSuddarthandKergosien(1990),Suddarthand Holden(1991),Abu-Mostafa (1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1967).Probabiliity Measureson Metric Spaces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 139
                            }
                        ],
                        "text": "For Boolean learning problems (pattern classification) these parameters are the bias learning analogue of theVapnik-Chervonenkis dimension(Vapnik, 1982; Blumer et al., 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 139
                            }
                        ],
                        "text": "In this paper we introduce and analyze a formal model ofbias learning that builds upon the PAC model of machine learning and its variants (Vapnik, 1982; Valiant, 1984; Blumer, Ehrenfeucht, Haussler, & Warmuth, 1989; Haussler, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 261
                            }
                        ],
                        "text": "\u2026is controlledby the size of certain covering numbers associated with the set of all hypothesis spaces available to the bias learner, in much the same way as the sample complexity in learning Boolean functions is controlled by theVapnik-Chervonenkis dimension (Vapnik, 1982; Blumer et al., 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 180
                            }
                        ],
                        "text": "Then with probability at least1 \u00c6 (over the choice of the training setz), allh 2 H will satisfy erP (h) e\u0302rz(h) + 32m d log 2emd + log 4\u00c6 1=2 (5)\nProofs of this result may be found in Vapnik (1982), Blumer etal."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59746611,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "78ecaabe915ba7df950671d36f92678192802df4",
            "isKey": true,
            "numCitedBy": 516,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Estimation-of-Dependences-Based-on-Empirical-Data:-Vapnik",
            "title": {
                "fragments": [],
                "text": "Estimation of Dependences Based on Empirical Data: Springer Series in Statistics (Springer Series in Statistics)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 121
                            }
                        ],
                        "text": "Bounds on the number of tasks and examples of each task required to ensure good performance on novel tasks were given in Baxter and Bartlett (1998), along with anexperiment in which a metric was successfully trained on examples of a subset of 400 Japanese characters and then used as a fixed\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 274
                            }
                        ],
                        "text": "\u2026distributions are identical and they only differ in the conditional probabilities they assign to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization and onenearest-neighbour classification (Baxter, 1995a, 1997b; Baxter & Bartlett, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 74
                            }
                        ],
                        "text": "The experiments reported in Baxter (1995a, chapter 4) and Baxter (1995b), Baxter and Bartlett (1998) are also of this nature."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 16
                            }
                        ],
                        "text": "For example, in Baxter and Bartlett (1998) we reported experiments in which a set of neural network features learnt on a subset of only 400 Japanese characters turned out to be good enough for classifying some 2600 unseen characters, even though the features contained several hundred thousand\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 101
                            }
                        ],
                        "text": "Once the feature map is learnt (which can be achieved usingthe techniques outlined in Baxter, 1995b; Baxter & Bartlett, 1998; Baxter, 1995a, chapter 4), only the output weights have to be estimated to learn a novel task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The canonical distorti"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 19
                            }
                        ],
                        "text": "From Theorem 13 in Bartlett (1993), we have VCdim(H 1) dl + l(k 1)2 + 1; which under the restrictions stated above is greater thanW=2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 782,
                                "start": 437
                            }
                        ],
                        "text": "Using the model of the present paper, and under some extra ass umptions on the tasks in the environment (specifically, that their marginal input-s pace distributions are identical and they only differ in the conditional probabilities they assi gn to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization an d onenearest-neighbour classification (Baxter, 1995a, 1997b; B axter & Bartlett, 1998). This metric can be learnt by sampling from a subset of tasks from the envir o ment, and then used as a distance measure when learning novel tasks drawn from the sa m environment. Bounds on the number of tasks and examples of each task required to ensu re good performance on novel tasks were given in Baxter and Bartlett (1998), along with an experiment in which a metric was successfully trained on examples of a subset of 400 Japan ese characters and then used as a fixed distance measure when learning 2600 as yet unseen char acters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 370,
                                "start": 27
                            }
                        ],
                        "text": "For example, in Baxter and Bartlett (1 998) we reported experiments in which a set of neural network features learnt on a subset of on ly 400 Japanese characters turned out to be good enough for classifying some 2600 unseen character s, even though the features contained several hundred thousand parameters. Similar results may b e found in Intrator and Edelman (1996) and in the experiments reported in Thrun (1996) and Thrun and Pratt (1997, chapter 8)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1052,
                                "start": 437
                            }
                        ],
                        "text": "Using the model of the present paper, and under some extra ass umptions on the tasks in the environment (specifically, that their marginal input-s pace distributions are identical and they only differ in the conditional probabilities they assi gn to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization an d onenearest-neighbour classification (Baxter, 1995a, 1997b; B axter & Bartlett, 1998). This metric can be learnt by sampling from a subset of tasks from the envir o ment, and then used as a distance measure when learning novel tasks drawn from the sa m environment. Bounds on the number of tasks and examples of each task required to ensu re good performance on novel tasks were given in Baxter and Bartlett (1998), along with an experiment in which a metric was successfully trained on examples of a subset of 400 Japan ese characters and then used as a fixed distance measure when learning 2600 as yet unseen char acters. A similar approach is described in Thrun and Mitchell (1995) , Thrun (1996), in which a neural network\u2019s output was trained to match labels on a nove l task, while simultaneously being forced to match its gradient to derivativeinformation generated from a distance metric trained on previous, related tasks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 20
                            }
                        ],
                        "text": "F rom Theorem 13 in Bartlett (1993), we have VCdim(H 1) dl + l(k 1) 2 + 1; which under the restrictions stated above is greater than W=2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 94
                            }
                        ],
                        "text": "Proof of Theorem 14 This proof follows a similar argument to the one presented in Anthony and Bartlett (1999) for ordinary Boolean function learning."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2061,
                                "start": 437
                            }
                        ],
                        "text": "Using the model of the present paper, and under some extra ass umptions on the tasks in the environment (specifically, that their marginal input-s pace distributions are identical and they only differ in the conditional probabilities they assi gn to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization an d onenearest-neighbour classification (Baxter, 1995a, 1997b; B axter & Bartlett, 1998). This metric can be learnt by sampling from a subset of tasks from the envir o ment, and then used as a distance measure when learning novel tasks drawn from the sa m environment. Bounds on the number of tasks and examples of each task required to ensu re good performance on novel tasks were given in Baxter and Bartlett (1998), along with an experiment in which a metric was successfully trained on examples of a subset of 400 Japan ese characters and then used as a fixed distance measure when learning 2600 as yet unseen char acters. A similar approach is described in Thrun and Mitchell (1995) , Thrun (1996), in which a neural network\u2019s output was trained to match labels on a nove l task, while simultaneously being forced to match its gradient to derivativeinformation generated from a distance metric trained on previous, related tasks. Performance on the nove l tasks improved substantially with the use of the derivative information. Note that there are many other adaptive metric techniques us d in machine learning, but these all focus exclusively on adjusting the metric for a fixed set o f pr blems rather than learning a metric suitable for learning novel, related tasks (bias lea rning). Feature learning or learning internal representations. As with adaptive metric techniques, there are many approaches to feature learning that focus on a dapting features for a fixed task rather than learning features to be used in novel tasks. One o f the few cases where features have been learnt on a subset of tasks with the explicit aim of u sing them on novel tasks was Intrator and Edelman (1996) in which a low-dimensional repr esentation was learnt for a set of multiple related image-recognition tasks and then used t o successfully learn novel tasks of the same kind."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2310,
                                "start": 437
                            }
                        ],
                        "text": "Using the model of the present paper, and under some extra ass umptions on the tasks in the environment (specifically, that their marginal input-s pace distributions are identical and they only differ in the conditional probabilities they assi gn to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization an d onenearest-neighbour classification (Baxter, 1995a, 1997b; B axter & Bartlett, 1998). This metric can be learnt by sampling from a subset of tasks from the envir o ment, and then used as a distance measure when learning novel tasks drawn from the sa m environment. Bounds on the number of tasks and examples of each task required to ensu re good performance on novel tasks were given in Baxter and Bartlett (1998), along with an experiment in which a metric was successfully trained on examples of a subset of 400 Japan ese characters and then used as a fixed distance measure when learning 2600 as yet unseen char acters. A similar approach is described in Thrun and Mitchell (1995) , Thrun (1996), in which a neural network\u2019s output was trained to match labels on a nove l task, while simultaneously being forced to match its gradient to derivativeinformation generated from a distance metric trained on previous, related tasks. Performance on the nove l tasks improved substantially with the use of the derivative information. Note that there are many other adaptive metric techniques us d in machine learning, but these all focus exclusively on adjusting the metric for a fixed set o f pr blems rather than learning a metric suitable for learning novel, related tasks (bias lea rning). Feature learning or learning internal representations. As with adaptive metric techniques, there are many approaches to feature learning that focus on a dapting features for a fixed task rather than learning features to be used in novel tasks. One o f the few cases where features have been learnt on a subset of tasks with the explicit aim of u sing them on novel tasks was Intrator and Edelman (1996) in which a low-dimensional repr esentation was learnt for a set of multiple related image-recognition tasks and then used t o successfully learn novel tasks of the same kind. The experiments reported in Baxter (1995a, ch apter 4) and Baxter (1995b), Baxter and Bartlett (1998) are also of this nature."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lower bounds on the VC-dimension of m"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 70
                            }
                        ],
                        "text": "His definition is very similar to Dudley\u2019s \u201cimage admissibl e Suslin\u201d (Dudley, 1984)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 625,
                                "start": 34
                            }
                        ],
                        "text": "His definition is very similar to Dudley\u2019s \u201cimage admissibl e Suslin\u201d (Dudley, 1984). We will be extending this definition to cover hypothesis space families. Throughout this section we assume all functions h map from (the complete separable metric space)Z into [0; 1\u2104. LetB(T ) denote the Borel -algebra of any topological space T . As in Section 2.2, we viewP, the set of all probability measures on Z, as a topological space by equipping it with the topology of weak convergence. B(P) is then the -algebra generated by this topology. The following two definitions are taken (with minor modification s) from Pollard (1984). Definition 8."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1984).A Course on Empirical Processes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 103
                            }
                        ],
                        "text": "Thus, H (n;m) emnd+ 1 l(d+1) emnl + 1 k(l+1) emnn(k + 1) n(k+1) :f(x) := x log x is a convex function, hence for alla; b; > 0,f ka+ lb+ k + l + 1 1k + l + 1 (kf(a) + lf(b) + f( ))) k + l + 1ka+ lb+ ka+lb+ 1a ka 1b lb 1 : Substitutinga = l + 1, b = d+ 1 and = n(k + 1) shows that H (n;m) emn(k + l +\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 275
                            }
                        ],
                        "text": "\u2026is controlledby the size of certain covering numbers associated with the set of all hypothesis spaces available to the bias learner, in much the same way as the sample complexity in learning Boolean functions is controlled by theVapnik-Chervonenkis dimension (Vapnik, 1982; Blumer et al., 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 32
                            }
                        ],
                        "text": "BAXTER\nIn general a set of \u201cstrong features\u201d may be viewed as a functio f : X !"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 14
                            }
                        ],
                        "text": "Based on the information contained inz, the learner\u2019s goal is to select a hypothesish : X !"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 153
                            }
                        ],
                        "text": "For Boolean learning problems (pattern classification) these parameters are the bias learning analogue of theVapnik-Chervonenkis dimension(Vapnik, 1982; Blumer et al., 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learnability and the vapnikchervonenkis dimension"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the ACM"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 625,
                                "start": 34
                            }
                        ],
                        "text": "His definition is very similar to Dudley\u2019s \u201cimage admissibl e Suslin\u201d (Dudley, 1984). We will be extending this definition to cover hypothesis space families. Throughout this section we assume all functions h map from (the complete separable metric space)Z into [0; 1\u2104. LetB(T ) denote the Borel -algebra of any topological space T . As in Section 2.2, we viewP, the set of all probability measures on Z, as a topological space by equipping it with the topology of weak convergence. B(P) is then the -algebra generated by this topology. The following two definitions are taken (with minor modification s) from Pollard (1984). Definition 8."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1989).Real Analysis and Probability"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 93
                            }
                        ],
                        "text": "If eachexamplecanbeclassifiedwith a\u201clargemargin\u201d thennaiveparameter countingcanbeimprovedupon(Bartlett, 1998)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 132
                            }
                        ],
                        "text": "Bounds on the number of tasks and examples of each task required to ensure good performance on novel tasks were given in Baxter and Bartlett (1998), along with anexperiment in which a metric was successfully trained on examples of a subset of 400 Japanese characters and then used as a fixed\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 283
                            }
                        ],
                        "text": "\u2026distributions are identical and they only differ in the conditional probabilities they assign to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization and onenearest-neighbour classification (Baxter, 1995a, 1997b; Baxter & Bartlett, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 85
                            }
                        ],
                        "text": "The experiments reported in Baxter (1995a, chapter 4) and Baxter (1995b), Baxter and Bartlett (1998) are also of this nature."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 27
                            }
                        ],
                        "text": "For example, in Baxter and Bartlett (1998) we reported experiments in which a set of neural network features learnt on a subset of only 400 Japanese characters turned out to be good enough for classifying some 2600 unseen characters, even though the features contained several hundred thousand\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 110
                            }
                        ],
                        "text": "Once the feature map is learnt (which can be achieved usingthe techniques outlined in Baxter, 1995b; Baxter & Bartlett, 1998; Baxter, 1995a, chapter 4), only the output weights have to be estimated to learn a novel task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 105
                            }
                        ],
                        "text": "If each example can be classified with a \u201clarge margin\u201d thennaive parameter counting can be improved upon (Bartlett, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The samplecomplexity of patternclassificationwith neuralnetworks: the sizeof the weightsis moreimportantthanthe sizeof the network"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactionson InformationTheory, 44(2), 525\u2013536."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 252
                            }
                        ],
                        "text": "\u2026distributions are identical and they only differ in the conditional probabilities they assign to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization and onenearest-neighbour classification (Baxter, 1995a, 1997b; Baxter & Bartlett, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 58
                            }
                        ],
                        "text": "The experiments reported in Baxter (1995a, chapter 4) and Baxter (1995b), Baxter and Bartlett (1998) are also of this nature."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 21
                            }
                        ],
                        "text": "For more details see Baxter (1995b) and Baxter (1995a, chapter 4), where empirical results supporting the theoretical results presented here are also given."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 86
                            }
                        ],
                        "text": "Once the feature map is learnt (which can be achieved usingthe techniques outlined in Baxter, 1995b; Baxter & Bartlett, 1998; Baxter, 1995a, chapter 4), only the output weights have to be estimated to learn a novel task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Internal Representations Department of Mathematics and Statistics, The Flinders University of South Australia"
            },
            "venue": {
                "fragments": [],
                "text": "Learning Internal Representations Department of Mathematics and Statistics, The Flinders University of South Australia"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 69
                            }
                        ],
                        "text": "His definition is very similar to Dudley\u2019s \u201cimage admissible Suslin\u201d (Dudley, 1984)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 600,
                                "start": 34
                            }
                        ],
                        "text": "His definition is very similar to Dudley\u2019s \u201cimage admissible Suslin\u201d (Dudley, 1984).Wewill beextendingthisdefinitionto cover hypothesisspacefamilies. Throughoutthis sectionwe assumeall functions \u00f1 mapfrom (the completeseparablemetric space)\u00fc into \u00cd \u00ddj\u00cf\u00e4\u00e5}\u00d2 . Let Y \u00c5 \u00b0\u00c6 denotetheBorel ~ -algebraof any topologicalspace . As in Section 2.2, we view \u00bf , the setof all probability measureson \u00fc , asa topologicalspaceby equippingit with thetopologyof weakconvergence.Y \u00c5 \u00bf \u00c6 is thenthe ~ -algebrageneratedby thistopology. The following two definitionsaretaken(with minor modifications)from Pollard(1984). Definition 8."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1984).A Courseon EmpiricalProcesses"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 121
                            }
                        ],
                        "text": "Bounds on the number of tasks and examples of each task required to ensure good performance on novel tasks were given in Baxter and Bartlett (1998), along with anexperiment in which a metric was successfully trained on examples of a subset of 400 Japanese characters and then used as a fixed\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 274
                            }
                        ],
                        "text": "\u2026distributions are identical and they only differ in the conditional probabilities they assign to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization and onenearest-neighbour classification (Baxter, 1995a, 1997b; Baxter & Bartlett, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 74
                            }
                        ],
                        "text": "The experiments reported in Baxter (1995a, chapter 4) and Baxter (1995b), Baxter and Bartlett (1998) are also of this nature."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 16
                            }
                        ],
                        "text": "For example, in Baxter and Bartlett (1998) we reported experiments in which a set of neural network features learnt on a subset of only 400 Japanese characters turned out to be good enough for classifying some 2600 unseen characters, even though the features contained several hundred thousand\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 101
                            }
                        ],
                        "text": "Once the feature map is learnt (which can be achieved usingthe techniques outlined in Baxter, 1995b; Baxter & Bartlett, 1998; Baxter, 1995a, chapter 4), only the output weights have to be estimated to learn a novel task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The canonicaldistortionmeasurein featurespaceand1-NN classification.In Advancesin Neural InformationProcessingSystems10"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000820"
                        ],
                        "name": "E. Slud",
                        "slug": "E.-Slud",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Slud",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Slud"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ") 6 =  1 2 Pr  N m  + 1 2 Pr  N (  ) &lt; m  = &gt; 1 2 Pr  N (  )  m  = which is half the probability that a binomial ( m; 1 = 2 = 2) random variable is at least m= . By Slud\u2019s inequality (Slud, 1977), Pr ( f (  ) 6 = &gt; 1 2 Pr ! Z  s m 2 1 2 where Z is normal (0 ; 1) . Tate\u2019s inequality (Tate, 1953) states that for all x  0 , Pr ( Z  x ) 1 2 h 1 p e x 2 i : Combining the last two inequaliti"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 21
                            }
                        ],
                        "text": "By Slud\u2019s inequality (Slud, 1977),Pr (f( ) 6= ) > 12 Pr Z s m 21 2! whereZ is normal(0; 1)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 120792465,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "97df7de2caa03d74b142a1ceb24157d3fe39e155",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Distribution-Inequalities-for-the-Binomial-Law-Slud",
            "title": {
                "fragments": [],
                "text": "Distribution Inequalities for the Binomial Law"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "96111862"
                        ],
                        "name": "R. Tate",
                        "slug": "R.-Tate",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tate",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tate"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 18
                            }
                        ],
                        "text": "Tate\u2019s inequality (Tate, 1953) states that for all x 0, Pr (Z x) 12 h1 p1 e x2i : Combining the last two inequalities completes the proof."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 18
                            }
                        ],
                        "text": "Tate\u2019s inequality (Tate, 1953) states that for allx 0,Pr (Z x) 12 h1 p1 e x2i : Combining the last two inequalities completes the proof."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120239414,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "07d65f4ae5f5b24cdc7af80304830347744ad7be",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-a-Double-Inequality-of-the-Normal-Distribution-Tate",
            "title": {
                "fragments": [],
                "text": "On a Double Inequality of the Normal Distribution"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1953
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881615"
                        ],
                        "name": "R. Dudley",
                        "slug": "R.-Dudley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dudley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dudley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ssibility\u201d on the hypothesis space family H . Permissibility was introduced by Pollard (1984) for ordinary hypothesis classes H . His de\ufb01nition is very similar to Dudley\u2019s \u201cimage admissibl e Suslin\u201d (Dudley, 1984). We will be extending this de\ufb01nition to cover hypothesis space families. Throughout this section we assume all functions h map from (the complete separable metric space) Z into [0 ; 1] . Let B ( T ) "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120994616,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3e211ab5f8fe33612149727fb3e5b1ad4af65d34",
            "isKey": false,
            "numCitedBy": 396,
            "numCiting": 97,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-course-on-empirical-processes-Dudley",
            "title": {
                "fragments": [],
                "text": "A course on empirical processes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145004630"
                        ],
                        "name": "M. Anthony",
                        "slug": "M.-Anthony",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Anthony",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Anthony"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61068933,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c69ec28c04f0bd283ccd1b09263274016731197",
            "isKey": false,
            "numCitedBy": 252,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-in-Neural-Networks:-Theoretical-Anthony-Bartlett",
            "title": {
                "fragments": [],
                "text": "Learning in Neural Networks: Theoretical Foundations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67186920"
                        ],
                        "name": "S. Russell",
                        "slug": "S.-Russell",
                        "structuredName": {
                            "firstName": "Sturart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Russell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ment of analogous tasks\u201d in the sense that conclusions about one task can be arrived at by analogy with (suf\ufb01ciently many of) the other tasks. For an early disc ussion of analogy in this context, see Russell (1989, S4.3), in particular the observation that for analogous problems the sampling burden per task can be reduced.  Metric-based approaches. The metric used in nearest-neighbour classi\ufb01cation, and in ve"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57444035,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "75b8e27a12cb001afb8b2b2f853dee09d93c84d5",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-use-of-knowledge-in-analogy-and-induction-Russell",
            "title": {
                "fragments": [],
                "text": "The use of knowledge in analogy and induction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 21
                            }
                        ],
                        "text": "In this context, see Silver and Mercer (1996), Thrun and O\u2019Sullivan (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The parallel transfer"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 270
                            }
                        ],
                        "text": "\u2026literature have proposed algorithms for both sharing the information in related tasks to improve average generalization performance across those tasks Singh (1992), Ring (1995), or learning bias from a set of tasks to improve performance on future tasks Sutton (1992), Thrun and Schwartz (1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Finding structurein reinforcementlearning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 252
                            }
                        ],
                        "text": "\u2026distributions are identical and they only differ in the conditional probabilities they assign to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization and onenearest-neighbour classification (Baxter, 1995a, 1997b; Baxter & Bartlett, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 106
                            }
                        ],
                        "text": "However, a model using a mixture of hierarchical Bayesian and information-theoretic ideaswas presented in Baxter (1997a), with similar conclusions to those found here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Bayesian/informationtheoreticmodelof learningto learnvia multiple task sampling.MachineLearning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 32
                            }
                        ],
                        "text": "Similar results may be found in Intrator and Edelman (1996) and in the experiments reported in Thrun (1996) and Thrun andPratt (1997, chapter 8)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 129
                            }
                        ],
                        "text": "One of the few cases where features have been learnt on a subset of tasks with the explicit aim of using them on novel tasks was Intrator and Edelman (1996) in which a low-dimensional representation was learnt for a set of multiple related image-recognition tasks and then used to successfully learn\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "How to make a low-dimensi"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 33
                            }
                        ],
                        "text": "Other similar approaches include Suddarth and Kergosien (1990), Suddarth and Holden (1991), Abu-Mostafa (1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rule-injectionhints as a meansof improving network performanceandlearningtime"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedingsof theEURASIPWorkshopon Neural NetworksPortugal.EURASIP"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 80
                            }
                        ],
                        "text": "For an extension of our two-level approach to arbitrarily deep hierarchies, see Langford (1999)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Staged learning. Tech. rep., CMU, School of Computer Science"
            },
            "venue": {
                "fragments": [],
                "text": "Staged learning. Tech. rep., CMU, School of Computer Science"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 34
                            }
                        ],
                        "text": "Consider the following quote from Vapnik (1996):\nThe classical approach to estimating multidimensional functio al dependencies is based on the following belief:\nReal-life problems are such that there exists a small numberof \u201cstrong features,\u201d simple functions of which (say linear combinations)\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1996).The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 99
                            }
                        ],
                        "text": "Some early algorithms for neural networks inthis vein are contained in Sharkey and Sharkey (1993), Pratt (1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminability-based transfer betw"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 64
                            }
                        ],
                        "text": "Other similar approaches include Suddarth and Kergosien (1990), Suddarth and Holden (1991), Abu-Mostafa (1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Symolic-neuralsystemsandtheuseof hints in developingcomplex"
            },
            "venue": {
                "fragments": [],
                "text": "systems.InternationalJournal of Man-MachineStudies,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 71
                            }
                        ],
                        "text": "Some early algorithms for neural networks inthis vein are contained in Sharkey and Sharkey (1993), Pratt (1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adaptive generalisation and the transfer of knowledge"
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence Review"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 21
                            }
                        ],
                        "text": "By Slud\u2019s inequality (Slud, 1977),Pr (f( ) 6= ) > 12 Pr Z s m 21 2! whereZ is normal(0; 1)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 21
                            }
                        ],
                        "text": "By Slud\u2019s inequality (Slud, 1977), Pr (f( ) 6= ) > 12 Pr Z s m 2 1 2! whereZ is normal(0; 1)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distribution inequalities for the binomia"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 82
                            }
                        ],
                        "text": "Proof of Theorem 14 This proof follows a similar argument to the one presented in Anthony and Bartlett (1999) for ordinary Boolean function learning."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1999).Neural Network Learning: Theoretical Foundations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Bayesian/information theoretic mode"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 47
                            }
                        ],
                        "text": "In this context, see Silver and Mercer (1996), Thrun and O\u2019Sullivan (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discovering structurein multiple learningtasks:The TC algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "In Saitta,L. (Ed.), Proceedingsof the 13th InternationalConferenceon Machine Learning(ICML"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 80
                            }
                        ],
                        "text": "Proof of Theorem 14 This proof follows a similar argumentto the one presentedin Anthony and Bartlett (1999) for ordinaryBooleanfunctionlearning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural NetworkLearning: Theoretical Foundations. CambridgeUniversityPress,Cambridge,UK"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 86
                            }
                        ],
                        "text": "Theearliestapproachesto biaslearningcomefrom HierarchicalBayesian methodsin statistics(Berger, 1985; Good,1980; Gelman,Carlin, Stern,& Rubim, 1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 96
                            }
                        ],
                        "text": "The earliest approaches to bias learning come from Hierarchical Bayesian\nmethods in statistics (Berger, 1985; Good, 1980; Gelman, Carlin, Stern, & Rubim, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "StatisticalDecisionTheoryand BayesianAnalysis"
            },
            "venue": {
                "fragments": [],
                "text": "Springer"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 252
                            }
                        ],
                        "text": "\u2026distributions are identical and they only differ in the conditional probabilities they assign to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization and onenearest-neighbour classification (Baxter, 1995a, 1997b; Baxter & Bartlett, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 106
                            }
                        ],
                        "text": "However, a model using a mixture of hierarchical Bayesian and information-theoretic ideaswas presented in Baxter (1997a), with similar conclusions to those found here."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Bayesian/information theoretic mode"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 80
                            }
                        ],
                        "text": "For an extension of our two-level approach to arbitrarily deep hierarchies, see Langford (1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 81
                            }
                        ],
                        "text": "For an extension of our two-level approach to arbitrarily de ep hierarchies, see Langford (1999). An interesting further question is to w hat extent the hierarchy can be inferred from data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Staged learning"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. rep., CMU, Sc"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 32
                            }
                        ],
                        "text": "\u201cSTABB\u201d or ShiftTo a BetterBias (Utgoff, 1986)wasanotherearlyschemefor adjustingbias,but unlike VBMS, STABB wasnot primarily focussedon searchingfor biasapplicableto largeproblemdomains."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 31
                            }
                        ],
                        "text": "\u201cSTABB\u201d orShift To a Better Bias(Utgoff, 1986) was another early scheme for adjusting bias, butunlike VBMS, STABB was not primarily focussed on searching for bias applicable to large problem domains."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1986).Shift of biasfor inductiveconceptlearning.In MachineLearning:AnArtificial IntelligenceApproach, pp.107\u2013147.MorganKaufmann"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 18
                            }
                        ],
                        "text": "Tate\u2019s inequality (Tate, 1953) states that for allx 0,Pr (Z x) 12 h1 p1 e x2i : Combining the last two inequalities completes the proof."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On a doubleinequality of the normal distribution"
            },
            "venue": {
                "fragments": [],
                "text": "Annalsof Mathematical Statistics,"
            },
            "year": 1953
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 21
                            }
                        ],
                        "text": "In this context, see Silver and Mercer (1996), Thrun and O\u2019Sullivan (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The parallel transferof task knowledgeusing dynamic learningratesbasedon ameasureof relatedness"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 19
                            }
                        ],
                        "text": "From Theorem 13 in Bartlett (1993), we have VCdim(H 1) dl + l(k 1)2 + 1; which under the restrictions stated above is greater thanW=2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lower bounds on the VC-dimension of multi-layer threshold networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proccedings of the Sixth ACM Conference on Computational Learning Theory Summary appeared in Neural Computation"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 3
                            }
                        ],
                        "text": "In Rendell, Seshu, and Tcheng (1987) \u201cVBMS\u201d orVariable Bias Management Systemwas introduced as a mechanism for selecting amongst different learning algorithms when tackling a new learning problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Layeredconceptlearninganddynamically-variable biasmanagement.In Proceedingsof the TenthInternationalJoint"
            },
            "venue": {
                "fragments": [],
                "text": "Conferenceon Artificial Intelligence(IJCAI \u201987),"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 71
                            }
                        ],
                        "text": "Some early algorithms for neural networks inthis vein are contained in Sharkey and Sharkey (1993), Pratt (1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 21
                            }
                        ],
                        "text": "In this context, see Silver and Mercer (1996), Thrun and O\u2019Sullivan (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 21
                            }
                        ],
                        "text": "In this context, see Silver and Mercer (1996), Thrun and O\u2019Sullivan (1996). Note that th e question of task relatedness is clearly only meaningful relativeto a particular hypothesis space family H (for example, all possible collections of tasks are related if H contains every possible hypothesis space)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adaptive generali"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Theoryof Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 99
                            }
                        ],
                        "text": "Some early algorithms for neural networks inthis vein are contained in Sharkey and Sharkey (1993), Pratt (1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminability-basedtransferbetweenneuralnetworks"
            },
            "venue": {
                "fragments": [],
                "text": "Hanson,S. J., Cowan,J. D., & Giles,C. L. (Eds.),Advancesin Neural InformationProcessingSystems5, pp.204\u2013211.MorganKaufmann."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 166
                            }
                        ],
                        "text": "\u2026literature have proposed algorithms for both sharing the information in related tasks to improve average generalization performance across those tasks Singh (1992), Ring (1995), or learning bias from a set of tasks to improve performance on future tasks Sutton (1992), Thrun and Schwartz (1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1995).Continual Learning in Reinforcement Environments"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 252
                            }
                        ],
                        "text": "\u2026distributions are identical and they only differ in the conditional probabilities they assign to class labels), it can be shown that there is anoptimal metric or distance measure to use for vector quantization and onenearest-neighbour classification (Baxter, 1995a, 1997b; Baxter & Bartlett, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 106
                            }
                        ],
                        "text": "However, a model using a mixture of hierarchical Bayesian and information-theoretic ideaswas presented in Baxter (1997a), with similar conclusions to those found here."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Thecanonicaldistortionmeasurefor vectorquantizationandfunctionapproximation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedingsof the FourteenthInternationalConferenceon Machine Learning, pp.39\u201347.MorganKaufmann."
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 32
                            }
                        ],
                        "text": "Similar results may be found in Intrator and Edelman (1996) and in the experiments reported in Thrun (1996) and Thrun andPratt (1997, chapter 8)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 129
                            }
                        ],
                        "text": "One of the few cases where features have been learnt on a subset of tasks with the explicit aim of using them on novel tasks was Intrator and Edelman (1996) in which a low-dimensional representation was learnt for a set of multiple related image-recognition tasks and then used to successfully learn\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "How to make a low-dimensionalrepresentationsuitablefor diversetasks.ConnectionScience"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 142
                            }
                        ],
                        "text": "An empirical study showing the utility of the hierarchical Bayes approach in a domain containing a large number of related tasks was given in Heskes (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "tasks:acombinationof multi-tasklearningand a hierarchicalBayesianapproach.In"
            },
            "venue": {
                "fragments": [],
                "text": "Shavlik, J. (Ed.),Proceedingsof the15thInternational ConferenceonMachineLearning(ICML"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 80
                            }
                        ],
                        "text": "For an extension of our two-level approach to arbitrarily deep hierarchies, see Langford (1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 73
                            }
                        ],
                        "text": "For anextensionof ourtwo-level approachto arbitrarilydeephierarchies, seeLangford (1999). An interestingfurther questionis to what extent the hierarchycan be inferred from data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stagedlearning"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. rep., CMU, School of ComputerScience. http://www.cs.cmu.edu/"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Decision theoretic generalizations o"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the densityof families of sets"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of CombinatorialTheoryA,"
            },
            "year": 1972
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 57,
            "methodology": 32,
            "result": 11
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 85,
        "totalPages": 9
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Model-of-Inductive-Bias-Learning-Baxter/727e1e16ede6eaad241bad11c525da07b154c688?sort=total-citations"
}