{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3131784"
                        ],
                        "name": "Taku Kudoh",
                        "slug": "Taku-Kudoh",
                        "structuredName": {
                            "firstName": "Taku",
                            "lastName": "Kudoh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taku Kudoh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681502"
                        ],
                        "name": "Yuji Matsumoto",
                        "slug": "Yuji-Matsumoto",
                        "structuredName": {
                            "firstName": "Yuji",
                            "lastName": "Matsumoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuji Matsumoto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 90
                            }
                        ],
                        "text": "In the CoNLL-2000 sharedtask, we achieved theaccuracy of 93.48usingIOB2-F representation (Kudo and Matsumoto,2000b) 5."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6953360,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "923db0aeb26a6dc1cb42069c9db04e5dd2d2200a",
            "isKey": false,
            "numCitedBy": 340,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we explore the use of Support Vector Machines (SVMs) for CoNLL-2000 shared task, chunk identification. SVMs are so-called large margin classifiers and are well-known as their good generalization performance. We investigate how SVMs with a very large number of features perform with the classification task of chunk labelling."
            },
            "slug": "Use-of-Support-Vector-Learning-for-Chunk-Kudoh-Matsumoto",
            "title": {
                "fragments": [],
                "text": "Use of Support Vector Learning for Chunk Identification"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper investigates how SVMs with a very large number of features perform with the classification task of chunk labelling, CoNLL-2000 shared task, chunk identification."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL/LLL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 28
                            }
                        ],
                        "text": "In addition,in orderto achieve higher accuracy, we apply weightedvoting of 8 SVM-basedsystemswhich are trained using distinct chunkrepresentations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 1
                            }
                        ],
                        "text": "(Joachims,1998;TairaandHaruno,1999; KudoandMatsumoto,2000a)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2427083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40212e9474c3ddf3d8c6ffd13dd3211ec9406c49",
            "isKey": false,
            "numCitedBy": 8601,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of Support Vector Machines (SVMs) for learning text classifiers from examples. It analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task. Empirical results support the theoretical findings. SVMs achieve substantial improvements over the currently best performing methods and behave robustly over a variety of different learning tasks. Furthermore they are fully automatic, eliminating the need for manual parameter tuning."
            },
            "slug": "Text-Categorization-with-Support-Vector-Machines:-Joachims",
            "title": {
                "fragments": [],
                "text": "Text Categorization with Support Vector Machines: Learning with Many Relevant Features"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper explores the use of Support Vector Machines for learning text classifiers from examples and analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765329"
                        ],
                        "name": "Taku Kudo",
                        "slug": "Taku-Kudo",
                        "structuredName": {
                            "firstName": "Taku",
                            "lastName": "Kudo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taku Kudo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681502"
                        ],
                        "name": "Yuji Matsumoto",
                        "slug": "Yuji-Matsumoto",
                        "structuredName": {
                            "firstName": "Yuji",
                            "lastName": "Matsumoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuji Matsumoto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 149
                            }
                        ],
                        "text": "The boosting techniqueis a typeof weightedvoting scheme,and hasbeenapplied to many NLP problemssuchas parsing,part-of-speechtaggingandtext categorization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 68
                            }
                        ],
                        "text": "In addition,in orderto achieve higher accuracy, we apply weightedvoting of 8 SVM-basedsystemswhich are trained using distinct chunkrepresentations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 90
                            }
                        ],
                        "text": "In the CoNLL-2000 sharedtask, we achieved theaccuracy of 93.48usingIOB2-F representation (Kudo and Matsumoto,2000b) 5."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9256794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "717fddf184c49107dbc374f7c63252143f425d0e",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method of Japanese dependency structure analysis based on Support Vector Machines (SVMs). Conventional parsing techniques based on Machine Learning framework, such as Decision Trees and Maximum Entropy Models, have difficulty in selecting useful features as well as finding appropriate combination of selected features. On the other hand, it is well-known that SVMs achieve high generalization performance even with input data of very high dimensional feature space. Furthermore, by introducing the Kernel principle, SVMs can carry out the training in high-dimensional spaces with a smaller computational cost independent of their dimensionality. We apply SVMs to Japanese dependency structure identification problem. Experimental results on Kyoto University corpus show that our system achieves the accuracy of 89.09% even with small training data (7958 sentences)."
            },
            "slug": "Japanese-Dependency-Structure-Analysis-Based-on-Kudo-Matsumoto",
            "title": {
                "fragments": [],
                "text": "Japanese Dependency Structure Analysis Based on Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This paper applies SVMs to Japanese dependency structure identification problem and introduces the Kernel principle, which can carry out the training in high-dimensional spaces with a smaller computational cost independent of their dimensionality."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u306e\u5206\u91ce\u306b\u304a \u3044\u3066\u3082, \u6587\u66f8\u5206\u985e\u3084\u4fc2\u308a\u53d7\u3051\u89e3\u6790\u306b\u5fdc\u7528\u3055\u308c\u3066\u304a\u308a, \u5f93\u6765\u306e\u624b\u6cd5\u306b\u6bd4\u3079\u3066\u9ad8\u3044\u6027\u80fd\u3092\u793a\u3057\u3066\u3044\u308b [6,  4 , 21]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14591650,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b1a9e50f18af8a7b9f8dd38f40e0466ad7a8e8",
            "isKey": false,
            "numCitedBy": 3047,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces Transductive Support Vector Machines (TSVMs) for text classi cation. While regular Support Vector Machines (SVMs) try to induce a general decision function for a learning task, Transductive Support Vector Machines take into account a particular test set and try to minimize misclassi cations of just those particular examples. The paper presents an analysis of why TSVMs are well suited for text classi cation. These theoretical ndings are supported by experiments on three test collections. The experiments show substantial improvements over inductive methods, especially for small training sets, cutting the number of labeled training examples down to a twentieth on some tasks. This work also proposes an algorithm for training TSVMs e ciently, handling 10,000 examples and more."
            },
            "slug": "Transductive-Inference-for-Text-Classification-Joachims",
            "title": {
                "fragments": [],
                "text": "Transductive Inference for Text Classification using Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "An analysis of why Transductive Support Vector Machines are well suited for text classi cation is presented, and an algorithm for training TSVMs, handling 10,000 examples and more is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157221"
                        ],
                        "name": "E. T. K. Sang",
                        "slug": "E.-T.-K.-Sang",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sang",
                            "middleNames": [
                                "Tjong",
                                "Kim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. T. K. Sang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3264129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8682725f2968836a5cd933eed4fdce80b0833bbc",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The performance of machine learning algorithms can be improved by combining the output of different systems. In this paper we apply this idea to the recognition of noun phrases. We generate different classifiers by using different representations of the data. By combining the results with voting techniques described in (Van Halteren et al., 1998) we manage to improve the best reported performances on standard data sets for base noun phrases and arbitrary noun phrases."
            },
            "slug": "Noun-Phrase-Recognition-by-System-Combination-Sang",
            "title": {
                "fragments": [],
                "text": "Noun Phrase Recognition by System Combination"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper generates different classifiers by using different representations of the data for noun phrases recognition to improve the best reported performances on standard data sets for base noun phrases and arbitrary noun phrases."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u6211\u3005\u306f, Virtual SVM[ 16 ]\u306e\u30a2\u30a4\u30c7\u30a2\u3092\u53d6\u308a\u3044\u308c,\u62bd\u51fa\u3055\u308c \u308b support ector\u306b\u5bfe\u3057\u5909\u5f62\u898f\u5247\u3092\u9069\u7528\u3057,\u53ef\u5909 \u9577\u306e\u6587\u8108\u3092\u9593\u63a5\u7684\u306b\u8003\u616e\u3059\u308b\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3057\u305f \u3044\u3068\u8003\u3048\u3066\u3044\u308b."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9756494,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55590f229e23a8e67af7d6d36f7456a595c251d1",
            "isKey": false,
            "numCitedBy": 319,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Developed only recently, support vector learning machines achieve high generalization ability by minimizing a bound on the expected test error; however, so far there existed no way of adding knowledge about invariances of a classification problem at hand. We present a method of incorporating prior knowledge about transformation invariances by applying transformations to support vectors, the training examples most critical for determining the classification boundary."
            },
            "slug": "Incorporating-Invariances-in-Support-Vector-Sch\u00f6lkopf-Burges",
            "title": {
                "fragments": [],
                "text": "Incorporating Invariances in Support Vector Learning Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work presents a method of incorporating prior knowledge about transformation invariances by applying transformations to support vectors, the training examples most critical for determining the classification boundary."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157221"
                        ],
                        "name": "E. T. K. Sang",
                        "slug": "E.-T.-K.-Sang",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sang",
                            "middleNames": [
                                "Tjong",
                                "Kim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. T. K. Sang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143667674"
                        ],
                        "name": "J. Veenstra",
                        "slug": "J.-Veenstra",
                        "structuredName": {
                            "firstName": "Jorn",
                            "lastName": "Veenstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Veenstra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1845735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "008a2291a257072f22764196a3acf0a394bf203a",
            "isKey": false,
            "numCitedBy": 392,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Dividing sentences in chunks of words is a useful preprocessing step for parsing, information extraction and information retrieval. (Ramshaw and Marcus, 1995) have introduced a \"convenient\" data representation for chunking by converting it to a tagging task. In this paper we will examine seven different data representations for the problem of recognizing noun phrase chunks. We will show that the the data representation choice has a minor influence on chunking performance. However, equipped with the most suitable data representation, our memory-based learning chunker was able to improve the best published chunking results for a standard data set."
            },
            "slug": "Representing-Text-Chunks-Sang-Veenstra",
            "title": {
                "fragments": [],
                "text": "Representing Text Chunks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the the data representation choice has a minor influence on chunking performance, however, equipped with the most suitable data representation, the memory-based learning chunker was able to improve the best published chunking results for a standard data set."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157221"
                        ],
                        "name": "E. T. K. Sang",
                        "slug": "E.-T.-K.-Sang",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sang",
                            "middleNames": [
                                "Tjong",
                                "Kim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. T. K. Sang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735272"
                        ],
                        "name": "Walter Daelemans",
                        "slug": "Walter-Daelemans",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Daelemans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Walter Daelemans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2131960"
                        ],
                        "name": "Herv\u00e9 D\u00e9jean",
                        "slug": "Herv\u00e9-D\u00e9jean",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "D\u00e9jean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Herv\u00e9 D\u00e9jean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299876"
                        ],
                        "name": "R. Koeling",
                        "slug": "R.-Koeling",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Koeling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Koeling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2349412"
                        ],
                        "name": "Yuval Krymolowski",
                        "slug": "Yuval-Krymolowski",
                        "structuredName": {
                            "firstName": "Yuval",
                            "lastName": "Krymolowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuval Krymolowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474158"
                        ],
                        "name": "Vasin Punyakanok",
                        "slug": "Vasin-Punyakanok",
                        "structuredName": {
                            "firstName": "Vasin",
                            "lastName": "Punyakanok",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vasin Punyakanok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3263632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13687a29e5b51c3f1b51593f95aa3dc2c67990e6",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "We use seven machine learning algorithms for one task: identifying base noun phrases. The results have been processed by different system combination methods and all of these outperformed the best individual result. We have applied the seven learners with the best combinator, a majority vote of the top five systems, to a standard data set and managed to improve the best published result for this data set."
            },
            "slug": "Applying-System-Combination-to-Base-Noun-Phrase-Sang-Daelemans",
            "title": {
                "fragments": [],
                "text": "Applying System Combination to Base Noun Phrase Identification"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This work uses seven machine learning algorithms for one task: identifying base noun phrases and applies the seven learners with the best combinator, a majority vote of the top five systems, to a standard data set and improves the best published result."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157221"
                        ],
                        "name": "E. T. K. Sang",
                        "slug": "E.-T.-K.-Sang",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sang",
                            "middleNames": [
                                "Tjong",
                                "Kim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. T. K. Sang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12841881,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e8de77316a43fd8675d546880b4607433793c31",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We will apply a system-internal combination of memory-based learning classifiers to the CoNLL-2000 shared task: finding base chunks. Apart from testing different combination methods, we will also examine if dividing the chunking process in a boundary recognition phase and a type identification phase would aid performance."
            },
            "slug": "Text-Chunking-by-System-Combination-Sang",
            "title": {
                "fragments": [],
                "text": "Text Chunking by System Combination"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A system-internal combination of memory-based learning classifiers is applied to the CoNLL-2000 shared task: finding base chunks to examine if dividing the chunking process in a boundary recognition phase and a type identification phase would aid performance."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL/LLL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125121"
                        ],
                        "name": "Hirotoshi Taira",
                        "slug": "Hirotoshi-Taira",
                        "structuredName": {
                            "firstName": "Hirotoshi",
                            "lastName": "Taira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hirotoshi Taira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47348275"
                        ],
                        "name": "M. Haruno",
                        "slug": "M.-Haruno",
                        "structuredName": {
                            "firstName": "Masahiko",
                            "lastName": "Haruno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Haruno"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 44
                            }
                        ],
                        "text": "In addition,in orderto achieve higher accuracy, we apply weightedvoting of 8 SVM-basedsystemswhich are trained using distinct chunkrepresentations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3142786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c026ffbd40e4beb386c18946e9079fac5da4afc0",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the effect of prior feature selection in Support Vector Machine (SVM) text categorization. The input space was gradually increased by using mutual information (MI) filtering and part-of-speech (POS) filtering, which determine the portion of words that are appropriate for learning from the information-theoretic and the linguistic perspectives, respectively. We tested the two filtering methods on SVMs as well as a decision tree algorithm C4.5. The SVMs' results common to both filtering are that 1) the optimal number of features differed completely across categories, and 2) the average performance for all categories was best when all of the words were used. In addition, a comparison of the two filtering methods clarified that POS filtering on SVMs consistently outperformed MI filtering, which indicates that SVMs cannot find irrelevant parts of speech. These results suggest a simple strategy for the SVM text categorization: use a full number of words found through a rough filtering technique like part-of-speech tagging."
            },
            "slug": "Feature-Selection-in-SVM-Text-Categorization-Taira-Haruno",
            "title": {
                "fragments": [],
                "text": "Feature Selection in SVM Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Results suggest a simple strategy for the SVM text categorization: use a full number of words found through a rough filtering technique like part-of-speech tagging, which indicates that SVMs cannot find irrelevant parts of speech."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 793899,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbc78c2669eb595c988ab69a6dd4cbabc2421043",
            "isKey": false,
            "numCitedBy": 398,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "New functionals for parameter (model) selection of Support Vector Machines are introduced based on the concepts of the span of support vectors and rescaling of the feature space. It is shown that using these functionals, one can both predict the best choice of parameters of the model and the relative quality of performance for any value of parameter."
            },
            "slug": "Model-Selection-for-Support-Vector-Machines-Chapelle-Vapnik",
            "title": {
                "fragments": [],
                "text": "Model Selection for Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "New functionals for parameter (model) selection of Support Vector Machines are introduced based on the concepts of the span of support vectors and rescaling of the feature space and it is shown that using these functionals one can both predict the best choice of parameters of the model and the relative quality of performance for any value of parameter."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40433342"
                        ],
                        "name": "M. Sassano",
                        "slug": "M.-Sassano",
                        "structuredName": {
                            "firstName": "Manabu",
                            "lastName": "Sassano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sassano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732417"
                        ],
                        "name": "T. Utsuro",
                        "slug": "T.-Utsuro",
                        "structuredName": {
                            "firstName": "Takehito",
                            "lastName": "Utsuro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Utsuro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 34
                            }
                        ],
                        "text": "Conventionalmachinelearningtechniques,such as Hidden Markov Model (HMM) and Maximum Entropy Model (ME), normally require a careful featureselectionin orderto achieve high accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1704543,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72748bb4e8c1f0818a70dda783445e7e775142f5",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper focuses on the issue of named entity chunking in Japanese named entity recognition. We apply the supervised decision list learning method to Japanese named entity recognition. We also investigate and incorporate several named-entity noun phrase chunking techniques and experimentally evaluate and compare their performance. In addition, we propose a method for incorporating richer contextual information as well as patterns of constituent morphemes within a named entity, which have not been considered in previous research, and show that the proposed method outperforms these previous approaches."
            },
            "slug": "Named-Entity-Chunking-Techniques-in-Supervised-for-Sassano-Utsuro",
            "title": {
                "fragments": [],
                "text": "Named Entity Chunking Techniques in Supervised Learning for Japanese Named Entity Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A method is proposed for incorporating richer contextual information as well as patterns of constituent morphemes within a named entity, which have not been considered in previous research, and it is shown that the proposed method outperforms these previous approaches."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157221"
                        ],
                        "name": "E. T. K. Sang",
                        "slug": "E.-T.-K.-Sang",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sang",
                            "middleNames": [
                                "Tjong",
                                "Kim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. T. K. Sang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782178"
                        ],
                        "name": "S. Buchholz",
                        "slug": "S.-Buchholz",
                        "structuredName": {
                            "firstName": "Sabine",
                            "lastName": "Buchholz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Buchholz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8940645,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "9e85832b04cc3700c2c26d6ba93fdeae39cac04a",
            "isKey": false,
            "numCitedBy": 872,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the CoNLL-2000 shared task: dividing text into syntactically related non-overlapping groups of words, so-called text chunking. We give background information on the data sets, present a general overview of the systems that have taken part in the shared task and briefly discuss their performance."
            },
            "slug": "Introduction-to-the-CoNLL-2000-Shared-Task-Chunking-Sang-Buchholz",
            "title": {
                "fragments": [],
                "text": "Introduction to the CoNLL-2000 Shared Task Chunking"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "The CoNLL-2000 shared task: dividing text into syntactically related non-overlapping groups of words, so-called text chunking is described."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL/LLL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744313"
                        ],
                        "name": "L. Ramshaw",
                        "slug": "L.-Ramshaw",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Ramshaw",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ramshaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 133
                            }
                        ],
                        "text": "Various machinelearningapproacheshave beenproposed for chunking(Ramshaw andMarcus,1995; Tjong Kim Sang,2000a; Tjong Kim Sanget al., 2000; TjongKim Sang,2000b;SassanoandUtsuro,2000; vanHalteren,2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 59
                            }
                        ],
                        "text": "Inside/Outside This representationwas first introduced in (Ramshaw and Marcus,1995), and hasbeen applied for baseNP chunking."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 725590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9c71db75046473f0e3d3229950d7c84c09afd5e",
            "isKey": false,
            "numCitedBy": 1530,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Transformation-based learning, a technique introduced by Eric Brill (1993b), has been shown to do part-of-speech tagging with fairly high accuracy. This same method can be applied at a higher level of textual interpretation for locating chunks in the tagged text, including non-recursive \u201cbaseNP\u201d chunks. For this purpose, it is convenient to view chunking as a tagging problem by encoding the chunk structure in new tags attached to each word. In automatic tests using Treebank-derived data, this technique achieved recall and precision rates of roughly 93% for baseNP chunks (trained on 950K words) and 88% for somewhat more complex chunks that partition the sentence (trained on 200K words). Working in this new application and with larger template and training sets has also required some interesting adaptations to the transformation-based learning approach."
            },
            "slug": "Text-Chunking-using-Transformation-Based-Learning-Ramshaw-Marcus",
            "title": {
                "fragments": [],
                "text": "Text Chunking using Transformation-Based Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work has shown that the transformation-based learning approach can be applied at a higher level of textual interpretation for locating chunks in the tagged text, including non-recursive \u201cbaseNP\u201d chunks."
            },
            "venue": {
                "fragments": [],
                "text": "VLC@ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2165139"
                        ],
                        "name": "H. V. Halteren",
                        "slug": "H.-V.-Halteren",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Halteren",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. V. Halteren"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13382016,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2b16a6f2154fd2814f50d9f96283a76c2959da0",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper I describe the application of the WPDV algorithm to the CoNLL-2000 shared task, the identification of base chunks in English text (Tjong Kim Sang and Buchholz, 2000). For this task, I use a three-stage architecture: I first run five different base chunkers, then combine them and finally try to correct some recurring errors. Except for one base chunker, which uses the memory-based machine learning system TiMBL, all modules are based on WPDV models (van Halteren, 2000a)."
            },
            "slug": "Chunking-with-WPDV-Models-Halteren",
            "title": {
                "fragments": [],
                "text": "Chunking with WPDV Models"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "This paper describes the application of the WPDV algorithm to the CoNLL-2000 shared task, the identification of base chunks in English text, using a three-stage architecture."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL/LLL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1943813"
                        ],
                        "name": "Erin Allwein",
                        "slug": "Erin-Allwein",
                        "structuredName": {
                            "firstName": "Erin",
                            "lastName": "Allwein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erin Allwein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 45
                            }
                        ],
                        "text": "IOB2 A B tagis givenfor every tokenwhich\nexists at the beginning of a chunk."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9790719,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd74cc5129c45268d4e766d3619e7cb0ead5c8c8",
            "isKey": false,
            "numCitedBy": 1991,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a unifying framework for studying the solution of multiclass categorization problems by reducing them to multiple binary problems that are then solved using a margin-based binary learning algorithm. The proposed framework unifies some of the most popular approaches in which each class is compared against all others, or in which all pairs of classes are compared to each other, or in which output codes with error-correcting properties are used. We propose a general method for combining the classifiers generated on the binary problems, and we prove a general empirical multiclass loss bound given the empirical loss of the individual binary learning algorithms. The scheme and the corresponding bounds apply to many popular classification learning algorithms including support-vector machines, AdaBoost, regression, logistic regression and decision-tree algorithms. We also give a multiclass generalization error analysis for general output codes with AdaBoost as the binary learner. Experimental results with SVM and AdaBoost show that our scheme provides a viable alternative to the most commonly used multiclass algorithms."
            },
            "slug": "Reducing-Multiclass-to-Binary:-A-Unifying-Approach-Allwein-Schapire",
            "title": {
                "fragments": [],
                "text": "Reducing Multiclass to Binary: A Unifying Approach for Margin Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A general method for combining the classifiers generated on the binary problems is proposed, and a general empirical multiclass loss bound is proved given the empirical loss of the individual binary learning algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1836349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68c1bfe375dde46777fe1ac8f3636fb651e3f0f8",
            "isKey": false,
            "numCitedBy": 8626,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "In an earlier paper, we introduced a new \"boosting\" algorithm called AdaBoost which, theoretically, can be used to significantly reduce the error of any learning algorithm that con- sistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a \"pseudo-loss\" which is a method for forcing a learning algorithm of multi-label concepts to concentrate on the labels that are hardest to discriminate. In this paper, we describe experiments we carried out to assess how well AdaBoost with and without pseudo-loss, performs on real learning problems. We performed two sets of experiments. The first set compared boosting to Breiman's \"bagging\" method when used to aggregate various classifiers (including decision trees and single attribute- value tests). We compared the performance of the two methods on a collection of machine-learning benchmarks. In the second set of experiments, we studied in more detail the performance of boosting using a nearest-neighbor classifier on an OCR problem."
            },
            "slug": "Experiments-with-a-New-Boosting-Algorithm-Freund-Schapire",
            "title": {
                "fragments": [],
                "text": "Experiments with a New Boosting Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper describes experiments carried out to assess how well AdaBoost with and without pseudo-loss, performs on real learning problems and compared boosting to Breiman's \"bagging\" method when used to aggregate various classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022386739"
                        ],
                        "name": "Peter Barlett",
                        "slug": "Peter-Barlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Barlett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Barlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740222"
                        ],
                        "name": "Wee Sun Lee",
                        "slug": "Wee-Sun-Lee",
                        "structuredName": {
                            "firstName": "Wee",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wee Sun Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 573509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d19272112b50547614479a0c409fca66e3b05f7",
            "isKey": false,
            "numCitedBy": 2844,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the surprising recurring phenomena observed in experiments with boosting is that the test error of the generated classifier usually does not increase as its size becomes very large, and often is observed to decrease even after the training error reaches zero. In this paper, we show that this phenomenon is related to the distribution of margins of the training examples with respect to the generated voting classification rule, where the margin of an example is simply the difference between the number of correct votes and the maximum number of votes received by any incorrect label. We show that techniques used in the analysis of Vapnik's support vector classifiers and of neural networks with small weights can be applied to voting methods to relate the margin distribution to the test error. We also show theoretically and experimentally that boosting is especially effective at increasing the margins of the training examples. Finally, we compare our explanation to those based on the bias-variance"
            },
            "slug": "Boosting-the-margin:-A-new-explanation-for-the-of-Schapire-Freund",
            "title": {
                "fragments": [],
                "text": "Boosting the margin: A new explanation for the effectiveness of voting methods"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that techniques used in the analysis of Vapnik's support vector classifiers and of neural networks with small weights can be applied to voting methods to relate the margin distribution to the test error."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783611"
                        ],
                        "name": "Kiyotaka Uchimoto",
                        "slug": "Kiyotaka-Uchimoto",
                        "structuredName": {
                            "firstName": "Kiyotaka",
                            "lastName": "Uchimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kiyotaka Uchimoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9374073"
                        ],
                        "name": "Qing-Lu Ma",
                        "slug": "Qing-Lu-Ma",
                        "structuredName": {
                            "firstName": "Qing-Lu",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qing-Lu Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697381"
                        ],
                        "name": "M. Murata",
                        "slug": "M.-Murata",
                        "structuredName": {
                            "firstName": "Masaki",
                            "lastName": "Murata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Murata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33743685"
                        ],
                        "name": "Hiromi Ozaku",
                        "slug": "Hiromi-Ozaku",
                        "structuredName": {
                            "firstName": "Hiromi",
                            "lastName": "Ozaku",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hiromi Ozaku"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714134"
                        ],
                        "name": "H. Isahara",
                        "slug": "H.-Isahara",
                        "structuredName": {
                            "firstName": "Hitoshi",
                            "lastName": "Isahara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Isahara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 24712229,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51a3e50521e4dfd1a520e626cc28a55e0f374493",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes named entity (NE) extraction based on a maximum entropy (M. E.) model and transformation rules. There are two types of named entities when focusing on the relationship between morphemes and NEs as defined in the NE task of the IREX competition held in 1999. Each NE consists of one or more morphemes, or includes a substring of a morpheme. We extract the former type of NE by using the M. E. model. We then extract the latter type of NE by applying transformation rules to the text."
            },
            "slug": "Named-Entity-Extraction-Based-on-A-Maximum-Entropy-Uchimoto-Ma",
            "title": {
                "fragments": [],
                "text": "Named Entity Extraction Based on A Maximum Entropy Model and Transformation Rules"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "This paper describes named entity extraction based on a maximum entropy (M. E.) model and transformation rules and extracts two types of named entities when focusing on the relationship between morphemes and NEs as defined in the IREX competition held in 1999."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299726"
                        ],
                        "name": "Thomas G. Dietterich",
                        "slug": "Thomas-G.-Dietterich",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dietterich",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas G. Dietterich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3242194"
                        ],
                        "name": "Ghulum Bakiri",
                        "slug": "Ghulum-Bakiri",
                        "structuredName": {
                            "firstName": "Ghulum",
                            "lastName": "Bakiri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ghulum Bakiri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 4
                            }
                        ],
                        "text": "IOB2 A B tagis givenfor every tokenwhich\nexists at the beginning of a chunk."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 47109072,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d221bbcbd20c7157e4500f942de8ceec490f8936",
            "isKey": false,
            "numCitedBy": 2852,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Multiclass learning problems involve finding a definition for an unknown function f(x) whose range is a discrete set containing k > 2 values (i.e., k \"classes\"). The definition is acquired by studying collections of training examples of the form (xi, f(xi)). Existing approaches to multiclass learning problems include direct application of multiclass algorithms such as the decision-tree algorithms C4.5 and CART, application of binary concept learning algorithms to learn individual binary functions for each of the k classes, and application of binary concept learning algorithms with distributed output representations. This paper compares these three approaches to a new technique in which error-correcting codes are employed as a distributed output representation. We show that these output representations improve the generalization performance of both C4.5 and backpropagation on a wide range of multiclass learning tasks. We also demonstrate that this approach is robust with respect to changes in the size of the training sample, the assignment of distributed representations to particular classes, and the application of overfitting avoidance techniques such as decision-tree pruning. Finally, we show that--like the other methods--the error-correcting code technique can provide reliable class probability estimates. Taken together, these results demonstrate that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems."
            },
            "slug": "Solving-Multiclass-Learning-Problems-via-Output-Dietterich-Bakiri",
            "title": {
                "fragments": [],
                "text": "Solving Multiclass Learning Problems via Error-Correcting Output Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is demonstrated that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28637672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "385197d4c02593e2823c71e4f90a0993b703620e",
            "isKey": false,
            "numCitedBy": 26322,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "slug": "Statistical-learning-theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "Statistical learning theory"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 62
                            }
                        ],
                        "text": "The datahaspart-ofspeech(POS)tagsannotatedby the Brill tagger(Brill, 1995)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 134248,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "2b2eb4a9bb146e3ffaa0b025fba0ed14240c683f",
            "isKey": false,
            "numCitedBy": 1821,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of injection molding wherein a pair of separable mold plates are initially urged together and fluid plastic is injected into a mold cavity formed between the mold plates to form an article. The injection pressure of the fluid plastic is utilized to generate forces sufficient to overcome the internal forces urging the mold plates apart and thus hold the mold plates together until the material being molded solidifies either by cooling, chemical reaction or phase change."
            },
            "slug": "Transformation-Based-Error-Driven-Learning-and-A-in-Brill",
            "title": {
                "fragments": [],
                "text": "Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "Injection molding wherein a pair of separable mold plates are initially urged together and fluid plastic is injected into a mold cavity formed between the mold plates to form an article."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69924093"
                        ],
                        "name": "S. Hyakin",
                        "slug": "S.-Hyakin",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Hyakin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hyakin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60577818,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "045310b06e8a3983a363a118cc9dcc3f292970b4",
            "isKey": false,
            "numCitedBy": 9899,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Simon Haykin Neural Networks A Comprehensive Foundation. Neural Networks A Comprehensive Foundation Simon S. Neural Networks A Comprehensive Foundation Simon S. Neural Networks A Comprehensive Foundation. Neural Networks Association for Computing Machinery. Book Review Neural Networks A Comprehensive Foundation. Neural Networks A Comprehensive Foundation Pearson. Neural networks a comprehensive foundation. Neural Networks a Comprehensive Foundation AbeBooks. Neural networks a comprehensive foundation solutions. cdn preterhuman net. Neural Networks A Comprehensive Foundation Goodreads. Neural Networks A Comprehensive Foundation Amazon it. Neural Networks A Comprehensive Foundation Amazon co uk. Neural Networks A Comprehensive Foundation 3rd Edition. Neural Networks A Comprehensive Foundation Simon. Neural Networks A Comprehensive Foundation amazon com. Neural networks a comprehensive foundation Academia edu. Neural Networks A Comprehensive Foundation Amazon. neural networks a comprehensive foundation simon haykin. Simon Haykin Neural Networks A Comprehensive Foundation. Neural Networks A comprehensive Foundation 2 ed. Simon haykin neural networks a comprehensive foundation pdf. Buy Neural Networks A Comprehensive Foundation Book. Neural networks a comprehensive foundation 2e book. Neural Networks A Comprehensive Foundation. NEURAL NETWORKS A COMPREHENSIVE FOUNDATION SIMON. Neural Networks a Comprehensive Foundation by Haykin Simon. Neural Networks A Comprehensive Foundation pdf PDF Drive. Neural Networks A Comprehensive Foundation amazon ca. Simon Haykin Neural Networks A Comprehensive Foundation. NEURAL NETWORKS A Comprehensive Foundation PDF. Neural Networks A Comprehensive Foundation pdf PDF Drive. Neural Networks A Comprehensive Foundation by Haykin. Neural Networks A Comprehensive Foundation 3rd Edition. Neural Networks A Comprehensive Foundation Simon S. Neural Networks A Comprehensive Foundation. Neural networks a comprehensive foundation Book 1994. Neural Networks A Comprehensive Foundation 2nd Edition. Neural Networks A Comprehensive Foundation S S Haykin. Neural Networks A Comprehensive Foundation International. Neural Networks A Comprehensive Foundation 2 e Pearson. Download Neural Networks A Comprehensive Foundation 2Nd. Neural Networks A comprehensive foundation Aalto"
            },
            "slug": "Neural-Networks:-A-Comprehensive-Foundation-Hyakin",
            "title": {
                "fragments": [],
                "text": "Neural Networks: A Comprehensive Foundation"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "Simon Haykin Neural Networks A Comprehensive Foundation Simon S. Haykin neural networks a comprehensive foundation pdf PDF Drive."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "139044657"
                        ],
                        "name": "U.H.-G. Kressel",
                        "slug": "U.H.-G.-Kressel",
                        "structuredName": {
                            "firstName": "U.H.-G.",
                            "lastName": "Kressel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U.H.-G. Kressel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57961414,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b6de3c8cc48ce8b0e11802a1abce6b7a890dc8c5",
            "isKey": false,
            "numCitedBy": 1140,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pairwise-classification-and-support-vector-machines-Kressel",
            "title": {
                "fragments": [],
                "text": "Pairwise classification and support vector machines"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reducingmulticlassto binary : A unifying approachfor margin classifiers"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00bfp Js=hM\u02dd3X2qO@J8"
            },
            "venue": {
                "fragments": [],
                "text": "\u00bfp Js=hM\u02dd3X2qO@J8"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "B:Cross Validation, C:VC bound"
            },
            "venue": {
                "fragments": [],
                "text": "B:Cross Validation, C:VC bound"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "n9@H\u02dcn9@H\u02dc, Fb;3\u00bf-IW , 0f:4 866Q"
            },
            "venue": {
                "fragments": [],
                "text": "n9@H\u02dcn9@H\u02dc, Fb;3\u00bf-IW , 0f:4 866Q"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 67
                            }
                        ],
                        "text": "The data has part-ofspeech (POS) tags annotated by the Brill tagger(Brill, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Transformation-Based ErrorDriven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[2] Oliver Chapelle and Vladimir Vapnik."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 62
                            }
                        ],
                        "text": "The datahaspart-ofspeech(POS)tagsannotatedby the Brill tagger(Brill, 1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 99
                            }
                        ],
                        "text": "\u305d\u306e\u4e00\u65b9\u3067 Chapelle \u3089 \u306f, \u3053\u308c\u3089\u3088\u308a\u4e88\u6e2c\u80fd\u529b\u306e\u9ad8\u3044 bound \u3092\u63d0\u6848 \u3057 ,Kernel \u95a2\u6570\u306e\u9078\u629e\u3084 Soft Margin \u30d1\u30e9\u30e1\u30fc \u30bf\u306e\u9078\u629e\u306b\u6975\u3081\u3066\u6709\u52b9\u3067\u3042\u308b\u3068\u3053\u3092\u793a\u3057\u3066\u3044\u308b [2]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vector Machine (SVM)\u306b\u57fa\u3065 \u304f\u4e00\u822c\u7684\u306a"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "B:8r:98!Dj C:VC bound D:Leave-One-Out bound I= 1: 8D!9$N%b%G%k"
            },
            "venue": {
                "fragments": [],
                "text": "B:8r:98!Dj C:VC bound D:Leave-One-Out bound I= 1: 8D!9$N%b%G%k"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "\u3053\u306e\u3088\u3046\u306a\u91cd\u307f\u4ed8\u304d\u591a\u6570\u6c7a\u306e\u624b\u6cd5\u306f, \u6f5c\u5728\u7684\u306b\u30de\u30fc \u30b8\u30f3\u6700\u5927\u5316\u306e\u52b9\u679c\u304c\u3042\u308a, \u6c4e\u5316\u80fd\u529b\u306e\u9ad8\u3044\u5f37\u5b66\u7fd2\u30a2\u30eb \u30b4\u30ea\u30ba\u30e0\u304c\u4f5c\u6210\u3067\u304d\u308b\u4e8b\u304c\u7406\u8ad6\u7684\u306b\u3082\u5b9f\u9a13\u7684\u306b\u3082\u660e \u3089\u304b\u306b\u306a\u3063\u3066\u3044\u308b [15]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Boosting the marting: A new explanation for the effectivenss of voting methods"
            },
            "venue": {
                "fragments": [],
                "text": "The Annals of Statistics,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Leave-One-Out bound $rDs0F"
            },
            "venue": {
                "fragments": [],
                "text": "Leave-One-Out bound $rDs0F"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "SangandJornVeenstra.1999. Representingtext chunks"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedingsof EACL\u201999,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bs : 1976 G/@8 . 1999 G/5\u02dcETBg3X9)3XItEE5$EE;R9)3X2JB4 , 2001 G/F'NI@h C\u00a12J3X5;=QBg3X1!Bg3X\u00bfpJs2J3X8&5f2JGn"
            },
            "venue": {
                "fragments": [],
                "text": "Bs : 1976 G/@8 . 1999 G/5\u02dcETBg3X9)3XItEE5$EE;R9)3X2JB4 , 2001 G/F'NI@h C\u00a12J3X5;=QBg3X1!Bg3X\u00bfpJs2J3X8&5f2JGn"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "$? 5 ftp://ftp.cis.upenn.edu/pub/chunker/$+$iF\u02dc\u00a1j2DG= 6 http://lcg-www.uia.ac.be/conll2000/chunking"
            },
            "venue": {
                "fragments": [],
                "text": "$? 5 ftp://ftp.cis.upenn.edu/pub/chunker/$+$iF\u02dc\u00a1j2DG= 6 http://lcg-www.uia.ac.be/conll2000/chunking"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Representingtext chunks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Noun phrase recognitionby systemcombination"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Boostingthe margin: a new explanationfor the effectivenessof voting methods.In InternationalConferenceonMachineLearning(ICML), pages322\u2013330"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Boostingthe margin : a new explanationfor the effectivenessof voting methods"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Named Entity ExtractionBasedon A MaximumEntropy Model andTransformationRules"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "82Cx$J 4.4 B??t7h$N8z2L I=2 $+$iB??t7h$r9T 8r:98!Dj , VC bound, Leave one Out bound $H$b$K%Y!\u00a1%9%i%$%s$G$ \" $k6Q0l$N=E$\u02d9IU$1$h$j@:EY $,8\u02dc\u00bfe$7$F$$$k. VC bound $rMQ$$$?\u00bfl9g$O"
            },
            "venue": {
                "fragments": [],
                "text": "%k%4 %j%:%'$K MBL, ME, IGTree Ey$N7 \u00a1oN'$N% \" %k%4 %j%:%' , $5 $i$K IOB1/IOB2/IOE1/IOE2 $N4 \u00a1oN'$NI=8=$rMQ $$$FFHN)$K3X="
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chunking with Support Vector Machines"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of NAACL-2001"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Applying systemcombinationto basenounphraseidentification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 4,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 44,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Chunking-with-Support-Vector-Machines-Kudo-Matsumoto/6ffea7929f0e4bbee9e98755eb3d8fc09e89cf4e?sort=total-citations"
}