{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 114
                            }
                        ],
                        "text": "Several methods of image analysis can be used to learn a suitable basis of global features (Vailaya et al., 1998; Oliva and Torralba, 2001; Vogel and Schiele, 2004; Fei-Fei and Perona, 2005) that capture the statistical regularities of natural-scene images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 142
                            }
                        ],
                        "text": "In addition to color, research has shown that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; Oliva and Torralba, 2001; Torralba and Oliva, 2003; McCotter et al., 2005) and can help to predict the presence or absence of objects in natural images\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 188
                            }
                        ],
                        "text": "A forest would be described as \u2018\u2018an enclosed environment, with a dense isotropic texture\u2019\u2019 and a street scene would be a \u2018\u2018man-made outdoor scene, with perspective, and medium level of clutter\u2019\u2019 (Oliva and Torralba, 2001, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 120
                            }
                        ],
                        "text": ", in perspective, cluttered) can be determined with a high probability from a diagnostic set of lowlevel image features (Oliva and Torralba, 2001; Walker Renninger and Malik, 2004; Fei-Fei and Perona, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 125
                            }
                        ],
                        "text": "In addition to color, research has shown that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; Oliva and Torralba, 2001; Torralba and Oliva, 2003; McCotter et al., 2005) and can help to predict the presence or absence of objects in natural images (Torralba, 2003a; Torralba and Oliva, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 90
                            }
                        ],
                        "text": "On the basis\nof a global spatial representation of the image, the Spatial Envelope model (Oliva and Torralba, 2001) provides a conceptual framework for the representation and the mechanisms of fast scene gist interpretation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 158
                            }
                        ],
                        "text": "Here w\nimages (the image collection includes scenes at all ranges of views, from closeup to panoramic, for both man-made and natural environments, similar to Oliva and Torralba, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 83
                            }
                        ],
                        "text": "6 illustrates the framework of the Spatial Envelope model (details can be found in Oliva and Torralba, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 43
                            }
                        ],
                        "text": "Because a scene is inherently a 3D entity, Oliva and Torralba (2001) proposed that fast scene recognition mechanisms might initially be based on global properties diagnostic of the space that the scene subtends and not necessarily the objects that the scene contains."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 214
                            }
                        ],
                        "text": "\u2026highway, coast, etc.) as well as global properties of the three-dimensional (3D) space (e.g., in perspective, cluttered) can be determined with a high probability from a diagnostic set of lowlevel image features (Oliva and Torralba, 2001; Walker Renninger and Malik, 2004; Fei-Fei and Perona, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 574,
                                "start": 548
                            }
                        ],
                        "text": "The global feature scene representation looks like a sketch version of the scene in which most of the contours and spatial frequencies from the original image have been conserved, but their spatial organization is only loosely preserved: a sketch at a resolution of 1 cycle/image (pulling local features from a 2 2 grid applied on image) is not informative of the spatial configuration of the image, but keeps the texture characteristics of the original scene so that we could probably decide whether the scene is a natural or man-made environment (Oliva and Torralba, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 175
                            }
                        ],
                        "text": "For higher resolution, we can define the layout of the image and identify regions with different texture qualities, and recognize the probable semantic category of the scene (Oliva and Torralba, 2001, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 197
                            }
                        ],
                        "text": "\u2026regions of the visual field, we can build a holistic and low-dimensional representation of the structure of a scene that does not require explicit segmentation of image regions and objects (as in Oliva and Torralba, 2001) and therefore require very low computational (or attentional) resources."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 89
                            }
                        ],
                        "text": "On the basis of a global spatial representation of the image, the Spatial Envelope model (Oliva and Torralba, 2001) provides a conceptual framework for the representation and the mechanisms of fast scene gist interpretation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 270
                            }
                        ],
                        "text": "\u2026(pulling local features from a 2 2 grid applied on image) is not informative of the spatial configuration of the image, but keeps the texture characteristics of the original scene so that we could probably decide whether the scene is a natural or man-made environment (Oliva and Torralba, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 183
                            }
                        ],
                        "text": "\u2026that, at least in early stages of processing, mechanisms involved in natural scene recognition may be independent from those involved in recognizing objects (Schyns and Oliva, 1994; Oliva and Torralba, 2001; Li et al., 2002; Fei Fei and Perona, 2004; Marois et al., 2004; McCotter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 3
                            }
                        ],
                        "text": "In Oliva and Torralba (2001), we introduced a holistic approach to scene recognition not only permitting to categorize the scene in its superordinate (e.g., urban, natural scene) and basic-level categories (e.g., street, mountain), but also describing its spatial layout in a meaningful way."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 373,
                                "start": 236
                            }
                        ],
                        "text": "Converging evidence from behavioral, imaging and computational studies suggest that, at least in early stages of processing, mechanisms involved in natural scene recognition may be independent from those involved in recognizing objects (Schyns and Oliva, 1994; Oliva and Torralba, 2001; Li et al., 2002; Fei Fei and Perona, 2004; Marois et al., 2004; McCotter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11664336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "869171b2f56cfeaa9b81b2626cb4956fea590a57",
            "isKey": false,
            "numCitedBy": 6523,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a computational model of the recognition of real world scenes that bypasses the segmentation and the processing of individual objects or regions. The procedure is based on a very low dimensional representation of the scene, that we term the Spatial Envelope. We propose a set of perceptual dimensions (naturalness, openness, roughness, expansion, ruggedness) that represent the dominant spatial structure of a scene. Then, we show that these dimensions may be reliably estimated using spectral and coarsely localized information. The model generates a multidimensional space in which scenes sharing membership in semantic categories (e.g., streets, highways, coasts) are projected closed together. The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category."
            },
            "slug": "Modeling-the-Shape-of-the-Scene:-A-Holistic-of-the-Oliva-Torralba",
            "title": {
                "fragments": [],
                "text": "Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059961473"
                        ],
                        "name": "Abel G. Oliva",
                        "slug": "Abel-G.-Oliva",
                        "structuredName": {
                            "firstName": "Abel",
                            "lastName": "Oliva",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abel G. Oliva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: scene recognition; gist; spatial envelope; global image feature; spatial frequency; natural image"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 209
                            }
                        ],
                        "text": "Colored surfaces, in addition to providing useful segmentation cues for parsing the image (Carson et al., 2002), also informs about semantic properties of a place, such as its probable temperature (Greene and Oliva, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 153
                            }
                        ],
                        "text": "The amount of perceptual and semantic information that observers comprehend within a glance (about 200ms) refers to the gist of the scene (for a review, Oliva, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 266
                            }
                        ],
                        "text": "Therefore, a model of scene gist should go beyond representing the principal contours or objects of the image or classifying an image into a category: it should include a description of semantic information that human observers comprehend and infer about the scene (Oliva, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 117
                            }
                        ],
                        "text": "The gist refers to the meaningful information that an observer can identify from a glimpse at a scene (Potter, 1975; Oliva, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17237792,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "80c816d748c9ece1145e7a747de1aa99284e5c24",
            "isKey": true,
            "numCitedBy": 477,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Gist-of-a-scene-Oliva",
            "title": {
                "fragments": [],
                "text": "Gist of a scene"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2287417"
                        ],
                        "name": "P. Schyns",
                        "slug": "P.-Schyns",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Schyns",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Schyns"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 275
                            }
                        ],
                        "text": "\u2026be inferred from their spatial layout (e.g., an arrangement of basic geometrical forms such as simple Geons clusters, Biederman, 1995; the spatial relationships between regions or blobs of particular size and aspect ratio, Schyns and Oliva, 1994; Sanocki and Epstein, 1997; Oliva and Schyns, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 349,
                                "start": 90
                            }
                        ],
                        "text": "The semantic category of most real-world scenes can be inferred from their spatial layout (e.g., an arrangement of basic geometrical forms such as simple Geons clusters, Biederman, 1995; the spatial relationships between regions or blobs of particular size and aspect ratio, Schyns and Oliva, 1994; Sanocki and Epstein, 1997; Oliva and Schyns, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 103
                            }
                        ],
                        "text": "The diagnosticity of colored surfaces in an image seems to be a key element of fast scene recognition (Oliva and Schyns, 2000; Goffaux et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 284,
                                "start": 262
                            }
                        ],
                        "text": "\u2026in gray levels, performance drop and participants need to see higher-resolution images before achieving the same recognition performance: the performance with a color image at 4 cycles/image is achieved at a resolution of 8 cycles/ image for a grayscale image (Oliva and Schyns, 2000, Exp. 3)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 247
                            }
                        ],
                        "text": "\u2026is obtained by encoding the organization of color blobs in the image (under this representation a view of a landscape corresponds to a blue blob on the top, a green blob on the bottom and a brownish blob in the center, e.g., Lipson et al.,\n1997; Oliva and Schyns, 2000; Carson et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 40
                            }
                        ],
                        "text": "For presentation time as short as 30ms, Oliva and Schyns (2000) observed that altering colors impaired scene recognition when color was a diagnostic feature of the scene category (e.g., forests are greenish, coasts are bluish) but it had no detrimental effect for the recognition of scenes for which\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17043497,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "f24db70b4283b56f43a94edd48d1d35e20935ef4",
            "isKey": false,
            "numCitedBy": 412,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "In this research, we aim to ground scene recognition on information other than the identity of component objects. Specifically we seek to understand the structure of color cues that allows the express recognition of scene gists. Using the L*a*b* color space we examined the conditions under which chromatic cues concur with brightness to allow a viewer to recognize scenes at a glance. Using different methods, Experiments 1 and 2 tested the hypothesis that colors do contribute when they are diagnostic (i.e., predictive) of a scene category. Experiment 3 examined the structure of colored cues at different spatial scales that are responsible for the effects of color diagnosticity reported in Experiments 1 and 2. Together, the results suggest that colored blobs at a coarse spatial scale concur with luminance cues to form the relevant spatial layout that mediates express scene recognition."
            },
            "slug": "Diagnostic-Colors-Mediate-Scene-Recognition-Oliva-Schyns",
            "title": {
                "fragments": [],
                "text": "Diagnostic Colors Mediate Scene Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The results suggest that colored blobs at a coarse spatial scale concur with luminance cues to form the relevant spatial layout that mediates express scene recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2123706"
                        ],
                        "name": "P. Lipson",
                        "slug": "P.-Lipson",
                        "structuredName": {
                            "firstName": "Pamela",
                            "lastName": "Lipson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lipson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "e.g., Carson et al., 2002;  Lipson et al., 1997;  Oliva & Schyns, 2000)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 226
                            }
                        ],
                        "text": "\u2026is obtained by encoding the organization of color blobs in the image (under this representation a view of a landscape corresponds to a blue blob on the top, a green blob on the bottom and a brownish blob in the center, e.g., Lipson et al.,\n1997; Oliva and Schyns, 2000; Carson et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206589454,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8cf3f0ea76961eca50bf26ab31e677037cab622",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Scene classification is a major open challenge in machine vision. Most solutions proposed so far such as those based on color histograms and local texture statistics cannot capture a scene's global configuration, which is critical in perceptual judgments of scene similarity. We present a novel approach, \"configural recognition\", for encoding scene class structure. The approach's main feature is its use of qualitative spatial and photometric relationships within and across regions in low resolution images. The emphasis on qualitative measures leads to enhanced generalization abilities and the use of low-resolution images renders the scheme computationally efficient. We present results on a large database of natural scenes. We also describe how qualitative scene concepts may be learned from examples."
            },
            "slug": "Configuration-based-scene-classification-and-image-Lipson-Grimson",
            "title": {
                "fragments": [],
                "text": "Configuration based scene classification and image indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel approach, \"configural recognition\", for encoding scene class structure using qualitative spatial and photometric relationships within and across regions in low resolution images and how qualitative scene concepts may be learned from examples is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2287417"
                        ],
                        "name": "P. Schyns",
                        "slug": "P.-Schyns",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Schyns",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Schyns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 224
                            }
                        ],
                        "text": "\u2026be inferred from their spatial layout (e.g., an arrangement of basic geometrical forms such as simple Geons clusters, Biederman, 1995; the spatial relationships between regions or blobs of particular size and aspect ratio, Schyns and Oliva, 1994; Sanocki and Epstein, 1997; Oliva and Schyns, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 165
                            }
                        ],
                        "text": "One remarkable aspect of human visual perception is that we are able to understand the meaning of a complex novel scene very quickly even when the image is blurred (Schyns and Oliva, 1994), or presented for only 20ms (Thorpe et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 263
                            }
                        ],
                        "text": "Instead, it illustrates the strength of spatial layout information in constraining the identity of the objects in normal conditions, which is especially evident in degraded conditions in which object identities cannot be inferred based only on local information (Schyns and Oliva, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 160
                            }
                        ],
                        "text": "If you squint, this demonstration fails, step back from the image until your\nstreet scene in HSF and the beach scene in LSF (cf. Schyns and\nfollowed by a mask, Schyns and Oliva, 1994), observers used the low spatial frequency part of hybrids (street in Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 159
                            }
                        ],
                        "text": "\u2026that, at least in early stages of processing, mechanisms involved in natural scene recognition may be independent from those involved in recognizing objects (Schyns and Oliva, 1994; Oliva and Torralba, 2001; Li et al., 2002; Fei Fei and Perona, 2004; Marois et al., 2004; McCotter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 145641722,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf85123feb2cf0ec42930ce324501fd2cd9c049c",
            "isKey": false,
            "numCitedBy": 720,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In very fast recognition tasks, scenes are identified as fast as isolated objects How can this efficiency be achieved, considering the large number of component objects and interfering factors, such as cast shadows and occlusions? Scene categories tend to have distinct and typical spatial organizations of their major components If human perceptual structures were tuned to extract this information early in processing, a coarse-to-fine process could account for efficient scene recognition A coarse description of the input scene (oriented \u201cblobs\u201d in a particular spatial organization) would initiate recognition before the identity of the objects is processed We report two experiments that contrast the respective roles of coarse and fine information in fast identification of natural scenes The first experiment investigated whether coarse and fine information were used at different stages of processing The second experiment tested whether coarse-to-fine processing accounts for fast scene categorization The data suggest that recognition occurs at both coarse and fine spatial scales By attending first to the coarse scale, the visual system can get a quick and rough estimate of the input to activate scene schemas in memory, attending to fine information allows refinement, or refutation, of the raw estimate"
            },
            "slug": "From-Blobs-to-Boundary-Edges:-Evidence-for-Time-and-Schyns-Oliva",
            "title": {
                "fragments": [],
                "text": "From Blobs to Boundary Edges: Evidence for Time- and Spatial-Scale-Dependent Scene Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The data suggest that recognition occurs at both coarse and fine spatial scales, and that attending first to the coarse scale can get a quick and rough estimate of the input to activate scene schemas in memory."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 143
                            }
                        ],
                        "text": "\u2026complexity, ruggedness, symmetry) served to establish an initial scene-centered description of the image (based on spatial layout properties, Oliva and Torralba, 2002) offering an alternative to object-centered description (where a scene is identified from labeling the objects or regions,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 188
                            }
                        ],
                        "text": "A forest would be described as \u2018\u2018an enclosed environment, with a dense isotropic texture\u2019\u2019 and a street scene would be a \u2018\u2018man-made outdoor scene, with perspective, and medium level of clutter\u2019\u2019 (Oliva and Torralba, 2001, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 175
                            }
                        ],
                        "text": "For higher resolution, we can define the layout of the image and identify regions with different texture qualities, and recognize the probable semantic category of the scene (Oliva and Torralba, 2001, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3146850,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9a21604e6db8020b9e76d89064f2b63fb875b67a",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a scene-centered representation able to provide a meaningful description of real world images at multiple levels of categorization (from superordinate to subordinate levels). The scene-centered representation is based upon the estimation of spatial envelope properties describing the shape of a scene (e.g. size, perspective, mean depth) and the nature of its content. The approach is holistic and free of segmentation phase, grouping mechanisms, 3D construction and object-centered analysis."
            },
            "slug": "Scene-Centered-Description-from-Spatial-Envelope-Oliva-Torralba",
            "title": {
                "fragments": [],
                "text": "Scene-Centered Description from Spatial Envelope Properties"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The scene-centered representation is based upon the estimation of spatial envelope properties describing the shape of a scene and the nature of its content and is holistic and free of segmentation phase, grouping mechanisms, 3D construction and object-centered analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Biologically Motivated Computer Vision"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 255
                            }
                        ],
                        "text": "\u2026that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; Oliva and Torralba, 2001; Torralba and Oliva, 2003; McCotter et al., 2005) and can help to predict the presence or absence of objects in natural images (Torralba, 2003a; Torralba and Oliva, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 253
                            }
                        ],
                        "text": "\u2026real-world scenes (global contextual priming, Torralba 2003a) and, on the other hand, provide a formal instance of a feed-forward mechanism for scene context evaluation, for the guidance of attention and eye movements in the scene (Oliva et al., 2003; Torralba, 2003a,b; Torralba et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "... image analysis but serve as a parallel pathway that can, on the one hand, quickly constrain local analysis, narrowing down the search for object in cluttered, real world scenes (global contextual priming, Torralba 2003a) and, on the other hand, provide a formal instance of a feed-forward mechanism for scene context evaluation, for the guidance of attention and eye movements in the scene (Oliva et al., 2003; Torralba et al., submitted;   ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Global image features and the spatial envelope representation are not meant to be an alternative to local image analysis but serve as a parallel pathway that can, on the one hand, quickly constrain local analysis, narrowing down the search for object in cluttered, real world scenes (global contextual priming,  Torralba 2003a ) and, on the other hand, provide a formal instance of a feed-forward mechanism for scene context evaluation, for the ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 149
                            }
                        ],
                        "text": "\u2026on the one hand, quickly constrain local analysis, narrowing down the search for object in cluttered, real-world scenes (global contextual priming, Torralba 2003a) and, on the other hand, provide a formal instance of a feed-forward mechanism for scene context evaluation, for the guidance of\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In addition to color, research has shown that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; McCotter et al., 2005; Oliva & Torralba, 2001; Torralba & Oliva, 2003) and can help to predict the presence or absence of objects in natural images ( Torralba, 2003a;  Torralba & Oliva, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7160604,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "4e8862366617f9ce13d603ac9311d396fb2d2e25",
            "isKey": false,
            "numCitedBy": 280,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "Models of visual attention have focused predominantly on bottom-up approaches that ignored structured contextual and scene information. I propose a model of contextual cueing for attention guidance based onthe global scene configuration. It is shown that the statistics of low-level features across the whole image can be used to prime the presence or absence of objects in the scene and to predict their location, scale, and appearance before exploring the image. In this scheme, visual context information can become available early in the visual processing chain, which allows modulation of the saliency of image regions and provides an efficient shortcut for object detection and recognition."
            },
            "slug": "Modeling-global-scene-factors-in-attention.-Torralba",
            "title": {
                "fragments": [],
                "text": "Modeling global scene factors in attention."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the statistics of low-level features across the whole image can be used to prime the presence or absence of objects in the scene and to predict their location, scale, and appearance before exploring the image."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics, image science, and vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116855406"
                        ],
                        "name": "Aude Olivia",
                        "slug": "Aude-Olivia",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Olivia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aude Olivia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35118156"
                        ],
                        "name": "Michael L. Mack",
                        "slug": "Michael-L.-Mack",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Mack",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael L. Mack"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2520964"
                        ],
                        "name": "M. Shrestha",
                        "slug": "M.-Shrestha",
                        "structuredName": {
                            "firstName": "Mochan",
                            "lastName": "Shrestha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shrestha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118261291"
                        ],
                        "name": "Angela S. Peeper",
                        "slug": "Angela-S.-Peeper",
                        "structuredName": {
                            "firstName": "Angela",
                            "lastName": "Peeper",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Angela S. Peeper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 131
                            }
                        ],
                        "text": "There are other important global scene properties that are not shown here (For instance, visual complexity is not represented here (Oliva et al., 2004), and color is also not"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8049814,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "e3690f7d8eebd147c3451ce723c1070d3e6b4fd2",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Scenes are composed of numerous objects, textures and colors which are arranged in a variety of spatial layouts. This presents the question of how visual complexity is represented by a cognitive system. In this paper, we aim to study the representation of visual complexity for real-world scene images. Is visual complexity a perceptual property simple enough so that it can be compressed along a unique perceptual dimension? Or is visual complexity better represented by a multi-dimensional space? Thirty-four participants performed a hierarchical grouping task in which they divided scenes into successive groups of decreasing complexity, describing the criteria they used at each stage. Half of the participants were told that complexity was related to the structure of the image whereas the instructions in the other half were unspecified. Results are consistent with a multi-dimensional representation of visual complexity (quantity of objects, clutter, openness, symmetry, organization, variety of colors) with task constraints modulating the shape of the complexity space (e.g. the weight of a specific dimension)."
            },
            "slug": "Identifying-the-Perceptual-Dimensions-of-Visual-of-Olivia-Mack",
            "title": {
                "fragments": [],
                "text": "Identifying the Perceptual Dimensions of Visual Complexity of Scenes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 266
                            }
                        ],
                        "text": "Building a scene representation from global image features\nHigh-level properties of a scene such as the degree of perspective or the mean depth of the space that the scene subtends have been found to be correlated with the configuration of low-level image features (Torralba and Oliva, 2002, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 129
                            }
                        ],
                        "text": "This permits to evaluate the degree of openness or mean depth of an image by measuring the distribution of\nlocal-image features (Torralba and Oliva, 2002, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 147
                            }
                        ],
                        "text": "\u2026research has shown that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; Oliva and Torralba, 2001; Torralba and Oliva, 2003; McCotter et al., 2005) and can help to predict the presence or absence of objects in natural images (Torralba, 2003a;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 272
                            }
                        ],
                        "text": "\u2026that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; Oliva and Torralba, 2001; Torralba and Oliva, 2003; McCotter et al., 2005) and can help to predict the presence or absence of objects in natural images (Torralba, 2003a; Torralba and Oliva, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11919476,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "697b45e902c9dd2f31d205f0720e7079f71db200",
            "isKey": false,
            "numCitedBy": 838,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we study the statistical properties of natural images belonging to different categories and their relevance for scene and object categorization tasks. We discuss how second-order statistics are correlated with image categories, scene scale and objects. We propose how scene categorization could be computed in a feedforward manner in order to provide top-down and contextual information very early in the visual processing chain. Results show how visual categorization based directly on low-level features, without grouping or segmentation stages, can benefit object localization and identification. We show how simple image statistics can be used to predict the presence and absence of objects in the scene before exploring the image."
            },
            "slug": "Statistics-of-natural-image-categories-Torralba-Oliva",
            "title": {
                "fragments": [],
                "text": "Statistics of natural image categories"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Results show how visual categorization based directly on low-level features, without grouping or segmentation stages, can benefit object localization and identification."
            },
            "venue": {
                "fragments": [],
                "text": "Network"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39262686"
                        ],
                        "name": "J. Steeves",
                        "slug": "J.-Steeves",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Steeves",
                            "middleNames": [
                                "K.",
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Steeves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3458413"
                        ],
                        "name": "G. Humphrey",
                        "slug": "G.-Humphrey",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Humphrey",
                            "middleNames": [
                                "Keith"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Humphrey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3048019"
                        ],
                        "name": "J. Culham",
                        "slug": "J.-Culham",
                        "structuredName": {
                            "firstName": "Jody",
                            "lastName": "Culham",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Culham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144637542"
                        ],
                        "name": "R. Menon",
                        "slug": "R.-Menon",
                        "structuredName": {
                            "firstName": "Ravi",
                            "lastName": "Menon",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Menon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153558474"
                        ],
                        "name": "A. Milner",
                        "slug": "A.-Milner",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Milner",
                            "middleNames": [
                                "David"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Milner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145989594"
                        ],
                        "name": "M. Goodale",
                        "slug": "M.-Goodale",
                        "structuredName": {
                            "firstName": "Melvyn",
                            "lastName": "Goodale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Goodale"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In a similar vein,  Steeves et al. (2004)  have shown that an individual with a profound visual form agnosia (i.e., incapable of recognizing objects based on their shape) could still identify scene pictures from colors and texture information only."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 19
                            }
                        ],
                        "text": "In a similar vein, Steeves et al. (2004) have shown that an individual with a profound visual form agnosia (i.e., incapable of recognizing objects based on their shape) could still identify scene pictures from colors and texture information only."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16636226,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "a4c5dbecd638b12deecc3363df0f24f05b53b45d",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "A common notion is that object perception is a necessary precursor to scene perception. Behavioral evidence suggests, however, that scene perception can operate independently of object perception. Further, neuroimaging has revealed a specialized human cortical area for viewing scenes that is anatomically distinct from areas activated by viewing objects. Here we show that an individual with visual form agnosia, D.F., who has a profound deficit in object recognition but spared color and visual texture perception, could still classify scenes and that she was fastest when the scenes were presented in the appropriate color. When scenes were presented as black-and-white images, she made a large number of errors in classification. Functional magnetic resonance imaging revealed selective activation in the parahippocampal place area (PPA) when D.F. viewed scenes. Unlike control observers, D.F. demonstrated higher activation in the PPA for scenes presented in the appropriate color than for black-and-white versions. The results demonstrate that an individual with profound form vision deficits can still use visual texture and color to classify scenesand that this intact ability is reflected in differential activation of the PPA with colored versions of scenes."
            },
            "slug": "Behavioral-and-Neuroimaging-Evidence-for-a-of-Color-Steeves-Humphrey",
            "title": {
                "fragments": [],
                "text": "Behavioral and Neuroimaging Evidence for a Contribution of Color and Texture Information to Scene Classification in a Patient with Visual Form Agnosia"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that an individual with visual form agnosia, D.F., who has a profound deficit in object recognition but spared color and visual texture perception, could still classify scenes and that she was fastest when the scenes were presented in the appropriate color."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 266
                            }
                        ],
                        "text": "Building a scene representation from global image features\nHigh-level properties of a scene such as the degree of perspective or the mean depth of the space that the scene subtends have been found to be correlated with the configuration of low-level image features (Torralba and Oliva, 2002, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 129
                            }
                        ],
                        "text": "This permits to evaluate the degree of openness or mean depth of an image by measuring the distribution of\nlocal-image features (Torralba and Oliva, 2002, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 168
                            }
                        ],
                        "text": "As the volume of scene space increases, the perceived image on the retina changes from large surfaces to smaller pieces, increasing the high spatial frequency content (Torralba and Oliva, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7138552,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "acf0b6745708457a53d5327eea345c0bcf466e97",
            "isKey": false,
            "numCitedBy": 333,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "In the absence of cues for absolute depth measurements as binocular disparity, motion, or defocus, the absolute distance between the observer and a scene cannot be measured. The interpretation of shading, edges, and junctions may provide a 3D model of the scene but it will not provide information about the actual \"scale\" of the space. One possible source of information for absolute depth estimation is the image size of known objects. However, object recognition, under unconstrained conditions, remains difficult and unreliable for current computational approaches. We propose a source of information for absolute depth estimation based on the whole scene structure that does not rely on specific objects. We demonstrate that, by recognizing the properties of the structures present in the image, we can infer the scale of the scene and, therefore, its absolute mean depth. We illustrate the interest in computing the mean depth of the scene with application to scene recognition and object detection."
            },
            "slug": "Depth-Estimation-from-Image-Structure-Torralba-Oliva",
            "title": {
                "fragments": [],
                "text": "Depth Estimation from Image Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is demonstrated that, by recognizing the properties of the structures present in the image, one can infer the scale of the scene and, therefore, its absolute mean depth."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30708169"
                        ],
                        "name": "D. Navon",
                        "slug": "D.-Navon",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Navon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Navon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 58
                            }
                        ],
                        "text": "According to the global precedent hypothesis advocated by Navon (1977) and validated in numerous studies since (for a review see Kimchi, 1992), the processing of the global structure and the spatial relationships between components precede the analysis of local details."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 125
                            }
                        ],
                        "text": "Within this framework, the analysis of visual information for fast scene understanding proceeds in a global to local manner (Navon, 1977; Treisman and Gelade, 1980), but not necessarily from low to high spatial frequencies."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "aining the identities of the local image structures (Navon, 1977)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 133
                            }
                        ],
                        "text": "On the other hand, low-scale resolution is more contrasted and might be privileged in terms of temporal processing than finer scale (Navon, 1977; Sugase et al., 1999), but this perceptual advantage might be offset by higher uncertainty about the identity of the blobs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 114
                            }
                        ],
                        "text": "This misinterpretation is not an error of the visual system. aining the identities of the local image structures (Navon, 1977).\ncontours and textures of the image that is still detailed enough to recognize the image\u2019s gist."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In Oliva and Torralba (2001), we introduced a holistic approach to scene recognition not only permitting to categorize the scene in its superordinate (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14119789,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "9f7d9abb2277e924a291033d5c3d1195989e80ff",
            "isKey": true,
            "numCitedBy": 3635,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Forest-before-trees:-The-precedence-of-global-in-Navon",
            "title": {
                "fragments": [],
                "text": "Forest before trees: The precedence of global features in visual perception"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 149
                            }
                        ],
                        "text": "\u2026early stage of scene perception, either because low spatial frequency luminance boundaries bootstrap the perceptual organization of finer contours (Lindeberg, 1993), or because the sparse detection of a few contours is sufficient to predict the orientation of the neighborhood edges (Geisler et\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11998035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8385d733a5d41f79ec6cc34be147ec39f592de56",
            "isKey": false,
            "numCitedBy": 489,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents: (i) a multiscale representation of grey-level shape called the scale-space primal sketch, which makes explicit both features in scale-space and the relations between structures at different scales, (ii) a methodology for extracting significant blob-like image structures from this representation, and (iii) applications to edge detection, histogram analysis, and junction classification demonstrating how the proposed method can be used for guiding later-stage visual processes.The representation gives a qualitative description of image structure, which allows for detection of stable scales and associated regions of interest in a solely bottom-up data-driven way. In other words, it generates coarse segmentation cues, and can hence be seen as preceding further processing, which can then be properly tuned. It is argued that once such information is available, many other processing tasks can become much simpler. Experiments on real imagery demonstrate that the proposed theory gives intuitive results."
            },
            "slug": "Detecting-salient-blob-like-image-structures-and-a-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A multiscale representation of grey-level shape called the scale-space primal sketch is presented, which gives a qualitative description of image structure, which allows for detection of stable scales and associated regions of interest in a solely bottom-up data-driven way."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3526863"
                        ],
                        "name": "D. M. Parker",
                        "slug": "D.-M.-Parker",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Parker",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Parker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144579828"
                        ],
                        "name": "J. Lishman",
                        "slug": "J.-Lishman",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Lishman",
                            "middleNames": [
                                "Rowland"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lishman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47727506"
                        ],
                        "name": "J. Hughes",
                        "slug": "J.-Hughes",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hughes",
                            "middleNames": [
                                "Nolie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hughes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: scene recognition; gist; spatial envelope; global image feature; spatial frequency; natural image"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 148
                            }
                        ],
                        "text": "\u2026studies showed that within a 30-ms exposure, both low and high spatial frequency bands from a hybrid image were registered by the visual system 1 (Parker et al., 1992, 1996; Oliva and Schyns, 1997, Exp.1), but that the requirements of the task determined which scale, coarse or fine, was\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 22757767,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "bdc836b9b9842cfd9a60fbe366384e450449f255",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Factors which govern the temporal integration of spatial information were examined in a group of five experiments. A series of high-pass and low-pass spatially filtered versions of a visual scene were generated. Observers' ratings of these filtered versions of the scene for perceived image quality indicated that quality was determined both by the bandwidth of spatial information and the presence of high-spatial-frequency edge information. When sequences of three different versions of the scene were presented over an interval of 120 ms the perceived quality of the resulting composite image was determined both from the ratings of the individual components of that sequence and from the order in which these components were presented. When the order of spatial information in a sequence moved from coarse to fine detail the perceived quality of the composite image was significantly better than when the order moved from fine to coarse. This evidence of a coarse-to-fine bias in pattern integration was further investigated with a detection paradigm. The pattern of errors once again indicated that temporal integration of spatial information was superior when a coarse-to-fine mode of information delivery was employed. Taken together the data indicate that the pattern-integration mechanism has an inherent order bias and does not accumulate spatial information so efficiently when the \u2018natural\u2019 coarse-to-fine order is violated."
            },
            "slug": "Temporal-Integration-of-Spatially-Filtered-Visual-Parker-Lishman",
            "title": {
                "fragments": [],
                "text": "Temporal Integration of Spatially Filtered Visual Images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The data indicate that the pattern-integration mechanism has an inherent order bias and does not accumulate spatial information so efficiently when the \u2018natural\u2019 coarse-to-fine order is violated."
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26761657"
                        ],
                        "name": "M. McCotter",
                        "slug": "M.-McCotter",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "McCotter",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. McCotter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074568"
                        ],
                        "name": "F. Gosselin",
                        "slug": "F.-Gosselin",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Gosselin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Gosselin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2740288"
                        ],
                        "name": "Paul T. Sowden",
                        "slug": "Paul-T.-Sowden",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Sowden",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul T. Sowden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2287417"
                        ],
                        "name": "P. Schyns",
                        "slug": "P.-Schyns",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Schyns",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Schyns"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 125
                            }
                        ],
                        "text": "In addition to color, research has shown that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; Oliva and Torralba, 2001; Torralba and Oliva, 2003; McCotter et al., 2005) and can help to predict the presence or absence of objects in natural images (Torralba, 2003a; Torralba and Oliva, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 373,
                                "start": 236
                            }
                        ],
                        "text": "Converging evidence from behavioral, imaging and computational studies suggest that, at least in early stages of processing, mechanisms involved in natural scene recognition may be independent from those involved in recognizing objects (Schyns and Oliva, 1994; Oliva and Torralba, 2001; Li et al., 2002; Fei Fei and Perona, 2004; Marois et al., 2004; McCotter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 154
                            }
                        ],
                        "text": "\u2026that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; Oliva and Torralba, 2001; Torralba and Oliva, 2003; McCotter et al., 2005) and can help to predict the presence or absence of objects in natural images (Torralba, 2003a; Torralba and Oliva, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 273
                            }
                        ],
                        "text": "\u2026that, at least in early stages of processing, mechanisms involved in natural scene recognition may be independent from those involved in recognizing objects (Schyns and Oliva, 1994; Oliva and Torralba, 2001; Li et al., 2002; Fei Fei and Perona, 2004; Marois et al., 2004; McCotter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14725878,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "86a6ee4562c153a382ab6378d08075750d173712",
            "isKey": true,
            "numCitedBy": 67,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite the complexity and diversity of natural scenes, humans are very fast and accurate at identifying basic-level scene categories. In this paper we develop a new technique (based on Bubbles, Gosselin & Schyns, 2001a; Schyns, Bonnar, & Gosselin, 2002) to determine some of the information requirements of basic-level scene categorizations. Using 2400 scenes from an established scene database (Oliva & Torralba, 2001), the algorithm randomly samples the Fourier coefficients of the phase spectrum. Sampled Fourier coefficients retain their original phase while the phase of nonsampled coefficients is replaced with that of white noise. Observers categorized the stimuli into 8 basic-level categories. The location of the sampled Fourier coefficients leading to correct categorizations was recorded per trial. Statistical analyses revealed the major scales and orientations of the phase spectrum that observers used to distinguish scene categories."
            },
            "slug": "The-use-of-visual-information-in-natural-scenes-McCotter-Gosselin",
            "title": {
                "fragments": [],
                "text": "The use of visual information in natural scenes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2653462"
                        ],
                        "name": "Ronald A. Rensink",
                        "slug": "Ronald-A.-Rensink",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rensink",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald A. Rensink"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6740010,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "00e64fb34f407f5939612481ebc93a44d571c9c7",
            "isKey": false,
            "numCitedBy": 866,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the more powerful impressions created by vision is that of a coherent, richly detailed world where everything is present simultaneously. Indeed, this impression is so compelling that we tend to ascribe these properties not only to the external world, but to our internal representations as well. But results from several recent experiments argue against this latter ascription. For example, changes in images of real-world scenes often go unnoticed when made during a saccade, flicker, blink, or movie cut. This \u201cchange blindness\u201d provides strong evidence against the idea that our brains contain a picture-like representation of the scene that is everywhere detailed and coherent.\r\nHow then do we represent a scene? It is argued here that focused attention provides spatiotemporal coherence for the stable representation of one object at a time. It is then argued that the allocation of attention can be co-ordinated to create a \u201cvirtual representation\u201d. In such a scheme, a stable object representation is formed whenever needed, making it appear to higher levels as if all objects in the scene are represented in detail simultaneously."
            },
            "slug": "The-Dynamic-Representation-of-Scenes-Rensink",
            "title": {
                "fragments": [],
                "text": "The Dynamic Representation of Scenes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3303774"
                        ],
                        "name": "L. Renninger",
                        "slug": "L.-Renninger",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Renninger",
                            "middleNames": [
                                "Walker"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Renninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14694860,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d0632c640086bdde66066542a4670d5e165ef381",
            "isKey": false,
            "numCitedBy": 251,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "When-is-scene-identification-just-texture-Renninger-Malik",
            "title": {
                "fragments": [],
                "text": "When is scene identification just texture recognition?"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398995671"
                        ],
                        "name": "Michel Vidal-Naquet",
                        "slug": "Michel-Vidal-Naquet",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Vidal-Naquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michel Vidal-Naquet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35195550"
                        ],
                        "name": "E. Sali",
                        "slug": "E.-Sali",
                        "structuredName": {
                            "firstName": "Erez",
                            "lastName": "Sali",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sali"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 271
                            }
                        ],
                        "text": "Note that the spatial envelope properties (e.g., openness, naturalness, expansion, symmetry) are implemented here as a weighted combination of global features, but spatial envelope properties could also be derived from other basis of low- or intermediate-level features (Ullman et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 236
                            }
                        ],
                        "text": "Research over the last decade has made substantial progress toward understanding the brain\nmechanisms underlying human object recognition (Kanwisher, 2003; Grill-Spector and Malach, 2004) and its modeling (Riesenhuber and Poggio, 1999; Ullman et al., 2002; Torralba et al., 2004; Serre et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 223
                            }
                        ],
                        "text": ", openness, naturalness, expansion, symmetry) are implemented here as a weighted combination of global features, but spatial envelope properties could also be derived from other basis of low- or intermediate-level features (Ullman et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 114
                            }
                        ],
                        "text": "mechanisms underlying human object recognition (Kanwisher, 2003; Grill-Spector and Malach, 2004) and its modeling (Riesenhuber and Poggio, 1999; Ullman et al., 2002; Torralba et al., 2004; Serre et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 205441432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d52be22dc0033293d335b6dc5cf3e3588c1fc0bc",
            "isKey": true,
            "numCitedBy": 655,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The human visual system analyzes shapes and objects in a series of stages in which stimulus features of increasing complexity are extracted and analyzed. The first stages use simple local features, and the image is subsequently represented in terms of larger and more complex features. These include features of intermediate complexity and partial object views. The nature and use of these higher-order representations remains an open question in the study of visual processing by the primate cortex. Here we show that intermediate complexity (IC) features are optimal for the basic visual task of classification. Moderately complex features are more informative for classification than very simple or very complex ones, and so they emerge naturally by the simple coding principle of information maximization with respect to a class of images. Our findings suggest a specific role for IC features in visual processing and a principle for their extraction."
            },
            "slug": "Visual-features-of-intermediate-complexity-and-use-Ullman-Vidal-Naquet",
            "title": {
                "fragments": [],
                "text": "Visual features of intermediate complexity and their use in classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that intermediate complexity (IC) features are optimal for the basic visual task of classification and suggest a specific role for IC features in visual processing and a principle for their extraction."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060684"
                        ],
                        "name": "M. Castelhano",
                        "slug": "M.-Castelhano",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Castelhano",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Castelhano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144897958"
                        ],
                        "name": "J. Henderson",
                        "slug": "J.-Henderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Henderson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Henderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 272
                            }
                        ],
                        "text": "\u2026real-world scenes (global contextual priming, Torralba 2003a) and, on the other hand, provide a formal instance of a feed-forward mechanism for scene context evaluation, for the guidance of attention and eye movements in the scene (Oliva et al., 2003; Torralba, 2003a,b; Torralba et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5875815,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b35e4d00d9a9bfae83a8b0914eb1073a77a11d78",
            "isKey": false,
            "numCitedBy": 1566,
            "numCiting": 144,
            "paperAbstract": {
                "fragments": [],
                "text": "Many experiments have shown that the human visual system makes extensive use of contextual information for facilitating object search in natural scenes. However, the question of how to formally model contextual influences is still open. On the basis of a Bayesian framework, the authors present an original approach of attentional guidance by global scene context. The model comprises 2 parallel pathways; one pathway computes local features (saliency) and the other computes global (scene-centered) features. The contextual guidance model of attention combines bottom-up saliency, scene context, and top-down mechanisms at an early stage of visual processing and predicts the image regions likely to be fixated by human observers performing natural search tasks in real-world scenes."
            },
            "slug": "Contextual-guidance-of-eye-movements-and-attention-Torralba-Oliva",
            "title": {
                "fragments": [],
                "text": "Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An original approach of attentional guidance by global scene context is presented that combines bottom-up saliency, scene context, and top-down mechanisms at an early stage of visual processing and predicts the image regions likely to be fixated by human observers performing natural search tasks in real-world scenes."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741887"
                        ],
                        "name": "M. Bar",
                        "slug": "M.-Bar",
                        "structuredName": {
                            "firstName": "Moshe",
                            "lastName": "Bar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 47
                            }
                        ],
                        "text": "In a related vein, Bar (Bar and Aminoff, 2003; Bar, 2004) found specific cortical regions (a network relating regions in the parahippocampal region and the retrosplenial cortex) involved in the analysis of the context of objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "Thanks to Michelle Greene, Barbara Hidalgo-Sotelo, Naomi Kenner, Talia Konkle and Thomas Serre for comments on the manuscript."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 380,
                                "start": 377
                            }
                        ],
                        "text": "The vocabulary given by observers (naturalness, openness, expansion, depth, roughness, complexity, ruggedness, symmetry) served to establish an initial scene-centered description of the image (based on spatial layout properties, Oliva and Torralba, 2002) offering an alternative to object-centered description (where a scene is identified from labeling the objects or regions, Barnard and Forsyth, 2001; Carson et al., 2002)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 205499985,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "bf12813b219ce0730f123bbd3e9c9227d0934f0b",
            "isKey": false,
            "numCitedBy": 1357,
            "numCiting": 178,
            "paperAbstract": {
                "fragments": [],
                "text": "We see the world in scenes, where visual objects occur in rich surroundings, often embedded in a typical context with other related objects. How does the human brain analyse and use these common associations? This article reviews the knowledge that is available, proposes specific mechanisms for the contextual facilitation of object recognition, and highlights important open questions. Although much has already been revealed about the cognitive and cortical mechanisms that subserve recognition of individual objects, surprisingly little is known about the neural underpinnings of contextual analysis and scene perception. Building on previous findings, we now have the means to address the question of how the brain integrates individual elements to construct the visual experience."
            },
            "slug": "Visual-objects-in-context-Bar",
            "title": {
                "fragments": [],
                "text": "Visual objects in context"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Building on previous findings, the knowledge that is available is reviewed, specific mechanisms for the contextual facilitation of object recognition are proposed, and important open questions are highlighted."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Reviews Neuroscience"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2969789"
                        ],
                        "name": "C. Carson",
                        "slug": "C.-Carson",
                        "structuredName": {
                            "firstName": "Chad",
                            "lastName": "Carson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Carson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143942875"
                        ],
                        "name": "H. Greenspan",
                        "slug": "H.-Greenspan",
                        "structuredName": {
                            "firstName": "Hayit",
                            "lastName": "Greenspan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Greenspan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "e.g.,  Carson et al., 2002;  Lipson et al., 1997; Oliva & Schyns, 2000)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The vocabulary given by observers (naturalness, openness, expansion, depth, roughness, complexity, ruggedness, symmetry) served to establish an initial scene-centered description of the image (based on spatial layout properties, Oliva and Torralba, 2002) offering an alternative to object-centered description (where a scene is identified from labeling the objects or regions, Barnard and Forsyth, 2001;  Carson et al., 2002 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 91
                            }
                        ],
                        "text": "Colored surfaces, in addition to providing useful segmentation cues for parsing the image (Carson et al., 2002), also informs about semantic properties of a place, such as its probable temperature (Greene and Oliva, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 271
                            }
                        ],
                        "text": "\u2026is obtained by encoding the organization of color blobs in the image (under this representation a view of a landscape corresponds to a blue blob on the top, a green blob on the bottom and a brownish blob in the center, e.g., Lipson et al.,\n1997; Oliva and Schyns, 2000; Carson et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 277
                            }
                        ],
                        "text": "\u2026to establish an initial scene-centered description of the image (based on spatial layout properties, Oliva and Torralba, 2002) offering an alternative to object-centered description (where a scene is identified from labeling the objects or regions, Barnard and Forsyth, 2001; Carson et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14715074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fedf7729b620ec2cf4e79705d2898f82e9a2ba66",
            "isKey": true,
            "numCitedBy": 1629,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Retrieving images from large and varied collections using image content as a key is a challenging and important problem. We present a new image representation that provides a transformation from the raw pixel data to a small set of image regions that are coherent in color and texture. This \"Blobworld\" representation is created by clustering pixels in a joint color-texture-position feature space. The segmentation algorithm is fully automatic and has been run on a collection of 10,000 natural images. We describe a system that uses the Blobworld representation to retrieve images from this collection. An important aspect of the system is that the user is allowed to view the internal representation of the submitted image and the query results. Similar systems do not offer the user this view into the workings of the system; consequently, query results from these systems can be inexplicable, despite the availability of knobs for adjusting the similarity metrics. By finding image regions that roughly correspond to objects, we allow querying at the level of objects rather than global image properties. We present results indicating that querying for images using Blobworld produces higher precision than does querying using color and texture histograms of the entire image in cases where the image contains distinctive objects."
            },
            "slug": "Blobworld:-Image-Segmentation-Using-and-Its-to-Carson-Belongie",
            "title": {
                "fragments": [],
                "text": "Blobworld: Image Segmentation Using Expectation-Maximization and Its Application to Image Querying"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results indicating that querying for images using Blobworld produces higher precision than does querying using color and texture histograms of the entire image in cases where the image contains distinctive objects are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34854785"
                        ],
                        "name": "Russell A. Epstein",
                        "slug": "Russell-A.-Epstein",
                        "structuredName": {
                            "firstName": "Russell",
                            "lastName": "Epstein",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Russell A. Epstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1931482"
                        ],
                        "name": "N. Kanwisher",
                        "slug": "N.-Kanwisher",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Kanwisher",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kanwisher"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 77
                            }
                        ],
                        "text": "Their fMRI study revealed higher activity in the parahippocampal place area (Epstein and Kanwisher, 1998) when the agnostic patient was viewing normally colored scenes pictures than when she was viewing black and white pictures."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 146
                            }
                        ],
                        "text": "Furthermore, the PPA seems to be sensitive to holistic properties of the scene layout, but not to its complexity in terms of\nquantity of objects (Epstein and Kanwisher, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 171
                            }
                        ],
                        "text": "Evidence in favor of distinct neural mechanisms supporting scene and object recognition, at least at an earlier stage of visual processing, comes from the pioneer work of Epstein and Kanwisher (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 920141,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "46ec521e3f4c89218db0292a097f0f44d17c753d",
            "isKey": true,
            "numCitedBy": 2725,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Medial temporal brain regions such as the hippocampal formation and parahippocampal cortex have been generally implicated in navigation and visual memory. However, the specific function of each of these regions is not yet clear. Here we present evidence that a particular area within human parahippocampal cortex is involved in a critical component of navigation: perceiving the local visual environment. This region, which we name the \u2018parahippocampal place area\u2019 (PPA), responds selectively and automatically in functional magnetic resonance imaging (fMRI) to passively viewed scenes, but only weakly to single objects and not at all to faces. The critical factor for this activation appears to be the presence in the stimulus of information about the layout of local space. The response in the PPA to scenes with spatial layout but no discrete objects (empty rooms) is as strong as the response to complex meaningful scenes containing multiple objects (the same rooms furnished) and over twice as strong as the response to arrays of multiple objects without three-dimensional spatial context (the furniture from these rooms on a blank background). This response is reduced if the surfaces in the scene are rearranged so that they no longer define a coherent space. We propose that the PPA represents places by encoding the geometry of the local environment."
            },
            "slug": "A-cortical-representation-of-the-local-visual-Epstein-Kanwisher",
            "title": {
                "fragments": [],
                "text": "A cortical representation of the local visual environment"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Evidence is presented that a particular area within human parahippocampal cortex is involved in a critical component of navigation: perceiving the local visual environment, and it is proposed that the PPA represents places by encoding the geometry of the local environment."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2966196"
                        ],
                        "name": "W. Geisler",
                        "slug": "W.-Geisler",
                        "structuredName": {
                            "firstName": "Wilson",
                            "lastName": "Geisler",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Geisler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16656212"
                        ],
                        "name": "J. Perry",
                        "slug": "J.-Perry",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Perry",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Perry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3221174"
                        ],
                        "name": "B. Super",
                        "slug": "B.-Super",
                        "structuredName": {
                            "firstName": "Boaz",
                            "lastName": "Super",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Super"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4536179"
                        ],
                        "name": "D. P. Gallogly",
                        "slug": "D.-P.-Gallogly",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Gallogly",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. P. Gallogly"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 276
                            }
                        ],
                        "text": "\u2026that are further apart tend to have more disparate\n1A hybrid scene presented for 30 ms and then masked would prime the recognition of a subsequent related scene, matching either the low- or the high-spatial scale of the hybrid (Oliva and Schyns, 1997, Exp. 1).\norientations (Geisler et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Moreover, statistical analysis of the distributions of orientations in natural images has shown that adjacent contours tend to have similar orientations whereas segments of the same contour that are further apart tend to have more disparate orientations ( Geisler et al., 2001 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 169
                            }
                        ],
                        "text": "\u2026organization of finer contours (Lindeberg, 1993), or because the sparse detection of a few contours is sufficient to predict the orientation of the neighborhood edges (Geisler et al., 2001), or because selective attention was attending to information at a finer scale (Oliva and Schyns, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2362588,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "5777e5fb5d0c00aa9e6a8edc8893f174486a235d",
            "isKey": false,
            "numCitedBy": 653,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Edge-co-occurrence-in-natural-images-predicts-Geisler-Perry",
            "title": {
                "fragments": [],
                "text": "Edge co-occurrence in natural images predicts contour grouping performance"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 253
                            }
                        ],
                        "text": "\u2026real-world scenes (global contextual priming, Torralba 2003a) and, on the other hand, provide a formal instance of a feed-forward mechanism for scene context evaluation, for the guidance of attention and eye movements in the scene (Oliva et al., 2003; Torralba, 2003a,b; Torralba et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 149
                            }
                        ],
                        "text": "\u2026on the one hand, quickly constrain local analysis, narrowing down the search for object in cluttered, real-world scenes (global contextual priming, Torralba 2003a) and, on the other hand, provide a formal instance of a feed-forward mechanism for scene context evaluation, for the guidance of\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 255
                            }
                        ],
                        "text": "\u2026that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; Oliva and Torralba, 2001; Torralba and Oliva, 2003; McCotter et al., 2005) and can help to predict the presence or absence of objects in natural images (Torralba, 2003a; Torralba and Oliva, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1073705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c99f2391b956dc189855541e49e53c21ae5ec603",
            "isKey": false,
            "numCitedBy": 888,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "There is general consensus that context can be a rich source of information about an object's identity, location and scale. In fact, the structure of many real-world scenes is governed by strong configurational rules akin to those that apply to a single object. Here we introduce a simple framework for modeling the relationship between context and object properties based on the correlation between the statistics of low-level features across the entire scene and the objects that it contains. The resulting scheme serves as an effective procedure for object priming, context driven focus of attention and automatic scale-selection on real-world scenes."
            },
            "slug": "Contextual-Priming-for-Object-Detection-Torralba",
            "title": {
                "fragments": [],
                "text": "Contextual Priming for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A simple framework for modeling the relationship between context and object properties based on the correlation between the statistics of low-level features across the entire scene and the objects that it contains serves as an effective procedure for object priming, context driven focus of attention and automatic scale-selection on real-world scenes."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2287417"
                        ],
                        "name": "P. Schyns",
                        "slug": "P.-Schyns",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Schyns",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Schyns"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 150
                            }
                        ],
                        "text": "\u2026that this result is not a evidence for a preference of the low spatial frequencies in the early stages of visual processing: additional experiments (Oliva and Schyns, 1997; Schyns and Oliva, 1999) showed that, in fact, the visual system can select which spatial scale to process depending on task\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 174
                            }
                        ],
                        "text": "It is important to stress that this result is not a evidence for a preference of the low spatial frequencies in the early stages of visual processing: additional experiments (Oliva and Schyns, 1997; Schyns and Oliva, 1999) showed that, in fact, the visual system can select which spatial scale to process depending on task constraints (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 86
                            }
                        ],
                        "text": ", 2001), or because selective attention was attending to information at a finer scale (Oliva and Schyns, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 270
                            }
                        ],
                        "text": "\u2026organization of finer contours (Lindeberg, 1993), or because the sparse detection of a few contours is sufficient to predict the orientation of the neighborhood edges (Geisler et al., 2001), or because selective attention was attending to information at a finer scale (Oliva and Schyns, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 229
                            }
                        ],
                        "text": "\u2026that are further apart tend to have more disparate\n1A hybrid scene presented for 30 ms and then masked would prime the recognition of a subsequent related scene, matching either the low- or the high-spatial scale of the hybrid (Oliva and Schyns, 1997, Exp. 1).\norientations (Geisler et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 148
                            }
                        ],
                        "text": "\u2026a 30-ms exposure, both low and high spatial frequency bands from a hybrid image were registered by the visual system 1 (Parker et al., 1992, 1996; Oliva and Schyns, 1997, Exp.1), but that the requirements of the task determined which scale, coarse or fine, was preferentially selected for covert\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2644477,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "48f0d6211dc70a56202c1a0c95124c65a51f721f",
            "isKey": false,
            "numCitedBy": 437,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "Efficient categorizations of complex visual stimuli require effective encodings of their distinctive properties. However, the question remains of how processes of object and scene categorization use the information associated with different perceptual spatial scales. The psychophysics of scale perception suggests that recognition uses coarse blobs before fine scale edges, because the former is perceptually available before the latter. Although possible, this perceptually determined scenario neglects the nature of the task the recognition system must solve. If different spatial scales transmit different information about the input, an identical scene might be flexibly encoded and perceived at the scale that optimizes information for the considered task-i.e., the diagnostic scale. This paper tests the hypothesis that scale diagnosticity can determine scale selection for recognition. Experiment 1 tested whether coarse and fine spatial scales were both available at the onset of scene categorization. The second experiment tested that the selection of one scale could change depending on the diagnostic information present at this scale. The third and fourth experiments investigated whether scale-specific cues were independently processed, or whether they perceptually cooperated in the recognition of the input scene. Results suggest that a mandatory low-level registration of multiple spatial scales promotes flexible scene encodings, perceptions, and categorizations."
            },
            "slug": "Coarse-Blobs-or-Fine-Edges-Evidence-That-Changes-of-Oliva-Schyns",
            "title": {
                "fragments": [],
                "text": "Coarse Blobs or Fine Edges? Evidence That Information Diagnosticity Changes the Perception of Complex Visual Stimuli"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper tests the hypothesis that scale diagnosticity can determine scale selection for recognition and suggests that a mandatory low-level registration of multiple spatial scales promotes flexible scene encodings, perceptions, and categorizations."
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717172"
                        ],
                        "name": "J. Wolfe",
                        "slug": "J.-Wolfe",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Wolfe",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wolfe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074098890"
                        ],
                        "name": "Sara C. Bennett",
                        "slug": "Sara-C.-Bennett",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Bennett",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sara C. Bennett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 16189579,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7b1ad97b8abaca591e9142e64173d1e6e509245",
            "isKey": false,
            "numCitedBy": 354,
            "numCiting": 141,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Preattentive-Object-Files:-Shapeless-Bundles-of-Wolfe-Bennett",
            "title": {
                "fragments": [],
                "text": "Preattentive Object Files: Shapeless Bundles of Basic Features"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502152"
                        ],
                        "name": "A. Treisman",
                        "slug": "A.-Treisman",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Treisman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Treisman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3662180"
                        ],
                        "name": "G. Gelade",
                        "slug": "G.-Gelade",
                        "structuredName": {
                            "firstName": "Garry",
                            "lastName": "Gelade",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gelade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 123
                            }
                        ],
                        "text": "Most of the contours in natural scenes need selective attention to be bound together to form a shape of higher complexity (Treisman and Gelade, 1980; Wolfe and Bennet, 1997; Wolfe et al., 2002), but contours persistent through the scale space might need fewer attentional (or computational)\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Within this framework, the analysis of visual information for fast scene understanding proceeds in a global to local manner (Navon, 1977;  Treisman and Gelade, 1980 ), but not necessarily from low to high spatial frequencies."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Most of the contours in natural scenes need selective attention to be bound together to form a shape of higher complexity ( Treisman and Gelade, 1980;  Wolfe and Bennet, 1997; Wolfe et al., 2002), but contours persistent through the scale space might need fewer attentional (or computational) resources to be represented early on. Therefore, one cannot dismiss the possibility that the analysis of fine contours and texture characteristics could ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 138
                            }
                        ],
                        "text": "Within this framework, the analysis of visual information for fast scene understanding proceeds in a global to local manner (Navon, 1977; Treisman and Gelade, 1980), but not necessarily from low to high spatial frequencies."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 138
                            }
                        ],
                        "text": "To clarify the terminology we will be using in this article, in the same way that \u2018\u2018red\u2019\u2019 and \u2018\u2018vertical\u2019\u2019 are local feature values of an object (Treisman and Gelade, 1980), a specific configuration of local features defines a global feature value of a scene or an object."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "To clarify the terminology we will be using in this article, in the same way that \u201cred\u201d and \u201cvertical\u201d are local feature values of an object ( Treisman & Gelade, 1980 ), a specific configuration of local features define a global feature value of a scene or an object."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 353246,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "76361a44e145732a39dbc68d9418871038c83be2",
            "isKey": true,
            "numCitedBy": 11415,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-feature-integration-theory-of-attention-Treisman-Gelade",
            "title": {
                "fragments": [],
                "text": "A feature-integration theory of attention"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3082093"
                        ],
                        "name": "M. Tarr",
                        "slug": "M.-Tarr",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Tarr",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tarr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423436"
                        ],
                        "name": "Q. Vuong",
                        "slug": "Q.-Vuong",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Vuong",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Vuong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 149
                            }
                        ],
                        "text": "\u2026of most real-world scenes can be inferred from their spatial layout (e.g., an arrangement of basic geometrical forms such as simple Geons clusters, Biederman, 1995; the spatial relationships between regions or blobs of particular size and aspect ratio, Schyns and Oliva, 1994; Sanocki and Epstein,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5427717,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "f8b8b4204a87c263e71e571e411894b0f17e296e",
            "isKey": false,
            "numCitedBy": 696,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "Object recognition concerns itself with two questions: What is the form of object representation? and How do observers match object percepts to object representations? Many objects look similar and most contain no single feature that uniquely identifies them. Furthermore, objects are rarely seen under identical viewing conditions: Objects change their size, position, orientation, and relations between parts, viewers move about, and sources of illumination turn on and off or move. Successful object recognition requires generalizing across such changes. Two different approaches to these issues have been adopted. Viewpoint-invariant theories assume that there are specific invariant cues to object identity that may be recovered under almost all viewing conditions. Viewpoint-dependent theories suggest that no such general invariants exist and that object features are represented much as they appeared when originally viewed, thereby preserving shape information and surface appearance. Despite many differences, theories of object recognition include some common principles. These include the decomposition of an image into component features, the coding of the spatial relations between such features, multiple views to represent feature sets arising from different object viewpoints, generalization mechanisms to normalize over changes in viewing conditions, and the flexibility to support recognition tasks ranging from item-specific individuation to basic-level categorization. \n \n \nKeywords: \n \nframes of reference; \nimage normalization; \nimage-based models; \nstructural description models; \nviewpoint-dependent recognition; \nviewpoint-invariant recognition"
            },
            "slug": "Visual-object-recognition-Tarr-Vuong",
            "title": {
                "fragments": [],
                "text": "Visual Object Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1981539"
                        ],
                        "name": "Thomas Serre",
                        "slug": "Thomas-Serre",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Serre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Serre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145128145"
                        ],
                        "name": "Lior Wolf",
                        "slug": "Lior-Wolf",
                        "structuredName": {
                            "firstName": "Lior",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lior Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 260426,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "040c23e5a409fbdedd5032263dfcb1a4d7dfd200",
            "isKey": false,
            "numCitedBy": 969,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel set of features for robust object recognition. Each element of this set is a complex feature obtained by combining position- and scale-tolerant edge-detectors over neighboring positions and multiple orientations. Our system's architecture is motivated by a quantitative model of visual cortex. We show that our approach exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories. We also demonstrate that our system is able to learn from very few examples. The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex."
            },
            "slug": "Object-recognition-with-features-inspired-by-visual-Serre-Wolf",
            "title": {
                "fragments": [],
                "text": "Object recognition with features inspired by visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex and exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5980237"
                        ],
                        "name": "R. Kimchi",
                        "slug": "R.-Kimchi",
                        "structuredName": {
                            "firstName": "Ruth",
                            "lastName": "Kimchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kimchi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 101
                            }
                        ],
                        "text": "The global precedence effect is particularly strong for images constituted of many element patterns (Kimchi, 1998), as it is the case of most realworld scene pictures."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195690955,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "af7bea45f32231439933a7e92ea7ca550a5c8cc9",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "The principle of uniform connectedness (S. E. Palmer & I. Rock, 1994) states that connected regions of uniform visual properties correspond to the entry-level units of visual stimuli. The implications of this principle for the perceptual organization of hierarchical patterns were investigated in 3 experiments. Primed matching and visual search were used to examine the microgenesis of organization for patterns that vary in number and relative size of their elements. Results for the few-element patterns showed an initial representation of elements with a weaker representation of global configuration. Grouping of elements into global configuration consolidated with time and involved focused attention. The entry-level units of many-element patterns were global configuration and texture. Individuation of elements occurred later and involved focused attention. These findings are discussed with reference to processes underlying perceptual organization."
            },
            "slug": "Uniform-connectedness-and-grouping-in-the-of-Kimchi",
            "title": {
                "fragments": [],
                "text": "Uniform connectedness and grouping in the perceptual organization of hierarchical patterns."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Primed matching and visual search were used to examine the microgenesis of organization for patterns that vary in number and relative size of their elements and showed an initial representation of elements with a weaker representation of global configuration."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Human perception and performance"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060684"
                        ],
                        "name": "M. Castelhano",
                        "slug": "M.-Castelhano",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Castelhano",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Castelhano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144897958"
                        ],
                        "name": "J. Henderson",
                        "slug": "J.-Henderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Henderson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Henderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5247911,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "id": "3cc6c4b2881c5607df9d3d6bb25ed94fd0add236",
            "isKey": false,
            "numCitedBy": 517,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Current computational models of visual attention focus on bottom-up information and ignore scene context. However, studies in visual cognition show that humans use context to facilitate object detection in natural scenes by directing their attention or eyes to diagnostic regions. Here we propose a model of attention guidance based on global scene configuration. We show that the statistics of low-level features across the scene image determine where a specific object (e.g. a person) should be located. Human eye movements show that regions chosen by the top-down model agree with regions scrutinized by human observers performing a visual search task for people. The results validate the proposition that top-down information from visual context modulates the saliency of image regions during the task of object detection. Contextual information provides a shortcut for efficient object detection systems."
            },
            "slug": "Top-down-control-of-visual-attention-in-object-Oliva-Torralba",
            "title": {
                "fragments": [],
                "text": "Top-down control of visual attention in object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The results validate the proposition that top-down information from visual context modulates the saliency of image regions during the task of object detection."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2003 International Conference on Image Processing (Cat. No.03CH37429)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277853"
                        ],
                        "name": "A. Vailaya",
                        "slug": "A.-Vailaya",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Vailaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vailaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15065442,
            "fieldsOfStudy": [
                "Environmental Science",
                "Computer Science"
            ],
            "id": "c411f93539714f512e437c45a7a9d0a6d5a7675e",
            "isKey": false,
            "numCitedBy": 442,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-image-classification:-city-images-vs.-landscapes-Vailaya-Jain",
            "title": {
                "fragments": [],
                "text": "On image classification: city images vs. landscapes"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2532970"
                        ],
                        "name": "G. Rousselet",
                        "slug": "G.-Rousselet",
                        "structuredName": {
                            "firstName": "Guillaume",
                            "lastName": "Rousselet",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Rousselet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4662988"
                        ],
                        "name": "Olivier R. Joubert",
                        "slug": "Olivier-R.-Joubert",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Joubert",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olivier R. Joubert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1396645431"
                        ],
                        "name": "M. Fabre-Thorpe",
                        "slug": "M.-Fabre-Thorpe",
                        "structuredName": {
                            "firstName": "Mich\u00e8le",
                            "lastName": "Fabre-Thorpe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fabre-Thorpe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 273
                            }
                        ],
                        "text": "\u2026was faster if it belonged to a category from which the colors distributions did not vary greatly across exemplars (for natural scenes like forest, coast, canyons), than for scene categories where color distribution varied (for indoors scenes, urban environments, see also Rousselet et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8741612,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d5e992636477690f7c7e423ffcb403b4a62ca8b6",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This study aimed at assessing the processing time of a natural scene in a fast categorization task of its context or \u201cgist\u201d. In Experiment 1, human subjects performed 4 go/no-go categorization tasks in succession with colour pictures of real-world scenes belonging to 2 natural categories: \u201cSea\u201d and \u201cmountain\u201d, and 2 artificial categories: \u201cIndoor\u201d and \u201curban\u201d. Experiment 2 used colour and grey-level scenes in the same tasks to assess the role of colour cues on performance. Pictures were flashed for 26 ms. Both experiments showed that the gist of real-world scenes can be extracted with high accuracy (>90%), short median RT (400-460 ms) and early responses triggered with latencies as short as 260-300 ms. Natural scenes were processed faster than artificial scenes. Categories for which colour could have a diagnostic value were processed faster in colour than in grey. Finally, processing speed is compared for scene and object categorization tasks."
            },
            "slug": "How-long-to-get-to-the-\u201cgist\u201d-of-real-world-natural-Rousselet-Joubert",
            "title": {
                "fragments": [],
                "text": "How long to get to the \u201cgist\u201d of real-world natural scenes?"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34931109"
                        ],
                        "name": "R. Baddeley",
                        "slug": "R.-Baddeley",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Baddeley",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Baddeley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 125
                            }
                        ],
                        "text": "In addition to color, research has shown that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; Oliva and Torralba, 2001; Torralba and Oliva, 2003; McCotter et al., 2005) and can help to predict the presence or absence of objects in natural images (Torralba, 2003a; Torralba and Oliva, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 126
                            }
                        ],
                        "text": "In addition to color, research has shown that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; Oliva and Torralba, 2001; Torralba and Oliva, 2003; McCotter et al., 2005) and can help to predict the presence or absence of objects in natural images\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15990439,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "83f4aa8845b3cc37ad02d7878171f4e8cfaba02d",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Physiologists have long proposed that correlated input activity is important in normal sensory development. Here it is postulated that the visual system is sensitive to the correlation in image intensity across the visual field, and that these correlations are used to help calibrate spatial representations. Since measurements made near to each other in the visual field are more correlated than measurements made at a distance, the degree of correlation can be used as an estimate of the distance between two measurements and can therefore be used to calibrate a roughly organized spatial representation. We therefore explored the hypothesis that low level spatial representations are calibrated using a signal based on image intensity correlation. If the visual system uses input statistics to calibrate its spatial representation, then any distortions and anisotropies in these input statistics should be mirrored by distortions in the representation of space. To test the psychological implications of this hypothesis, a collection of 81 images of open and urban landscapes were used to estimate the degree of correlation between image intensity measurement pairs as a function of both distance and orientation. Doing this we show that a system that used the statistics measured to calibrate its representation would show: 1. (1) a horizontal-vertical illusion; 2. (2) the magnitude of this illusion would depend on the amount of open and urban landscapes in the environment; 3. (3) there would be a nontrivial relationship between line orientation and judged length. Analogues of all these distortions and regularities can be found in the psychophysical literature on distance estimation. This gives strength to the proposal that spatial representations are calibrated using input statistics."
            },
            "slug": "The-Correlational-Structure-of-Natural-Images-and-Baddeley",
            "title": {
                "fragments": [],
                "text": "The Correlational Structure of Natural Images and the Calibration of Spatial Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The hypothesis that low level spatial representations are calibrated using a signal based on image intensity correlation is explored and shows that a system that used input statistics to calibrate its representation would show a horizontal-vertical illusion and there would be a nontrivial relationship between line orientation and judged length."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187218"
                        ],
                        "name": "A. J. Bell",
                        "slug": "A.-J.-Bell",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Bell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 88
                            }
                        ],
                        "text": "For instance, other bases could be obtained by applying independent component analysis (Bell and Sejnowski, 1997) or searching for sparse codes (Olshausen and Field, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6219133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca1d23be869380ac9e900578c601c2d1febcc0c9",
            "isKey": false,
            "numCitedBy": 2373,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-\u201cindependent-components\u201d-of-natural-scenes-are-Bell-Sejnowski",
            "title": {
                "fragments": [],
                "text": "The \u201cindependent components\u201d of natural scenes are edge filters"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40538579"
                        ],
                        "name": "J. Vogel",
                        "slug": "J.-Vogel",
                        "structuredName": {
                            "firstName": "Julia",
                            "lastName": "Vogel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vogel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14752064,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "206ff6b47ee55303d3e0d988f0ac824014468568",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach to categorize real-world natural scenes based on a semantic typicality measure. The proposed typicality measure allows to grade the similarity of an image with respect to a scene category. We argue that such a graded decision is appropriate and justified both from a human\u2019s perspective as well as from the image-content point of view. The method combines bottom-up information of local semantic concepts with the typical semantic content of an image category. Using this learned category representation the proposed typicality measure also quantifies the semantic transitions between image categories such as coasts, rivers/lakes, forest, plains, mountains or sky/clouds. The method is evaluated quantitatively and qualitatively on a database of natural scenes. The experiments show that the typicality measure well represents the diversity of the given image categories as well as the ambiguity in human judgment of image categorization."
            },
            "slug": "A-Semantic-Typicality-Measure-for-Natural-Scene-Vogel-Schiele",
            "title": {
                "fragments": [],
                "text": "A Semantic Typicality Measure for Natural Scene Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "An approach to categorize real-world natural scenes based on a semantic typicality measure that represents the diversity of the given image categories as well as the ambiguity in human judgment of image categorization."
            },
            "venue": {
                "fragments": [],
                "text": "DAGM-Symposium"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153281777"
                        ],
                        "name": "D. Marr",
                        "slug": "D.-Marr",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Marr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31857045"
                        ],
                        "name": "E. Hildreth",
                        "slug": "E.-Hildreth",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Hildreth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hildreth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 229
                            }
                        ],
                        "text": "On the one hand, the shape of an object is more precisely defined at high spatial frequencies but the object boundaries are interleaved by considerable noise, which requires\nextensive processing to be filtered out (among others, Marr and Hildreth, 1980; Shashua and Ullman, 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: scene recognition; gist; spatial envelope; global image feature; spatial frequency; natural image"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2150419,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9009c9685754346deb93f316144a9da1f70ffcd8",
            "isKey": false,
            "numCitedBy": 7031,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "A theory of edge detection is presented. The analysis proceeds in two parts. (1) Intensity changes, which occur in a natural image over a wide range of scales, are detected separately at different scales. An appropriate filter for this purpose at a given scale is found to be the second derivative of a Gaussian, and it is shown that, provided some simple conditions are satisfied, these primary filters need not be orientation-dependent. Thus, intensity changes at a given scale are best detected by finding the zero values of \u22072G(x, y)* I(x, y) for image I, where G(x, y) is a two-dimensional Gaussian distribution and \u22072 is the Laplacian. The intensity changes thus discovered in each of the channels are then represented by oriented primitives called zero-crossing segments, and evidence is given that this representation is complete. (2) Intensity changes in images arise from surface discontinuities or from reflectance or illumination boundaries, and these all have the property that they are spatially localized. Because of this, the zero-crossing segments from the different channels are not independent, and rules are deduced for combining them into a description of the image. This description is called the raw primal sketch. The theory explains several basic psychophysical findings, and the operation of forming oriented zero-crossing segments from the output of centre-surround \u22072G filters acting on the image forms the basis for a physiological model of simple cells (see Marr & Ullman 1979)."
            },
            "slug": "Theory-of-edge-detection-Marr-Hildreth",
            "title": {
                "fragments": [],
                "text": "Theory of edge detection"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The theory of edge detection explains several basic psychophysical findings, and the operation of forming oriented zero-crossing segments from the output of centre-surround \u22072G filters acting on the image forms the basis for a physiological model of simple cells."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Royal Society of London. Series B. Biological Sciences"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 224
                            }
                        ],
                        "text": "\u2026be inferred from their spatial layout (e.g., an arrangement of basic geometrical forms such as simple Geons clusters, Biederman, 1995; the spatial relationships between regions or blobs of particular size and aspect ratio, Schyns and Oliva, 1994; Sanocki and Epstein, 1997; Oliva and Schyns, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 165
                            }
                        ],
                        "text": "One remarkable aspect of human visual perception is that we are able to understand the meaning of a complex novel scene very quickly even when the image is blurred (Schyns and Oliva, 1994), or presented for only 20ms (Thorpe et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "(B) A hybrid image combining the high spatial quency (LSF, 8 cycles/image) of the street scene."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 91
                            }
                        ],
                        "text": "B) The complementary hybrid image, with the street scene in HSF and the beach scene in LSF (cf. Oliva and Schyns, 1997; Schyns and Oliva, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 263
                            }
                        ],
                        "text": "Instead, it illustrates the strength of spatial layout information in constraining the identity of the objects in normal conditions, which is especially evident in degraded conditions in which object identities cannot be inferred based only on local information (Schyns and Oliva, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 160
                            }
                        ],
                        "text": "If you squint, this demonstration fails, step back from the image until your\nstreet scene in HSF and the beach scene in LSF (cf. Schyns and\nfollowed by a mask, Schyns and Oliva, 1994), observers used the low spatial frequency part of hybrids (street in Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 159
                            }
                        ],
                        "text": "\u2026that, at least in early stages of processing, mechanisms involved in natural scene recognition may be independent from those involved in recognizing objects (Schyns and Oliva, 1994; Oliva and Torralba, 2001; Li et al., 2002; Fei Fei and Perona, 2004; Marois et al., 2004; McCotter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38536052,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8437bb1a15eb2c2a09abbcae3cf6ae0210d26eae",
            "isKey": true,
            "numCitedBy": 661,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Certain salient structures in images attract our immediate attention without requiring a systematic scan. We present a method for computing saliency by a simple iterative scheme, using a uniform network of locally connected processing elements. The network uses an optimization approach to produce a ``saliency map,'''' a representation of the image emphasizing salient locations. The main properties of the network are: (i) the computations are simple and local, (ii) globally salient structures emerge with a small number of iterations, and (iii) as a by-product of the computations, contours are smoothed and gaps are filled in."
            },
            "slug": "Structural-Saliency:-The-Detection-Of-Globally-A-Shashua-Ullman",
            "title": {
                "fragments": [],
                "text": "Structural Saliency: The Detection Of Globally Salient Structures using A Locally Connected Network"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A method for computing saliency by a simple iterative scheme, using a uniform network of locally connected processing elements, to produce a ``saliency map,'''' a representation of the image emphasizing salient locations."
            },
            "venue": {
                "fragments": [],
                "text": "[1988 Proceedings] Second International Conference on Computer Vision"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3164225"
                        ],
                        "name": "T. Sanocki",
                        "slug": "T.-Sanocki",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Sanocki",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sanocki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145978461"
                        ],
                        "name": "W. Epstein",
                        "slug": "W.-Epstein",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Epstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Epstein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 349,
                                "start": 90
                            }
                        ],
                        "text": "The semantic category of most real-world scenes can be inferred from their spatial layout (e.g., an arrangement of basic geometrical forms such as simple Geons clusters, Biederman, 1995; the spatial relationships between regions or blobs of particular size and aspect ratio, Schyns and Oliva, 1994; Sanocki and Epstein, 1997; Oliva and Schyns, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 248
                            }
                        ],
                        "text": "\u2026be inferred from their spatial layout (e.g., an arrangement of basic geometrical forms such as simple Geons clusters, Biederman, 1995; the spatial relationships between regions or blobs of particular size and aspect ratio, Schyns and Oliva, 1994; Sanocki and Epstein, 1997; Oliva and Schyns, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 145808201,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "424316b83b62084c72450657c8638a0b81c6d598",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Observers responded to full-color images of scenes by indicating which of two critical objects was closer in the pictorial space. These target images were preceded by prime images of the same scene sans critical objects, or by control primes or different-scene primes. Reaction times were faster following same-scene primes than following the various control and different-scene primes. Same-scene facilitation was obtained with color primes, line-drawing primes, and primes with shifted views. The effect occurred with natural scenes having gist and simple artificial scenes having little or no gist. The results indicate that prime-induced representations influence the perception of spatial layout in pictures."
            },
            "slug": "Priming-Spatial-Layout-of-Scenes-Sanocki-Epstein",
            "title": {
                "fragments": [],
                "text": "Priming Spatial Layout of Scenes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144548193"
                        ],
                        "name": "A. R. Rao",
                        "slug": "A.-R.-Rao",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Rao",
                            "middleNames": [
                                "Ravishankar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. R. Rao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470310"
                        ],
                        "name": "G. Lohse",
                        "slug": "G.-Lohse",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Lohse",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lohse"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1676003,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ecdfd517e4b270c718a5d9a6221fac9b379947ef",
            "isKey": false,
            "numCitedBy": 250,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A fundamental issue in texture analysis is that of deciding what textural features are important in texture perception, and how they are used. Experiments on human preattentive vision have identified several low-level features (such as orientation of blobs and size of line segments), which are used in texture perception. However, the question of what higher level features of texture are used has not been adequately addressed. We designed an experiment to help identify the relevant higher order features of texture perceived by humans. We used 20 subjects, who were asked to perform an unsupervised classification of 30 pictures from Brodatz\u2032s album on texture. Each subject was asked to group these pictures into as many classes as desired. Both hierarchical cluster analysis and nonparametric multidimensional scaling (MDS) were applied to the pooled similarity matrix generated from the subjects\u2032 groupings. A surprising outcome is that the MDS solutions fit the data very well. The stress in the two-dimensional case is 0.10, and the stress in the three-dimensional case is 0.045. We rendered the original textures in these coordinate systems, and interpreted the (rotated) axes. It appears that the axes in the 2D case correspond to periodicity versus irregularity, and directionality versus nondirectionality. In the 3D case, the third dimension represents the structural complexity of the texture. Furthermore, the clusters identified by the hierarchical cluster analysis remain virtually intact in the MDS solution. The results of our experiment indicate that people use three high-level features for texture perception. Future studies are needed to determine the appropriateness of these high-level features for computational texture analysis and classification."
            },
            "slug": "Identifying-High-Level-Features-of-Texture-Rao-Lohse",
            "title": {
                "fragments": [],
                "text": "Identifying High Level Features of Texture Perception"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The results of this experiment indicate that people use three high-level features for texture perception, and future studies are needed to determine the appropriateness of these high- level features for computational texture analysis and classification."
            },
            "venue": {
                "fragments": [],
                "text": "CVGIP Graph. Model. Image Process."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115374542"
                        ],
                        "name": "F. Li",
                        "slug": "F.-Li",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Li",
                            "middleNames": [
                                "Fei"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4814195"
                        ],
                        "name": "R. VanRullen",
                        "slug": "R.-VanRullen",
                        "structuredName": {
                            "firstName": "Rufin",
                            "lastName": "VanRullen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. VanRullen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624227"
                        ],
                        "name": "C. Koch",
                        "slug": "C.-Koch",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 373,
                                "start": 236
                            }
                        ],
                        "text": "Converging evidence from behavioral, imaging and computational studies suggest that, at least in early stages of processing, mechanisms involved in natural scene recognition may be independent from those involved in recognizing objects (Schyns and Oliva, 1994; Oliva and Torralba, 2001; Li et al., 2002; Fei Fei and Perona, 2004; Marois et al., 2004; McCotter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 209
                            }
                        ],
                        "text": "\u2026that, at least in early stages of processing, mechanisms involved in natural scene recognition may be independent from those involved in recognizing objects (Schyns and Oliva, 1994; Oliva and Torralba, 2001; Li et al., 2002; Fei Fei and Perona, 2004; Marois et al., 2004; McCotter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9045292,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "9101fdb09e83a0bbfce3eb5f3d723d7e1b3e84ca",
            "isKey": false,
            "numCitedBy": 744,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "What can we see when we do not pay attention? It is well known that we can be \u201cblind\u201d even to major aspects of natural scenes when we attend elsewhere. The only tasks that do not need attention appear to be carried out in the early stages of the visual system. Contrary to this common belief, we report that subjects can rapidly detect animals or vehicles in briefly presented novel natural scenes while simultaneously performing another attentionally demanding task. By comparison, they are unable to discriminate large T's from L's, or bisected two-color disks from their mirror images under the same conditions. We conclude that some visual tasks associated with \u201chigh-level\u201d cortical areas may proceed in the near absence of attention."
            },
            "slug": "Rapid-natural-scene-categorization-in-the-near-of-Li-VanRullen",
            "title": {
                "fragments": [],
                "text": "Rapid natural scene categorization in the near absence of attention"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is reported that subjects can rapidly detect animals or vehicles in briefly presented novel natural scenes while simultaneously performing another attentionally demanding task, and some visual tasks associated with \u201chigh-level\u201d cortical areas may proceed in the near absence of attention."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34854785"
                        ],
                        "name": "Russell A. Epstein",
                        "slug": "Russell-A.-Epstein",
                        "structuredName": {
                            "firstName": "Russell",
                            "lastName": "Epstein",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Russell A. Epstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49211712"
                        ],
                        "name": "A. Harris",
                        "slug": "A.-Harris",
                        "structuredName": {
                            "firstName": "Alison",
                            "lastName": "Harris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40363678"
                        ],
                        "name": "D. Stanley",
                        "slug": "D.-Stanley",
                        "structuredName": {
                            "firstName": "Damian",
                            "lastName": "Stanley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stanley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1931482"
                        ],
                        "name": "N. Kanwisher",
                        "slug": "N.-Kanwisher",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Kanwisher",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kanwisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6668048,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "7ebb7f861d5c07320a3688842284a34361539ff6",
            "isKey": false,
            "numCitedBy": 781,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Parahippocampal-Place-Area-Recognition,-or-Epstein-Harris",
            "title": {
                "fragments": [],
                "text": "The Parahippocampal Place Area Recognition, Navigation, or Encoding?"
            },
            "venue": {
                "fragments": [],
                "text": "Neuron"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996960"
                        ],
                        "name": "M. Riesenhuber",
                        "slug": "M.-Riesenhuber",
                        "structuredName": {
                            "firstName": "Maximilian",
                            "lastName": "Riesenhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riesenhuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8920227,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "85abadb689897997f1e37baa7b5fc6f7d497518b",
            "isKey": false,
            "numCitedBy": 3318,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual processing in cortex is classically modeled as a hierarchy of increasingly sophisticated representations, naturally extending the model of simple to complex cells of Hubel and Wiesel. Surprisingly, little quantitative modeling has been done to explore the biological feasibility of this class of models to explain aspects of higher-level visual processing such as object recognition. We describe a new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions. The model is based on a MAX-like operation applied to inputs to certain cortical neurons that may have a general role in cortical function."
            },
            "slug": "Hierarchical-models-of-object-recognition-in-cortex-Riesenhuber-Poggio",
            "title": {
                "fragments": [],
                "text": "Hierarchical models of object recognition in cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions is described."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 148
                            }
                        ],
                        "text": "\u2026studies showed that within a 30-ms exposure, both low and high spatial frequency bands from a hybrid image were registered by the visual system 1 (Parker et al., 1992, 1996; Oliva and Schyns, 1997, Exp.1), but that the requirements of the task determined which scale, coarse or fine, was\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4358477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8012c4a1e2ca663f1a04e80cbb19631a00cbab27",
            "isKey": false,
            "numCitedBy": 5639,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "THE receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented1\u20134 and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms5,6. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding7\u201312. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties13\u201318, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal8,12 that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs."
            },
            "slug": "Emergence-of-simple-cell-receptive-field-properties-Olshausen-Field",
            "title": {
                "fragments": [],
                "text": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3526863"
                        ],
                        "name": "D. M. Parker",
                        "slug": "D.-M.-Parker",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Parker",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Parker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144579828"
                        ],
                        "name": "J. Lishman",
                        "slug": "J.-Lishman",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Lishman",
                            "middleNames": [
                                "Rowland"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lishman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47727506"
                        ],
                        "name": "J. Hughes",
                        "slug": "J.-Hughes",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hughes",
                            "middleNames": [
                                "Nolie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hughes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 148
                            }
                        ],
                        "text": "\u2026studies showed that within a 30-ms exposure, both low and high spatial frequency bands from a hybrid image were registered by the visual system 1 (Parker et al., 1992, 1996; Oliva and Schyns, 1997, Exp.1), but that the requirements of the task determined which scale, coarse or fine, was\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11815892,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "75ac015d28fe8f18a37d5e85abb8c000e01c167a",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "In 4 experiments the role of coarse (low-pass filtered) and fine (high-pass filtered) spatial information in guiding visual processing was studied in a same-different task. The second of a pair of sequential patterns was either a normal image or the first 100 ms was restricted either coarse or fine information before a normal image was shown for the rest of the presentation. This 100-ms cue could be from the immediately succeeding image (relevant) or from other images in the set (irrelevant). Analysis of response times and errors showed relevant coarse- and fine-scale cues were usually equally effective, but any differences favored fine-scale versions. Irrelevant fine-scale cuing was significantly more disruptive than coarse-scale cuing. No evidence of preferential cuing by coarse-scale information occurred in any experiment."
            },
            "slug": "Role-of-coarse-and-fine-spatial-information-in-face-Parker-Lishman",
            "title": {
                "fragments": [],
                "text": "Role of coarse and fine spatial information in face and object processing."
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "In 4 experiments the role of coarse and fine spatial information in guiding visual processing was studied in a same-different task and relevant coarse- and fine-scale cues were usually equally effective, but any differences favored fine- scales."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Human perception and performance"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796908"
                        ],
                        "name": "D. Ariely",
                        "slug": "D.-Ariely",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Ariely",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ariely"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 249
                            }
                        ],
                        "text": "\u2026literature suggest that our visual system analyzes global statistical summary of the image in a preselective stage of visual processing, or at least with minimal attentional resources (mean orientation, Parkes et al., 2001; mean of set of objects, Ariely, 2001; Chong and Treisman, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: scene recognition; gist; spatial envelope; global image feature; spatial frequency; natural image"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6435925,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "5494c4ca523c5ef1999941e27c5248cea907c7af",
            "isKey": false,
            "numCitedBy": 728,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Sets of similar objects are common occurrences\u2014a crowd of people, a bunch of bananas, a copse of trees, a shelf of books, a line of cars. Each item in the set may be distinct, highly visible, and discriminable. But when we look away from the set, what information do we have? The current article starts to address this question by introducing the idea of a set representation. This idea was tested using two new paradigms: mean discrimination and member identification. Three experiments using sets of different-sized spots showed that observers know a set's mean quite accurately but know little about the individual items, except their range. Taken together, these results suggest that the visual system represents the overall statistical, and not individual, properties of sets."
            },
            "slug": "Seeing-Sets:-Representation-by-Statistical-Ariely",
            "title": {
                "fragments": [],
                "text": "Seeing Sets: Representation by Statistical Properties"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "Three experiments showed that observers know a set's mean quite accurately but know little about the individual items, except their range, which suggests that the visual system represents the overall statistical, and not individual, properties of sets."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological science"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2102334675"
                        ],
                        "name": "Laura Parkes",
                        "slug": "Laura-Parkes",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Parkes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laura Parkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2655339"
                        ],
                        "name": "J. Lund",
                        "slug": "J.-Lund",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Lund",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31640297"
                        ],
                        "name": "A. Angelucci",
                        "slug": "A.-Angelucci",
                        "structuredName": {
                            "firstName": "Alessandra",
                            "lastName": "Angelucci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Angelucci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2221312"
                        ],
                        "name": "J. Solomon",
                        "slug": "J.-Solomon",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Solomon",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Solomon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145968374"
                        ],
                        "name": "M. Morgan",
                        "slug": "M.-Morgan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Morgan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Morgan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10975462,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "ca83c68b9b05fadc8e701776f23d5ddabcb002cd",
            "isKey": false,
            "numCitedBy": 806,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "A shape can be more difficult to identify when other shapes are near it. For example, when several grating patches are viewed parafoveally, observers are unable to report the orientation of the central patch. This phenomenon, known as 'crowding,' has historically been confused with lateral masking, in which one stimulus attenuates signals generated by another stimulus. Here we show that despite their inability to report the orientation of an individual patch, observers can reliably estimate the average orientation, demonstrating that the local orientation signals are combined rather than lost. Our results imply that crowding is distinct from ordinary masking, and is perhaps related to texture perception. Under crowded conditions, the orientation signals in primary visual cortex are pooled before they reach consciousness."
            },
            "slug": "Compulsory-averaging-of-crowded-orientation-signals-Parkes-Lund",
            "title": {
                "fragments": [],
                "text": "Compulsory averaging of crowded orientation signals in human vision"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that despite their inability to report the orientation of an individual patch, observers can reliably estimate the average orientation, demonstrating that the local orientation signals are combined rather than lost."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145944906"
                        ],
                        "name": "M. Potter",
                        "slug": "M.-Potter",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Potter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Potter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48180646"
                        ],
                        "name": "A. Staub",
                        "slug": "A.-Staub",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Staub",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Staub"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1396399044"
                        ],
                        "name": "D. H. O\u2019Connor",
                        "slug": "D.-H.-O\u2019Connor",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "O\u2019Connor",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. H. O\u2019Connor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145944906"
                        ],
                        "name": "M. Potter",
                        "slug": "M.-Potter",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Potter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Potter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 34
                            }
                        ],
                        "text": "Mary Potter (1975, 1976, see also Potter et al., 2004) demonstrated that during a rapid presentation of a stream of images, observers were able to identify the semantic category of each image as well as a few objects and their attributes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1543909,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d5b098283d708cfb83b964a4395be242a2628570",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Pictures seen in a rapid sequence are remembered briefly, but most are forgotten within a few seconds (M. C. Potter. A. Staub, J. Rado. & D. H. O'Connor. 2002). The authors investigated the pictorial and conceptual components of this fleeting memory by presenting 5 pictured scenes and immediately testing recognition of verbal titles (e.g., people at a table) or recognition of the pictures themselves. Recognition declined during testing, but initial performance was higher and the decline steeper when pictures were tested. A final experiment included test decoy pictures that were conceptually similar to but visually distinct from the original pictures. Yeses to decoys were higher than yeses to other distractors. Fleeting memory for glimpsed pictures has a strong conceptual component (conceptual short-term memory), but there is additional highly volatile pictorial memory (pictorial short-term memory) that is not tapped hy a gist title or decoy picture."
            },
            "slug": "Pictorial-and-conceptual-representation-of-glimpsed-Potter-Staub",
            "title": {
                "fragments": [],
                "text": "Pictorial and conceptual representation of glimpsed pictures."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Fleeting memory for glimpsed pictures has a strong conceptual component (conceptual short-term memory), but there is additional highly volatile pictorial memory (pictorial short- term memory) that is not tapped hy a gist title or decoy picture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Human perception and performance"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 120
                            }
                        ],
                        "text": ", in perspective, cluttered) can be determined with a high probability from a diagnostic set of lowlevel image features (Oliva and Torralba, 2001; Walker Renninger and Malik, 2004; Fei-Fei and Perona, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 165
                            }
                        ],
                        "text": "Several methods of image analysis can be used to learn a suitable basis of global features (Vailaya et al., 1998; Oliva and Torralba, 2001; Vogel and Schiele, 2004; Fei-Fei and Perona, 2005) that capture the statistical regularities of natural-scene images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 274
                            }
                        ],
                        "text": "\u2026highway, coast, etc.) as well as global properties of the three-dimensional (3D) space (e.g., in perspective, cluttered) can be determined with a high probability from a diagnostic set of lowlevel image features (Oliva and Torralba, 2001; Walker Renninger and Malik, 2004; Fei-Fei and Perona, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6387937,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a2252ccce2b65abc3759149b5c06587cc318e2f",
            "isKey": false,
            "numCitedBy": 3886,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach to learn and recognize natural scene categories. Unlike previous work, it does not require experts to annotate the training set. We represent the image of a scene by a collection of local regions, denoted as codewords obtained by unsupervised learning. Each region is represented as part of a \"theme\". In previous work, such themes were learnt from hand-annotations of experts, while our method learns the theme distributions as well as the codewords distribution over the themes without supervision. We report satisfactory categorization performances on a large set of 13 categories of complex scenes."
            },
            "slug": "A-Bayesian-hierarchical-model-for-learning-natural-Fei-Fei-Perona",
            "title": {
                "fragments": [],
                "text": "A Bayesian hierarchical model for learning natural scene categories"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This work proposes a novel approach to learn and recognize natural scene categories by representing the image of a scene by a collection of local regions, denoted as codewords obtained by unsupervised learning."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41191911"
                        ],
                        "name": "C. Heaps",
                        "slug": "C.-Heaps",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Heaps",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Heaps"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36809098"
                        ],
                        "name": "S. Handel",
                        "slug": "S.-Handel",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Handel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Handel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 156
                            }
                        ],
                        "text": "These properties are in fact meaningful to a human observer who may use them for comparing similarities between two forest images (cf. Rao and Lohse, 1993; Heaps and Handel, 1999 for a similar account in the domain of textures)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: scene recognition; gist; spatial envelope; global image feature; spatial frequency; natural image"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 144999778,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "40efcda4d703edd9391250c41c3c9965289179f6",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In 3 experiments the type of model that is best for conceptualizing the attentive similarity of natural textures was investigated. Different groups of participants placed pictures into groups however they wished, described the resulting clusters and multidimensional scaling dimensions, identified the objects or surfaces depicted in the pictures, and ranked the pictures along several hypothesized attribute-based dimensions. Results indicate that similarity is context dependent, that natural textures seem to be organized according to family resemblances, and that a dimensional model is inappropriate. These outcomes suggest that models of preattentive segregation and attentive cognition may be incommensurable."
            },
            "slug": "Similarity-and-Features-of-Natural-Textures-Heaps-Handel",
            "title": {
                "fragments": [],
                "text": "Similarity and Features of Natural Textures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107881808"
                        ],
                        "name": "Stella X. Yu",
                        "slug": "Stella-X.-Yu",
                        "structuredName": {
                            "firstName": "Stella",
                            "lastName": "Yu",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stella X. Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2791772,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1a288bbaa785ca17a98c3a6d242cf2321e2dc997",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Perceptual organization is scale-invariant. In turn, a segmentation that separates features consistently at all scales is the desired one that reveals the underlying structural organization of an image. Addressing cross-scale correspondence with interior pixels, we develop this intuition into a general segmenter that handles texture and illusory contours through edges entirely without any explicit characterization of texture or curvilinearity. Experimental results demonstrate that our method not only performs on par with either texture segmentation or boundary completion methods on their specialized examples, but also works well on a variety of real images."
            },
            "slug": "Segmentation-induced-by-scale-invariance-Yu",
            "title": {
                "fragments": [],
                "text": "Segmentation induced by scale invariance"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work develops cross-scale correspondence with interior pixels into a general segmenter that handles texture and illusory contours through edges entirely without any explicit characterization of texture or curvilinearity."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741887"
                        ],
                        "name": "M. Bar",
                        "slug": "M.-Bar",
                        "structuredName": {
                            "firstName": "Moshe",
                            "lastName": "Bar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2240829"
                        ],
                        "name": "E. Aminoff",
                        "slug": "E.-Aminoff",
                        "structuredName": {
                            "firstName": "Elissa",
                            "lastName": "Aminoff",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Aminoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 24
                            }
                        ],
                        "text": "In a related vein, Bar (Bar and Aminoff, 2003; Bar, 2004) found specific cortical regions (a network relating regions in the parahippocampal region and the retrosplenial cortex) involved in the analysis of the context of objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "Thanks to Michelle Greene, Barbara Hidalgo-Sotelo, Naomi Kenner, Talia Konkle and Thomas Serre for comments on the manuscript."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In a related vein, Bar (2004; Bar and Aminoff, 2003) found specific cortical regions (a network relating regions in the parahippocampal region and the retrosplenial cortex) involved in the analysis of the context of objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 380,
                                "start": 377
                            }
                        ],
                        "text": "The vocabulary given by observers (naturalness, openness, expansion, depth, roughness, complexity, ruggedness, symmetry) served to establish an initial scene-centered description of the image (based on spatial layout properties, Oliva and Torralba, 2002) offering an alternative to object-centered description (where a scene is identified from labeling the objects or regions, Barnard and Forsyth, 2001; Carson et al., 2002)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 559150,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "46a2d5effc3cc1b6da662d4ab95deeb321eba9fe",
            "isKey": true,
            "numCitedBy": 561,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Cortical-Analysis-of-Visual-Context-Bar-Aminoff",
            "title": {
                "fragments": [],
                "text": "Cortical Analysis of Visual Context"
            },
            "venue": {
                "fragments": [],
                "text": "Neuron"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739475"
                        ],
                        "name": "J. Goh",
                        "slug": "J.-Goh",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Goh",
                            "middleNames": [
                                "Oon",
                                "Soo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Goh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5625075"
                        ],
                        "name": "Soon Chun Siong",
                        "slug": "Soon-Chun-Siong",
                        "structuredName": {
                            "firstName": "Soon",
                            "lastName": "Siong",
                            "middleNames": [
                                "Chun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soon Chun Siong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116006908"
                        ],
                        "name": "Denise C. Park",
                        "slug": "Denise-C.-Park",
                        "structuredName": {
                            "firstName": "Denise",
                            "lastName": "Park",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Denise C. Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3028161"
                        ],
                        "name": "A. Gutchess",
                        "slug": "A.-Gutchess",
                        "structuredName": {
                            "firstName": "Angela",
                            "lastName": "Gutchess",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gutchess"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2405278"
                        ],
                        "name": "A. Hebrank",
                        "slug": "A.-Hebrank",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Hebrank",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hebrank"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145154233"
                        ],
                        "name": "M. Chee",
                        "slug": "M.-Chee",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Chee",
                            "middleNames": [
                                "W.",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 32
                            }
                        ],
                        "text": "This misinterpretation is not an error of the visual system. aining the identities of the local image structures (Navon, 1977).\ncontours and textures of the image that is still detailed enough to recognize the image\u2019s gist."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6716245,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "bd4bb3ca028e35c54deb08c212ad0fe0bbffec03",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous work has suggested that object and place processing are neuroanatomically dissociated in ventral visual areas under conditions of passive viewing. It has also been shown that the hippocampus and parahippocampal gyrus mediate the integration of objects with background scenes in functional imaging studies, but only when encoding or retrieval processes have been directed toward the relevant stimuli. Using functional magnetic resonance adaptation, we demonstrated that object, background scene, and contextual integration of selectively repeated objects and background scenes could be dissociated during the passive viewing of naturalistic pictures involving object-scene pairings. Specifically, bilateral fusiform areas showed adaptation to object repetition, regardless of whether the associated scene was novel or repeated, suggesting sensitivity to object processing. Bilateral parahippocampal regions showed adaptation to background scene repetition, regardless of whether the focal object was novel or repeated, suggesting selectivity for background scene processing. Finally, bilateral parahippocampal regions distinct from those involved in scene processing and the right hippocampus showed adaptation only when the unique pairing of object with background scene was repeated, suggesting that these regions perform binding operations."
            },
            "slug": "Cortical-Areas-Involved-in-Object,-Background,-and-Goh-Siong",
            "title": {
                "fragments": [],
                "text": "Cortical Areas Involved in Object, Background, and Object-Background Processing Revealed with Functional Magnetic Resonance Adaptation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Using functional magnetic resonance adaptation, it is demonstrated that object, background scene, and contextual integration of selectively repeated objects and background scenes could be dissociated during the passive viewing of naturalistic pictures involving object-scene pairings."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of Neuroscience"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403305613"
                        ],
                        "name": "K. Grill-Spector",
                        "slug": "K.-Grill-Spector",
                        "structuredName": {
                            "firstName": "Kalanit",
                            "lastName": "Grill-Spector",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Grill-Spector"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1993227"
                        ],
                        "name": "R. Malach",
                        "slug": "R.-Malach",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Malach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Malach"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 156
                            }
                        ],
                        "text": "Research over the last decade has made substantial progress toward understanding the brain\nmechanisms underlying human object recognition (Kanwisher, 2003; Grill-Spector and Malach, 2004) and its modeling (Riesenhuber and Poggio, 1999; Ullman et al., 2002; Torralba et al., 2004; Serre et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 47
                            }
                        ],
                        "text": "mechanisms underlying human object recognition (Kanwisher, 2003; Grill-Spector and Malach, 2004) and its modeling (Riesenhuber and Poggio, 1999; Ullman et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6143322,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "d1c990fe6281865827364d6f8691027a4a5951b4",
            "isKey": false,
            "numCitedBy": 1016,
            "numCiting": 239,
            "paperAbstract": {
                "fragments": [],
                "text": "The discovery and analysis of cortical visual areas is a major accomplishment of visual neuroscience. In the past decade the use of noninvasive functional imaging, particularly functional magnetic resonance imaging (fMRI), has dramatically increased our detailed knowledge of the functional organization of the human visual cortex and its relation to visual perception. The fMRI method offers a major advantage over other techniques applied in neuroscience by providing a large-scale neuroanatomical perspective that stems from its ability to image the entire brain essentially at once. This bird's eye view has the potential to reveal large-scale principles within the very complex plethora of visual areas. Thus, it could arrange the entire constellation of human visual areas in a unified functional organizational framework. Here we review recent findings and methods employed to uncover the functional properties of the human visual cortex focusing on two themes: functional specialization and hierarchical processing."
            },
            "slug": "The-human-visual-cortex.-Grill-Spector-Malach",
            "title": {
                "fragments": [],
                "text": "The human visual cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Recent findings and methods employed to uncover the functional properties of the human visual cortex focusing on two themes: functional specialization and hierarchical processing are reviewed."
            },
            "venue": {
                "fragments": [],
                "text": "Annual review of neuroscience"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: scene recognition; gist; spatial envelope; global image feature; spatial frequency; natural image"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 250
                            }
                        ],
                        "text": "\u2026to establish an initial scene-centered description of the image (based on spatial layout properties, Oliva and Torralba, 2002) offering an alternative to object-centered description (where a scene is identified from labeling the objects or regions, Barnard and Forsyth, 2001; Carson et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13121800,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e36d141e2964817c3d926c380793e404a3a3367",
            "isKey": false,
            "numCitedBy": 615,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a statistical model for organizing image collections which integrates semantic information provided by associate text and visual information provided by image features. The model is very promising for information retrieval tasks such as database browsing and searching for images based on text and/or image features. Furthermore, since the model learns relationships between text and image features, it can be used for novel applications such as associating words with pictures, and unsupervised learning for object recognition."
            },
            "slug": "Learning-the-semantics-of-words-and-pictures-Barnard-Forsyth",
            "title": {
                "fragments": [],
                "text": "Learning the semantics of words and pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The model is very promising for information retrieval tasks such as database browsing and searching for images based on text and/or image features, and can be used for novel applications such as associating words with pictures, and unsupervised learning for object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879621"
                        ],
                        "name": "V. Goffaux",
                        "slug": "V.-Goffaux",
                        "structuredName": {
                            "firstName": "Val\u00e9rie",
                            "lastName": "Goffaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Goffaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38610185"
                        ],
                        "name": "C. Jacques",
                        "slug": "C.-Jacques",
                        "structuredName": {
                            "firstName": "Corentin",
                            "lastName": "Jacques",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jacques"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790504"
                        ],
                        "name": "A. Mouraux",
                        "slug": "A.-Mouraux",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Mouraux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mouraux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2287417"
                        ],
                        "name": "P. Schyns",
                        "slug": "P.-Schyns",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Schyns",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Schyns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2650548"
                        ],
                        "name": "B. Rossion",
                        "slug": "B.-Rossion",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Rossion",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rossion"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The neural correlates of the role of color layout has been recently investigated by  Goffaux et al (2005) , who have observed an ERP frontal signal 150 msec"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 127
                            }
                        ],
                        "text": "The diagnosticity of colored surfaces in an image seems to be a key element of fast scene recognition (Oliva and Schyns, 2000; Goffaux et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The diagnosticity of colored surfaces in an image seems to be a key element of fast scene recognition ( Goffaux et al., 2005;  Oliva & Schyns, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 84
                            }
                        ],
                        "text": "The neural correlates of the role of color layout has been recently investigated by Goffaux et al. (2005), who\nhave observed an Event-Related Potential (ERP) frontal signal 150ms after image onset (a well-documented temporal marker of image categorization, Thorpe et al., 1996; Van Rullen and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 144448426,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "e2a85e97407eba666f98000113e67e73afb5cd5e",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We examined the effects of colour cues on the express categorization of natural scenes. Using a go/no-go paradigm sensitive to fast recognition processes, we measured early event-related potential (ERP) correlates of scene categorization to elucidate the processing stage at which colour contributes to scene recognition. Observers were presented with scenes belonging to four colour-diagnostic categories (desert, forest, canyon and coastline). Scenes were presented in one of three forms: Diagnostically coloured, nondiagnostically coloured, or greyscale images. In a verification task, observers were instructed to respond whenever the presented stimulus matched a previously presented category name. Reaction times and accuracy were optimal when the stimuli were presented as their original diagnostically coloured version, followed by their greyscale version, and lastly by their nondiagostically coloured version. These effects were mirrored in the early (i.e., 150 ms following stimulus onset) ERP frontal correlates. Their onset was delayed for greyscale scenes compared to diagnostically coloured scenes, and for nondiagnostically coloured scenes compared to the other two conditions. Frontal ERP amplitudes also decreased for greyscale and nondiagnostically coloured scenes. Together, the results suggest that diagnostic colours are part of the scene gist responsible for express scene categorization."
            },
            "slug": "Diagnostic-colours-contribute-to-the-early-stages-Goffaux-Jacques",
            "title": {
                "fragments": [],
                "text": "Diagnostic colours contribute to the early stages of scene categorization: Behavioural and neurophysiological evidence"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145955205"
                        ],
                        "name": "R. Watt",
                        "slug": "R.-Watt",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Watt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Watt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 96
                            }
                        ],
                        "text": "of the image, fleshed out later by finer structures existing at higher spatial frequency scales (Linderberg, 1993; Watt, 1987; Yu, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 254
                            }
                        ],
                        "text": "\u2026edges that would persist across the scale space are likely to be important structures of the image (Linderberg, 1993), and would define an initial skeleton of the image, fleshed out later by finer structures existing at higher spatial frequency scales (Watt, 1987; Linderberg, 1993; Yu, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14730166,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "7e6fcd89eaa3a4d610887969b445fb109e153827",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The manner in which the spatial characteristics of simple discrimination tasks change with time after the onset of a stimulus were examined. The experiments measured the improvements in sensitivity to the length, orientation, curvature, and stereoscopic depth of short lines that accrue with increased exposure durations. These improvements can be consistently interpreted in terms of a change of the spatial scale of analysis from coarse to fine over a period of at least 1000 msec. Variations in visual resolution acuity over the same period are negligible, and it is concluded that the changes in spatial characteristics concern the range of spatial filters in operation. This range progressively shrinks after stimulus presentation."
            },
            "slug": "Scanning-from-coarse-to-fine-spatial-scales-in-the-Watt",
            "title": {
                "fragments": [],
                "text": "Scanning from coarse to fine spatial scales in the human visual system after the onset of a stimulus."
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The manner in which the spatial characteristics of simple discrimination tasks change with time after the onset of a stimulus were examined, and it is concluded that the changes in spatial characteristics concern the range of spatial filters in operation."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46804968"
                        ],
                        "name": "Y. Sugase",
                        "slug": "Y.-Sugase",
                        "structuredName": {
                            "firstName": "Yasuko",
                            "lastName": "Sugase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Sugase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706597"
                        ],
                        "name": "S. Yamane",
                        "slug": "S.-Yamane",
                        "structuredName": {
                            "firstName": "Shigeru",
                            "lastName": "Yamane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Yamane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069219"
                        ],
                        "name": "S. Ueno",
                        "slug": "S.-Ueno",
                        "structuredName": {
                            "firstName": "Shoogo",
                            "lastName": "Ueno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ueno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34917500"
                        ],
                        "name": "K. Kawano",
                        "slug": "K.-Kawano",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Kawano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kawano"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 4341077,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "0c9ae311014432f13b141a4728b0d38aa008c4b3",
            "isKey": false,
            "numCitedBy": 738,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "When we see a person's face, we can easily recognize their species, individual identity and emotional state. How does the brain represent such complex information? A substantial number of neurons in the macaque temporal cortex respond to faces. However, the neuronal mechanisms underlying the processing ofcomplex information are not yet clear. Here we recorded the activity of single neurons in the temporal cortex of macaque monkeys while presenting visual stimuli consisting of geometric shapes, and monkey and human faces with various expressions. Information theory was used to investigate how well the neuronal responses could categorize the stimuli. We found that single neurons conveyed two different scales of facial information intheir firing patterns, starting at different latencies. Global information, categorizing stimuli as monkey faces, human faces or shapes, was conveyed in the earliest part of the responses. Fineinformation about identity or expression was conveyed later,beginning on average 51\u2009ms after global information. We speculate that global information could be used as a \u2018header\u2019 to prepare destination areas for receiving more detailed information."
            },
            "slug": "Global-and-fine-information-coded-by-single-neurons-Sugase-Yamane",
            "title": {
                "fragments": [],
                "text": "Global and fine information coded by single neurons in the temporal visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "It is speculated that global information could be used as a \u2018header\u2019 to prepare destination areas for receiving more detailed information."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2738838"
                        ],
                        "name": "R. Marois",
                        "slug": "R.-Marois",
                        "structuredName": {
                            "firstName": "Ren\u00e9",
                            "lastName": "Marois",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Marois"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46704705"
                        ],
                        "name": "Do-Joon Yi",
                        "slug": "Do-Joon-Yi",
                        "structuredName": {
                            "firstName": "Do-Joon",
                            "lastName": "Yi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Do-Joon Yi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3286262"
                        ],
                        "name": "M. Chun",
                        "slug": "M.-Chun",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Chun",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 373,
                                "start": 236
                            }
                        ],
                        "text": "Converging evidence from behavioral, imaging and computational studies suggest that, at least in early stages of processing, mechanisms involved in natural scene recognition may be independent from those involved in recognizing objects (Schyns and Oliva, 1994; Oliva and Torralba, 2001; Li et al., 2002; Fei Fei and Perona, 2004; Marois et al., 2004; McCotter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 271,
                                "start": 252
                            }
                        ],
                        "text": "\u2026that, at least in early stages of processing, mechanisms involved in natural scene recognition may be independent from those involved in recognizing objects (Schyns and Oliva, 1994; Oliva and Torralba, 2001; Li et al., 2002; Fei Fei and Perona, 2004; Marois et al., 2004; McCotter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8478899,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "1510a26f08bc4bb2b5c2cf1a2b2c5dac137690fe",
            "isKey": false,
            "numCitedBy": 302,
            "numCiting": 119,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Neural-Fate-of-Consciously-Perceived-and-Missed-Marois-Yi",
            "title": {
                "fragments": [],
                "text": "The Neural Fate of Consciously Perceived and Missed Events in the Attentional Blink"
            },
            "venue": {
                "fragments": [],
                "text": "Neuron"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34180590"
                        ],
                        "name": "S. Thorpe",
                        "slug": "S.-Thorpe",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Thorpe",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thorpe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50780533"
                        ],
                        "name": "D. Fize",
                        "slug": "D.-Fize",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Fize",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fize"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3677347"
                        ],
                        "name": "Catherine Marlot",
                        "slug": "Catherine-Marlot",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Marlot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catherine Marlot"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4303570,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "addbd39fc775c12aa453ebd0cb77ea1bd3389572",
            "isKey": false,
            "numCitedBy": 2548,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speed-of-processing-in-the-human-visual-system-Thorpe-Fize",
            "title": {
                "fragments": [],
                "text": "Speed of processing in the human visual system"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1920282"
                        ],
                        "name": "S. C. Chong",
                        "slug": "S.-C.-Chong",
                        "structuredName": {
                            "firstName": "Sang",
                            "lastName": "Chong",
                            "middleNames": [
                                "Chul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. C. Chong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502152"
                        ],
                        "name": "A. Treisman",
                        "slug": "A.-Treisman",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Treisman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Treisman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11768948,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5c285034d2fd56d88a7b9a6647563ee7b3c6a12d",
            "isKey": false,
            "numCitedBy": 506,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Representation-of-statistical-properties-Chong-Treisman",
            "title": {
                "fragments": [],
                "text": "Representation of statistical properties"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 257
                            }
                        ],
                        "text": "Research over the last decade has made substantial progress toward understanding the brain\nmechanisms underlying human object recognition (Kanwisher, 2003; Grill-Spector and Malach, 2004) and its modeling (Riesenhuber and Poggio, 1999; Ullman et al., 2002; Torralba et al., 2004; Serre et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 114
                            }
                        ],
                        "text": "mechanisms underlying human object recognition (Kanwisher, 2003; Grill-Spector and Malach, 2004) and its modeling (Riesenhuber and Poggio, 1999; Ullman et al., 2002; Torralba et al., 2004; Serre et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11194336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42de22c119f25d303032396b8f7d962f62d6498b",
            "isKey": false,
            "numCitedBy": 441,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of detecting a large number of different object classes in cluttered scenes. Traditional approaches require applying a battery of different classifiers to the image, which can be slow and require much training data. We present a multi-class boosting procedure (joint boosting) that reduces both the computational and sample complexity, by finding common features that can be shared across the classes. The detectors for each class are trained jointly, rather than independently. For a given performance level, the total number of features required is observed to scale approximately logarithmically with the number of classes. In addition, we find that the features selected by independently trained classifiers are often specific to the class, whereas the features selected by the jointly trained classifiers are more generic features, such as lines and edges."
            },
            "slug": "Sharing-features:-efficient-boosting-procedures-for-Torralba-Murphy",
            "title": {
                "fragments": [],
                "text": "Sharing features: efficient boosting procedures for multiclass object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A multi-class boosting procedure (joint boosting) is presented that reduces both the computational and sample complexity, by finding common features that can be shared across the classes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2287417"
                        ],
                        "name": "P. Schyns",
                        "slug": "P.-Schyns",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Schyns",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Schyns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 146
                            }
                        ],
                        "text": "On the other hand, low-scale resolution is more contrasted and might be privileged in terms of temporal processing than finer scale (Navon, 1977; Sugase et al., 1999), but this perceptual advantage might be offset by higher uncertainty about the identity of the blobs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13161091,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6bf00fd779c01ef392848db089648176774b7f94",
            "isKey": false,
            "numCitedBy": 444,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Dr.-Angry-and-Mr.-Smile:-when-categorization-the-of-Schyns-Oliva",
            "title": {
                "fragments": [],
                "text": "Dr. Angry and Mr. Smile: when categorization flexibly modifies the perception of faces in rapid visual presentations"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4814195"
                        ],
                        "name": "R. VanRullen",
                        "slug": "R.-VanRullen",
                        "structuredName": {
                            "firstName": "Rufin",
                            "lastName": "VanRullen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. VanRullen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34180590"
                        ],
                        "name": "S. Thorpe",
                        "slug": "S.-Thorpe",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Thorpe",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thorpe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 6
                            }
                        ],
                        "text": "To the contrary of hybrid images, contours of a natural image are correlated across scale space: a contour existing at low spatial frequency exists also at high spatial frequency."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 137
                            }
                        ],
                        "text": "\u2026Potential (ERP) frontal signal 150ms after image onset (a well-documented temporal marker of image categorization, Thorpe et al., 1996; Van Rullen and Thorpe, 2001), when observers identified normally colored scene pictures (e.g., a green forest, a red canyon) compared to their\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11223614,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "f5623823baccf3d7024b71b35e1474fd4ab4e61c",
            "isKey": false,
            "numCitedBy": 668,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Experiments investigating the mechanisms involved in visual processing often fail to separate low-level encoding mechanisms from higher-level behaviorally relevant ones. Using an alternating dual-task event-related potential (ERP) experimental paradigm (animals or vehicles categorization) where targets of one task are intermixed among distractors of the other, we show that visual categorization of a natural scene involves different mechanisms with different time courses: a perceptual, task-independent mechanism, followed by a task-related, category-independent process. Although average ERP responses reflect the visual category of the stimulus shortly after visual processing has begun (e.g. 75-80 msec), this difference is not correlated with the subject's behavior until 150 msec poststimulus."
            },
            "slug": "The-Time-Course-of-Visual-Processing:-From-Early-to-VanRullen-Thorpe",
            "title": {
                "fragments": [],
                "text": "The Time Course of Visual Processing: From Early Perception to Decision-Making"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that visual categorization of a natural scene involves different mechanisms with different time courses: a perceptual, task-independent mechanism, followed by a task-related, category-independent process."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145944906"
                        ],
                        "name": "M. Potter",
                        "slug": "M.-Potter",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Potter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Potter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 874632,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "f94029da4e3ccf30281a570b8c52a36945c7bdea",
            "isKey": false,
            "numCitedBy": 999,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Three converving procedures were used to determine whether pictures presented in a rapid sequence at rates comparable to eye fixations are understood and then quickly forgotten. In two experiments, sequences of 16 color photographs were presented at rates of 113, 167, or 333 msec per picture. In one group, subjects were given an immediate test of recognition memory for the pictures and in other groups they searched for a target picture. Even when the target had only been specified by a title (e.g., a boat) detection of a target was strikingly superior to recognition memory. Detection was slightly but significantly better for pictured than named targets. In a third experiment pictures were presented for 50, 70, 90 or 120 msec preceded and followed by a visual mask; at 120 msec recognition memory was as accurate as detection had been. The results, taken together with those in 1969 of Potter and Levy for slower rates of sequential presentation, suggest that on the average a scene is understood and so becomes immune to ordinary visual masking within about 100 msec but requires about 300 msec of further processing before the memory representation is resistant to conceptual masking from a following picture. Possible functions of a short-term conceptual memory, such as the control of eye fixations, are discussed."
            },
            "slug": "Short-term-conceptual-memory-for-pictures.-Potter",
            "title": {
                "fragments": [],
                "text": "Short-term conceptual memory for pictures."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The results, taken together with those in 1969 of Potter and Levy for slower rates of sequential presentation, suggest that on the average a scene is understood and so becomes immune to ordinary visual masking within about 100 msec but requires about 300 msec of further processing before the memory representation is resistant to conceptual masks from a following picture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Human learning and memory"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144599246"
                        ],
                        "name": "A. Yezzi",
                        "slug": "A.-Yezzi",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Yezzi",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yezzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715959"
                        ],
                        "name": "Stefano Soatto",
                        "slug": "Stefano-Soatto",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Soatto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefano Soatto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2753879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4addfc803134d5ca5340445eaa37b56244ecb43a",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "What does it mean for a deforming object to be \u201cmoving\u201d? How can we separate the overall motion (a finite-dimensional group action) from the more general deformation (a diffeomorphism)? In this paper we propose a definition of motion for a deforming object and introduce a notion of \u201cshape average\u201d as the entity that separates the motion from the deformation. Our definition allows us to derive novel and efficient algorithms to register non-identical shapes using region-based methods, and to simultaneously approximate and align structures in greyscale images. We also extend the notion of shape average to that of a \u201cmoving average\u201d in order to track moving and deforming objects through time. The algorithms we propose extend prior work on landmark-based matching to smooth curves, and involve the numerical integration of partial differential equations, which we address within the framework of level set methods."
            },
            "slug": "Deformotion:-Deforming-Motion,-Shape-Average-and-of-Yezzi-Soatto",
            "title": {
                "fragments": [],
                "text": "Deformotion: Deforming Motion, Shape Average and the Joint Registration and Approximation of Structures in Images"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A definition of motion for a deforming object is proposed and a notion of \u201cshape average\u201d is introduced as the entity that separates the motion from the deformation to derive novel and efficient algorithms to register non-identical shapes using region-based methods and to simultaneously approximate and align structures in greyscale images."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2312012"
                        ],
                        "name": "D. Osherson",
                        "slug": "D.-Osherson",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Osherson",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Osherson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144541931"
                        ],
                        "name": "Edward E. Smith",
                        "slug": "Edward-E.-Smith",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Smith",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward E. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 144666330,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "de1740720637dad182d5dccd5802b00a88aaaa29",
            "isKey": false,
            "numCitedBy": 569,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Symbolic processes in the brain - the case of insect navigation, Charles R. Gallistel The mental representation of time - uncovering a biological clock, Seth Roberts The evolution of cognition - questions we will never answer, Richard C. Lewontin Consciousness and the mind - contributions from philosophy, neuroscience, and psychology, Owen Flanagan, Donald T. Dryden Cognitive algorithms - questions of representation and computation in building a theory, Mark Steedman A gentle introduction to Soar - an architecture for human cognition, Jill Fain Lehman et al Learning arithmetic with a neural network - seven times seven is about 50, James a. anderson Models for reading letters and words, Dominic W. Massaro Inferring mental operations from reaction-time data - how we compare objects, Saul Sternberg Models of visual search - finding a face in the crowd, Barbara Anne Dosher Skill acquisition and plans for actions - learning to write with your other hand, Patricia G. Lindenmann, Charles E. Wright Drawing conclusions from data - statistical methods for coping with uncertainty, Thomas D. Wickens Separating discrimination and decision in detection, recognition, and matters of life and death, John A. Swets Discovering mental processing stages - the method of additive factors, Saul Sternberg Brainwaves and mental processes - electrical evidence of attention, perception, and intention, Allen Osman."
            },
            "slug": "An-Invitation-to-cognitive-science-Osherson-Smith",
            "title": {
                "fragments": [],
                "text": "An Invitation to cognitive science"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5980237"
                        ],
                        "name": "R. Kimchi",
                        "slug": "R.-Kimchi",
                        "structuredName": {
                            "firstName": "Ruth",
                            "lastName": "Kimchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kimchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 129
                            }
                        ],
                        "text": "According to the global precedent hypothesis advocated by Navon (1977) and validated in numerous studies since (for a review see Kimchi, 1992), the processing of the global structure and the spatial relationships between components precede the analysis of local details."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: scene recognition; gist; spatial envelope; global image feature; spatial frequency; natural image"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16169426,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "01fda35e92a1e0edf36bc6c652af1bfe1ca641e9",
            "isKey": false,
            "numCitedBy": 677,
            "numCiting": 137,
            "paperAbstract": {
                "fragments": [],
                "text": "The question of whether perception is analytic or wholistic is an enduring issue in psychology. The global-precedence hypothesis, considered by many as a modern version of the Gestaltist claim about the perceptual primacy of wholes, has generated a large body of research, but the debate still remains very active. This article reviews the research within the global/local paradigm, and critically analyzes the assumptions underlying this paradigm. The extent to which this line of research contributes to understanding the role of wholistic processing in object perception is discussed. It is concluded that one should be very cautious in making inferences about wholistic processing from the processing advantage of the global level of stimulus structure. A distinction is proposed between global properties, defined by their position in the hierarchical structure of the stimulus, and wholistic properties, defined as a function of interrelations among component parts. It is suggested that a direct comparison between processing of wholistic and component properties is needed to support the hypothesis about the perceptual primacy of wholistic processing."
            },
            "slug": "Primacy-of-wholistic-processing-and-global/local-a-Kimchi",
            "title": {
                "fragments": [],
                "text": "Primacy of wholistic processing and global/local paradigm: a critical review."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The research within the global/local paradigm is reviewed, and it is suggested that a direct comparison between processing of wholistic and component properties is needed to support the hypothesis about the perceptual primacy ofWholistic processing."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological bulletin"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717172"
                        ],
                        "name": "J. Wolfe",
                        "slug": "J.-Wolfe",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Wolfe",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wolfe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2266431"
                        ],
                        "name": "S. Butcher",
                        "slug": "S.-Butcher",
                        "structuredName": {
                            "firstName": "Serena",
                            "lastName": "Butcher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Butcher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3628059"
                        ],
                        "name": "Helga C. Arsenio",
                        "slug": "Helga-C.-Arsenio",
                        "structuredName": {
                            "firstName": "Helga",
                            "lastName": "Arsenio",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helga C. Arsenio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Most of the contours in natural scenes need selective attention to be bound together to form a shape of higher complexity (Treisman and Gelade, 1980; Wolfe and Bennet, 1997;  Wolfe et al., 2002 ), but contours persistent through the scale space might need fewer attentional (or computational) resources to be represented early on. Therefore, one cannot dismiss the possibility that the analysis of fine contours and texture characteristics could ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 143
                            }
                        ],
                        "text": "\u2026scenes need selective attention to be bound together to form a shape of higher complexity (Treisman and Gelade, 1980; Wolfe and Bennet, 1997; Wolfe et al., 2002), but contours persistent through the scale space might need fewer attentional (or computational) resources to be represented\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9294652,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "44b36024279299d2e0300c7ae23fc5c5d1223480",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "In seven experiments, observers searched for a scrambled object among normal objects. The critical comparison was between repeated search in which the same set of stimuli remained present in fixed positions in the display for many (>100) trials and unrepeated conditions in which new stimuli were presented on each trial. In repeated search conditions, observers monitored an essentially stable display for the disruption of a clearly visible object. This is an extension of repeated search experiments in which subjects search a fixed set of items for different targets on each trial (Wolfe, Klempen, & Dahlen, 2000) and can be considered as a form of a \"change blindness\" task. The unrepeated search was very inefficient, showing that a scrambled object does not \"pop-out\" among intact objects (or vice versa). Interestingly, the repeated search condition was just as inefficient, as if participants had to search for the scrambled target even after extensive experience with the specific change in the specific scene. The results suggest that the attentional processes involved in searching for a target in a novel scene may be very similar to those used to confirm the presence of a target in a familiar scene."
            },
            "slug": "An-unbinding-problem-The-disintegration-of-visible,-Wolfe-Oliva",
            "title": {
                "fragments": [],
                "text": "An unbinding problem? The disintegration of visible, previously attended objects does not attract attention."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The results suggest that the attentional processes involved in searching for a target in a novel scene may be very similar to those used to confirm the presence of a targets in a familiar scene."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of vision"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7326223"
                        ],
                        "name": "L. Itti",
                        "slug": "L.-Itti",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Itti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Itti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145521470"
                        ],
                        "name": "G. Rees",
                        "slug": "G.-Rees",
                        "structuredName": {
                            "firstName": "Geraint",
                            "lastName": "Rees",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Rees"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727853"
                        ],
                        "name": "John K. Tsotsos",
                        "slug": "John-K.-Tsotsos",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tsotsos",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John K. Tsotsos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 54123739,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "8419ec7c5587924208322d1bc72bfae87bd96025",
            "isKey": false,
            "numCitedBy": 454,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A key property of neural processing in higher mammals is the ability to focus resources by selectively directing attention to relevant perceptions, thoughts or actions. Research into attention has grown rapidly over the past two decades, as new techniques have become available to study higher brain function in humans, non-human primates, and other mammals. Neurobiology of Attention is the first encyclopedic volume to summarize the latest developments in attention research. An authoritative collection of over 100 chapters organized into thematic sections provides both broad coverage and access to focused, up-to-date research findings. This book presents a state-of-the-art multidisciplinary perspective on psychological, physiological and computational approaches to understanding the neurobiology of attention. Ideal for students, as a reference handbook or for rapid browsing, the book has a wide appeal to anybody intereseted in attention research. * Contains numerous quick-reference articles covering the breadth of investigation into the subject of attention * Provides extensive introductory commentary to orient and guide the reader * Includes the most recent research results in this field of study. \u00a9 2005 Elsevier Inc. All rights reserved."
            },
            "slug": "Neurobiology-of-Attention-Itti-Rees",
            "title": {
                "fragments": [],
                "text": "Neurobiology of Attention"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Neurobiology of Attention is the first encyclopedic volume to summarize the latest developments in attention research, and presents a state-of-the-art multidisciplinary perspective on psychological, physiological and computational approaches to understanding the neurobiology of attention."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145944906"
                        ],
                        "name": "M. Potter",
                        "slug": "M.-Potter",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Potter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Potter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 103
                            }
                        ],
                        "text": "The gist refers to the meaningful information that an observer can identify from a glimpse at a scene (Potter, 1975; Oliva, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35385513,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "29c5af8f630bb688ad627e6f750ba5c10fc8b86c",
            "isKey": false,
            "numCitedBy": 584,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Viewers briefly glimpsed pictures presented in a sequence at rates up to eight per second. They recognized a target picture as accurately and almost as rapidly when they knew only its meaning given by a name (for example, a boat) as when they had seen the picture itself in advance."
            },
            "slug": "Meaning-in-visual-search.-Potter",
            "title": {
                "fragments": [],
                "text": "Meaning in visual search."
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Viewers briefly glimpsed pictures presented in a sequence at rates up to eight per second and recognized a target picture as accurately and almost as rapidly when they knew only its meaning given by a name."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4809524"
                        ],
                        "name": "V. Maljkovic",
                        "slug": "V.-Maljkovic",
                        "structuredName": {
                            "firstName": "Vera",
                            "lastName": "Maljkovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Maljkovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145457269"
                        ],
                        "name": "P. Martini",
                        "slug": "P.-Martini",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Martini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Martini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 196
                            }
                        ],
                        "text": "\u2026Fax: +1-617-258-8654; E-mail: oliva@mit.edu\nDOI: 10.1016/S0079-6123(06)55002-2 23\nglimpse of each picture, you can identify each shot\u2019s meaning, the actors and the emotion depicted in each scene (Maljkovic and Martini, 2005) even though you will not necessarily remember the details of the trailer."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 143
                            }
                        ],
                        "text": "1016/S0079-6123(06)55002-2 23 glimpse of each picture, you can identify each shot\u2019s meaning, the actors and the emotion depicted in each scene (Maljkovic and Martini, 2005) even though you will not necessarily remember the details of the trailer."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7325509,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "552b708b3151bfbd8cb206b3f27f51c7e596c31d",
            "isKey": true,
            "numCitedBy": 73,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "The emotional content of visual images can be parameterized along two dimensions: valence (pleasantness) and arousal (intensity of emotion). In this study we ask how these distinct emotional dimensions affect the short-term memory of human observers viewing a rapid stream of images and trying to remember their content. We show that valence and arousal modulate short-term memory as independent factors. Arousal influences dramatically the average speed of data accumulation in memory: higher arousal results in faster accumulation. Valence has a more interesting effect: while a picture is being viewed, information from positive and neutral scenes accumulates in memory at a constant rate, whereas information from negative scenes is encoded slowly at first, then increasingly faster. We provide evidence showing that neither differences in low-level image properties nor differences in the ability to apprehend the meaning of images at short exposures can account for the observed results, and propose that the effects are specific to the short-term memory mechanism. We interpret this pattern of results to mean that information accumulation in short-term memory is a controlled process, whose gain is modulated by valence and arousal acting as endogenous attentional cues."
            },
            "slug": "Short-term-memory-for-scenes-with-affective-Maljkovic-Martini",
            "title": {
                "fragments": [],
                "text": "Short-term memory for scenes with affective content."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that valence and arousal modulate short-term memory as independent factors, and interpret this pattern of results to mean that information accumulation in short- term memory is a controlled process, whose gain is modulated by valenceand arousal acting as endogenous attentional cues."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334226"
                        ],
                        "name": "D. Hubel",
                        "slug": "D.-Hubel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hubel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hubel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2629471"
                        ],
                        "name": "T. Wiesel",
                        "slug": "T.-Wiesel",
                        "structuredName": {
                            "firstName": "Torsten",
                            "lastName": "Wiesel",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wiesel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: scene recognition; gist; spatial envelope; global image feature; spatial frequency; natural image"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 215
                            }
                        ],
                        "text": "This suggests that a reliable scene representation can be built, in a feed-forward manner, from the same low-level features used for local neural representations of an image (receptive fields of early visual areas, Hubel and Wiesel, 1968)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7136759,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "c5f5311fa1f34159ab3a0a1d58da51cd0340a640",
            "isKey": false,
            "numCitedBy": 6319,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "1. The striate cortex was studied in lightly anaesthetized macaque and spider monkeys by recording extracellularly from single units and stimulating the retinas with spots or patterns of light. Most cells can be categorized as simple, complex, or hypercomplex, with response properties very similar to those previously described in the cat. On the average, however, receptive fields are smaller, and there is a greater sensitivity to changes in stimulus orientation. A small proportion of the cells are colour coded."
            },
            "slug": "Receptive-fields-and-functional-architecture-of-Hubel-Wiesel",
            "title": {
                "fragments": [],
                "text": "Receptive fields and functional architecture of monkey striate cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The striate cortex was studied in lightly anaesthetized macaque and spider monkeys by recording extracellularly from single units and stimulating the retinas with spots or patterns of light, with response properties very similar to those previously described in the cat."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of physiology"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3299879"
                        ],
                        "name": "L. Chalupa",
                        "slug": "L.-Chalupa",
                        "structuredName": {
                            "firstName": "Leo",
                            "lastName": "Chalupa",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Chalupa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8493495"
                        ],
                        "name": "J. Werner",
                        "slug": "J.-Werner",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Werner",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Werner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4421019"
                        ],
                        "name": "C. Barnstable",
                        "slug": "C.-Barnstable",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Barnstable",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Barnstable"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 141896166,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "a9d01339fd63e07d0e8ac6881b0309f94d287fcc",
            "isKey": false,
            "numCitedBy": 988,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Historical foundations developmental processes retinal mechanisms and processes organization of visual pathways subcortical processing processing in primary visual cortex detection and sampling brightness and colour from, shape and object recognition motion, depth and spatial relationships eye movements attention and cognition theoretical and computational perspectives."
            },
            "slug": "The-visual-neurosciences-Chalupa-Werner",
            "title": {
                "fragments": [],
                "text": "The visual neurosciences"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Historical foundations developmental processes retinal mechanisms and processes organization of visual pathways subcortical processing processing in primary visual cortex detection and sampling brightness and colour from, shape and object recognition motion, depth and spatial relationships eye movements attention and cognition theoretical and computational perspectives."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 266
                            }
                        ],
                        "text": "Building a scene representation from global image features\nHigh-level properties of a scene such as the degree of perspective or the mean depth of the space that the scene subtends have been found to be correlated with the configuration of low-level image features (Torralba and Oliva, 2002, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 129
                            }
                        ],
                        "text": "This permits to evaluate the degree of openness or mean depth of an image by measuring the distribution of\nlocal-image features (Torralba and Oliva, 2002, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 147
                            }
                        ],
                        "text": "\u2026research has shown that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; Oliva and Torralba, 2001; Torralba and Oliva, 2003; McCotter et al., 2005) and can help to predict the presence or absence of objects in natural images (Torralba, 2003a;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 272
                            }
                        ],
                        "text": "\u2026that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; Oliva and Torralba, 2001; Torralba and Oliva, 2003; McCotter et al., 2005) and can help to predict the presence or absence of objects in natural images (Torralba, 2003a; Torralba and Oliva, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistics of Natural Images Categories"
            },
            "venue": {
                "fragments": [],
                "text": "Network: Computation in Neural Systems"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 272
                            }
                        ],
                        "text": "\u2026that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; Oliva and Torralba, 2001; Torralba and Oliva, 2003; McCotter et al., 2005) and can help to predict the presence or absence of objects in natural images (Torralba, 2003a; Torralba and Oliva, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 125
                            }
                        ],
                        "text": "In addition to color, research has shown that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; Oliva and Torralba, 2001; Torralba and Oliva, 2003; McCotter et al., 2005) and can help to predict the presence or absence of objects in natural images (Torralba, 2003a; Torralba and Oliva, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 129
                            }
                        ],
                        "text": "This permits to evaluate the degree of openness or mean depth of an image by measuring the distribution of\nlocal-image features (Torralba and Oliva, 2002, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 266
                            }
                        ],
                        "text": "Building a scene representation from global image features\nHigh-level properties of a scene such as the degree of perspective or the mean depth of the space that the scene subtends have been found to be correlated with the configuration of low-level image features (Torralba and Oliva, 2002, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 147
                            }
                        ],
                        "text": "\u2026research has shown that the configuration of contours is also a key diagnostic cue of scene categories (Baddeley, 1997; Oliva and Torralba, 2001; Torralba and Oliva, 2003; McCotter et al., 2005) and can help to predict the presence or absence of objects in natural images (Torralba, 2003a;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 85
                            }
                        ],
                        "text": ", 2005) and can help to predict the presence or absence of objects in natural images (Torralba, 2003a; Torralba and Oliva, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistics of natural images categories. Network: Comput"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Systems,"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136978"
                        ],
                        "name": "Michelle R. Greene",
                        "slug": "Michelle-R.-Greene",
                        "structuredName": {
                            "firstName": "Michelle",
                            "lastName": "Greene",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michelle R. Greene"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 198
                            }
                        ],
                        "text": "Colored surfaces, in addition to providing useful segmentation cues for parsing the image (Carson et al., 2002), also informs about semantic properties of a place, such as its probable temperature (Greene and Oliva, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 96471551,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2f256bf036e554f2ee2687cbd189d35e202a369",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Better-to-run-than-to-hide:-The-time-course-of-Greene-Oliva",
            "title": {
                "fragments": [],
                "text": "Better to run than to hide: The time course of naturalistic scene decisions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 272
                            }
                        ],
                        "text": "\u2026real-world scenes (global contextual priming, Torralba 2003a) and, on the other hand, provide a formal instance of a feed-forward mechanism for scene context evaluation, for the guidance of attention and eye movements in the scene (Oliva et al., 2003; Torralba, 2003a,b; Torralba et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 558,
                                "start": 496
                            }
                        ],
                        "text": "Global image features and the spatial envelope representation are not meant to be an alternative to local image analysis but serve as a parallel pathway that can, on the one hand, quickly constrain local analysis, narrowing down the search for object in cluttered, real-world scenes (global contextual priming, Torralba 2003a) and, on the other hand, provide a formal instance of a feed-forward mechanism for scene context evaluation, for the guidance of attention and eye movements in the scene (Oliva et al., 2003; Torralba, 2003a,b; Torralba et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Contextual guidance of attention in natural scenes: the role of global features on object"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 272
                            }
                        ],
                        "text": "\u2026real-world scenes (global contextual priming, Torralba 2003a) and, on the other hand, provide a formal instance of a feed-forward mechanism for scene context evaluation, for the guidance of attention and eye movements in the scene (Oliva et al., 2003; Torralba, 2003a,b; Torralba et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Contextual guidance of attention in natural scenes : the role of global features on object search"
            },
            "venue": {
                "fragments": [],
                "text": "Psychol . Rev ."
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 149
                            }
                        ],
                        "text": "\u2026of most real-world scenes can be inferred from their spatial layout (e.g., an arrangement of basic geometrical forms such as simple Geons clusters, Biederman, 1995; the spatial relationships between regions or blobs of particular size and aspect ratio, Schyns and Oliva, 1994; Sanocki and Epstein,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visual object recognition In An Invitation to Cognitive Science: Visual Cognition"
            },
            "venue": {
                "fragments": [],
                "text": "Visual object recognition In An Invitation to Cognitive Science: Visual Cognition"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 149
                            }
                        ],
                        "text": "\u2026of most real-world scenes can be inferred from their spatial layout (e.g., an arrangement of basic geometrical forms such as simple Geons clusters, Biederman, 1995; the spatial relationships between regions or blobs of particular size and aspect ratio, Schyns and Oliva, 1994; Sanocki and Epstein,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visual object recognition An Invitation to Cognitive Science"
            },
            "venue": {
                "fragments": [],
                "text": "Visual Cognition"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 139
                            }
                        ],
                        "text": "Research over the last decade has made substantial progress toward understanding the brain\nmechanisms underlying human object recognition (Kanwisher, 2003; Grill-Spector and Malach, 2004) and its modeling (Riesenhuber and Poggio, 1999; Ullman et al., 2002; Torralba et al., 2004; Serre et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The ventral visual object pathway in humans: evidence from fMRI The Visual Neurosciences"
            },
            "venue": {
                "fragments": [],
                "text": "The ventral visual object pathway in humans: evidence from fMRI The Visual Neurosciences"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 148
                            }
                        ],
                        "text": "\u2026studies showed that within a 30-ms exposure, both low and high spatial frequency bands from a hybrid image were registered by the visual system 1 (Parker et al., 1992, 1996; Oliva and Schyns, 1997, Exp.1), but that the requirements of the task determined which scale, coarse or fine, was\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Role of coarse and fine information"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 198
                            }
                        ],
                        "text": "They found a region of cortex referred to as the parahippocampal place area (PPA) that responds more strongly to pictures of intact scenes (indoors, outdoors, closeup views), than to objects alone (Epstein et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The parahippocampal place area: perception, encoding, or memory"
            },
            "venue": {
                "fragments": [],
                "text": "retrieval? Neuron,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 92
                            }
                        ],
                        "text": "Several methods of image analysis can be used to learn a suitable basis of global features (Vailaya et al., 1998; Oliva and Torralba, 2001; Vogel and Schiele, 2004; Fei-Fei and Perona, 2005) that capture the statistical regularities of natural-scene images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On image classification: city images"
            },
            "venue": {
                "fragments": [],
                "text": "vs. landscapes. Patt. Recogn.,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 102
                            }
                        ],
                        "text": "The diagnosticity of colored surfaces in an image seems to be a key element of fast scene recognition (Goffaux et al., 2005; Oliva & Schyns, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 127
                            }
                        ],
                        "text": "The diagnosticity of colored surfaces in an image seems to be a key element of fast scene recognition (Oliva and Schyns, 2000; Goffaux et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 84
                            }
                        ],
                        "text": "The neural correlates of the role of color layout has been recently investigated by Goffaux et al. (2005), who\nhave observed an Event-Related Potential (ERP) frontal signal 150ms after image onset (a well-documented temporal marker of image categorization, Thorpe et al., 1996; Van Rullen and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "natural images predicts contour grouping performances"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Res.,"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Blobworld: image"
            },
            "venue": {
                "fragments": [],
                "text": "Visual Cognition (2nd edition). M. Kosslyn and D.N. Osherson (eds.),"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 198
                            }
                        ],
                        "text": "They found a region of cortex referred to as the parahippocampal place area (PPA) that responds more strongly to pictures of intact scenes (indoors, outdoors, closeup views), than to objects alone (Epstein et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The parahippocampal place area : perception , encoding , or memory retrieval ?"
            },
            "venue": {
                "fragments": [],
                "text": "Neuron"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: scene recognition; gist; spatial envelope; global image feature; spatial frequency; natural image"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 103
                            }
                        ],
                        "text": "The gist refers to the meaningful information that an observer can identify from a glimpse at a scene (Potter, 1975; Oliva, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Meaning in visual scenes"
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 148
                            }
                        ],
                        "text": "\u2026studies showed that within a 30-ms exposure, both low and high spatial frequency bands from a hybrid image were registered by the visual system 1 (Parker et al., 1992, 1996; Oliva and Schyns, 1997, Exp.1), but that the requirements of the task determined which scale, coarse or fine, was\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Role of coarse and fine information in face and object processing"
            },
            "venue": {
                "fragments": [],
                "text": "J. Exp. Psychol. Hum. Percept. Perform.,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Role of coarse and fine information in face and object processing"
            },
            "venue": {
                "fragments": [],
                "text": "J . Exp . Psychol . Hum . Percept . Perform ."
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 139
                            }
                        ],
                        "text": "Research over the last decade has made substantial progress toward understanding the brain\nmechanisms underlying human object recognition (Kanwisher, 2003; Grill-Spector and Malach, 2004) and its modeling (Riesenhuber and Poggio, 1999; Ullman et al., 2002; Torralba et al., 2004; Serre et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 47
                            }
                        ],
                        "text": "mechanisms underlying human object recognition (Kanwisher, 2003; Grill-Spector and Malach, 2004) and its modeling (Riesenhuber and Poggio, 1999; Ullman et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The ventral visual object pathway in humans: evidence from fMRI"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Preattentive object files: shapeless bundles"
            },
            "venue": {
                "fragments": [],
                "text": "after onset of a stimulus. J. Opt. Soc.Am:A,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 280
                            }
                        ],
                        "text": "Research over the last decade has made substantial progress toward understanding the brain\nmechanisms underlying human object recognition (Kanwisher, 2003; Grill-Spector and Malach, 2004) and its modeling (Riesenhuber and Poggio, 1999; Ullman et al., 2002; Torralba et al., 2004; Serre et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object Recognition with Features"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 73
                            }
                        ],
                        "text": "To clarify the terminology we will be using in this article, in the same way that \u2018\u2018red\u2019\u2019 and \u2018\u2018vertical\u2019\u2019 are local feature values of an object (Treisman and Gelade, 1980), a specific configuration of local features defines a global feature value of a scene or an object."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: scene recognition; gist; spatial envelope; global image feature; spatial frequency; natural image"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 198
                            }
                        ],
                        "text": "They found a region of cortex referred to as the parahippocampal place area (PPA) that responds more strongly to pictures of intact scenes (indoors, outdoors, closeup views), than to objects alone (Epstein et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The parahippocampal place area: perception, encoding, or memory retrieval? Neuron"
            },
            "venue": {
                "fragments": [],
                "text": "The parahippocampal place area: perception, encoding, or memory retrieval? Neuron"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 150
                            }
                        ],
                        "text": "\u2026a evidence for a preference of the low spatial frequencies in the early stages of visual processing: additional experiments (Oliva and Schyns, 1997; Schyns and Oliva, 1999) showed that, in fact, the visual system can select which spatial scale to process depending on task constraints (e.g., if the\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 174
                            }
                        ],
                        "text": "It is important to stress that this result is not a evidence for a preference of the low-spatial frequencies in the early stages of visual processing: additional experiments (Oliva and Schyns, 1997; Schyns and Oliva, 1999) showed that, in fact, the visual system can select which spatial scale to process depending on task constraints (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "spatial-scale-dependent scene recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 72,
            "methodology": 12
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 96,
        "totalPages": 10
    },
    "page_url": "https://www.semanticscholar.org/paper/Building-the-gist-of-a-scene:-the-role-of-global-in-Oliva-Torralba/9d94fc289d82738a4d1071470b16ba861ea12169?sort=total-citations"
}