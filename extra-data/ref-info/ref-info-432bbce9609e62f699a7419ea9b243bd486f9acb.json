{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Recently research [23] demonstrated ReLUs brings several times speedup in training compared to using tanh units."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "Recently successful neural network methods report that dropout [23], [9] improves learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195908774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "isKey": false,
            "numCitedBy": 80948,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
            },
            "slug": "ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever",
            "title": {
                "fragments": [],
                "text": "ImageNet classification with deep convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143775793"
                        ],
                        "name": "J. Kumar",
                        "slug": "J.-Kumar",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144449660"
                        ],
                        "name": "Peng Ye",
                        "slug": "Peng-Ye",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "Various structure or layoutbased features have been introduced [3], [4], [5], [6] and are shown to be effective for document image classification and retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[4], [6] extended the spatial-pyramid features for document images by using a novel pooling method with horizontalvertical partitions that are adapted to the typical layout of document images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 391056,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31da8cace27a08e6339145f95f190a77197f01b2",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a method for the retrieval of document images with chosen layout characteristics. The proposed method is based on statistics of patch-codewords over different regions of image. We begin with a set of wanted and a random set of unwanted images representative of a large heterogeneous collection. We then use raw-image patches extracted from the unlabeled images to learn a codebook. To model the spatial relationships between patches, the image is recursively partitioned horizontally and vertically, and a histogram of patch-codewords is computed in each partition. The resulting set of features give a high precision and recall for the retrieval of hand-drawn and machine-print table-documents, and unconstrained mixed form-type documents, when trained using a random forest classifier. We compare our method to the spatial-pyramid method, and show that the proposed approach for learning layout characteristics is competitive for document images."
            },
            "slug": "Learning-document-structure-for-retrieval-and-Kumar-Ye",
            "title": {
                "fragments": [],
                "text": "Learning document structure for retrieval and classification"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The proposed method is based on statistics of patch-codewords over different regions of image, which gives a high precision and recall for the retrieval of hand-drawn and machine-print table-documents, and unconstrained mixed form-type documents, when trained using a random forest classifier."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069634816"
                        ],
                        "name": "J. Kumar",
                        "slug": "J.-Kumar",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144449660"
                        ],
                        "name": "Peng Ye",
                        "slug": "Peng-Ye",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "[4], [6] extended the spatial-pyramid features for document images by using a novel pooling method with horizontalvertical partitions that are adapted to the typical layout of document images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 147
                            }
                        ],
                        "text": "We mainly compare our method to previous methods spatial pyramid/random forest (SP-RF) and horizontal-vertical partitioning/random forest (HVP-RF) [6], therefore we follow the same evaluation protocol."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "A median accuracy of of 100% is achieved through 100 partitions of training and test, which ties with [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 78
                            }
                        ],
                        "text": "Various structure or layoutbased features have been introduced [3], [4], [5], [6] and are shown to be effective for document image classification and retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "Our CNN consistently outperforms SP-RF and HVP-RF [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207329118,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7ae643f8c1f987e6ba61f177a340e879a8644e0",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Structural-similarity-for-document-image-and-Kumar-Ye",
            "title": {
                "fragments": [],
                "text": "Structural similarity for document image classification and retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144338164"
                        ],
                        "name": "Siyuan Chen",
                        "slug": "Siyuan-Chen",
                        "structuredName": {
                            "firstName": "Siyuan",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Siyuan Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119287726"
                        ],
                        "name": "Yuan He",
                        "slug": "Yuan-He",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144291081"
                        ],
                        "name": "Jun Sun",
                        "slug": "Jun-Sun",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753831"
                        ],
                        "name": "S. Naoi",
                        "slug": "S.-Naoi",
                        "structuredName": {
                            "firstName": "Satoshi",
                            "lastName": "Naoi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Naoi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Other methods such as [26] achieved similar accuracies, but more training samples are used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12462738,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "887e5ebacf16eebe47a187ff1b1e45bc0d96e464",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Following the recent trend in using low level image features in classifying document images, in this paper we present a novel approach for structured document classification by matching the salient feature points between the query image and the reference images. Our method is robust to diverse training data size, image formats and qualities. Through matching the feature points, image registration is available for the query image as well. Although we aimed for the large domain of the structured document images, our method already achieved zero error rates in the tests on the benchmark NIST tax form databases."
            },
            "slug": "Structured-document-classification-by-matching-Chen-He",
            "title": {
                "fragments": [],
                "text": "Structured document classification by matching local salient features"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper presents a novel approach for structured document classification by matching the salient feature points between the query image and the reference images, which is robust to diverse training data size, image formats and qualities."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "CNNs are good at discovering spatially local correlation by enforcing a local connectivity pattern between neurons of adjacent layers [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35262,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793750"
                        ],
                        "name": "C. Wallraven",
                        "slug": "C.-Wallraven",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Wallraven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wallraven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3033284"
                        ],
                        "name": "B. Caputo",
                        "slug": "B.-Caputo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Caputo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caputo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144813423"
                        ],
                        "name": "Arnulf B. A. Graf",
                        "slug": "Arnulf-B.-A.-Graf",
                        "structuredName": {
                            "firstName": "Arnulf",
                            "lastName": "Graf",
                            "middleNames": [
                                "B.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnulf B. A. Graf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 138
                            }
                        ],
                        "text": "Approaches based on bag-of-words (BOW) models have shown promising results on many computer vision problems, such as image classification [16], scene understanding [17] and document image classification [18], [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4573035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c393b31ca71e8c4dd7c8c5a11653b18447c90466",
            "isKey": false,
            "numCitedBy": 462,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent developments in computer vision have shown that local features can provide efficient representations suitable for robust object recognition. Support vector machines have been established as powerful learning algorithms with good generalization capabilities. We combine these two approaches and propose a general kernel method for recognition with local features. We show that the proposed kernel satisfies the Mercer condition and that it is, suitable for many established local feature frameworks. Large-scale recognition results are presented on three different databases, which demonstrate that SVMs with the proposed kernel perform better than standard matching techniques on local features. In addition, experiments on noisy and occluded images show that local feature representations significantly outperform global approaches."
            },
            "slug": "Recognition-with-local-features:-the-kernel-recipe-Wallraven-Caputo",
            "title": {
                "fragments": [],
                "text": "Recognition with local features: the kernel recipe"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Large-scale recognition results are presented, which demonstrate that SVMs with the proposed kernel perform better than standard matching techniques on local features and that local feature representations significantly outperform global approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069634816"
                        ],
                        "name": "J. Kumar",
                        "slug": "J.-Kumar",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36073757"
                        ],
                        "name": "R. Prasad",
                        "slug": "R.-Prasad",
                        "structuredName": {
                            "firstName": "Rohit",
                            "lastName": "Prasad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Prasad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39784761"
                        ],
                        "name": "Huaigu Cao",
                        "slug": "Huaigu-Cao",
                        "structuredName": {
                            "firstName": "Huaigu",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huaigu Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404588675"
                        ],
                        "name": "W. Abd-Almageed",
                        "slug": "W.-Abd-Almageed",
                        "structuredName": {
                            "firstName": "Wael",
                            "lastName": "Abd-Almageed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Abd-Almageed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145603129"
                        ],
                        "name": "P. Natarajan",
                        "slug": "P.-Natarajan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Natarajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Natarajan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 209
                            }
                        ],
                        "text": "Approaches based on bag-of-words (BOW) models have shown promising results on many computer vision problems, such as image classification [16], scene understanding [17] and document image classification [18], [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6294186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fb819a736b808b76c2cbcd94f714792dbd3f01d",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a novel method for extracting handwritten and printed text zones from noisy document images with mixed content. We use Triple-Adjacent-Segment (TAS) based features which encode local shape characteristics of text in a consistent manner. We first construct two codebooks of the shape features extracted from a set of handwritten and printed text documents respectively. We then compute the normalized histogram of codewords for each segmented zone and use it to train a Support Vector Machine (SVM) classifier. The codebook based approach is robust to the background noise present in the image and TAS features are invariant to translation, scale and rotation of text. In experiments, we show that a pixel-weighted zone classification accuracy of 98% can be achieved for noisy Arabic documents. Further, we demonstrate the effectiveness of our method for document page classification and show that a high precision can be achieved for the detection of machine printed documents. The proposed method is robust to the size of zones, which may contain text content at line or paragraph level."
            },
            "slug": "Shape-codebook-based-handwritten-and-machine-text-Kumar-Prasad",
            "title": {
                "fragments": [],
                "text": "Shape codebook based handwritten and machine printed text zone extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A novel method for extracting handwritten and printed text zones from noisy document images with mixed content using Triple-Adjacent-Segment (TAS) based features which encode local shape characteristics of text in a consistent manner is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3351018"
                        ],
                        "name": "Pedro Quelhas",
                        "slug": "Pedro-Quelhas",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Quelhas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro Quelhas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1824057"
                        ],
                        "name": "Florent Monay",
                        "slug": "Florent-Monay",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Monay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florent Monay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719610"
                        ],
                        "name": "J. Odobez",
                        "slug": "J.-Odobez",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Odobez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odobez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403029865"
                        ],
                        "name": "D. G\u00e1tica-P\u00e9rez",
                        "slug": "D.-G\u00e1tica-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "G\u00e1tica-P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G\u00e1tica-P\u00e9rez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 164
                            }
                        ],
                        "text": "Approaches based on bag-of-words (BOW) models have shown promising results on many computer vision problems, such as image classification [16], scene understanding [17] and document image classification [18], [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14100761,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba6417baed41a8f0fd4cab342aa214704389dcf9",
            "isKey": false,
            "numCitedBy": 452,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach to model visual scenes in image collections, based on local invariant features and probabilistic latent space models. Our formulation provides answers to three open questions:(l) whether the invariant local features are suitable for scene (rather than object) classification; (2) whether unsupennsed latent space models can be used for feature extraction in the classification task; and (3) whether the latent space formulation can discover visual co-occurrence patterns, motivating novel approaches for image organization and segmentation. Using a 9500-image dataset, our approach is validated on each of these issues. First, we show with extensive experiments on binary and multi-class scene classification tasks, that a bag-of-visterm representation, derived from local invariant descriptors, consistently outperforms state-of-the-art approaches. Second, we show that probabilistic latent semantic analysis (PLSA) generates a compact scene representation, discriminative for accurate classification, and significantly more robust when less training data are available. Third, we have exploited the ability of PLSA to automatically extract visually meaningful aspects, to propose new algorithms for aspect-based image ranking and context-sensitive image segmentation."
            },
            "slug": "Modeling-scenes-with-local-descriptors-and-latent-Quelhas-Monay",
            "title": {
                "fragments": [],
                "text": "Modeling scenes with local descriptors and latent aspects"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Probabilistic latent semantic analysis generates a compact scene representation, discriminative for accurate classification, and significantly more robust when less training data are available, and the ability of PLSA to automatically extract visually meaningful aspects is exploited to propose new algorithms for aspect-based image ranking and context-sensitive image segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2691315"
                        ],
                        "name": "Nawei Chen",
                        "slug": "Nawei-Chen",
                        "structuredName": {
                            "firstName": "Nawei",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nawei Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703931"
                        ],
                        "name": "D. Blostein",
                        "slug": "D.-Blostein",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Blostein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blostein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 152
                            }
                        ],
                        "text": "Existing approaches in the literatures differ from each other mainly in their choices of local features, global representations and learning mechanisms [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 189
                            }
                        ],
                        "text": "A detailed survey on document classification based on three components: the problem statement, the classifier architecture, and the performance evaluation can be found in Chen and Blostein [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2813627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb033a3dd89765bc14dfdef4ed081d358a305078",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Document image classification is an important step in Office Automation, Digital Libraries, and other document image analysis applications. There is great diversity in document image classifiers: they differ in the problems they solve, in the use of training data to construct class models, and in the choice of document features and classification algorithms. We survey this diverse literature using three components: the problem statement, the classifier architecture, and performance evaluation. This brings to light important issues in designing a document classifier, including the definition of document classes, the choice of document features and feature representation, and the choice of classification algorithm and learning mechanism. We emphasize techniques that classify single-page typeset document images without using OCR results. Developing a general, adaptable, high-performance classifier is challenging due to the great variety of documents, the diverse criteria used to define document classes, and the ambiguity that arises due to ill-defined or fuzzy document classes."
            },
            "slug": "A-survey-of-document-image-classification:-problem-Chen-Blostein",
            "title": {
                "fragments": [],
                "text": "A survey of document image classification: problem statement, classifier architecture and performance evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This work focuses on techniques that classify single-page typeset document images without using OCR results, and brings to light important issues in designing a document classifier, including the definition of document classes, the choices of document features and feature representation, and the choice of classification algorithm and learning mechanism."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403434962"
                        ],
                        "name": "K. Collins-Thompson",
                        "slug": "K.-Collins-Thompson",
                        "structuredName": {
                            "firstName": "Kevyn",
                            "lastName": "Collins-Thompson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Collins-Thompson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "Collins-Thompson and Nickolov [12] proposed a model for estimating the inter-page similarity in ordered collections 2014 22nd International Conference on Pattern Recognition"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 0
                            }
                        ],
                        "text": "Collins-Thompson and Nickolov [12] proposed a model for estimating the inter-page similarity in ordered collections\n1051-4651/14 $31.00 \u00a9 2014 IEEE DOI 10.1109/ICPR.2014.546\n3168\nof document images."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1366361,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29febec8e0415fb3ac4b64a269d2c3016f6d9b65",
            "isKey": true,
            "numCitedBy": 32,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "For text, audio, video, and still images, a number of projects have addressed the problem of estimating inter-object similarity and the related problem of finding transition, or \u2018segmentation\u2019 points in a stream of objects of the same media type. There has been relatively little work in this area for document images, which are typically text-intensive and contain a mixture of layout, text-based, and image features. Beyond simple partitioning, the problem of clustering related page images is also important, especially for information retrieval problems such as document image searching and browsing. Motivated by this, we describe a model for estimating inter-page similarity in ordered collections of document images, based on a combination of text and layout features. The features are used as input to a discriminative classifier, whose output is used in a constrained clustering criterion. We do a task-based evaluation of our method by applying it the problem of automatic document separation during batch scanning. Using layout and page numbering features, our algorithm achieved a separation accuracy of 95.6% on the test collection."
            },
            "slug": "A-Clustering-Based-Algorithm-for-Automatic-Document-Collins-Thompson",
            "title": {
                "fragments": [],
                "text": "A Clustering-Based Algorithm for Automatic Document Separation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A model for estimating inter-page similarity in ordered collections of document images, based on a combination of text and layout features is described, which achieves a separation accuracy of 95.6% on the test collection."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2187254"
                        ],
                        "name": "K. V. U. Reddy",
                        "slug": "K.-V.-U.-Reddy",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Reddy",
                            "middleNames": [
                                "V.",
                                "Umamaheswara"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. V. U. Reddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723877"
                        ],
                        "name": "V. Govindaraju",
                        "slug": "V.-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Govindaraju"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15] addressed the form classification problem with a classifier based on the k-means algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26819227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ec134307c11bd35b69d3dfeed692bd85a406fa4",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of form classification is to assign a single-page form image to one of a set of predefined form types or classes. We classify the form images using low level pixel density information from the binary images of the documents. In this paper, we solve the form classification problem with a classifier based on the k-means algorithm, supported by adaptive boosting. Our classification method is tested on the NIST scanned tax forms data bases (special forms databases 2 and 6) which include machine-typed and handwritten documents. Our method improves the performance over published results on the same databases, while still using a simple set of image features."
            },
            "slug": "Form-classification-Reddy-Govindaraju",
            "title": {
                "fragments": [],
                "text": "Form classification"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper solves the form classification problem with a classifier based on the k-means algorithm, supported by adaptive boosting, and improves the performance over published results on the same databases, while still using a simple set of image features."
            },
            "venue": {
                "fragments": [],
                "text": "DRR"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 196
                            }
                        ],
                        "text": "One of the early methods proposes the creation of spatial-pyramid features by partitioning the image into increasingly finer grids and computing the weighted histogram based kernel in each region [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2421251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dbaff29d3898cf60f63f5a34cb9610ebb75220c",
            "isKey": false,
            "numCitedBy": 8328,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba\u2019s \"gist\" and Lowe\u2019s SIFT descriptors."
            },
            "slug": "Beyond-Bags-of-Features:-Spatial-Pyramid-Matching-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence that exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2897313"
                        ],
                        "name": "Nitish Srivastava",
                        "slug": "Nitish-Srivastava",
                        "structuredName": {
                            "firstName": "Nitish",
                            "lastName": "Srivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nitish Srivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "Recently successful neural network methods report that dropout [23], [9] improves learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "We employ dropout [9] to prevent overfitting."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14832074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1366de5bb112746a555e9c0cd00de3ad8628aea8",
            "isKey": false,
            "numCitedBy": 6191,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This \"overfitting\" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random \"dropout\" gives big improvements on many benchmark tasks and sets new records for speech and object recognition."
            },
            "slug": "Improving-neural-networks-by-preventing-of-feature-Hinton-Srivastava",
            "title": {
                "fragments": [],
                "text": "Improving neural networks by preventing co-adaptation of feature detectors"
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143685864"
                        ],
                        "name": "Yi Yang",
                        "slug": "Yi-Yang",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145211099"
                        ],
                        "name": "S. Newsam",
                        "slug": "S.-Newsam",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Newsam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Newsam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 188
                            }
                        ],
                        "text": "Recently, there has been a focus on selecting the optimal feature combination strategy and efficient ways to learn these local statistics, and a number of methods have been proposed [21], [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 231648,
            "fieldsOfStudy": [
                "Environmental Science",
                "Computer Science"
            ],
            "id": "93deda60276a7e5b378c41013af6604b45351588",
            "isKey": false,
            "numCitedBy": 302,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel image representation termed spatial pyramid co-occurrence which characterizes both the photometric and geometric aspects of an image. Specifically, the co-occurrences of visual words are computed with respect to spatial predicates over a hierarchical spatial partitioning of an image. The representation captures both the absolute and relative spatial arrangement of the words and, through the choice and combination of the predicates, can characterize a variety of spatial relationships. Our representation is motivated by the analysis of overhead imagery such as from satellites or aircraft. This imagery generally does not have an absolute reference frame and thus the relative spatial arrangement of the image elements often becomes the key discriminating feature. We validate this hypothesis using a challenging ground truth image dataset of 21 land-use classes manually extracted from high-resolution aerial imagery. Our approach is shown to result in higher classification rates than a non-spatial bagof- visual-words approach as well as a popular approach for characterizing the absolute spatial arrangement of visual words, the spatial pyramid representation of Lazebnik et al. [7]. While our primary objective is analyzing overhead imagery, we demonstrate that our approach achieves state-of-the-art performance on the Graz-01 object class dataset and performs competitively on the 15 Scene dataset."
            },
            "slug": "Spatial-pyramid-co-occurrence-for-image-Yang-Newsam",
            "title": {
                "fragments": [],
                "text": "Spatial pyramid co-occurrence for image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A novel image representation termed spatial pyramid co-occurrence which characterizes both the photometric and geometric aspects of an image which achieves state-of-the-art performance on the Graz-01 object class dataset and performs competitively on the 15 Scene dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084270570"
                        ],
                        "name": "Guillaume Joutel",
                        "slug": "Guillaume-Joutel",
                        "structuredName": {
                            "firstName": "Guillaume",
                            "lastName": "Joutel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guillaume Joutel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721326"
                        ],
                        "name": "V. Eglin",
                        "slug": "V.-Eglin",
                        "structuredName": {
                            "firstName": "V\u00e9ronique",
                            "lastName": "Eglin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Eglin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784847"
                        ],
                        "name": "S. Bres",
                        "slug": "S.-Bres",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Bres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739381"
                        ],
                        "name": "H. Emptoz",
                        "slug": "H.-Emptoz",
                        "structuredName": {
                            "firstName": "Hubert",
                            "lastName": "Emptoz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Emptoz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[13] presented an approach for the retrieval of handwritten historical documents at page level based on the curvelet transform to compose a unique signature for each page."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16683602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "443adf054bbf093cd5c90900d7f5594ff3ebb15c",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new use of the curvelet transform as a multiscale method for indexing linear singularities and curved handwritten shapes in documents images. As it belongs to the wavelet family, this representation can be useful at several scales of details. The proposed scheme for handwritten shape characterization targets to detect oriented and curved fragments at different scales so as to compose an unique signature for each handwritten analyzed samples. In this way, curvelets coefficients are used as a representation tool for handwriting when searching in large manuscripts databases by finding similar handwritten samples. Current results of ancient manuscripts retrieval are very promising with very satisfying precisions and recalls."
            },
            "slug": "Curvelets-Based-Queries-for-CBIR-Application-in-Joutel-Eglin",
            "title": {
                "fragments": [],
                "text": "Curvelets Based Queries for CBIR Application in Handwriting Collections"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This paper presents a new use of the curvelet transform as a multiscale method for indexing linear singularities and curved handwritten shapes in documents images to compose an unique signature for each handwritten analyzed samples."
            },
            "venue": {
                "fragments": [],
                "text": "Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1941286"
                        ],
                        "name": "Christian K. Shin",
                        "slug": "Christian-K.-Shin",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Shin",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian K. Shin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Shin and Doermann [11] defined visual similarity of layout structures and applied supervised classification for each specific type."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8015543,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d67d64b16537107ccb81af1915b7b0b40b147300",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe issues related to the measurement of structural similarity between document images. We define structural similarity, and discuss the benefits of using it as a complement to content similarity for querying document image databases. We present an approach to computing a geometrically invariant structural similarity, and use this measure to search document image databases. Our approach supports both full image matching using query by example (QBE) and sub-image matching using query by sketch (QBS). The similarity measure considers spatial and layout structure, and is computed by aggregating content area overlap measures with respect to their underlying column structures. These techniques are tested within the Intelligent Document Image Retrieval (IDIR) System, and results demonstrating effectiveness and efficiency of structure queries with respect to human relevance judgments are presented."
            },
            "slug": "Document-Image-Retrieval-Based-on-Layout-Structural-Shin-Doermann",
            "title": {
                "fragments": [],
                "text": "Document Image Retrieval Based on Layout Structural Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "An approach to computing a geometrically invariant structural similarity, and use this measure to search document image databases, and results demonstrating effectiveness and efficiency of structure queries with respect to human relevance judgments are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IPCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749498"
                        ],
                        "name": "Andrew D. Bagdanov",
                        "slug": "Andrew-D.-Bagdanov",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Bagdanov",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew D. Bagdanov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717056"
                        ],
                        "name": "M. Worring",
                        "slug": "M.-Worring",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Worring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Worring"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 63
                            }
                        ],
                        "text": "Various structure or layoutbased features have been introduced [3], [4], [5], [6] and are shown to be effective for document image classification and retrieval."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "Bagdanov and Worring [3] approached the general problem of genre classification of printed document images using attributed relational graphs (ARGs)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15780873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1546988d9874914a772084aafbb2da3636f08590",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We approach the general problem of classifying machine-printed documents into genres. Layout is a critical factor in recognizing fine-grained genres, as document content features are similar. Document genre is determined from the layout structure detected from scanned binary images of the document pages, using no OCR results and minimal a priori knowledge of document logical structures. Our method uses the attributed relational graphs (ARGs) to represent the layout structure of document instances, and the first order random graphs (FORGs) to represent document genres. In this paper we develop our FORG-based genre classification method and present a comparative evaluation between our technique and a variety of statistical pattern classifiers. FORGs are capable of modeling common layout structure within a document genre and are shown to significantly outperform traditional pattern classification techniques when fine-grained genre distinctions must be drawn."
            },
            "slug": "Fine-grained-document-genre-classification-using-Bagdanov-Worring",
            "title": {
                "fragments": [],
                "text": "Fine-grained document genre classification using first order random graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper develops a FORG-based genre classification method for machine-printed documents and presents a comparative evaluation between the technique and a variety of statistical pattern classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073603971"
                        ],
                        "name": "Vinod Nair",
                        "slug": "Vinod-Nair",
                        "structuredName": {
                            "firstName": "Vinod",
                            "lastName": "Nair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinod Nair"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 99
                            }
                        ],
                        "text": "For the task of document image classification, a new type of neuron, Rectified Linear Units (ReLU) [8], is used in our CNN to speed up training."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 86
                            }
                        ],
                        "text": "Instead of traditional sigmoid or tanh neurons, we use Rectified Linear Units (ReLUs) [8] in the convolutional and fully connected layers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15539264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a538b05ebb01a40323997629e171c91aa28b8e2f",
            "isKey": false,
            "numCitedBy": 12808,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these \"Stepped Sigmoid Units\" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors."
            },
            "slug": "Rectified-Linear-Units-Improve-Restricted-Boltzmann-Nair-Hinton",
            "title": {
                "fragments": [],
                "text": "Rectified Linear Units Improve Restricted Boltzmann Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units that learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060000798"
                        ],
                        "name": "E. Barbu",
                        "slug": "E.-Barbu",
                        "structuredName": {
                            "firstName": "Eugen",
                            "lastName": "Barbu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Barbu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1826457"
                        ],
                        "name": "P. H\u00e9roux",
                        "slug": "P.-H\u00e9roux",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "H\u00e9roux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. H\u00e9roux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143680806"
                        ],
                        "name": "S\u00e9bastien Adam",
                        "slug": "S\u00e9bastien-Adam",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00e9bastien Adam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35863204"
                        ],
                        "name": "\u00c9. Trupin",
                        "slug": "\u00c9.-Trupin",
                        "structuredName": {
                            "firstName": "\u00c9ric",
                            "lastName": "Trupin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c9. Trupin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 203
                            }
                        ],
                        "text": "Approaches based on bag-of-words (BOW) models have shown promising results on many computer vision problems, such as image classification [16], scene understanding [17] and document image classification [18], [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10662134,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf83c2268d4cad01700c9869f34d1d8b275f8616",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A database is only usefull if it is associated a set of procedures allowing to retrieve relevant elements for the users\u2019 needs. A lot of IR techniques have been developed for automatic indexing and retrieval in document databases. Most of these use indexes depending on the textual content of documents, and very few are able to handle graphical or image content without human annotation. \n \nThis paper describes an approach similar to the bag of words technique for automatic indexing of graphical document image databases and different ways to consequently query these databases. In an unsupervised manner, this approach proposes a set of automatically discovered symbols that can be combined with logical operators to build queries."
            },
            "slug": "Using-Bags-of-Symbols-for-Automatic-Indexing-of-Barbu-H\u00e9roux",
            "title": {
                "fragments": [],
                "text": "Using Bags of Symbols for Automatic Indexing of Graphical Document Image Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper describes an approach similar to the bag of words technique for automatic indexing of graphical document image databases and different ways to consequently query these databases using a set of automatically discovered symbols that can be combined with logical operators to build queries."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730636"
                        ],
                        "name": "Yungcheol Byun",
                        "slug": "Yungcheol-Byun",
                        "structuredName": {
                            "firstName": "Yungcheol",
                            "lastName": "Byun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yungcheol Byun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710749"
                        ],
                        "name": "Yillbyung Lee",
                        "slug": "Yillbyung-Lee",
                        "structuredName": {
                            "firstName": "Yillbyung",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yillbyung Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "Byun and Lee [10] used a partial matching method in which document structure recognition and classification is applied to only part of input form images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15262202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e919593a2990ec6020abda6bd658036f221bd5c",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In order to process many kinds of form document, form classification must be performed in the first place. However, a substantial amount of time is required to analyze and recognize such form documents according to the increase of t, lte number of registered models. To solve this problem, w,' suggest document understanding with a partial matchmg method in which form structure recognition and form (:lassification are performed for only some areas of the input form. In this case, the definition of the matching areas and ibrm classification are performed by using a DP matching algorithm. By using this approach, the recognition of an input form and the extraction of field items can be protessed at a high recognition rate in a reasonable time span. in terms of al)plicability, the experimental recognition rate and processing time seem to be encouraging."
            },
            "slug": "Form-classification-using-DP-matching-Byun-Lee",
            "title": {
                "fragments": [],
                "text": "Form classification using DP matching"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "By using this approach, the recognition of an input form and the extraction of field items can be protessed at a high recognition rate in a reasonable time span, and the experimental recognition rate and processing time seem to be encouraging."
            },
            "venue": {
                "fragments": [],
                "text": "SAC '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642099"
                        ],
                        "name": "F. Dubiel",
                        "slug": "F.-Dubiel",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Dubiel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Dubiel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 202
                            }
                        ],
                        "text": "Classifying and grouping document images into known categories is often a prerequisite step towards document understanding tasks, such as text recognition, document retrieval and information extraction [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19200855,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ea4167f9eb9ad893be32ba35147fe4539b6cdd4",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a system which is capable of learning the presentation of document logical structures, exemplarily shown for business letters. Presenting a set of instances to the system, it clusters them into structural concepts and induces a concept hierarchy. This concept hierarchy is taken as a source for classifying future input. The paper introduces the different learning steps, describes how the resulting concept hierarchy is applied for logical labeling and reports on the results."
            },
            "slug": "Clustering-and-classification-of-document-machine-Dengel-Dubiel",
            "title": {
                "fragments": [],
                "text": "Clustering and classification of document structure-a machine learning approach"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A system capable of learning the presentation of document logical structures, exemplarily shown for business letters, is described, which clusters them into structural concepts and induces a concept hierarchy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35151749"
                        ],
                        "name": "G. Agam",
                        "slug": "G.-Agam",
                        "structuredName": {
                            "firstName": "Gady",
                            "lastName": "Agam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Agam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144628595"
                        ],
                        "name": "S. Argamon",
                        "slug": "S.-Argamon",
                        "structuredName": {
                            "firstName": "Shlomo",
                            "lastName": "Argamon",
                            "middleNames": [
                                "Engelson"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Argamon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741208"
                        ],
                        "name": "O. Frieder",
                        "slug": "O.-Frieder",
                        "structuredName": {
                            "firstName": "Ophir",
                            "lastName": "Frieder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Frieder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693690"
                        ],
                        "name": "D. Grossman",
                        "slug": "D.-Grossman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Grossman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Grossman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20833434"
                        ],
                        "name": "J. Heard",
                        "slug": "J.-Heard",
                        "structuredName": {
                            "firstName": "Jefferson",
                            "lastName": "Heard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Heard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "(1) Tobacco litigation dataset [24]: we used 3482 images categorized in 10 genres(classes): report, memo, resume, scientific, letter, news, note, ad, form, email."
                    },
                    "intents": []
                }
            ],
            "corpusId": 19516087,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47c6d10fe8a29fcd1727e805a2b9f804c12e0d4d",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Research and development of information access technology for scanned paper documents has been hampered by the lack of public test collections of realistic scope and complexity. As part of a project to create a prototype system for search and mining of masses of document images, we are assembling a 1.5 terabyte dataset to support evaluation of both end-to-end complex document information processing (CDIP) tasks (e.g., text retrieval and data mining) as well as component technologies such as optical character recognition (OCR), document structure analysis, signature matching, and authorship attribution."
            },
            "slug": "Building-a-test-collection-for-complex-document-Lewis-Agam",
            "title": {
                "fragments": [],
                "text": "Building a test collection for complex document information processing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A 1.5 terabyte dataset is assembled to support evaluation of both end-to-end complex document information processing (CDIP) tasks (e.g., text retrieval and data mining) as well as component technologies such as optical character recognition (OCR), document structure analysis, signature matching, and authorship attribution."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31844557"
                        ],
                        "name": "T. Kochi",
                        "slug": "T.-Kochi",
                        "structuredName": {
                            "firstName": "Tsukasa",
                            "lastName": "Kochi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kochi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066251026"
                        ],
                        "name": "T. Saitoh",
                        "slug": "T.-Saitoh",
                        "structuredName": {
                            "firstName": "Takashi",
                            "lastName": "Saitoh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Saitoh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Kochi and Saitoh [14] proposed a system for identifying the type of a semi-formatted document based on important textual elements extraction and by using a flexible matching strategy for easy model generation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42577487,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c37afa374165479c0789a8748bc47f3ce756a0bb",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "An automatic document entry system is described that identifies the type of document and extracts textual information, such as titles or authors, from semi-formatted document images. The system registers documents, offers easy retrieval of documents used in a daily workflow analyzes the layout structure of documents by using document specific models, and assumes that each type of document is known in advance. In this paper we focus on a method for identifying the type of document."
            },
            "slug": "User-defined-template-for-identifying-document-type-Kochi-Saitoh",
            "title": {
                "fragments": [],
                "text": "User-defined template for identifying document type and extracting information from documents"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An automatic document entry system is described that identifies the type of document and extracts textual information, such as titles or authors, from semi-formatted document images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318)"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "(2) NIST tax-form dataset [25]: a collection of 5590 taxform images from National Institute of Standards and Technology, categorized into 20 classes, with labels like Form1040-1, Form1040-2, Form4562-1, Form2441 and so on."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nist structured forms reference set of binary images (sfrs)"
            },
            "venue": {
                "fragments": [],
                "text": "1991. [Online]. Available: \u3008http://www.nist.gov/srd/nistsd2.cfm\u3009"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 48
                            }
                        ],
                        "text": "We implemented the CNN using the python library Theano [27] which enables easy deployment on a GPU to speed up\nthe process without much manual optimization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "We implemented the CNN using the python library Theano [27] which enables easy deployment on a GPU to speed up"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theano: a CPU and GPU math expression compiler"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Python for Scientific Computing Conference (SciPy), Jun. 2010. 3172"
            },
            "year": 2010
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 17,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 25,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Convolutional-Neural-Networks-for-Document-Image-Kang-Kumar/432bbce9609e62f699a7419ea9b243bd486f9acb?sort=total-citations"
}