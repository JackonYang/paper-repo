{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 67
                            }
                        ],
                        "text": "For these, we refer the reader to the previously mentioned surveys [62, 63, 97]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 143
                            }
                        ],
                        "text": "As an experiment, the entire survey was converted into tabular form for the version of the GREC proceedings later published as a separate book [63]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 116
                            }
                        ],
                        "text": "Reflecting this growing interest, a number of surveys on table processing have appeared over the past several years [37, 47, 62, 63, 97]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": ", [63]) reveals that the question \u201cWhat constitutes a table?\u201d is indeed difficult to answer."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30699745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5cd207fa19e51db1d6eadb0e5e70f1c5b8d1ecd0",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are the only acceptable means of communicating certain types of structured data. A precise definition of \"tabularity\" remains elusive because some bureaucratic forms, multicolumn text layouts, and schematic drawings share many characteristics of tables. There are significant differences between typeset tables, electronic files designed for display of tables, and tables in symbolic form intended for information retrieval. Although most research to date has addressed the extraction of low-level geometric information from scanned raster images of paper tables, the recent trend toward the analysis of tables in electronic form may pave the way to a higherl evel of table understanding. \n \nRecent research on table composition and table analysis has improved ourunde rstanding of the distinction between the logical and physical structures of tables, and has led to improved formalisms for modeling tables. The present study indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display. \n \nAlthough tables are not a conventional format for conveying the primary content of technical papers, here we attempt to subdue our natural garrulity by adopting this genre to communicate what we have to say about tables entirely in tabular form."
            },
            "slug": "A-Tabular-Survey-of-Automated-Table-Processing-Lopresti-Nagy",
            "title": {
                "fragments": [],
                "text": "A Tabular Survey of Automated Table Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The present study indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 116
                            }
                        ],
                        "text": "Reflecting this growing interest, a number of surveys on table processing have appeared over the past several years [37, 47, 62, 63, 97]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "One way we can formally extend the definition is by defining nested labels [47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 54
                            }
                        ],
                        "text": "Indeed, some researchers have offered generalizations [47, 84]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "In the following discussion we show the nested augmentation of Table 2 using the notation of [47]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "Hurst [47] develops a characterization of tables as document objects in context, recognizing the potential for surrounding text to impact the understanding of the table."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "Developed originally in the days of printed or handwritten documents (indeed, tables may pre-date sentential text [47]), they have been adapted to word processors and page composition languages, and form the underlying paradigm for spreadsheets and relational database systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "thesis [47] and a recent paper by Embley et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5481713,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ba28bb5c79f9115b3f3b62593feedf1d73b3027",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis looks at the issues relating to the development of technology capable of processing tables as they appear in textual documents so that their contents may be accessed and further interpreted by standard information extraction and natural language processing systems. The thesis offers a formal description of the table and the description and evaluation of a system which provides instances of that model for table examples. There are three parts to the thesis. The first looks at tables in general terms, suggests where their complexities are to be found, and reviews the literature dealing with research into tables in other fields. The second part introduces a layered model of the table and provides some notational equipment for encoding tables in these component layers. The final part discusses the design, implementation and evaluation of a system which produces an instance of the model for the tables found in a document. It also discusses the design and collection of a corpus of tables used for the training and evaluation of the system. The thesis catalogues a laxge number of phenomena discovered in the corpus collected during the research and provides appropriate terminology."
            },
            "slug": "The-interpretation-of-tables-in-texts-Hurst",
            "title": {
                "fragments": [],
                "text": "The interpretation of tables in texts"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This thesis looks at the issues relating to the development of technology capable of processing tables as they appear in textual documents so that their contents may be accessed and further interpreted by standard information extraction and natural language processing systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41490827,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e9383c894019f34e8cd77b68b89af5c1d42c7e9",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are an important means for communicating information in written media, and understanding such tables is a challenging problem in document layout analysis. In this paper we describe a general solution to the problem of recognizing the structure of a detected table region. First hierarchial clustering is used to identify columns and then spatial and lexical criteria to classify headers. We also address the problem of evaluating table structure recognition. Our model is based on a directed acyclic attribute graph, or table DAG. We describe a new paradigm, 'random graph probing,' for comparing the results returned by the recognition system and the representation created during ground-truthing. Probing is in fact a general concept that could be applied to other document recognition tasks and perhaps even other computer vision problems as well."
            },
            "slug": "Table-structure-recognition-and-its-evaluation-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Table structure recognition and its evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new paradigm, 'random graph probing,' is described for comparing the results returned by the recognition system and the representation created during ground-truthing, which could be applied to other document recognition tasks and perhaps even other computer vision problems as well."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2494216"
                        ],
                        "name": "P. Pyreddy",
                        "slug": "P.-Pyreddy",
                        "structuredName": {
                            "firstName": "Pallavi",
                            "lastName": "Pyreddy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pyreddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Pyreddy and Croft [73] characterize tables in a typed-line-manner due to the limitations of an ASCII representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 189
                            }
                        ],
                        "text": "In the ASCII domain, Pyreddy and Croft report on a table extraction and retrieval experiment involving 6,509 tables from a corpus consisting of 6 years of text from the Wall Street Journal [73]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 52
                            }
                        ],
                        "text": "Among references that address electronic tables are [26, 48, 71, 73]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Pyreddy and Croft have elaborate heuristics to separate leaf cells from other table content but do not differentiate between table captions and headings because they are used in a similar way in their information retrieval system."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13991200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d674f1289f336d88c4ab93e7204a345a302ed2eb",
            "isKey": true,
            "numCitedBy": 96,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables form an important kind of data element in text retrieval. Often, the gist of an entire news article or other exposition can be concisely captured in tabular form. In this paper, we examine the utility of exploiting information other than the key words in a digital document to provide the users with more flexible and powerful query capabilities. More specifically, we exploit the structural information in a document to identify tables and their component fields and let the users query based on these fields. Our empirical results have demonstrated that heuristic method based table extraction and component tagging can be performed effectively and efficiently. Moreover, our experiments in retrieval using the TINTIN system have strongly indicated that such structural decomposition can facilitate better representation of user\u2019s information needs and hence more effective retrieval of tables."
            },
            "slug": "TINTIN:-a-system-for-retrieval-in-text-tables-Pyreddy-Croft",
            "title": {
                "fragments": [],
                "text": "TINTIN: a system for retrieval in text tables"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper examines the utility of exploiting information other than the key words in a digital document to provide the users with more flexible and powerful query capabilities and demonstrates that heuristic method based table extraction and component tagging can be performed effectively and efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "DL '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2456613"
                        ],
                        "name": "J. H. Shamilian",
                        "slug": "J.-H.-Shamilian",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shamilian",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Shamilian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1394247998"
                        ],
                        "name": "T. Wood",
                        "slug": "T.-Wood",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Wood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wood"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[80] in which a system based on predefined layout structures in given."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "Grid-based models include [60] and [80]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 141
                            }
                        ],
                        "text": "An example of an application in this area is the work done at AT&T/Lucent on the conversion of telephone billing statements to a usable form [80]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "The application context is one in which a known table (or small set of tables) is input many times and requires interpretation [80]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 53
                            }
                        ],
                        "text": "Examples of systems that fit this definition include [22, 28, 31, 60, 80]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206775234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ad7b7fe1c5e346b1cb9034af4fa18b5afe4d45e",
            "isKey": true,
            "numCitedBy": 55,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the architecture of a system for reading machine-printed documents in known predefined tabular-data layout styles. In these tables, textual data are presented in record lines made up of fixed-width fields. Tables often do not rely on line-art (ruled lines) to delimit fields, and in this way differ crucially from fixed forms. Our system performs these steps: copes with multiple tables per page; identifies records within tables; segments records into fields; and recognizes characters within fields, constrained by field-specific contextual knowledge. Obstacles to good performance on tables include small print, tight line-spacing, poor-quality text (such as photocopies), and line-art or background patterns that touch the text. Precise skew-correction and pitch-estimation, and high-performance OCR using neural nets proved crucial in overcoming these obstacles. The most significant technical advances in this work appear to be algorithms for identifying and segmenting records with known layout, and integration of these algorithms with a graphical user interface (GUI) for defining new layouts. This GUI has been ergonomically designed to make efficient and intuitive use of exemplary images, so that the skill and manual effort required to retarget the system to new table layouts are held to a minimum. The system has been applied in this way to more than 400 distinct tabular layouts. During the last three years the system has read over fifty million records with high accuracy."
            },
            "slug": "A-retargetable-table-reader-Shamilian-Baird",
            "title": {
                "fragments": [],
                "text": "A retargetable table reader"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The architecture of a system for reading machine-printed documents in known predefined tabular-data layout styles, and algorithms for identifying and segmenting records with known layout, and integration of these algorithms with a graphical user interface (GUI) for defining new layouts are described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145658132"
                        ],
                        "name": "David Pinto",
                        "slug": "David-Pinto",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pinto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Pinto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876441"
                        ],
                        "name": "Xing Wei",
                        "slug": "Xing-Wei",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[72] describe an approach for locating and extracting tables based on conditional random fields."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1092004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6991606a1a9d5c285af385ee9159fd46cc14048e",
            "isKey": false,
            "numCitedBy": 440,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to find tables and extract information from them is a necessary component of data mining, question answering, and other information retrieval tasks. Documents often contain tables in order to communicate densely packed, multi-dimensional information. Tables do this by employing layout patterns to efficiently indicate fields and records in two-dimensional form.Their rich combination of formatting and content present difficulties for traditional language modeling techniques, however. This paper presents the use of conditional random fields (CRFs) for table extraction, and compares them with hidden Markov models (HMMs). Unlike HMMs, CRFs support the use of many rich and overlapping layout and language features, and as a result, they perform significantly better. We show experimental results on plain-text government statistical reports in which tables are located with 92% F1, and their constituent lines are classified into 12 table-related categories with 94% accuracy. We also discuss future work on undirected graphical models for segmenting columns, finding cells, and classifying them as data cells or label cells."
            },
            "slug": "Table-extraction-using-conditional-random-fields-Pinto-McCallum",
            "title": {
                "fragments": [],
                "text": "Table extraction using conditional random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Unlike HMMs, CRFs support the use of many rich and overlapping layout and language features, and as a result, they perform significantly better, and are compared with hidden Markov models (HMMs)."
            },
            "venue": {
                "fragments": [],
                "text": "DG.O"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1500661115"
                        ],
                        "name": "Toyohide Watanabe",
                        "slug": "Toyohide-Watanabe",
                        "structuredName": {
                            "firstName": "Toyohide",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toyohide Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074293587"
                        ],
                        "name": "Q. Luo",
                        "slug": "Q.-Luo",
                        "structuredName": {
                            "firstName": "Qin",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692608"
                        ],
                        "name": "N. Sugie",
                        "slug": "N.-Sugie",
                        "structuredName": {
                            "firstName": "Noboru",
                            "lastName": "Sugie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sugie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 32
                            }
                        ],
                        "text": "Toyohide Watanabe and coworkers [64, 92, 91, 90, 93] aim at a complete description of the various types of information necessary to interpret a ruled scanned table."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 120
                            }
                        ],
                        "text": "The majority of the published work on table processing deals with the extraction of structure from scanned paper tables [1, 10, 15, 32, 39, 50, 60, 87, 93, 98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "Formal paradigms for describing the structure of tables are the Table Syntax [32, 58], the Structure Description Tree [93], and the Cohesion Domain Template [48]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 156
                            }
                        ],
                        "text": "A training set of diverse tables is used to populate a classification tree, and each node of the classification tree contains information, in the form of a Structure Description Tree (SDT), to interpret a specific family of tables."
                    },
                    "intents": []
                }
            ],
            "corpusId": 23198522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa208b677239912cb394e5dbc6e7483a75f16ea4",
            "isKey": true,
            "numCitedBy": 140,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Many approaches have reported that knowledge-based layout recognition methods are very successful in classifying the meaningful data from document images automatically. However, these approaches are applicable to only the same kind of documents because they are based on the paradigm that specifies the structure definition information in advance so as to be able to analyze a particular class of documents intelligently. In this paper, the authors propose a method to recognize the layout structures of multi-kinds of table-form document images. For this purpose, the authors introduce a classification tree to manage the relationships among different classes of layout structures. The authors' recognition system has two modes: layout knowledge acquisition and layout structure recognition. In the layout knowledge acquisition mode, table-form document images are distinguished according to this. Classification tree and then the structure description trees which specify the logical structures of table-form documents are generated automatically. While, in the layout structure recognition mode, individual item fields in the table-form document images are extracted and classified successfully by searching the classification tree and interpreting the structure description tree. >"
            },
            "slug": "Layout-Recognition-of-Multi-Kinds-of-Table-Form-Watanabe-Luo",
            "title": {
                "fragments": [],
                "text": "Layout Recognition of Multi-Kinds of Table-Form Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The authors introduce a classification tree to manage the relationships among different classes of layout structures and propose a method to recognize the layout structures of multi-kinds of table-form document images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1500661115"
                        ],
                        "name": "Toyohide Watanabe",
                        "slug": "Toyohide-Watanabe",
                        "structuredName": {
                            "firstName": "Toyohide",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toyohide Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074293587"
                        ],
                        "name": "Q. Luo",
                        "slug": "Q.-Luo",
                        "structuredName": {
                            "firstName": "Qin",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692608"
                        ],
                        "name": "N. Sugie",
                        "slug": "N.-Sugie",
                        "structuredName": {
                            "firstName": "Noboru",
                            "lastName": "Sugie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sugie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 32
                            }
                        ],
                        "text": "Toyohide Watanabe and coworkers [64, 92, 91, 90, 93] aim at a complete description of the various types of information necessary to interpret a ruled scanned table."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27626504,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b8ec3847c2cdbb50aca64d310703b5d89c81a4b",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A framework of four-layer recognition processes is proposed for understanding documents, and a knowledge representation method adaptable to the understanding of table-form documents is addressed. Although Y. Nakano et al. (1986) looked upon the recognition of multi-kinds of table-form documents as an important subject from a practical point of view, they could not report any successful approach because their knowledge was based only on the physical coordinate data. In the approach presented, this recognition issue was solved, using both the classification tree based on the physical characteristics and the structure description tree based on the logical characteristics. At least, it is not so difficult to classify various kinds of documents into appropriate document classes since table-form documents are well designed on the basis of vertical and horizontal line segments. However, it is not easy in the case of the other documents because the geometric and spatial characteristics of documents are not well specified. It is necessary to investigate the application techniques for the other documents from the viewpoint of the knowledge representation.<<ETX>>"
            },
            "slug": "Toward-a-practical-document-understanding-of-its-Watanabe-Luo",
            "title": {
                "fragments": [],
                "text": "Toward a practical document understanding of table-form documents: its framework and knowledge representation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A framework of four-layer recognition processes is proposed for understanding documents, and a knowledge representation method adaptable to the understanding of table-form documents is addressed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73282614"
                        ],
                        "name": "Y. Hirayama",
                        "slug": "Y.-Hirayama",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Hirayama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Hirayama"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 120
                            }
                        ],
                        "text": "The majority of the published work on table processing deals with the extraction of structure from scanned paper tables [1, 10, 15, 32, 39, 50, 60, 87, 93, 98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "Hirayama [39] uses ruling lines as initial evidence of a table or figure and then further refines this decision to distinguish tables from figures by a measure based on such features as the presence of characters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "Hirayama proposes a sophisticated algorithm for segmenting a partially-ruled table into a lattice composed of a grid of rectangles [39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206774876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcf75b367f24919a8a4b0f627960f6d6bf5ae33f",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel method for table structure analysis. Many documents have table areas, and some have both table and figure areas. It is very important to be able to classify table and figure areas automatically. Furthermore, in tables, the column and row in which a character string is located are very important pieces of information. To detect and analyze table areas, the following method is applied: First, areas that may contain tables or figures are distinguished from text areas by the presence of horizontal and vertical lines. Next, the areas are assumed to be table areas and are analyzed as such. A judgment is made on whether each of the areas can in fact be a table area or not; in this way, the actual table areas are detected. Finally, the structures of the areas are analyzed and character strings in the areas are arranged by using the DP matching method. This method was applied to sixty-five pages of Japanese technical papers, magazines, manuals for software programs, and pages including 34 table areas, 48 line drawing areas, and 35 image areas. As a result, 96.6 percent of the areas were detected correctly and 91.7 percent of the tables were analyzed and arranged correctly."
            },
            "slug": "A-method-for-table-structure-analysis-using-DP-Hirayama",
            "title": {
                "fragments": [],
                "text": "A method for table structure analysis using DP matching"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This paper presents a novel method for table structure analysis that was applied to sixty-five pages of Japanese technical papers, magazines, manuals for software programs, and pages including 34 table areas, 48 line drawing areas, and 35 image areas."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689847"
                        ],
                        "name": "Jean-Yves Ramel",
                        "slug": "Jean-Yves-Ramel",
                        "structuredName": {
                            "firstName": "Jean-Yves",
                            "lastName": "Ramel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Yves Ramel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719698"
                        ],
                        "name": "M. Crucianu",
                        "slug": "M.-Crucianu",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Crucianu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Crucianu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145645182"
                        ],
                        "name": "N. Vincent",
                        "slug": "N.-Vincent",
                        "structuredName": {
                            "firstName": "Nicole",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38138508"
                        ],
                        "name": "C. Faure",
                        "slug": "C.-Faure",
                        "structuredName": {
                            "firstName": "Claudie",
                            "lastName": "Faure",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faure"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 212
                            }
                        ],
                        "text": "We believe that the extraction of tables from HTML documents is evanescent compared to the conversion of paper documents because XML-based schemes are conceived with the goal of assuring machine interpretability [75]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [75], table structure is viewed as a perfectly regular isothetic tessellation of a rectangular region into virtual cells, and a superimposed partitions of the virtual cells with"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18293386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "275d79256336a53141e6602d5fdf736139e90b8f",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We are concerned with the extraction of tables from exchange format representations of very diverse composite documents. We put forward a flexible representation scheme for complex tables, based on a clear distinction between the physical layout of a table and its logical structure. Relying on this scheme, we develop a new method for the detection and the extraction of tables by an analysis of the graphic lines. To deal with tables that lack all or most of the graphic marks, one must focus on the regularities of the text elements alone. We propose such a method, based on a multi-level analysis of the layout of text components on a page. A general graph representation of the relative positions of blocks of text is exploited."
            },
            "slug": "Detection,-extraction-and-representation-of-tables-Ramel-Crucianu",
            "title": {
                "fragments": [],
                "text": "Detection, extraction and representation of tables"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A flexible representation scheme for complex tables is put forward, based on a clear distinction between the physical layout of a table and its logical structure, and a new method for the detection and the extraction of tables by an analysis of the graphic lines is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108023096"
                        ],
                        "name": "Xinxin Wang",
                        "slug": "Xinxin-Wang",
                        "structuredName": {
                            "firstName": "Xinxin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinxin Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "Extending some of the concepts presented in [88],"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "captures both logical and physical aspects [88]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "Many other table composition systems are surveyed in [88]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 130
                            }
                        ],
                        "text": "She also mentions the possibility of creating subtables in response to a query, which is similar to view generation in a database [88]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16895319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb8327c5b091ea26e42ed924e25a02c564998f19",
            "isKey": true,
            "numCitedBy": 151,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation investigates the composition of high-quality tables with the use of electronic tools. A generic model is designed to support the different stages of tabular composition, including the editing of logical structure, the specification of layout structure, and the formatting of concrete tables. The model separates table's logical structure from its layout structure, which consists of tabular topology and typographic style. The notion of an abstract table, which describes the logical relationships among tabular items, is formally defined and a set of logical operations is proposed to manipulate tables based on these logical relationships. An abstract table can be visualized through a layout structure specified by a set of topological rules, which determine the relative placement of tabular items in two dimensions, and a set of style rules, which determine the final appearance of different items. The absolute placement of a concrete table can be automatically generated by applying a layout specification to an abstract line. An NP-complete problem arises in the formatting process that uses automatic line breaking and determines the physical dimension of a table to satisfy user-specified size constraints. An algorithm has been designed to solve the formatting problem in polynomial time for typical tables. Based on the tabular model, a prototype tabular composition system has been implemented in a UNIX, X Windows environment. This prototype provides an interactive interface to edit the logical structure, the topology and the styles of tables. It allows us to manipulate tables based on the logical relationships tabular items, regardless of where the items are placed in the layout structure, and capable of presenting a table in different topologies and styles so that we can select a high-quality layout structure."
            },
            "slug": "Tabular-Abstraction,-Editing,-and-Formatting-Wang",
            "title": {
                "fragments": [],
                "text": "Tabular Abstraction, Editing, and Formatting"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This dissertation investigates the composition of high-quality tables with the use of electronic tools using a generic model designed to support the different stages of tabular composition, including the editing of logical structure, the specification of layout structure, and the formatting of concrete tables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "They also present evaluation measures for quantifying the performance of such algorithms [45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7630958,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af42cc46f93bc9cf413770af4f7243f54a31336e",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. While techniques for evaluating the performance of lower-level document analysis tasks such as optical character recognition have gained acceptance in the literature, attempts to formalize the problem for higher-level algorithms, while receiving a fair amount of attention in terms of theory, have generally been less successful in practice, perhaps owing to their complexity. In this paper, we introduce intuitive, easy-to-implement evaluation schemes for the related problems of table detection and table structure recognition. We also present the results of several small experiments, demonstrating how well the methodologies work and the useful sorts of feedback they provide. We first consider the table detection problem. Here algorithms can yield various classes of errors, including non-table regions improperly labeled as tables (insertion errors), tables missed completely (deletion errors), larger tables broken into a number of smaller ones (splitting errors), and groups of smaller tables combined to form larger ones (merging errors). This leads naturally to the use of an edit distance approach for assessing the results of table detection. Next we address the problem of evaluating table structure recognition. Our model is based on a directed acyclic attribute graph, or table DAG. We describe a new paradigm, \u201cgraph probing,\u201d for comparing the results returned by the recognition system and the representation created during ground-truthing. Probing is in fact a general concept that could be applied to other document recognition tasks as well."
            },
            "slug": "Evaluating-the-performance-of-table-processing-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Evaluating the performance of table processing algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An intuitive, easy-to-implement evaluation schemes for the related problems of table detection and table structure recognition are introduced and a new paradigm, \u201cgraph probing,\u201d is described for comparing the results returned by the recognition system and the representation created during ground-truthing."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34736316"
                        ],
                        "name": "K. Summers",
                        "slug": "K.-Summers",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Summers",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Summers"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "The approach is based on the notion that layout objects do not explicitly represent logical structure but contain cues about their role in the structure [82]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60848936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4e46c009f7759080942171309371ef88b988e82",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The availability of large, heterogeneous repositories of electronic documents is increasing rapidly, and the need for flexible, sophisticated document manipulation tools is growing correspondingly. These tools can benefit greatly by exploiting logical structure, a hierarchy of visually observable organizational components of a document, such as paragraphs, lists, sections, etc. Knowledge of this structure can enable a multiplicity of applications, including hierarchical browsing, structural hyperlinking, logical component-based retrieval, and style translation. \nMost work on the problem of deriving logical structure from document layout either relies on knowledge of the particular document style or finds a single flat set of text blocks. This thesis describes an implemented approach to discovering a full logical hierarchy in generic text documents, based primarily on layout information. Since the styles of the documents are not known a priori, the precise layout effects of the logical structure are unknown. Nonetheless, typographical capabilities and conventions provide cues that can be used to deduce a logical structure for a generic document. In particular, the key idea is that analyses of the text contours at appropriate levels of granularity offer a rich source of information about document structure. \nThe problem of logical structure discovery is divided into problems of segmentation, which separates the text into logical pieces, and classification, which labels the pieces with structure types. The segmentation algorithm relies entirely on layout-based cues, and the classification algorithm uses word-based information only when this is demonstrably unavoidable. Thus, this approach is particularly appropriate for scanned-in documents, since it is more robust with respect to OCR errors than a content-oriented approach would be. It is applicable, however, to the problem of analyzing any electronic document whose original formatting style rules remain unknown; thus, it can provide the basis for flexible document manipulation tools in heterogeneous collections."
            },
            "slug": "Automatic-Discovery-of-Logical-Document-Structure-Summers",
            "title": {
                "fragments": [],
                "text": "Automatic Discovery of Logical Document Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The key idea is that analyses of the text contours at appropriate levels of granularity offer a rich source of information about document structure, which can provide the basis for flexible document manipulation tools in heterogeneous collections."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1901883"
                        ],
                        "name": "Shona Douglas",
                        "slug": "Shona-Douglas",
                        "structuredName": {
                            "firstName": "Shona",
                            "lastName": "Douglas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shona Douglas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054489514"
                        ],
                        "name": "David Quinn",
                        "slug": "David-Quinn",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Quinn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Quinn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 52
                            }
                        ],
                        "text": "Among references that address electronic tables are [26, 48, 71, 73]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18944899,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "211d7cdfbff8f379ad4885e96f4b68d0d9bc9b9e",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Figure 2:A generic table with terminology (`*' representsoptionality)3.2VariationsonTableLayoutDi erent layout arrangements can b e thought of as expressing functional asp ects of the relation, usingsomesimple heuristicsab outthewaygroupingandorderingmay b eexpressedintodimensions.Because we conventionally read tables from the left and from the top, we distinguish theleft marginandtopmarginoftablesasareasthetableinwhichhigh-precedencedomains areplaced(seeFigure 2).A given layout supp orts a certainreading order.This reading order reectsthe way inwhich domains are organised and sp eci cally thegroupsandordersin which domains can b e easilyusedaskeysin cho osing and reading/constructing a tuple from the table; the reading order is thusthe emb o diment of the decision structure we identi ed as the functional part of the table.Thus,while a single canonical form may have many layouts, a given canonical form plus functionalinformation will have a much reducedrange of felicitous layouts.These typical constraints on laoutwillb eusedlaterinourpro cessingheuristics.First,wepresentarep ertoireoftransformations ofsimple tables in terms of which we can analyse the variations in layout that o ccur.RotationThis transformation is b est describ ed by example:StandardslumpValue75mmv1ST1125mmv275mmv3ST2125mmv4!Standard75mm125mmValueST1v1v2v34"
            },
            "slug": "Using-Natural-Language-Processing-for-Identifying-Douglas-Hurst",
            "title": {
                "fragments": [],
                "text": "Using Natural Language Processing for Identifying and Interpreting Tables in Plain Text"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "While a single canonical form may have many layouts, a given canonical form plus functional information will have a much reducedrange of felicitous layouts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144881104"
                        ],
                        "name": "E. A. Green",
                        "slug": "E.-A.-Green",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Green",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. A. Green"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751773"
                        ],
                        "name": "M. Krishnamoorthy",
                        "slug": "M.-Krishnamoorthy",
                        "structuredName": {
                            "firstName": "Mukkai",
                            "lastName": "Krishnamoorthy",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krishnamoorthy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 120
                            }
                        ],
                        "text": "The majority of the published work on table processing deals with the extraction of structure from scanned paper tables [1, 10, 15, 32, 39, 50, 60, 87, 93, 98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 77
                            }
                        ],
                        "text": "Formal paradigms for describing the structure of tables are the Table Syntax [32, 58], the Structure Description Tree [93], and the Cohesion Domain Template [48]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 22
                            }
                        ],
                        "text": "In a series of papers [31, 32, 33], Green and Krishnamoorthy apply a compiler design approach to parsing scanned ruled tables."
                    },
                    "intents": []
                }
            ],
            "corpusId": 866386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ecb5fdcdeff0d56ebf61b151ac8617ae3b30881e",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a strategy for extracting the underlying relational information from the images of printed tables. Visual clues that exist in the image are used for extracting first the physical, and then the logical structure of the table. Since these visual clues generally have a logical meaning, there must be some association made between the graphical attributes extracted and their function of reflecting the logic expressed by the table; this knowledge is coordinated in a model. This approach, therefore, can be adapted to all tables which have graphical attributes discernible to the image analysis being used."
            },
            "slug": "Model-based-analysis-of-printed-tables-Green-Krishnamoorthy",
            "title": {
                "fragments": [],
                "text": "Model-based analysis of printed tables"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This strategy for extracting the underlying relational information from the images of printed tables is developed and can be adapted to all tables which have graphical attributes discernible to the image analysis being used."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060810463"
                        ],
                        "name": "Akira Amano",
                        "slug": "Akira-Amano",
                        "structuredName": {
                            "firstName": "Akira",
                            "lastName": "Amano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akira Amano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2406896"
                        ],
                        "name": "Naoki Asada",
                        "slug": "Naoki-Asada",
                        "structuredName": {
                            "firstName": "Naoki",
                            "lastName": "Asada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naoki Asada"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "Other notable work on forms includes [5] and [69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7044142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62018285f077a277c77d58c1e5732c71be58a98d",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Structure analysis of table form document is importantbecause printed documents and also electronical documentsonly provide geometrical layout and lexical information explicitly.To handle these documents automatically, logicalstructure information is necessary. In this paper, we firstpropose a general representation of table form documentbased on XML, which contains both structure and layoutinformation. Next, we present structure analysis systembased on graph grammar which represents document structureknowledge. As the relation between adjacent fields intable form documents become two dimensional, two dimensionalnotation is necessary to denote structural knowledge.Therefore, we adopt two dimensional graph grammar to denotethem. By using grammar notation, we can easily modifyand keep consistency of it, as the rules are relatively simple.Another advantage of using grammar notation is that,it can be used for generating documents only from logicalstructure. Experimental results have shown that the systemsuccessfully analyzed several kinds of table forms."
            },
            "slug": "Graph-grammar-based-analysis-system-of-complex-form-Amano-Asada",
            "title": {
                "fragments": [],
                "text": "Graph grammar based analysis system of complex table form document"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A general representation of table form document based on XML, which contains both structure and layout information and a structure analysis system based on graph grammar which represents document structureknowledge is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1901883"
                        ],
                        "name": "Shona Douglas",
                        "slug": "Shona-Douglas",
                        "structuredName": {
                            "firstName": "Shona",
                            "lastName": "Douglas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shona Douglas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "Formal paradigms for describing the structure of tables are the Table Syntax [32, 58], the Structure Description Tree [93], and the Cohesion Domain Template [48]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 52
                            }
                        ],
                        "text": "Among references that address electronic tables are [26, 48, 71, 73]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14091058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "971af881cefc0bccb7f47046095d0a92f0de3152",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Describes a prototype system for assigning table cells to their proper place in the logical structure of the table, based on a simple model of table structure combined with a number of measures of cohesion between cells. A framework is presented for examining the effect of particular variables on the performance of the system, and preliminary results are presented showing the effect of cohesion measures based on the simplest domain-independent analyses, with the aim allowing future comparison with more knowledge-intensive analyses based on natural language processing. These baseline results suggest that very simple string-based cohesion measures are not sufficient to support the extraction of tuples as we require. Future work will pursue the aim of more adequate approximations to a notional subtype/supertype definition of the relationship between value cells and label cells."
            },
            "slug": "Layout-and-language:-preliminary-investigations-in-Hurst-Douglas",
            "title": {
                "fragments": [],
                "text": "Layout and language: preliminary investigations in recognizing the structure of tables"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "B baseline results suggest that very simple string-based cohesion measures are not sufficient to support the extraction of tuples as it is suggested that more adequate approximations to a notional subtype/supertype definition of the relationship between value cells and label cells are needed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047403"
                        ],
                        "name": "S. Balasubramanian",
                        "slug": "S.-Balasubramanian",
                        "structuredName": {
                            "firstName": "Sanjay",
                            "lastName": "Balasubramanian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Balasubramanian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25727408"
                        ],
                        "name": "Surekha Chandran",
                        "slug": "Surekha-Chandran",
                        "structuredName": {
                            "firstName": "Surekha",
                            "lastName": "Chandran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Surekha Chandran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27130718"
                        ],
                        "name": "J. F. Arias",
                        "slug": "J.-F.-Arias",
                        "structuredName": {
                            "firstName": "Juan",
                            "lastName": "Arias",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. F. Arias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34817063"
                        ],
                        "name": "A. Chhabra",
                        "slug": "A.-Chhabra",
                        "structuredName": {
                            "firstName": "Atul",
                            "lastName": "Chhabra",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chhabra"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27987574,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e4351fbb1150bf7ccc3d1c6bd3cc90b0e64cbcdf",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents efficient methodologies to extract information from tabular drawings representing telephone cable interconnections. These tables include records of cable counts, cables in service, assignment charts, and cable running and wiring lists. An interesting problem in these drawings is that the changes to the data are occasionally recorded by crossing out entries and appending the changes rather than redrawing the entire documents. The objective of the work described here is the extraction of information contained in these table structured documents to facilitate the creation of a computer database. Our software system makes use of contextual information in these drawings (e.g., a particular line pattern is used to represent repeated entries, ignore crossed-out entries, etc.). The system uses features like inter-line spacing, length of lines, line orientation, and start and end locations of the lines to detect the diagonal lines and vertical lines with demarcations. Experimental results are also included."
            },
            "slug": "Information-extraction-from-tabular-drawings-Balasubramanian-Chandran",
            "title": {
                "fragments": [],
                "text": "Information extraction from tabular drawings"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The software system makes use of contextual information in these drawings and uses features like inter-line spacing, length of lines, line orientation, and start and end locations of the lines to detect the diagonal lines and vertical lines with demarcations."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 156
                            }
                        ],
                        "text": "T-Recs (Table REcognition System), an elaborate program for the structural analysis of ASCII tables based on bottom\u2013up clustering of words, is described in [53]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206405589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "108030474840ce5e1086cc8ef598ff3e6c13693c",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an efficient approach to identify tabular structures within either electronic or paper documents. The resulting T-Recs system takes word bounding box information as input, and outputs the corresponding logical text block units. Starting with an arbitrary word as block seed the algorithm recursively expands this block to all words that interleave with their vertical neighbors. Since even smallest gaps of table columns prevent their words from mutual interleaving, this initial segmentation is able to identify and isolate such columns. In order to deal with some inherent segmentation errors caused by isolated lines, overhanging words, or cells spawning more than one column, a series of postprocessing steps is added. These steps benefit form a very simple distinction between type 1 and type 2 blocks: type 1 blocks are those of at most one word per line, all others are of type 2. This distinction allows the selective application of heuristics to each group of blocks. The conjoint decomposition of column blocks into subsets of table cells leads to the final block segmentation of a homogeneous abstraction level. These segments serve the final layout analysis which identifies table environments and cells that are stretching over several rows and/or columns."
            },
            "slug": "Table-structure-recognition-based-on-robust-block-Kieninger",
            "title": {
                "fragments": [],
                "text": "Table structure recognition based on robust block segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An efficient approach to identify tabular structures within either electronic or paper documents by taking word bounding box information as input, and outputs the corresponding logical text block units through the T-Recs system."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[42] describe a technique for detecting tables"
                    },
                    "intents": []
                }
            ],
            "corpusId": 37293831,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "edbd577d793a083de4f337acac992ec7837609e0",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "An important step towards the goal of table understanding is a method for reliable table detection. This paper describes a general solution for detecting tables based on computing an optimal partitioning of a document into some number of tables. A dynamic programming algorithm is given to solve the resulting optimization problem. This high-level framework is independent of any particular table quality measure and independent of the document medium. Moreover, it does not rely on the presence of ruling lines or other table delimiters. We also present table quality measures based on white space correlation and vertical connected component analysis. These measures can be applied equally well to ASCII text and scanned images. We report on some preliminary experiments using this method to detect tables in both ASCII text and scanned images, yielding promising results. We present detailed evaluation of these results using three different criteria which by themselves pose interesting research questions."
            },
            "slug": "Medium-independent-table-detection-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Medium-independent table detection"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A general solution for detecting tables based on computing an optimal partitioning of a document into some number of tables is described and a dynamic programming algorithm is given to solve the resulting optimization problem."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145723023"
                        ],
                        "name": "C. Tao",
                        "slug": "C.-Tao",
                        "structuredName": {
                            "firstName": "Cui",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742211"
                        ],
                        "name": "Stephen W. Liddle",
                        "slug": "Stephen-W.-Liddle",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Liddle",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen W. Liddle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5406402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b777c808a71ed4bd8c9da4f1a2475110b15d23f7",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automating-the-extraction-of-data-from-HTML-tables-Embley-Tao",
            "title": {
                "fragments": [],
                "text": "Automating the extraction of data from HTML tables with unknown structure"
            },
            "venue": {
                "fragments": [],
                "text": "Data Knowl. Eng."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143772136"
                        ],
                        "name": "O. Hori",
                        "slug": "O.-Hori",
                        "structuredName": {
                            "firstName": "Osamu",
                            "lastName": "Hori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Hori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "Box-driven reasoning is proposed in [40] to mitigate content-separator overlaps."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 163
                            }
                        ],
                        "text": "The primary goal of this research was the recovery of cell structure from fully lined but highly degraded tables with broken rulings and overlapping cell contents [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2750254,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92e74fde9c613dd22c193bb11d889d7a0428bced",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Table form document structure analysis is an important problem in the document processing domain. The paper presents a method called Box Driven Reasoning (BDR) to robustly analyze the structure of table form documents which include touching characters and broken lines. Most previous methods employ a line oriented approach. Real documents are copied repeatedly and overlaid with printed data, resulting in characters which touch cells and lines which are broken. BDR deals with regions directly, in contrast with other previous methods. Experimental tests show that BDR reliably recognizes cells and strings in document images with touching characters and broken lines."
            },
            "slug": "Robust-table-form-structure-analysis-based-on-Hori-Doermann",
            "title": {
                "fragments": [],
                "text": "Robust table-form structure analysis based on box-driven reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A method called Box Driven Reasoning (BDR) is presented to robustly analyze the structure of table form documents which include touching characters and broken lines."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793699"
                        ],
                        "name": "R. Zanibbi",
                        "slug": "R.-Zanibbi",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zanibbi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zanibbi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703931"
                        ],
                        "name": "D. Blostein",
                        "slug": "D.-Blostein",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Blostein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blostein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683822"
                        ],
                        "name": "J. Cordy",
                        "slug": "J.-Cordy",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cordy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cordy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[97] includes references to much new material, organized according to a view of table recognition as the interaction of \u201cmodels, observations, transformations, and inferences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 67
                            }
                        ],
                        "text": "For these, we refer the reader to the previously mentioned surveys [62, 63, 97]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 116
                            }
                        ],
                        "text": "Reflecting this growing interest, a number of surveys on table processing have appeared over the past several years [37, 47, 62, 63, 97]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14319498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6e4c5aa32fd8180d336ce2b6ea8bf3194678636",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 102,
            "paperAbstract": {
                "fragments": [],
                "text": "Table characteristics vary widely. Consequently, a great variety of computational approaches have been applied to table recognition. In this survey, the table recognition literature is presented as an interaction of table models, observations, transformations and inferences. A table model defines the physical and logical structure of tables; the model is used to detect tables, and to analyze and decompose the detected tables. Observations perform feature measurements and data lookup, transformations alter or restructure data, and inferences generate and test hypotheses. This presentation clarifies the decisions that are made by a table recognizer, and the assumptions and inferencing techniques that underlie these decisions."
            },
            "slug": "A-Survey-of-Table-Recognition-:-Models-,-,-,-and-Zanibbi-Blostein",
            "title": {
                "fragments": [],
                "text": "A Survey of Table Recognition : Models , Observations , Transformations , and Inferences"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This presentation clarifies the decisions that are made by a table recognizer, and the assumptions and inferencing techniques that underlie these decisions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "A more flexible approach, T-Recs++, that can detect and analyze less regular tables as well as business letters, was subsequently reported [52]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206776168,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "d25a61cc0cd816eba75864912fe2f6f44be3cecf",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper summarizes the core idea of the T-Recs table recognition system, an integrated system covering block-segmentation, table location and a model-free structural analysis of tables. T-Recs works on the output of commercial OCR systems that provide the word bounding box geometry together with the text itself (e.g. Xerox ScanWorX). While T-Recs performs well on a number of document categories, business letters still remained a challenging domain because the T-Recs location heuristics are mislead by their header or footer resulting in a low recognition precision. Business letters such as invoices are a very interesting domain for industrial applications due to the large amount of documents to be analyzed and the importance of the data carried within their tables. Hence, we developed a more restrictive approach which is implemented in the T-Recs++ prototype. This paper describes the ideas of the T-Recs++ location and also proposes a quality evaluation measure that reflects the bottom-up strategy of either T-Recs or T-Recs++. Finally, some results comparing both systems on a collection of business letters are given."
            },
            "slug": "Applying-the-T-Recs-table-recognition-system-to-the-Kieninger-Dengel",
            "title": {
                "fragments": [],
                "text": "Applying the T-Recs table recognition system to the business letter domain"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper summarizes the core idea of the T-Recs table recognition system, an integrated system covering block-segmentation, table location and a model-free structural analysis of tables, and proposes a quality evaluation measure that reflects the bottom-up strategy of either T-recs or T- Recs++."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144531841"
                        ],
                        "name": "Saleh A. Alrashed",
                        "slug": "Saleh-A.-Alrashed",
                        "structuredName": {
                            "firstName": "Saleh",
                            "lastName": "Alrashed",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saleh A. Alrashed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144002848"
                        ],
                        "name": "W. Gray",
                        "slug": "W.-Gray",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Gray",
                            "middleNames": [
                                "Alex"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 120
                            }
                        ],
                        "text": "Our desire here is only to indicate that it is possible to create such ontological models as suggested in both [36] and [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 263,
                                "start": 260
                            }
                        ],
                        "text": "The Semantic and Representation Detection (SRD) framework is proposed for combining information from a domain ontology, and standard-unit ontology, and table metadata (possibly derived from surrounding context) into relational tables for populating a database [4]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11986534,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e59a5822525e06ede91e66838bd72a6066a63f0a",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "When linking information presented in documents as tables with data held in databases, it is important to determine as much information about the table and its content. Such an integrated use of Web-based data requires information about its organization and meaning i.e. the semantics of the table. This paper describes approaches that can be used to detect and extract the semantics for a table held in the text. Our objective is to detect and extract table semantics that are buried in the text. For this goal to be achieved, a domain ontology that covers the semantics of the term used in this table must be available to the information system. The overall aim is to link this tabular information in an interoperable environment containing database and other structures information. ..."
            },
            "slug": "Detection-Approaches-for-Table-Semantics-in-Text-Alrashed-Gray",
            "title": {
                "fragments": [],
                "text": "Detection Approaches for Table Semantics in Text"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper describes approaches that can be used to detect and extract the semantics for a table held in the text, and a domain ontology that covers the semantics of the term used in this table must be available to the information system."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32392240"
                        ],
                        "name": "H. Wasserman",
                        "slug": "H.-Wasserman",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Wasserman",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wasserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3303960"
                        ],
                        "name": "Keitaro Yukawa",
                        "slug": "Keitaro-Yukawa",
                        "structuredName": {
                            "firstName": "Keitaro",
                            "lastName": "Yukawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keitaro Yukawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881895"
                        ],
                        "name": "B. Sy",
                        "slug": "B.-Sy",
                        "structuredName": {
                            "firstName": "Bon",
                            "lastName": "Sy",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145219946"
                        ],
                        "name": "K. Kwok",
                        "slug": "K.-Kwok",
                        "structuredName": {
                            "firstName": "Kui-Lam",
                            "lastName": "Kwok",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kwok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "A proposal to combine page analysis and table structure analysis by seeking regions with horizontally and vertically aligned word bounding boxes is advanced in [89]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5740466,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e9ce92b0f7701da4178bb70af1bf217d49e9198",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The algorithm described in this paper is designed to detect potential table regions in the document, to decide whether a potential table region is, in fact, a table, and, when it is, to analyze the table structure. The decision and analysis phases of the algorithm and the resulting system are based primarily on a precise definition of table, and it is such a definition that is discussed in this paper. An adequate definition need not be complete in the sense of encompassing all possible structures that might be deemed to be tables, but it should encompass most such structures, it should include essential features of tables, and it should exclude features never or very rarely possessed by tables."
            },
            "slug": "A-Theoretical-Foundation-and-a-Method-for-Document-Wasserman-Yukawa",
            "title": {
                "fragments": [],
                "text": "A Theoretical Foundation and a Method for Document Table Structure Extraction and Decompositon"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The algorithm described in this paper is designed to detect potential table regions in the document, to decide whether a potential table region is, in fact, a table, and, when it is, to analyze the table structure."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145944286"
                        ],
                        "name": "D. Rus",
                        "slug": "D.-Rus",
                        "structuredName": {
                            "firstName": "Daniela",
                            "lastName": "Rus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34736316"
                        ],
                        "name": "K. Summers",
                        "slug": "K.-Summers",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Summers",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Summers"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "Low-level models use line-art [31], white space [78], and character distributions [51] as key features to drive analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60453794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "283fbac96fc1f7460a5f8105c6afae6835807883",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We present and analyze efficient algorithms for the automated recognition and interpretation of layout structures in electronic documents. The key idea is to use the patterns in the distribution of white space in a document to recognize and interpret its components. The recognition algorithm divides the document into a hierarchy of logical elements; the interpretation algorithms classify these divisions as base-text, tables, indented lists, polygonal drawings, and graphs. We present experimental data and discuss an information access application. Our methodology allows the automatic markup of documents\\footnote{For instance in the SGML format} and the creation of multi-level indices and browsing tools for electronic libraries."
            },
            "slug": "Using-White-Space-for-Automated-Document-Rus-Summers",
            "title": {
                "fragments": [],
                "text": "Using White Space for Automated Document Structuring"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The key idea is to use the patterns in the distribution of white space in a document to recognize and interpret its components to allow the automatic markup of documents and the creation of multi-level indices and browsing tools for electronic libraries."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27130718"
                        ],
                        "name": "J. F. Arias",
                        "slug": "J.-F.-Arias",
                        "structuredName": {
                            "firstName": "Juan",
                            "lastName": "Arias",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. F. Arias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34817063"
                        ],
                        "name": "A. Chhabra",
                        "slug": "A.-Chhabra",
                        "structuredName": {
                            "firstName": "Atul",
                            "lastName": "Chhabra",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chhabra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066269376"
                        ],
                        "name": "Vishal Misra",
                        "slug": "Vishal-Misra",
                        "structuredName": {
                            "firstName": "Vishal",
                            "lastName": "Misra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vishal Misra"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8881316,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "f7b301562f56b12892269aaefb8ff7056e6a2572",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a methodology to interpret the information from telephone company DSX assignment table drawings. Horizontal lines are found using an efficient algorithm that works over the run-length encoded representation of the image. For vertical lines, the image is transposed using an efficient method we developed, and the algorithm for horizontal lines is applied again. Using the information about the lines, the tabular structures are extracted by finding biconnected components on the graph formed by the lines and their intersections. A methodology has also been developed for the representation of end access to the entries inside the tables."
            },
            "slug": "Interpreting-and-representing-tabular-documents-Arias-Chhabra",
            "title": {
                "fragments": [],
                "text": "Interpreting and representing tabular documents"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "This paper describes a methodology to interpret the information from telephone company DSX assignment table drawings using an efficient algorithm that works over the run-length encoded representation of the image."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34996245"
                        ],
                        "name": "B. Klein",
                        "slug": "B.-Klein",
                        "structuredName": {
                            "firstName": "Bertin",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2602600"
                        ],
                        "name": "Serdar G\u00f6kkus",
                        "slug": "Serdar-G\u00f6kkus",
                        "structuredName": {
                            "firstName": "Serdar",
                            "lastName": "G\u00f6kkus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serdar G\u00f6kkus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42252433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea049d0fc3995977b52c10be08fc288789b86ac1",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces three approaches for an industrial, comprehensive document analysis system to enable it to spot tables in documents. Searching for a set of known table headers (approach 1) works rather well in a significant number of documents. But this approach (though it is implemented tolerant to OCR errors) is not tolerant enough towards some kinds of even minor aberrations. This not only decreases the recognition results, but also, even worse, makes users feel uncomfortable. Pragmatically trying to mimic for what the human eyes might key, leads to our two further, complementary approaches: searching for layout structures which resemble parts of columns (approach 2), and searching for groupings of similar lines (approach 3). The suitability of the approaches for our system requires them to be very simple to implement and simple to explain to users, computationally cheap, and combinable. In the domain of health insurances who receive huge amounts of so called medical liquidations on a daily basis we obtain very good results. On document samples representative for the every day practice of five customers-health insurance companies-tables were spotted as good and as fast as the customers expected the system to be. We thus consider our current approaches as a step towards cognitive adequacy."
            },
            "slug": "Three-approaches-to-\"industrial\"-table-spotting-Klein-G\u00f6kkus",
            "title": {
                "fragments": [],
                "text": "Three approaches to \"industrial\" table spotting"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "This paper introduces three approaches for an industrial, comprehensive document analysis system to enable it to spot tables in documents, and considers the current approaches as a step towards cognitive adequacy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728727"
                        ],
                        "name": "A. Laurentini",
                        "slug": "A.-Laurentini",
                        "structuredName": {
                            "firstName": "Aldo",
                            "lastName": "Laurentini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Laurentini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73412977"
                        ],
                        "name": "P. Viada",
                        "slug": "P.-Viada",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Viada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Viada"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 53
                            }
                        ],
                        "text": "Examples of systems that fit this definition include [22, 28, 31, 60, 80]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 120
                            }
                        ],
                        "text": "The majority of the published work on table processing deals with the extraction of structure from scanned paper tables [1, 10, 15, 32, 39, 50, 60, 87, 93, 98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "Grid-based models include [60] and [80]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "Among the earliest researchers to tackle table recognition were Laurentini and Vida [60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61361377,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b22149f09750ef752196a7a31d0adccb762d14f0",
            "isKey": true,
            "numCitedBy": 48,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are important components of technical documents. This paper addresses the following problems: (i) identifying a tabular component in a scanned image of a compound document containing text, drawings, diagrams, etc.; (ii) understanding the content of the table in order to convert the table into electronic format. As far as the authors are aware, the problems addressed are new. An algorithm for performing both the above tasks has been studied and implemented. Preliminary experimental results indicate satisfactory performance for many table lay-out styles.<<ETX>>"
            },
            "slug": "Identifying-and-understanding-tabular-material-in-Laurentini-Viada",
            "title": {
                "fragments": [],
                "text": "Identifying and understanding tabular material in compound documents"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This paper addresses the following problems: identifying a tabular component in a scanned image of a compound document containing text, drawings, diagrams, etc."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695936"
                        ],
                        "name": "M. Rahgozar",
                        "slug": "M.-Rahgozar",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Rahgozar",
                            "middleNames": [
                                "Armon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rahgozar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "75168337"
                        ],
                        "name": "R. Cooperman",
                        "slug": "R.-Cooperman",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Cooperman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cooperman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 37
                            }
                        ],
                        "text": "While other encoding\nschemes such as PostScript and HTML have the potential to be much more complex, the simple fact is that such documents are rendered all the time, and developing systems to perform this function is not considered a particularly daunting task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "Notable exceptions to this assumption include work by Rahgozar and Cooperman [74], where a system based on graph-rewriting is described and work done by Shamalian et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "Tables may also be reproduced in any raster image format, such as TIF or GIF, or rendered directly in PostScript [74]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 70
                            }
                        ],
                        "text": "They may also be encoded in a page-descriptor language such as PDF or PostScript, or in an electronic file format such as the one used by Microsoft Word."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 4
                            }
                        ],
                        "text": "For PostScript, for example, the input ontology would capture bounding boxes for strings along with string content, and for HTML, the input ontology would capture the table-row and table-data structure as provided by the \u3008tr\u3009 and \u3008td\u3009 tags."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 49
                            }
                        ],
                        "text": "PDF files can be readily transformed to and from PostScript, and are relatively small due to embedded compression."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 396,
                                "start": 386
                            }
                        ],
                        "text": "For example, we might have the following input, where spaces are indicated by a dash symbol, -, and carriage returns are indicated by a new paragraph symbol, \u00b6:\nLASTNAME----INITIAL----BIRTHDATE\u00b6Smith------J----------12/3/1988\u00b6Barr--------K---------25/5/1975\u00b6 which would be rendered (on a coarse grid) as:\nLASTNAME INITIAL BIRTHDATE Smith J 12/3/1988 Barr K 25/5/1975\nOn the other hand, in PostScript a similar table would be represented, thus:\n/Courier-New findfont 8 scalefont setfont 0 100 moveto (LASTNAME) show"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 24
                            }
                        ],
                        "text": "The former are known as PostScript interpreters (e.g., Ghostscript), while the latter are referred to as Web browsers (e.g., Mozilla)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 41
                            }
                        ],
                        "text": "Page-descriptor file (Word, LATEX, HTML, PostScript, PDF) with linguistic content, and refined formatting."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 104
                            }
                        ],
                        "text": "In any case, independent of the form of the input (whether it is a simple string of ASCII characters, a PostScript file, an HTML file, or an ontologically described sequence of ASCII character instances), the goal is to obtain the following kind of output:\n5 The \u2018o\u2019 at the base of the arrowhead connected to ASCII Character in Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 54
                            }
                        ],
                        "text": "Notable exceptions to this assumption include work by Rahgozar and Cooperman [74], where a system based on graph-rewriting is described and work done by Shamalian et al. [80] in which a system based on predefined layout structures in given."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "The sequence of productions reproduces the table structure of rows and columns [74]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5695794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cac606274759fa664bce3d98f53d24ccdf23e46b",
            "isKey": true,
            "numCitedBy": 27,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a bottom-up method for recognizing tables within a document. This method is based on the paradigm of graph-rewriting. First, the document image is transformed into a layout graph whose nodes and edges represent document entities and their interrelations respectively. This graph is subsequently rewritten using a set of rules designed based on a priori document knowledge and general formatting conventions. The resulting graph provides a logical view of the document content. It can be parsed to provide general format analysis information."
            },
            "slug": "Graph-based-table-recognition-system-Rahgozar-Cooperman",
            "title": {
                "fragments": [],
                "text": "Graph-based table recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper proposes a bottom-up method for recognizing tables within a document based on the paradigm of graph-rewriting whose nodes and edges represent document entities and their interrelations respectively."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398550688"
                        ],
                        "name": "L. O'Gorman",
                        "slug": "L.-O'Gorman",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "O'Gorman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. O'Gorman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "adjacency graph reminiscent of DocStrum [70]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 117
                            }
                        ],
                        "text": "The authors propose to link together cells in the same row or column with a text-blockadjacency graph reminiscent of DocStrum [70]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 22995244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d85097da36118fbccfeb7802abf89bf4b4c63a3e",
            "isKey": false,
            "numCitedBy": 728,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Page layout analysis is a document processing technique used to determine the format of a page. This paper describes the document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components. The method yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks. It is advantageous over many other methods in three main ways: independence from skew angle, independence from different text spacings, and the ability to process local regions of different text orientations within the same image. Results of the method shown for several different page formats and for randomly oriented subpages on the same image illustrate the versatility of the method. We also discuss the differences, advantages, and disadvantages of the docstrum with respect to other lay-out methods. >"
            },
            "slug": "The-Document-Spectrum-for-Page-Layout-Analysis-O'Gorman",
            "title": {
                "fragments": [],
                "text": "The Document Spectrum for Page Layout Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components, yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47530341"
                        ],
                        "name": "T. Bayer",
                        "slug": "T.-Bayer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Bayer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bayer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 141
                            }
                        ],
                        "text": "A notation and an inference algorithm to identify conceptual cell commonalities, such as \u201camount fields\u201d and \u201cdates,\u201d was developed by Bayer [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 19851329,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dfbac9745a17c42ebf05c4bd0b509767fefffde4",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A document analysis system which is capable of extracting the semantics of specific text portions of structured documents is presented. The architecture of the analysis system is based on a knowledge representation scheme, a semantic network, called Resco-Frame Representation of Structured Documents. It allows the definition of knowledge about document components as well as knowledge about analysis algorithms in a uniform, simple, but powerful representation formalism. Hence, this architecture enables the analysis system to exploit the specific power of both the algorithmic knowledge describing the properties of algorithms and the declarative knowledge about properties of text objects in documents. The inference engine and the control algorithm show how these two knowledge sources are combined and utilized. The flexibility of the representation formalism Fresco, the recognition results and the computational complexity of the inference algorithm are presented in two different applications.<<ETX>>"
            },
            "slug": "Understanding-structured-text-documents-by-a-model-Bayer",
            "title": {
                "fragments": [],
                "text": "Understanding structured text documents by a model based document analysis system"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A document analysis system which is capable of extracting the semantics of specific text portions of structured documents is presented and the inference engine and the control algorithm show how these two knowledge sources are combined and utilized."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094489850"
                        ],
                        "name": "Konstantin Zuyev",
                        "slug": "Konstantin-Zuyev",
                        "structuredName": {
                            "firstName": "Konstantin",
                            "lastName": "Zuyev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Konstantin Zuyev"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 120
                            }
                        ],
                        "text": "The majority of the published work on table processing deals with the extraction of structure from scanned paper tables [1, 10, 15, 32, 39, 50, 60, 87, 93, 98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Konstantin Zuyev [98] converts scanned ruled tables into a grid structure by finding horizontal and vertical \u201csplit points\u201d using connected components, projection profiles, and gap thresholds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206775477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6863be337e896e638b5a52c89caac04e76aa62e4",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithm for table image segmentation, a part of complete document recognition system is presented. The proposed approach introduces a concept of table grid which can serve for advanced methods of table structure analysis. It provides a layer of terminal symbols for the table, which is used by syntactical methods. Detailed discussion of grid detection is presented which is performed through the analysis of connected components projection profile. Simple rules for analysis of table structure cover majority of real life tables. The system is implemented, rested, and is now extensively used in FineReader OCR product."
            },
            "slug": "Table-image-segmentation-Zuyev",
            "title": {
                "fragments": [],
                "text": "Table image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The proposed approach introduces a concept of table grid which can serve for advanced methods of table structure analysis, which provides a layer of terminal symbols for the table, which is used by syntactical methods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741958"
                        ],
                        "name": "Katsuhiko Itonori",
                        "slug": "Katsuhiko-Itonori",
                        "structuredName": {
                            "firstName": "Katsuhiko",
                            "lastName": "Itonori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katsuhiko Itonori"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 120
                            }
                        ],
                        "text": "The majority of the published work on table processing deals with the extraction of structure from scanned paper tables [1, 10, 15, 32, 39, 50, 60, 87, 93, 98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "Itonori [50] combines text-block information with ruled lines."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "torization [1] and projection profiles [50]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2755403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a924e8096b3bd1b287cb4d07cc27a93b33fdfd07",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Describes a new method to recognize table structures from document images. Each cell of a table is arranged regularly in two dimensions and is represented by a row-column pair. Even in the absence of ruled lines, its coordinates are explicitly found. Thus, it is assumed that an arrangement of textblocks defines the table structure, which is an arrangement of rows and columns, and ruled lines make clear their relationship. This process is composed of two procedures: the expansion of cell bounding boxes and the assignment of row-column numbers to each edge. It is shown that the method can be applied to partially ruled tables with some experimental results.<<ETX>>"
            },
            "slug": "Table-structure-recognition-based-on-textblock-and-Itonori",
            "title": {
                "fragments": [],
                "text": "Table structure recognition based on textblock arrangement and ruled line position"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A new method to recognize table structures from document images is described, which is composed of the expansion of cell bounding boxes and the assignment of row-column numbers to each edge."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740614"
                        ],
                        "name": "S. Tsuruoka",
                        "slug": "S.-Tsuruoka",
                        "structuredName": {
                            "firstName": "Shinji",
                            "lastName": "Tsuruoka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tsuruoka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116799162"
                        ],
                        "name": "Toru Tanaka",
                        "slug": "Toru-Tanaka",
                        "structuredName": {
                            "firstName": "Toru",
                            "lastName": "Tanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toru Tanaka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31972052"
                        ],
                        "name": "T. Yoshikawa",
                        "slug": "T.-Yoshikawa",
                        "structuredName": {
                            "firstName": "Tomohiro",
                            "lastName": "Yoshikawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Yoshikawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996464"
                        ],
                        "name": "T. Shinogi",
                        "slug": "T.-Shinogi",
                        "structuredName": {
                            "firstName": "Tsuyoshi",
                            "lastName": "Shinogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Shinogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49867221"
                        ],
                        "name": "K. Takao",
                        "slug": "K.-Takao",
                        "structuredName": {
                            "firstName": "Kensuke",
                            "lastName": "Takao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Takao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "While other encoding\nschemes such as PostScript and HTML have the potential to be much more complex, the simple fact is that such documents are rendered all the time, and developing systems to perform this function is not considered a particularly daunting task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Nevertheless, HTML preserves some relative ordering."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "Interestingly, many if not most Web pages are constructed with the HTML <table> construct (just as figures in Microsoft Word are often laid out using its table facility)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "Mark-up languages like SGML, HTML, and XML have special conventions for tables, but there is no assurance that table tags are not abused or misused."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "A recent review [2] lists four alternative techniques: hand recoding, trans-coding (automatic replacement of HTML tags by device- and targetspecific tags), re-authoring based on automatic layout analysis, and re-authoring based on natural language processing\n(NLP)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 156
                            }
                        ],
                        "text": "Higher dimension tables, for example, may be recursively nested, broken into labeled groups of tables, or successively linked through hypertext in cells of HTML tables."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "For PostScript, for example, the input ontology would capture bounding boxes for strings along with string content, and for HTML, the input ontology would capture the table-row and table-data structure as provided by the \u3008tr\u3009 and \u3008td\u3009 tags."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "This is exploited in [3] to re-author an HTML list."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "Further suggestions for generalizing the notions of precedence, proximity, prominence, and preference for interpreting content flow in HTML documents are presented in [2]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "with a rendering (on a fine grid) like this:\nLASTNAME INITIAL BIRTHDATE Smith J 12/3/1988 Barr K 25/5/1975\nLastly, in HTML, for an input like this:"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "A method based on a similar view of tables, using projection profiles and aligned spaces between word bounding boxes, was applied to convert Japanese tables into HTML [86]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "Page-descriptor file (Word, LATEX, HTML, PostScript, PDF) with linguistic content, and refined formatting."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "As noted earlier, these may originate either in ASCII form (e.g., as part of an e-mail message), or as the result of saving a \u201cricher\u201d document (e.g., an HTML page) in \u201ctext-only\u201d format."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "In any case, independent of the form of the input (whether it is a simple string of ASCII characters, a PostScript file, an HTML file, or an ontologically described sequence of ASCII character instances), the goal is to obtain the following kind of output:\n5 The \u2018o\u2019 at the base of the arrowhead connected to ASCII Character in Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "Simple electronic tables, whether ASCII, PDF, RTF, SGML, HTML, XML, LATEX, Tbl, or other, can probably be converted with moderate effort to an abstract form with over 90% accuracy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "We believe that the extraction of tables from HTML documents is evanescent compared to the conversion of paper documents because XML-based schemes are conceived with the goal of assuring machine interpretability [75]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "Electronic forms are based on HTML, JAVA, Active-X, or XML."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206776270,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f46d15c00823f9018e342b8686ff838ee7cc1794",
            "isKey": true,
            "numCitedBy": 16,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a system of region segmentation and conversion into an HTML file for an unknown machine-printed table image. Ruled lines delimit some cells of the table, and omitted ruled lines also delimit other cells. We consider a table analysis system for both types of table cell. First, our system segments a table by means of the ruled lines into some regions. Secondly, these segmented regions are further segmented into cells by the omitted ruled lines that are indicators (such as numerals and characters). The cells include several character lines, and our system can convert a table of unknown complex structure into an HTML file. Also, we confirm the effectiveness of our region segmentation method for various kinds of tables with omitted ruled lines by computer experiments."
            },
            "slug": "Region-segmentation-for-table-image-with-unknown-Tsuruoka-Tanaka",
            "title": {
                "fragments": [],
                "text": "Region segmentation for table image with unknown complex structure"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A system of region segmentation and conversion into an HTML file for an unknown machine-printed table image that segments a table by means of the ruled lines into some regions and segmented into cells by the omitted ruled lines that are indicators (such as numerals and characters)."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35155791"
                        ],
                        "name": "William A. Kornfeld",
                        "slug": "William-A.-Kornfeld",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Kornfeld",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William A. Kornfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152697317"
                        ],
                        "name": "J. Wattecamps",
                        "slug": "J.-Wattecamps",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wattecamps",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wattecamps"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 77
                            }
                        ],
                        "text": "Formal paradigms for describing the structure of tables are the Table Syntax [32, 58], the Structure Description Tree [93], and the Cohesion Domain Template [48]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10974046,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "675519b637ca69534a7ffd8829f05ce774885e26",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Information retrieval of ASCLI documents generally refers to retrieval based on linear patterns found in the source documents. We have developed a method for recognizing and extracting tabular data, inthis case financial tables. Tables are extracted using a version of the LR(k) parsing algorithm adapted for this purpose. Because of sloppiness in the construction of tables, somewhat less than 100% of the tables can be retrieved automatically; a method has been found to integrate the parsing algorithm into amodule analogous to a programming language debugger that allows operators to quickly correct defects in the source document. This paper describes an application in commercial use."
            },
            "slug": "Automatically-locating,-extracting-and-analyzing-Kornfeld-Wattecamps",
            "title": {
                "fragments": [],
                "text": "Automatically locating, extracting and analyzing tabular data"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A method has been found to integrate the parsing algorithm into amodule analogous to a programming language debugger that allows operators to quickly correct defects in the source document."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35074265"
                        ],
                        "name": "J. Handley",
                        "slug": "J.-Handley",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Handley",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Handley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "Although spanning header cells are found, their relationship to the leaf cells is not determined [38]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31720553,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "c730e6636e4245e2e282725d3c62a307e442eb02",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A table in a document is a rectilinear arrangement of cells where each cell contains a sequence of words. Several lines of text may compose one cell. Cells may be delimited by horizontal or vertical lines, but often this is not the case. A table analysis system is described which reconstructs table formatting information from table images whether or not the cells are explicitly delimited. Inputs to the system are word bounding boxes and any horizontal and vertical lines that delimit cells. Using a sequence of carefully-crafted rules, multi-line cells and their interrelationships are found even though no explicit delimiters are visible. This robust system is a component of a commercial document recognition system."
            },
            "slug": "Table-analysis-for-multiline-cell-identification-Handley",
            "title": {
                "fragments": [],
                "text": "Table analysis for multiline cell identification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A table analysis system is described which reconstructs table formatting information from table images whether or not the cells are explicitly delimited, and is a component of a commercial document recognition system."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3285734"
                        ],
                        "name": "S. Marinai",
                        "slug": "S.-Marinai",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Marinai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Marinai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 36383828,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b43d647d8966f25757f05f0250531f0c0281992",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Implications of technical demands made within digital libraries (DL\u2019s) for document image analysis systems are discussed. The state-of-the-art is summarized, including a digest of themes that emerged during the recent International Workshop on Document Image Analysis for Libraries. We attempt to specify, in considerable detail, the essential features of document analysis systems that can assist in: (a) the creation of DL\u2019s; (b) automatic indexing and retrieval of doc-images within DL\u2019s; (c) the presentation of doc-images to DL users; (d) navigation within and among doc-images in DL\u2019s; and (e) effective use of personal and"
            },
            "slug": "Document-Analysis-Systems-VI-Marinai-Dengel",
            "title": {
                "fragments": [],
                "text": "Document Analysis Systems VI"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The essential features of document analysis systems that can assist in the creation of digital libraries and automatic indexing and retrieval of doc-images within DL\u2019s are specified."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27130718"
                        ],
                        "name": "J. F. Arias",
                        "slug": "J.-F.-Arias",
                        "structuredName": {
                            "firstName": "Juan",
                            "lastName": "Arias",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. F. Arias"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 120
                            }
                        ],
                        "text": "The majority of the published work on table processing deals with the extraction of structure from scanned paper tables [1, 10, 15, 32, 39, 50, 60, 87, 93, 98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 113583753,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2a725e03bef89b63eaeaef2af42d13fda5f582f",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Utility companies maintain the information of the layout of their service installations and equipment as large size (D-size or E-size) paper drawings. Managing and updating this paper based information is a costly and tedious process. There are commercially available CAD-based systems which allow management of this information in a more easy and efficient way, but the large number of drawings in every company makes the manual conversion of the paper drawings to these systems infeasible. Therefore, efficient interpretation systems must be developed to perform this task. \nUtility company drawings usually consist of graphical structures formed by intersecting horizontal and vertical line segments. In this research, techniques for the construction of interpretation systems for drawings with such characteristics have been developed. The methodology is based on the use of the spatial relation between the different types of intersections formed by orthogonal line segments to describe the graphical objects. With this purpose, efficient algorithms for the extraction of intersection features and detection of lines between pairs of intersections have been developed. Techniques for the efficient manipulation in memory of the large image files that result from scanning the paper drawings have also been developed. \nUsing these techniques, interpretation systems for central office front equipment drawings and central office assignment table drawings from NYNEX, one of the local telephone companies in the U.S., have been constructed. \nAn evaluation of the algorithms for the extraction of the intersection primitives and the detection of lines has been performed. The interpretation systems developed are also tested using real central office drawings provided by NYNEX."
            },
            "slug": "Efficient-techniques-for-line-drawing-and-their-to-Arias",
            "title": {
                "fragments": [],
                "text": "Efficient techniques for line drawing interpretation and their application to telephone company drawings"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Techniques for the construction of interpretation systems for drawings with such characteristics have been developed, based on the use of the spatial relation between the different types of intersections formed by orthogonal line segments to describe the graphical objects."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25727408"
                        ],
                        "name": "Surekha Chandran",
                        "slug": "Surekha-Chandran",
                        "structuredName": {
                            "firstName": "Surekha",
                            "lastName": "Chandran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Surekha Chandran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 120
                            }
                        ],
                        "text": "The majority of the published work on table processing deals with the extraction of structure from scanned paper tables [1, 10, 15, 32, 39, 50, 60, 87, 93, 98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30719791,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "4c8cb8fd8a87ff2e60094385492a13c30977554b",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A system for extraction of structural information of a table from its image is discussed. Following the initial binarization and deskewing operations, the image is scanned to extract all horizontal and vertical lines that are present. The table's dimensions are estimated based on these lines. Unlike other systems, the procedure described does not depend on the sole existence of lines to mark the item blocks. White streams are recognized in both the horizontal and vertical direction as substitutes for any missing demarcation lines. A structure interpretation procedure uses the extracted demarcation information to identify each of the item blocks in the table. Subsequently, the interrelations of these item blocks are used to recognize the structure of the tabulated data.<<ETX>>"
            },
            "slug": "Structural-recognition-of-tabulated-data-Chandran-Kasturi",
            "title": {
                "fragments": [],
                "text": "Structural recognition of tabulated data"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A system for extraction of structural information of a table from its image using white streams as substitutes for any missing demarcation lines to identify each of the item blocks in the table."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122689890"
                        ],
                        "name": "Lee S. Jensen",
                        "slug": "Lee-S.-Jensen",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Jensen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lee S. Jensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 53
                            }
                        ],
                        "text": "Examples of systems that fit this definition include [22, 28, 31, 60, 80]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2313483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0909fee90833e20913adb553bf6667c9a3b854b0",
            "isKey": false,
            "numCitedBy": 293,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "A program that makes an existing website look like a database is called a wrapper. Wrapper learning is the problem of learning website wrappers from examples. We present a wrapper-learning system called WL2 that can exploit several different representations of a document. Examples of such different representations include DOM-level and token-level representations, as well as two-dimensional geometric views of the rendered page (for tabular data) and representations of the visual appearance of text asm it will be rendered. Additionally, the learning system is modular, and can be easily adapted to new domains and tasks. The learning system described is part of an \"industrial-strength\" wrapper management system that is in active use at WhizBang Labs. Controlled experiments show that the learner has broader coverage and a faster learning rate than earlier wrapper-learning systems."
            },
            "slug": "A-flexible-learning-system-for-wrapping-tables-and-Cohen-Hurst",
            "title": {
                "fragments": [],
                "text": "A flexible learning system for wrapping tables and lists in HTML documents"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A wrapper-learning system called WL2 that can exploit several different representations of a document, including DOM-level and token-level representations, as well as two-dimensional geometric views of the rendered page and representations of the visual appearance of text asm it will be rendered."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1839745"
                        ],
                        "name": "Y. Tijerino",
                        "slug": "Y.-Tijerino",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Tijerino",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Tijerino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730612"
                        ],
                        "name": "Deryle W. Lonsdale",
                        "slug": "Deryle-W.-Lonsdale",
                        "structuredName": {
                            "firstName": "Deryle",
                            "lastName": "Lonsdale",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deryle W. Lonsdale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645191"
                        ],
                        "name": "Yihong Ding",
                        "slug": "Yihong-Ding",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Ding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Ding"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11682816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "288673018a6f48a8aa20936833bcd3ef8661508b",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "At the heart of today's information-explosion problems are issues involving semantics, mutual understanding, concept matching, and interoperability. Ontologies and the Semantic Web are offered as a potential solution, but creating ontologies for real-world knowledge is nontrivial. If we could automate the process, we could significantly improve our chances of making the Semantic Web a reality. While understanding natural language is difficult, tables and other structured information make it easier to interpret new items and relations. In this paper we introduce an approach to generating ontologies based on table analysis. We thus call our approach TANGO (Table ANalysis for Generating Ontologies). Based on conceptual modeling extraction techniques, TANGO attempts to (i) understand a table's structure and conceptual content; (ii) discover the constraints that hold between concepts extracted from the table; (iii) match the recognized concepts with ones from a more general specification of related concepts; and (iv) merge the resulting structure with other similar knowledge representations. TANGO is thus a formalized method of processing the format and content of tables that can serve to incrementally build a relevant reusable conceptual ontology."
            },
            "slug": "Towards-Ontology-Generation-from-Tables-Tijerino-Embley",
            "title": {
                "fragments": [],
                "text": "Towards Ontology Generation from Tables"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper introduces an approach to generating ontologies based on table analysis called TANGO (Table ANalysis for Generating Ontologies), a formalized method of processing the format and content of tables that can serve to incrementally build a relevant reusable conceptual ontology."
            },
            "venue": {
                "fragments": [],
                "text": "World Wide Web"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27130718"
                        ],
                        "name": "J. F. Arias",
                        "slug": "J.-F.-Arias",
                        "structuredName": {
                            "firstName": "Juan",
                            "lastName": "Arias",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. F. Arias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34817063"
                        ],
                        "name": "A. Chhabra",
                        "slug": "A.-Chhabra",
                        "structuredName": {
                            "firstName": "Atul",
                            "lastName": "Chhabra",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chhabra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066269376"
                        ],
                        "name": "Vishal Misra",
                        "slug": "Vishal-Misra",
                        "structuredName": {
                            "firstName": "Vishal",
                            "lastName": "Misra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vishal Misra"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38874165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bc0fa7e9c67458d273b1f125a7b78cf700d5637",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We present efficient techniques for the interpretation and representation of tabular documents. Our goal is to achieve processing times that are fast enough for an interactive table conversion system. The techniques are based on the run-length encoded representation of scanned documents. We use DSX assignment tables, a predominant type of engineering drawing in telephone company central offices, as sample images in this paper. However, the techniques presented can be applied directly to tabular documents in any application."
            },
            "slug": "Efficient-interpretation-of-tabular-documents-Arias-Chhabra",
            "title": {
                "fragments": [],
                "text": "Efficient interpretation of tabular documents"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "Efficient techniques for the interpretation and representation of tabular documents are presented based on the run-length encoded representation of scanned documents to achieve processing times that are fast enough for an interactive table conversion system."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789181"
                        ],
                        "name": "Bertrand Co\u00fcasnon",
                        "slug": "Bertrand-Co\u00fcasnon",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Co\u00fcasnon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bertrand Co\u00fcasnon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 137
                            }
                        ],
                        "text": "Enhanced Position Formalism (EPF) is a 2-D grammar able to describe document layouts for sheet music, mathematical equations, and tables [24, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12982013,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8afc676c5f2ee8090b67b4c60ab2d8a9e3ebd4a",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Genericity in structured document recognition is a difficult challenge. We therefore propose a new generic document recognition method, called DMOS (Description and MOdification of Segmentation), that is made up of a new grammatical formalism, called EPF (Enhanced Position Formalism) and an associated parser which is able to introduce context in segmentation. We implement this method to obtain a generator of document recognition systems. This generator can automatically produce new recognition systems. It is only necessary to describe the document with an EPF grammar, which is then simply compiled. In this way, we have developed various recognition systems: one on musical scores, one on mathematical formulae and one on recursive table structures. We have also defined a specific application to damaged military forms of the 19th Century. We have been able to test the generated system on 5,000 of these military forms. This has permitted us to validate the DMOS method on a real-world application."
            },
            "slug": "DMOS:-a-generic-document-recognition-method,-to-an-Co\u00fcasnon",
            "title": {
                "fragments": [],
                "text": "DMOS: a generic document recognition method, application to an automatic generator of musical scores, mathematical formulae and table structures recognition systems"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A new generic document recognition method, called DMOS (Description and MOdification of Segmentation), that is made up of a new grammatical formalism, called EPF (Enhanced Position Formalism), and an associated parser which is able to introduce context in segmentation is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149125050"
                        ],
                        "name": "Bing Liu",
                        "slug": "Bing-Liu",
                        "structuredName": {
                            "firstName": "Bing",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bing Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112316836"
                        ],
                        "name": "Zao Jiang",
                        "slug": "Zao-Jiang",
                        "structuredName": {
                            "firstName": "Zao",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zao Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97628243"
                        ],
                        "name": "Hong Zhao",
                        "slug": "Hong-Zhao",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2592604"
                        ],
                        "name": "Tobias Ostgathe",
                        "slug": "Tobias-Ostgathe",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Ostgathe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias Ostgathe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "The similarities between table and form processing are emphasized in [87] and [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 639663,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01c46a70170838fae9291f42d1476fc2a2fd9d69",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Many methods on form document image analysis have been proposed, but few have treated the extraction of logical structure. A new method for the logical structure extraction of form document is proposed in this paper. The algorithm of it consists of three phases: global division of the whole document, local logical structure analysis and global re- division of the whole document. GLG method emphasizes the global layout structure analysis and has higher accuracy. It is robust for treating with the accidental direct adjacent relationship between two irrelated cells. In addition, a logical structure tree is proposed to represent the logical structure of a form document."
            },
            "slug": "New-method-for-logical-structure-extraction-of-form-Liu-Jiang",
            "title": {
                "fragments": [],
                "text": "New method for logical structure extraction of form document image"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new method for the logical structure extraction of form document, called GLG method, which emphasizes the global layout structure analysis and has higher accuracy and is robust for treating with the accidental direct adjacent relationship between two irrelated cells."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1813168"
                        ],
                        "name": "Heath E. Nielson",
                        "slug": "Heath-E.-Nielson",
                        "structuredName": {
                            "firstName": "Heath",
                            "lastName": "Nielson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heath E. Nielson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144055367"
                        ],
                        "name": "W. Barrett",
                        "slug": "W.-Barrett",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Barrett",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Barrett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "Other notable work on forms includes [5] and [69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16384589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8098fd7ed3ba9374986339b8da837bababb6e4e1",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Zoning documents increases the resolution of indexingfrom the image level to the field level. A line-delimited tabulardocument forms a well defined series of regions. However,as image quality decreases, accurate zoning becomesincreasingly difficult. Given a sequence of documents withthe same layout, we present a robust zoning method whichexploits both intra- and inter-document consensus to forma more accurate combined result (template) that can be appliedto any other document with the same layout."
            },
            "slug": "Consensus-based-table-form-recognition-Nielson-Barrett",
            "title": {
                "fragments": [],
                "text": "Consensus-based table form recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A robust zoning method is presented that combines both intra- and inter-document consensus to form a more accurate combined result (template) that can be applied to any other document with the same layout."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3075265"
                        ],
                        "name": "E. Codd",
                        "slug": "E.-Codd",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Codd",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Codd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "[84], relational tables [21] do provide a theoretical basis for tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60513637,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4bd2f89039031f09b9ddec07e6d456b0d08aab4",
            "isKey": false,
            "numCitedBy": 883,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "ion, not implementation. His goal is to describe data, not to build a model of computation (which one would then be expected to prove equivalent to Turing Machines). It seems that some of the ideas presented in this paper are also found in Object-Oriented programming. There seem to be parallels between the idea of data encapsulation and interfaces, to reduce implementation dependencies, and the idea of using a relation view of data to avoid ordering dependencies, access path dependencies and other implementation dependencies. Did the Object-Oriented paradigm influence the Declarative or was it the other way around? Or were both views simply applying the same theoretical abstractions? I think both are applying the same general principle abstraction is your friend. The paper says normalization is an advantage for storage (381, third paragraph). I don\u2019t know how to prove this to be true. From the employee example, I can see the primary key man# are duplicated many times. Duplication doesn\u2019t sound like an advantage for storage. The keys are typicaly integers, which doesn\u2019t add much overhead. I don\u2019t know enough about the previous designs to tell you how much overhead there was in making subrelations as values. Is there a systematic method to design a relation or database tables? Like how to decide what and how many tables, primary key, foreign key are needed? There are some clear ways to analyze problems to determine potential relations, but I expect that there is also some art (and therefore some experience) required."
            },
            "slug": "A-Relational-Model-for-Large-Shared-Data-Banks-Codd",
            "title": {
                "fragments": [],
                "text": "A Relational Model for Large Shared Data Banks"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "His goal is to describe data, not to build a model of computation (which one would then be expected to prove equivalent to Turing Machines), and the idea of using a relation view of data to avoid ordering dependencies, access path dependencies and other implementation dependencies."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074293587"
                        ],
                        "name": "Q. Luo",
                        "slug": "Q.-Luo",
                        "structuredName": {
                            "firstName": "Qin",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1500661115"
                        ],
                        "name": "Toyohide Watanabe",
                        "slug": "Toyohide-Watanabe",
                        "structuredName": {
                            "firstName": "Toyohide",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toyohide Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29765151"
                        ],
                        "name": "Y. Yoshida",
                        "slug": "Y.-Yoshida",
                        "structuredName": {
                            "firstName": "Yuuji",
                            "lastName": "Yoshida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yoshida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056747928"
                        ],
                        "name": "Y. Inagaki",
                        "slug": "Y.-Inagaki",
                        "structuredName": {
                            "firstName": "Yasuyoshi",
                            "lastName": "Inagaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Inagaki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 32
                            }
                        ],
                        "text": "Toyohide Watanabe and coworkers [64, 92, 91, 90, 93] aim at a complete description of the various types of information necessary to interpret a ruled scanned table."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 75318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66ee99be93ee3ffd9d28eb3d63e18f4a158bc9be",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a new method to extract and classify the meaningful information from documents automatically. The basic idea in our method is to utilize the spatial and geometric relationships between document items. Our approach is adaptable even if the layout structures are modified more or less, because the coordinate values of positions, sizes, lengthes and so on are not specified directly. Additionally, some experiments for typical documents such as library cataloging cards, name cards and letters are shown concretely."
            },
            "slug": "Recognition-of-Document-Structure-on-the-Basis-of-Luo-Watanabe",
            "title": {
                "fragments": [],
                "text": "Recognition of Document Structure on the Basis of Spatial and Geometric Relationships between Document Items"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The basic idea in the method is to utilize the spatial and geometric relationships between document items to extract and classify the meaningful information from documents automatically."
            },
            "venue": {
                "fragments": [],
                "text": "MVA"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27130718"
                        ],
                        "name": "J. F. Arias",
                        "slug": "J.-F.-Arias",
                        "structuredName": {
                            "firstName": "Juan",
                            "lastName": "Arias",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. F. Arias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047403"
                        ],
                        "name": "S. Balasubramanian",
                        "slug": "S.-Balasubramanian",
                        "structuredName": {
                            "firstName": "Sanjay",
                            "lastName": "Balasubramanian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Balasubramanian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153819718"
                        ],
                        "name": "Arathi Prasad",
                        "slug": "Arathi-Prasad",
                        "structuredName": {
                            "firstName": "Arathi",
                            "lastName": "Prasad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arathi Prasad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34817063"
                        ],
                        "name": "A. Chhabra",
                        "slug": "A.-Chhabra",
                        "structuredName": {
                            "firstName": "Atul",
                            "lastName": "Chhabra",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chhabra"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206588983,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "5d757fef48d23733fc0528bdb8f970f5f3ac35ad",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A system for the interpretation of telephone company drawings is described. Two different types of drawings are interpreted: manhole and table drawings. Each drawing is interpreted by using a different approach to suit its characteristics. Manhole drawings represent the interconnection of telephone lines in the field. The approach used is the vectorization of the line segments to extract continuous lines. The table drawings contain information related to the cables in the manhole. The approach is to locate lines and their intersections to extract the information for entries. An Intelligent Character Recognition (ICR) system is used to interpret text information by using grammars.<<ETX>>"
            },
            "slug": "Information-extraction-from-telephone-company-Arias-Balasubramanian",
            "title": {
                "fragments": [],
                "text": "Information extraction from telephone company drawings"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A system for the interpretation of telephone company drawings is described and an Intelligent Character Recognition (ICR) system is used to interpret text information by using grammars."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34996245"
                        ],
                        "name": "B. Klein",
                        "slug": "B.-Klein",
                        "structuredName": {
                            "firstName": "Bertin",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2582412"
                        ],
                        "name": "S. Agne",
                        "slug": "S.-Agne",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Agne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Agne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4839405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "88ffc69930d8ee8c4d762ac90978d96d71023bf7",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Companies order, receive, and pay for goods. Hence they continually receive and process invoices. For the most part these are printed on paper and are dealt with manually, so that each invoice after receipt involves processing costs of about 9 Euro on average. Often, human searching and typing of data into computer forms is required to transfer the information from paper into the computer, e.g. into ERP-systems, like SAP, that many companies run. This article presents the main results of our 300-page market survey of 11 suppliers of invoice reading systems (\\(\\mathcal{I}\\)-\\(\\mathcal{R}\\)-\\(\\mathcal{S}\\)), which automate the transfer of invoice data to ERP-systems. For the scientific \\(\\mathcal{I}\\)-\\(\\mathcal{R}\\)-\\(\\mathcal{S}\\) community we hope to provide the service of a better visibility of our discipline to potential investors and users."
            },
            "slug": "Results-of-a-Study-on-Invoice-Reading-Systems-in-Klein-Agne",
            "title": {
                "fragments": [],
                "text": "Results of a Study on Invoice-Reading Systems in Germany"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This article presents the main results of the 300-page market survey of 11 suppliers of invoice reading systems (I-R-S), which automate the transfer of invoice data to ERP-systems, to provide a better visibility of the discipline to potential investors and users."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687313"
                        ],
                        "name": "T. Watanabe",
                        "slug": "T.-Watanabe",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35087915"
                        ],
                        "name": "T. Fukumura",
                        "slug": "T.-Fukumura",
                        "structuredName": {
                            "firstName": "Teruo",
                            "lastName": "Fukumura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Fukumura"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 32
                            }
                        ],
                        "text": "Toyohide Watanabe and coworkers [64, 92, 91, 90, 93] aim at a complete description of the various types of information necessary to interpret a ruled scanned table."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206774839,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19b1796327075e6a7e0a2d140c83e5992755b615",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the knowledge representation for understanding table-form documents. In particular, we focus on the knowledge for establishing the correctness of recognized results in addition to the traditional syntactic/constructive-oriented understanding framework. In order to attain to this subject, we introduce the semantic information to specify domains and relationships among individual items definitely, which is complementary to the syntactic/constructive information available in the traditional framework."
            },
            "slug": "A-framework-for-validating-recognized-results-in-Watanabe-Fukumura",
            "title": {
                "fragments": [],
                "text": "A framework for validating recognized results in understanding table-form document images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The semantic information to specify domains and relationships among individual items definitely is introduced, which is complementary to the syntactic/constructive information available in the traditional framework."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "Experiments have shown that even human \u201cexperts\u201d do not always agree on the sets of label\u2013value pairs for a table [41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16106027,
            "fieldsOfStudy": [
                "Computer Science",
                "Philosophy"
            ],
            "id": "9e16dcd290d9ab780107270c666d71c00e569b22",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The principle that for every document analysis task there exists a mechanism for creating well-defined ground-truth is a widely held tenet. Past experience with standard datasets providing ground-truth for character recognition and page segmentation tasks supports this belief. In the process of attempting to evaluate several table recognition algorithms we have been developing, however, we have uncovered a number of serious hurdles connected with the ground-truthing of tables. This problem may, in fact, be much more difficult than it appears. We present a detailed analysis of why table ground-truthing is so hard, including the notions that there may exist more than one acceptable \"truth\" and/or incomplete or partial \"truths\"."
            },
            "slug": "Why-table-ground-truthing-is-hard-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Why table ground-truthing is hard"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a detailed analysis of why table ground-truthing is so hard, including the notions that there may exist more than one acceptable \"truth\" and/or incomplete or partial \"truths\"."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789181"
                        ],
                        "name": "Bertrand Co\u00fcasnon",
                        "slug": "Bertrand-Co\u00fcasnon",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Co\u00fcasnon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bertrand Co\u00fcasnon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760753"
                        ],
                        "name": "J. Camillerapp",
                        "slug": "J.-Camillerapp",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Camillerapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Camillerapp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3126026"
                        ],
                        "name": "I. Leplumey",
                        "slug": "I.-Leplumey",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Leplumey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Leplumey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 137
                            }
                        ],
                        "text": "Enhanced Position Formalism (EPF) is a 2-D grammar able to describe document layouts for sheet music, mathematical equations, and tables [24, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12428873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd2acea5b2e9a57874ccfaf75b773facec6af266",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present annotations needed for handwritten archive document retrieval by content. We propose two complementary ways of producing those annotations: automatically by using document image analysis and collectively by using Internet and a manual input by users. A platform for managing those annotations is presented as well as examples of automatic annotations on civil status registers, military forms (tested on 60000 pages) and naturalization decrees, using a generic document recognition method. Examples of collective annotations built on automatic annotations are also given. This platform will be officially open to public on Internet and inside the new building of the Archives departementales des Yvelines in December 2003. 1200000 images of civil status registers will be available for collective annotation as well as 35000 pages of military forms with automatic annotation of handwritten names."
            },
            "slug": "Making-handwritten-archives-documents-accessible-to-Co\u00fcasnon-Camillerapp",
            "title": {
                "fragments": [],
                "text": "Making handwritten archives documents accessible to public with a generic system of document image analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A platform for managing annotations needed for handwritten archive document retrieval by content is presented as well as examples of automatic annotations on civil status registers, military forms and naturalization decrees, using a generic document recognition method."
            },
            "venue": {
                "fragments": [],
                "text": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32072466"
                        ],
                        "name": "T. Gruber",
                        "slug": "T.-Gruber",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Gruber",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gruber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "Since \u201can ontology is a formal, explicit specification of a shared conceptualization\u201d [34], a table understanding ontology formally and explicitly specifies a shared conceptualization of table understanding."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15709015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5120f65919f77859a974fcc1ad08f72b2918b8ec",
            "isKey": false,
            "numCitedBy": 13142,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract To support the sharing and reuse of formally represented knowledge among AI systems, it is useful to define the common vocabulary in which shared knowledge is represented. A specification of a representational vocabulary for a shared domain of discourse\u2014definitions of classes, relations, functions, and other objects\u2014is called an ontology. This paper describes a mechanism for defining ontologies that are portable over representation systems. Definitions written in a standard format for predicate calculus are translated by a system called Ontolingua into specialized representations, including frame-based systems as well as relational languages. This allows researchers to share and reuse ontologies, while retaining the computational benefits of specialized implementations. We discuss how the translation approach to portability addresses several technical problems. One problem is how to accommodate the stylistic and organizational differences among representations while preserving declarative content. Another is how to translate from a very expressive language into restricted languages, remaining system-independent while preserving the computational efficiency of implemented systems. We describe how these problems are addressed by basing Ontolingua itself on an ontology of domain-independent, representational idioms."
            },
            "slug": "A-translation-approach-to-portable-ontology-Gruber",
            "title": {
                "fragments": [],
                "text": "A translation approach to portable ontology specifications"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper describes a mechanism for defining ontologies that are portable over representation systems, basing Ontolingua itself on an ontology of domain-independent, representational idioms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145802082"
                        ],
                        "name": "R. Chiang",
                        "slug": "R.-Chiang",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Chiang",
                            "middleNames": [
                                "H.",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3067877"
                        ],
                        "name": "T. M. Barron",
                        "slug": "T.-M.-Barron",
                        "structuredName": {
                            "firstName": "Terence",
                            "lastName": "Barron",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. M. Barron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764975"
                        ],
                        "name": "V. Storey",
                        "slug": "V.-Storey",
                        "structuredName": {
                            "firstName": "Veda",
                            "lastName": "Storey",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Storey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": ", [20]) a collection of tables into a conceptual model (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15388725,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5066ed811791845cb95b741480fb15fd43d7c3c4",
            "isKey": false,
            "numCitedBy": 286,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Reverse-Engineering-of-Relational-Databases:-of-an-Chiang-Barron",
            "title": {
                "fragments": [],
                "text": "Reverse Engineering of Relational Databases: Extraction of an EER Model from a Relational Database"
            },
            "venue": {
                "fragments": [],
                "text": "Data Knowl. Eng."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143894263"
                        ],
                        "name": "Hui Chao",
                        "slug": "Hui-Chao",
                        "structuredName": {
                            "firstName": "Hui",
                            "lastName": "Chao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui Chao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962939"
                        ],
                        "name": "Jian Fan",
                        "slug": "Jian-Fan",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Fan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 129
                            }
                        ],
                        "text": "It is clear that the combination of the current text layer and vector graphics layer analysis provides the necessary foundations [16, 17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16993093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "358899712252e129c431a34a23d0a6bf754cebcf",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Portable document format (PDF) is a common output format for electronic documents. Most PDF documents are untagged and do not have basic high-level document logical structural information, which makes the reuse or modification of the documents difficult. We developed techniques that identified logical components on a PDF document page. The outlines, style attributes and the contents of the logical components were extracted and expressed in an XML format. These techniques could facilitate the reuse and modification of the layout and the content of a PDF document page."
            },
            "slug": "Layout-and-Content-Extraction-for-PDF-Documents-Chao-Fan",
            "title": {
                "fragments": [],
                "text": "Layout and Content Extraction for PDF Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Techniques that identified logical components on a PDF document page were developed and the outlines, style attributes and the contents of the logical components were extracted and expressed in an XML format."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34996245"
                        ],
                        "name": "B. Klein",
                        "slug": "B.-Klein",
                        "structuredName": {
                            "firstName": "Bertin",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4847569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea98bba9cde188317573a37e7d6efbc64e11008d",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.Although the Internet is increasingly emerging as \u201cthe\u201d widespread platform for information interchange, day-to-day work in companies still necessitates the laborious, manual processing of huge amounts of printed documents. This article presents the system smartFIX, a document analysis and understanding system developed by the DFKI spin-off insiders technologies. It enables the automatic processing of documents ranging from fixed format forms to unstructured letters of any format. In addition to the architecture, main components, and system characteristics, we also show some results from the application of smartFIX to medical bills and prescriptions."
            },
            "slug": "Problem-adaptable-document-analysis-and-for-Klein-Dengel",
            "title": {
                "fragments": [],
                "text": "Problem-adaptable document analysis and understanding for high-volume applications"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The system smartFIX, a document analysis and understanding system developed by the DFKI spin-off insiders technologies, enables the automatic processing of documents ranging from fixed format forms to unstructured letters of any format."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis and Recognition"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32166584"
                        ],
                        "name": "L. Cherry",
                        "slug": "L.-Cherry",
                        "structuredName": {
                            "firstName": "Lorinda",
                            "lastName": "Cherry",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cherry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142223"
                        ],
                        "name": "M. Lesk",
                        "slug": "M.-Lesk",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lesk",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lesk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "Page composition languages have elaborate facilities for formatting tables, like TROFF Tbl [61] and the LATEX table and array environments [59]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 53898874,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "70d7d7c5345d971ec90d8e77f2ff0bb14ee29350",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Tbl is a document formatting preprocessor for troff or nroff which makes even fairly complex tables easy to specify and enter. Tables are made up of columns which may be independently centered, right-adjusted, left-adjusted, or aligned by decimal points. Headings may be placed over single columns or groups of columns. A table entry may contain equations, or may consist of several rows of text. Horizontal or vertical lines may be drawn as desired in the table, and any table or element may be enclosed in a box. For example: _ ________________________________________ U. S. Energy Production/Consumption (in quadrillion Btu) _ ________________________________________ _ ________________________________________ Production Consumption Year all sources Net _ ________________________________________ 1953 36.77 36.27 +0.51 1958 38.81 40.35 \u2013 1.54 1963 45.85 48.32 \u2013 2.47 1968 56.81 61.00 \u2013 4.19 1973 62.06 74.28 \u2013 12.22 1978 61.01 78.09 \u2013 17.08 1983 61.19 70.05 \u2013 8.86 1987 64.55 76.01 \u2013 11.46 _ ________________________________________ \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec\uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec\uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec\uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec"
            },
            "slug": "TB1\u2014a-program-to-format-tables-Cherry-Lesk",
            "title": {
                "fragments": [],
                "text": "TB1\u2014a program to format tables"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Tbl is a document formatting preprocessor for troff or nroff which makes even fairly complex tables easy to specify and enter."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720135"
                        ],
                        "name": "A. Anjewierden",
                        "slug": "A.-Anjewierden",
                        "structuredName": {
                            "firstName": "Anjo",
                            "lastName": "Anjewierden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Anjewierden"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 252
                            }
                        ],
                        "text": "PDF encodes a document as four types of graphics rendering instructions: (1) control instructions produce no output; (2) text instructions render glyphs of symbols; (3) graphics instructions render line art; (4) image instructions map bitmapped images [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 124
                            }
                        ],
                        "text": "A shallow grammar is implemented for recognizing each function: tables are recognized as a proximate set of \u201cfloating\u201d text [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16469563,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d92ab24a84412ff83e87c994a1174856aebe1895",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "AIDAS is part of a research project in which the aim is to turn technical manuals into a database of indexed training material. We describe the approach AIDAS uses to extract the logical document structure from PDF documents. The approach is based on the idea that the layout structure contains cues about the logical structure and that the logical structure can be discovered incrementally."
            },
            "slug": "AIDAS:-incremental-logical-structure-discovery-in-Anjewierden",
            "title": {
                "fragments": [],
                "text": "AIDAS: incremental logical structure discovery in PDF documents"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "AIDAS is part of a research project in which the aim is to turn technical manuals into a database of indexed training material and the approach AIDAS uses to extract the logical document structure from PDF documents is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145421878"
                        ],
                        "name": "R. Sproat",
                        "slug": "R.-Sproat",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sproat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sproat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107759288"
                        ],
                        "name": "J. Hu",
                        "slug": "J.-Hu",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1390823203"
                        ],
                        "name": "H. Chen",
                        "slug": "H.-Chen",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "In the EMU project [81], it may be desirable to detect and access newly received tables in e-mail by telephone."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206476406,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c4a627815f65874e803f4334000245f38678d71",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "E-mail reading is one of the most important commercial applications of text-to-speech synthesis (TTS). Yet e-mail is one of the most difficult types of text to deal with, since it is both highly structured -frequently containing elements such as tables, signatures, \"artwork\" and quotations from previous messages; and at the same time often lacks any reliable unambiguous indicators for such structure. This paper describes Emu, an e-mail mark-up and rendering program that preprocesses e-mail for TTS. We discuss algorithms for detecting regions of interest in the input text; for \"normalizing\" the input; and for actually rendering the input through the Bell Labs TTS system."
            },
            "slug": "Emu:-an-e-mail-preprocessor-for-text-to-speech-Sproat-Hu",
            "title": {
                "fragments": [],
                "text": "Emu: an e-mail preprocessor for text-to-speech"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Emmu is described, an e-mail mark-up and rendering program that preprocesses e- email for TTS and discusses algorithms for detecting regions of interest in the input text; for \"normalizing\" the input; and for actually rendering the input through the Bell Labs TTS system."
            },
            "venue": {
                "fragments": [],
                "text": "1998 IEEE Second Workshop on Multimedia Signal Processing (Cat. No.98EX175)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34996245"
                        ],
                        "name": "B. Klein",
                        "slug": "B.-Klein",
                        "structuredName": {
                            "firstName": "Bertin",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2582412"
                        ],
                        "name": "S. Agne",
                        "slug": "S.-Agne",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Agne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Agne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749498"
                        ],
                        "name": "Andrew D. Bagdanov",
                        "slug": "Andrew-D.-Bagdanov",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Bagdanov",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew D. Bagdanov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10145168,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d41da8ba937a2190ee276c8f5f131befe21a93e9",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We turn to the viewpoint of users of a DAU system. Out ofthe view of users we sketch a picture of \"Document Analysisand Understanding\" (DAU), only a simple division ofDAU into six sub-tasks, and consider this a model of DAU.We provide one elaborate example of a use of the model: themodule design of the commercially successful DAU systemsmartFIX. We argue that such modeling of DAU can beof benefit to the whole field of DAU."
            },
            "slug": "Understanding-document-analysis-and-understanding-Klein-Agne",
            "title": {
                "fragments": [],
                "text": "Understanding document analysis and understanding (through modeling)"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is argued that such modeling of DAU can be of benefit to the whole field ofDAU and one elaborate example of a use of the model is provided: themodule design of the commercially successful DAU systemsmartFIX."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34817063"
                        ],
                        "name": "A. Chhabra",
                        "slug": "A.-Chhabra",
                        "structuredName": {
                            "firstName": "Atul",
                            "lastName": "Chhabra",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chhabra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066269376"
                        ],
                        "name": "Vishal Misra",
                        "slug": "Vishal-Misra",
                        "structuredName": {
                            "firstName": "Vishal",
                            "lastName": "Misra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vishal Misra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27130718"
                        ],
                        "name": "J. F. Arias",
                        "slug": "J.-F.-Arias",
                        "structuredName": {
                            "firstName": "Juan",
                            "lastName": "Arias",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. F. Arias"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41479210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57e2f7d47618c43ac067e093a3152faa1ffeba12",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a fast method for finding horizontal lines in run length encoded images. The method was motivated by the need for quick and reliable detection of horizontal lines in an interactive drawing conversion system for telephone company drawings. At the core of the algorithm are the processes of filtering run lengths, assembling filtered run lengths, generating top silhouette, and thresholding the gradient of the top silhouette to extract one horizontal line at a time. The method is robust in the presence of distortion; it can tolerate significant skew and warping, both local and global, and can bridge significant breaks in lines without too many false positive lines."
            },
            "slug": "Detection-of-Horizontal-Lines-in-Noisy-Run-Length-Chhabra-Misra",
            "title": {
                "fragments": [],
                "text": "Detection of Horizontal Lines in Noisy Run Length Encoded Images: The FAST Method"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The method is robust in the presence of distortion; it can tolerate significant skew and warping, both local and global, and can bridge significant breaks in lines without too many false positive lines."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145944286"
                        ],
                        "name": "D. Rus",
                        "slug": "D.-Rus",
                        "structuredName": {
                            "firstName": "Daniela",
                            "lastName": "Rus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144922029"
                        ],
                        "name": "D. Subramanian",
                        "slug": "D.-Subramanian",
                        "structuredName": {
                            "firstName": "Devika",
                            "lastName": "Subramanian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Subramanian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 37
                            }
                        ],
                        "text": "Building on extensive previous work, Rus and Subramanian [77] offer an interactive method of building models\nconsisting of modular interactive agents for information access and capture in distributed databases."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "Building on extensive previous work, Rus and Subramanian [77] offer an interactive method of building models consisting of modular interactive agents for information access and capture in distributed databases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13156464,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9c6887986159246f98648b5a9b432b41f5e17a3",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a customizable architecture for software agents that capture and access information in large, heterogeneous, distributed electronic repositories. The key idea is to exploit underlying structure at various levels of granularity to build high-level indices with task-specific interpretations. Information agents construct such indices and are configured as a network of reusable modules called structure detectors and segmenters. We illustrate our architecture with the design and implementation of smart information filters in two contexts: retrieving stock market data from Internet newsgroups and retrieving technical reports from Internet FTP sites."
            },
            "slug": "Customizing-information-capture-and-access-Rus-Subramanian",
            "title": {
                "fragments": [],
                "text": "Customizing information capture and access"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This article presents a customizable architecture for software agents that capture and access information in large, heterogeneous, distributed electronic repositories to exploit underlying structure at various levels of granularity to build high-level indices with task-specific interpretations."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143965889"
                        ],
                        "name": "S. Whittaker",
                        "slug": "S.-Whittaker",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Whittaker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Whittaker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2668280"
                        ],
                        "name": "C. Sidner",
                        "slug": "C.-Sidner",
                        "structuredName": {
                            "firstName": "Candace",
                            "lastName": "Sidner",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sidner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "The Semantic Web requires an abundance of ontologies, and creating them by hand is seen as a barrier preventing widespread use of the Semantic Web."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "3.7 Table modification for display\nRetargeting Web page displays for small-screen devices like personal digital assistants (PDAs) and cell phones has assumed increased urgency and importance with the deployment of fast wireless connectivity."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": "The real problem with layout analysis on Web pages is that everything floats."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 147
                            }
                        ],
                        "text": "Continuing efforts to pass processing costs down to the end users will cause many of these mass form-processing applications to be migrated to the Web."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "Expandable (clickable) Web tables and Web tables employing hypertext links (embedded URLs)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "Interestingly, many if not most Web pages are constructed with the HTML <table> construct (just as figures in Microsoft Word are often laid out using its table facility)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 122
                            }
                        ],
                        "text": "Electronic tables such as those found in word processing documents, e-mail, Portable Document Format (PDF) files, and the Web, already have the content of the leaf cells in symbolic form, so OCR is not necessary, but the structure is seldom available in a convenient form."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 142
                            }
                        ],
                        "text": "Thus, a relatively new application for table processing is the consolidation of information from multiple tables (usually downloaded from the Web) to generate domain-specific ontologies."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 151
                            }
                        ],
                        "text": "3.9 Ontology learning from tables\nOntology learning (e.g., [65]) has recently received considerable attention because of the emergence of the Semantic Web."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 144
                            }
                        ],
                        "text": "At least partially automating the preparation of such bodies of factual information may help pave the way towards a realization of the Semantic Web."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 178
                            }
                        ],
                        "text": "Bitmap file of an image of a table with white space around it.4\n5.1 Tables presented in electronic format\nTables in plain text format may appear in e-mail or on certain kinds of Web pages."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 128
                            }
                        ],
                        "text": "3.3 Individual database creation\nThis is a filing application for data that arrives in e-mail, by post, or is discovered on the Web [94]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "VXML is a proposed general-purpose format for audio access to Web documents."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "FrameMaker offers PDF for posting tables on the Web in non-editable form, and XML for applications where the structure needs to be accessible."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "The former are known as PostScript interpreters (e.g., Ghostscript), while the latter are referred to as Web browsers (e.g., Mozilla)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "This is a filing application for data that arrives in e-mail, by post, or is discovered on the Web [94]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "While this is of increasing interest, especially arising out of the Semantic Web, there has been more work on the earlier aspects."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1727842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7672ff5d79812e6cc85b18c6c4ed5aae197c676",
            "isKey": true,
            "numCitedBy": 1095,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Email is one oftl~ most successful computer applicmiom yet devised. Our empin~:al ct~ta show however, that althongh email was origiraUy designed as a c~nmunica/ons application, it is now used for ~tional funaions, that it was not designed for, such as tab management and persona/ afoOt/v/rig. We call this ernt~l oveHoad We demonstrate that email overload creates problems for personal information manageaa,cnt: users eden have cluttered inboxes cor~mining hundreds of n~:age~\u00a2, incl~rling outstanding tasks, partially read documents and conversational threads. Furthermore,, user attemt:Xs to rationalise their inbox~ by ~ing are ~Ron unsuccessful, with the consequence that important rr~ges get overlooked, or \"lost\" in archives. We explain how em~l over/oad/ng arises and propose technical solutions to the problem."
            },
            "slug": "Email-overload:-exploring-personal-information-of-Whittaker-Sidner",
            "title": {
                "fragments": [],
                "text": "Email overload: exploring personal information management of email"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is demonstrated that email overload creates problems for personal information manageaa, and how this arises is explained and technical solutions to the problem are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "CHI"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104083354"
                        ],
                        "name": "K. Larson",
                        "slug": "K.-Larson",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Larson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Larson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9844322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5bd990ad3c65602fe74edfd31697c616c5ec061",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer screens have a big problem in terms of resolution, even LCD screens on most laptops and desktop computers have a resolution of only about 100 pixels per inch. It is observed that a printed page has much better quality. This paper discusses how to achieve a much better resolution on a computer screen to improve one's reading experience."
            },
            "slug": "The-Technology-of-Text-Larson",
            "title": {
                "fragments": [],
                "text": "The Technology of Text"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper discusses how to achieve a much better resolution on a computer screen to improve one's reading experience."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Spectrum"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1835956"
                        ],
                        "name": "E. Turolla",
                        "slug": "E.-Turolla",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Turolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Turolla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2448729"
                        ],
                        "name": "Y. Bela\u00efd",
                        "slug": "Y.-Bela\u00efd",
                        "structuredName": {
                            "firstName": "Yolande",
                            "lastName": "Bela\u00efd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Bela\u00efd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2128453"
                        ],
                        "name": "A. Bela\u00efd",
                        "slug": "A.-Bela\u00efd",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Bela\u00efd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bela\u00efd"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 76
                            }
                        ],
                        "text": "Image processing techniques for the extraction of line segments include the Hough Transform [87], thinning, vectorization [1] and projection profiles [50]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 120
                            }
                        ],
                        "text": "The majority of the published work on table processing deals with the extraction of structure from scanned paper tables [1, 10, 15, 32, 39, 50, 60, 87, 93, 98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 30
                            }
                        ],
                        "text": "The lines are found using the Hough Transform."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "The similarities between table and form processing are emphasized in [87] and [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "Image processing techniques for the extraction of line segments include the Hough Transform [87], thinning, vec-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12914079,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "9e6e39892aa2e15fabf0b850645c0edb4211fd91",
            "isKey": true,
            "numCitedBy": 18,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an item searching method which has been applied to various kinds of forms. This approach is based on line detection through the Hough transform. After obtaining the straight lines, Hough directions are used to detect the real segments in the image. Segments can correspond either to continuous line, or to black parts of dashed or dotted lines. So, the segments are grouped together and classified between both adjacent line crossing points. Items are located by searching the minimum cycles of the graph constructed from the line intersection points. The last step consists of verifying the line classes based on the homogeneity hypothesis of item sides."
            },
            "slug": "Form-Item-Extraction-Based-on-Line-Searching-Turolla-Bela\u00efd",
            "title": {
                "fragments": [],
                "text": "Form Item Extraction Based on Line Searching"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper presents an item searching method which has been applied to various kinds of forms based on line detection through the Hough transform, and verifying the line classes based on the homogeneity hypothesis of item sides."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34817063"
                        ],
                        "name": "A. Chhabra",
                        "slug": "A.-Chhabra",
                        "structuredName": {
                            "firstName": "Atul",
                            "lastName": "Chhabra",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chhabra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144964966"
                        ],
                        "name": "D. Dori",
                        "slug": "D.-Dori",
                        "structuredName": {
                            "firstName": "Dov",
                            "lastName": "Dori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dori"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10328124,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02bff69bace0e9e2056c50c195693f4fb8d63875",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "As a complement to quantitative evaluation methods for raster\u2013to\u2013graphics conversion, we discuss in this paper some qualitative elements which should be taken into account when choosing the different steps of one\u2019s vectorization method. We stress the importance of having robust methods and stable implementations, and we base ourselves extensively on our own implementations and tests, concentrating on methods designed to have few, if any, parameters."
            },
            "slug": "Graphics-Recognition-Recent-Advances-Chhabra-Dori",
            "title": {
                "fragments": [],
                "text": "Graphics Recognition Recent Advances"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Some qualitative elements which should be taken into account when choosing the different steps of one\u2019s vectorization method are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13440867,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "f5ecf0fe5a2a06463d2ff560985a623cfeb81d88",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Document images are degraded through bilevel processes such as scanning, printing, and photocopying. The resulting image degradations can be categorized based either on observable degradation features or on degradation model parameters. The degradation features can be related mathematically to model parameters. In this paper we statistically compare pairs of populations of degraded character images created with different model parameters. The changes in the probability that the characters are from different populations when the model parameters vary correlate with the relationship between observable degradation features and the model parameters. The paper also shows which features have the largest impact on the image."
            },
            "slug": "Document-Analysis-Systems-V-Lopresti-Hu",
            "title": {
                "fragments": [],
                "text": "Document Analysis Systems V"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper statistically compares pairs of populations of degraded character images created with different model parameters to show the changes in the probability that the characters are from different populations when the model parameters vary correlate with the relationship between observable degradation features and themodel parameters."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122087553"
                        ],
                        "name": "P. Gray",
                        "slug": "P.-Gray",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Gray",
                            "middleNames": [
                                "M.",
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83552432"
                        ],
                        "name": "Z. Cui",
                        "slug": "Z.-Cui",
                        "structuredName": {
                            "firstName": "Zhan",
                            "lastName": "Cui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Cui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726599"
                        ],
                        "name": "S. Embury",
                        "slug": "S.-Embury",
                        "structuredName": {
                            "firstName": "Suzanne",
                            "lastName": "Embury",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Embury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145745247"
                        ],
                        "name": "W. A. Gray",
                        "slug": "W.-A.-Gray",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gray",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. A. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143671486"
                        ],
                        "name": "K. Hui",
                        "slug": "K.-Hui",
                        "structuredName": {
                            "firstName": "Kit-Ying",
                            "lastName": "Hui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2209754"
                        ],
                        "name": "Hyunmin Yoon",
                        "slug": "Hyunmin-Yoon",
                        "structuredName": {
                            "firstName": "Hyunmin",
                            "lastName": "Yoon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyunmin Yoon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "The database itself can be used to facilitate and validate data extraction from the tables [29]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17255622,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e46f97199442e66fdb3ab4dec73941854c943a9e",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Extended Abstract The members of the KRAFT (Knowledge Reuse And Fusion/Transformation) consortium 3] are working together to design and build a system which will have intelligent mediators that act as knowledge brokers and, more signiicantly, transform knowledge to make it useable by powerful problem-solvers at various sites on the network. The project aims to investigate how Distributed Information System architectures can support the transformation and reuse of a particular class of knowledge, namely constraints 2]. Currently there is great interest in Distributed Information Systems using mediators and fa-cilitators following the DARPA-funded Knowledge Sharing EEort (KSE) 5], which has led to systems such as InfoSleuth 6]. Whereas the KSE has explored very general kinds of common-sense knowledge and natural language applications, we wish to look more speciically at those kinds of knowledge that can be represented declaratively as constraints, and transformed in various ways for use in design, scheduling, knowledge integration, and many other applications. The KRAFT architecture is thus thoroughly based on agents, in order to provide extensibility and adaptability to new sources of data. The agents pass around highly structured data items, representing entity instances, deened according to an extensible data model schema. These entity instances often contain cross-references to other entities, much as in hypertext, but which are regulated by a formally typed structure given by a data model. Thus much of the behaviour of the agents is driven by the structure and content of the entities being passed. A big diierence from other agent-based systems is that the agents can also pass constraints as data, where constraints are a very general declarative form of predicate deenition which can compute using functions. They are eeectively recipes for selecting or calculating things; they can be passed between agents, and may then be fused together or transformed into new recipes. This is the heart of the KRAFT architecture. It opens up lots of possibilities. One obvious area of application is in connguration problems. Traditionally these have been tackled by Rule-based Systems such as the famous XCON system, used for connguring VAX computers. Nowadays we tackle them more as Constraint Satisfaction problems. In the KRAFT architecture the domains of many of the variables will be entities stored in remote databases. Constraints on these entity types may be set by their makers, and stored with them in the database, as in the example given below. The constraints can then be found by \u2026"
            },
            "slug": "An-Agent-Based-System-for-Handling-Distributed-Gray-Cui",
            "title": {
                "fragments": [],
                "text": "An Agent-Based System for Handling Distributed Design Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "The members of the KRAFT (Knowledge Reuse And Fusion/Transformation) consortium are working together to design and build a system which will have intelligent mediators that act as knowledge brokers and transform knowledge to make it useable by powerful problem-solvers at various sites on the network."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679622"
                        ],
                        "name": "L. Lamport",
                        "slug": "L.-Lamport",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Lamport",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lamport"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "Page composition languages have elaborate facilities for formatting tables, like TROFF Tbl [61] and the LATEX table and array environments [59]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60891396,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04a0e41a4a10e68895b2fd1255779f497cc1817c",
            "isKey": false,
            "numCitedBy": 903,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This user's guide and reference for the LaTeX computer typesetting system has been revised to document features available in release LaTeX2e."
            },
            "slug": "Latex-:-A-Document-Preparation-System-Lamport",
            "title": {
                "fragments": [],
                "text": "Latex : A Document Preparation System"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This user's guide and reference for the LaTeX computer typesetting system has been revised to document features available in release LaTeX2e."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "Table-processing paradigms are part of the older field of document image analysis [67]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 620082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce3b569e18670f6c10e61aa9a8bda7c30fd37411",
            "isKey": false,
            "numCitedBy": 554,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "The contributions to document image analysis of 99 papers published in the IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) are clustered, summarized, interpolated, interpreted, and evaluated."
            },
            "slug": "Twenty-Years-of-Document-Image-Analysis-in-PAMI-Nagy",
            "title": {
                "fragments": [],
                "text": "Twenty Years of Document Image Analysis in PAMI"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The contributions to document image analysis of 99 papers published in the IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) are clustered, summarized, interpolated, interpreted, and evaluated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806905"
                        ],
                        "name": "A. Maedche",
                        "slug": "A.-Maedche",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Maedche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Maedche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752093"
                        ],
                        "name": "Steffen Staab",
                        "slug": "Steffen-Staab",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Staab",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Staab"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": ", [65]) has recently received considerable attention because of the emergence of the Semantic Web."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1411149,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "48e752c719d33ff55b3b3bec3538727f8ce69399",
            "isKey": false,
            "numCitedBy": 2204,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "The Semantic Web relies heavily on formal ontologies to structure data for comprehensive and transportable machine understanding. Thus, the proliferation of ontologies factors largely in the Semantic Web's success. The authors present an ontology learning framework that extends typical ontology engineering environments by using semiautomatic ontology construction tools. The framework encompasses ontology import, extraction, pruning, refinement and evaluation."
            },
            "slug": "Ontology-Learning-for-the-Semantic-Web-Maedche-Staab",
            "title": {
                "fragments": [],
                "text": "Ontology Learning for the Semantic Web"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The authors present an ontology learning framework that extends typical ontology engineering environments by using semiautomatic ontology construction tools and encompasses ontology import, extraction, pruning, refinement and evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Intell. Syst."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145249669"
                        ],
                        "name": "D. Maier",
                        "slug": "D.-Maier",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Maier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 58
                            }
                        ],
                        "text": "Using a standard, formal definition of a relational table [66, 84] shows how to define a canonical table as follows."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "Another way we can formally extend the definition is by defining collections of tables, in which case we have the equivalent of a relational database [66]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215753726,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "dca5a035bf1d99e5e01adc77d6ed9f2338f254f5",
            "isKey": false,
            "numCitedBy": 1791,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "1. The method of operating a water-cooled neutronic reactor having a graphite moderator which comprises flowing a gaseous mixture of carbon dioxide and helium, in which the helium comprises 40-60 volume percent of the mixture, in contact with the graphite moderator."
            },
            "slug": "The-Theory-of-Relational-Databases-Maier",
            "title": {
                "fragments": [],
                "text": "The Theory of Relational Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The method of operating a water-cooled neutronic reactor having a graphite moderator which comprises flowing a gaseous mixture of carbon dioxide and helium, in which the helium comprises 40-60 volume percent of the mixture, in contact with thegraphite moderator."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 341,
                                "start": 337
                            }
                        ],
                        "text": "Keywords Document analysis \u00b7 Table recognition \u00b7 Table understanding\nD. W. Embley Computer Science Department, Brigham Young University, Provo, UT 84602, USA\nM. Hurst Intelliseek Applied Research Center, Pittsburgh, PA 15213, USA\nD. Lopresti (B) Department of Computer Science and Engineering, Lehigh University, Bethlehem, PA 18015, USA\nG. Nagy Department of Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic Institute, Troy, NY 12180, USA\n1 Introduction\n1.1 Why tables?"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 67
                            }
                        ],
                        "text": "For these, we refer the reader to the previously mentioned surveys [62, 63, 97]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "The review by Lopresti and Nagy [62] aims at exploring the diversity and extent of the table world, and the many areas where further progress is needed to make the transition between traditional tables and digital presentation of structured information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 116
                            }
                        ],
                        "text": "Reflecting this growing interest, a number of surveys on table processing have appeared over the past several years [37, 47, 62, 63, 97]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automated table processing: An (opinionated) survey"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Third IAPR International Workshop on Graphics Recognition, pp. 109\u2013134. Jaipur, India"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820595"
                        ],
                        "name": "L. Vincent",
                        "slug": "L.-Vincent",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Vincent",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694191"
                        ],
                        "name": "J. Hull",
                        "slug": "J.-Hull",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hull",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hull"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62663271,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b521e88ae4dd67a01552aec8c761b73b999fa361",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Document-Recognition-IV-Vincent-Hull",
            "title": {
                "fragments": [],
                "text": "Document Recognition IV"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82939764"
                        ],
                        "name": "\u6c60\u5185 \u5065\u4e8c",
                        "slug": "\u6c60\u5185-\u5065\u4e8c",
                        "structuredName": {
                            "firstName": "\u6c60\u5185",
                            "lastName": "\u5065\u4e8c",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u6c60\u5185 \u5065\u4e8c"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 209032598,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a7f94f79e30bb8f647d54c8a94d9fe8e9548a57",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Document-preparation-system-\u6c60\u5185",
            "title": {
                "fragments": [],
                "text": "Document preparation system"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152106334"
                        ],
                        "name": "J. Guthrie",
                        "slug": "J.-Guthrie",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Guthrie",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Guthrie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[35] consider the nature of categories."
                    },
                    "intents": []
                }
            ],
            "corpusId": 144105454,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6d0661a8d77118eb49269b737dd49c40761778e6",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Roles-of-Document-Structure,-Cognitive-Strategy,-in-Guthrie",
            "title": {
                "fragments": [],
                "text": "Roles of Document Structure, Cognitive Strategy, and Awareness in Searching for Information."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103067023"
                        ],
                        "name": "William DeBuvitz",
                        "slug": "William-DeBuvitz",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "DeBuvitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William DeBuvitz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122728422,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "b45ac7df194b039c50b98bb1944069b622600e7b",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recording-for-the-blind-and-dyslexic-DeBuvitz",
            "title": {
                "fragments": [],
                "text": "Recording for the blind and dyslexic"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "He converts the resulting \u201ctable skeleton\u201d first into an X\u2013Y tree [68] and to Microsoft Excel spreadsheets using Excel macros [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59683040,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc45263226de157763006aef70b681dbac744dcc",
            "isKey": false,
            "numCitedBy": 316,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "HIERARCHICAL-REPRESENTATION-OF-OPTICALLY-SCANNED-Nagy-Seth",
            "title": {
                "fragments": [],
                "text": "HIERARCHICAL REPRESENTATION OF OPTICALLY SCANNED DOCUMENTS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Although much too complex to depict and describe in this survey, [27] gives an ontology that for-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 53906384,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a151884208ca8ac91d6cb9fa4d99239b210d4a86",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Object-oriented-systems-analysis-Embley",
            "title": {
                "fragments": [],
                "text": "Object-oriented systems analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144547441"
                        ],
                        "name": "H. Alam",
                        "slug": "H.-Alam",
                        "structuredName": {
                            "firstName": "Hassan",
                            "lastName": "Alam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Alam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144980901"
                        ],
                        "name": "F. Rahman",
                        "slug": "F.-Rahman",
                        "structuredName": {
                            "firstName": "Fuad",
                            "lastName": "Rahman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Rahman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713439"
                        ],
                        "name": "Y. Tarnikova",
                        "slug": "Y.-Tarnikova",
                        "structuredName": {
                            "firstName": "Yuliya",
                            "lastName": "Tarnikova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Tarnikova"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "This is exploited in [3] to re-author an HTML list."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7868758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1aee4f908a545142363f026a80340371013fc5b",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "When-is-a-List-is-a-List:-Web-Page-Re-authoring-for-Alam-Rahman",
            "title": {
                "fragments": [],
                "text": "When is a List is a List?: Web Page Re-authoring for Small Display Devices"
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795288"
                        ],
                        "name": "K. Tombre",
                        "slug": "K.-Tombre",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Tombre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tombre"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1994108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "977de35166b6039c14c86b3e906774ba9be75831",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Graphics-Recognition-Methods-and-Applications-Kasturi-Tombre",
            "title": {
                "fragments": [],
                "text": "Graphics Recognition Methods and Applications"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35743958"
                        ],
                        "name": "Peter P. Chen",
                        "slug": "Peter-P.-Chen",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Chen",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter P. Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52801746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d91c688c559de70afb02249666aa14a611d1bea",
            "isKey": false,
            "numCitedBy": 2323,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "A data model, called the entity-relationship model, is proposed. This model incorporates some of the important semantic information about the real world. A special diagrammatic technique is introduced as a tool for database design. An example of database design and description using the model and the diagrammatic technique is given. Some implications for data integrity, information retrieval, and data manipulation are discussed.\nThe entity-relationship model can be used as a basis for unification of different views of data: the network model, the relational model, and the entity set model. Semantic ambiguities in these models are analyzed. Possible ways to derive their views of data from the entity-relationship model are presented."
            },
            "slug": "The-entity-relationship-model\u2014toward-a-unified-view-Chen",
            "title": {
                "fragments": [],
                "text": "The entity-relationship model\u2014toward a unified view of data"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A data model, called the entity-relationship model, is proposed that incorporates some of the important semantic information about the real world and can be used as a basis for unification of different views of data: the network model, the relational model, and the entity set model."
            },
            "venue": {
                "fragments": [],
                "text": "TODS"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Large-volume, mixed table conversion. 3. Individual database creation"
            },
            "venue": {
                "fragments": [],
                "text": "Large-volume, mixed table conversion. 3. Individual database creation"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 120
                            }
                        ],
                        "text": "The majority of the published work on table processing deals with the extraction of structure from scanned paper tables [1, 10, 15, 32, 39, 50, 60, 87, 93, 98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 126
                            }
                        ],
                        "text": "He converts the resulting \u201ctable skeleton\u201d first into an X\u2013Y tree [68] and to Microsoft Excel spreadsheets using Excel macros [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "torization [1] and projection profiles [50]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Table processing and table understanding"
            },
            "venue": {
                "fragments": [],
                "text": "Master\u2019s thesis, Rensselaer Polytechnic Institute, May"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "One targeted application is automatically reformulating tables found in email for user access over the telephone [43]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A system for understanding and reformulating tables"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth IAPR International Workshop on Document Analysis Systems, pp. 361\u2013372. Rio de Janeiro, Brazil"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "TCG Informatik AG\u2014Data capture at its best"
            },
            "venue": {
                "fragments": [],
                "text": "TCG Informatik AG\u2014Data capture at its best"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 129
                            }
                        ],
                        "text": "It is clear that the combination of the current text layer and vector graphics layer analysis provides the necessary foundations [16, 17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Background pattern recognition in multi-page PDF document"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Third International Workshop on Document Layout Interpretations and its Applications (DLIA2003), pp. 41\u201345"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 167
                            }
                        ],
                        "text": "Further suggestions for generalizing the notions of precedence, proximity, prominence, and preference for interpreting content flow in HTML documents are presented in [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "A recent review [2] lists four alternative techniques: hand recoding, trans-coding (automatic replacement of HTML tags by device- and targetspecific tags), re-authoring based on automatic layout analysis, and re-authoring based on natural language processing (NLP)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Web document manipulation for small screen devices: A review"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Workshop on Web Document Analysis (WDA2003)"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Table manipulation"
            },
            "venue": {
                "fragments": [],
                "text": "Table manipulation"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "TCG Informatik AG \u2014 Data capture at its best ( 2005 )"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "Our desire here is only to indicate that it is possible to create such ontological models as suggested in both [36] and [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "To formalize this process, we can adopt the ideas from [36], which proposes the use of an ontology for automated table understanding."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "1 An output ontology for tables [36] the one in Fig."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The development of a prototype knowledge-based tableprocessing system"
            },
            "venue": {
                "fragments": [],
                "text": "Master\u2019s thesis, Brigham Young University, Provo, Utah"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Table modification for display"
            },
            "venue": {
                "fragments": [],
                "text": "Table modification for display"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Using natural language processing for identifying and interpreting tables in plain text Object-oriented Systems Analysis: A Model Driven Apprach"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Symposium on Document Analysis and Information Retrieval (SDAIR'95)"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Results of a study on invoicereading systems in Germany Document Analysis Systems VI"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 130
                            }
                        ],
                        "text": "It is clear that even aside from possible OCR and image processing errors, manual editing would be required for most applications [71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 52
                            }
                        ],
                        "text": "Among references that address electronic tables are [26, 48, 71, 73]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[71], for example, state that \u201ctables have a regular repetitive structure along one axis so that the data type is determined either by the horizontal or vertical indices."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A system for table understanding"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Symposium on Document Image Understanding Technology (SDIUT\u201997), pp. 55\u201362. Annapolis, MD"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Large-volume, homogeneous table conversion"
            },
            "venue": {
                "fragments": [],
                "text": "Large-volume, homogeneous table conversion"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tbl\u2014a program to format tables In: UNIX Programmer's Manual"
            },
            "venue": {
                "fragments": [],
                "text": "2A. Bell Telephone Laboratories"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Wright [95] describes the understanding of the organizational principles in tables, and Guthrie et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A user-oriented approach to the design of tables and flowcharts"
            },
            "venue": {
                "fragments": [],
                "text": "Jonassen, D.H. (ed.) The Technology of Text. Educational Technology Publications"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 32
                            }
                        ],
                        "text": "Toyohide Watanabe and coworkers [64, 92, 91, 90, 93] aim at a complete description of the various types of information necessary to interpret a ruled scanned table."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Structure analysis of table-form document on the basis of the recognition of vertical and horizontal line segments"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the First International Conference on Document Analysis and Recognition, pp. 638\u2013646"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A theoretical foundation and a method for document table structure extraction and decomposition A framework for validating recognized results in understanding table-form documents"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Third International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "Low-level models use line-art [31], white space [78], and character distributions [51] as key features to drive analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A paper-to-HTML table converting system"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Document Analysis Systems (DAS) 98. Nagano, Japan"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The development of a prototype knowledge-based tableprocessing system. Master's thesis"
            },
            "venue": {
                "fragments": [],
                "text": "The development of a prototype knowledge-based tableprocessing system. Master's thesis"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Towards ontology generation from tables. World Wide Web J. (in press) 85. TREC Data\u2014English Test Questions (Topics)"
            },
            "venue": {
                "fragments": [],
                "text": "Towards ontology generation from tables. World Wide Web J. (in press) 85. TREC Data\u2014English Test Questions (Topics)"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "Low-end OCR systems, such as ScanSoft\u2019s OmniPage [79], provide table location and segmentation features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ScanSoft OmniPage, February (2005) http://www.scansoft.com /omnipage"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "Handley\u2019s survey on document recognition [37] has sections on table recognition and forms recognition with accurate and detailed descriptions of many previously published"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 116
                            }
                        ],
                        "text": "Reflecting this growing interest, a number of surveys on table processing have appeared over the past several years [37, 47, 62, 63, 97]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Dougherty, E.R. (ed.) Electronic Imaging Technology, chapter 8. SPIE\u2014The International Society for Optical Engineering"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "The foundations for a more sophisticated scheme are laid in [46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Layout and language: beyond simple text for information interaction\u2014modelling the table"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Multimodal Interfaces. Hong Kong"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tabular browsing. 5. Audio access to tables"
            },
            "venue": {
                "fragments": [],
                "text": "Tabular browsing. 5. Audio access to tables"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 22
                            }
                        ],
                        "text": "In a series of papers [31, 32, 33], Green and Krishnamoorthy apply a compiler design approach to parsing scanned ruled tables."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognition of tables using table grammars"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Symposium on Document Analysis and Information Retrieval (SDAIR\u201995), pp. 261\u2013277. Las Vegas, NV"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 61,
            "methodology": 25,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 110,
        "totalPages": 11
    },
    "page_url": "https://www.semanticscholar.org/paper/Table-processing-paradigms:-a-research-survey-Embley-Hurst/e8eb9090db385fd6fa77f02736f48d7c98a8d6a5?sort=total-citations"
}