{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060655186"
                        ],
                        "name": "Sebastian",
                        "slug": "Sebastian",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Sebastian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2099456341"
                        ],
                        "name": "SeungBell",
                        "slug": "SeungBell",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "SeungBell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "SeungBell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097547514"
                        ],
                        "name": "LaboratoriesLucent",
                        "slug": "LaboratoriesLucent",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "LaboratoriesLucent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "LaboratoriesLucent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097742561"
                        ],
                        "name": "TechnologiesMurray",
                        "slug": "TechnologiesMurray",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "TechnologiesMurray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "TechnologiesMurray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2062113182"
                        ],
                        "name": "Hill",
                        "slug": "Hill",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15492129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34321fbc7dc49774366bc3e1cdf864b665519470",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The representation of hidden variable models by attractor neural net works is studied Memories are stored in a dynamical attractor that is a continuous manifold of xed points as illustrated by linear and nonlinear networks with hidden neurons Pattern analysis and synthesis are forms of pattern completion by recall of a stored memory Analysis and synthesis in the linear network are performed by bottom up and top down connec tions In the nonlinear network the analysis computation additionally requires recti cation nonlinearity and inner product inhibition between hidden neurons One popular approach to sensory processing is based on generative models which assume that sensory input patterns are synthesized from some underlying hidden variables For example the sounds of speech can be synthesized from a sequence of phonemes and images of a face can be synthesized from pose and lighting variables Hidden variables are useful because they constitute a simpler representation of the variables that are visible in the sensory input Using a generative model for sensory processing requires a method of pattern analysis Given a sensory input pattern analysis is the recovery of the hidden variables from which it was synthesized In other words analysis and synthesis are inverses of each other There are a number of approaches to pattern analy sis In analysis by synthesis the synthetic model is embedded inside a negative feedback loop Another approach is to construct a separate analysis model This paper explores a third approach in which visible hidden pairs are em bedded as attractive xed points or attractors in the state space of a recurrent neural network The attractors can be regarded as memories stored in the net work and analysis and synthesis as forms of pattern completion by recall of a memory The approach is illustrated with linear and nonlinear network ar chitectures In both networks the synthetic model is linear as in principal"
            },
            "slug": "Pattern-Analysis-and-Synthesis-in-AttractorNeural-Sebastian-SeungBell",
            "title": {
                "fragments": [],
                "text": "Pattern Analysis and Synthesis in AttractorNeural NetworksH"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper explores a third approach in which visible hidden pairs are bedded as attractive xed points or attractors in the state space of a recurrent neural network and can be regarded as memories stored in the net work and analysis and synthesis as forms of pattern completion by recall of a memory."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39671808"
                        ],
                        "name": "Fu-Sheng Tsung",
                        "slug": "Fu-Sheng-Tsung",
                        "structuredName": {
                            "firstName": "Fu-Sheng",
                            "lastName": "Tsung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fu-Sheng Tsung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48524582"
                        ],
                        "name": "G. Cottrell",
                        "slug": "G.-Cottrell",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Cottrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cottrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 661135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bec62424fdb3633f3478216638671a2c78f6d833",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Existing recurrent net learning algorithms are inadequate. We introduce the conceptual framework of viewing recurrent training as matching vector fields of dynamical systems in phase space. Phase-space reconstruction techniques make the hidden states explicit, reducing temporal learning to a feed-forward problem. In short, we propose viewing iterated prediction [LF88] as the best way of training recurrent networks on deterministic signals. Using this framework, we can train multiple trajectories, insure their stability, and design arbitrary dynamical systems."
            },
            "slug": "Phase-Space-Learning-Tsung-Cottrell",
            "title": {
                "fragments": [],
                "text": "Phase-Space Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes viewing iterated prediction [LF88] as the best way of training recurrent networks on deterministic signals on phase space, and uses this framework to train multiple trajectories, insure their stability, and design arbitrary dynamical systems."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144902513"
                        ],
                        "name": "P. Baldi",
                        "slug": "P.-Baldi",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Baldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764952"
                        ],
                        "name": "K. Hornik",
                        "slug": "K.-Hornik",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Hornik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hornik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 152
                            }
                        ],
                        "text": "The average distortion is minimized when this matrix becomes a projection operator onto the subspace spanned by the principal components of the examples[9]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14333248,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9552ac39a57daacf3d75865a268935b5a0df9bbb",
            "isKey": false,
            "numCitedBy": 1336,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-networks-and-principal-component-analysis:-Baldi-Hornik",
            "title": {
                "fragments": [],
                "text": "Neural networks and principal component analysis: Learning from examples without local minima"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 136
                            }
                        ],
                        "text": "In a number of recent neurobiological models, continuous attractors have been used to represent continuous quantities like eye position-[3], direction of reaching[4], head direction[5], and orientation of a visual stimulus[6]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "This is illustrated by a simple example, a descent dynamics on a trough-shaped energy landscape[3]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10001273,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c0a382b73c6f18ce31eeeba834d59c81030403cb",
            "isKey": false,
            "numCitedBy": 486,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "The brain can hold the eyes still because it stores a memory of eye position. The brain's memory of horizontal eye position appears to be represented by persistent neural activity in a network known as the neural integrator, which is localized in the brainstem and cerebellum. Existing experimental data are reinterpreted as evidence for an \"attractor hypothesis\" that the persistent patterns of activity observed in this network form an attractive line of fixed points in its state space. Line attractor dynamics can be produced in linear or nonlinear neural networks by learning mechanisms that precisely tune positive feedback."
            },
            "slug": "How-the-brain-keeps-the-eyes-still.-Seung",
            "title": {
                "fragments": [],
                "text": "How the brain keeps the eyes still."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Existing experimental data are reinterpreted as evidence for an \"attractor hypothesis\" that the persistent patterns of activity observed in this network form an attractive line of fixed points in its state space."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "93006261"
                        ],
                        "name": "D. I. Feinstein",
                        "slug": "D.-I.-Feinstein",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Feinstein",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. I. Feinstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50760571"
                        ],
                        "name": "R. Palmer",
                        "slug": "R.-Palmer",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Palmer",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Palmer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "Contrastive Hebbian learning[14] is a simpler alternative."
                    },
                    "intents": []
                }
            ],
            "corpusId": 4269710,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology",
                "Psychology"
            ],
            "id": "786b660e60069ecf01673ade33e287d6adb022b7",
            "isKey": false,
            "numCitedBy": 399,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Crick and Mitchison1 have presented a hypothesis for the functional role of dream sleep involving an \u2018unlearning\u2019 process. We have independently carried out mathematical and computer modelling of learning and \u2018unlearning\u2019 in a collective neural network of 30\u20131,000 neurones. The model network has a content-addressable memory or \u2018associative memory\u2019 which allows it to learn and store many memories. A particular memory can be evoked in its entirety when the network is stimulated by any adequate-sized subpart of the information of that memory2. But different memories of the same size are not equally easy to recall. Also, when memories are learned, spurious memories are also created and can also be evoked. Applying an \u2018unlearning\u2019 process, similar to the learning processes but with a reversed sign and starting from a noise input, enhances the performance of the network in accessing real memories and in minimizing spurious ones. Although our model was not motivated by higher nervous function, our system displays behaviours which are strikingly parallel to those needed for the hypothesized role of \u2018unlearning\u2019 in rapid eye movement (REM) sleep."
            },
            "slug": "\u2018Unlearning\u2019-has-a-stabilizing-effect-in-collective-Hopfield-Feinstein",
            "title": {
                "fragments": [],
                "text": "\u2018Unlearning\u2019 has a stabilizing effect in collective memories"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Although the model was not motivated by higher nervous function, the system displays behaviours which are strikingly parallel to those needed for the hypothesized role of \u2018unlearning\u2019 in rapid eye movement (REM) sleep."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308302"
                        ],
                        "name": "D. Ackley",
                        "slug": "D.-Ackley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ackley",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ackley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 153
                            }
                        ],
                        "text": "Density estimation, rather than regression, is the dominant formulation of unsupervised learning in stochastic neural networks like the Boltzmann machine[2] ."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12174018,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0d16f0e99f7ce5e6fb70b1a68c685e9ad610657",
            "isKey": false,
            "numCitedBy": 3396,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Learning-Algorithm-for-Boltzmann-Machines-Ackley-Hinton",
            "title": {
                "fragments": [],
                "text": "A Learning Algorithm for Boltzmann Machines"
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107184820"
                        ],
                        "name": "K. Zhang",
                        "slug": "K.-Zhang",
                        "structuredName": {
                            "firstName": "K",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 181
                            }
                        ],
                        "text": "In a number of recent neurobiological models, continuous attractors have been used to represent continuous quantities like eye position-[3], direction of reaching[4], head direction[5], and orientation of a visual stimulus[6]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15267169,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b21789504655b03de6b0bce2bba08f1b60896372",
            "isKey": false,
            "numCitedBy": 847,
            "numCiting": 171,
            "paperAbstract": {
                "fragments": [],
                "text": "The head-direction (HD) cells found in the limbic system in freely mov ing rats represent the instantaneous head direction of the animal in the horizontal plane regardless of the location of the animal. The internal direction represented by these cells uses both self-motion information for inertially based updating and familiar visual landmarks for calibration. Here, a model of the dynamics of the HD cell ensemble is presented. The stability of a localized static activity profile in the network and a dynamic shift mechanism are explained naturally by synaptic weight distribution components with even and odd symmetry, respectively. Under symmetric weights or symmetric reciprocal connections, a stable activity profile close to the known directional tuning curves will emerge. By adding a slight asymmetry to the weights, the activity profile will shift continuously without disturbances to its shape, and the shift speed can be controlled accurately by the strength of the odd-weight component. The generic formulation of the shift mechanism is determined uniquely within the current theoretical framework. The attractor dynamics of the system ensures modality- independence of the internal representation and facilitates the correction for cumulative error by the putative local-view detectors. The model offers a specific one-dimensional example of a computational mechanism in which a truly world-centered representation can be derived from observer-centered sensory inputs by integrating self-motion information."
            },
            "slug": "Representation-of-spatial-orientation-by-the-of-the-Zhang",
            "title": {
                "fragments": [],
                "text": "Representation of spatial orientation by the intrinsic dynamics of the head-direction cell ensemble: a theory"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The model offers a specific one-dimensional example of a computational mechanism in which a truly world-centered representation can be derived from observer-centered sensory inputs by integrating self-motion information."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of neuroscience : the official journal of the Society for Neuroscience"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101942206"
                        ],
                        "name": "R. Ben-Yishai",
                        "slug": "R.-Ben-Yishai",
                        "structuredName": {
                            "firstName": "Rani",
                            "lastName": "Ben-Yishai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ben-Yishai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1421306527"
                        ],
                        "name": "R. Bar-Or",
                        "slug": "R.-Bar-Or",
                        "structuredName": {
                            "firstName": "Ruth",
                            "lastName": "Bar-Or",
                            "middleNames": [
                                "Lev"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bar-Or"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720547"
                        ],
                        "name": "H. Sompolinsky",
                        "slug": "H.-Sompolinsky",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Sompolinsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sompolinsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 222
                            }
                        ],
                        "text": "In a number of recent neurobiological models, continuous attractors have been used to represent continuous quantities like eye position-[3], direction of reaching[4], head direction[5], and orientation of a visual stimulus[6]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1338584,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "21e911c2a1b919ed359774fd8f727334d6d83fe6",
            "isKey": false,
            "numCitedBy": 1038,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The role of intrinsic cortical connections in processing sensory input and in generating behavioral output is poorly understood. We have examined this issue in the context of the tuning of neuronal responses in cortex to the orientation of a visual stimulus. We analytically study a simple network model that incorporates both orientation-selective input from the lateral geniculate nucleus and orientation-specific cortical interactions. Depending on the model parameters, the network exhibits orientation selectivity that originates from within the cortex, by a symmetry-breaking mechanism. In this case, the width of the orientation tuning can be sharp even if the lateral geniculate nucleus inputs are only weakly anisotropic. By using our model, several experimental consequences of this cortical mechanism of orientation tuning are derived. The tuning width is relatively independent of the contrast and angular anisotropy of the visual stimulus. The transient population response to changing of the stimulus orientation exhibits a slow \"virtual rotation.\" Neuronal cross-correlations exhibit long time tails, the sign of which depends on the preferred orientations of the cells and the stimulus orientation."
            },
            "slug": "Theory-of-orientation-tuning-in-visual-cortex.-Ben-Yishai-Bar-Or",
            "title": {
                "fragments": [],
                "text": "Theory of orientation tuning in visual cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A simple network model is analytically studied that incorporates both orientation-selective input from the lateral geniculate nucleus and orientation-specific cortical interactions, and exhibits orientation selectivity that originates from within the cortex, by a symmetry-breaking mechanism."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34282229"
                        ],
                        "name": "A. Georgopoulos",
                        "slug": "A.-Georgopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Georgopoulos",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Georgopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38356151"
                        ],
                        "name": "M. Taira",
                        "slug": "M.-Taira",
                        "structuredName": {
                            "firstName": "Masato",
                            "lastName": "Taira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Taira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12876485"
                        ],
                        "name": "A. Lukashin",
                        "slug": "A.-Lukashin",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Lukashin",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lukashin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15828685,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "6ce353b319f51b00493db27536233c9472485fad",
            "isKey": false,
            "numCitedBy": 361,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "A major challenge of current neuroscience is to elucidate the brain mechanisms that underlie cognitive function. There is no doubt that cognitive processing in the brain engages large populations of cells. This article explores the logic of investigating these problems by combining psychological studies in human subjects and neurophysiological studies of neuronal populations in the motor cortex of behaving monkeys. The results obtained show that time-varying psychological processes can be visualized in the time-varying activity of neuronal populations. Moreover, the functional interactions between cells in the motor cortex are very similar to those observed in a massively interconnected artificial network performing the same computation."
            },
            "slug": "Cognitive-neurophysiology-of-the-motor-cortex.-Georgopoulos-Taira",
            "title": {
                "fragments": [],
                "text": "Cognitive neurophysiology of the motor cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The logic of investigating the brain mechanisms that underlie cognitive function by combining psychological studies in human subjects and neurophysiological studies of neuronal populations in the motor cortex of behaving monkeys shows that time-varying psychological processes can be visualized in the time-Varying activity of neurons."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48524582"
                        ],
                        "name": "G. Cottrell",
                        "slug": "G.-Cottrell",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Cottrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cottrell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 262
                            }
                        ],
                        "text": "For the case of a single time step (T = 1), training the recurrent network of Figure 2a to retain patterns is equivalent to training the autoencoder of Figure 2b by minimizing the squared difference between its input and output layers, averaged over the examples[8]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 58450507,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee4214baad6d96b2ee23f56959886f30a257eb04",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-compression-by-back-propagation:-An-example-Cottrell",
            "title": {
                "fragments": [],
                "text": "Image compression by back-propagation: An example of extensional programming"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152547641"
                        ],
                        "name": "Corinna Cortes",
                        "slug": "Corinna-Cortes",
                        "structuredName": {
                            "firstName": "Corinna",
                            "lastName": "Cortes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Corinna Cortes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050470845"
                        ],
                        "name": "H. Drucker",
                        "slug": "H.-Drucker",
                        "structuredName": {
                            "firstName": "Harris",
                            "lastName": "Drucker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Drucker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145636949"
                        ],
                        "name": "Urs Muller",
                        "slug": "Urs-Muller",
                        "structuredName": {
                            "firstName": "Urs",
                            "lastName": "Muller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Urs Muller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97914531"
                        ],
                        "name": "E. Sackinger",
                        "slug": "E.-Sackinger",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Sackinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sackinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "Experiments were conducted with images of handwritten digits from the USPS database described in [12]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13411815,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "842dd6d0f4b72ce0e8f3ac8e6861637c1f4645ea",
            "isKey": false,
            "numCitedBy": 444,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper compares the performance of several classi er algorithms on a standard database of handwritten digits. We consider not only raw accuracy, but also training time, recognition time, and memory requirements. When available, we report measurements of the fraction of patterns that must be rejected so that the remaining patterns have misclassi cation rates less than a given threshold."
            },
            "slug": "Learning-algorithms-for-classification:-A-on-digit-LeCun-Jackel",
            "title": {
                "fragments": [],
                "text": "Learning algorithms for classification: A comparison on handwritten digit recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper compares the performance of several classi er algorithms on a standard database of handwritten digits by considering not only raw accuracy, but also training time, recognition time, and memory requirements."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48524582"
                        ],
                        "name": "G. Cottrell",
                        "slug": "G.-Cottrell",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Cottrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cottrell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 262
                            }
                        ],
                        "text": "For the case of a single time step (T = 1), training the recurrent network of Figure 2a to retain patterns is equivalent to training the autoencoder of Figure 2b by minimizing the squared difference between its input and output layers, averaged over the examples[8]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 58450507,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee4214baad6d96b2ee23f56959886f30a257eb04",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-compression-by-back-propagation:-An-example-Cottrell",
            "title": {
                "fragments": [],
                "text": "Image compression by back-propagation: An example of extensional programming"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 784288,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98b4d4e24aab57ab4e1124ff8106909050645cfa",
            "isKey": false,
            "numCitedBy": 16694,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices."
            },
            "slug": "Neural-networks-and-physical-systems-with-emergent-Hopfield",
            "title": {
                "fragments": [],
                "text": "Neural networks and physical systems with emergent collective computational abilities."
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A model of a system having a large number of simple equivalent components, based on aspects of neurobiology but readily adapted to integrated circuits, produces a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "This feature map is distinct from others[13) because of its use of top-down and bottom-up connections in a feedback loop."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9348814,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ce38ff6a6801a0a7e0ec1fbd24503d7a2142fbf",
            "isKey": false,
            "numCitedBy": 3780,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-self-organizing-map-Kohonen",
            "title": {
                "fragments": [],
                "text": "The self-organizing map"
            },
            "venue": {
                "fragments": [],
                "text": "Neurocomputing"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 162
                            }
                        ],
                        "text": "In a number of recent neurobiological models, continuous attractors have been used to represent continuous quantities like eye position-[3], direction of reaching[4], head direction[5], and orientation of a visual stimulus[6]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cognitive neurophysiology of the motor"
            },
            "venue": {
                "fragments": [],
                "text": "cortex. Science,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning algorithms for classiication: a comparison on handwritten digit recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Neural networks: the statistical mechanics perspective"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Phase-space learning. Adv"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Info . Proc. Syst.,"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 17,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-Continuous-Attractors-in-Recurrent-Seung/9b20ad513361a26e98289e5a517291c6ff49960d?sort=total-citations"
}