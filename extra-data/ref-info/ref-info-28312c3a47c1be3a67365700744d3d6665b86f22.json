{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2432463"
                        ],
                        "name": "E. Hjelm\u00e5s",
                        "slug": "E.-Hjelm\u00e5s",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Hjelm\u00e5s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hjelm\u00e5s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054024193"
                        ],
                        "name": "B. K. Low",
                        "slug": "B.-K.-Low",
                        "structuredName": {
                            "firstName": "Boon",
                            "lastName": "Low",
                            "middleNames": [
                                "Kee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. K. Low"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 138
                            }
                        ],
                        "text": "Extensive research on the subtasks has been carried out and relevant surveys have appeared on, for example, the subtask of face detection [Hjelmas and Low 2001; Yang et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 139
                            }
                        ],
                        "text": "Extensive research on \nthe subtasks has been carried out and rel\u00adevant surveys have appeared on, for exam\u00adple, the subtask of \nface detection [Hjelmas and Low 2001; Yang et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15724653,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "887567782cb859ecd339693589056903b0071353",
            "isKey": false,
            "numCitedBy": 1649,
            "numCiting": 336,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a comprehensive and critical survey of face detection algorithms. Face detection is a necessary first-step in face recognition systems, with the purpose of localizing and extracting the face region from the background. It also has several applications in areas such as content-based image retrieval, video coding, video conferencing, crowd surveillance, and intelligent human?computer interfaces. However, it was not until recently that the face detection problem received considerable attention among researchers. The human face is a dynamic object and has a high degree of variability in its apperance, which makes face detection a difficult problem in computer vision. A wide variety of techniques have been proposed, ranging from simple edge-based algorithms to composite high-level approaches utilizing advanced pattern recognition methods. The algorithms presented in this paper are classified as either feature-based or image-based and are discussed in terms of their technical approach and performance. Due to the lack of standardized tests, we do not provide a comprehensive comparative evaluation, but in cases where results are reported on common datasets, comparisons are presented. We also give a presentation of some proposed applications and possible application areas."
            },
            "slug": "Face-Detection:-A-Survey-Hjelm\u00e5s-Low",
            "title": {
                "fragments": [],
                "text": "Face Detection: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A comprehensive and critical survey of face detection algorithms, ranging from simple edge-based algorithms to composite high-level approaches utilizing advanced pattern recognition methods, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144286385"
                        ],
                        "name": "Charles L. Wilson",
                        "slug": "Charles-L.-Wilson",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Wilson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles L. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503366"
                        ],
                        "name": "S. Sirohey",
                        "slug": "S.-Sirohey",
                        "structuredName": {
                            "firstName": "Saad",
                            "lastName": "Sirohey",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sirohey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 85
                            }
                        ],
                        "text": "Numerous methods have been proposed for face recognition based on image in\u00adtensities [Chellappa et al. \n1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 24
                            }
                        ],
                        "text": "In 1995, a review paper [Chellappa et al. 1995] gave a thorough survey of FRT at that time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 25
                            }
                        ],
                        "text": "In 1995, a review paper [Chellappa \net al. 1995] gave a thorough survey of FRT at that time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 85
                            }
                        ],
                        "text": "\u2014Numerous methods have been proposed for face recognition based on image intensities [Chellappa et al. 1995]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 62185766,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa1755e87301af36485ca01e3454bf8888dde8d1",
            "isKey": false,
            "numCitedBy": 3007,
            "numCiting": 177,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this paper is to present a critical survey of existing literature on human and machine recognition of faces. Machine recognition of faces has several applications, ranging from static matching of controlled photographs as in mug shots matching and credit card verification to surveillance video images. Such applications have different constraints in terms of complexity of processing requirements and thus present a wide range of different technical challenges. Over the last 20 years researchers in psychophysics, neural sciences and engineering, image processing analysis and computer vision have investigated a number of issues related to face recognition by humans and machines. Ongoing research activities have been given a renewed emphasis over the last five years. Existing techniques and systems have been tested on different sets of images of varying complexities. But very little synergism exists between studies in psychophysics and the engineering literature. Most importantly, there exists no evaluation or benchmarking studies using large databases with the image quality that arises in commercial and law enforcement applications In this paper, we first present different applications of face recognition in commercial and law enforcement sectors. This is followed by a brief overview of the literature on face recognition in the psychophysics community. We then present a detailed overview of move than 20 years of research done in the engineering community. Techniques for segmentation/location of the face, feature extraction and recognition are reviewed. Global transform and feature based methods using statistical, structural and neural classifiers are summarized. >"
            },
            "slug": "Human-and-machine-recognition-of-faces:-a-survey-Chellappa-Wilson",
            "title": {
                "fragments": [],
                "text": "Human and machine recognition of faces: a survey"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A critical survey of existing literature on human and machine recognition of faces is presented, followed by a brief overview of the literature on face recognition in the psychophysics community and a detailed overview of move than 20 years of research done in the engineering community."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 115
                            }
                        ],
                        "text": "1997], need accurate locations of key facial features such as eyes, nose, and mouth to normalize the detected face [Martinez 2002; Yang et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 122
                            }
                        ],
                        "text": "After candidate face regions are located, still-image-based face detection \ntechniques can be applied to locate the faces [Yang et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 152
                            }
                        ],
                        "text": "This is true even for holistic matching methods, since accurate location of key facial features such as eyes is required to normalize the detected face [Yang et al. 2002; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 138
                            }
                        ],
                        "text": "Extensive research on the subtasks has been carried out and relevant surveys have appeared on, for example, the subtask of face detection [Hjelmas and Low 2001; Yang et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 121
                            }
                        ],
                        "text": "After candidate face regions are located, still-image-based face detection techniques can be applied to locate the faces [Yang et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 153
                            }
                        ],
                        "text": "This is true even for holistic matching methods, since accurate location of key facial fea\u00adtures \nsuch as eyes is required to normal\u00adize the detected face [Yang et al. 2002; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 284,
                                "start": 268
                            }
                        ],
                        "text": "It is well known that even holistic matching \nmethods, for example, eigenfaces [Turk and Pentland 1991] and Fisherfaces [Belhumeur et al. 1997], need \naccurate locations of key facial features such as eyes, nose, and mouth to normal\u00adize the detected face \n[Martinez 2002; Yang et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 161
                            }
                        ],
                        "text": "Extensive research on \nthe subtasks has been carried out and rel\u00adevant surveys have appeared on, for exam\u00adple, the subtask of \nface detection [Hjelmas and Low 2001; Yang et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9045232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebb34b75982f628f9ce5995821fff81fd967dc2d",
            "isKey": true,
            "numCitedBy": 3968,
            "numCiting": 251,
            "paperAbstract": {
                "fragments": [],
                "text": "Images containing faces are essential to intelligent vision-based human-computer interaction, and research efforts in face processing include face recognition, face tracking, pose estimation and expression recognition. However, many reported methods assume that the faces in an image or an image sequence have been identified and localized. To build fully automated systems that analyze the information contained in face images, robust and efficient face detection algorithms are required. Given a single image, the goal of face detection is to identify all image regions which contain a face, regardless of its 3D position, orientation and lighting conditions. Such a problem is challenging because faces are non-rigid and have a high degree of variability in size, shape, color and texture. Numerous techniques have been developed to detect faces in a single image, and the purpose of this paper is to categorize and evaluate these algorithms. We also discuss relevant issues such as data collection, evaluation metrics and benchmarking. After analyzing these algorithms and identifying their limitations, we conclude with several promising directions for future research."
            },
            "slug": "Detecting-Faces-in-Images:-A-Survey-Yang-Kriegman",
            "title": {
                "fragments": [],
                "text": "Detecting Faces in Images: A Survey"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 41
                            }
                        ],
                        "text": "Earlier work \non multiview-based meth\u00adods [Beymer 1993] was extended to ex\u00adplore the prior class information that is \nspeci.c to a face class and can be learned from a set of prototypes [Beymer 1993, 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 40
                            }
                        ],
                        "text": "Earlier work on multiview-based methods [Beymer 1993] was extended to explore the prior class information that is specific to a face class and can be learned from a set of prototypes [Beymer 1993, 1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2546027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e5949d95c53dd041c721bf40e67b3966805e385",
            "isKey": false,
            "numCitedBy": 488,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "Researchers in computer vision and pattern recognition have worked on automatic techniques for recognizing human faces for the last 20 years. While some systems, especially template-based ones, have been quite successful on expressionless, frontal views of faces with controlled lighting, not much work has taken face recognizers beyond these narrow imaging conditions. Our goal is to build a face recognizer that works under varying pose, the difficult part of which is to handle face relations in depth. Building on successful template-based systems, our basic approach is to represent faces with templates from multiple model views that cover different poses from the viewing sphere. To recognize a novel view, the recognizer locates the eyes and nose features, uses these locations to geometrically register the input with model views, and then uses correlation on model templates to find the best match in the data base of people. Our system has achieved a recognition rate of 98% on a data base of 62 people containing 10 testing and 15 modeling views per person.<<ETX>>"
            },
            "slug": "Face-recognition-under-varying-pose-Beymer",
            "title": {
                "fragments": [],
                "text": "Face recognition under varying pose"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The goal is to build a face recognizer that works under varying pose, the difficult part of which is to handle face relations in depth."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205216"
                        ],
                        "name": "Y. Adini",
                        "slug": "Y.-Adini",
                        "structuredName": {
                            "firstName": "Yael",
                            "lastName": "Adini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Adini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2957934"
                        ],
                        "name": "Y. Moses",
                        "slug": "Y.-Moses",
                        "structuredName": {
                            "firstName": "Yael",
                            "lastName": "Moses",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Moses"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 76
                            }
                        ],
                        "text": "For more details about these methods and about the evaluation database, see [181]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 36
                            }
                        ],
                        "text": "This was experimentally observed in [181] using a dataset of 25 individuals, and was theoretically proved in [182] for systems based on eigenface projection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 75
                            }
                        ],
                        "text": "These two problems have been documented in many evaluations of FRT systems [4, 181] and in the divided opinions of the psychology community [24, 23, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 33
                            }
                        ],
                        "text": "2 Image Comparison Approaches In [181], approaches based on image comparison using di erent image representations and distance measures were evaluated."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6519687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46a92002675b214e5b24305487e2928d2d669ad5",
            "isKey": true,
            "numCitedBy": 905,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "A face recognition system must recognize a face from a novel image despite the variations between images of the same face. A common approach to overcoming image variations because of changes in the illumination conditions is to use image representations that are relatively insensitive to these variations. Examples of such representations are edge maps, image intensity derivatives, and images convolved with 2D Gabor-like filters. Here we present an empirical study that evaluates the sensitivity of these representations to changes in illumination, as well as viewpoint and facial expression. Our findings indicated that none of the representations considered is sufficient by itself to overcome image variations because of a change in the direction of illumination. Similar results were obtained for changes due to viewpoint and expression. Image representations that emphasized the horizontal features were found to be less sensitive to changes in the direction of illumination. However, systems based only on such representations failed to recognize up to 20 percent of the faces in our database. Humans performed considerably better under the same conditions. We discuss possible reasons for this superiority and alternative methods for overcoming illumination effects in recognition."
            },
            "slug": "Face-Recognition:-The-Problem-of-Compensating-for-Adini-Moses",
            "title": {
                "fragments": [],
                "text": "Face Recognition: The Problem of Compensating for Changes in Illumination Direction"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Evaluating the sensitivity of image representations to changes in illumination, as well as viewpoint and facial expression, indicated that none of the representations considered is sufficient by itself to overcome image variations because of a change in the direction of illumination."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136478"
                        ],
                        "name": "P. Grother",
                        "slug": "P.-Grother",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Grother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Grother"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3107704"
                        ],
                        "name": "R. Micheals",
                        "slug": "R.-Micheals",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Micheals",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Micheals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32889627"
                        ],
                        "name": "D. Blackburn",
                        "slug": "D.-Blackburn",
                        "structuredName": {
                            "firstName": "Duane",
                            "lastName": "Blackburn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blackburn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2326261"
                        ],
                        "name": "Elham Tabassi",
                        "slug": "Elham-Tabassi",
                        "structuredName": {
                            "firstName": "Elham",
                            "lastName": "Tabassi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elham Tabassi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144505249"
                        ],
                        "name": "Mike Bone",
                        "slug": "Mike-Bone",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Bone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mike Bone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 30512497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "491472dcde6783f5607f69b7922fb4dcc21f4bcb",
            "isKey": false,
            "numCitedBy": 409,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Summary form only given. The face recognition vendor test (FRVT) 2002 is an independently administered technology evaluation of mature face recognition systems. FRVT 2002 provides performance measures for assessing the capability of face recognition systems to meet requirements for large-scale, real-world applications. Participation in FRVT 2002 was open to commercial and mature prototype systems from universities, research institutes, and companies. Ten companies submitted either commercial or prototype systems. FRVT 2002 computed performance statistics on an extremely large data set-121,589 operational facial images of 37,437 individuals. FRVT 2002 1) characterized identification and watch list performance as a function of database size, 2) estimated the variability in performance for different groups of people, 3) characterized performance as a function of elapsed time between enrolled and new images of a person, and 4) investigated the effect of demographics on performance. FRVT 2002 showed that recognition from indoor images has made substantial progress since FRVT 2000. Demographic results show that males are easier to recognize than females and that older people are easier to recognize than younger people. FRVT 2002 also assessed the impact of three new techniques for improving face recognition: three-dimensional morphable models, normalization of similarity scores, and face recognition from video sequences. Results show that three-dimensional morphable models and normalization increase performance and that face recognition from video sequences offers only a limited increase in performance over still images. A new XML-based evaluation protocol was developed for FRVT 2002. This protocol is flexible and supports evaluations of biometrics in general The FRVT 2002 reports can be found at http://www.frvt.org."
            },
            "slug": "Face-recognition-vendor-test-2002-Phillips-Grother",
            "title": {
                "fragments": [],
                "text": "Face recognition vendor test 2002"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Results show that recognition from indoor images has made substantial progress since FRVT 2000 and that three-dimensional morphable models and normalization increase performance and that face recognition from video sequences offers only a limited increase in performance over still images."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE International SOI Conference. Proceedings (Cat. No.03CH37443)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144784813"
                        ],
                        "name": "S. Gong",
                        "slug": "S.-Gong",
                        "structuredName": {
                            "firstName": "Shaogang",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6435894"
                        ],
                        "name": "S. McKenna",
                        "slug": "S.-McKenna",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "McKenna",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. McKenna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2639990"
                        ],
                        "name": "A. Psarrou",
                        "slug": "A.-Psarrou",
                        "structuredName": {
                            "firstName": "Alexandra",
                            "lastName": "Psarrou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Psarrou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 80
                            }
                        ],
                        "text": "The voting can be deterministic, \nbut probabilistic voting is better in general [Gong et al. 2000; McKenna and Gong 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 79
                            }
                        ],
                        "text": "The voting can be deterministic, but probabilistic voting is better in general [Gong et al. 2000; McKenna and Gong 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5529088,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e999e9eb2968b320698c6c3f0d01631ff885d96",
            "isKey": false,
            "numCitedBy": 302,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nFace recognition is a task which the human visual system seems to perform almost effortlessly, yet goal of building machines with comparable capabilities has proven difficult to realize. The task requires the ability to locate and track faces through scenes which are often complex and dynamic. Recognition is difficult because of variations in factors such as lighting conditions, viewpoint, body movement and facial expression. Although evidence from psychophysical and neurobiological experiments provides intriguing insights into how we might code and recognize faces, their bearings on computational and engineering solutions are far from clear. \nThis book describes how to build learning machines to perform face recognition in dynamic scenes. The task at hand is that of engineering robust machine vision systems that can operate under poorly controlled and changing conditions. Many of the issues raised are relevant to object recognition in general, and such visual learning machines have numerous potential applications in areas such as visual surveillance multimedia and visually mediated interaction."
            },
            "slug": "Dynamic-Vision-From-Images-to-Face-Recognition-Gong-McKenna",
            "title": {
                "fragments": [],
                "text": "Dynamic Vision - From Images to Face Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Many of the issues raised are relevant to object recognition in general, and such visual learning machines have numerous potential applications in areas such as visual surveillance multimedia and visually mediated interaction."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3230391"
                        ],
                        "name": "A. Georghiades",
                        "slug": "A.-Georghiades",
                        "structuredName": {
                            "firstName": "Athinodoros",
                            "lastName": "Georghiades",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Georghiades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 330,
                                "start": 305
                            }
                        ],
                        "text": "23 To address GBR ambiguity, the authors proposed exploiting face symmetry (to correct tilt) and the fact that the chin and the forehead are at about the same height (to correct slant), and requiring that the range of heights of the surface be about twice the distance between the eyes (to correct scale) [Georghiades et al. 2001]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 262
                            }
                        ],
                        "text": "\u2026pro\u00adposed \nexploiting face symmetry (to correct tilt) and the fact that the chin and the fore\u00adhead are at about \nthe same height (to cor\u00adrect slant), and requiring that the range of heights of the surface be about \ntwice the distance between the eyes (to correct scale) [Georghiades et al. 2001]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9234219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6642e9c6cf7432e2d11b7edf7cd47f1285acd54e",
            "isKey": false,
            "numCitedBy": 4696,
            "numCiting": 163,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a generative appearance-based method for recognizing human faces under variation in lighting and viewpoint. Our method exploits the fact that the set of images of an object in fixed pose, but under all possible illumination conditions, is a convex cone in the space of images. Using a small number of training images of each face taken with different lighting directions, the shape and albedo of the face can be reconstructed. In turn, this reconstruction serves as a generative model that can be used to render (or synthesize) images of the face under novel poses and illumination conditions. The pose space is then sampled and, for each pose, the corresponding illumination cone is approximated by a low-dimensional linear subspace whose basis vectors are estimated using the generative model. Our recognition algorithm assigns to a test image the identity of the closest approximated illumination cone. Test results show that the method performs almost without error, except on the most extreme lighting directions."
            },
            "slug": "From-Few-to-Many:-Illumination-Cone-Models-for-Face-Georghiades-Belhumeur",
            "title": {
                "fragments": [],
                "text": "From Few to Many: Illumination Cone Models for Face Recognition under Variable Lighting and Pose"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A generative appearance-based method for recognizing human faces under variation in lighting and viewpoint that exploits the fact that the set of images of an object in fixed pose but under all possible illumination conditions, is a convex cone in the space of images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": false,
            "numCitedBy": 14955,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716933"
                        ],
                        "name": "I. Cox",
                        "slug": "I.-Cox",
                        "structuredName": {
                            "firstName": "Ingemar",
                            "lastName": "Cox",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864754"
                        ],
                        "name": "J. Ghosn",
                        "slug": "J.-Ghosn",
                        "structuredName": {
                            "firstName": "Joumana",
                            "lastName": "Ghosn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ghosn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3203897"
                        ],
                        "name": "P. Yianilos",
                        "slug": "P.-Yianilos",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Yianilos",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Yianilos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 159
                            }
                        ],
                        "text": "\u20261997] PDBNN Probabilistic decision based NN [Lin et al. 1997] Feature-based \nmethods Pure geometry methods Earlier methods [Kanade 1973; Kelly 1970]; recent methods [Cox et al. 1996; \nManjunath et al. 1992] Dynamic link architecture Graph matching methods [Okada et al. 1998; Wiskott et \nal."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 119
                            }
                        ],
                        "text": "However, the feature extraction techniques needed for this type of ap\u00adproach are still not reliable or \naccurate enough [Cox et al. 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 98
                            }
                        ],
                        "text": "More recently, \na mixture-distance based approach using manually extracted distances was reported [Cox et al. 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15344386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb55f2c02ada7b3e79d54baffccb38a71290b844",
            "isKey": false,
            "numCitedBy": 298,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of feature-based face recognition in the setting where only a single example of each face is available for training. The mixture-distance technique we introduce achieves a recognition rate of 95% on a database of 685 people in which each face is represented by 30 measured distances. This is currently the best recorded recognition rate for a feature-based system applied to a database of this size. By comparison, nearest neighbor search using Euclidean distance yields 84%. In our work a novel distance function is constructed based on local second order statistics as estimated by modeling the training data as a mixture of normal densities. We report on the results from mixtures of several sizes. We demonstrate that a flat mixture of mixtures performs as well as the best model and therefore represents an effective solution to the model selection problem. A mixture perspective is also taken for individual Gaussians to choose between first order (variance) and second order (covariance) models. Here an approximation to flat combination is proposed and seen to perform well in practice. Our results demonstrate that even in the absence of multiple training examples for each class, it is sometimes possible to infer from a statistical model of training data, a significantly improved distance function for use in pattern recognition."
            },
            "slug": "Feature-based-face-recognition-using-Cox-Ghosn",
            "title": {
                "fragments": [],
                "text": "Feature-based face recognition using mixture-distance"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The results demonstrate that even in the absence of multiple training examples for each class, it is sometimes possible to infer from a statistical model of training data, a significantly improved distance function for use in pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32889627"
                        ],
                        "name": "D. Blackburn",
                        "slug": "D.-Blackburn",
                        "structuredName": {
                            "firstName": "Duane",
                            "lastName": "Blackburn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blackburn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144505249"
                        ],
                        "name": "Mike Bone",
                        "slug": "Mike-Bone",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Bone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mike Bone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 126
                            }
                        ],
                        "text": "To assess the state of the art in COTS face recognition systems the Face Recogni\u00adtion Vendor Test (FRVT) \n200018 was orga\u00adnized [Blackburn et al. 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 30
                            }
                        ],
                        "text": "Full details \ncan be found in [Blackburn et al. 2001], and include iden\u00adti.cation and veri.cation performance statistics."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 124
                            }
                        ],
                        "text": "Re\u00adcently, more extensive evaluations using commercial systems and thousands of im\u00adages have been \nperformed in the FRVT 2000 [Blackburn et al. 2001] and FRVT 2002 [Phillips et al. 2003] tests."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 148
                            }
                        ],
                        "text": "\u2026system\u00adatic \nempirical evaluations of face recog\u00adnition techniques (FRT), including the FERET [Phillips et al. 1998b, \n2000; Rizvi et al. 1998], FRVT 2000 [Blackburn et al. 2001], FRVT 2002 [Phillips et al. 2003], and XM2VTS \n[Messer et al. 1999] pro\u00adtocols, and many commercially available\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 57
                            }
                        ],
                        "text": "\u00adculty was documented in the FERET and FRVT test reports [Blackburn et al. 2001; Phillips \net al. 2002b, 2003], and was sug\u00adgested as a major research issue."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62749895,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a0eb886c51196409f6fc62f22cb89adf44bf5b7",
            "isKey": false,
            "numCitedBy": 268,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The biggest change in the facial recognition community since the completion of the FERET program has been the introduction of facial recognition products to the commercial market. Open market competitiveness has driven numerous technological advances in automated face recognition since the FERET program and significantly lowered system costs. Today there are dozens of facial recognition systems available that have the potential to meet performance requirements for numerous applications. But which of these systems best meet the performance requirements for given applications? Repeated inquiries from numerous government agencies on the current state of facial recognition technology prompted the DoD Counterdrug Technology Development Program Office to establish a new set of evaluations. The Facial Recognition Vendor Test 2000 (FRVT 2000) was cosponsored by the DoD Counterdrug Technology Development Program Office, the National Institute of Justice and the Defense Advanced Research Projects Agency and was administered in May and June 2000."
            },
            "slug": "Face-Recognition-Vendor-Test-2000:-Evaluation-Blackburn-Bone",
            "title": {
                "fragments": [],
                "text": "Face Recognition Vendor Test 2000: Evaluation Report"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Facial Recognition Vendor Test 2000 (FRVT 2000) was cosponsored by the DoD Counterdrug Technology Development Program Office, the National Institute of Justice and the Defense Advanced Research Projects Agency and was administered in May and June 2000."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144013393"
                        ],
                        "name": "A. Samal",
                        "slug": "A.-Samal",
                        "structuredName": {
                            "firstName": "Ashok",
                            "lastName": "Samal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Samal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32130323"
                        ],
                        "name": "Prasana A. Iyengar",
                        "slug": "Prasana-A.-Iyengar",
                        "structuredName": {
                            "firstName": "Prasana",
                            "lastName": "Iyengar",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prasana A. Iyengar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 20
                            }
                        ],
                        "text": "(An earlier survey [Samal and Iyengar 1992] \nappeared in 1992.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 19
                            }
                        ],
                        "text": "(An earlier survey [Samal and Iyengar 1992] appeared in 1992."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 205013679,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0be360a2964c4bb91aaad0cc6d1baa6639746028",
            "isKey": false,
            "numCitedBy": 1067,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-recognition-and-analysis-of-human-faces-a-Samal-Iyengar",
            "title": {
                "fragments": [],
                "text": "Automatic recognition and analysis of human faces and facial expressions: a survey"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38480590"
                        ],
                        "name": "Wenyi Zhao",
                        "slug": "Wenyi-Zhao",
                        "structuredName": {
                            "firstName": "Wenyi",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyi Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 94
                            }
                        ],
                        "text": "Finally, the fourth column shows real images that \nare close to the prototype images [Zhao and Chellappa 2000]. local SFS algorithm [Tsai and Shah 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 120
                            }
                        ],
                        "text": "To assess the pose problem more sys\u00adtematically, an attempt has been made to classify pose problems [Zhao \n1999; Zhao and Chellappa 2000b]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11507811,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0404d6da115f190b7eb08f907af7ccd0b42547c",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Sensitivity to variations in illumination is a fundamental and challenging problem in face recognition. In this paper, we describe a new method based on symmetric shape-from-shading (SSFS) to develop a face recognition system that is robust to changes in illumination. The basic idea of this approach is to use the SSFS algorithm as a tool to obtain a prototype image which is illumination-normalized. It has been shown that the SSFS algorithm has a unique point-wise solution. But it is still difficult to recover accurate shape information given a single real face image with complex shape and varying albedo. In stead, we utilize the fact that all faces share a similar shape making the direct computation of the prototype image from a given face image feasible. Finally, to demonstrate the efficacy of our method, we have applied it to several publicly available face databases."
            },
            "slug": "Illumination-insensitive-face-recognition-using-Zhao-Chellappa",
            "title": {
                "fragments": [],
                "text": "Illumination-insensitive face recognition using symmetric shape-from-shading"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A new method based on symmetric shape-from-shading (SSFS) to develop a face recognition system that is robust to changes in illumination and utilizes the fact that all faces share a similar shape making the direct computation of the prototype image from a given face image feasible."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47128406"
                        ],
                        "name": "Shang-Hung Lin",
                        "slug": "Shang-Hung-Lin",
                        "structuredName": {
                            "firstName": "Shang-Hung",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shang-Hung Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144410963"
                        ],
                        "name": "S. Kung",
                        "slug": "S.-Kung",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Kung",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111062938"
                        ],
                        "name": "Long-Ji Lin",
                        "slug": "Long-Ji-Lin",
                        "structuredName": {
                            "firstName": "Long-Ji",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long-Ji Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 24636915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa2603efaf717974c77162c93d800defae61a129",
            "isKey": false,
            "numCitedBy": 669,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a face recognition system, based on probabilistic decision-based neural networks (PDBNN). With technological advance on microelectronic and vision system, high performance automatic techniques on biometric recognition are now becoming economically feasible. Among all the biometric identification methods, face recognition has attracted much attention in recent years because it has potential to be most nonintrusive and user-friendly. The PDBNN face recognition system consists of three modules: First, a face detector finds the location of a human face in an image. Then an eye localizer determines the positions of both eyes in order to generate meaningful feature vectors. The facial region proposed contains eyebrows, eyes, and nose, but excluding mouth (eye-glasses will be allowed). Lastly, the third module is a face recognizer. The PDBNN can be effectively applied to all the three modules. It adopts a hierarchical network structures with nonlinear basis functions and a competitive credit-assignment scheme. The paper demonstrates a successful application of PDBNN to face recognition applications on two public (FERET and ORL) and one in-house (SCR) databases. Regarding the performance, experimental results on three different databases such as recognition accuracies as well as false rejection and false acceptance rates are elaborated. As to the processing speed, the whole recognition process (including PDBNN processing for eye localization, feature extraction, and classification) consumes approximately one second on Sparc10, without using hardware accelerator or co-processor."
            },
            "slug": "Face-recognition/detection-by-probabilistic-neural-Lin-Kung",
            "title": {
                "fragments": [],
                "text": "Face recognition/detection by probabilistic decision-based neural network"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The paper demonstrates a successful application of PDBNN to face recognition applications on two public (FERET and ORL) and one in-house (SCR) databases and experimental results on three different databases such as recognition accuracies as well as false rejection and false acceptance rates are elaborated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2218905"
                        ],
                        "name": "M. Bartlett",
                        "slug": "M.-Bartlett",
                        "structuredName": {
                            "firstName": "Marian",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "Stewart"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bartlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35146156"
                        ],
                        "name": "M. Lades",
                        "slug": "M.-Lades",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Lades",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 157
                            }
                        ],
                        "text": "Based on the argument that for tasks such as face recognition much of the important \ninformation is contained in high-order statistics, it has been pro\u00adposed [Bartlett et al. 1998] to use \nICA to extract features for face recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 170
                            }
                        ],
                        "text": "Comparison of basis images using \ntwo architectures for performing ICA: (a) 25 indepen\u00addent components of Architecture I, (b) 25 independent \ncomponents of Architecture II [Bartlett et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 271
                            }
                        ],
                        "text": "\u2026Atick 1996] Shape-normalized Flexible appearance models [Lanitis et al. 1995] Component-based Face \nregion and components [Huang et al. 2003] analysis (ICA) is argued to have more representative power \nthan PCA, and hence may provide better recognition per\u00adformance than PCA [Bartlett et al. 1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 248
                            }
                        ],
                        "text": "\u2026(their supports extend over the entire grid of images), LFA kernels (Figure12) \nK (xi, y) at selected grids xi have local support.10 10These kernels (Figure 12) indexed by grids xi \nare similar to the ICA kernels in the .rst ICA system architecture [Bartlett et al. 1998; Bell and Sejnowski \n1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 143
                            }
                        ],
                        "text": "\u2026\npursuit Enhanced GA learning [Liu and Wechsler 2000a] Feature lines Point-to-line distance based [Li \nand Lu 1999] ICA ICA-based feature analysis [Bartlett et al. 1998] Other representations LDA/FLD LDA/FLD \non raw image [Etemad and Chellappa 1997] PDBNN Probabilistic decision based NN\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 108
                            }
                        ],
                        "text": "Performing source separation on the \npixels produces a factorial code in the columns of the output matrix U [Bartlett et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16204207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76050b8fc3992a5d04b229fb3bfc2bda0511b7c3",
            "isKey": true,
            "numCitedBy": 413,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In a task such as face recognition, much of the important information may be contained in the high-order relationships among the image pixels. A number of face recognition algorithms employ principal component analysis (PCA), which is based on the second-order statistics of the image set, and does not address high-order statistical dependencies such as the relationships among three or more pixels. Independent component analysis (ICA) is a generalization of PCA which separates the high-order moments of the input in addition to the second-order moments. ICA was performed on a set of face images by an unsupervised learning algorithm derived from the principle of optimal information transfer through sigmoidal neurons. The algorithm maximizes the mutual information between the input and the output, which produces statistically independent outputs under certain conditions. ICA was performed on the face images under two different architectures. The first architecture provided a statistically independent basis set for the face images that can be viewed as a set of independent facial features. The second architecture provided a factorial code, in which the probability of any combination of features can be obtained from the product of their individual probabilities. Both ICA representations were superior to representations based on principal components analysis for recognizing faces across sessions and changes in expression."
            },
            "slug": "Independent-component-representations-for-face-Bartlett-Lades",
            "title": {
                "fragments": [],
                "text": "Independent component representations for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "ICA was performed on a set of face images by an unsupervised learning algorithm derived from the principle of optimal information transfer through sigmoidal neurons, which maximizes the mutual information between the input and the output, which produces statistically independent outputs under certain conditions."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145403429"
                        ],
                        "name": "A. J. Howell",
                        "slug": "A.-J.-Howell",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Howell",
                            "middleNames": [
                                "Jonathan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Howell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764331"
                        ],
                        "name": "H. Buxton",
                        "slug": "H.-Buxton",
                        "structuredName": {
                            "firstName": "Hilary",
                            "lastName": "Buxton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Buxton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16865366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b5918a34c96ed0f608037391492c85fdc822508",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents experiments using a radial basis function (RBF) network to tackle the unconstrained face recognition problem using low resolution video information. Input representations that mimic the effects of receptive field functions found at various stages of the human vision system were used with RBF network; that learnt to classify and generalise over different views of each person to be recognised. In particular, Difference of Gaussian (DoG) filtering and Gabor wavelet analysis are compared for face recognition from an image sequence. RBF techniques are shown to provide excellent levels of performance where the view varies and the authors discuss how to relax constraints on data capture and improve preprocessing to obtain an effective scheme for real-time, unconstrained face recognition."
            },
            "slug": "Towards-unconstrained-face-recognition-from-image-Howell-Buxton",
            "title": {
                "fragments": [],
                "text": "Towards unconstrained face recognition from image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Experiments using a radial basis function (RBF) network to tackle the unconstrained face recognition problem using low resolution video information are presented and the authors discuss how to relax constraints on data capture and improve preprocessing to obtain an effective scheme for real-time, unconstraining face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38480590"
                        ],
                        "name": "Wenyi Zhao",
                        "slug": "Wenyi-Zhao",
                        "structuredName": {
                            "firstName": "Wenyi",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyi Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 85
                            }
                        ],
                        "text": "Finally, the fourth column shows real images that \nare close to the prototype images [Zhao and Chellappa 2000]. local SFS algorithm [Tsai and Shah 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [201], a uni ed approach was proposed to solving the pose and illumination problems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 111
                            }
                        ],
                        "text": "To assess the pose problem more sys\u00adtematically, an attempt has been made to classify pose problems [Zhao \n1999; Zhao and Chellappa 2000b]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7316199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ae6c0c09bdb6b76034b6c529f9d8baf2a173188",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Sensitivity to variations in pose is a challenging problem in face recognition using appearance-based methods. More specifically, the appearance of a face changes dramatically when viewing and/or lighting directions change. Various approaches have been proposed to solve this difficult problem. They can be broadly divided into three classes: (1) multiple image-based methods where multiple images of various poses per person are available; (2) hybrid methods where multiple example images are available during learning but only one database image per person is available during recognition; and (3) single image-based methods where no example-based learning is carried out. We present a method that comes under class 3. This method, based on shape-from-shading (SFS), improves the performance of a face recognition system in handling variations due to pose and illumination via image synthesis."
            },
            "slug": "SFS-based-view-synthesis-for-robust-face-Zhao-Chellappa",
            "title": {
                "fragments": [],
                "text": "SFS based view synthesis for robust face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This method, based on shape-from-shading (SFS), improves the performance of a face recognition system in handling variations due to pose and illumination via image synthesis."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110065403"
                        ],
                        "name": "Jennifer Huang",
                        "slug": "Jennifer-Huang",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jennifer Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684626"
                        ],
                        "name": "B. Heisele",
                        "slug": "B.-Heisele",
                        "structuredName": {
                            "firstName": "Bernd",
                            "lastName": "Heisele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Heisele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2880906"
                        ],
                        "name": "V. Blanz",
                        "slug": "V.-Blanz",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Blanz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Blanz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1553425,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d45ab87e0f93006a53769e52fcd508c91d69083",
            "isKey": false,
            "numCitedBy": 423,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for pose and illumination invariant face recognition that combines two recent advances in the computer vision field: 3D morphable models and component-based recognition. A 3D morphable model is used to compute 3D face models from three input images of each subject in the training database. The 3D models are rendered under varying pose and illumination conditions to build a large set of synthetic images. These images are then used for training a component-based face recognition system. The face recognition module is preceded by a fast hierarchical face detector resulting in a system that can detect and identify faces in video images at about 4 Hz. The system achieved a recognition rate of 88% on a database of 2000 real images of ten people, which is significantly better than a comparable global face recognition system. The results clearly show the potential of the combination of morphable models and component-based recognition towards pose and illumination invariant face recognition."
            },
            "slug": "Component-Based-Face-Recognition-with-3D-Morphable-Huang-Heisele",
            "title": {
                "fragments": [],
                "text": "Component-Based Face Recognition with 3D Morphable Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A 3D morphable model is used to compute 3D face models from three input images of each subject in the training database and the system achieved a recognition rate significantly better than a comparable global face recognition system."
            },
            "venue": {
                "fragments": [],
                "text": "2004 Conference on Computer Vision and Pattern Recognition Workshop"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38480590"
                        ],
                        "name": "Wenyi Zhao",
                        "slug": "Wenyi-Zhao",
                        "structuredName": {
                            "firstName": "Wenyi",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyi Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 85
                            }
                        ],
                        "text": "Finally, the fourth column shows real images that \nare close to the prototype images [Zhao and Chellappa 2000]. local SFS algorithm [Tsai and Shah 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 111
                            }
                        ],
                        "text": "To assess the pose problem more sys\u00adtematically, an attempt has been made to classify pose problems [Zhao \n1999; Zhao and Chellappa 2000b]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16404234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "345872e8ce4aff4598b08808684a8d836baf4bd5",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In face recognition literature, 2D image based approaches are possibly the most promising ones. However, the 2D images/patterns can change dramatically in practice. We first study the performance degradation due to 2D distortions and illumination variations on the input images. We then propose several methods to improve the system performance. Finally experiments are carried out using FERET and other face databases to demonstrate the improvement of one particular system-the subspace LDA system."
            },
            "slug": "Robust-image-based-face-recognition-Zhao-Chellappa",
            "title": {
                "fragments": [],
                "text": "Robust image based face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work first studies the performance degradation due to 2D distortions and illumination variations on the input images, and proposes several methods to improve the system performance."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2000 International Conference on Image Processing (Cat. No.00CH37101)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3062639"
                        ],
                        "name": "L. Gu",
                        "slug": "L.-Gu",
                        "structuredName": {
                            "firstName": "Lie",
                            "lastName": "Gu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34679741"
                        ],
                        "name": "S. Li",
                        "slug": "S.-Li",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 203
                            }
                        ],
                        "text": "\u2026\ntechniques could only han\u00addle single or a few well-separated frontal faces in images with simple backgrounds, \nwhile state-of-the-art algorithms can de\u00adtect faces and their poses in cluttered backgrounds [Gu et al. \n2001; Heisele et al. 2001; Schneiderman and Kanade 2000; Vi\u00adola and Jones 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 59
                            }
                        ],
                        "text": "One approach is based on training on multiple\u00adview samples \n[Gu et al. 2001; Schnei\u00adderman and Kanade 2000]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 119
                            }
                        ],
                        "text": "Newly de\u00adveloped segmentation methods \nlocate the face and estimate its pose simultaneously without extracting features [Gu et al. 2001; Li \net al. 2001b]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7342390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "88b367f75285c4412cba9baa6409bca256d38a6b",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Modeling subspaces of a distribution of interest in high dimensional spaces is a challenging problem in pattern analysis. In this paper, we present a novel framework for pose invariant face detection through. multi-view face distribution modeling. The approach is aimed to learn a set of low-dimensional subspaces from an originally nonlinear distribution by using the mixtures of probabilistic PCA. From the experiments, we found the learned PPCA models are of low dimensionality and exhibit high local linearity, and consequently offer an efficient representation for visual recognition. The model is then used to extract features and select \"representative\" negative training samples. Multi-view face detection is performed in the derived feature space by classifying each face into one of the view classes or into the nonface class, by using a multi-class SVM array classifier. The classification results from each view are fused together and yields the final classification results. The experimental results demonstrate the performance superiority of our proposed framework while performing multi-view face detection."
            },
            "slug": "Learning-probabilistic-distribution-model-for-face-Gu-Li",
            "title": {
                "fragments": [],
                "text": "Learning probabilistic distribution model for multi-view face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This paper presents a novel framework for pose invariant face detection through multi-view face distribution modeling aimed to learn a set of low-dimensional subspaces from an originally nonlinear distribution by using the mixtures of probabilistic PCA."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3230391"
                        ],
                        "name": "A. Georghiades",
                        "slug": "A.-Georghiades",
                        "structuredName": {
                            "firstName": "Athinodoros",
                            "lastName": "Georghiades",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Georghiades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 160
                            }
                        ],
                        "text": "More recently, an illumination cone has been proposed as an e ective method of handling illumination variations, including shadowing and multiple light sources [185, 186]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 191
                            }
                        ],
                        "text": "More \nrecently, an illumination cone has been proposed as an effective method of handling illumination variations, \nin\u00adcluding shadowing and multiple light sources [Belhumeur and Kriegman 1997; Georghiades et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 143
                            }
                        ],
                        "text": "Experiments on face recognition showed improved \nperfor\u00admance over eigenfaces, which were some\u00adwhat worse than the illumination cone\u00adbased method [Georghiades \net al. 1998] on the same set of data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 761294,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a7401db2d9c664bb5500e79e7a5d9d97f6829711",
            "isKey": false,
            "numCitedBy": 251,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Due to illumination variability, the same object can appear dramatically different even when viewed in fixed pose. To handle this variability, an object recognition system must employ a representation that is either invariant to, or models this variability. This paper presents an appearance-based method for modeling the variability due to illumination in the images of objects. The method differs from past appearance-based methods, however, in that a small set of training images is used to generate a representation-the illumination cone-which models the complete set of images of an object with Lambertian reflectance map under an arbitrary combination of point light sources at infinity. This method is both an implementation and extension (an extension in that it models cast shadows) of the illumination cone representation proposed in Belhumeur and Kriegman (1996). The method is tested on a database of 660 images of 10 faces, and the results exceed those of popular existing methods."
            },
            "slug": "Illumination-cones-for-recognition-under-variable-Georghiades-Kriegman",
            "title": {
                "fragments": [],
                "text": "Illumination cones for recognition under variable lighting: faces"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This method is both an implementation and extension (an extension in that it models cast shadows) of the illumination cone representation proposed in Belhumeur and Kriegman (1996), and the results exceed those of popular existing methods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40638847"
                        ],
                        "name": "Hyeonjoon Moon",
                        "slug": "Hyeonjoon-Moon",
                        "structuredName": {
                            "firstName": "Hyeonjoon",
                            "lastName": "Moon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyeonjoon Moon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11563321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f095554be869d80ff273f438875ecad391bfdae0",
            "isKey": false,
            "numCitedBy": 522,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms based on principal component analysis (PCA) form the basis of numerous studies in the psychological and algorithmic face-recognition literature. PCA is a statistical technique and its incorporation into a face-recognition algorithm requires numerous design decisions. We explicitly state the design decisions by introducing a generic modular PCA-algorithm. This allows us to investigate these decisions, including those not documented in the literature. We experimented with different implementations of each module, and evaluated the different implementations using the September 1996 FERET evaluation protocol (the de facto standard for evaluating face-recognition algorithms). We experimented with (i) changing the illumination normalization procedure; (ii) studying effects on algorithm performance of compressing images with JPEG and wavelet compression algorithms; (iii) varying the number of eigenvectors in the representation; and (iv) changing the similarity measure in the classification process. We performed two experiments. In the first experiment, we obtained performance results on the standard September 1996 FERET large-gallery image sets. In the second experiment, we examined the variability in algorithm performance on different sets of facial images. The study was performed on 100 randomly generated image sets (galleries) of the same size. Our two most significant results are (i) changing the similarity measure produced the greatest change in performance, and (ii) that difference in performance of \u00b110% is needed to distinguish between algorithms."
            },
            "slug": "Computational-and-Performance-Aspects-of-PCA-Based-Moon-Phillips",
            "title": {
                "fragments": [],
                "text": "Computational and Performance Aspects of PCA-Based Face-Recognition Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Two most significant results are that changing the similarity measure produced the greatest change in performance, and that difference in performance of \u00b110% is needed to distinguish between algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2920582"
                        ],
                        "name": "E. Petajan",
                        "slug": "E.-Petajan",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Petajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Petajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775043"
                        ],
                        "name": "H. Graf",
                        "slug": "H.-Graf",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Graf",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Graf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 38285340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6baadb412906434d1d378911bafe8df57fda56d9",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The robust acquisition of facial features needed for visual speech processing is fraught with difficulties which greatly increase the complexity of the machine vision system. This system must extract the inner lip contour from facial images with variations in pose, lighting, and facial hair. This paper describes a face feature acquisition system with robust performance in the presence of extreme lighting variations and moderate variations in pose. Furthermore, system performance is not degraded by facial hair or glasses. To find the position of a face reliably we search the whole image for facial features. These features are then combined and tests are applied, to determine whether any such combination actually belongs to a face. In order to find where the lips are, other features of the face, such as the eyes, must be located as well. Without this information it is difficult to reliably find the mouth in a complex image. Just the mouth by itself is easily missed or other elements in the image can be mistaken for a mouth. If camera position can be constrained to allow the nostrils to be viewed, then nostril tracking is used to both reduce computation and provide additional robustness. Once the nostrils are tracked from frame to frame using a tracking window the mouth area can be isolated and normalized for scale and rotation. A mouth detail analysis procedure is then used to estimate the inner lip contour and teeth and tongue regions. The inner lip contour and head movements are then mapped to synthetic face parameters to generate a graphical talking head synchronized with the original human voice. This information can also be used as the basis for visual speech features in an automatic speechreading system. Similar features were used in our previous automatic speechreading systems."
            },
            "slug": "Robust-face-feature-analysis-for-automatic-and-Petajan-Graf",
            "title": {
                "fragments": [],
                "text": "Robust face feature analysis for automatic speechreading and character animation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A face feature acquisition system with robust performance in the presence of extreme lighting variations and moderate variations in pose, which can be used as the basis for visual speech features in an automatic speechreading system."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1971263"
                        ],
                        "name": "K. Etemad",
                        "slug": "K.-Etemad",
                        "structuredName": {
                            "firstName": "Kamran",
                            "lastName": "Etemad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Etemad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69416958"
                        ],
                        "name": "Ramalingam Chellappa",
                        "slug": "Ramalingam-Chellappa",
                        "structuredName": {
                            "firstName": "Ramalingam",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ramalingam Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 221895897,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d6bfe51abb006ab56ee039b4b54a643fd53ed7fa",
            "isKey": false,
            "numCitedBy": 425,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper the discriminatory power of various human facial features is studied and a new scheme for Automatic Face Recognition (AFR) is proposed. Using Linear Discriminant Analysis (LDA) of different aspects of human faces in spatial domain, we first evaluate the significance of visual information in different parts/features of the face for identifying the human subject. The LDA of faces also provides us with a small set of features that carry the most relevant information for classification purposes. The features are obtained through eigenvector analysis of scatter matrices with the objective of maximizing between-class and minimizing within-class variations. The result is an efficient projection-based feature extraction and classification scheme for AFR. Soft decisions made based on each of the projections are combined, using probabilistic or evidential approaches to multisource data analysis. For medium-sized databases of human faces, good classification accuracy is achieved using very low-dimensional feature vectors."
            },
            "slug": "Discriminant-analysis-for-recognition-of-human-face-Etemad-Chellappa",
            "title": {
                "fragments": [],
                "text": "Discriminant analysis for recognition of human face images"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The discriminatory power of various human facial features is studied and a new scheme for Automatic Face Recognition (AFR) is proposed and an efficient projection-based feature extraction and classification scheme for AFR is proposed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2173900"
                        ],
                        "name": "K. Messer",
                        "slug": "K.-Messer",
                        "structuredName": {
                            "firstName": "Kieron",
                            "lastName": "Messer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Messer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59925312,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef88fe030886af62db232598de4d2c90544ea333",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe the acquisition of a large multi-modal database intended for training and testing of multi-modal verification systems. When completed, the XM2FDB database will contain recordings of about 300 hundred subjects taken over a period of four months. The use of biometric measurements in security applications is becoming common to a level where a dedicated journal [1] monitors the developments in the area. Extremely reliable methods of biometric personal identification exist, eg. fingerprint analysis, retinal or iris scans. But most of these methods are considered unacceptable by users in all but high-security scenarios. Personal identification system based on analysis of speech, frontal or profile images of face are non-intrusive and therefore user-friendly. Moreover, personal identity can by often ascertained without client\u2019s assistance. However, the speech and image-based systems are less robust to imposter attack, especially if the imposter possesses information about a client, eg. a photograph or a recording of client\u2019s speech. Multi-modal personal verification is one of the most promising approaches to user-friendly (hence acceptable) highly secure personal verification systems [2]. Recognition and verification system need training; the larger the training set, the better the performance achieved [3]. The volume of data required for training a multi-modal system based on analysis of video and audio signals is in the order of TBytes (1000 GBytes); technology allowing manipulation and effective use of such amounts of data has only recently become available in the form of digital video. In acquiring the database over three-hundred volunteers from the University of Surrey visited a recording studio four times at approximately one month intervals. On each visit (session) two recordings (shots) were made. The first shot consisted of speech. The subject, whom a clip-on microphone had been attached, was asked to sit in chair. He/she was then asked to read three sentences which were written on a board positioned just below the camera. The subjects were asked to read at their normal pace, to pause briefly at the end of each sentence and to read through the three sentences twice. The three sentences remained the same throughout all four recording sessions and were"
            },
            "slug": "Acquisition-of-a-Large-Database-for-Biometric-Messer-Matas",
            "title": {
                "fragments": [],
                "text": "Acquisition of a Large Database for Biometric Identity Verification"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "The acquisition of a large multi-modal database intended for training and testing of multi- modal verification systems is described and the XM2FDB database will contain recordings of about 300 hundred subjects taken over a period of four months."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143979395"
                        ],
                        "name": "H. Wechsler",
                        "slug": "H.-Wechsler",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wechsler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wechsler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152292143"
                        ],
                        "name": "Jeffrey R. Huang",
                        "slug": "Jeffrey-R.-Huang",
                        "structuredName": {
                            "firstName": "Jeffrey R.",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey R. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 69
                            }
                        ],
                        "text": "In the recent com\u00adprehensive \nFERET evaluations [Phillips et al. 2000; Phillips et al. 1998b; Rizvi et al. 1998], aimed at evaluating \ndif\u00adferent systems using the same large database containing thousands of images, the systems described \nin Moghaddam and Pentland [1997]; Swets and Weng [1996b];\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 149
                            }
                        ],
                        "text": "\u2026on Automatic Face and Gesture Recognition (AFGR) since 1995, system\u00adatic \nempirical evaluations of face recog\u00adnition techniques (FRT), including the FERET [Phillips et al. 1998b, \n2000; Rizvi et al. 1998], FRVT 2000 [Blackburn et al. 2001], FRVT 2002 [Phillips et al. 2003], and XM2VTS \n[Messer et\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 258
                            }
                        ],
                        "text": "The second FERET evaluation was adminis\u00ad 17http://www.itl.nist.gov/iad/humanid/feret/. \ntered in March 1995; it consisted of a sin\u00adgle test that measured identi.cation per\u00adformance from a gallery \nof 817 individ\u00aduals, and included 463 duplicates in the probe set [Phillips et al. 1998b]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "The .rst FERET evaluation \ntest was administered in August 1994 [Phillips et al. 1998b]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 33
                            }
                        ],
                        "text": "The se\u00adries of FERET evaluations [Phillips et al. 2000b, 1998; Rizvi et al. 1998]17 \nattracted nine institutions and companies to partic\u00adipate."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17779599,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc8b25e35a3acb812beb499844734081722319b4",
            "isKey": false,
            "numCitedBy": 2398,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-FERET-database-and-evaluation-procedure-for-Phillips-Wechsler",
            "title": {
                "fragments": [],
                "text": "The FERET database and evaluation procedure for face-recognition algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1384255355"
                        ],
                        "name": "Aleix M. Martinez",
                        "slug": "Aleix-M.-Martinez",
                        "structuredName": {
                            "firstName": "Aleix M.",
                            "lastName": "Martinez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aleix M. Martinez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13862950,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed2ad7dfdb82039f63908b20dd736a92b6fdf3d5",
            "isKey": false,
            "numCitedBy": 868,
            "numCiting": 184,
            "paperAbstract": {
                "fragments": [],
                "text": "The classical way of attempting to solve the face (or object) recognition problem is by using large and representative data sets. In many applications, though, only one sample per class is available to the system. In this contribution, we describe a probabilistic approach that is able to compensate for imprecisely localized, partially occluded, and expression-variant faces even when only one single training sample per class is available to the system. To solve the localization problem, we find the subspace (within the feature space, e.g., eigenspace) that represents this error for each of the training images. To resolve the occlusion problem, each face is divided into k local regions which are analyzed in isolation. In contrast with other approaches where a simple voting space is used, we present a probabilistic method that analyzes how \"good\" a local match is. To make the recognition system less sensitive to the differences between the facial expression displayed on the training and the testing images, we weight the results obtained on each local area on the basis of how much of this local area is affected by the expression displayed on the current test image."
            },
            "slug": "Recognizing-Imprecisely-Localized,-Partially-and-a-Martinez",
            "title": {
                "fragments": [],
                "text": "Recognizing Imprecisely Localized, Partially Occluded, and Expression Variant Faces from a Single Sample per Class"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A probabilistic approach that is able to compensate for imprecisely localized, partially occluded, and expression-variant faces even when only one single training sample per class is available to the system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145508996"
                        ],
                        "name": "J. Wilder",
                        "slug": "J.-Wilder",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Wilder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wilder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980956"
                        ],
                        "name": "Cunhong Jiang",
                        "slug": "Cunhong-Jiang",
                        "structuredName": {
                            "firstName": "Cunhong",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cunhong Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067135310"
                        ],
                        "name": "S. Wiener",
                        "slug": "S.-Wiener",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Wiener",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wiener"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[85] describes an initial study comparing the e ectiveness of visible and infra-red (IR) imagery for detecting and recognizing faces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1208659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d30bccb82c115317d5f60a889b36603570cad012",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents initial results in a study comparing the effectiveness of visible and infra-red (IR) imagery for detecting and recognizing faces in areas where personnel identification is critical, (e.g. airports and secure buildings). We compare the effectiveness of visible versus IR imagery by running three face recognition algorithms on a database of images collected for this study. There are both IR and visible images for each person in the database collected using the same scenarios. We used three very different feature-extraction and decision-making algorithms for our study to insure that the comparisons would not depend on a particular processing technique. We also present recognition results when visible and infra-red decision metrics are fused. The recognition results show that both visible and IR imagery perform similarly across algorithms and that fusion of IR and visible imagery as a viable means of enhancing performance beyond that of either acting alone. We examine the relative importance of different regions of the face for recognition. We also discuss practical issues of implementation, along with plans for the next phase of the study, face detection in an uncontrolled environment. Preliminary face detection results are presented."
            },
            "slug": "Comparison-of-visible-and-infra-red-imagery-for-Wilder-Phillips",
            "title": {
                "fragments": [],
                "text": "Comparison of visible and infra-red imagery for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The recognition results show that both visible and IR imagery perform similarly across algorithms and that fusion of IR and visible imagery as a viable means of enhancing performance beyond that of either acting alone."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 154
                            }
                        ],
                        "text": "3 Class-Based Approaches Under the assumptions of Lambertian surfaces and no shadowing, a 3D linear illumination subspace for a person was constructed in [66, 67, 184, 185] for a xed viewpoint, using three aligned faces/images acquired under di erent lighting conditions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6611218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef768a5c9bd0aaeddafea1d56b08b0c8180760c0",
            "isKey": false,
            "numCitedBy": 1493,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of automatically learning object models for recognition and pose estimation is addressed. In contrast to the traditional approach, the recognition problem is formulated as one of matching appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties and constant for a rigid object, pose and illumination vary from scene to scene. A compact representation of object appearance is proposed that is parametrized by pose and illumination. For each object of interest, a large set of images is obtained by automatically varying pose and illumination. This image set is compressed to obtain a low-dimensional subspace, called the eigenspace, in which the object is represented as a manifold. Given an unknown input image, the recognition system projects the image to eigenspace. The object is recognized based on the manifold it lies on. The exact position of the projection on the manifold determines the object's pose in the image.A variety of experiments are conducted using objects with complex appearance characteristics. The performance of the recognition and pose estimation algorithms is studied using over a thousand input images of sample objects. Sensitivity of recognition to the number of eigenspace dimensions and the number of learning samples is analyzed. For the objects used, appearance representation in eigenspaces with less than 20 dimensions produces accurate recognition results with an average pose estimation error of about 1.0 degree. A near real-time recognition system with 20 complex objects in the database has been developed. The paper is concluded with a discussion on various issues related to the proposed learning and recognition methodology."
            },
            "slug": "Visual-learning-and-recognition-of-3-d-objects-from-Murase-Nayar",
            "title": {
                "fragments": [],
                "text": "Visual learning and recognition of 3-d objects from appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A near real-time recognition system with 20 complex objects in the database has been developed and a compact representation of object appearance is proposed that is parametrized by pose and illumination."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40302807"
                        ],
                        "name": "G. Gordon",
                        "slug": "G.-Gordon",
                        "structuredName": {
                            "firstName": "Gaile",
                            "lastName": "Gordon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gordon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 46
                            }
                        ],
                        "text": "Barring \na few exceptions that use range data [Gordon 1991], the face recognition problem has been formulated \nas recogniz\u00ading three-dimensional (3D) objects from two-dimensional (2D) images.1 Earlier ap\u00adproaches \ntreated it as a 2D pattern recog\u00adnition problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 45
                            }
                        ],
                        "text": "Barring a few exceptions that use range data [Gordon 1991], the face recognition problem has been formulated as recognizing three-dimensional (3D) objects from two-dimensional (2D) images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17991489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "948f339fa0196b8694d4ec7a4e5754a6c1cabfd5",
            "isKey": false,
            "numCitedBy": 248,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the representation of the human face by features based on the curvature of the face surface. Curature captures many features necessary to accurately describe the face, such as the shape of the forehead, jawline, and cheeks, which are not easily detected from standard intensity images. Moreover, the value of curvature at a point on the surface is also viewpoint invariant. Until recently range data of high enough resolution and accuracy to perform useful curvature calculations on the scale of the human face had been unavailable. Although several researchers have worked on the problem of interpreting range data from curved (although usually highly geometrically structured) surfaces, the main approaches have centered on segmentation by signs of mean and Gaussian curvature which have not proved sufficient in themselves for the case of the human face. This paper details the calculation of principal curvature for a particular data set, the calculation of general surface descriptors based on curvature, and the calculation of face specific descriptors based both on curvature features and a priori knowledge about the structure of the face. These face specific descriptors can be incorporated into many different recognition strategies. A system that implements one such strategy, depth template comparison, giving recognition rates between 80% and 90% is described."
            },
            "slug": "Face-recognition-based-on-depth-maps-and-surface-Gordon",
            "title": {
                "fragments": [],
                "text": "Face recognition based on depth maps and surface curvature"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The calculation of principal curvature for a particular data set, the calculation of general surface descriptors based on curvature, and the calculation a system that implements one such strategy, depth template comparison, giving recognition rates between 80% and 90% is described."
            },
            "venue": {
                "fragments": [],
                "text": "Optics & Photonics"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398079691"
                        ],
                        "name": "Tammy Riklin-Raviv",
                        "slug": "Tammy-Riklin-Raviv",
                        "structuredName": {
                            "firstName": "Tammy",
                            "lastName": "Riklin-Raviv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tammy Riklin-Raviv"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14358167,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "219fd359c33cc072a46788d82ee64513356bc285",
            "isKey": false,
            "numCitedBy": 653,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper addresses the problem of \"class-based\" image-based recognition and rendering with varying illumination. The rendering problem is defined as follows: Given a single input image of an object and a sample of images with varying illumination conditions of other objects of the same general class, re-render the input image to simulate new illumination conditions. The class-based recognition problem is similarly defined: Given a single image of an object in a database of images of other objects, some of them multiply sampled under varying illumination, identify (match) any novel image of that object under varying illumination with the single image of that object in the database. We focus on Lambertian surface classes and, in particular, the class of human faces. The key result in our approach is based on a definition of an illumination invariant signature image which enables an analytic generation of the image space with varying illumination. We show that a small database of objects-in our experiments as few as two objects-is sufficient for generating the image space with varying illumination of any new object of the class from a single input image of that object. In many cases, the recognition results outperform by far conventional methods and the re-rendering is of remarkable quality considering the size of the database of example images and the mild preprocess required for making the algorithm work."
            },
            "slug": "The-Quotient-Image:-Class-Based-Re-Rendering-and-Shashua-Riklin-Raviv",
            "title": {
                "fragments": [],
                "text": "The Quotient Image: Class-Based Re-Rendering and Recognition with Varying Illuminations"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "It is shown that a small database of objects is sufficient for generating the image space with varying illumination of any new object of the class from a single input image of that object."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404727582"
                        ],
                        "name": "A. Roy-Chowdhury",
                        "slug": "A.-Roy-Chowdhury",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Roy-Chowdhury",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Roy-Chowdhury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2929b70f2810313d4f6f334193f57a808a7c1247",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Face-reconstruction-from-monocular-video-using-and-Roy-Chowdhury-Chellappa",
            "title": {
                "fragments": [],
                "text": "Face reconstruction from monocular video using uncertainty analysis and a generic model"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 270
                            }
                        ],
                        "text": "\u2026\ntechniques could only han\u00addle single or a few well-separated frontal faces in images with simple backgrounds, \nwhile state-of-the-art algorithms can de\u00adtect faces and their poses in cluttered backgrounds [Gu et al. \n2001; Heisele et al. 2001; Schneiderman and Kanade 2000; Vi\u00adola and Jones 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 313,
                                "start": 224
                            }
                        ],
                        "text": "Earlier face detection techniques could only handle single or a few well-separated frontal faces in images with simple backgrounds, while state-of-the-art algorithms can detect faces and their poses in cluttered backgrounds [Gu et al. 2001; Heisele et al. 2001; Schneiderman and Kanade 2000; Viola and Jones 2001]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2715202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63",
            "isKey": false,
            "numCitedBy": 17887,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection."
            },
            "slug": "Rapid-object-detection-using-a-boosted-cascade-of-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Rapid object detection using a boosted cascade of simple features"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates and the introduction of a new image representation called the \"integral image\" which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 47
                            }
                        ],
                        "text": "Compared to the parallel deformation scheme in [195], this method reduces the need to compute correspondences between images of di erent poses."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 183
                            }
                        ],
                        "text": "person are available [191, 192, 193, 194], 2) hybrid methods when multiple images are available during training but only one database image per person is available during recognition [80, 195, 196, 197], and 3) single image based methods when no training is carried out."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 150
                            }
                        ],
                        "text": "\u20261997], (3) a linear class-based method [Blanz and Vetter 1999; \nVetter and Poggio 1997], (4) a vectorized im\u00adage representation based method [Beymer 1995; Beymer and \nPoggio 1995], and (5) a view-based appearance model [Cootes 23GBR is a 3D af.ne transformation with three \npa\u00adrameters: scale,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 150
                            }
                        ],
                        "text": "\u2026and the novel image at the same pose, then (B) the .ow is mapped onto the novel face, \nand .nally (C) the novel face is 2D-warped to the vir\u00adtual view [Beymer and Poggio 1995]. ter the correspondence \nbetween the new image and the prototype image at pose .1 is computed; using the warped .ow, a\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 30
                            }
                        ],
                        "text": "In \nboth methods [Beymer 1995; Beymer and Poggio 1995], an optical .ow algorithm is used to compute a dense \ncor\u00adrespondence between the images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14814282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66505cb708b098a93331471f079965f6ded4ea7f",
            "isKey": true,
            "numCitedBy": 449,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "To create a pose-invariant face recognizer, one strategy is the view-based approach, which uses a set of real example views at different poses. But what if we only have one real view available, such as a scanned passport photo-can we still recognize faces under different poses? Given one real view at a known pose, it is still possible to use the view-based approach by exploiting prior knowledge of faces to generate virtual views, or views of the face as seen from different poses. To represent prior knowledge, we use 2D example views of prototype faces under different rotations. We develop example-based techniques for applying the rotation seen in the prototypes to essentially \"rotate\" the single real view which is available. Next, the combined set of one real and multiple virtual views is used as example views for a view-based, pose-invariant face recognizer. Oar experiments suggest that among the techniques for expressing prior knowledge of faces, 2D example-based approaches should be considered alongside the more standard 3D modeling techniques.<<ETX>>"
            },
            "slug": "Face-recognition-from-one-example-view-Beymer-Poggio",
            "title": {
                "fragments": [],
                "text": "Face recognition from one example view"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Oar experiments suggest that among the techniques for expressing prior knowledge of faces, 2D example-based approaches should be considered alongside the more standard 3D modeling techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107496353"
                        ],
                        "name": "W. Zhao",
                        "slug": "W.-Zhao",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103240750"
                        ],
                        "name": "P. J. PhillipsCenter",
                        "slug": "P.-J.-PhillipsCenter",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "PhillipsCenter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. J. PhillipsCenter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 43
                            }
                        ],
                        "text": "On the other hand, the subspace LDA method [Zhao et al. 1999] works well for both large and small images, for example, 96 \u00d7 84 or 12 \u00d7 11."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 198
                            }
                        ],
                        "text": "Some authors have argued that there exists a universal face subspace of fixed dimension; hence for holistic recognition, image size does not matter as long as it exceeds the subspace dimensionality [Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 139
                            }
                        ],
                        "text": "However, it has been demonstrated that the image size can be very small for holistic face recognition: 12 \u00d7 11 for the subspace LDA system [Zhao et al. 1999], 14\u00d710 for the PDBNN system [Lin et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 198
                            }
                        ],
                        "text": "Some authors have argued that there exists a uni\u00adversal \nface subspace of .xed dimension; hence for holistic recognition, image size does not matter as long as \nit exceeds the subspace dimensionality [Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 64
                            }
                        ],
                        "text": "One way to unify PCA and LDA is to use regularized subspace LDA [Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 178
                            }
                        ],
                        "text": "To address the \nissue of varying albedo, a direct 2D-to-2D approach was proposed based on the assumption that front-view \nfaces are symmetric and making use of a generic 3D model [Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 199
                            }
                        ],
                        "text": "Using the Yale and Weizmann databases (Table V), significant performance improvements were reported when the prototype images were used in a subspace LDA system in place of the original input images [Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 126
                            }
                        ],
                        "text": "Three of the algorithms performed very well: probabilistic eigenface from MIT [Moghaddam et al. 1996], \nsub\u00adspace LDA from UMD [Zhao et al. 1998, 1999], and Elastic Graph Matching from USC [Wiskott et al. \n1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 52
                            }
                        ],
                        "text": "Improved \nrecognition results based on subspace LDA [Zhao et al. 1999] were reported on a small database consist\u00ading \nof frontal and quasipro.le images of 115 novel objects (size 48\u00d742)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 161
                            }
                        ],
                        "text": "Face recognition systems using LDA/FLD have also been very suc\u00adcessful [Belhumeur et al. 1997; \nEtemad and Chellappa 1997; Swets and Weng 1996b; Zhao et al. 1998; Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 51
                            }
                        ],
                        "text": "Improved recognition results based on subspace LDA [Zhao et al. 1999] were reported on a small database consisting of frontal and quasiprofile images of 115 novel objects (size 48\u00d742)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 177
                            }
                        ],
                        "text": "To address the issue of varying albedo, a direct 2D-to-2D approach was proposed based on the assumption that front-view faces are symmetric and making use of a generic 3D model [Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 138
                            }
                        ],
                        "text": "However, it has been demonstrated that the image size can be very small for holistic face recognition: \n12 \u00d7 11 for the subspace LDA system [Zhao et al. 1999], 14\u00d710 for the PDBNN system [Lin et al. 1997], \nand 18 \u00d7 24 for human percep\u00adtion [Bachmann 1991]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 199
                            }
                        ],
                        "text": "Using the Yale and Weizmann databases (Table V), signi.cant performance im\u00adprovements were reported when \nthe pro\u00adtotype images were used in a subspace LDA system in place of the original in\u00adput images [Zhao \net al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 65
                            }
                        ],
                        "text": "One way to unify PCA and LDA is to use regularized \nsubspace LDA [Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 44
                            }
                        ],
                        "text": "On the other hand, the \nsubspace LDA method [Zhao et al. 1999] works well for both large and small images, for example, 96 \u00d7 \n84 or 12 \u00d7 11."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 70
                            }
                        ],
                        "text": "Face recognition systems using LDA/FLD have also been very successful [Belhumeur et al. 1997; Etemad and Chellappa 1997; Swets and Weng 1996b; Zhao et al. 1998; Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13341931,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aea16acb0677c83149742e547bcdc531e55bdd6b",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a holistic face recognition method based on subspace Linear Dis-criminant Analysis (LDA). The method consists of two steps: rst we project the face image from the original vector space to a face subspace via Principal Component Analysis where the subspace dimension is carefully chosen, and then we use LDA to obtain a linear classiier in the subspace. The criterion we use to choose the subspace dimension enables us to generate class-separable features via LDA from the full subspace representation. Hence we are able to solve the generalization/overrtting problem when we perform face recognition on a large face dataset but with very few training face images available per testing person. In addition, we employ a weighted distance metric guided by the LDA eigenvalues to improve the performance of the subspace LDA method. Finally, the improved performance of the subspace LDA approach is demonstrated through experiments using the FERET dataset for face recognition/veriication, a large mugshot dataset for person veriication, and the MPEG-7 dataset. We believe that this approach provides a useful framework for other image recognition tasks as well."
            },
            "slug": "Subspace-Linear-Discriminant-Analysis-for-Face-Zhao-Chellappa",
            "title": {
                "fragments": [],
                "text": "Subspace Linear Discriminant Analysis for Face RecognitionW"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The holistic face recognition method based on subspace Linear Dis-criminant Analysis (LDA) is described, which is able to solve the generalization/overrtting problem when the authors perform face recognition on a large face dataset but with very few training face images available per testing person."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 286,
                                "start": 273
                            }
                        ],
                        "text": "\u20262001; Swets and Weng 1996b; Zhao \net al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA) [Fisher 1938]; Bayesian methods, \nwhich use a probabilistic distance metric [Moghaddam and Pentland 1997]; and SVM methods, which use a \nsupport vector machine as the classi.er [Phillips 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 147
                            }
                        ],
                        "text": "\u20261997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and Wechsler 2000a] Feature lines Point-to-line distance based [Li \nand Lu 1999] ICA\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16287282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1032522498375a819bfcbe844bbe4d30f00880c",
            "isKey": false,
            "numCitedBy": 428,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Face recognition is a K class problem. where K is the number of known individuals; and support vector machines (SVMs) are a binary classification method. By reformulating the face recognition problem and reinterpreting the output of the SVM classifier. we developed a SVM -based face recognition algorithm. The face recognition problem is formulated as a problem in difference space. which models dissimilarities between two facial images. In difference space we formulate face recognition as a two class problem. The classes are: dissimilarities between faces of the same person. and dissimilarities between faces of different people. By modifying the interpretation of the decision surface generated by SVM. we generated a similarity metric between faces that is learned from examples of differences between faces. The SVM-based algorithm is compared with a principal component analysis (PCA) based algorithm on a difficult set of images from the FERET database. Performance was measured for both verification and identification scenarios. The identification performance for SVM is 77-78% versus 54% for PCA. For verification. the equal error rate is 7% for SVM and 13% for PCA."
            },
            "slug": "Support-Vector-Machines-Applied-to-Face-Recognition-Phillips",
            "title": {
                "fragments": [],
                "text": "Support Vector Machines Applied to Face Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A SVM -based face recognition algorithm that is compared with a principal component analysis (PCA) based algorithm on a difficult set of images from the FERET database and generated a similarity metric between faces that is learned from examples of differences between faces."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736143"
                        ],
                        "name": "Constantine Kotropoulos",
                        "slug": "Constantine-Kotropoulos",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Kotropoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Constantine Kotropoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144064571"
                        ],
                        "name": "I. Pitas",
                        "slug": "I.-Pitas",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Pitas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061647120"
                        ],
                        "name": "S. Fischer",
                        "slug": "S.-Fischer",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2100878"
                        ],
                        "name": "B. Duc",
                        "slug": "B.-Duc",
                        "structuredName": {
                            "firstName": "Beno\u00eet",
                            "lastName": "Duc",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Duc"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 65
                            }
                        ],
                        "text": "Several experiments have been conducted using the rst four shots [175, 176, 177, 178, 179, 180], with the goals of investigating text-dependent speaker veri cation from speech text-independent speaker veri cation from speech facial feature extraction and tracking from moving images veri cation from an overall frontal view veri cation from lip shape veri cation from depth information (obtained using structured light) veri cation from a pro le synchronization of speech and lip movement 39"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2648328,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b1ca60a31ba37755a799b97a1b39dd1877948904",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A very attractive approach for face detection is based on multiresolution images (also known as mosaic images). Motivated by the simplicity of this approach, a rule-based face detection algorithm in frontal views is developed first. Second, a novel dynamic link architecture based on multiscale morphological dilation-erosion is proposed for face authentication. More specifically, a sparse grid is placed over the outcome of face detection stage for each person in a reference set. Subsequently, multiscale morphological operations are employed to yield a feature vector at each node of the grid and dynamic link matching is applied to verify the identity of each person from a test set. The first experimental results reported in this paper verify the superiority of the proposed method over the (standard) dynamic link matching that is based on Gabor wavelets."
            },
            "slug": "Face-Authentication-Using-Morphological-Dynamic-Kotropoulos-Pitas",
            "title": {
                "fragments": [],
                "text": "Face Authentication Using Morphological Dynamic Link Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A rule-based face detection algorithm in frontal views is developed and a novel dynamic link architecture based on multiscale morphological dilation-erosion is proposed for face authentication."
            },
            "venue": {
                "fragments": [],
                "text": "AVBPA"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34679741"
                        ],
                        "name": "S. Li",
                        "slug": "S.-Li",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150152476"
                        ],
                        "name": "Juwei Lu",
                        "slug": "Juwei-Lu",
                        "structuredName": {
                            "firstName": "Juwei",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Juwei Lu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5959423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f570e77bc9a6e9362b7eec366e98448d96e4c5a4",
            "isKey": false,
            "numCitedBy": 582,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel classification method, called the nearest feature line (NFL), for face recognition. Any two feature points of the same class (person) are generalized by the feature line (FL) passing through the two points. The derived FL can capture more variations of face images than the original points and thus expands the capacity of the available database. The classification is based on the nearest distance from the query feature point to each FL. With a combined face database, the NFL error rate is about 43.7-65.4% of that of the standard eigenface method. Moreover, the NFL achieves the lowest error rate reported to date for the ORL face database."
            },
            "slug": "Face-recognition-using-the-nearest-feature-line-Li-Lu",
            "title": {
                "fragments": [],
                "text": "Face recognition using the nearest feature line method"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A novel classification method, called the nearest feature line (NFL), for face recognition, based on the nearest distance from the query feature point to each FL, which achieves the lowest error rate reported for the ORL face database."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939761"
                        ],
                        "name": "P. S. Penev",
                        "slug": "P.-S.-Penev",
                        "structuredName": {
                            "firstName": "Penio",
                            "lastName": "Penev",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. S. Penev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49555086"
                        ],
                        "name": "L. Sirovich",
                        "slug": "L.-Sirovich",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Sirovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sirovich"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2632759,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c29bbd996a086f2aaccc1373643546a905f0b6a",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A low-dimensional representation of sensory signals is the key to solving many of the computational problems encountered in high-level vision. Principal component analysis (PCA) has been used in the past to derive such compact representations for the object class of human faces. Here, with an interpretation of PCA as a probabilistic model, we employ two objective criteria to study its generalization properties in the context of large frontal-pose face databases. We find that the eigenfaces, the eigenspectrum, and the generalization depend strongly on the ensemble composition and size, with statistics for populations as large as 5500, still not stationary. Further, the assumption of mirror symmetry of the ensemble improves the quality of the results substantially in the low-statistics regime, and is also essential in the high-statistics regime. We employ a perceptual criterion and argue that, even with large statistics, the dimensionality of the PCA subspace necessary for adequate representation of the identity information in relatively tightly cropped faces is in the 400-700 range, and we show that a dimensionality of 200 is inadequate. Finally, we discuss some of the shortcomings of PCA and suggest possible solutions."
            },
            "slug": "The-global-dimensionality-of-face-space-Penev-Sirovich",
            "title": {
                "fragments": [],
                "text": "The global dimensionality of face space"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is argued that, even with large statistics, the dimensionality of the PCA subspace necessary for adequate representation of the identity information in relatively tightly cropped faces is in the 400-700 range, and it is shown that a dimensionality in the range of 200 is inadequate."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 176
                            }
                        ],
                        "text": "\u20261997] PDBNN Probabilistic decision based NN [Lin et al. 1997] Feature-based \nmethods Pure geometry methods Earlier methods [Kanade 1973; Kelly 1970]; recent methods [Cox et al. 1996; \nManjunath et al. 1992] Dynamic link architecture Graph matching methods [Okada et al. 1998; Wiskott et \nal."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46325945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a735c80fd1a467d82efb3960faf88a522f690be2",
            "isKey": false,
            "numCitedBy": 393,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A feature-based approach to face recognition in which the features are derived from the intensity data without assuming any knowledge of the face structure is presented. The feature extraction model is biologically motivated, and the locations of the features often correspond to salient facial features such as the eyes, nose, etc. Topological graphs are used to represent relations between features, and a simple deterministic graph-matching scheme that exploits the basic structure is used to recognize familiar faces from a database. Each of the stages in the system can be fully implemented in parallel to achieve real-time recognition. Experimental results for a 128*128 image with very little noise are evaluated.<<ETX>>"
            },
            "slug": "A-feature-based-approach-to-face-recognition-Manjunath-Chellappa",
            "title": {
                "fragments": [],
                "text": "A feature based approach to face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A feature-based approach to face recognition in which the features are derived from the intensity data without assuming any knowledge of the face structure is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783224"
                        ],
                        "name": "A. Colmenarez",
                        "slug": "A.-Colmenarez",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Colmenarez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Colmenarez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9192390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e744c3eef4fbc4ac52b2458eb2d545a4432bcb86",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a visual learning technique that maximizes the discrimination between positive and negative examples in a training set. We demonstrate our technique in the context of face detection with complex background without color or motion information, which has proven to be a challenging problem. We use a family of discrete Markov processes to model the face and background patterns and estimate the probability models using the data statistics. Then, we convert the learning process into an optimization, selecting the Markov process that optimizes the information-based discrimination between the two classes. The detection process is carried out by computing the likelihood ratio using the probability model obtained from the learning procedure. We show that because of the discrete nature of these models, the detection process is at least two orders of magnitude less computationally expensive than neural network approaches. However, no improvement in terms of correct-answer/false-alarm tradeoff is achieved."
            },
            "slug": "Face-detection-with-information-based-maximum-Colmenarez-Huang",
            "title": {
                "fragments": [],
                "text": "Face detection with information-based maximum discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A visual learning technique that maximizes the discrimination between positive and negative examples in a training set by using a family of discrete Markov processes to model the face and background patterns and estimate the probability models using the data statistics."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143979395"
                        ],
                        "name": "H. Wechsler",
                        "slug": "H.-Wechsler",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wechsler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wechsler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2008925"
                        ],
                        "name": "Vishal Kakkad",
                        "slug": "Vishal-Kakkad",
                        "structuredName": {
                            "firstName": "Vishal",
                            "lastName": "Kakkad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vishal Kakkad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152292143"
                        ],
                        "name": "Jeffrey R. Huang",
                        "slug": "Jeffrey-R.-Huang",
                        "structuredName": {
                            "firstName": "Jeffrey R.",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey R. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145699982"
                        ],
                        "name": "S. Gutta",
                        "slug": "S.-Gutta",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Gutta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gutta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732930"
                        ],
                        "name": "Victor Y. Chen",
                        "slug": "Victor-Y.-Chen",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Chen",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Y. Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 146
                            }
                        ],
                        "text": "\u2026Still-image methods Basic methods [Turk and \nPentland 1991; Lin et al. 1997; Moghaddam and Pentland 1997; Okada et al. 1998; Penev and Atick 1996; \nWechsler et al. 1997; Wiskott et al. 1997] Tracking-enhanced [Edwards et al. 1998; McKenna and Gong 1997, \n1998; Steffens et al. 1998] Multimodal\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 161
                            }
                        ],
                        "text": "After over twenty years of research on image sequence analysis [86, 87, 88, 89], only a little of that research had been applied to the face recognition problem [90, 91, 92, 93, 94, 95] up to the mid-nineties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [92], a fully automatic person authentication system is described which includes video break, face detection, and authentication modules."
                    },
                    "intents": []
                }
            ],
            "corpusId": 41554301,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72b75e1c6dd15219c81efd90e952ed04d31cf92e",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "As more and more forensic information becomes available on video we address in this paper the Automatic Video-Based Biometric Person Authentication (AVBPA). Possible tasks and application scenarios under consideration involve detection and tracking of humans and human (ID) verification. Authentication corresponds to ID verification and involves actual (face) recognition for the subject(s) detected in the video sequence. The architecture for AVBPA takes advantage of the active vision paradigm and it involves difference methods or optical flow analysis to detect the moving subject, projection analysis and decision trees (DT) for face location, and connectionist network \u2014 Radial Basis Function (RBF) for authentication. Subject detection and face location correspond to video break and key frame detection, respectively, while recognition itself corresponds to authentication. The active vision paradigm is most appropriate for video processing where one has to cope with huge amounts of image data and where further sensing and processing of additional frames is feasible. As a result of such an approach video processing becomes feasible in terms of decreased computational resources (\u2018time\u2019) spent and increased confidence in the (authentication) decisions reached despite sometime poor quality imagery. Experimental results on three FERET video sequences prove the feasibility of our approach."
            },
            "slug": "Automatic-Video-based-Person-Authentication-Using-Wechsler-Kakkad",
            "title": {
                "fragments": [],
                "text": "Automatic Video-based Person Authentication Using the RBF Network"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The architecture for AVBPA takes advantage of the active vision paradigm and it involves difference methods or optical flow analysis to detect the moving subject, projection analysis and decision trees (DT) for face location, and connectionist network \u2014 Radial Basis Function (RBF) for authentication."
            },
            "venue": {
                "fragments": [],
                "text": "AVBPA"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1576036019"
                        ],
                        "name": "B. Knight",
                        "slug": "B.-Knight",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Knight",
                            "middleNames": [
                                "Ann"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41211372"
                        ],
                        "name": "A. Johnston",
                        "slug": "A.-Johnston",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Johnston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Johnston"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 143795397,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "da9b342b1c7a72d2f404128d87d8ab72a74d899a",
            "isKey": false,
            "numCitedBy": 246,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The movement of the face may provide information that facilitates recognition. However, in mostsituations people who are very familiar to us can be recognized easily from a single typical view of the face and the presence of further information derived from movement would not be expected to improve performance. Here the effects of movement on face recognition are investigated for faces presented under non-optimal conditions. Subjects were required to identify moving or still videotaped faces of famous and unknown people. Faces were presented in negative, a manipulation which preserved the two-dimensional shape and configuration of the face and facial features, while degrading face recognition performance. Results indicated that moving faces were significantly better recognized than still faces. It was proposed that movement may provide evidence about the three-dimensional structure of the face and allow the recognition of characteristic facial gestures. When the faces were inverted, no significant effect ..."
            },
            "slug": "The-Role-of-Movement-in-Face-Recognition-Knight-Johnston",
            "title": {
                "fragments": [],
                "text": "The Role of Movement in Face Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31843833"
                        ],
                        "name": "Xiaogang Wang",
                        "slug": "Xiaogang-Wang",
                        "structuredName": {
                            "firstName": "Xiaogang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaogang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50295995"
                        ],
                        "name": "Xiaoou Tang",
                        "slug": "Xiaoou-Tang",
                        "structuredName": {
                            "firstName": "Xiaoou",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoou Tang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7883766,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a828ab27cef4f307fcf747389c15264be69de4c",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Linear discriminant analysis (LDA) is a popular feature extraction technique for face recognition. However, it often suffers from the small sample size problem when dealing with the high dimensional face data. Some approaches have been proposed to overcome this problem, but they are often unstable and have to discard some discriminative information. In this paper, a dual-space LDA approach for face recognition is proposed to take full advantage of the discriminative information in the face space. Based on a probabilistic visual model, the eigenvalue spectrum in the null space of within-class scatter matrix is estimated, and discriminant analysis is simultaneously applied in the principal and null subspaces of the within-class scatter matrix. The two sets of discriminative features are then combined for recognition. It outperforms existing LDA approaches."
            },
            "slug": "Dual-space-linear-discriminant-analysis-for-face-Wang-Tang",
            "title": {
                "fragments": [],
                "text": "Dual-space linear discriminant analysis for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A dual-space LDA approach for face recognition is proposed to take full advantage of the discriminative information in the face space and outperforms existing LDA approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51422577"
                        ],
                        "name": "H. Hill",
                        "slug": "H.-Hill",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2287417"
                        ],
                        "name": "P. Schyns",
                        "slug": "P.-Schyns",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Schyns",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Schyns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49052113"
                        ],
                        "name": "S. Akamatsu",
                        "slug": "S.-Akamatsu",
                        "structuredName": {
                            "firstName": "Shigeru",
                            "lastName": "Akamatsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Akamatsu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7205249,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "1cebd7002df51e10e793fb46533029322ee5a0b8",
            "isKey": false,
            "numCitedBy": 252,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Information-and-viewpoint-dependence-in-face-Hill-Schyns",
            "title": {
                "fragments": [],
                "text": "Information and viewpoint dependence in face recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145840115"
                        ],
                        "name": "S. Lawrence",
                        "slug": "S.-Lawrence",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Lawrence",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lawrence"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733691"
                        ],
                        "name": "A. Tsoi",
                        "slug": "A.-Tsoi",
                        "structuredName": {
                            "firstName": "Ah",
                            "lastName": "Tsoi",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tsoi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144288586"
                        ],
                        "name": "A. Back",
                        "slug": "A.-Back",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Back",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Back"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 58
                            }
                        ],
                        "text": "Convolution Neural Network SOM learning based CNN methods [Lawrence et al. 1997]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 146
                            }
                        ],
                        "text": "\u2026Markov model HMM methods [Ne.an and Hayes 1998; Samaria 1994; Samaria and Young 1994] \nConvolution Neural Network SOM learning based CNN methods [Lawrence et al. 1997] Hybrid methods Modular \neigenfaces Eigenfaces and eigenmodules [Pentland et al. 1994] Hybrid LFA Local feature method [Penev\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 151
                            }
                        ],
                        "text": "Using an unsupervised \nlearn\u00ading method based on a self-organizing map (SOM), a system based on a convolutional neural network \n(CNN) has been developed [Lawrence et al. 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 150
                            }
                        ],
                        "text": "Using an unsupervised learning method based on a self-organizing map (SOM), a system based on a convolutional neural network (CNN) has been developed [Lawrence et al. 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2883848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86890c82b589e24007c56e1f40c5f928a0e04183",
            "isKey": true,
            "numCitedBy": 2720,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a hybrid neural-network for human face recognition which compares favourably with other methods. The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network. The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer."
            },
            "slug": "Face-recognition:-a-convolutional-neural-network-Lawrence-Giles",
            "title": {
                "fragments": [],
                "text": "Face recognition: a convolutional neural-network approach"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A hybrid neural-network for human face recognition which compares favourably with other methods and analyzes the computational complexity and discusses how new classes could be added to the trained recognizer."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299972"
                        ],
                        "name": "I. Biederman",
                        "slug": "I.-Biederman",
                        "structuredName": {
                            "firstName": "Irving",
                            "lastName": "Biederman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Biederman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2811821"
                        ],
                        "name": "P. Kalocsai",
                        "slug": "P.-Kalocsai",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Kalocsai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kalocsai"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 88
                            }
                        ],
                        "text": "The success of the EBGM system may be due to its resemblance to the human visual system [Biederman and Kalocsai 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 42
                            }
                        ],
                        "text": "\u2014Is face recognition a dedicated process? [Biederman and Kalocsai 1998; Ellis 1986; Gauthier et al. 1999; Gauthier and Logothetis 2000]: It is traditionally believed that face recognition is a dedicated process different from other object recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 89
                            }
                        ],
                        "text": "The suc\u00adcess of the EBGM system may be due to its resemblance to the \nhuman visual sys\u00adtem [Biederman and Kalocsai 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 146
                            }
                        ],
                        "text": "\u2026been concerned with issues such as \nwhether face perception is a dedicated process (this issue is still be\u00ading debated in the psychology \ncommunity [Biederman and Kalocsai 1998; Ellis 1986; Gauthier et al. 1999; Gauthier and Logo\u00adthetis 2000]) \nand whether it is done holis\u00adtically or by local\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 84
                            }
                        ],
                        "text": "Seven differences between face recognition and object recognition can be summarized [Biederman and Kalocsai 1998] based on empirical evidence: (1) configural effects (related to the choice of different types of machine recognition systems), (2) expertise, (3) differences verbalizable, (4) sensitivity to contrast polarity and illumination direction (related to the illumination problem in machine recognition systems), (5) metric variation, (6) Rotation in depth (related to the pose variation problem in machine recognition systems), and (7) rotation in plane/inverted face."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 187
                            }
                        ],
                        "text": "Psychophysicists and neuroscientists have been concerned with issues such as whether face perception is a dedicated process (this issue is still being debated in the psychology community [Biederman and Kalocsai 1998; Ellis 1986; Gauthier et al. 1999; Gauthier and Logothetis 2000]) and whether it is done holistically or by local feature analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 1
                            }
                        ],
                        "text": "[Biederman and Kalocsai 1998; Ellis 1986; Gauthier et \nal."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 85
                            }
                        ],
                        "text": "Seven differences between face recognition and object recognition \ncan be summa\u00adrized [Biederman and Kalocsai 1998] based on empirical evidence: (1) con\u00ad.gural effects \n(related to the choice of different types of machine recognition systems), (2) expertise, (3) differences \nverbalizable, (4)\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118328793,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "50097c0008eed4f91f0e1661267e2d0977f55596",
            "isKey": true,
            "numCitedBy": 40,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of behavioral phenomena distinguish the recognition of faces and objects, even when members of the set of objects are highly similar. Because faces have the same parts in approximately the same relations, individuation of faces typically requires specification of the metric variation in a holistic and integral representation of the facial surface. The direct mapping of a hypercolumn-like pattern of activation onto a representation layer that preserves relative spatial filter values in a 2D coordinate space, as proposed by C. von der Malsburg and his associates (Lades et al, 1993; Wiskott, et al., 1997), may account for many of the phenomena associated with face recognition. An additional refinement, in which each column of filters (termed \u201ca jet\u201d) is centered on a particular facial feature (or fiducial point), allows selectivity of the input into the holistic representation to avoid incorporation of occluding or nearby surfaces. The initial hypercolumn representation also characterizes the first stage of object perception, but the image variation for objects at a given location in a 2D coordinate space may be too great to yield sufficient predictability directly from the output of spatial kernels. Consequently, objects can be represented by a structural description specifying qualitative (typically, nonaccidental) characterizations of an object\u2019s parts, the attributes of the parts, and the relations among the parts, largely based on orientation and depth discontinuities (e.g., Hummel & Biederman, 1992). A series of experiments on the name priming or physical matching of complementary images (in the Fourier domain) of objects and faces (See Kalocsai & Biederman, this volume) documents that whereas face recognition is strongly dependent on the original spatial filter values, object recognition evidences strong invariance to these values, even when distinguishing among objects that are as similar as faces."
            },
            "slug": "Neural-and-psychophysical-analysis-of-object-and-Biederman-Kalocsai",
            "title": {
                "fragments": [],
                "text": "Neural and psychophysical analysis of object and face recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2275441"
                        ],
                        "name": "K. Yow",
                        "slug": "K.-Yow",
                        "structuredName": {
                            "firstName": "Kin",
                            "lastName": "Yow",
                            "middleNames": [
                                "Choong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 39
                            }
                        ],
                        "text": "For technical details, please refer to [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9259230,
            "fieldsOfStudy": [
                "Business",
                "Computer Science"
            ],
            "id": "88c59a97f9bb64d94fb7b71c3c6243b4c0dd2c5c",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Many current human face detection algorithms make implicit assumptions about the scale, orientation or viewpoint of faces in an image and exploit these constraints to detect and localize faces. The algorithm may be robust for the assumed conditions but it becomes very difficult to extend the results to general imaging conditions. In an earlier paper (Yow and Cipolla, 1996) we proposed a feature-based face detection algorithm to detect faces in a complex background. In this paper we examine its ability to detect faces under different scale, orientation and viewpoint. The results show that the algorithm can indeed cope with a good range of scale, orientation and viewpoint variations that is typical of a subject sitting in front of a computer terminal."
            },
            "slug": "Detection-of-human-faces-under-scale,-orientation-Yow-Cipolla",
            "title": {
                "fragments": [],
                "text": "Detection of human faces under scale, orientation and viewpoint variations"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The results show that the feature-based face detection algorithm proposed can indeed cope with a good range of scale, orientation and viewpoint variations that is typical of a subject sitting in front of a computer terminal."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143920486"
                        ],
                        "name": "F. Samaria",
                        "slug": "F.-Samaria",
                        "structuredName": {
                            "firstName": "Ferdinando",
                            "lastName": "Samaria",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Samaria"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 87
                            }
                        ],
                        "text": "1997] Hidden Markov model HMM methods [Ne.an and Hayes 1998; Samaria 1994; Samaria and Young 1994] \nConvolution Neural Network SOM learning based CNN methods [Lawrence et al. 1997] Hybrid methods Modular \neigenfaces Eigenfaces and eigenmodules [Pentland et al. 1994] Hybrid LFA Local feature method\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 217
                            }
                        ],
                        "text": "Without .nding the exact locations of facial features, Hidden Markov Model\u00ad(HMM-) based methods use strips \nof pix\u00adels that cover the forehead, eye, nose, mouth, and chin [Ne.an and Hayes 1998; Samaria 1994; Samaria \nand Young 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 61
                            }
                        ],
                        "text": "1997] Hidden Markov model HMM methods [Ne.an and Hayes 1998; Samaria 1994; Samaria and Young 1994] \nConvolution Neural Network SOM learning based CNN methods [Lawrence et al. 1997] Hybrid methods Modular \neigenfaces Eigenfaces and eigenmodules [Pentland et al. 1994] Hybrid LFA Local feature method [Penev \nand Atick 1996] Shape-normalized Flexible appearance models [Lanitis et al. 1995] Component-based Face \nregion and components [Huang et al. 2003] analysis (ICA) is argued to have more representative power \nthan PCA, and hence may provide better recognition per\u00adformance than PCA [Bartlett et al. 1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 56
                            }
                        ],
                        "text": "[Ne.an and Hayes 1998] reported bet\u00adter performance than Samaria [1994] by using the \nKL projection coef.cients in\u00adstead of the strips of raw pixels."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 187
                            }
                        ],
                        "text": "Many methods in the structural matching category \nhave been proposed, including many early methods based on geometry of local features [Kanade 1973; Kelly \n1970] as well as 1D [Samaria and Young 1994] and pseudo-2D [Samaria 1994] HMM methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10798965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bcb88b6842b8fa0fb257e904f4113487e7af554",
            "isKey": true,
            "numCitedBy": 370,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "HMM-based-architecture-for-face-identification-Samaria-Young",
            "title": {
                "fragments": [],
                "text": "HMM-based architecture for face identification"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 16
                            }
                        ],
                        "text": "In both methods [Beymer 1995; Beymer and Poggio 1995], an optical flow algorithm is used to compute a dense correspondence between the images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 139
                            }
                        ],
                        "text": "1997], (3) a linear class-based method [Blanz and Vetter 1999; Vetter and Poggio 1997], (4) a vectorized image representation based method [Beymer 1995; Beymer and Poggio 1995], and (5) a view-based appearance model [Cootes"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 17
                            }
                        ],
                        "text": "In \nboth methods [Beymer 1995; Beymer and Poggio 1995], an optical .ow algorithm is used to compute a dense \ncor\u00adrespondence between the images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 183
                            }
                        ],
                        "text": "Earlier work \non multiview-based meth\u00adods [Beymer 1993] was extended to ex\u00adplore the prior class information that is \nspeci.c to a face class and can be learned from a set of prototypes [Beymer 1993, 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 144
                            }
                        ],
                        "text": "\u2026et al. 1997], (3) a linear class-based method [Blanz and Vetter 1999; \nVetter and Poggio 1997], (4) a vectorized im\u00adage representation based method [Beymer 1995; Beymer and \nPoggio 1995], and (5) a view-based appearance model [Cootes 23GBR is a 3D af.ne transformation with three\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13952915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34a823d412c2134f87ab4f5e8a87c8a203a08b5c",
            "isKey": true,
            "numCitedBy": 72,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The correspondence problem in computer vision is basically a matching task between two or more sets of features. In this paper, we introduce a vectorized image representation, which is a feature-based representation where correspondence has been established with respect to a reference image. This representation has two components: (1) shape, or (x, y) feature locations, and (2) texture, defined as the image grey levels mapped onto the standard reference image. This paper explores an automatic technique for ``vectorizing'''' face images. Our face vectorizer alternates back and forth between computation steps for shape and texture, and a key idea is to structure the two computations so that each one uses the output of the other. A hierarchical coarse-to-fine implementation is discussed, and applications are presented to the problems of facial feature detection and registration of two arbitrary faces."
            },
            "slug": "Vectorizing-Face-Images-by-Interleaving-Shape-and-Beymer",
            "title": {
                "fragments": [],
                "text": "Vectorizing Face Images by Interleaving Shape and Texture Computations"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper introduces a vectorized image representation, which is a feature-based representation where correspondence has been established with respect to a reference image, and explores an automatic technique for ``vectorizing'' face images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36427051"
                        ],
                        "name": "Peter W. Hallinan",
                        "slug": "Peter-W.-Hallinan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hallinan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter W. Hallinan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 105
                            }
                        ],
                        "text": "Early approaches focused on individual features; for example, a template-based approach was described in [Hallinan 1991] to detect and recognize the human eye in a frontal face."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 106
                            }
                        ],
                        "text": "Early ap\u00adproaches focused on individual features; for example, \na template-based approach was described in [Hallinan 1991] to de\u00adtect and recognize the human eye in \na frontal face."
                    },
                    "intents": []
                }
            ],
            "corpusId": 121453877,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fa0f72bef8474a76c3f4e67e00f2784ff0f9b20",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Steps are taken toward the automatic, intensity-based recognition of human faces by constructing a vision system to automatically detect frontally-viewed human eyes in real data. The eye is modeled using a deformable template that specifies a parameterized geometry and an intensity model. The fit of the template is measured by a cost-functional employing robust estimators, i.e., (alpha) -trimmed means and variances, to overcome highlights, shadows, nonrigid boundaries, noise, and other such difficulties. Recognition proceeds in three stages. First, candidate eyes are located by matching a simplified eye model against the responses of a robust, general purpose detector of intensity valleys and peaks. Second, the best fit of each candidate eye is found by minimizing the energy of a cost functional. Third, each candidate is accepted or rejected based on the amount of variance in the image data it explains."
            },
            "slug": "Recognizing-human-eyes-Hallinan",
            "title": {
                "fragments": [],
                "text": "Recognizing human eyes"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "Steps are taken toward the automatic, intensity-based recognition of human faces by constructing a vision system to automatically detect frontally-viewed human eyes in real data using a deformable template using a parameterized geometry and an intensity model."
            },
            "venue": {
                "fragments": [],
                "text": "Optics & Photonics"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145387780"
                        ],
                        "name": "M. Pantic",
                        "slug": "M.-Pantic",
                        "structuredName": {
                            "firstName": "Maja",
                            "lastName": "Pantic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pantic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713654"
                        ],
                        "name": "L. Rothkrantz",
                        "slug": "L.-Rothkrantz",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Rothkrantz",
                            "middleNames": [
                                "J.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rothkrantz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11844016,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "087a6f471b5177014b08a342968901e1ef083ed1",
            "isKey": false,
            "numCitedBy": 1936,
            "numCiting": 212,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans detect and interpret faces and facial expressions in a scene with little or no effort. Still, development of an automated system that accomplishes this task is rather difficult. There are several related problems: detection of an image segment as a face, extraction of the facial expression information, and classification of the expression (e.g., in emotion categories). A system that performs these operations accurately and in real time would form a big step in achieving a human-like interaction between man and machine. The paper surveys the past work in solving these problems. The capability of the human visual system with respect to these problems is discussed, too. It is meant to serve as an ultimate goal and a guide for determining recommendations for development of an automatic facial expression analyzer."
            },
            "slug": "Automatic-Analysis-of-Facial-Expressions:-The-State-Pantic-Rothkrantz",
            "title": {
                "fragments": [],
                "text": "Automatic Analysis of Facial Expressions: The State of the Art"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The capability of the human visual system with respect to these problems is discussed, and it is meant to serve as an ultimate goal and a guide for determining recommendations for development of an automatic facial expression analyzer."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35195550"
                        ],
                        "name": "E. Sali",
                        "slug": "E.-Sali",
                        "structuredName": {
                            "firstName": "Erez",
                            "lastName": "Sali",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sali"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43497586,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18ca3e41a79cb07349b48cd7034eb770372dfe57",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is presented for class-based recognition using a small number of example views taken under several different viewing conditions. The main emphasis is on using a small number of examples. Previous work assumed that the set of examples is sufficient to span the entire space of possible objects, and that in generalizing to a new viewing conditions a sufficient number of previous examples under the new conditions will be available to the recognition system. Here we have considerably relaxed these assumptions and consequently obtained good class-based generalization from a small number of examples, even a single example view, for both viewing position and illumination changes. In addition, previous class-based approaches only focused on viewing position changes and did not deal with illumination changes. Here we used a class-based approach that can generalize for both illumination and viewing position changes. The method was applied to face and car model images. New views under viewing position and illumination changes were synthesized from a small number of examples."
            },
            "slug": "Recognizing-novel-3-D-objects-under-new-and-viewing-Sali-Ullman",
            "title": {
                "fragments": [],
                "text": "Recognizing novel 3-D objects under new illumination and viewing position using a small number of example views or even a single view"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A class-based approach that can generalize for both illumination and viewing position changes was used, and new views under viewing position and illumination changes were synthesized from a small number of examples."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3231915"
                        ],
                        "name": "S. Der",
                        "slug": "S.-Der",
                        "structuredName": {
                            "firstName": "Sandor",
                            "lastName": "Der",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Der"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14238832,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39577ba5d7020bc1750b3a417b7d6432ebb7f00c",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As part of the Face Recognition Technology (FERET) program, the U.S. Army Research Laboratory (ARL) conducted supervised government tests and evaluations of automatic face recognition algorithms. The goal of the tests was to provide an independent method of evaluating algorithms and assessing the state of the art in automatic face recognition. This report describes the design and presents the results of the August 1994 and March 1995 FERET tests. Results for FERET tests administered by ARL between August 1994 and August 1996 are reported."
            },
            "slug": "FERET-(Face-Recognition-Technology)-Recognition-and-Phillips-Rauss",
            "title": {
                "fragments": [],
                "text": "FERET (Face Recognition Technology) Recognition Algorithm Development and Test Results."
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The design and results of the August 1994 and March 1995 FERET tests are described and the goal was to provide an independent method of evaluating algorithms and assessing the state of the art in automatic face recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771659"
                        ],
                        "name": "R. Freund",
                        "slug": "R.-Freund",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Freund",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 39
                            }
                        ],
                        "text": "For technical details, please refer to [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [37], a face detection scheme based on SVMs is proposed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "A recent approach using a Support Vector Machine (SVM) is also brie y reviewed [37]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2845602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9008cdacbdcff8a218a6928e94fe7c6dfc237b24",
            "isKey": false,
            "numCitedBy": 2841,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points."
            },
            "slug": "Training-support-vector-machines:-an-application-to-Osuna-Freund",
            "title": {
                "fragments": [],
                "text": "Training support vector machines: an application to face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets is presented, and the feasibility of the approach on a face detection problem that involves a data set of 50,000 data points is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70059059"
                        ],
                        "name": "J. Matasetal",
                        "slug": "J.-Matasetal",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Matasetal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Matasetal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60654674,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "526f05aa7bf3244d8a0f0b6d8143289a2c337680",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents results of the face verification contest that was organized in conjunction with International Conference on Pattern Recognition 2000 [14]. Participants had to use identical data sets from a large, publicly available multimodal database XM2VTSDB. Training and evaluation was carried out according to an a priori known protocol ([7]). Verification results of all tested algorithms have been collected and made public on the XM2VTSDB website [15], facilitating large scale experiments on classifier combination and fusion. Tested methods included, among others, representatives of the most common approaches to face verification elastic graph matching, Fisher's linear discriminant and Support vector machines."
            },
            "slug": "Comparison-of-Face-Verification-Results-on-the-Matasetal",
            "title": {
                "fragments": [],
                "text": "Comparison of Face Verification Results on the XM2VTS Database"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "Results of the face verification contest that was organized in conjunction with International Conference on Pattern Recognition 2000 are presented, featuring representatives of the most common approaches to face verification elastic graph matching, Fisher's linear discriminant and Support vector machines."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39664966"
                        ],
                        "name": "C. Liu",
                        "slug": "C.-Liu",
                        "structuredName": {
                            "firstName": "Chengjun",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143979395"
                        ],
                        "name": "H. Wechsler",
                        "slug": "H.-Wechsler",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wechsler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wechsler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 150
                            }
                        ],
                        "text": "\u2026et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and Wechsler 2000a] Feature lines Point-to-line distance based [Li \nand Lu 1999] ICA ICA-based feature analysis [Bartlett et al. 1998] Other\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 156
                            }
                        ],
                        "text": "One ex\u00adample is the Probabilistic Decision-Based Neural Network \n(PDBNN) method [Lin et al. 1997] and the other is the evolution pursuit (EP) method [Liu and Wechsler \n2000a]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 150
                            }
                        ],
                        "text": "Toward \nthat end, EP implements strategies characteristic of ge\u00adnetic algorithms (GAs) for searching the so-called \nenhanced FLD (EFM) approach [Liu and Wechsler 2000b]. space of possible solutions to determine the optimal \nbasis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9787011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cada4a2cee3530bb762c5df439a5f671aeea47e3",
            "isKey": false,
            "numCitedBy": 368,
            "numCiting": 106,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduces evolutionary pursuit (EP) as an adaptive representation method for image encoding and classification. In analogy to projection pursuit, EP seeks to learn an optimal basis for the dual purpose of data compression and pattern classification. It should increase the generalization ability of the learning machine as a result of seeking the trade-off between minimizing the empirical risk encountered during training and narrowing the confidence interval for reducing the guaranteed risk during testing. It therefore implements strategies characteristic of GA for searching the space of possible solutions to determine the optimal basis. It projects the original data into a lower dimensional whitened principal component analysis (PCA) space. Directed random rotations of the basis vectors in this space are searched by GA where evolution is driven by a fitness function defined by performance accuracy (empirical risk) and class separation (confidence interval). Accuracy indicates the extent to which learning has been successful, while separation gives an indication of expected fitness. The method has been tested on face recognition using a greedy search algorithm. To assess both accuracy and generalization capability, the data includes for each subject images acquired at different times or under different illumination conditions. EP has better recognition performance than PCA (eigenfaces) and better generalization abilities than the Fisher linear discriminant (Fisherfaces)."
            },
            "slug": "Evolutionary-Pursuit-and-Its-Application-to-Face-Liu-Wechsler",
            "title": {
                "fragments": [],
                "text": "Evolutionary Pursuit and Its Application to Face Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "EP has better recognition performance than PCA (eigenfaces) and better generalization abilities than the Fisher linear discriminant (Fisherfaces)."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39664966"
                        ],
                        "name": "C. Liu",
                        "slug": "C.-Liu",
                        "structuredName": {
                            "firstName": "Chengjun",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143979395"
                        ],
                        "name": "H. Wechsler",
                        "slug": "H.-Wechsler",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wechsler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wechsler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14213505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5636a8021c09870c350e7505c87625fe1681bd4",
            "isKey": false,
            "numCitedBy": 277,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a new face coding and recognition method, the enhanced Fisher classifier (EFC), which employs the enhanced Fisher linear discriminant model (EFM) on integrated shape and texture features. Shape encodes the feature geometry of a face while texture provides a normalized shape-free image. The dimensionalities of the shape and the texture spaces are first reduced using principal component analysis, constrained by the EFM for enhanced generalization. The corresponding reduced shape and texture features are then combined through a normalization procedure to form the integrated features that are processed by the EFM for face recognition. Experimental results, using 600 face images corresponding to 200 subjects of varying illumination and facial expressions, show that (1) the integrated shape and texture features carry the most discriminating information followed in order by textures, masked images, and shape images, and (2) the new coding and face recognition method, EFC, performs the best among the eigenfaces method using L(1) or L(2) distance measure, and the Mahalanobis distance classifiers using a common covariance matrix for all classes or a pooled within-class covariance matrix. In particular, EFC achieves 98.5% recognition accuracy using only 25 features."
            },
            "slug": "A-shape-and-texture-based-enhanced-Fisher-for-face-Liu-Wechsler",
            "title": {
                "fragments": [],
                "text": "A shape- and texture-based enhanced Fisher classifier for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The new coding and face recognition method, EFC, performs the best among the eigenfaces method using L(1) or L(2) distance measure, and the Mahalanobis distance classifiers using a common covariance matrix for all classes or a pooled within-class covariance Matrix."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299972"
                        ],
                        "name": "I. Biederman",
                        "slug": "I.-Biederman",
                        "structuredName": {
                            "firstName": "Irving",
                            "lastName": "Biederman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Biederman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 1
                            }
                        ],
                        "text": "[Bie\u00adderman 1987; Hill et al. 1997; Tarr and Bulthoff 1995]: Much work in vi\u00adsual object \nrecognition (e.g. [Biederman 1987]) has been cast within a theo\u00adretical framework introduced in [Marr \n1982] in which different views of ob\u00adjects are analyzed in a way which allows access to (largely)\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": ", [24]) has been cast within a theoretical framework introduced by Marr [25] in which di erent views of objects are analyzed in a way which allows access to (largely) viewpoint-invariant descriptions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 140
                            }
                        ],
                        "text": "These two problems have been documented in many evaluations of FRT systems [4, 181] and in the divided opinions of the psychology community [24, 23, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 32
                            }
                        ],
                        "text": "Viewpoint-invariant recognition?[23, 24]: Much work in visual object recognition (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8054340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b37258659bcdbc380b1e6c4e22cce9ea06397a1",
            "isKey": true,
            "numCitedBy": 5632,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "The perceptual recognition of objects is conceptualized to be a process in which the image of the input is segmented at regions of deep concavity into an arrangement of simple geometric components, such as blocks, cylinders, wedges, and cones. The fundamental assumption of the proposed theory, recognition-by-components (RBC), is that a modest set of generalized-cone components, called geons (N \u00a3 36), can be derived from contrasts of five readily detectable properties of edges in a two-dimensiona l image: curvature, collinearity, symmetry, parallelism, and cotermination. The detection of these properties is generally invariant over viewing position an$ image quality and consequently allows robust object perception when the image is projected from a novel viewpoint or is degraded. RBC thus provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition: The constraints toward regularization (Pragnanz) characterize not the complete object but the object's components. Representational power derives from an allowance of free combinations of the geons. A Principle of Componential Recovery can account for the major phenomena of object recognition: If an arrangement of two or three geons can be recovered from the input, objects can be quickly recognized even when they are occluded, novel, rotated in depth, or extensively degraded. The results from experiments on the perception of briefly presented pictures by human observers provide empirical support for the theory. Any single object can project an infinity of image configurations to the retina. The orientation of the object to the viewer can vary continuously, each giving rise to a different two-dimensional projection. The object can be occluded by other objects or texture fields, as when viewed behind foliage. The object need not be presented as a full-colored textured image but instead can be a simplified line drawing. Moreover, the object can even be missing some of its parts or be a novel exemplar of its particular category. But it is only with rare exceptions that an image fails to be rapidly and readily classified, either as an instance of a familiar object category or as an instance that cannot be so classified (itself a form of classification)."
            },
            "slug": "Recognition-by-components:-a-theory-of-human-image-Biederman",
            "title": {
                "fragments": [],
                "text": "Recognition-by-components: a theory of human image understanding."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Recognition-by-components (RBC) provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160279"
                        ],
                        "name": "P. Hancock",
                        "slug": "P.-Hancock",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hancock",
                            "middleNames": [
                                "J.",
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hancock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144975752"
                        ],
                        "name": "V. Bruce",
                        "slug": "V.-Bruce",
                        "structuredName": {
                            "firstName": "Vicki",
                            "lastName": "Bruce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Bruce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052767688"
                        ],
                        "name": "M. Burton",
                        "slug": "M.-Burton",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Burton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 104
                            }
                        ],
                        "text": "On the other hand, machine systems provide tools for conducting studies \nin psychology and neuroscience [Hancock et al. 1998; Kalocsai et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6222965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c2fe5997a5570720bac2ab5ce187f1bd2aed1e7",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-comparison-of-two-computer-based-face-systems-of-Hancock-Bruce",
            "title": {
                "fragments": [],
                "text": "A comparison of two computer-based face identification systems with human perceptions of faces"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145314289"
                        ],
                        "name": "J. Strom",
                        "slug": "J.-Strom",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Strom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Strom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768120"
                        ],
                        "name": "T. Jebara",
                        "slug": "T.-Jebara",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Jebara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jebara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8611534"
                        ],
                        "name": "S. Basu",
                        "slug": "S.-Basu",
                        "structuredName": {
                            "firstName": "Sumit",
                            "lastName": "Basu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Basu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6911600,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91440c25c776f1330f485ba78e6e9233d1290a7b",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A real-time system for tracking and modeling of faces using an analysis-by-synthesis approach is presented. A 3D face model is texture-mapped with a head-on view of the face. Feature points in the face-texture are then selected based on image Hessians. The selected points of the rendered image are tracked in the incoming video using normalized correlation. The result is fed into an extended Kalman filter to recover camera geometry, head pose, and structure from motion. This information is used to rigidly move the face model to render the next image needed for tracking. Every point is tracked from the Kalman filter's estimated position. The variance of each measurement is estimated using a number of factors, including the residual error and the angle between the surface normal and the camera. The estimated head pose can be used to warp the face in the incoming video back to frontal position, and parts of the image can then be subject to eigenspace coding for efficient transmission. The mouth texture is transmitted in this way using 50 bits per frame plus overhead from the person specific eigenspace. The face tracking system runs at 30 Hz, coding the mouth texture slows it down to 12 Hz."
            },
            "slug": "Real-time-tracking-and-modeling-of-faces:-an-by-Strom-Jebara",
            "title": {
                "fragments": [],
                "text": "Real time tracking and modeling of faces: an EKF-based analysis by synthesis approach"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A real-time system for tracking and modeling of faces using an analysis-by-synthesis approach is presented, which can be used to warp the face in the incoming video back to frontal position, and parts of the image can then be subject to eigenspace coding for efficient transmission."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE International Workshop on Modelling People. MPeople'99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50024179"
                        ],
                        "name": "Yongmin Li",
                        "slug": "Yongmin-Li",
                        "structuredName": {
                            "firstName": "Yongmin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongmin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144784813"
                        ],
                        "name": "S. Gong",
                        "slug": "S.-Gong",
                        "structuredName": {
                            "firstName": "Shaogang",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2934996"
                        ],
                        "name": "H. Liddell",
                        "slug": "H.-Liddell",
                        "structuredName": {
                            "firstName": "Heather",
                            "lastName": "Liddell",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Liddell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 135
                            }
                        ],
                        "text": "Newly de\u00adveloped segmentation methods \nlocate the face and estimate its pose simultaneously without extracting features [Gu et al. 2001; Li \net al. 2001b]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 38
                            }
                        ],
                        "text": "These meth\u00adods [Li and Chellappa \n2001; Li et al. 2001a] coherently exploit both spatial in\u00adformation (in each frame) and temporal in\u00adformation \n(such as the trajectories of fa\u00adcial features)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 78
                            }
                        ],
                        "text": "1999] Spatiotemporal methods Feature trajectory-based [Li and Chellappa 2001; Li et al. 2001a] Video-to \nvideo methods [Zhou et al. 2003] while Strom et al. [1999] tracked only points with high Hessian values."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 99
                            }
                        ],
                        "text": "Tracking also plays a key role in spatiotemporal-based recognition methods [Li and Chellappa 2001; Li \net al. 2001a] which directly use the tracking in\u00adformation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 34
                            }
                        ],
                        "text": "The multiview dy\u00adnamic face model [Li et al. \n2001b] con\u00adsists of a sparse Point Distribution Model (PDM) [Cootes et al. 1995], a shape-and\u00adpose-free \ntexture model, and an af.ne ge\u00adometrical model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14345080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7a74278d282308e668dd574aa1ff97067a463a8",
            "isKey": true,
            "numCitedBy": 30,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "A comprehensive novel multi-view dynamic face model is presented in this paper to address two challenging problems in face recognition and facial analysis: modelling faces with large pose variation and modelling faces dynamically in video sequences. The model consists of a sparse 3D shape model learnt from 2D images, a shape-and-pose-free texture model, and an affine geometrical model. Model fitting is performed by optimising (1) a global fitting criterion on the overall face appearance while it changes across views and over time, (2) a local fitting criterion on a set of landmarks, and (3) a temporal fitting criterion between successive frames in a video sequence. By temporally estimating the model parameters over a sequence input, the identity and geometrical information of a face is extracted separately. The former is crucial to face recognition and facial analysis. The latter is used to aid tracking and aligning faces. We demonstrate the results of successfully applying this model on faces with large variation of pose and expression over time."
            },
            "slug": "Modelling-faces-dynamically-across-views-and-over-Li-Gong",
            "title": {
                "fragments": [],
                "text": "Modelling faces dynamically across views and over time"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A comprehensive novel multi-view dynamic face model is presented in this paper to address two challenging problems in face recognition and facial analysis: modelling faces with large pose variation and modelling faces dynamically in video sequences."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50024179"
                        ],
                        "name": "Yongmin Li",
                        "slug": "Yongmin-Li",
                        "structuredName": {
                            "firstName": "Yongmin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongmin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144784813"
                        ],
                        "name": "S. Gong",
                        "slug": "S.-Gong",
                        "structuredName": {
                            "firstName": "Shaogang",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2934996"
                        ],
                        "name": "H. Liddell",
                        "slug": "H.-Liddell",
                        "structuredName": {
                            "firstName": "Heather",
                            "lastName": "Liddell",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Liddell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 48
                            }
                        ],
                        "text": "Spatiotemporal methods Feature trajectory-based [Li and Chellappa 2001; Li et al. 2001a]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 14
                            }
                        ],
                        "text": "These methods [Li and Chellappa 2001; Li et al. 2001a] coherently exploit both spatial information (in each frame) and temporal information (such as the trajectories of facial features)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 75
                            }
                        ],
                        "text": "Tracking also plays a key role in spatiotemporal-based recognition methods [Li and Chellappa 2001; Li et al. 2001a] which directly use the tracking information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7500278,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ba5bb30e37928de7276faf571449dc02ee3e375",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Recognising face with large pose variation is more challenging than that in a fixed view, e.g. frontal-view, due to the severe non-linearity caused by rotation in depth, self-shading and self-occlusion. To address this problem, a multi-view dynamic face model is designed to extract the shape-and-pose-free facial texture patterns from multi-view face images. Kernel Discriminant Analysis is developed to extract the significant non-linear discriminating features which maximise the between-class variance and minimise the within-class variance. By using the kernel technique, this process is equivalent to a Linear Discriminant Analysis in a high-dimensional feature space which can be solved conveniently. The identity surfaces are then constructed from these non-linear discriminating features. Face recognition can be performed dynamically from an image sequence by matching an object trajectory and model trajectories on the identity surfaces."
            },
            "slug": "Constructing-facial-identity-surfaces-in-a-space-Li-Gong",
            "title": {
                "fragments": [],
                "text": "Constructing facial identity surfaces in a nonlinear discriminating space"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Kernel Discriminant Analysis is developed to extract the significant non-linear discriminating features which maximise the between- class variance and minimise the within-class variance in multi-view face images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98789412"
                        ],
                        "name": "Johan Stephen Simeon Ballot",
                        "slug": "Johan-Stephen-Simeon-Ballot",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Ballot",
                            "middleNames": [
                                "Stephen",
                                "Simeon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johan Stephen Simeon Ballot"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17856109,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "320d6e79fa184dcf24c30232ab762d29f7e3d9c6",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Face recognition using Hidden Markov Models J.S.S. Ballot Department of Electrical & Electronic Engineering University of Stellenbosch Private Bag X1, 7602 Matieland, South Africa Thesis: MScEng (E&E + CS) April 2005 This thesis relates to the design, implementation and evaluation of statistical face recognition techniques. In particular, the use of Hidden Markov Models in various forms is investigated as a recognition tool and critically evaluated. Current face recognition techniques are very dependent on issues like background noise, lighting and position of key features (ie. the eyes, lips etc.). Using an approach which specifically uses an embedded Hidden Markov Model along with spectral domain feature extraction techniques, shows that these dependencies may be lessened while high recognition rates are maintained."
            },
            "slug": "Face-recognition-using-Hidden-Markov-Models-Ballot",
            "title": {
                "fragments": [],
                "text": "Face recognition using Hidden Markov Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Using an approach which specifically uses an embedded Hidden Markov Model along with spectral domain feature extraction techniques, shows that these dependencies may be lessened while high recognition rates are maintained."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40302807"
                        ],
                        "name": "G. Gordon",
                        "slug": "G.-Gordon",
                        "structuredName": {
                            "firstName": "Gaile",
                            "lastName": "Gordon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gordon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820595"
                        ],
                        "name": "L. Vincent",
                        "slug": "L.-Vincent",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Vincent",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vincent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "In related work [82], the process of nding the features was formalized for recognition purposes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18856734,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "252565c20476feba5f304afee620cd0e29e1060a",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of morphological operators for feature extraction in range images and curvature maps of the human face. Two general procedures are described. The first is the identification of connected part boundaries for convex structures, which is used to extract the nose outline and the eye socket outlines of the face. The part boundaries are defined locally based on minima of minimum principal curvature on the surface. The locus of these points suggests boundary lines which surround most convex regions on the surface. However, most of these boundaries are not completely connected. To remedy this problem, a general two-step connection procedure is developed: the partial boundaries are first dilated in such a way that the gaps between them are filled. Second, the resulting dilated outlines are skeletonized with the constraint that the pixels belonging to the original boundary parts cannot be removed. A marker which identifies the convex region being described is then used to select the region enclosed by the new connected outline. Examples are given of this procedure in the extraction of the nose boundary and eye socket boundary. The second general procedure discussed is the identification of connected ridge lines, which is demonstrated in the extraction of the browline and the chin/jaw line. Ridge lines are defined as local maxima of maximum curvature in the direction of maximum curvature. The same skeleton-based procedure as above is first used to connect the ridge lines. Skeletonization is then used again to reduce these lines to simply connected ones. The last step primarily consists in extracting the longest path within the obtained components: this is achieved by using the propagation function to find the extremities of these paths and then connecting them within the components by means of geodesic distance functions. The entire process provides a robust and accurate extraction of brow and chin/jaw lines."
            },
            "slug": "Application-of-morphology-to-feature-extraction-for-Gordon-Vincent",
            "title": {
                "fragments": [],
                "text": "Application of morphology to feature extraction for face recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2880906"
                        ],
                        "name": "V. Blanz",
                        "slug": "V.-Blanz",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Blanz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Blanz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 46
                            }
                        ],
                        "text": "21One exception is a recent report [Blanz and Vetter 2003] where faces were represented \nusing 4448 im\u00adages from the CMU-PIE databases and 1940 images from the FERET database."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 908514,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d66c98009018ac1512047e6bdfb525c35683b16",
            "isKey": false,
            "numCitedBy": 2116,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for face recognition across variations in pose, ranging from frontal to profile views, and across a wide range of illuminations, including cast shadows and specular reflections. To account for these variations, the algorithm simulates the process of image formation in 3D space, using computer graphics, and it estimates 3D shape and texture of faces from single images. The estimate is achieved by fitting a statistical, morphable model of 3D faces to images. The model is learned from a set of textured 3D scans of heads. We describe the construction of the morphable model, an algorithm to fit the model to images, and a framework for face identification. In this framework, faces are represented by model parameters for 3D shape and texture. We present results obtained with 4,488 images from the publicly available CMU-PIE database and 1,940 images from the FERET database."
            },
            "slug": "Face-Recognition-Based-on-Fitting-a-3D-Morphable-Blanz-Vetter",
            "title": {
                "fragments": [],
                "text": "Face Recognition Based on Fitting a 3D Morphable Model"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This paper presents a method for face recognition across variations in pose, ranging from frontal to profile views, and across a wide range of illuminations, including cast shadows and specular reflections, using computer graphics."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 99
                            }
                        ],
                        "text": "Compared to feature-based methods and template-matching \nmethods, appearance\u00ador image-based methods [Rowley et al. 1998; Sung and Poggio 1997] that train machine \nsystems on large numbers of samples have achieved the best results."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 107
                            }
                        ],
                        "text": "Treating face detection as a two-class classi.cation problem helps to reduce false positives \ndramatically [Rowley et al. 1998; Sung and Poggio 1997] while maintaining true positives."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1619589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2fd1c99edbb3d22cec4adc9ba9319cfc2360e903",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a neural network-based face detection system. Unlike similar systems which are limited to detecting upright, frontal faces, this system detects faces at any degree of rotation in the image plane. The system employs multiple networks; a \"router\" network first processes each input window to determine its orientation and then uses this information to prepare the window for one or more \"detector\" networks. We present the training methods for both types of networks. We also perform sensitivity analysis on the networks, and present empirical results on a large test set. Finally, we present preliminary results for detecting faces rotated out of the image plane, such as profiles and semi-profiles."
            },
            "slug": "Rotation-invariant-neural-network-based-face-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Rotation invariant neural network-based face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper presents a neural network-based face detection system, which is limited to detecting upright, frontal faces, and presents preliminary results for detecting faces rotated out of the image plane, such as profiles and semi-profiles."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38480590"
                        ],
                        "name": "Wenyi Zhao",
                        "slug": "Wenyi-Zhao",
                        "structuredName": {
                            "firstName": "Wenyi",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyi Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2030268"
                        ],
                        "name": "A. Krishnaswamy",
                        "slug": "A.-Krishnaswamy",
                        "structuredName": {
                            "firstName": "Arvindh",
                            "lastName": "Krishnaswamy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krishnaswamy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "Using tree-structure learning, \nthe eigenspace and LDA projections are recursively applied to smaller and smaller sets of samples."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "Experiments were performed on a database of 500 images created by Hallinan \n[1994] and a sequential PCA and LDA projections; these three bases are shown for visual comparison in \nFigure 6. database of 176 images created at Yale."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "Baseline algorithms available are PCA, LDA, elastic \nbunch graph matching, and Bayesian Intrap\u00adersonal/Extrapersoanl Image Diffference Classi.er."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 155
                            }
                        ],
                        "text": "The best re\u00adsults of FA and FR on the test data (FA/FR: \n2.3%/2.5% and 1.2%/1.0% for evaulation con.gurations I and II, respectively) were obtained using an LDA \nalgorithm with a non-Euclidean metric (University of Sur\u00adrey) when the threshold was set so that FA was \nequal to FB on the evaulation re\u00adsult."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 172
                            }
                        ],
                        "text": "Among appearance-based holistic approaches, \neigenfaces [Kirby and Sirovich 1990; Turk and Pentland 1991] and Fisher\u00adfaces [Belhumeur et al. 1997; \nEtemad and Chellappa 1997; Zhao et al. 1998] have proved to be effective in experiments with large databases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 501,
                                "start": 498
                            }
                        ],
                        "text": "Using principal-component \nanalysis (PCA), many face recognition techniques have been developed: eigenfaces [Turk and Pentland 1991], \nwhich use a nearest\u00adneighbor classi.er; feature-line-based methods, which replace the point-to-point \ndistance with the distance between a point and the feature line linking two stored sample points [Li \nand Lu 1999]; Fisher\u00adfaces [Belhumeur et al. 1997; Liu and Wechsler 2001; Swets and Weng 1996b; Zhao \net al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA) [Fisher 1938]; Bayesian methods, \nwhich use a probabilistic distance metric [Moghaddam and Pentland 1997]; and SVM methods, which use a \nsupport vector machine as the classi.er [Phillips 1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "The neural network method based on Elastic Bunch Graph Matching [79], the statistical method based on subspace LDA [60], and the probabilistic PCA method [33] were adjudged to be among the top three, with each method showing di erent levels of performance on di erent subsets of sequestered images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 265
                            }
                        ],
                        "text": "Four methods \nwere compared in this pa\u00adper: (1) a correlation-based method, (2) a variant of the linear subspace method \nsug\u00adgested in Shashua [1994], (3) an eigenface method Turk and Pentland [1991], and (4) a Fisherface \nmethod which uses subspace projection prior to LDA projection to avoid the possible singularity in Sw \nas in Swets and Weng [1996b]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Experimental re\u00adsults using images/videos collected at UMD, NIST/USF, and CMU with pose/illumination \nvariations have illus\u00adtrated the effectiveness of this approach in both still-to-video and video-to-video \nscenarios with appropriate model choices."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "PCA versus LDA."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 64
                            }
                        ],
                        "text": "The EBGM sys\u00adtem [Wiskott et al. 1997], the subspace \nLDA system [Zhao et al. 1998], and the probabilistic eigenface system [Moghad\u00addam and Pentland 1997] \nwere judged to be among the top three, with each method showing different levels of performance on different \nsubsets of sequestered images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 120
                            }
                        ],
                        "text": "Face recognition systems using Linear/Fisher Discriminant Analysis [55] as the classi er have also been very successful [56, 57, 58, 59, 60, 61, 62, 63]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 167
                            }
                        ],
                        "text": "The authors selected the dimension\u00adality of the universal face subspace based on the \ncharacteristics of the eigenvectors (face-like or not) instead of the eigenval\u00adues [Zhao et al. 1998], \nas is commonly done."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 147
                            }
                        ],
                        "text": "\u2026analysis\u00adbased \nalgorithms from Michigan State University [Swets and Weng 1996b] (Sept. 1996) and the University of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997); a gray-scale projection algorithm \nfrom Rutgers University [Wilder 1994] (Sept. 1996); an\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 150
                            }
                        ],
                        "text": "\u2026and the feature line linking two stored sample points [Li \nand Lu 1999]; Fisher\u00adfaces [Belhumeur et al. 1997; Liu and Wechsler 2001; Swets and Weng 1996b; Zhao \net al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA) [Fisher 1938]; Bayesian methods, \nwhich use a probabilistic distance\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 359,
                                "start": 356
                            }
                        ],
                        "text": "Categorization of Still Face Recognition Techniques Approach Representative work Holistic \nmethods Principal-component analysis (PCA) Eigenfaces Direct application of PCA [Craw and Cameron 1996; \nKirby and Sirovich 1990; Turk and Pentland 1991] Probabilistic eigenfaces Two-class problem with prob. \nmeasure [Moghaddam and Pentland 1997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and Wechsler 2000a] Feature lines Point-to-line distance based [Li \nand Lu 1999] ICA ICA-based feature analysis [Bartlett et al. 1998] Other representations LDA/FLD LDA/FLD \non raw image [Etemad and Chellappa 1997] PDBNN Probabilistic decision based NN [Lin et al. 1997] Feature-based \nmethods Pure geometry methods Earlier methods [Kanade 1973; Kelly 1970]; recent methods [Cox et al. 1996; \nManjunath et al. 1992] Dynamic link architecture Graph matching methods [Okada et al. 1998; Wiskott et \nal."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 126
                            }
                        ],
                        "text": "Three of the algorithms performed very well: probabilistic eigenface from MIT [Moghaddam et al. 1996], \nsub\u00adspace LDA from UMD [Zhao et al. 1998, 1999], and Elastic Graph Matching from USC [Wiskott et al. \n1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 37
                            }
                        ],
                        "text": "1996) and the University of Maryland [59, 60] (Sept."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "At least one of the following three characteristics separates this system \nfrom other LDA\u00adbased systems: (1) the unique selection of the universal face subspace dimension, (2) \nthe use of a weighted distance mea\u00adsure, and (3) a regularized procedure that modi.es the within-class \nscatter matrix Sw."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 93
                            }
                        ],
                        "text": "On the other hand, if only one or two samples are available per class \n(a degenerate case for LDA), PCA is a better choice."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "Improved \nrecognition results based on subspace LDA [Zhao et al. 1999] were reported on a small database consist\u00ading \nof frontal and quasipro.le images of 115 novel objects (size 48\u00d742)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 143
                            }
                        ],
                        "text": "Face recognition systems using LDA/FLD have also been very suc\u00adcessful [Belhumeur et al. 1997; \nEtemad and Chellappa 1997; Swets and Weng 1996b; Zhao et al. 1998; Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 145
                            }
                        ],
                        "text": "\u2026problem with prob. \nmeasure [Moghaddam and Pentland 1997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and Wechsler 2000a] Feature\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "Another issue is when to use \nPCA and when to use LDA in building a system."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "However, for veri.cation, \nthe equal error rates were 2% and 14% for USC, and 1% and 12% for UMD."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 89
                            }
                        ],
                        "text": "In McKenna and Gong [1998], this work was extended to person authentication \nusing PCA or LDA."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 101
                            }
                        ],
                        "text": "In the extreme case where only one sample per class is available, this regularization \ntransforms the LDA prob\u00adlem into a standard PCA problem with Sb being the covariance matrix C. Applying \nthis approach, without retraining the LDA basis, to a testing/probe set of 46 individ\u00aduals of which 24 \nwere trained and 22 were not trained (a total of 115 images including 19 untrained images of nonfrontal \nviews), the authors reported the following perfor\u00admance based on a front-view-only gallery database of \n738 images: 85.2% for all im\u00adages and 95.1% for frontal views."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 180
                            }
                        ],
                        "text": "Good generalization ability of this system was demonstrated by ex\u00adperiments that carried \nout testing on new classes/individuals without retraining the PCA bases  , and sometimes the LDA bases \nW ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 45
                            }
                        ],
                        "text": "For a more de\u00adtailed comparison of PCA versus LDA, \nsee Beveridge et al. [2001]; Martinez and Kak [2001]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 126
                            }
                        ],
                        "text": "However, it has been demonstrated that the image size can be very small for holistic face recognition: \n12 \u00d7 11 for the subspace LDA system [Zhao et al. 1999], 14\u00d710 for the PDBNN system [Lin et al. 1997], \nand 18 \u00d7 24 for human percep\u00adtion [Bachmann 1991]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 364,
                                "start": 361
                            }
                        ],
                        "text": "There were twelve algorithms from four partipicants \nin this contest [Matas et al. 2000]: an EBGM algorithm from IDIAP (Daller Molle Institute for Per\u00adceptual \nArti.cial Intelligence), a slightly modi.ed EBGM algorithm from Aristo\u00adtle University of Thessaloniki, \na FND\u00adbased (Fractal Neighbor Distance) algo\u00adrithm from the University of Sydney, and eight variants \nof LDA algorithms and one SVM algorithm from the University of Surrey."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 149
                            }
                        ],
                        "text": "Using the Yale and Weizmann databases (Table V), signi.cant performance im\u00adprovements were reported when \nthe pro\u00adtotype images were used in a subspace LDA system in place of the original in\u00adput images [Zhao \net al. 1999]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "LDA training is \ncarried out via scatter matrix analysis [Fukunaga 1989]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "For LDA algorithms, the distance can be unweighted or weighted."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "Apparently, when the number of training samples per class \nis large, LDA is the best choice."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 280
                            }
                        ],
                        "text": "In all these projection al\u00adgorithms, classi.cation \nis performed by (1) projecting the input x into a subspace via a projection/basis matrix Proj 6: total \ncovariance C used to compute the PCA projec\u00adtion is C = M Pr(.i )Ci. i=1 6Proj is < for eigenfaces, W \nfor Fisherfaces with pure LDA projection, and W < for Fisherfaces with z = Proj x; (4) (2) comparing \nthe projection coef.cient vector z of the input to all the prestored projection vectors of labeled classes \nto determine the input class label."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "One way to unify PCA and LDA is to use regularized \nsubspace LDA [Zhao et al. 1999]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "8Weighted metrics have also been used in the pure LDA approach [Etemad and Chellappa \n1997] and the Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 130
                            }
                        ],
                        "text": "The choice of such a xed subspace dimension is mainly based on the characteristics of the eigenvectors instead of the eigenvalues [60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "On the other hand, the \nsubspace LDA method [Zhao et al. 1999] works well for both large and small images, for example, 96 \u00d7 \n84 or 12 \u00d7 11."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "A weighted distance metric \nin the pro\u00adjection space z was used to improve per\u00adformance [Zhao 1999].8 Finally, the LDA 7This makes \nsense because the .nal classi.cation is carried out in the projection space z by comparison with prestored \nprojection vectors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 196
                            }
                        ],
                        "text": "The series of tests has allowed advances in algorithm de\u00advelopment to \nbe quanti.ed for exam\u00adple, the performance improvements in the MIT algorithms between March 1995 and \nSeptember 1996, and in the UMD al\u00adgorithms between September 1996 and March 1997."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 129
                            }
                        ],
                        "text": "While the reason for not re\u00adtraining PCA is obvious, it is interesting to test the adaptive capability \nof the sys\u00adtem by .xing the LDA bases when im\u00adages from new classes are added.7 The .xed PCA subspace \nof dimensionality 300 was trained from a large number of sam\u00adples."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 107
                            }
                        ],
                        "text": "Three of the algorithms performed very well: Probabilistic Eigenface from MIT [169], Subspace LDA from UMD [60, 63], and Elastic Graph Matching from USC [79]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "For identi.cation, on the fb and duplicate \nprobes, the USC scores were 94% and 59%, and the UMD scores were 96% and 47%."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 182
                            }
                        ],
                        "text": "In a recent comprehensive FERET evaluation [3, 4, 5, 6], aimed at evaluating di erent systems using the same, large database containing thousands of images, the systems described in [33, 44, 56, 60, 79], as well as others were evaluated."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "To improve the performance of LDA\u00adbased \nsystems, a regularized subspace LDA system that uni.es PCA and LDA was proposed in Zhao [1999] and Zhao \net al. [1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 195
                            }
                        ],
                        "text": "The .rst row shows the .rst .ve pure LDA basis images \nW ; the second row shows the .rst .ve subspace LDA basis images W <; the average face and .rst four eigenfaces \n< are shown on the third row [Zhao et al. 1998].  their respective means mi: Ci =E[(x(.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7032646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8e6580749e9cd3eebf7f9b95b58645c23d043ea",
            "isKey": false,
            "numCitedBy": 628,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a face recognition method based on PCA (Principal Component Analysis) and LDA (Linear Discriminant Analysis). The method consists of two steps: first we project the face image from the original vector space to a face subspace via PCA, second we use LDA to obtain a best linear classifier. The basic idea of combining PCA and LDA is to improve the generalization capability of LDA when only few samples per class are available. Using PCA, we are able to construct a face subspace in which we apply LDA to perform classification. Using FERET dataset we demonstrate a significant improvement when principal components rather than original images are fed to the LDA classifier. The hybrid classifier using PCA and LDA provides a useful framework for other image recognition tasks as well."
            },
            "slug": "Discriminant-analysis-of-principal-components-for-Zhao-Chellappa",
            "title": {
                "fragments": [],
                "text": "Discriminant analysis of principal components for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A hybrid classifier using PCA and LDA provides a useful framework for other image recognition tasks as well and demonstrates a significant improvement when principal components rather than original images are fed to the LDA classifier."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801638"
                        ],
                        "name": "J. Kittler",
                        "slug": "J.-Kittler",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Kittler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kittler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32866621"
                        ],
                        "name": "K. Jonsson",
                        "slug": "K.-Jonsson",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Jonsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Jonsson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13939344,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70fb70918a82353a6fe110406b49a0322e07ff72",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel person veriication system for real-time face identiication. The main features of the system include accurate registration of face images using a robust form of correlation, a framework for global registration of a face database using a minimum spanning tree algorithm and a method for selecting a subset of features optimal for discrimination between clients and impostors. We present results obtained through experiments on a large database with 295 subjects and show that the method is performing well in comparison with two standard methods based on elastic graph matching."
            },
            "slug": "Learning-Salient-Features-for-Real-Time-Face-Kittler-Matas",
            "title": {
                "fragments": [],
                "text": "Learning Salient Features for Real-Time Face Verification"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A novel person veriication system for real-time face identiication using a robust form of correlation, a framework for global registration of a face database using a minimum spanning tree algorithm and a method for selecting a subset of features optimal for discrimination between clients and impostors."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145668226"
                        ],
                        "name": "S. Zhou",
                        "slug": "S.-Zhou",
                        "structuredName": {
                            "firstName": "Shaohua",
                            "lastName": "Zhou",
                            "middleNames": [
                                "Kevin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48378203"
                        ],
                        "name": "V. Kr\u00fcger",
                        "slug": "V.-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Kr\u00fcger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kr\u00fcger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 179
                            }
                        ],
                        "text": "While most face recognition algorithms take \nstill images as probe inputs, a video\u00adbased face recognition approach that takes video sequences as inputs \nhas recently been developed [Zhou et al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 119
                            }
                        ],
                        "text": "1999] Spatiotemporal methods Feature trajectory-based [Li and Chellappa 2001; Li et al. 2001a] Video-to \nvideo methods [Zhou et al. 2003] while Strom et al. [1999] tracked only points with high Hessian values."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 178
                            }
                        ],
                        "text": "While most face recognition algorithms take still images as probe inputs, a videobased face recognition approach that takes video sequences as inputs has recently been developed [Zhou et al. 2003]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10785532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a7877effc33e4d9bff0c7251f8772f06982d779",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Most present face recognition approaches recognize faces based on still images. We present a novel approach to recognize faces in video. In that scenario, the face gallery may consist of still images or may be derived from a videos. For evidence integration we use classical Bayesian propagation over time and compute the posterior distribution using sequential importance sampling. The probabilistic approach allows us to handle uncertainties in a systematic manner. Experimental results using videos collected by NIST/USF and CMU illustrate the effectiveness of this approach in both still-to-video and video-to-video scenarios with appropriate model choices."
            },
            "slug": "Probabilistic-recognition-of-human-faces-from-video-Zhou-Kr\u00fcger",
            "title": {
                "fragments": [],
                "text": "Probabilistic recognition of human faces from video"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A novel approach to recognize faces in video using classical Bayesian propagation over time and the probabilistic approach to handle uncertainties in a systematic manner is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. International Conference on Image Processing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055501916"
                        ],
                        "name": "Thomas Maurer",
                        "slug": "Thomas-Maurer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Maurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Maurer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 35
                            }
                        ],
                        "text": "After face pose is estimated as in [129], a virtual frontal face can be synthesized, so that the performance of face recognition can be improved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 192
                            }
                        ],
                        "text": "To handle the pose variation problem, the pose of the face is .rst \ndetermined using prior class infor\u00admation [Kruger et al. 1997], and the jet transformations under pose \nvariation are learned [Maurer and Malsburg 1996a]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 35
                            }
                        ],
                        "text": "A face tracking system was used in [129] to estimate the pose of the face."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17312452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce5f297cb037b2101da175344e2597a52c0e5908",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate a system capable of tracking in real world image sequences, landmarks such as eyes, mouth, or chin on a face. In the standard version, knowledge previously collected about faces is used for finding the landmarks in the first frame. In a second version, the system is able to track the face without any prior knowledge about faces and is thus applicable to other object classes. By using Gabor filters as visual features, and by both avoiding limiting assumptions and many parameters our tracking tool is simple and easy to use. As a first application the tracking results are used to estimate the pose of a face."
            },
            "slug": "Tracking-and-learning-graphs-and-pose-on-image-of-Maurer-Malsburg",
            "title": {
                "fragments": [],
                "text": "Tracking and learning graphs and pose on image sequences of faces"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A system capable of tracking in real world image sequences, landmarks such as eyes, mouth, or chin on a face, and is applicable to other object classes by using Gabor filters as visual features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116478939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0075fa2e7d8f341f497e6a6fa126b9afa6396a34",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis addresses the problem of visual recognition under two sources of variability: geometric and photometric. The geometric deals with the relation between 3D objects and their views under parallel, perspective, and central projection. The photometric deals with the relation between 3D matte objects and their images under changing illumination conditions. Taken together, an alignment-based method is presented for recognizing objects viewed from arbitrary viewing positions and illuminated by arbitrary settings of light sources. \nIn the first part of the thesis we show that a relative non-metric structure invariant that holds under both parallel and central projection models can be defined relative to four points in space and, moreover, can be uniquely recovered from two views regardless of whether one or the other was created by means of parallel or central projection. As a result, we propose a method that is useful for purposes of recognition (via alignment) and structure from motion, and that has the following properties: (i) the transition between projection models is natural and transparent, (ii) camera calibration is not required, and (iii) structure is defined relative to the object and does not involve the center of projection. \nThe second part of this thesis addresses the photometric aspect of recognition under changing illumination. First, we argue that image properties alone do not appear to be generally sufficient for dealing with the effects of changing illumination; we propose a model-based approach instead. Second, we observe that the process responsible for factoring out the illumination during the recognition process appears to require more than just contour information, but just slightly more. Taken together, we introduce a model-based alignment method that compensates for the effects of changing illumination by linearly combining model images of the object. The model images, each taken from a different illumination condition, can be converted onto novel images of the object regardless of whether the image is represented by grey-values, sign-bits, or other forms of reduced representations. \nThe third part of this thesis addresses the problem of achieving full correspondence between model views and puts together the geometric and photometric components into a single recognition system. The method for achieving correspondence is based on combining affine or projective geometry and optical flow techniques into a single working framework. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)"
            },
            "slug": "Geometry-and-photometry-in-three-dimensional-visual-Shashua-Ullman",
            "title": {
                "fragments": [],
                "text": "Geometry and photometry in three-dimensional visual recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A model-based alignment method that compensates for the effects of changing illumination by linearly combining model images of the object and the method for achieving correspondence is based on combining affine or projective geometry and optical flow techniques into a single working framework."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38995786"
                        ],
                        "name": "S. Pigeon",
                        "slug": "S.-Pigeon",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Pigeon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pigeon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698047"
                        ],
                        "name": "L. Vandendorpe",
                        "slug": "L.-Vandendorpe",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Vandendorpe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vandendorpe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 67
                            }
                        ],
                        "text": "The XM2VTS database is an expan\u00adsion of the earlier M2VTS database [Pigeon and Vandendorpe \n1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 66
                            }
                        ],
                        "text": "The XM2VTS database is an expansion of the earlier M2VTS database [174]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 45537808,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75898aaf072431a4355b5c86ad6c53c004e55787",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The primary goal of the M2VTS project is to address the issue of secured access to buildings or multi-media services by the use of automatic person verification based on multimodal strategies (secured access based on speech, face images and other information). This paper presents an overview of the multimodal face database recorded at UCL premises for the purpose of research applications inside the M2VTS project. This database offers synchronized video and speech data as well as image sequences allowing to access multiple views of a face. This material should permit the design and the testing of identification strategies based on speech andro labial analysis, frontal and/or profile face analysis as well as 3-D analysis thanks to the multiple views. The M2VTS Database is available to any non-commercial user on request to the European Language Resource Agency."
            },
            "slug": "The-M2VTS-Multimodal-Face-Database-(Release-1.00)-Pigeon-Vandendorpe",
            "title": {
                "fragments": [],
                "text": "The M2VTS Multimodal Face Database (Release 1.00)"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents an overview of the multimodal face database recorded at UCL premises for the purpose of research applications inside the M2VTS project, offering synchronized video and speech data as well as image sequences allowing to access multiple views of a face."
            },
            "venue": {
                "fragments": [],
                "text": "AVBPA"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1882708"
                        ],
                        "name": "T. Bachmann",
                        "slug": "T.-Bachmann",
                        "structuredName": {
                            "firstName": "Talis",
                            "lastName": "Bachmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bachmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 234
                            }
                        ],
                        "text": "However, it has been demonstrated that the image size can be very small for holistic face recognition: \n12 \u00d7 11 for the subspace LDA system [Zhao et al. 1999], 14\u00d710 for the PDBNN system [Lin et al. 1997], \nand 18 \u00d7 24 for human percep\u00adtion [Bachmann 1991]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 144451130,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "cd946590cd1195764ca9601c3c40fe04d873b7aa",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Six images of human faces were quantised into isoluminant square-shaped pixels (16 grey levels) at eight different spatial levels of quantisation. The subjects had to identify the faces that were presented with different exposure durations (from 1 to 200 msec) and with one of two brightness conditions (variable brightness in Experiment 1 or isobrightness in Experiment 2). All finer quantisation levels led to better identification than the most coarse quantisation level (15 pixels per face in the horizontal dimension) at all exposure durations. The observation of an abrupt decrease in identification efficiency on moving from 18 or more pixels per face to 15 pixels per face and the approximate equality in identification efficiency within a broad range of quantisation levels above 18 pixels per face pose some problems for existing theories of face recognition. The implications of these findings for prototype-related, auto correlation and micro genetic accounts of face and pattern processing are disc..."
            },
            "slug": "Identification-of-spatially-quantised-images-of-How-Bachmann",
            "title": {
                "fragments": [],
                "text": "Identification of spatially quantised tachistoscopic images of faces: How many pixels does it take to carry identity?"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17525960,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e88ca837b122a9c9e546db5395b451f27ea01f19",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe our work on 3-D model-based tracking and recognition of human movement from real images. Our system has two major components. The rst component takes real image sequences acquired from multiple views and recovers the 3-D body pose at each time instant. The pose-recovery problem is formulated as a search problem and entails nding the pose parameters of a graphical human model for which its synthesized appearance is most similar to the actual appearance of the real human in the multi-view images. Currently, we use a best-rst search technique and chamfer matching as a fast similarity measure between synthesized and real edge images. The second component of our system deals with the representation and recognition of human movement patterns. The recognition of human movement patterns is considered as a classiication problem involving the matching of a test sequence with several reference sequences representing prototypical activities. A variation of dynamic time-warping is used to match movement patterns using 3-D joint angles as features. We illustrate our approach on real data acquired simultaneously from three views and data derived from stereo Moving Light Displays with diierent types of hand-gestures."
            },
            "slug": "Towards-3-D-model-based-tracking-and-recognition-of-Gavrila-Davis",
            "title": {
                "fragments": [],
                "text": "Towards 3-D model-based tracking and recognition of human movement: a multi-view approach"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "3-D model-based tracking and recognition of human movement from real images, and a variation of dynamic time-warping is used to match movement patterns using 3-D joint angles as features."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 128
                            }
                        ],
                        "text": "For exam\u00adple, in Moghaddam and Pentland [1997] simple contrast normalization was used to preprocess \nthe detected faces, while in Sung and Poggio [1997] normalization in intensity was done by .rst subtract\u00ading \na best-.t brightness plane and then applying histogram equalization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "Their system is very similar to that in [30] except that no matching measurements are computed and the classi er is a SVM."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 41
                            }
                        ],
                        "text": "The image synthesis method in Vetter and Poggio [1997] is based on the assump\u00adtion of linear \n3D object classes and the ex\u00adtension of linearity to images (both shape and texture) that are 2D projections \nof the 3D objects."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 119
                            }
                        ],
                        "text": "Compared to feature-based methods and template-matching \nmethods, appearance\u00ador image-based methods [Rowley et al. 1998; Sung and Poggio 1997] that train machine \nsystems on large numbers of samples have achieved the best results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "[38, 39] and the example-based learning approach of Sung and Poggio [30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 127
                            }
                        ],
                        "text": "Treating face detection as a two-class classi.cation problem helps to reduce false positives \ndramatically [Rowley et al. 1998; Sung and Poggio 1997] while maintaining true positives."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 229
                            }
                        ],
                        "text": "We review several \nrepresenta\u00adtive methods here: (1) a view-based eigen\u00adface method [Pentland et al. 1994], (2) a graph \nmatching-based method [Wiskott et al. 1997], (3) a linear class-based method [Blanz and Vetter 1999; \nVetter and Poggio 1997], (4) a vectorized im\u00adage representation based method [Beymer 1995; Beymer and \nPoggio 1995], and (5) a view-based appearance model [Cootes 23GBR is a 3D af.ne transformation with three \npa\u00adrameters: scale, slant, and tilt."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 161
                            }
                        ],
                        "text": "Akamatsu et al. [1992], Beymer [1993], Georghiades et al. [1999, 2001], and \nUllman and Basri [1991] are examples of the .rst class and Beymer [1995], Beymer and Poggio [1995], Cootes \net al. [2000], Maurer and Malsburg [1996a], Sali and Ullman [1998], and Vetter and Poggio [1997] of the \nsecond class."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 67
                            }
                        ],
                        "text": "Figure 27 illustrates a particular procedure adopted \nin Beymer and Poggio [1995]: the parallel deforma\u00adtion needed to compute the .ow between the prototype \nimage and the novel im\u00adage."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 39
                            }
                        ],
                        "text": "For technical details, please refer to [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 229
                            }
                        ],
                        "text": "First (A) the prototype .ow is measured between \nthe prototype image and the novel image at the same pose, then (B) the .ow is mapped onto the novel face, \nand .nally (C) the novel face is 2D-warped to the vir\u00adtual view [Beymer and Poggio 1995]. ter the correspondence \nbetween the new image and the prototype image at pose .1 is computed; using the warped .ow, a virtual \nview can be generated by warping the novel image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 260
                            }
                        ],
                        "text": "In Moghaddam and Pentland [1997], an ef.cient technique of probabil\u00adity density \nestimation was proposed by de\u00adcomposing the input space into two mu\u00adtually exclusive subspaces: the principal \nsubspace F and its orthogonal subspace F (a similar idea was explored in Sung and Poggio [1997])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 331,
                                "start": 316
                            }
                        ],
                        "text": "We have observed that the multiclass face recognition problem can be converted into a two-class \ndetection problem by using image differences [Moghaddam and Pentland 1997]; and the face de\u00adtection problem \ncan be converted into a multiclass recognition problem by us\u00ading additional nonface clusters of nega\u00adtive \nsamples [Sung and Poggio 1997]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 58
                            }
                        ],
                        "text": "Compared to the parallel deforma\u00adtion scheme \nin Beymer and Poggio [1995], C. Taylor.) this method reduces the need to compute correspondences between \nimages of differ\u00adent poses."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 41
                            }
                        ],
                        "text": "In \nboth methods [Beymer 1995; Beymer and Poggio 1995], an optical .ow algorithm is used to compute a dense \ncor\u00adrespondence between the images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [30], an example-based learning approach to locating vertical frontal views of human faces in complex scenes is presented."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7164794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088eb2d102c6bb486f5270d0b2adff76961994cf",
            "isKey": true,
            "numCitedBy": 2061,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system."
            },
            "slug": "Example-Based-Learning-for-View-Based-Human-Face-Sung-Poggio",
            "title": {
                "fragments": [],
                "text": "Example-Based Learning for View-Based Human Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An example-based learning approach for locating vertical frontal views of human faces in complex scenes and shows empirically that the distance metric adopted for computing difference feature vectors, and the \"nonface\" clusters included in the distribution-based model, are both critical for the success of the system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738894"
                        ],
                        "name": "T. Starner",
                        "slug": "T.-Starner",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Starner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Starner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 145
                            }
                        ],
                        "text": "\u2026\nConvolution Neural Network SOM learning based CNN methods [Lawrence et al. 1997] Hybrid methods Modular \neigenfaces Eigenfaces and eigenmodules [Pentland et al. 1994] Hybrid LFA Local feature method [Penev \nand Atick 1996] Shape-normalized Flexible appearance models [Lanitis et al. 1995]\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 154
                            }
                        ],
                        "text": "The popular eigenface approach [44] to face recognition has been extended to a view-based eigenface method in order to achieve pose-invariant recognition [45]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 191
                            }
                        ],
                        "text": "We review three representative examples here; the rst is a linear class based method [196], the second is a graph matching based method [79], and the third is a view-based eigenface approach [45]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 82
                            }
                        ],
                        "text": "We review several \nrepresenta\u00adtive methods here: (1) a view-based eigen\u00adface method [Pentland et al. 1994], (2) a graph \nmatching-based method [Wiskott et al. 1997], (3) a linear class-based method [Blanz and Vetter 1999; \nVetter and Poggio 1997], (4) a vectorized im\u00adage representation based method\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 83
                            }
                        ],
                        "text": "In the hybrid method category, we will brie.y review \nthe modular eigenface method [Pentland et al. 1994], a hybrid representation based on PCA and local feature \nanalysis (LFA) [Penev and Atick 1996], a .exible appearance model-based method [Lanitis et al. 1995], \nand a recent development [Huang\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 128
                            }
                        ],
                        "text": "There has been renewed interest in the use of the Karhunen-Loeve (KL) expansion for the representation [42, 43] and recognition [44, 45] of faces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 46
                            }
                        ],
                        "text": "For example, the modular eigen\u00adfaces approach [Pentland et al. 1994] \nuses both global eigenfaces and local eigenfeatures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 4
                            }
                        ],
                        "text": "In [Pentland et al. 1994],  Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 80
                            }
                        ],
                        "text": "For lower-order spaces, the eigenfeatures \nperformed better than the eigenfaces [Pentland et al. 1994]; when the combined set was used, only marginal \nimprovement was obtained."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 175
                            }
                        ],
                        "text": "The popular eigenface approach [Turk \nand Pentland 1991] to face recognition has been extended to a view-based eigenface method in order to \nachieve pose-invariant recognition [Pentland et al. 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "The capabilities of the system in [44] are extended in [45] in several directions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 136280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0bf5d558220d39698ce96d59ee5772e8e1a0663",
            "isKey": true,
            "numCitedBy": 2234,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe experiments with eigenfaces for recognition and interactive search in a large-scale face database. Accurate visual recognition is demonstrated using a database of O(10/sup 3/) faces. The problem of recognition under general viewing orientation is also examined. A view-based multiple-observer eigenspace technique is proposed for use in face recognition under variable pose. In addition, a modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields higher recognition rates as well as a more robust framework for face recognition. An automatic feature extraction technique using feature eigentemplates is also demonstrated.<<ETX>>"
            },
            "slug": "View-based-and-modular-eigenspaces-for-face-Pentland-Moghaddam",
            "title": {
                "fragments": [],
                "text": "View-based and modular eigenspaces for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer, which yields higher recognition rates as well as a more robust framework for face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38480590"
                        ],
                        "name": "Wenyi Zhao",
                        "slug": "Wenyi-Zhao",
                        "structuredName": {
                            "firstName": "Wenyi",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyi Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3136431"
                        ],
                        "name": "D. Bhat",
                        "slug": "D.-Bhat",
                        "structuredName": {
                            "firstName": "Dinkar",
                            "lastName": "Bhat",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bhat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3023166"
                        ],
                        "name": "N. Nandhakumar",
                        "slug": "N.-Nandhakumar",
                        "structuredName": {
                            "firstName": "Nagaraj",
                            "lastName": "Nandhakumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nandhakumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 94
                            }
                        ],
                        "text": "Finally, the fourth column shows real images that \nare close to the prototype images [Zhao and Chellappa 2000]. local SFS algorithm [Tsai and Shah 1994]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 172
                            }
                        ],
                        "text": "Among appearance-based holistic approaches, \neigenfaces [Kirby and Sirovich 1990; Turk and Pentland 1991] and Fisher\u00adfaces [Belhumeur et al. 1997; \nEtemad and Chellappa 1997; Zhao et al. 1998] have proved to be effective in experiments with large databases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 187
                            }
                        ],
                        "text": "For example, .ndings in psychology [Bruce 1988; Shepherd et al. 1981] about \nthe rela\u00adtive importance of different facial features have been noted in the engineering liter\u00adature \n[Etemad and Chellappa 1997]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Experimental re\u00adsults using images/videos collected at UMD, NIST/USF, and CMU with pose/illumination \nvariations have illus\u00adtrated the effectiveness of this approach in both still-to-video and video-to-video \nscenarios with appropriate model choices."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 64
                            }
                        ],
                        "text": "The EBGM sys\u00adtem [Wiskott et al. 1997], the subspace \nLDA system [Zhao et al. 1998], and the probabilistic eigenface system [Moghad\u00addam and Pentland 1997] \nwere judged to be among the top three, with each method showing different levels of performance on different \nsubsets of sequestered images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 10
                            }
                        ],
                        "text": "In Li and Chellappa [2001], a face ver\u00adi.cation system based on tracking facial features \nwas presented."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 396,
                                "start": 389
                            }
                        ],
                        "text": "The Sep96 evaluation tested the follow\u00ading 10 algorithms: \nan algorithm from Excalibur Corpora\u00adtion (Carlsbad, CA)(Sept. 1996); two algorithms from MIT Media Labo\u00adratory \n(Sept. 1996) [Moghaddam et al. 1996; Turk and Pentland 1991]; three linear discriminant analysis\u00adbased \nalgorithms from Michigan State University [Swets and Weng 1996b] (Sept. 1996) and the University of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997); a gray-scale projection algorithm \nfrom Rutgers University [Wilder 1994] (Sept. 1996); an Elastic Graph Matching algorithm from the University \nof Southern Cali\u00adfornia [Okada et al. 1998; Wiskott et al. 1997] (March 1997); a baseline PCA algorithm \n[Moon and Phillips 2001; Turk and Pentland 1991]; and a baseline normalized correlation matching algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 167
                            }
                        ],
                        "text": "The authors selected the dimension\u00adality of the universal face subspace based on the \ncharacteristics of the eigenvectors (face-like or not) instead of the eigenval\u00adues [Zhao et al. 1998], \nas is commonly done."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 25
                            }
                        ],
                        "text": "In 1995, a review paper [Chellappa \net al. 1995] gave a thorough survey of FRT at that time."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 65
                            }
                        ],
                        "text": "Some details about \nthe tracking algo\u00adrithm are as follows [Li and Chellappa 2001]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 12
                            }
                        ],
                        "text": "In Zhao and Chellappa [2000b], \na uni.ed approach was proposed to solving both the pose and illumination problems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 147
                            }
                        ],
                        "text": "\u2026analysis\u00adbased \nalgorithms from Michigan State University [Swets and Weng 1996b] (Sept. 1996) and the University of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997); a gray-scale projection algorithm \nfrom Rutgers University [Wilder 1994] (Sept. 1996); an\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 129
                            }
                        ],
                        "text": "Authors addresses: W. Zhao, \nVision Technologies Lab, Sarnoff Corporation, Princeton, NJ 08543-5300; email: wzhao@sarnoff.com; R. \nChellappa and A. Rosenfeld, Center for Automation Research, University of Maryland, College Park, MD \n20742-3275; email: {rama,ar}@cfar.umd.edu; P. J. Phillips, National Institute of Standards and Technology, \nGaithersburg, MD 20899; email: jonathon@nist.gov."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 70
                            }
                        ],
                        "text": "This method is a natural \nextension of the method proposed in Zhao and Chellappa [2000] to handle the illumination problem."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 22
                            }
                        ],
                        "text": "These meth\u00adods [Li and Chellappa \n2001; Li et al. 2001a] coherently exploit both spatial in\u00adformation (in each frame) and temporal in\u00adformation \n(such as the trajectories of fa\u00adcial features)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 150
                            }
                        ],
                        "text": "\u2026and the feature line linking two stored sample points [Li \nand Lu 1999]; Fisher\u00adfaces [Belhumeur et al. 1997; Liu and Wechsler 2001; Swets and Weng 1996b; Zhao \net al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA) [Fisher 1938]; Bayesian methods, \nwhich use a probabilistic distance\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 741,
                                "start": 734
                            }
                        ],
                        "text": "Categorization of Still Face Recognition Techniques Approach Representative work Holistic \nmethods Principal-component analysis (PCA) Eigenfaces Direct application of PCA [Craw and Cameron 1996; \nKirby and Sirovich 1990; Turk and Pentland 1991] Probabilistic eigenfaces Two-class problem with prob. \nmeasure [Moghaddam and Pentland 1997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and Wechsler 2000a] Feature lines Point-to-line distance based [Li \nand Lu 1999] ICA ICA-based feature analysis [Bartlett et al. 1998] Other representations LDA/FLD LDA/FLD \non raw image [Etemad and Chellappa 1997] PDBNN Probabilistic decision based NN [Lin et al. 1997] Feature-based \nmethods Pure geometry methods Earlier methods [Kanade 1973; Kelly 1970]; recent methods [Cox et al. 1996; \nManjunath et al. 1992] Dynamic link architecture Graph matching methods [Okada et al. 1998; Wiskott et \nal."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 126
                            }
                        ],
                        "text": "Three of the algorithms performed very well: probabilistic eigenface from MIT [Moghaddam et al. 1996], \nsub\u00adspace LDA from UMD [Zhao et al. 1998, 1999], and Elastic Graph Matching from USC [Wiskott et al. \n1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 143
                            }
                        ],
                        "text": "Face recognition systems using LDA/FLD have also been very suc\u00adcessful [Belhumeur et al. 1997; \nEtemad and Chellappa 1997; Swets and Weng 1996b; Zhao et al. 1998; Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 145
                            }
                        ],
                        "text": "\u2026problem with prob. \nmeasure [Moghaddam and Pentland 1997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and Wechsler 2000a] Feature\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 62
                            }
                        ],
                        "text": "1999] Spatiotemporal methods Feature trajectory-based [Li and Chellappa 2001; Li et al. 2001a] Video-to \nvideo methods [Zhou et al. 2003] while Strom et al. [1999] tracked only points with high Hessian values."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "However, for veri.cation, \nthe equal error rates were 2% and 14% for USC, and 1% and 12% for UMD."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 83
                            }
                        ],
                        "text": "Tracking also plays a key role in spatiotemporal-based recognition methods [Li and Chellappa 2001; Li \net al. 2001a] which directly use the tracking in\u00adformation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 52
                            }
                        ],
                        "text": "Basic Techniques \nof Video-Based Face Recognition In Chellappa et al. [1995], four computer vision areas were mentioned \nas being im\u00adportant for video-based face recognition: segmentation of moving objects (humans) from a \nvideo sequence; structure estima\u00adtion; 3D models for faces; and nonrigid mo\u00adtion analysis."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 96
                            }
                        ],
                        "text": "A recent paper on using .ow\u00adbased SfM techniques for face modeling is A. K. R. Chowdhury, and R. Chellappa \n[2003]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 120
                            }
                        ],
                        "text": "To assess the pose problem more sys\u00adtematically, an attempt has been made to classify pose problems [Zhao \n1999; Zhao and Chellappa 2000b]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 75
                            }
                        ],
                        "text": "8Weighted metrics have also been used in the pure LDA approach [Etemad and Chellappa \n1997] and the Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 196
                            }
                        ],
                        "text": "The series of tests has allowed advances in algorithm de\u00advelopment to \nbe quanti.ed for exam\u00adple, the performance improvements in the MIT algorithms between March 1995 and \nSeptember 1996, and in the UMD al\u00adgorithms between September 1996 and March 1997."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "For identi.cation, on the fb and duplicate \nprobes, the USC scores were 94% and 59%, and the UMD scores were 96% and 47%."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 195
                            }
                        ],
                        "text": "The .rst row shows the .rst .ve pure LDA basis images \nW ; the second row shows the .rst .ve subspace LDA basis images W <; the average face and .rst four eigenfaces \n< are shown on the third row [Zhao et al. 1998].  their respective means mi: Ci =E[(x(.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 85
                            }
                        ],
                        "text": "Numerous methods have been proposed for face recognition based on image in\u00adtensities [Chellappa et al. \n1995]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7740678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aae437acae7224edb347860bd94ea4c3bde670c8",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-reliable-descriptor-for-face-objects-in-visual-Zhao-Bhat",
            "title": {
                "fragments": [],
                "text": "A reliable descriptor for face objects in visual content"
            },
            "venue": {
                "fragments": [],
                "text": "Signal Process. Image Commun."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3195445"
                        ],
                        "name": "Ronald-Bryan O. Alferez",
                        "slug": "Ronald-Bryan-O.-Alferez",
                        "structuredName": {
                            "firstName": "Ronald-Bryan",
                            "lastName": "Alferez",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald-Bryan O. Alferez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47904091"
                        ],
                        "name": "Yuan-fang Wang",
                        "slug": "Yuan-fang-Wang",
                        "structuredName": {
                            "firstName": "Yuan-fang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan-fang Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 93
                            }
                        ],
                        "text": "However, it is worth pointing out that some recent work on invariant methods based on images [199] may lead to progress in this direction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11113191,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "d989954202999f92fd55fc961aa2546228b52650",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose invariant formulations that can potentially be combined into a single system. In particular, we describe a framework for computing invariant features which are insensitive to rigid motion, affine transform, changes of parameterization and scene illumination, perspective transform, and view point change. This is unlike most current research on image invariants which concentrates on either geometric or illumination invariants exclusively. The formulations are widely applicable to many popular basis representations, such as wavelets, short-time Fourier analysis, and splines. Exploiting formulations that examine information about shape and color at different resolution levels, the new approach is neither strictly global nor local. It enables a quasi-localized, hierarchical shape analysis which is rarely found in other known invariant techniques, such as global invariants. Furthermore, it does not require estimating high-order derivatives in computing invariants (unlike local invariants), whence is more robust. We provide results of numerous experiments on both synthetic and real data to demonstrate the validity and flexibility of the proposed framework."
            },
            "slug": "Geometric-and-Illumination-Invariants-for-Object-Alferez-Wang",
            "title": {
                "fragments": [],
                "text": "Geometric and Illumination Invariants for Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A framework for computing invariant features which are insensitive to rigid motion, affine transform, changes of parameterization and scene illumination, perspective transform, and view point change is described, unlike most current research on image invariants which concentrates on either geometric or illumination invariants exclusively."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6435894"
                        ],
                        "name": "S. McKenna",
                        "slug": "S.-McKenna",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "McKenna",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. McKenna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144784813"
                        ],
                        "name": "S. Gong",
                        "slug": "S.-Gong",
                        "structuredName": {
                            "firstName": "Shaogang",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18090553,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "633754be2c47971b9fe7bbd2545817124c079efe",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Face recognition systems typically operate robustly only within highly constrained environments. This paper describes work aimed at performing face recognition in more unconstrained environments such as occur in security applications based on closed-circuit television (CCTV). The system described detects and tracks several people as they move through complex scenes. It uses a single, fixed camera and extracts segmented face sequences which can be used to perform face recognition or verification. Example sequences are given to illustrate performance. An application in non-intrusive access control is discussed."
            },
            "slug": "Non-intrusive-Person-Authentication-for-Access-by-McKenna-Gong",
            "title": {
                "fragments": [],
                "text": "Non-intrusive Person Authentication for Access Control by Visual Tracking and Face Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Work aimed at performing face recognition in more unconstrained environments such as occur in security applications based on closed-circuit television (CCTV) and an application in non-intrusive access control is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "AVBPA"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400601690"
                        ],
                        "name": "A. O'Toole",
                        "slug": "A.-O'Toole",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "O'Toole",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. O'Toole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145327111"
                        ],
                        "name": "D. Roark",
                        "slug": "D.-Roark",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Roark",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144319186"
                        ],
                        "name": "H. Abdi",
                        "slug": "H.-Abdi",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Abdi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Abdi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2462084,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b4698e4046b34bfb9900fdb4106d088b7a85c699",
            "isKey": false,
            "numCitedBy": 455,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recognizing-moving-faces:-a-psychological-and-O'Toole-Roark",
            "title": {
                "fragments": [],
                "text": "Recognizing moving faces: a psychological and neural synthesis"
            },
            "venue": {
                "fragments": [],
                "text": "Trends in Cognitive Sciences"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144075899"
                        ],
                        "name": "Tanzeem Choudhury",
                        "slug": "Tanzeem-Choudhury",
                        "structuredName": {
                            "firstName": "Tanzeem",
                            "lastName": "Choudhury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tanzeem Choudhury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46978775"
                        ],
                        "name": "B. Clarkson",
                        "slug": "B.-Clarkson",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Clarkson",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Clarkson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768120"
                        ],
                        "name": "T. Jebara",
                        "slug": "T.-Jebara",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Jebara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jebara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116449956"
                        ],
                        "name": "Alex Pentland Perceptual",
                        "slug": "Alex-Pentland-Perceptual",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Perceptual",
                            "middleNames": [
                                "Pentland"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Pentland Perceptual"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 21
                            }
                        ],
                        "text": "More re\u00adcent methods [Choudhury et al. \n1999; McKenna and Gong 1998] have used mo\u00adtion and/or color information to speed up the process of searching \nfor possible face regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "The face images are warped into frontal views whenever pose and depth information about the faces is available [95]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "Some systems [95] use non-visual cues (speech, for example) to enhance their performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 18
                            }
                        ],
                        "text": "Two other systems [93, 95] are more practical in terms of accuracy and size of the database."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "Both of these systems use more than one cue; for example [95] uses both audio and video, and [93] uses stereo."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "A multimodal based person recognition system is described in [95]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 125
                            }
                        ],
                        "text": "The locations of feature points can be used for pose estimation, which is im\u00adportant \nfor synthesizing a virtual frontal view [Choudhury et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 161
                            }
                        ],
                        "text": "After over twenty years of research on image sequence analysis [86, 87, 88, 89], only a little of that research had been applied to the face recognition problem [90, 91, 92, 93, 94, 95] up to the mid-nineties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 67
                            }
                        ],
                        "text": "They have been used in many multimodal systems [Bigun et al. 1998; Choudhury et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 967395,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "670b164d4587ab0cacd6b5aed62acf5473559a83",
            "isKey": true,
            "numCitedBy": 168,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a person identi cation technique that can recognize and verify people from unconstrained video and audio. We do not expect fully frontal face image or clean speech as our input. Our recognition algorithm can detect and compensate for pose variation and changes in the auditory background and also select the most reliable video frame and audio clip to use for recognition. We also use 3D depth information of a human head to detect the presence of an actual person as opposed to an image of that person. Our system achieves 100% recognition and veri cation rates on natural real-time input with 26 registered clients."
            },
            "slug": "Multimodal-person-recognition-using-unconstrained-Choudhury-Clarkson",
            "title": {
                "fragments": [],
                "text": "Multimodal person recognition using unconstrained audio and video"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work proposes a person identification technique that can recognize and verify people from unconstrained video and audio and achieves 100% recognition and veri cation rates on natural real-time input with 26 registered clients."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1060186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbe488bb190d75f4b665d43e306bcab1ab228890",
            "isKey": false,
            "numCitedBy": 459,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe an algorithm for object recognition that explicitly models and estimated the posterior probability function, P(object/image). We have chosen a functional form of the posterior probability function that captures the joint statistics of local appearance and position on the object as well as the statistics of local appearance in the visual world at large. We use a discrete representation of local appearance consisting of approximately 10/sup 6/ patterns. We compute an estimate of P(object/image) in closed form by counting the frequency of occurrence of these patterns over various sets of training images. We have used this method for detecting human faces from frontal and profile views. The algorithm for frontal views has shown a detection rate of 93.0% with 88 false alarms on a set of 125 images containing 483 faces combining the MIT test set of Sung and Poggio with the CMU test sets of Rowley, Baluja, and Kanade. The algorithm for detection of profile views has also demonstrated promising results."
            },
            "slug": "Probabilistic-modeling-of-local-appearance-and-for-Schneiderman-Kanade",
            "title": {
                "fragments": [],
                "text": "Probabilistic modeling of local appearance and spatial relationships for object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "An algorithm for object recognition that explicitly models and estimated the posterior probability function, P(object/image) in closed form is described, which captures the joint statistics of local appearance and position on the object as well as the statistics ofLocal appearance in the visual world at large."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830709"
                        ],
                        "name": "A. Lanitis",
                        "slug": "A.-Lanitis",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lanitis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lanitis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 143
                            }
                        ],
                        "text": "To account for texture variation, the ASM model has been expanded to statistical appearance models including a Flexible Appearance Model (FAM) [Lanitis et al. 1995] and an Active Appearance Model (AAM) [Cootes et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 149
                            }
                        ],
                        "text": "\u2026on constructing invariant features \n[Wiskott et al. 1997] or synthesizing a prototypical view (frontal view) after a full model is extracted \nfrom the input image [Lanitis et al. 1995].22 Such methods work well for small rota\u00adtion angles, but \nthey fail when the angle is large, say 60., causing\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 110
                            }
                        ],
                        "text": "1997] or synthesizing a prototypical view (frontal view) after a full model is extracted from the input image [Lanitis et al. 1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 89
                            }
                        ],
                        "text": "A flexible appearance model based method for automatic face recognition was presented in [Lanitis et al. 1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 144
                            }
                        ],
                        "text": "To account for tex\u00adture variation, the ASM model \nhas been expanded to statistical appearance mod\u00adels including a Flexible Appearance Model (FAM) [Lanitis \net al. 1995] and an Active Appearance Model (AAM) [Cootes et al. 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 208
                            }
                        ],
                        "text": "\u2026will brie.y review \nthe modular eigenface method [Pentland et al. 1994], a hybrid representation based on PCA and local feature \nanalysis (LFA) [Penev and Atick 1996], a .exible appearance model-based method [Lanitis et al. 1995], \nand a recent development [Huang et al. 2003] along this direction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 89
                            }
                        ],
                        "text": "A .exible appearance model based method for automatic face recognition was presented in [Lanitis \net al. 1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 150
                            }
                        ],
                        "text": "\u2026Eigenfaces and eigenmodules [Pentland et al. 1994] Hybrid LFA Local feature method [Penev \nand Atick 1996] Shape-normalized Flexible appearance models [Lanitis et al. 1995] Component-based Face \nregion and components [Huang et al. 2003] analysis (ICA) is argued to have more representative power\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 44
                            }
                        ],
                        "text": "Shape-normalized Flexible appearance models [Lanitis et al. 1995]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 142
                            }
                        ],
                        "text": "1994], a hybrid representation based on PCA and local feature analysis (LFA) [Penev and Atick 1996], a flexible appearance model-based method [Lanitis et al. 1995], and a recent development [Huang et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122941737,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b65b06ecdd9df916d8f688e73ac41a2bb0fd63f",
            "isKey": true,
            "numCitedBy": 253,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-face-identification-system-using-flexible-Lanitis-Taylor",
            "title": {
                "fragments": [],
                "text": "Automatic face identification system using flexible appearance models"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684626"
                        ],
                        "name": "B. Heisele",
                        "slug": "B.-Heisele",
                        "structuredName": {
                            "firstName": "Bernd",
                            "lastName": "Heisele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Heisele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1981539"
                        ],
                        "name": "Thomas Serre",
                        "slug": "Thomas-Serre",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Serre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Serre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 43
                            }
                        ],
                        "text": "The basic idea of component-based methods [Heisele et al. 2001] is to \ndecom\u00adpose a face into a set of facial components such as mouth and eyes that are intercon\u00ad 11Recall \nthat in Craw and Cameron [1996] and Moghaddam and Pentland [1997] these shape-free images are used as \nthe inputs to the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 219
                            }
                        ],
                        "text": "\u2026\ntechniques could only han\u00addle single or a few well-separated frontal faces in images with simple backgrounds, \nwhile state-of-the-art algorithms can de\u00adtect faces and their poses in cluttered backgrounds [Gu et al. \n2001; Heisele et al. 2001; Schneiderman and Kanade 2000; Vi\u00adola and Jones 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 138
                            }
                        ],
                        "text": "The last method [Huang et al. 2003] that we review in this category \nis based on re\u00adcent advances in component-based detec\u00adtion/recognition [Heisele et al. 2001] and 3D morphable \nmodels [Blanz and Vetter 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 42
                            }
                        ],
                        "text": "The basic idea of component-based methods [Heisele et al. 2001] is to decompose a face into a set of facial components such as mouth and eyes that are intercon-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 107
                            }
                        ],
                        "text": "2003] that we review in this category is based on recent advances in component-based detection/recognition [Heisele et al. 2001] and 3D morphable models [Blanz and Vetter 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 313,
                                "start": 224
                            }
                        ],
                        "text": "Earlier face detection techniques could only handle single or a few well-separated frontal faces in images with simple backgrounds, while state-of-the-art algorithms can detect faces and their poses in cluttered backgrounds [Gu et al. 2001; Heisele et al. 2001; Schneiderman and Kanade 2000; Viola and Jones 2001]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9084180,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "015a3cdf3c335fa29dd8bb0b82b01a09ed2eb5a0",
            "isKey": true,
            "numCitedBy": 209,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a component-based, trainable system for detecting frontal and near-frontal views of faces in still gray images. The system consists of a two-level hierarchy of Support Vector Machine (SVM) classifiers. On the first level, component classifiers independently detect components Of a face. On the second level, a single classifier checks if the geometrical configuration of the detected components in the image matches a geometrical model of a face. We propose a method for automatically learning components by using 3-D head models, This approach has the advantage that no manual interaction is required for choosing and extracting components. Experiments show that the component-based system is significantly more robust against rotations in depth than a comparable system trained on whole face patterns."
            },
            "slug": "Component-based-face-detection-Heisele-Serre",
            "title": {
                "fragments": [],
                "text": "Component-based face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A method for automatically learning components by using 3-D head models, which has the advantage that no manual interaction is required for choosing and extracting components."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144975752"
                        ],
                        "name": "V. Bruce",
                        "slug": "V.-Bruce",
                        "structuredName": {
                            "firstName": "Vicki",
                            "lastName": "Bruce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Bruce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160279"
                        ],
                        "name": "P. Hancock",
                        "slug": "P.-Hancock",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hancock",
                            "middleNames": [
                                "J.",
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hancock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34513773"
                        ],
                        "name": "A. Burton",
                        "slug": "A.-Burton",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Burton",
                            "middleNames": [
                                "Mike"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Burton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 64
                            }
                        ],
                        "text": "\u2014Is face perception the result of holistic or feature analysis? [Bruce 1988; Bruce et al. 1998]: Both holistic and feature information are crucial for the perception and recognition of faces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 189
                            }
                        ],
                        "text": "This observation has been extended to show that movement helps in the recognition of familiar faces shown under a range of different types of degradations\u2014negated, inverted, or thresholded [Bruce et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 31
                            }
                        ],
                        "text": "\u2014Movement and face recognition [O\u2019Toole et al. 2002; Bruce et al. 1998; Knight and Johnston 1997]: A recent study [Knight"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 190
                            }
                        ],
                        "text": "This observation has been extended to show that \nmovement helps in the recognition of familiar faces shown under a range of different types of degradations \nnegated, inverted, or thresholded [Bruce et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 52
                            }
                        ],
                        "text": "Movement and face recognition [O Toole et al. 2002; Bruce et al. 1998; Knight and Johnston \n1997]: A recent study [Knight and Johnston 1997] showed that fa\u00admous faces are easier to recognize when \nshown in moving sequences than in still photographs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 13
                            }
                        ],
                        "text": "[Bruce 1988; Bruce \net al. 1998]: Both holistic and feature information are crucial for the percep\u00adtion and recognition of \nfaces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 27
                            }
                        ],
                        "text": "\u2014Effect of lighting change [Bruce et al. 1998; Hill and Bruce 1996; Johnston et al. 1992]: It has long been informally observed that photographic negatives of faces are difficult to recognize."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 27
                            }
                        ],
                        "text": "Effect of lighting change [Bruce et al. 1998; Hill \nand Bruce 1996; Johnston et al. 1992]: It has long been informally observed that photographic negatives \nof faces are dif.cult to recognize."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 142616982,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "e42798ce16dc6f2c1b8964e839cb7eb00e19520c",
            "isKey": true,
            "numCitedBy": 55,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter reviews factors which affect the perception and recognition of faces by humans, in order to describe those characteristics that must be exhibited by any computational or engineering system which claims psychological or neurobiological plausibility. Effects of photographic negation and the difficulty of recognising line-drawings suggest that the representations mediating human face recognition are based upon image-features rather than on more abstract derived measurements of face features. However, to understand which image-based coding scheme has most psychological plausibility requires that different models re compared against human similarity ratings and memory performance data using the same face images. Some recent investigations of pixel-based PCA and wavelet-based graph-matching models are briefly discussed."
            },
            "slug": "Human-Face-Perception-and-Identification-Bruce-Hancock",
            "title": {
                "fragments": [],
                "text": "Human Face Perception and Identification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 98
                            }
                        ],
                        "text": "Compared to feature-based methods and template-matching methods, appearanceor image-based methods [Rowley et al. 1998; Sung and Poggio 1997] that train machine systems on large numbers of samples have achieved the best results."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 99
                            }
                        ],
                        "text": "Compared to feature-based methods and template-matching \nmethods, appearance\u00ador image-based methods [Rowley et al. 1998; Sung and Poggio 1997] that train machine \nsystems on large numbers of samples have achieved the best results."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 107
                            }
                        ],
                        "text": "Treating face detection as a two-class classi.cation problem helps to reduce false positives \ndramatically [Rowley et al. 1998; Sung and Poggio 1997] while maintaining true positives."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 107
                            }
                        ],
                        "text": "Treating face detection as a two-class classification problem helps to reduce false positives dramatically [Rowley et al. 1998; Sung and Poggio 1997] while maintaining true positives."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d76ef8e61395a6e9c32627f1f108772d084e2e9",
            "isKey": true,
            "numCitedBy": 4156,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural Network-Based Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1384255355"
                        ],
                        "name": "Aleix M. Martinez",
                        "slug": "Aleix-M.-Martinez",
                        "structuredName": {
                            "firstName": "Aleix M.",
                            "lastName": "Martinez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aleix M. Martinez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703247"
                        ],
                        "name": "A. Kak",
                        "slug": "A.-Kak",
                        "structuredName": {
                            "firstName": "Avinash",
                            "lastName": "Kak",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5523504,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d544475dc01daa0c4f9847ef72adb8878df8ce99",
            "isKey": false,
            "numCitedBy": 3193,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "In the context of the appearance-based paradigm for object recognition, it is generally believed that algorithms based on LDA (linear discriminant analysis) are superior to those based on PCA (principal components analysis). In this communication, we show that this is not always the case. We present our case first by using intuitively plausible arguments and, then, by showing actual results on a face database. Our overall conclusion is that when the training data set is small, PCA can outperform LDA and, also, that PCA is less sensitive to different training data sets."
            },
            "slug": "PCA-versus-LDA-Martinez-Kak",
            "title": {
                "fragments": [],
                "text": "PCA versus LDA"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The overall conclusion is that when the training data set is small, PCA can outperform LDA and, also, that PCA is less sensitive to different training data sets."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 258278,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f12041657812df52ad7317f1df77b030c9f76030",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The correspondence problem in computer vision is basically a matching task between two or more sets of features. We introduce a vectorized image representation, which is a feature-based representation where correspondence has been established with respect to a reference image. The representation consists of two image measurements made at the feature points: shape and texture. Feature geometry, or shape, is represented using the (x,y) locations of features relative to the some standard reference shape. Image grey levels, or texture, are represented by mapping image grey levels onto the standard reference shape. Computing this representation is essentially a correspondence task and in this paper we explore on automatic technique for \"vectorizing\" face images. Our face vectorizer alternates back and forth between computation steps for shape and texture, and a key idea is to structure the two computations so that each one uses the output of the other. In addition to describing the vectorizer, an application to the problem of facial feature detection is presented."
            },
            "slug": "Feature-correspondence-by-interleaving-shape-and-Beymer",
            "title": {
                "fragments": [],
                "text": "Feature correspondence by interleaving shape and texture computations"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A vectorized image representation is introduced, which is a feature-based representation where correspondence has been established with respect to a reference image, which consists of two image measurements made at the feature points: shape and texture."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2811821"
                        ],
                        "name": "P. Kalocsai",
                        "slug": "P.-Kalocsai",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Kalocsai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kalocsai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38480590"
                        ],
                        "name": "Wenyi Zhao",
                        "slug": "Wenyi-Zhao",
                        "structuredName": {
                            "firstName": "Wenyi",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyi Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889830"
                        ],
                        "name": "Egor Elagin",
                        "slug": "Egor-Elagin",
                        "structuredName": {
                            "firstName": "Egor",
                            "lastName": "Elagin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Egor Elagin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 103
                            }
                        ],
                        "text": "On the other hand, machine systems provide tools for conducting studies in psychology and neuroscience [Hancock et al. 1998; Kalocsai et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 125
                            }
                        ],
                        "text": "On the other hand, machine systems provide tools for conducting studies \nin psychology and neuroscience [Hancock et al. 1998; Kalocsai et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5568784,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "debbfb646869294e1ca05b97b40a786326d39182",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The performance of a local feature based system, using Gabor filters, and a global template matching based system, using a combination of PCA (principal component analysis) and LDA (linear discriminant analysis) was correlated with human performance on a recognition task involving 32 face images. Both systems showed qualitative similarities to human performance in that all but one of the calculated correlation coefficients were very or moderately high. The Gabor filter model seemed to capture human performance better than the PCA-LDA model since the coefficients for this model were higher for all examined conditions. These results indicate that the preservation of local feature based representation might be necessary to achieve recognition performance similar to that of humans."
            },
            "slug": "Face-similarity-space-as-perceived-by-humans-and-Kalocsai-Zhao",
            "title": {
                "fragments": [],
                "text": "Face similarity space as perceived by humans and artificial systems"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The results indicate that the preservation of local feature based representation might be necessary to achieve recognition performance similar to that of humans."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35146156"
                        ],
                        "name": "M. Lades",
                        "slug": "M.-Lades",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Lades",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39354852,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38d74f6cf071100e9503494ae2ff21ad452383c2",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A neural system is presented for invariant object recognition. Its flexibility is demonstrated with freely taken camera images of human faces. The system is an application of the dynamic link architecture, which owes its strength to an enhancement of tradition neural networks by a new kind of variable to express the hierarchical grouping of neurons. This capability is used to group primitive local feature detectors (Gabor-based wavelets) into composite feature detectors (jets) and to preserve neighborhood relationships between jets when they lose position information on the way from the image domain to the object domain. Due to the potential for grouping, objects can be represented as attributed graphs, with jets serving as attributes. Recognition is formulated as graph matching and is implemented as a topologically constrained diffusion of image-object links. A hierarchical sequence of matches, from low-frequency components of jets to high-frequency components, is used. Size invariance is achieved by interposing diffusion steps in magnification space. The system is implemented on a network of transputers"
            },
            "slug": "Size-and-distortion-invariant-object-recognition-by-Buhmann-Lades",
            "title": {
                "fragments": [],
                "text": "Size and distortion invariant object recognition by hierarchical graph matching"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A neural system for invariant object recognition is presented, an application of the dynamic link architecture, which owes its strength to an enhancement of tradition neural networks by a new kind of variable to express the hierarchical grouping of neurons."
            },
            "venue": {
                "fragments": [],
                "text": "1990 IJCNN International Joint Conference on Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802702"
                        ],
                        "name": "M. Hamouz",
                        "slug": "M.-Hamouz",
                        "structuredName": {
                            "firstName": "Miroslav",
                            "lastName": "Hamouz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hamouz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32866621"
                        ],
                        "name": "K. Jonsson",
                        "slug": "K.-Jonsson",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Jonsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Jonsson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801638"
                        ],
                        "name": "J. Kittler",
                        "slug": "J.-Kittler",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Kittler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kittler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110456780"
                        ],
                        "name": "Yongping Li",
                        "slug": "Yongping-Li",
                        "structuredName": {
                            "firstName": "Yongping",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongping Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736143"
                        ],
                        "name": "Constantine Kotropoulos",
                        "slug": "Constantine-Kotropoulos",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Kotropoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Constantine Kotropoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737071"
                        ],
                        "name": "A. Tefas",
                        "slug": "A.-Tefas",
                        "structuredName": {
                            "firstName": "Anastasios",
                            "lastName": "Tefas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tefas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144064571"
                        ],
                        "name": "I. Pitas",
                        "slug": "I.-Pitas",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Pitas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3196216"
                        ],
                        "name": "T. Tan",
                        "slug": "T.-Tan",
                        "structuredName": {
                            "firstName": "Teewoon",
                            "lastName": "Tan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152996923"
                        ],
                        "name": "Hong Yan",
                        "slug": "Hong-Yan",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3276986"
                        ],
                        "name": "F. Smeraldi",
                        "slug": "F.-Smeraldi",
                        "structuredName": {
                            "firstName": "Fabrizio",
                            "lastName": "Smeraldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Smeraldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2505025"
                        ],
                        "name": "N. Capdevielle",
                        "slug": "N.-Capdevielle",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Capdevielle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Capdevielle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708945"
                        ],
                        "name": "W. Gerstner",
                        "slug": "W.-Gerstner",
                        "structuredName": {
                            "firstName": "Wulfram",
                            "lastName": "Gerstner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gerstner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2031573"
                        ],
                        "name": "Y. Abdeljaoued",
                        "slug": "Y.-Abdeljaoued",
                        "structuredName": {
                            "firstName": "Yousri",
                            "lastName": "Abdeljaoued",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Abdeljaoued"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775110"
                        ],
                        "name": "J. Big\u00fcn",
                        "slug": "J.-Big\u00fcn",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Big\u00fcn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Big\u00fcn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2177973"
                        ],
                        "name": "S. B. Yacoub",
                        "slug": "S.-B.-Yacoub",
                        "structuredName": {
                            "firstName": "Souheil",
                            "lastName": "Yacoub",
                            "middleNames": [
                                "Ben"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. B. Yacoub"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1915200"
                        ],
                        "name": "E. Mayoraz",
                        "slug": "E.-Mayoraz",
                        "structuredName": {
                            "firstName": "Eddy",
                            "lastName": "Mayoraz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Mayoraz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 69
                            }
                        ],
                        "text": "There were twelve algorithms from four partipicants \nin this contest [Matas et al. 2000]: an EBGM algorithm from IDIAP (Daller Molle Institute for Per\u00adceptual \nArti.cial Intelligence), a slightly modi.ed EBGM algorithm from Aristo\u00adtle University of Thessaloniki, \na FND\u00adbased (Fractal Neighbor\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9895541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "437e8b926ffeb493fdcb6a1b6c3eb55af3f86c2c",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents results of the face verification contest that was organized in conjunction with International Conference on Pattern Recognition 2000. Participants had to use identical data sets from a large, publicly available multimodal database XM2VTSDB. Training and evaluation was carried out according to an a priori known protocol. Verification results of all tested algorithms have been collected and made public on the XM2VTSDB website, facilitating large scale experiments on classifier combination and fusion. Tested methods included, among others, representatives of the most common approaches to face verification -elastic graph matching, Fisher's linear discriminant and support vector machines."
            },
            "slug": "Comparison-of-face-verification-results-on-the-Matas-Hamouz",
            "title": {
                "fragments": [],
                "text": "Comparison of face verification results on the XM2VTFS database"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Results of the face verification contest that was organized in conjunction with International Conference on Pattern Recognition 2000 are presented, featuring representatives of the most common approaches to face verification -elastic graph matching, Fisher's linear discriminant and support vector machines."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 15th International Conference on Pattern Recognition. ICPR-2000"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055501916"
                        ],
                        "name": "Thomas Maurer",
                        "slug": "Thomas-Maurer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Maurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Maurer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 192
                            }
                        ],
                        "text": "To handle the pose variation problem, the pose of the face is .rst \ndetermined using prior class infor\u00admation [Kruger et al. 1997], and the jet transformations under pose \nvariation are learned [Maurer and Malsburg 1996a]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 183
                            }
                        ],
                        "text": "person are available [191, 192, 193, 194], 2) hybrid methods when multiple images are available during training but only one database image per person is available during recognition [80, 195, 196, 197], and 3) single image based methods when no training is carried out."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 188
                            }
                        ],
                        "text": "To handle the pose variation problem in face recognition, the face pose is rst determined using prior information [36] and the transformations of the sets under pose variation are learned [80]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11534904,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04c306621210fd9dc96b6106e1f5a6bd745ff5dd",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for recognizing objects (faces) on the basis of just one stored view, in spite of rotation in depth. The method is not based on the construction of a three-dimensional model for the object. Our recognition results represent a signi cant improvement over a previous system developed in our laboratory. We achieve this with the help of a simple assumption about the transformation of local feature vectors with rotation in depth."
            },
            "slug": "Single-View-Based-Recognition-of-Faces-Rotated-in-Maurer-Malsburg",
            "title": {
                "fragments": [],
                "text": "Single-View Based Recognition of Faces Rotated in Depth"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work presents a method for recognizing objects (faces) on the basis of just one stored view, in spite of rotation in depth, with the help of a simple assumption about the transformation of local feature vectors with rotation in Depth."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107746882"
                        ],
                        "name": "B. Li",
                        "slug": "B.-Li",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 57
                            }
                        ],
                        "text": "Some details about the tracking algorithm are as follows [Li and Chellappa 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 48
                            }
                        ],
                        "text": "Spatiotemporal methods Feature trajectory-based [Li and Chellappa 2001; Li et al. 2001a]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 14
                            }
                        ],
                        "text": "These methods [Li and Chellappa 2001; Li et al. 2001a] coherently exploit both spatial information (in each frame) and temporal information (such as the trajectories of facial features)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 75
                            }
                        ],
                        "text": "Tracking also plays a key role in spatiotemporal-based recognition methods [Li and Chellappa 2001; Li et al. 2001a] which directly use the tracking information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37700316,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92843560b02b290246ab2c82b017f6336149f913",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an algorithm for face verification through tracking facial features by using sequential importance sampling. Specifically, we first formulate tracking as a Bayesian inference problem and propose to use Markov chain Monte Carlo techniques for obtaining an empirical solution. A reparameterization is introduced under parametric motion assumption, which facilitates the empirical estimation and also allows verification to be addressed along with tracking. The facial features to be tracked are defined on a grid with Gabor attributes (jets). The motion of facial feature points is modeled as a global two-dimensional (2-D) affine transformation (accounting for head motion) plus a local deformation (accounting for residual motion that is due to inaccuracies in 2-D affine modeling and other factors such as facial expression). Motion of both types is processed simultaneously by the tracker: The global motion is estimated by importance sampling, and the residual motion is handled by incorporating local deformation into the measurement likelihood in computing the weight of a sample. Experiments with a real database of face image sequences are presented."
            },
            "slug": "Face-verification-through-tracking-facial-features.-Li-Chellappa",
            "title": {
                "fragments": [],
                "text": "Face verification through tracking facial features."
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "An algorithm for face verification through tracking facial features by using sequential importance sampling and a reparameterization is introduced under parametric motion assumption, which facilitates the empirical estimation and also allows verification to be addressed along with tracking."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics, image science, and vision"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932501"
                        ],
                        "name": "J. N. Bassili",
                        "slug": "J.-N.-Bassili",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Bassili",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. N. Bassili"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 8
                            }
                        ],
                        "text": "Bassili [134] suggested that motion in the image of a face could allow emotions to be identi ed even with minimal information about the spatial arrangement of the features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7451041,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2e1001a450974f4ab16721e2b8c2b48f32449db8",
            "isKey": false,
            "numCitedBy": 644,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In order to investigate the role of facial movement in the recognition of emotions, faces were covered with black makeup and white spots. Video recordings of such faces were played back so that only the white spots were visible. The results demonstrated that moving displays of happiness, sadness, fear, surprise, anger and disgust were recognized more accurately than static displays of the white spots at the apex of the expressions. This indicated that facial motion, in the absence of information about the shape and position of facial features, is informative about these basic emotions. Normally illuminated dynamic displays of these expressions, however, were recognized more accurately than displays of moving spots. The relative effectiveness of upper and lower facial areas for the recognition of these six emotions was also investigated using normally illuminated and spots-only displays. In both instances the results indicated that different facial regions are more informative for different emitions. The movement patterns characterizing the various emotional expressions as well as common confusions between emotions are also discussed."
            },
            "slug": "Emotion-recognition:-the-role-of-facial-movement-of-Bassili",
            "title": {
                "fragments": [],
                "text": "Emotion recognition: the role of facial movement and the relative importance of upper and lower areas of the face."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The results demonstrated that moving displays of happiness, sadness, fear, surprise, anger and disgust were recognized more accurately than static displays of the white spots at the apex of the expressions, indicating that facial motion, in the absence of information about the shape and position of facial features, is informative about these basic emotions."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of personality and social psychology"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586918"
                        ],
                        "name": "D. Stork",
                        "slug": "D.-Stork",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stork",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stork"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32533286"
                        ],
                        "name": "M. Hennecke",
                        "slug": "M.-Hennecke",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Hennecke",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hennecke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1467303,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23016ae7d4a5cf1401e4f5c11197800f3d94596a",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We give an overview of speechreading systems from the perspective of the face and gesture recognition community, paying particular attention to approaches to key design decisions and the benefits and drawbacks. We discuss the central issue of sensory integration how much processing of the acoustic and the visual information should go on before integration how should it be integrated. We describe several possible practical applications, and conclude with a list of important outstanding problems that seem amenable to attack using techniques developed in the face and gesture recognition community."
            },
            "slug": "Speechreading:-an-overview-of-image-processing,-and-Stork-Hennecke",
            "title": {
                "fragments": [],
                "text": "Speechreading: an overview of image processing, feature extraction, sensory integration and pattern recognition techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "An overview of speechreading systems from the perspective of the face and gesture recognition community is given, paying particular attention to approaches to key design decisions and the benefits and drawbacks."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21472040"
                        ],
                        "name": "Irfan Essa",
                        "slug": "Irfan-Essa",
                        "structuredName": {
                            "firstName": "Irfan",
                            "lastName": "Essa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irfan Essa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093562"
                        ],
                        "name": "Rawesak Tanawongsuwan",
                        "slug": "Rawesak-Tanawongsuwan",
                        "structuredName": {
                            "firstName": "Rawesak",
                            "lastName": "Tanawongsuwan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rawesak Tanawongsuwan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11135588"
                        ],
                        "name": "Scott Stillman",
                        "slug": "Scott-Stillman",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Stillman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Stillman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9982828,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d08a78a2dc387e500b6a017b16eea7e95f830716",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a robust real-time method for tracking and recognizing multiple people with multiple cameras. Our method uses both static and Pan-Tilt-Zoom (PTZ) cameras to provide visual attention. The PTZ camera system uses face recognition to register people in the scene and \u201clock-on\u201d to those individuals. The static camera system provides a global view of the environment and is used to re-adjust the tracking of the system when the PTZ cameras lose their targets. The system works well even when people occlude one another. The underlying visual processes rely on color segmentation, movement tracking and shape information to locate target candidates. Color indexing and face recognition modules help register these candidates with the system."
            },
            "slug": "A-System-for-Tracking-and-Recognizing-Multiple-with-Essa-Tanawongsuwan",
            "title": {
                "fragments": [],
                "text": "A System for Tracking and Recognizing Multiple People with Multiple Cameras"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper presents a robust real-time method for tracking and recognizing multiple people with multiple cameras that works well even when people occlude one another."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721722"
                        ],
                        "name": "N. Kr\u00fcger",
                        "slug": "N.-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Kr\u00fcger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kr\u00fcger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47284853"
                        ],
                        "name": "M. P\u00f6tzsch",
                        "slug": "M.-P\u00f6tzsch",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "P\u00f6tzsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. P\u00f6tzsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16559239,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2382359da7a5cae09cd7f675829239306487c757",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Determination-of-face-position-and-pose-with-a-on-Kr\u00fcger-P\u00f6tzsch",
            "title": {
                "fragments": [],
                "text": "Determination of face position and pose with a learned representation based on labelled graphs"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5258674,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a6b10ab0dddcfbd10e16b4219086a875198b15c",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In many vision problems, we want to infer two (or more) hidden factors which interact to produce our observations. We may want to disentangle illuminant and object colors in color constancy; rendering conditions from surface shape in shape-from-shading; face identity and head pose in face recognition; or font and letter class in character recognition. We refer to these two factors generically as \"style\" and \"content\". Bilinear models offer a powerful framework for extracting the two-factor structure of a set of observations, and are familiar in computational vision from several well-known lines of research. This paper shows how bilinear models can be used to learn the style-content structure of a pattern analysis or synthesis problem, which can then be generalized to solve related tasks using different styles and/or content. We focus on three tasks: extrapolating the style of data to unseen content classes, classifying data with known content under a novel style, and translating data from novel content classes and style to a known style or content. We show examples from color constancy, face pose estimation, shape-from-shading, typography and speech."
            },
            "slug": "Learning-bilinear-models-for-two-factor-problems-in-Freeman-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "Learning bilinear models for two-factor problems in vision"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper shows how bilinear models can be used to learn the style-content structure of a pattern analysis or synthesis problem, which can then be generalized to solve related tasks using different styles and/or content."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50564384"
                        ],
                        "name": "G. Edwards",
                        "slug": "G.-Edwards",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "Edwards",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 134
                            }
                        ],
                        "text": "More specifically, the following steps are needed: (1) removing the effects of orientation, (2) projecting into the identity subspace [Edwards et al. 1998], (3) projecting across into the subspace of the target model, and (4) adding the appropriate orientation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 148
                            }
                        ],
                        "text": "\u2026Lin et al. 1997; Moghaddam and Pentland 1997; Okada et al. 1998; Penev and Atick 1996; \nWechsler et al. 1997; Wiskott et al. 1997] Tracking-enhanced [Edwards et al. 1998; McKenna and Gong 1997, \n1998; Steffens et al. 1998] Multimodal methods Video-and audio-based [Bigun et al. 1998; Choudhury et\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 134
                            }
                        ],
                        "text": "More speci.cally, the following steps are needed: (1) remov\u00ading the effects of orientation, \n(2) pro\u00adjecting into the identity subspace [Ed\u00adwards et al. 1998], (3) projecting across into the subspace \nof the target model, and (4) adding the appropriate orienta\u00adtion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 276
                            }
                        ],
                        "text": "Categorization of Video-Based \nFace Recognition Techniques Approach Representative work Still-image methods Basic methods [Turk and \nPentland 1991; Lin et al. 1997; Moghaddam and Pentland 1997; Okada et al. 1998; Penev and Atick 1996; \nWechsler et al. 1997; Wiskott et al. 1997] Tracking-enhanced [Edwards et al. 1998; McKenna and Gong 1997, \n1998; Steffens et al. 1998] Multimodal methods Video-and audio-based [Bigun et al. 1998; Choudhury et \nal."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5497564,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "98f4a96d0bb9112fffceb108cbbab5bf80407f84",
            "isKey": true,
            "numCitedBy": 82,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of robust face identification in the presence of pose, lighting, and expression variation. Previous approaches to the problem have assumed similar models of variation for each individual, estimated from pooled training data. We describe a method of updating a first order global estimate of identity by learning the class-specific correlation between the estimate and the residual variation during a sequence. This is integrated with an optimal tracking scheme, in which identity variation is decoupled from pose, lighting and expression variation. The method results in robust tracking and a more stable estimate of facial identity under changing conditions."
            },
            "slug": "Learning-to-identify-and-track-faces-in-image-Edwards-Taylor",
            "title": {
                "fragments": [],
                "text": "Learning to identify and track faces in image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A method of updating a first order global estimate of identity by learning the class-specific correlation between the estimate and the residual variation during a sequence is described, integrated with an optimal tracking scheme, in which identity variation is decoupled from pose, lighting and expression variation."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768120"
                        ],
                        "name": "T. Jebara",
                        "slug": "T.-Jebara",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Jebara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jebara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2707321"
                        ],
                        "name": "Kenneth B. Russell",
                        "slug": "Kenneth-B.-Russell",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Russell",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth B. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2112235,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86fd73a94640da250e7d456482f0690095707eb3",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a face modeling system which estimates complete facial structure and texture from a real-time video stream. The system begins with a face trading algorithm which detects and stabilizes live facial images into a canonical 3D pose. The resulting canonical texture is then processed by a statistical model to filter imperfections and estimate unknown components such as missing pixels and underlying 3D structure. This statistical model is a soft mixture of eigenfeature selectors which span the 3D deformations and texture changes across a training set of laser scanned faces. An iterative algorithm is introduced for determining the dimensional partitioning of the eigenfeatures to maximize their generalization capability over a cross-validation set of data. The model's abilities to filter and estimate absent facial components are then demonstrated over incomplete 3D data. This ultimately allows the model to span known and regress unknown facial information front stabilized natural video sequences generated by a face tracking algorithm. The resulting continuous and dynamic estimation of the model's parameters over a video sequence generates a compact temporal description of the 3D deformations and texture changes of the face."
            },
            "slug": "Mixtures-of-eigenfeatures-for-real-time-structure-Jebara-Russell",
            "title": {
                "fragments": [],
                "text": "Mixtures of eigenfeatures for real-time structure from texture"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A face modeling system which estimates complete facial structure and texture from a real-time video stream and allows the model to span known and regress unknown facial information front stabilized natural video sequences generated by a face tracking algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2746834,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "00afe07e6bb6880b9c83faf8aee3ffc60cd3a2ae",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of determining whether two images come from different objects or the same object in the same pose, but under different illumination conditions. We show that this problem cannot be solved using hard constraints: even using a Lambertian reflectance model, there is always an object and a pair of lighting conditions consistent with any two images. Nevertheless, we show that for point sources and objects with Lambertian reflectance, the ratio of two images from the same object is simpler than the ratio of images from different objects. We also show that the ratio of the two images provides two of the three distinct values in the Hessian matrix of the object's surface. Using these observations, we develop a simple measure for matching images under variable illumination, comparing its performance to other existing methods on a database of 450 images of 10 individuals."
            },
            "slug": "Comparing-images-under-variable-illumination-Jacobs-Belhumeur",
            "title": {
                "fragments": [],
                "text": "Comparing images under variable illumination"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that for point sources and objects with Lambertian reflectance, the ratio of two images from the same object is simpler than the ratios of images from different objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145926447"
                        ],
                        "name": "J. Weng",
                        "slug": "J.-Weng",
                        "structuredName": {
                            "firstName": "Juyang",
                            "lastName": "Weng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 24
                            }
                        ],
                        "text": "We list here only books [86, 87, 106, 107, 108, 109] and review papers [110, 111, 112]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118334964,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "8f0a97f4006c69f314e1e7946f4f904b64d31e5c",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Estimating motion and structure of the scene from image sequences is a very important and active research area in computer vision. The results of research have applications in vision-guided navigation, robot vision, 3-D object recognition and manipulation etc. Many theoretical results and new techniques developed may also apply to the related problems of other fields. \nComputing the image displacement field, or matching two images is one of the difficult problems in motion analysis. A computational approach to image matching has been developed that uses multiple attributes associated with images to yield a generally overdetermined system of matching constraints, taking into account possible structural discontinuities and occlusions. \nFrom the computed image displacement field, the next step is to compute the motion parameters and the structure of the scene. A two-step approach is introduced to solve the nonlinear optimization problem reliably and efficiently. The uniqueness of solution, robustness of the solution in the presence of noise, estimation of errors, dependency of the reliability of solution on motion, scene, and the parameters of image sensors have been investigated. It is analyzed that a batch processing technique (Levenberg-Marquardt nonlinear least-squares method) generally performs better than a sequential processing technique (iterated extended Kalman filtering) for nonlinear problems. For those problems where estimates are needed before all the data are acquired, a recursive batch processing technique has been developed to improve performance and computational efficiency. The performance of the motion estimation algorithm has essentially reached the Cramer-Rao bound. \nThe algorithm has been applied to real world scenes with depth discontinuities and occlusions to compute motion parameters, dense depth maps and occlusion maps, from two images taken at different unknown positions and orientations relative to the scene. The standard discrepancy between the projection of the inferred 3-D scene and the actually observed projection is as small as one half of a pixel. \nOther problems investigated include: (1) motion and structure from point correspondences for planar scenes. (2) motion and structure from line correspondences. (3) dynamic motion estimation and prediction from long image sequences."
            },
            "slug": "Motion-and-Structure-from-Image-Sequences-Weng-Ahuja",
            "title": {
                "fragments": [],
                "text": "Motion and Structure from Image Sequences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107496353"
                        ],
                        "name": "W. Zhao",
                        "slug": "W.-Zhao",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Zhao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 131
                            }
                        ],
                        "text": "However, with\u00adout \naccurate face and feature location, no\u00adticeable degradation in recognition perfor\u00admance is observed [Martinez \n2002; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 80
                            }
                        ],
                        "text": "Other \nheuristic methods based on frontal-face symmetry have also been proposed [Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 175
                            }
                        ],
                        "text": "For a limited class of objects such as face images that are normalized with respect to scale, trans\u00adlation, \nand rotation, the redundancy is even greater [Penev and Atick 1996; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 120
                            }
                        ],
                        "text": "Face recognition systems using Linear/Fisher Discriminant Analysis [55] as the classi er have also been very successful [56, 57, 58, 59, 60, 61, 62, 63]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 40
                            }
                        ],
                        "text": "They can be divided into three classes \n[Zhao 1999]: (1) multiview im\u00adage methods, when multiview database images of each person are available; \n(2) hybrid methods, when multiview training images are available during training but only one database \nimage per person is available during recognition;\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 235
                            }
                        ],
                        "text": "This claim has been supported by limited experiments \nusing normal\u00adized face images of different sizes, for 12Early work using range images was reported in \nGordon [1991]. example, from 12 \u00d7 11 to 48 \u00d7 42, to obtain different face subspaces [Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 171
                            }
                        ],
                        "text": "This is true even for holistic matching methods, since accurate location of key facial fea\u00adtures \nsuch as eyes is required to normal\u00adize the detected face [Yang et al. 2002; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "This claim was supported by experiments using normalized face images of di erent sizes to obtain di erent face subspaces [62]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 49
                            }
                        ],
                        "text": "These approaches \ncan be divided into four types [Zhao 1999]: (1) heuristic methods, for example, discarding the leading \nprincipal components; (2) im\u00adage comparison methods in which appro\u00adpriate image representations and distance \nmeasures are used; (3) class-based meth\u00adods using multiple images\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 100
                            }
                        ],
                        "text": "To assess the pose problem more sys\u00adtematically, an attempt has been made to classify pose problems [Zhao \n1999; Zhao and Chellappa 2000b]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 86
                            }
                        ],
                        "text": "A weighted distance metric \nin the pro\u00adjection space z was used to improve per\u00adformance [Zhao 1999].8 Finally, the LDA 7This makes \nsense because the .nal classi.cation is carried out in the projection space z by comparison with prestored \nprojection vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17746953,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d47898a2e1605a6eb06907e137d512b6002787b",
            "isKey": true,
            "numCitedBy": 16,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, several new applications for subspace methods are introduced, including: (1) subspace method used for overcoming generalization/overfitting problem for applications such as face recognition, (2) multiple subspaces constructed from the original subspace to accommodate the inputs distorted by scaling, rotating, translating etc. and (3) a subspace framework based on which the original signal can be transformed into the subspace of a much higher dimension space through a nonlinear mapping. This nonlinear mapping provides an alternative to direct nonlinear classification in the original space, that is to perform a linear classification in this subspace."
            },
            "slug": "Subspace-methods-in-object/face-recognition-Zhao",
            "title": {
                "fragments": [],
                "text": "Subspace methods in object/face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper introduces a subspace framework based on which the original signal can be transformed into the subspace of a much higher dimension space through a nonlinear mapping, which provides an alternative to direct nonlinear classification in the original space."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35146156"
                        ],
                        "name": "M. Lades",
                        "slug": "M.-Lades",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Lades",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3189439"
                        ],
                        "name": "J. Vorbr\u00fcggen",
                        "slug": "J.-Vorbr\u00fcggen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Vorbr\u00fcggen",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vorbr\u00fcggen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075388397"
                        ],
                        "name": "J. Lange",
                        "slug": "J.-Lange",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Lange",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lange"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038814"
                        ],
                        "name": "R. W\u00fcrtz",
                        "slug": "R.-W\u00fcrtz",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "W\u00fcrtz",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. W\u00fcrtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34993891"
                        ],
                        "name": "W. Konen",
                        "slug": "W.-Konen",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Konen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Konen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1266405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fb52984078d75ec5655962dc94dc7848182286b",
            "isKey": false,
            "numCitedBy": 2072,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented. The dynamic link architecture exploits correlations in the fine-scale temporal structure of cellular signals to group neurons dynamically into higher-order entities. These entities represent a rich structure and can code for high-level objects. To demonstrate the capabilities of the dynamic link architecture, a program was implemented that can recognize human faces and other objects from video images. Memorized objects are represented by sparse graphs, whose vertices are labeled by a multiresolution description in terms of a local power spectrum, and whose edges are labeled by geometrical distance vectors. Object recognition can be formulated as elastic graph matching, which is performed here by stochastic optimization of a matching cost function. The implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images. The performance of the program is evaluated by a statistical analysis of recognition results from a portrait gallery comprising images of 87 persons. >"
            },
            "slug": "Distortion-Invariant-Object-Recognition-in-the-Link-Lades-Vorbr\u00fcggen",
            "title": {
                "fragments": [],
                "text": "Distortion Invariant Object Recognition in the Dynamic Link Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented and the implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Computers"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49052113"
                        ],
                        "name": "S. Akamatsu",
                        "slug": "S.-Akamatsu",
                        "structuredName": {
                            "firstName": "Shigeru",
                            "lastName": "Akamatsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Akamatsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110791903"
                        ],
                        "name": "Tsutomu Sasaki",
                        "slug": "Tsutomu-Sasaki",
                        "structuredName": {
                            "firstName": "Tsutomu",
                            "lastName": "Sasaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsutomu Sasaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143906699"
                        ],
                        "name": "H. Fukamachi",
                        "slug": "H.-Fukamachi",
                        "structuredName": {
                            "firstName": "Hideo",
                            "lastName": "Fukamachi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Fukamachi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49721559"
                        ],
                        "name": "Nobuhiko Masui",
                        "slug": "Nobuhiko-Masui",
                        "structuredName": {
                            "firstName": "Nobuhiko",
                            "lastName": "Masui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nobuhiko Masui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34857543"
                        ],
                        "name": "Y. Suenaga",
                        "slug": "Y.-Suenaga",
                        "structuredName": {
                            "firstName": "Yasuhito",
                            "lastName": "Suenaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Suenaga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61857749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f762055c98ad8fb93719471302c41d468fed0369",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Proposes a scheme that offers accurate and robust identification of human faces. The scheme is characterized by four aspects: facial feature detection using color image segmentation; target image extraction using a sub-space classification method; robust feature extraction based on K-L expansion of an invariant feature space; and face classifier training based on 3D CG modeling of the human face. The scheme's flexibility under a wide range of image acquisition conditions has been confirmed through the assessment of an experimental face identification system.<<ETX>>"
            },
            "slug": "An-accurate-and-robust-face-identification-scheme-Akamatsu-Sasaki",
            "title": {
                "fragments": [],
                "text": "An accurate and robust face identification scheme"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "The proposed scheme is characterized by four aspects: facial feature detection using color image segmentation; target image extraction using a sub-space classification method; robust feature extraction based on K-L expansion of an invariant feature space; and face classifier training based on 3D CG modeling of the human face."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2417905"
                        ],
                        "name": "H. Ellis",
                        "slug": "H.-Ellis",
                        "structuredName": {
                            "firstName": "Hadyn",
                            "lastName": "Ellis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ellis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144568050"
                        ],
                        "name": "M. Jeeves",
                        "slug": "M.-Jeeves",
                        "structuredName": {
                            "firstName": "Malcolm",
                            "lastName": "Jeeves",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jeeves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4921384"
                        ],
                        "name": "F. Newcombe",
                        "slug": "F.-Newcombe",
                        "structuredName": {
                            "firstName": "Freda",
                            "lastName": "Newcombe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Newcombe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087095606"
                        ],
                        "name": "A. Young",
                        "slug": "A.-Young",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Young",
                            "middleNames": [
                                "W"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Young"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 142320865,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6f4b506655e609fcbb99e53e4ac3f4b734931b8e",
            "isKey": false,
            "numCitedBy": 419,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction.- to aspects of face processing: Ten questions in need of answers.- 2. Perceptual Processes.- Microgenesis of face perception..- Recognition memory transfer between spatial- frequency analyzed faces..- Reaction time measures of feature saliency in a perceptual integration task..- Perception of upside-down faces: An analysis from the viewpoint of cue-saliency..- 3. Memory Processes.- On the memorability of the human face..- Face recognition is not unique. Evidence from individual differences..- Lateral reversal and facial recognition memory: Are right-lookers special?.- Context effects in recognition memory of faces: Some theoretical problems..- 4. Cognitive Processes.- Recognising familiar faces..- Face recognition: More than a feeling of familiarity?.- Getting semantic information from familiar faces..- What happens when a face rings a bell?: The automatic processing of famous faces..- 5. Socio-Cognitive Factors.- Levels of representation and memory for faces..- Formation of facial prototypes..- Stereotyping and face memory..- The influence of race on face recognition..- Faces, prototypes, and additive tree representations..- 6. Cortical Specialisation.- Functional organization of visual neurones processing face identity..- Hemispheric asymmetry in face processing in infancy..- Models of laterality effects in face perception..- Hemispheric asymmetries in face recognition and naming: effects of prior stimulus exposure..- Patterns of cerebral dominance in wholistic and featural stages of facial processing..- Hemispheric differences in the evoked potential to face stimuli..- Cerebral and behavioural asymmetries in the processing of \"unusual\" faces: A review..- 7. Prosopagnosias.- Current issues on prosopagnosia..- The cognitive psychophysiology of prosopagnosia..- Prosopagnosia: Anatomic and physiologic aspects..- Faces and non-faces in prosopagnosic patients..- Observations on a case of prosopagnosia..- 8. Brain Pathology.- Facial processing in the dementias..- The matching of famous and unknown faces, given either the internal or the external features: A study on patients with unilateral brain lesions..- Face recognition dysfunction and delusional mis identification syndromes (D.M.S.)..- 9. Facial Expressions.- Facial expression processing..- The perception of action versus feeling in facial expression..- Towards the quantification of facial expressions with the use of a mathematic model of the face..- Is the faster processing of expressions of happiness modality-specific?.- Primary stages in single-glance face recognition: Expression and identity..- Affective and cognitive decisions on faces in normals..- 10. Applications and Computer Technology.- Dynamics of facial recall..- The recall and reconstruction of faces: Implications for theory and practice..- An interactive computer system for retrieving faces..- Investigating face recognition with an image processing computer..- Practical face recognition and verification with WISARD..- 11. An Overview.- Plenary session. An overview. Complementary approaches to common problems in face recognition..- 12. References.- Addresses of Principal Authors."
            },
            "slug": "Aspects-of-face-processing-Ellis-Jeeves",
            "title": {
                "fragments": [],
                "text": "Aspects of face processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 162
                            }
                        ],
                        "text": "More \nrecently, an illumination cone has been proposed as an effective method of handling illumination variations, \nin\u00adcluding shadowing and multiple light sources [Belhumeur and Kriegman 1997; Georghiades et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 160
                            }
                        ],
                        "text": "More recently, an illumination cone has been proposed as an e ective method of handling illumination variations, including shadowing and multiple light sources [185, 186]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 154
                            }
                        ],
                        "text": "3 Class-Based Approaches Under the assumptions of Lambertian surfaces and no shadowing, a 3D linear illumination subspace for a person was constructed in [66, 67, 184, 185] for a xed viewpoint, using three aligned faces/images acquired under di erent lighting conditions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 42
                            }
                        ],
                        "text": "More recently, an illumination-cone\u00adbased \n[Belhumeur and Kriegman 1997] image synthesis method [Georghiades et al. 1999] has been proposed to han\u00addle \nboth pose and illumination problems in face recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 55
                            }
                        ],
                        "text": "This method is based on the illumination cone approach [185]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 182
                            }
                        ],
                        "text": "The rationale for develop such a method of directly comparing images is the poten\u00adtial dif.culty \nof building a complete repre\u00adsentation of an object s possible images as suggested in [Belhumeur and \nKriegman 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2580433,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "acd0e8aedd2bb81a0cd8714ac350f9aac67c33ed",
            "isKey": true,
            "numCitedBy": 491,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The appearance of a particular object depends on both the viewpoint from which it is observed and the light sources by which it is illuminated. If the appearance of two objects is never identical for any pose or lighting conditions, then-in theory - the objects can always be distinguished or recognized. The question arises: What is the set of images of an object under all lighting conditions and pose? In this paper, we consider only the set of images of an object under variable illumination (including multiple, extended light sources and attached shadows). We prove that the set of n-pixel images of a convex object with a Lambertian reflectance function, illuminated by an arbitrary number of point light sources at infinity, forms a convex polyhedral cone in IR/sup n/ and that the dimension of this illumination cone equals the number of distinct surface normals. Furthermore, we show that the cone for a particular object can be constructed from three properly chosen images. Finally, we prove that the set of n-pixel images of an object of any shape and with an arbitrary reflectance function, seen under all possible illumination conditions, still forms a convex cone in IR/sup n/. These results immediately suggest certain approaches to object recognition. Throughout this paper, we offer results demonstrating the empirical validity of the illumination cone representation."
            },
            "slug": "What-is-the-set-of-images-of-an-object-under-all-Belhumeur-Kriegman",
            "title": {
                "fragments": [],
                "text": "What is the set of images of an object under all possible lighting conditions?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is proved that the set of n-pixel images of a convex object with a Lambertian reflectance function, illuminated by an arbitrary number of point light sources at infinity, forms a conveX polyhedral cone in IR/sup n/ and that the dimension of this illumination cone equals the number of distinct surface normals."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2160942"
                        ],
                        "name": "R. Baron",
                        "slug": "R.-Baron",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Baron",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Baron"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "The procedure is claimed to be superior to other correlation-based schemes such as that of [48] in the sense that it is independent of scale or orientation."
                    },
                    "intents": []
                }
            ],
            "corpusId": 29658209,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "0fb4d98ac0a2f3c6f058ec4b2c25835ee8a24fcc",
            "isKey": false,
            "numCitedBy": 226,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Mechanisms-of-Human-Facial-Recognition-Baron",
            "title": {
                "fragments": [],
                "text": "Mechanisms of Human Facial Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Man Mach. Stud."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32250556"
                        ],
                        "name": "D. H. Cooper",
                        "slug": "D.-H.-Cooper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cooper",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. H. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47581828"
                        ],
                        "name": "J. Graham",
                        "slug": "J.-Graham",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Graham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Graham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 119
                            }
                        ],
                        "text": "Compared to this model, which is manually designed, the statistical \nshape model (Active Shape Model, ASM) pro\u00adposed in [Cootes et al. 1995] offers more .exibility and robustness."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 71
                            }
                        ],
                        "text": "The appearance model is a combination of the active shape model (ASM) [Cootes et al. 1995] and the shape-free \ntexture model after warping the face into a mean shape."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 132
                            }
                        ],
                        "text": "To de\u00adtect the features more reliably, recent \nap\u00adproaches have used structural matching methods, for example, the Active Shape Model [Cootes et al. \n1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 86
                            }
                        ],
                        "text": "It extends the linear shape model (which is very similar to the active shape model of [198]) from a representation based on feature points to full images of objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 104
                            }
                        ],
                        "text": "The multiview dy\u00adnamic face model [Li et al. \n2001b] con\u00adsists of a sparse Point Distribution Model (PDM) [Cootes et al. 1995], a shape-and\u00adpose-free \ntexture model, and an af.ne ge\u00adometrical model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15242659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f731b6745d829241941307c3ebf163e90e200318",
            "isKey": true,
            "numCitedBy": 7909,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "!, Model-based vision is firmly established as a robust approach to recognizing and locating known rigid objects in the presence of noise, clutter, and occlusion. It is more problematic to apply modelbased methods to images of objects whose appearance can vary, though a number of approaches based on the use of flexible templates have been proposed. The problem with existing methods is that they sacrifice model specificity in order to accommodate variability, thereby compromising robustness during image interpretation. We argue that a model should only be able to deform in ways characteristic of the class of objects it represents. We describe a method for building models by learning patterns of variability from a training set of correctly annotated images. These models can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes). The key difference is that our Active Shape Models can only deform to fit the data in ways consistent with the training set. We show several practical examples where we have built such models and used them to locate partially occluded objects in noisy, cluttered images. Q 199s A&& prrss, IN."
            },
            "slug": "Active-Shape-Models-Their-Training-and-Application-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Active Shape Models-Their Training and Application"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work describes a method for building models by learning patterns of variability from a training set of correctly annotated images that can be used for image search in an iterative refinement algorithm analogous to that employed by Active Contour Models (Snakes)."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143905691"
                        ],
                        "name": "J. Beveridge",
                        "slug": "J.-Beveridge",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Beveridge",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beveridge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33841710"
                        ],
                        "name": "Kai She",
                        "slug": "Kai-She",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "She",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai She"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694404"
                        ],
                        "name": "B. Draper",
                        "slug": "B.-Draper",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Draper",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Draper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750370"
                        ],
                        "name": "G. Givens",
                        "slug": "G.-Givens",
                        "structuredName": {
                            "firstName": "Geof",
                            "lastName": "Givens",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Givens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 104
                            }
                        ],
                        "text": "Recently, systematic \ncomparisons and independent reevaluations of ex\u00adisting methods have been published [Beveridge et al. \n2001]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 533019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e949aed040f393f45f05507a30a14a0feb920608",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The FERET evaluation compared recognition rates for different semi-automated and automated face recognition algorithms. We extend FERET by considering when differences in recognition rates are statistically distinguishable subject to changes in test imagery. Nearest Neighbor classifiers using principal component and linear discriminant subspaces are compared using different choices of distance metric. Probability distributions for algorithm recognition rates and pairwise differences in recognition rates are determined using a permutation methodology. The principal component subspace with Mahalanobis distance is the best combination; using L2 is second best. Choice of distance measure for the linear discriminant subspace matters little, and performance is always worse than the principal components classifier using either Mahalanobis or L1 distance. We make the source code for the algorithms, scoring procedures and Monte Carlo study available in the hopes others will extend this comparison to newer algorithms."
            },
            "slug": "A-nonparametric-statistical-comparison-of-principal-Beveridge-She",
            "title": {
                "fragments": [],
                "text": "A nonparametric statistical comparison of principal component and linear discriminant subspaces for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This work extends FERET by considering when differences in recognition rates are statistically distinguishable subject to changes in test imagery and makes the source code for the algorithms, scoring procedures and Monte Carlo study available in the hopes others will extend this comparison to newer algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 39
                            }
                        ],
                        "text": "1997], (3) a linear class-based method [Blanz and Vetter 1999; Vetter and Poggio 1997], (4) a vectorized image representation based method [Beymer 1995; Beymer and Poggio 1995], and (5) a view-based appearance model [Cootes"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10047234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "617b34332fcd1cb196f93656ee1d49561b81ebf8",
            "isKey": false,
            "numCitedBy": 471,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The need to generate new views of a 3D object from a single real image arises in several fields, including graphics and object recognition. While the traditional approach relies on the use of 3D models, simpler techniques are applicable under restricted conditions. The approach exploits image transformations that are specific to the relevant object class, and learnable from example views of other \"prototypical\" objects of the same class. In this paper, we introduce such a technique by extending the notion of linear class proposed by the authors (1992). For linear object classes, it is shown that linear transformations can be learned exactly from a basis set of 2D prototypical views. We demonstrate the approach on artificial objects and then show preliminary evidence that the technique can effectively \"rotate\" high-resolution face images from a single 2D view."
            },
            "slug": "Linear-Object-Classes-and-Image-Synthesis-From-a-Vetter-Poggio",
            "title": {
                "fragments": [],
                "text": "Linear Object Classes and Image Synthesis From a Single Example Image"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "For linear object classes, it is shown that linear transformations can be learned exactly from a basis set of 2D prototypical views and preliminary evidence that the technique can effectively \"rotate\" high-resolution face images from a single 2D view is shown."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34993891"
                        ],
                        "name": "W. Konen",
                        "slug": "W.-Konen",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Konen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Konen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 35
                            }
                        ],
                        "text": "2 Sketches and Infra-Red Images In [83, 84], face recognition based on sketches, which are quite common in law enforcement, is described."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [84], a system called PHANTOMAS (phantom automatic search) is described."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 100457,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10b4199240e9a1400319a031608e359bb18db900",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We report on an application of neural face recognition algorithms to a task with relevance to forensic investigations: The software tool PHANTOMAS (phantom automatic search) allows to compare facial line drawings (the German \u201cPhantomzeichnung\u201d) with gray-level images of faces. In addition to normal (textual) database search actions, this software tool allows picture-to-picture searches. We present first results on the evaluation of a benchmark on this task. The ranking quality of PHANTOMAS allows to spot the true match belonging to a certain drawing on the average within the upper 2.7% of the database (N=103). It is shown that this is comparable to the human performance on the same data material. Computation time makes it feasible to search online in large databases (N \u2248 10000). \u2014 With the same algorithm it is also possible to classify complex characteristica in faces or facial line drawings, which we demonstrate on the example of gender classification."
            },
            "slug": "Comparing-Facial-Line-Drawings-with-Gray-Level-A-on-Konen",
            "title": {
                "fragments": [],
                "text": "Comparing Facial Line Drawings with Gray-Level Images: A Case Study on PHANTOMAS"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The ranking quality of PHANTOMAS allows to spot the true match belonging to a certain drawing on the average within the upper 2.7% of the database (N=103), and it is shown that this is comparable to the human performance on the same data material."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2958806"
                        ],
                        "name": "S. A. Rizvi",
                        "slug": "S.-A.-Rizvi",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Rizvi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. A. Rizvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40638847"
                        ],
                        "name": "Hyeonjoon Moon",
                        "slug": "Hyeonjoon-Moon",
                        "structuredName": {
                            "firstName": "Hyeonjoon",
                            "lastName": "Moon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyeonjoon Moon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 92
                            }
                        ],
                        "text": "In the recent com\u00adprehensive \nFERET evaluations [Phillips et al. 2000; Phillips et al. 1998b; Rizvi et al. 1998], aimed at evaluating \ndif\u00adferent systems using the same large database containing thousands of images, the systems described \nin Moghaddam and Pentland [1997]; Swets and Weng [1996b];\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 62
                            }
                        ],
                        "text": "The se\u00adries of FERET evaluations [Phillips et al. 2000b, 1998; Rizvi et al. 1998]17 \nattracted nine institutions and companies to partic\u00adipate."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 148
                            }
                        ],
                        "text": "\u2026Recognition (AFGR) since 1995, system\u00adatic \nempirical evaluations of face recog\u00adnition techniques (FRT), including the FERET [Phillips et al. 1998b, \n2000; Rizvi et al. 1998], FRVT 2000 [Blackburn et al. 2001], FRVT 2002 [Phillips et al. 2003], and XM2VTS \n[Messer et al. 1999] pro\u00adtocols, and\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 14631640,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8620814aa00631b03195e183c1e86d24b1c5caa5",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Two key performance characterization of biometric algorithms (face recognition in particular) are (1) verification performance and (2) and performance as a function of database size and composition. This characterization is required for developing robust face recognition algorithms and for successfully transitioning algorithms from the laboratory to real world. In this paper we (1) present a general verification protocol and apply it to the results from the Sep96 FERET test, and (2) discuss and present results on the effects of database size and variability on identification and verification performance."
            },
            "slug": "A-verification-protocol-and-statistical-performance-Rizvi-Phillips",
            "title": {
                "fragments": [],
                "text": "A verification protocol and statistical performance analysis for face recognition algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A general verification protocol is presented and applied to the results from the Sep96 FERET test, and results on the effects of database size and variability on identification and verification performance are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61999742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5648d1f511a5180cc0bf7af80a42d3dea3a4680",
            "isKey": false,
            "numCitedBy": 322,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation. In contrast to the traditional approach, they formulate the recognition problem as one of matching visual appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties of an object and are constant, pose and illumination vary from scene to scene. They present a new compact representation of object appearance that is parameterized by pose and illumination. They have conducted experiments using several objects with complex appearance characteristics.<<ETX>>"
            },
            "slug": "Learning-and-recognition-of-3D-objects-from-Murase-Nayar",
            "title": {
                "fragments": [],
                "text": "Learning and recognition of 3D objects from appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation as one of matching visual appearance rather than shape and present a new compact representation of object appearance that is parameterized by pose and illumination."
            },
            "venue": {
                "fragments": [],
                "text": "[1993] Proceedings IEEE Workshop on Qualitative Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145469814"
                        ],
                        "name": "R. McCabe",
                        "slug": "R.-McCabe",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "McCabe",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McCabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 69
                            }
                        ],
                        "text": "In the recent com\u00adprehensive \nFERET evaluations [Phillips et al. 2000; Phillips et al. 1998b; Rizvi et al. 1998], aimed at evaluating \ndif\u00adferent systems using the same large database containing thousands of images, the systems described \nin Moghaddam and Pentland [1997]; Swets and Weng [1996b];\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 149
                            }
                        ],
                        "text": "\u2026on Automatic Face and Gesture Recognition (AFGR) since 1995, system\u00adatic \nempirical evaluations of face recog\u00adnition techniques (FRT), including the FERET [Phillips et al. 1998b, \n2000; Rizvi et al. 1998], FRVT 2000 [Blackburn et al. 2001], FRVT 2002 [Phillips et al. 2003], and XM2VTS \n[Messer et\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 258
                            }
                        ],
                        "text": "The second FERET evaluation was adminis\u00ad 17http://www.itl.nist.gov/iad/humanid/feret/. \ntered in March 1995; it consisted of a sin\u00adgle test that measured identi.cation per\u00adformance from a gallery \nof 817 individ\u00aduals, and included 463 duplicates in the probe set [Phillips et al. 1998b]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "The .rst FERET evaluation \ntest was administered in August 1994 [Phillips et al. 1998b]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 33
                            }
                        ],
                        "text": "The se\u00adries of FERET evaluations [Phillips et al. 2000b, 1998; Rizvi et al. 1998]17 \nattracted nine institutions and companies to partic\u00adipate."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16497127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7fa4d5eea02d8b1775227d6dd1a10ba5d37c758",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Biometric-based identification and verification systems are poised to become a key technology, with applications including controlling access to 'buildings and computers, reducing fraudulent transactions in electronic commerce, and discouraging illegal immigration. There are at least eight image-based biometrics that are being actively considered. In image-based biometrics, the biometric signature is acquired as an image and the image is processed using techniques from computer vision, image understanding, and pattern recognition. We consider two promising image-based biometrics, faces and fingerprints. For each, we provide a critical assessment of the state of the art, suggest future research directions, and identify technological challenges."
            },
            "slug": "Biometric-image-processing-and-recognition-Phillips-McCabe",
            "title": {
                "fragments": [],
                "text": "Biometric image processing and recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work considers two promising image-based biometrics, faces and fingerprints, and provides a critical assessment of the state of the art, suggest future research directions, and identify technological challenges."
            },
            "venue": {
                "fragments": [],
                "text": "9th European Signal Processing Conference (EUSIPCO 1998)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 21
                            }
                        ],
                        "text": "person are available [191, 192, 193, 194], 2) hybrid methods when multiple images are available during training but only one database image per person is available during recognition [80, 195, 196, 197], and 3) single image based methods when no training is carried out."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8989489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d781d5e651e12bf666cf993ae307db785113b9ae",
            "isKey": false,
            "numCitedBy": 951,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed. It is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views. For objects with sharp edges, the linear combination representation is exact. For objects with smooth boundaries, it is an approximation that often holds over a wide range of viewing angles. Rigid transformations (with or without scaling) can be distinguished from more general linear transformations of the object by testing certain constraints placed on the coefficients of the linear combinations. Three alternative methods of determining the transformation that matches a model to a given image are proposed. >"
            },
            "slug": "Recognition-by-Linear-Combinations-of-Models-Ullman-Basri",
            "title": {
                "fragments": [],
                "text": "Recognition by Linear Combinations of Models"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed and it is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145328018"
                        ],
                        "name": "M. Oren",
                        "slug": "M.-Oren",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Oren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7967646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd0534a87e09b3d64b7e7462e2684c60c9aca1f5",
            "isKey": false,
            "numCitedBy": 837,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a trainable object detection architecture that is applied to detecting people in static images of cluttered scenes. This problem poses several challenges. People are highly non-rigid objects with a high degree of variability in size, shape, color, and texture. Unlike previous approaches, this system learns from examples and does not rely on any a priori (hand-crafted) models or on motion. The detection technique is based on the novel idea of the wavelet template that defines the shape of an object in terms of a subset of the wavelet coefficients of the image. It is invariant to changes in color and texture and can be used to robustly define a rich and complex class of objects such as people. We show how the invariant properties and computational efficiency of the wavelet template make it an effective tool for object detection."
            },
            "slug": "Pedestrian-detection-using-wavelet-templates-Oren-Papageorgiou",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection using wavelet templates"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This paper presents a trainable object detection architecture that is applied to detecting people in static images of cluttered scenes and shows how the invariant properties and computational efficiency of the wavelet template make it an effective tool for object detection."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36427051"
                        ],
                        "name": "Peter W. Hallinan",
                        "slug": "Peter-W.-Hallinan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hallinan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter W. Hallinan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 112
                            }
                        ],
                        "text": "An interesting comparison was made between the \nproposed method and the 3D linear illumination subspace methods [Hallinan 1994; Shashua 1994]; the 3D \nlinear methods are just .rst-order harmonic approximations without the DC components."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 61
                            }
                        ],
                        "text": "This method is an extension of the 3D linear subspace method [Hallinan 1994; Shashua 1994] and has the same drawback, requiring at least three aligned training images acquired under different lighting conditions per person."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 111
                            }
                        ],
                        "text": "An interesting comparison was made between the proposed method and the 3D linear illumination subspace methods [Hallinan 1994; Shashua 1994]; the 3D linear methods are just first-order harmonic approximations without the DC components."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 62
                            }
                        ],
                        "text": "This method is an extension of the 3D linear subspace method [Hallinan 1994; Shashua 1994] and has the \nsame drawback, requiring at least three aligned training images acquired under different lighting con\u00additions \nper person."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46324024,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "236c132eda073ad7e80fcc45a248ac2baea9a786",
            "isKey": true,
            "numCitedBy": 342,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "When recognizing a fixed object from a fixed viewpoint, the dominant source of variation in image intensity is lighting changes. We propose a low-dimensional model for human faces that can both synthesize a face image when given lighting conditions and can estimate lighting conditions when given a face image. The model can handle non-Lambertian and self-shadowing surfaces such as faces because it does not make any assumptions about either the surface geometry or bidirectional reflectance function. The model can be adapted to handle any arbitrary lighting condition, and is easily extendable to any other viewpoint or to any other object.<<ETX>>"
            },
            "slug": "A-low-dimensional-representation-of-human-faces-for-Hallinan",
            "title": {
                "fragments": [],
                "text": "A low-dimensional representation of human faces for arbitrary lighting conditions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A low-dimensional model for human faces is proposed that can both synthesize a face image when given lighting conditions and can estimate lighting conditions when given a face images."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753908"
                        ],
                        "name": "Michael Elad",
                        "slug": "Michael-Elad",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Elad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Elad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153902"
                        ],
                        "name": "A. Feuer",
                        "slug": "A.-Feuer",
                        "structuredName": {
                            "firstName": "Arie",
                            "lastName": "Feuer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Feuer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 95
                            }
                        ],
                        "text": "One possible way to improve the quality of face images is to apply super-resolution techniques [99, 100, 101, 102]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1724361,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e12040588665f76bcca11690afa5537ecb4cc446",
            "isKey": false,
            "numCitedBy": 1089,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "The three main tools in the single image restoration theory are the maximum likelihood (ML) estimator, the maximum a posteriori probability (MAP) estimator, and the set theoretic approach using projection onto convex sets (POCS). This paper utilizes the above known tools to propose a unified methodology toward the more complicated problem of superresolution restoration. In the superresolution restoration problem, an improved resolution image is restored from several geometrically warped, blurred, noisy and downsampled measured images. The superresolution restoration problem is modeled and analyzed from the ML, the MAP, and POCS points of view, yielding a generalization of the known superresolution restoration methods. The proposed restoration approach is general but assumes explicit knowledge of the linear space- and time-variant blur, the (additive Gaussian) noise, the different measured resolutions, and the (smooth) motion characteristics. A hybrid method combining the simplicity of the ML and the incorporation of nonellipsoid constraints is presented, giving improved restoration performance, compared with the ML and the POCS approaches. The hybrid method is shown to converge to the unique optimal solution of a new definition of the optimization problem. Superresolution restoration from motionless measurements is also discussed. Simulations demonstrate the power of the proposed methodology."
            },
            "slug": "Restoration-of-a-single-superresolution-image-from-Elad-Feuer",
            "title": {
                "fragments": [],
                "text": "Restoration of a single superresolution image from several blurred, noisy, and undersampled measured images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A hybrid method combining the simplicity of theML and the incorporation of nonellipsoid constraints is presented, giving improved restoration performance, compared with the ML and the POCS approaches."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145893752"
                        ],
                        "name": "J. Fellous",
                        "slug": "J.-Fellous",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Fellous",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fellous"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721722"
                        ],
                        "name": "N. Kr\u00fcger",
                        "slug": "N.-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Kr\u00fcger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kr\u00fcger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10223132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c27487c3e0894b65e976a287e6f8c9aa40f089c",
            "isKey": false,
            "numCitedBy": 2136,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for recognizing human faces from single images out of a large database containing one image per person. Faces are represented by labeled graphs, based on a Gabor wavelet transform. Image graphs of new faces are extracted by an elastic graph matching process and can be compared by a simple similarity function. The system differs from Lades et al. (1993) in three respects. Phase information is used for accurate node positioning. Object-adapted graphs are used to handle large rotations in depth. Image graph extraction is based on a novel data structure, the bunch graph, which is constructed from a small set of sample image graphs."
            },
            "slug": "Face-recognition-by-elastic-bunch-graph-matching-Wiskott-Fellous",
            "title": {
                "fragments": [],
                "text": "Face recognition by elastic bunch graph matching"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A system for recognizing human faces from single images out of a large database containing one image per person, based on a Gabor wavelet transform, which differs from Lades et al. (1993) in three respects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Image Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70600861"
                        ],
                        "name": "N. Kr",
                        "slug": "N.-Kr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Kr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118146052"
                        ],
                        "name": "M. Pp",
                        "slug": "M.-Pp",
                        "structuredName": {
                            "firstName": "Menchetti",
                            "lastName": "Pp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081179731"
                        ],
                        "name": "C. V. D. Malsburgxz",
                        "slug": "C.-V.-D.-Malsburgxz",
                        "structuredName": {
                            "firstName": "C",
                            "lastName": "Malsburgxz",
                            "middleNames": [
                                "V",
                                "D"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. V. D. Malsburgxz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 109
                            }
                        ],
                        "text": "To handle the pose variation problem, the pose of the face is .rst \ndetermined using prior class infor\u00admation [Kruger et al. 1997], and the jet transformations under pose \nvariation are learned [Maurer and Malsburg 1996a]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 39
                            }
                        ],
                        "text": "For technical details, please refer to [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "To handle the pose variation problem in face recognition, the face pose is rst determined using prior information [36] and the transformations of the sets under pose variation are learned [80]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14693537,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1d2378361cad4c643af28279884ba42569d23de",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural system for the automatic determination of the position, size and pose of the head of a human gure in a camera image. The system is based on Elastic Graph Matching. The aspect of a human head in a speciic pose in an image is modeled by a labeled graph. The nodes of the graph refer to landmarks centered on speciic points of a head, e.g., the tip of the nose. Edges between nodes are labeled with distance vectors. The shape of a landmark is encoded in the form of a jet. A jet is a set of numbers extracted from the image by a family of wavelets that are all centered on one image point. The nodes of a pose graph are labeled by a bunch of diierent jets taken at the same landmark in diierent portraits. We therefore speak of \\bunch graphs.\" A pose is determined by matching a number of bunch graphs that model diierent poses to the image and picking the one matching best. We here introduce a pose determination system which is based on well known face recognition system published previously. The pose determination system is characterized by a certain reliability and speed. We improve this performance and speed with the help of statistical estimation methods. In order to make these applicable, we reduce the originally very high dimensionality of our system with the help of a number of a priori principles. The rst of these is locality in the form of independence of diierent landmarks. This reduces model space to a set of independent subspaces. We reformulate the given global quality criteria as principles that can be applied to individual nodes and optimize the system according to these principles. We achieve signiicant improvement in speed and reliability. We discuss a possible extension of the learning algorithm aiming a completely autonomous object recognition system at the end of the paper."
            },
            "slug": "Determination-of-Face-Position-and-Pose-with-a-on-a-Kr-Pp",
            "title": {
                "fragments": [],
                "text": "Determination of Face Position and Pose with a Learned Representation Based on Labeled Graphs Determination of Face Position and Pose with a Learned Representation Based on Labeled Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A pose determination system which is based on well known face recognition system published previously is introduced and improved in speed and reliability and a possible extension of the learning algorithm aiming a completely autonomous object recognition system is discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 705632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9238dddec1cb05811a892e15585f36f25974a435",
            "isKey": false,
            "numCitedBy": 491,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of local parametrized models of image motion for recovering and recognizing the non-rigid and articulated motion of human faces. Parametric flow models (for example affine) are popular for estimating motion in rigid scenes. We observe that within local regions in space and time, such models not only accurately model non-rigid facial motions but also provide a concise description of the motion in terms of a small number of parameters. These parameters are intuitively related to the motion of facial features during facial expressions and we show how expressions such as anger, happiness, surprise, fear, disgust, and sadness can be recognized from the local parametric motions in the presence of significant head motion. The motion tracking and expression recognition approach performed with high accuracy in extensive laboratory experiments involving 40 subjects as well as in television and movie sequences."
            },
            "slug": "Recognizing-Facial-Expressions-in-Image-Sequences-Black-Yacoob",
            "title": {
                "fragments": [],
                "text": "Recognizing Facial Expressions in Image Sequences Using Local Parameterized Models of Image Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper explores the use of local parametrized models of image motion for recovering and recognizing the non-rigid and articulated motion of human faces and shows how expressions can be recognized from the local parametric motions in the presence of significant head motion."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49072208"
                        ],
                        "name": "J. Steffens",
                        "slug": "J.-Steffens",
                        "structuredName": {
                            "firstName": "Johannes",
                            "lastName": "Steffens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Steffens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889830"
                        ],
                        "name": "Egor Elagin",
                        "slug": "Egor-Elagin",
                        "structuredName": {
                            "firstName": "Egor",
                            "lastName": "Elagin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Egor Elagin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2665814"
                        ],
                        "name": "H. Neven",
                        "slug": "H.-Neven",
                        "structuredName": {
                            "firstName": "Hartmut",
                            "lastName": "Neven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Neven"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 18
                            }
                        ],
                        "text": "Two other systems [93, 95] are more practical in terms of accuracy and size of the database."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "Both of these systems use more than one cue; for example [95] uses both audio and video, and [93] uses stereo."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [93], a system called PersonSpotter is described."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 161
                            }
                        ],
                        "text": "After over twenty years of research on image sequence analysis [86, 87, 88, 89], only a little of that research had been applied to the face recognition problem [90, 91, 92, 93, 94, 95] up to the mid-nineties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "For details about these modules, see [93]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 39994885,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4444defd17ba2d2dfb6cad483724acdf7d417788",
            "isKey": true,
            "numCitedBy": 99,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a real-time face recognition system which is able to capture, track and recognize a person walking toward a stereo CCD camera. The system is built for real world applications where environmental conditions like illumination, background structure and room architecture are specified only roughly or not at all. The program is implemented on a 4-processor system running UNIX and reaches a recognition speed of 6-8 persons per minute."
            },
            "slug": "PersonSpotter-fast-and-robust-system-for-human-and-Steffens-Elagin",
            "title": {
                "fragments": [],
                "text": "PersonSpotter-fast and robust system for human detection, tracking and recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A real-time face recognition system which is able to capture, track and recognize a person walking toward a stereo CCD camera, built for real world applications where environmental conditions are specified only roughly or not at all."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2958806"
                        ],
                        "name": "S. A. Rizvi",
                        "slug": "S.-A.-Rizvi",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Rizvi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. A. Rizvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40638847"
                        ],
                        "name": "Hyeonjoon Moon",
                        "slug": "Hyeonjoon-Moon",
                        "structuredName": {
                            "firstName": "Hyeonjoon",
                            "lastName": "Moon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyeonjoon Moon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9512074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6136d4e52a6ffd0b21ae85a36fd2e400af41ca78",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Two critical performance characterizations of biometric algorithms, including face recognition, are identification and verification. Identification performance of face recognition algorithms on the FERET tests has been previously reported. We report on verification performance obtained from the Sept96 FERET test. The databases used to develop and test algorithms are usually smaller than the databases that will be encountered in applications. We examine the effects of size of the database on performance for both identification and verification."
            },
            "slug": "The-FERET-verification-testing-protocol-for-face-Rizvi-Phillips",
            "title": {
                "fragments": [],
                "text": "The FERET verification testing protocol for face recognition algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "The effects of size of the database on performance for both identification and verification of face recognition algorithms, including face recognition, are examined."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281877"
                        ],
                        "name": "J. Atick",
                        "slug": "J.-Atick",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Atick",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Atick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2385089"
                        ],
                        "name": "P. A. Griffin",
                        "slug": "P.-A.-Griffin",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Griffin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. A. Griffin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144513847"
                        ],
                        "name": "A. Redlich",
                        "slug": "A.-Redlich",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Redlich",
                            "middleNames": [
                                "Norman"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Redlich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 119
                            }
                        ],
                        "text": "Using a statistical representation of the 3D heads, PCA was suggested as a tool for solving the parametric SFS problem [Atick et al. 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 120
                            }
                        ],
                        "text": "Using a statistical representation of the 3D heads, \nPCA was suggested as a tool for solving the parametric SFS prob\u00adlem [Atick et al. 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17146562,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3d0aa18ce358c93f485cbe9264db515651ad483",
            "isKey": false,
            "numCitedBy": 289,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "The human visual system is proficient in perceiving three-dimensional shape from the shading patterns in a two-dimensional image. How it does this is not well understood and continues to be a question of fundamental and practical interest. In this paper we present a new quantitative approach to shape-from-shading that may provide some answers. We suggest that the brain, through evolution or prior experience, has discovered that objects can be classified into lower-dimensional object-classes as to their shape. Extraction of shape from shading is then equivalent to the much simpler problem of parameter estimation in a low-dimensional space. We carry out this proposal for an important class of three-dimensional (3D) objects: human heads. From an ensemble of several hundred laser-scanned 3D heads, we use principal component analysis to derive a low-dimensional parameterization of head shape space. An algorithm for solving shape-from-shading using this representation is presented. It works well even on real images where it is able to recover the 3D surface for a given person, maintaining facial detail and identity, from a single 2D image of his face. This algorithm has applications in face recognition and animation."
            },
            "slug": "Statistical-Approach-to-Shape-from-Shading:-of-Face-Atick-Griffin",
            "title": {
                "fragments": [],
                "text": "Statistical Approach to Shape from Shading: Reconstruction of Three-Dimensional Face Surfaces from Single Two-Dimensional Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is suggested that the brain, through evolution or prior experience, has discovered that objects can be classified into lower-dimensional object-classes as to their shape, and extraction of shape from shading is then equivalent to the much simpler problem of parameter estimation in a low-dimensional space."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741830"
                        ],
                        "name": "Haibo Li",
                        "slug": "Haibo-Li",
                        "structuredName": {
                            "firstName": "Haibo",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haibo Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2402858"
                        ],
                        "name": "P. Roivainen",
                        "slug": "P.-Roivainen",
                        "structuredName": {
                            "firstName": "Pertti",
                            "lastName": "Roivainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Roivainen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767736"
                        ],
                        "name": "R. Forchheimer",
                        "slug": "R.-Forchheimer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Forchheimer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Forchheimer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 58
                            }
                        ],
                        "text": "3D Models for Faces 3D models of faces have been employed [113, 114, 115] in the model-based image compression literature by several research groups."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2860506,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac38092add978eefedede183c0d07702fb05a711",
            "isKey": false,
            "numCitedBy": 415,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to estimating the motion of the head and facial expressions in model-based facial image coding is presented. An affine nonrigid motion model is set up. The specific knowledge about facial shape and facial expression is formulated in this model in the form of parameters. A direct method of estimating the two-view motion parameters that is based on the affine method is discussed. Based on the reasonable assumption that the 3-D motion of the face is almost smooth in the time domain, several approaches to predicting the motion of the next frame are proposed. Using a 3-D model, the approach is characterized by a feedback loop connecting computer vision and computer graphics. Embedding the synthesis techniques into the analysis phase greatly improves the performance of motion estimation. Simulations with long image sequences of real-world scenes indicate that the method not only greatly reduces computational complexity but also substantially improves estimation accuracy. >"
            },
            "slug": "3-D-Motion-Estimation-in-Model-Based-Facial-Image-Li-Roivainen",
            "title": {
                "fragments": [],
                "text": "3-D Motion Estimation in Model-Based Facial Image Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Simulations with long image sequences of real-world scenes indicate that the approach to estimating the motion of the head and facial expressions in model-based facial image coding not only greatly reduces computational complexity but also substantially improves estimation accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 48
                            }
                        ],
                        "text": "For example, an interactive computer/smart room [96, 97] can recognize such behavior and initiate appropriate action."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16899691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb10e0669d514e1c9b3f58427de0a322590951c2",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate real-time face tracking and pose estimation in an unconstrained office environment with an active foveated camera. Using vision routines previously implemented for an interactive environment, we determine the spatial location of a user's head and guide an active camera to obtain foveated images of the face. Faces are analyzed using a set of eigenspaces indexed over both pose and world location. Closed loop feedback from the estimated facial location is used to guide the camera when a face is present in the foveated view. Our system can detect the head pose of an unconstrained user in real-time as he or she moves about an open room."
            },
            "slug": "Active-face-tracking-and-pose-estimation-in-an-room-Darrell-Moghaddam",
            "title": {
                "fragments": [],
                "text": "Active face tracking and pose estimation in an interactive room"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This work determines the spatial location of a user's head and guides an active camera to obtain foveated images of the face to demonstrate real-time face tracking and pose estimation in an unconstrained office environment with an active foveate camera."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 63
                            }
                        ],
                        "text": "After over twenty years of research on image sequence analysis [86, 87, 88, 89], only a little of that research had been applied to the face recognition problem [90, 91, 92, 93, 94, 95] up to the mid-nineties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 24
                            }
                        ],
                        "text": "We list here only books [86, 87, 106, 107, 108, 109] and review papers [110, 111, 112]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 146278985,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "c2d2fefc1c61298059f9a160f190e6957587b74e",
            "isKey": false,
            "numCitedBy": 2090,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This book uses the methodology of artificial intelligence to investigate the phenomena of visual motion perception: how the visual system constructs descriptions of the environment in terms of objects, their three-dimensional shape, and their motion through space, on the basis of the changing image that reaches the eye. The author has analyzed the computations performed in the course of visual motion analysis. Workable schemes able to perform certain tasks performed by the visual system have been constructed and used as vehicles for investigating the problems faced by the visual system and its methods for solving them.Two major problems are treated: first, the correspondence problem, which concerns the identification of image elements that represent the same object at different times, thereby maintaining the perceptual identity of the object in motion or in change. The second problem is the three-dimensional interpretation of the changing image once a correspondence has been established.The author's computational approach to visual theory makes the work unique, and it should be of interest to psychologists working in visual perception and readers interested in cognitive studies in general, as well as computer scientists interested in machine vision, theoretical neurophysiologists, and philosophers of science."
            },
            "slug": "The-Interpretation-of-Visual-Motion-Ullman",
            "title": {
                "fragments": [],
                "text": "The Interpretation of Visual Motion"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144986880"
                        ],
                        "name": "I. Craw",
                        "slug": "I.-Craw",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Craw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Craw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066105510"
                        ],
                        "name": "Peter Cameron",
                        "slug": "Peter-Cameron",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Cameron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Cameron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8657476,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c66dcbbfbe7414ae9fcd769fc72fd2c2123f471d",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a coding scheme to index face images for subsequent retrieval, which seems effective, under some conditions, at coding the faces themselves, rather than particular face images, and uses typically 100 bytes. We report tests searching a pool of 100 faces, using as cue a different image of a face in the pool, taken 10 years later. In two of three tests with different faces, the target face best matches the corresponding cue."
            },
            "slug": "Face-Recognition-by-Computer-Craw-Cameron",
            "title": {
                "fragments": [],
                "text": "Face Recognition by Computer"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A coding scheme to index face images for subsequent retrieval seems effective, under some conditions, at coding the faces themselves, rather than particular face images, and uses typically 100 bytes."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6435894"
                        ],
                        "name": "S. McKenna",
                        "slug": "S.-McKenna",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "McKenna",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. McKenna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144784813"
                        ],
                        "name": "S. Gong",
                        "slug": "S.-Gong",
                        "structuredName": {
                            "firstName": "Shaogang",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 76
                            }
                        ],
                        "text": "A big difference between these methods and the probabilistic voting methods [McKenna and Gong 1998] is the use of representations in a joint temporal and spatial space for identification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 79
                            }
                        ],
                        "text": "The voting can be deterministic, but probabilistic voting is better in general [Gong et al. 2000; McKenna and Gong 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 20
                            }
                        ],
                        "text": "More recent methods [Choudhury et al. 1999; McKenna and Gong 1998] have used motion and/or color information to speed up the process of searching for possible face regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 127187272,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "36c98521bb12638e17c0218cee65637a54bf3236",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to engineering real-time computer vision systems for face recognition is described. The tasks considered involve recognition of multiple people in poorly constrained dynamic scenes. Modules for focus of attention, face detection, tracking and recognition are described. The need for integration of different processes using prediction and feedback is emphasised. Some examples from working systems are given."
            },
            "slug": "Recognising-Moving-Faces-McKenna-Gong",
            "title": {
                "fragments": [],
                "text": "Recognising Moving Faces"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "An approach to engineering real-time computer vision systems for face recognition that involves recognition of multiple people in poorly constrained dynamic scenes and the need for integration of different processes using prediction and feedback is emphasised."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2880906"
                        ],
                        "name": "V. Blanz",
                        "slug": "V.-Blanz",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Blanz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Blanz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 55
                            }
                        ],
                        "text": "To overcome this problem, \nthe 3D morphable face model [Blanz and Vetter 1999] is ap\u00adplied to generate arbitrary synthetic im\u00adages \nunder varying pose and illumination."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 54
                            }
                        ],
                        "text": "To overcome this problem, the 3D morphable face model [Blanz and Vetter 1999] is applied to generate arbitrary synthetic images under varying pose and illumination."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 147
                            }
                        ],
                        "text": "\u2026(1) a view-based eigen\u00adface method [Pentland et al. 1994], (2) a graph \nmatching-based method [Wiskott et al. 1997], (3) a linear class-based method [Blanz and Vetter 1999; \nVetter and Poggio 1997], (4) a vectorized im\u00adage representation based method [Beymer 1995; Beymer and \nPoggio 1995], and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 184
                            }
                        ],
                        "text": "The last method [Huang et al. 2003] that we review in this category \nis based on re\u00adcent advances in component-based detec\u00adtion/recognition [Heisele et al. 2001] and 3D morphable \nmodels [Blanz and Vetter 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 39
                            }
                        ],
                        "text": "1997], (3) a linear class-based method [Blanz and Vetter 1999; Vetter and Poggio 1997], (4) a vectorized image representation based method [Beymer 1995; Beymer and Poggio 1995], and (5) a view-based appearance model [Cootes"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207637109,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae0ef252d1b42df430ffb90724132040abf20341",
            "isKey": true,
            "numCitedBy": 2345,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a new technique for modeling textured 3D faces is introduced. 3D faces can either be generated automatically from one or more photographs, or modeled directly through an intuitive user interface. Users are assisted in two key problems of computer aided face modeling. First, new face images or new 3D face models can be registered automatically by computing dense one-to-one correspondence to an internal face model. Second, the approach regulates the naturalness of modeled faces avoiding faces with an \u201cunlikely\u201d appearance. Starting from an example set of 3D face models, we derive a morphable face model by transforming the shape and texture of the examples into a vector space representation. New faces and expressions can be modeled by forming linear combinations of the prototypes. Shape and texture constraints derived from the statistics of our example faces are used to guide manual modeling or automated matching algorithms. We show 3D face reconstructions from single images and their applications for photo-realistic image manipulations. We also demonstrate face manipulations according to complex parameters such as gender, fullness of a face or its distinctiveness."
            },
            "slug": "A-morphable-model-for-the-synthesis-of-3D-faces-Blanz-Vetter",
            "title": {
                "fragments": [],
                "text": "A morphable model for the synthesis of 3D faces"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A new technique for modeling textured 3D faces by transforming the shape and texture of the examples into a vector space representation, which regulates the naturalness of modeled faces avoiding faces with an \u201cunlikely\u201d appearance."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803182"
                        ],
                        "name": "A. Nefian",
                        "slug": "A.-Nefian",
                        "structuredName": {
                            "firstName": "Ara",
                            "lastName": "Nefian",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Nefian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144449603"
                        ],
                        "name": "M. Hayes",
                        "slug": "M.-Hayes",
                        "structuredName": {
                            "firstName": "Monson",
                            "lastName": "Hayes",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hayes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7040774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02f3de834f99bcbaac611dc6ae23535317648b0f",
            "isKey": false,
            "numCitedBy": 370,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The work presented in this paper focuses on the use of hidden Markov models for face recognition. A new method based on the extraction of 2D-DCT feature vectors is described, and the recognition results are compared with other face recognition approaches. The method introduced reduces significantly the computational complexity of previous HMM-based face recognition system, while preserving the same recognition rate."
            },
            "slug": "Hidden-Markov-models-for-face-recognition-Nefian-Hayes",
            "title": {
                "fragments": [],
                "text": "Hidden Markov models for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A new method based on the extraction of 2D-DCT feature vectors is described, and the recognition results are compared with other face recognition approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829021"
                        ],
                        "name": "D. Ruderman",
                        "slug": "D.-Ruderman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ruderman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ruderman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 89
                            }
                        ],
                        "text": "It is well known that there exist signi.cant statistical redundancies in natural im\u00adages [Ruderman 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 259
                            }
                        ],
                        "text": "Its biological \nmotivation comes from the fact that, though a huge array of receptors (more than six million cones) exist \nin the human retina, only a small fraction of them are active, corre\u00adsponding to natural objects/signals \nthat are statistically redundant [Ruderman 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2793971,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "13206b6ba3711a14a56cf1599ecb08c16f49061e",
            "isKey": false,
            "numCitedBy": 912,
            "numCiting": 144,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently there has been a resurgence of interest in the properties of natural images. Their statistics are important not only in image compression but also for the study of sensory processing in biology, which can be viewed as satisfying certain \u2018design criteria\u2019. This review summarizes previous work on image statistics and presents our own data. Perhaps the most notable property of natural images is an invariance to scale. We present data to support this claim as well as evidence for a hierarchical invariance in natural scenes. These symmetries provide a powerful description of natural images as they greatly restrict the class of allowed distributions."
            },
            "slug": "The-statistics-of-natural-images-Ruderman",
            "title": {
                "fragments": [],
                "text": "The statistics of natural images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49053294"
                        ],
                        "name": "K. Okada",
                        "slug": "K.-Okada",
                        "structuredName": {
                            "firstName": "Kazunori",
                            "lastName": "Okada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Okada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49072208"
                        ],
                        "name": "J. Steffens",
                        "slug": "J.-Steffens",
                        "structuredName": {
                            "firstName": "Johannes",
                            "lastName": "Steffens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Steffens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49072208"
                        ],
                        "name": "J. Steffens",
                        "slug": "J.-Steffens",
                        "structuredName": {
                            "firstName": "Johannes",
                            "lastName": "Steffens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Steffens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055501916"
                        ],
                        "name": "Thomas Maurer",
                        "slug": "Thomas-Maurer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Maurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Maurer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093215944"
                        ],
                        "name": "Hai Hong",
                        "slug": "Hai-Hong",
                        "structuredName": {
                            "firstName": "Hai",
                            "lastName": "Hong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hai Hong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889830"
                        ],
                        "name": "Egor Elagin",
                        "slug": "Egor-Elagin",
                        "structuredName": {
                            "firstName": "Egor",
                            "lastName": "Elagin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Egor Elagin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2665814"
                        ],
                        "name": "H. Neven",
                        "slug": "H.-Neven",
                        "structuredName": {
                            "firstName": "Hartmut",
                            "lastName": "Neven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Neven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 145
                            }
                        ],
                        "text": "\u2026projection algorithm \nfrom Rutgers University [Wilder 1994] (Sept. 1996); an Elastic Graph Matching algorithm from the University \nof Southern Cali\u00adfornia [Okada et al. 1998; Wiskott et al. 1997] (March 1997); a baseline PCA algorithm \n[Moon and Phillips 2001; Turk and Pentland 1991]; and a\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 170
                            }
                        ],
                        "text": "Many \nmethods re\u00adviewed in Section 3 belong to this category: eigenfaces [Turk and Pentland 1991], probabilistic \neigenfaces [Moghaddam and Pentland 1997], the EBGM method [Okada et al. 1998; Wiskott et al. 1997], and \nthe PDBNN method [Lin et al. 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 249
                            }
                        ],
                        "text": "\u20261997] PDBNN Probabilistic decision based NN [Lin et al. 1997] Feature-based \nmethods Pure geometry methods Earlier methods [Kanade 1973; Kelly 1970]; recent methods [Cox et al. 1996; \nManjunath et al. 1992] Dynamic link architecture Graph matching methods [Okada et al. 1998; Wiskott et \nal."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 145
                            }
                        ],
                        "text": "\u2026Techniques Approach Representative work Still-image methods Basic methods [Turk and \nPentland 1991; Lin et al. 1997; Moghaddam and Pentland 1997; Okada et al. 1998; Penev and Atick 1996; \nWechsler et al. 1997; Wiskott et al. 1997] Tracking-enhanced [Edwards et al. 1998; McKenna and Gong 1997,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 55
                            }
                        ],
                        "text": "(Notice how this method is similar \nto the EBGM system [Okada et al. 1998; Wiskott et al. 1997] except that gray-scale compo\u00adnents are used \ninstead of Gabor wavelets.)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 95
                            }
                        ],
                        "text": "One of the most \nsuccessful of these systems is the Elas\u00adtic Bunch Graph Matching (EBGM) sys\u00adtem [Okada et al. 1998; Wiskott \net al. 1997], which is based on DLA [Buhmann et al. 1990; Lades et al. 1993]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 36
                            }
                        ],
                        "text": "For example, the EBGM-based method [Okada et al. 1998] has very good performance, but \nit requires an image size, for exam\u00adple, 128 \u00d7 128, which severely restricts its possible application \nto video-based surveillance where the image size of the face area is very small."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 141
                            }
                        ],
                        "text": "Clearly the image size cannot be too small for meth\u00adods that \ndepend heavily on accurate feature localization, such as graph matching methods [Okada et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 82
                            }
                        ],
                        "text": "One of the most successful systems in \nthis cate\u00adgory is the graph matching system [Okada et al. 1998; Wiskott et al. 1997], which is based \non the Dynamic Link Architec\u00adture (DLA) [Buhmann et al. 1990; Lades et al. 1993]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9076139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9579768d142a7020d095090183805c98a2f78e5",
            "isKey": true,
            "numCitedBy": 177,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper summarizes the Bochum/USC face recognition system, our preparations for the FERET Phase III test, and test results as far as they have been made known to us. Our technology is based on Gabor wavelets and elastic bunch graph matching. We briefly discuss our technology in relation to biological and PCA based systems and indicate current activities in the lab and potential future applications."
            },
            "slug": "The-Bochum/USC-Face-Recognition-System-And-How-it-Okada-Steffens",
            "title": {
                "fragments": [],
                "text": "The Bochum/USC Face Recognition System And How it Fared in the FERET Phase III Test"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This paper summarizes the Bochum/USC face recognition system, the preparations for the FERET Phase III test, and test results as far as they have been made known to us."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144658464"
                        ],
                        "name": "V. Pavlovic",
                        "slug": "V.-Pavlovic",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Pavlovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Pavlovic"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 57
                            }
                        ],
                        "text": "For a review of hand gesture recognition techniques, see [145]; for more detailed descriptions of various techniques, see the Proceedings of the AFGR Conferences [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14141930,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a36dbcb17471821b4d4b9776c402eabdf65450d",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Hand gestures are a form of communication among people. Yet we still limit human-computer interaction to cumbersome mice movements. The use of hand gestures in the eld of human-computer interaction has attracted new interest in the past several years. Special glove-based devices have been developed to analyze nger and hand motion and use them to manipulate and explore virtual worlds. To further enrich the naturalness of the interaction, different computer vision-based techniques have been brought into use. At the same time the need for more eecient systems has resulted in new gesture modeling approaches. In this paper we present a review of the most recent work related to hand gesture modeling, analysis and synthesis. We describe four major classes of hand gesture interface techniques: glove-based techniques, vision-based techniques , techniques that use drawing gestures, and other gesture analysis techniques. A brief description of more than thirty gesture-interface systems is presented with special attention focused on the systems that use computer vision techniques."
            },
            "slug": "Hand-Gesture-Modeling,-Analysis,-and-Synthesis-Huang-Pavlovic",
            "title": {
                "fragments": [],
                "text": "Hand Gesture Modeling, Analysis, and Synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A review of the most recent work related to hand gesture modeling, analysis and synthesis is presented and four major classes of hand gesture interface techniques are described: glove- based techniques, vision-based techniques, techniques that use drawing gestures, and other gesture analysis techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403958042"
                        ],
                        "name": "E. Bailly-Bailli\u00e9re",
                        "slug": "E.-Bailly-Bailli\u00e9re",
                        "structuredName": {
                            "firstName": "Enrique",
                            "lastName": "Bailly-Bailli\u00e9re",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bailly-Bailli\u00e9re"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9457270"
                        ],
                        "name": "F. Bimbot",
                        "slug": "F.-Bimbot",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Bimbot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bimbot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802702"
                        ],
                        "name": "M. Hamouz",
                        "slug": "M.-Hamouz",
                        "structuredName": {
                            "firstName": "Miroslav",
                            "lastName": "Hamouz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hamouz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801638"
                        ],
                        "name": "J. Kittler",
                        "slug": "J.-Kittler",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Kittler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kittler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683784"
                        ],
                        "name": "J. Mari\u00e9thoz",
                        "slug": "J.-Mari\u00e9thoz",
                        "structuredName": {
                            "firstName": "Johnny",
                            "lastName": "Mari\u00e9thoz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mari\u00e9thoz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2173900"
                        ],
                        "name": "K. Messer",
                        "slug": "K.-Messer",
                        "structuredName": {
                            "firstName": "Kieron",
                            "lastName": "Messer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Messer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726603"
                        ],
                        "name": "Vlad Popovici",
                        "slug": "Vlad-Popovici",
                        "structuredName": {
                            "firstName": "Vlad",
                            "lastName": "Popovici",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vlad Popovici"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143903227"
                        ],
                        "name": "F. Por\u00e9e",
                        "slug": "F.-Por\u00e9e",
                        "structuredName": {
                            "firstName": "Fabienne",
                            "lastName": "Por\u00e9e",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Por\u00e9e"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080516092"
                        ],
                        "name": "Bel\u00e9n Ru\u00edz-Mezcua",
                        "slug": "Bel\u00e9n-Ru\u00edz-Mezcua",
                        "structuredName": {
                            "firstName": "Bel\u00e9n",
                            "lastName": "Ru\u00edz-Mezcua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bel\u00e9n Ru\u00edz-Mezcua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710257"
                        ],
                        "name": "J. Thiran",
                        "slug": "J.-Thiran",
                        "structuredName": {
                            "firstName": "Jean-Philippe",
                            "lastName": "Thiran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Thiran"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 111
                            }
                        ],
                        "text": "Fortunately, relatively \nlarge video databases exist, for example, the XM2TV database [Messer et al. 1999], the BANCA database \n[Bailly-Bailliere et al. 2003], and the addition of video into the FERET and FRVT2002 16Stereo is less \nsensitive to illumination change but still has dif.culty in handling textureless regions. databases."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 127
                            }
                        ],
                        "text": "Fortunately, relatively \nlarge video databases exist, for example, the XM2TV database [Messer et al. 1999], the BANCA database \n[Bailly-Bailliere et al. 2003], and the addition of video into the FERET and FRVT2002 16Stereo is less \nsensitive to illumination change but still has dif.culty in\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 4
                            }
                        ],
                        "text": "The \nBANCA database and evalua\u00adtion protocol."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 124
                            }
                        ],
                        "text": "We describe here the most important face databases and their associated evaluation methods, \nin\u00adcluding the XM2VTS and BANCA [Bailly-Bailliere et al. 2003] database."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4071650,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f83e1a0c05da3a2f316b75b4a178fadf709dd68",
            "isKey": true,
            "numCitedBy": 504,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe the acquisition and content of a new large, realistic and challenging multi-modal database intended for training and testing multi-modal verification systems. The BANCA database was captured in four European languages in two modalities (face and voice). For recording, both high and low quality microphones and cameras were used. The subjects were recorded in three different scenarios, controlled, degraded and adverse over a period of three months. In total 208 people were captured, half men and half women. In this paper we also describe a protocol for evaluating verification algorithms on the database. The database will be made available to the research community through http://www.ee.surrey.ac.uk/Research/VSSP/banca."
            },
            "slug": "The-BANCA-Database-and-Evaluation-Protocol-Bailly-Bailli\u00e9re-Bengio",
            "title": {
                "fragments": [],
                "text": "The BANCA Database and Evaluation Protocol"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A protocol for evaluating verification algorithms on the BANCA database, a new large, realistic and challenging multi-modal database intended for training and testing multi- modal verification systems, is described."
            },
            "venue": {
                "fragments": [],
                "text": "AVBPA"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716722"
                        ],
                        "name": "D. DeCarlo",
                        "slug": "D.-DeCarlo",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "DeCarlo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. DeCarlo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711560"
                        ],
                        "name": "Dimitris N. Metaxas",
                        "slug": "Dimitris-N.-Metaxas",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Metaxas",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimitris N. Metaxas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14922384,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "8e8aa06aa2125008a1baea0dafb4a945892abe61",
            "isKey": false,
            "numCitedBy": 346,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical flow provides a constraint on the motion of a deformable model. We derive and solve a dynamic system incorporating flow as a hard constraint, producing a model-based least-squares optical flow solution. Our solution also ensures the constraint remains satisfied when combined with edge information, which helps combat tracking error accumulation. Constraint enforcement can be relaxed using a Kalman filter, which permits controlled constraint violations based on the noise present in the optical flow information, and enables optical flow and edge information to be combined more robustly and efficiently. We apply this framework to the estimation of face shape and motion using a 3D deformable face model. This model uses a small number of parameters to describe a rich variety of face shapes and facial expressions. We present experiments in extracting the shape and motion of a face from image sequences which validate the accuracy of the method. They also demonstrate that our treatment of optical flow as a hard constraint, as well as our use of a Kalman filter to reconcile these constraints with the uncertainty in the optical flow, are vital for improving the performance of our system."
            },
            "slug": "Optical-Flow-Constraints-on-Deformable-Models-with-DeCarlo-Metaxas",
            "title": {
                "fragments": [],
                "text": "Optical Flow Constraints on Deformable Models with Applications to Face Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A dynamic system incorporating flow as a hard constraint is derived and solved, producing a model-based least-squares optical flow solution that ensures the constraint remains satisfied when combined with edge information, which helps combat tracking error accumulation."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144410963"
                        ],
                        "name": "S. Kung",
                        "slug": "S.-Kung",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Kung",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399066120"
                        ],
                        "name": "J. Taur",
                        "slug": "J.-Taur",
                        "structuredName": {
                            "firstName": "J.S.",
                            "lastName": "Taur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Taur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12732573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d750b2d6c0ccf4f93fe3cd7f146b3ca3b8d18bc",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Supervised learning networks based on a decision-based formulation are explored. More specifically, a decision-based neural network (DBNN) is proposed, which combines the perceptron-like learning rule and hierarchical nonlinear network structure. The decision-based mutual training can be applied to both static and temporal pattern recognition problems. For static pattern recognition, two hierarchical structures are proposed: hidden-node and subcluster structures. The relationships between DBNN's and other models (linear perceptron, piecewise-linear perceptron, LVQ, and PNN) are discussed. As to temporal DBNN's, model-based discriminant functions may be chosen to compensate possible temporal variations, such as waveform warping and alignments. Typical examples include DTW distance, prediction error, or likelihood functions. For classification applications, DBNN's are very effective in computation time and performance. This is confirmed by simulations conducted for several applications, including texture classification, OCR, and ECG analysis."
            },
            "slug": "Decision-based-neural-networks-with-signal/image-Kung-Taur",
            "title": {
                "fragments": [],
                "text": "Decision-based neural networks with signal/image classification applications"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A decision-based neural network is proposed, which combines the perceptron-like learning rule and hierarchical nonlinear network structure, which is confirmed by simulations conducted for several applications, including texture classification, OCR, and ECG analysis."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2323849"
                        ],
                        "name": "P. Jourlin",
                        "slug": "P.-Jourlin",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Jourlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Jourlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678373"
                        ],
                        "name": "J. Luettin",
                        "slug": "J.-Luettin",
                        "structuredName": {
                            "firstName": "Juergen",
                            "lastName": "Luettin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Luettin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722226"
                        ],
                        "name": "D. Genoud",
                        "slug": "D.-Genoud",
                        "structuredName": {
                            "firstName": "Dominique",
                            "lastName": "Genoud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Genoud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3055877"
                        ],
                        "name": "Hubert Wassner",
                        "slug": "Hubert-Wassner",
                        "structuredName": {
                            "firstName": "Hubert",
                            "lastName": "Wassner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hubert Wassner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2627470,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5c6ddb7985cdb72804610aad28661c7c5638472",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Acoustic-labial-speaker-verification-Jourlin-Luettin",
            "title": {
                "fragments": [],
                "text": "Acoustic-labial Speaker Verification"
            },
            "venue": {
                "fragments": [],
                "text": "AVBPA"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2968162"
                        ],
                        "name": "I. Gauthier",
                        "slug": "I.-Gauthier",
                        "structuredName": {
                            "firstName": "Isabel",
                            "lastName": "Gauthier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Gauthier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31772450"
                        ],
                        "name": "N. Logothetis",
                        "slug": "N.-Logothetis",
                        "structuredName": {
                            "firstName": "Nikos",
                            "lastName": "Logothetis",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Logothetis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 194
                            }
                        ],
                        "text": "\u2026with issues such as \nwhether face perception is a dedicated process (this issue is still be\u00ading debated in the psychology \ncommunity [Biederman and Kalocsai 1998; Ellis 1986; Gauthier et al. 1999; Gauthier and Logo\u00adthetis 2000]) \nand whether it is done holis\u00adtically or by local feature analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 14
                            }
                        ],
                        "text": "Accord\u00ading to [Gauthier and Logothetis 2000], recent neuroimaging \nstudies in humans indicate that level of categorization and expertise interact to produce the speci\u00ad.cation \nfor faces in the middle fusiform gyrus.3 Hence it is possible that the en\u00adcoding scheme used for faces \nmay also be\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 6
                            }
                        ],
                        "text": "1999; Gauthier and Logothetis 2000]: It is traditionally be\u00adlieved that face recognition is a dedi\u00adcated \nprocess different from other ob\u00adject recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6092861,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "1257c64f8ef5de527b82cefe9d3a4051b9257a39",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 142,
            "paperAbstract": {
                "fragments": [],
                "text": "In monkeys, a number of different neocortical as well as limbic structures have cell populations that respond preferentially to face stimuli. Face selectivity is also differentiated within itself: Cells in the inferior temporal and prefrontal cortex tend to respond to facial identity, others in the upper bank of the superior temporal sulcus to gaze directions, and yet another population in the amygdala to facial expression. The great majority of these cells are sensitive to the entire configuration of a face. Changing the spatial arrangement of the facial features greatly diminishes the neurons' response. It would appear, then, that an entire neural network for faces exists which contains units highly selective to complex configurations and that respond to different aspects of the object \u201cface.\u201d Given the vital importance of face recognition in primates, this may not come as a surprise. But are faces the only objects represented in this way? Behavioural work in humans suggests that nonface objects may be processed like faces if subjects are required to discriminate between visually similar exemplars and acquire sufficient expertise in doing so. Recent neuroimaging studies in humans indicate that level of categorisation and expertise interact to produce the specialisation for faces in the middle fusiform gyrus. Here we discuss some new evidence in the monkey suggesting that any arbitrary homogeneous class of artificial objects\u2014which the animal has to individually learn, remember, and recognise again and again from among a large number of distractors sharing a number of common features with the target\u2014can induce configurational selectivity in the response of neurons in the visual system. For all of the animals tested, the neurons from which we recorded were located in the anterior inferotemporal cortex. However, as we have only recorded from the posterior and anterior ventrolateral temporal lobe, other cells with a similar selectivity for the same objects may also exist in areas of the medial temporal lobe or in the limbic structures of the same \u201cexpert\u201d monkeys. It seems that the encoding scheme used for faces may also be employed for other classes with similar properties. Thus, regarding their neural encoding, faces are not \u201cspecial\u201d but rather the \u201cdefault special\u201d class in the primate recognition system."
            },
            "slug": "IS-FACE-RECOGNITION-NOT-SO-UNIQUE-AFTER-ALL-Gauthier-Logothetis",
            "title": {
                "fragments": [],
                "text": "IS FACE RECOGNITION NOT SO UNIQUE AFTER ALL?"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Some new evidence in the monkey is discussed suggesting that any arbitrary homogeneous class of artificial objects\u2014which the animal has to individually learn, remember, and recognise again and again from among a large number of distractors sharing a number of common features with the target\u2014can induce configurational selectivity in the response of neurons in the visual system."
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive neuropsychology"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3230391"
                        ],
                        "name": "A. Georghiades",
                        "slug": "A.-Georghiades",
                        "structuredName": {
                            "firstName": "Athinodoros",
                            "lastName": "Georghiades",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Georghiades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 94
                            }
                        ],
                        "text": "More recently, an illumination-conebased [Belhumeur and Kriegman 1997] image synthesis method [Georghiades et al. 1999] has been proposed to handle both pose and illumination problems in face recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 95
                            }
                        ],
                        "text": "More recently, an illumination-cone\u00adbased \n[Belhumeur and Kriegman 1997] image synthesis method [Georghiades et al. 1999] has been proposed to han\u00addle \nboth pose and illumination problems in face recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17347397,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8c21e69440e3f1d03a1f50e136967a1971d81bc",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an illumination-based method for synthesizing images of an object under novel viewing conditions. Our method requires as few as three images of the object taken under variable illumination, but from a fixed viewpoint. Unlike multi-view based image synthesis, our method does not require the determination of point or line correspondences. Furthermore, our method is able to synthesize not simply novel viewpoints, but novel illumination conditions as well. We demonstrate the effectiveness of our approach by generating synthetic images of human faces."
            },
            "slug": "Illumination-based-image-synthesis:-creating-novel-Georghiades-Belhumeur",
            "title": {
                "fragments": [],
                "text": "Illumination-based image synthesis: creating novel images of human faces under differing pose and lighting"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "An illumination-based method for synthesizing images of an object under novel viewing conditions that requires as few as three images of the object taken under variable illumination, but from a fixed viewpoint is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Workshop on Multi-View Modeling and Analysis of Visual Scenes (MVIEW'99)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678633"
                        ],
                        "name": "Gregory Hager",
                        "slug": "Gregory-Hager",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Hager",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory Hager"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11616840,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b844126725ab2dad5bf69dc11d58e465742694a",
            "isKey": false,
            "numCitedBy": 1309,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "As an object moves through the field of view of a camera, the images of the object may change dramatically. This is not simply due to the translation of the object across the image plane; complications arise due to the fact that the object undergoes changes in pose relative to the viewing camera, in illumination relative to light sources, and may even become partially or fully occluded. We develop an efficient general framework for object tracking, which addresses each of these complications. We first develop a computationally efficient method for handling the geometric distortions produced by changes in pose. We then combine geometry and illumination into an algorithm that tracks large image regions using no more computation than would be required to track with no accommodation for illumination changes. Finally, we augment these methods with techniques from robust statistics and treat occluded regions on the object as statistical outliers. Experimental results are given to demonstrate the effectiveness of our methods."
            },
            "slug": "Efficient-Region-Tracking-With-Parametric-Models-of-Hager-Belhumeur",
            "title": {
                "fragments": [],
                "text": "Efficient Region Tracking With Parametric Models of Geometry and Illumination"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work develops a computationally efficient method for handling the geometric distortions produced by changes in pose and combines geometry and illumination into an algorithm that tracks large image regions using no more computation than would be required to track with no accommodation for illumination changes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1816827"
                        ],
                        "name": "Gianluca Donato",
                        "slug": "Gianluca-Donato",
                        "structuredName": {
                            "firstName": "Gianluca",
                            "lastName": "Donato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gianluca Donato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2218905"
                        ],
                        "name": "M. Bartlett",
                        "slug": "M.-Bartlett",
                        "structuredName": {
                            "firstName": "Marian",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "Stewart"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bartlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072657855"
                        ],
                        "name": "J. C. Hager",
                        "slug": "J.-C.-Hager",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Hager",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. Hager"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21451088"
                        ],
                        "name": "P. Ekman",
                        "slug": "P.-Ekman",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Ekman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ekman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4517874,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d306e3382a119d61d5fdc243408bf2d433f1e38b",
            "isKey": false,
            "numCitedBy": 1117,
            "numCiting": 165,
            "paperAbstract": {
                "fragments": [],
                "text": "The Facial Action Coding System (FACS) [23] is an objective method for quantifying facial movement in terms of component actions. This system is widely used in behavioral investigations of emotion, cognitive processes, and social interaction. The coding is presently performed by highly trained human experts. This paper explores and compares techniques for automatically recognizing facial actions in sequences of images. These techniques include analysis of facial motion through estimation of optical flow; holistic spatial analysis, such as principal component analysis, independent component analysis, local feature analysis, and linear discriminant analysis; and methods based on the outputs of local filters, such as Gabor wavelet representations and local principal components. Performance of these systems is compared to naive and expert human subjects. Best performances were obtained using the Gabor wavelet representation and the independent component representation, both of which achieved 96 percent accuracy for classifying 12 facial actions of the upper and lower face. The results provide converging evidence for the importance of using local filters, high spatial frequencies, and statistical independence for classifying facial actions."
            },
            "slug": "Classifying-Facial-Actions-Donato-Bartlett",
            "title": {
                "fragments": [],
                "text": "Classifying Facial Actions"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper explores and compares techniques for automatically recognizing facial actions in sequences of images and provides converging evidence for the importance of using local filters, high spatial frequencies, and statistical independence for classifying facial actions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738894"
                        ],
                        "name": "T. Starner",
                        "slug": "T.-Starner",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Starner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Starner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[140] used geometrical parameters (the image coordinates and orientations of the hands) as image features and employed an HMM ve-state topology for gesture classi cation; good results were reported on classifying 40 American Sign Language gestures in real-time video."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16542114,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b9712ad56c6821cfe05ba5ddeb22a71000397d4",
            "isKey": false,
            "numCitedBy": 815,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Using hidden Markov models (HMM's), an unobstrusive single view camera system is developed that can recognize hand gestures, namely, a subset of American Sign Language (ASL). Previous systems have concentrated on finger spelling or isolated word recognition, often using tethered electronic gloves for input. We achieve high recognition rates for full sentence ASL using only visual cues. A forty word lexicon consisting of personal pronouns, verbs, nouns, and adjectives is used to create 494 randomly constructed five word sentences that are signed by the subject to the computer. The data is separated into a 395 sentence training set and an independent 99 sentence test set. While signing, the 2D position, orientation, and eccentricity of bounding ellipses of the hands are tracked in real time with the assistance of solidly colored gloves. Simultaneous recognition and segmentation of the resultant stream of feature vectors occurs five times faster than real time on an HP 735. With a strong grammar, the system achieves an accuracy of 97%; with no grammar, an accuracy of 91% is reached (95% correct)."
            },
            "slug": "Visual-Recognition-of-American-Sign-Language-Using-Starner",
            "title": {
                "fragments": [],
                "text": "Visual Recognition of American Sign Language Using Hidden Markov Models."
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "Using hidden Markov models (HMM's), an unobstrusive single view camera system is developed that can recognize hand gestures, namely, a subset of American Sign Language (ASL), achieving high recognition rates for full sentence ASL using only visual cues."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2301906"
                        ],
                        "name": "M. Berthod",
                        "slug": "M.-Berthod",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Berthod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Berthod"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3047421"
                        ],
                        "name": "H. Shekarforoush",
                        "slug": "H.-Shekarforoush",
                        "structuredName": {
                            "firstName": "Hassan",
                            "lastName": "Shekarforoush",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shekarforoush"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27379268"
                        ],
                        "name": "M. Werman",
                        "slug": "M.-Werman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Werman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Werman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730707"
                        ],
                        "name": "J. Zerubia",
                        "slug": "J.-Zerubia",
                        "structuredName": {
                            "firstName": "Josiane",
                            "lastName": "Zerubia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zerubia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 95
                            }
                        ],
                        "text": "One possible way to improve the quality of face images is to apply super-resolution techniques [99, 100, 101, 102]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8888869,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f9aba25c6f273e0a39ff660cb1796960cefeb01",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a set of low resolution camera images, it is possible to reconstruct high resolution luminance and depth information, specially if the relative displacements of the image frames are known. We propose iterative algorithms for recovering hash resolution albedo and depth maps that require no a priori knowledge of the scene, and therefore do not depend on other methods, as regards boundary and initial conditions. The problem of surface reconstruction has been formulated as one of expectation maximization (EM) and has been tackled in a probabilistic framework using Markov random fields (MRF). As for the depth map, our method directly recovers surface heights without refering to surface orientations, while increasing the resolution by camera jittering. Conventional statistical models have been coupled with geometrical techniques to construct a general model of the world and the imaging process.<<ETX>>"
            },
            "slug": "Reconstruction-of-high-resolution-3D-visual-Berthod-Shekarforoush",
            "title": {
                "fragments": [],
                "text": "Reconstruction of high resolution 3D visual information"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work proposes iterative algorithms for recovering hash resolution albedo and depth maps that require no a priori knowledge of the scene, and therefore do not depend on other methods, as regards boundary and initial conditions."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21472040"
                        ],
                        "name": "Irfan Essa",
                        "slug": "Irfan-Essa",
                        "structuredName": {
                            "firstName": "Irfan",
                            "lastName": "Essa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irfan Essa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 72
                            }
                        ],
                        "text": "3D motion estimation has also been used to recognize facial expressions [136]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13200879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4eed9d20232953a1265ef35edeeb4843a519b319",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a computer vision system for observing the \"action units\" of a face using video sequences as input. The visual observation (sensing) is achieved by using an optimal estimation optical flow method coupled with a geometric and a physical (muscle) model describing the facial structure. This modeling results in a time-varying spatial patterning of facial shape and a parametric representation of the independent muscle action groups, responsible for the observed facial motions. These muscle action patterns may then be used for analysis, interpretation, and synthesis. Thus, by interpreting facial motions within a physics-based optimal estimation framework, a new control model of facial movement is developed. The newly extracted action units (which we name \"FACS+\") are both physics and geometry-based, and extend the well-known FACS parameters for facial expressions by adding temporal information and non-local spatial patterning of facial motion.<<ETX>>"
            },
            "slug": "A-vision-system-for-observing-and-extracting-facial-Essa-Pentland",
            "title": {
                "fragments": [],
                "text": "A vision system for observing and extracting facial action parameters"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "By interpreting facial motions within a physics-based optimal estimation framework, a new control model of facial movement is developed and the newly extracted action units are both physics and geometry-based, and extend the well-known FACS parameters for facial expressions by adding temporal information and non-local spatial patterning of facial motion."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2968162"
                        ],
                        "name": "I. Gauthier",
                        "slug": "I.-Gauthier",
                        "structuredName": {
                            "firstName": "Isabel",
                            "lastName": "Gauthier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Gauthier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2788357"
                        ],
                        "name": "M. Behrmann",
                        "slug": "M.-Behrmann",
                        "structuredName": {
                            "firstName": "Marlene",
                            "lastName": "Behrmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Behrmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3082093"
                        ],
                        "name": "M. Tarr",
                        "slug": "M.-Tarr",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Tarr",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tarr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 172
                            }
                        ],
                        "text": "\u2026with issues such as \nwhether face perception is a dedicated process (this issue is still be\u00ading debated in the psychology \ncommunity [Biederman and Kalocsai 1998; Ellis 1986; Gauthier et al. 1999; Gauthier and Logo\u00adthetis 2000]) \nand whether it is done holis\u00adtically or by local feature analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 187
                            }
                        ],
                        "text": "Psychophysicists and neuroscientists have been concerned with issues such as whether face perception is a dedicated process (this issue is still being debated in the psychology community [Biederman and Kalocsai 1998; Ellis 1986; Gauthier et al. 1999; Gauthier and Logothetis 2000]) and whether it is done holistically or by local feature analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 42
                            }
                        ],
                        "text": "\u2014Is face recognition a dedicated process? [Biederman and Kalocsai 1998; Ellis 1986; Gauthier et al. 1999; Gauthier and Logothetis 2000]: It is traditionally believed that face recognition is a dedicated process different from other object recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7111762,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2f47f825dca83e34642344af799c7a999e40f750",
            "isKey": false,
            "numCitedBy": 332,
            "numCiting": 147,
            "paperAbstract": {
                "fragments": [],
                "text": "We argue that the current literature on prosopagnosia fails to demonstrate unequivocal evidence for a disproportionate impairment for faces as compared to nonface objects. Two prosopagnosic subjects were tested for the discrimination of objects from several categories (face as well as nonface) at different levels of categorization (basic, subordinate, and exemplar levels). Several dependent measures were obtained including accuracy, signal detection measures, and response times. The results from Experiments 1 to 4 demonstrate that, in simultaneous-matching tasks, response times may reveal impairments with nonface objects in subjects whose error rates only indicate a face deficit. The results from Experiments 5 and 6 show that, given limited stimulus presentation times for face and nonface objects, the same subjects may demonstrate a decit for both stimulus categories in sensitivity. In Experiments 7, 8 and 9, a match-to-sample task that places greater demands on memory led to comparable recognition sensitivity with both face and nonface objects. Regardless of object category, the prosopagnosic subjects were more affected by manipulations of the level of categorization than normal controls. This result raises questions regarding neuropsychological evidence for the modularity of face recognition, as well as its theoretical and methodological foundations."
            },
            "slug": "Can-Face-Recognition-Really-be-Dissociated-from-Gauthier-Behrmann",
            "title": {
                "fragments": [],
                "text": "Can Face Recognition Really be Dissociated from Object Recognition?"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "It is argued that the current literature on prosopagnosia fails to demonstrate unequivocal evidence for a disproportionate impairment for faces as compared to nonface objects, and questions regarding neuropsychological evidence for the modularity of face recognition, as well as its theoretical and methodological foundations are raised."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145546235"
                        ],
                        "name": "Mark H. Johnson",
                        "slug": "Mark-H.-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark H. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4920049"
                        ],
                        "name": "S. Dziurawiec",
                        "slug": "S.-Dziurawiec",
                        "structuredName": {
                            "firstName": "Suzanne",
                            "lastName": "Dziurawiec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dziurawiec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2417905"
                        ],
                        "name": "H. Ellis",
                        "slug": "H.-Ellis",
                        "structuredName": {
                            "firstName": "Hadyn",
                            "lastName": "Ellis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ellis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144377104"
                        ],
                        "name": "J. Morton",
                        "slug": "J.-Morton",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Morton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Morton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1726414,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "ae042a1589152a251962194827732362b4717d80",
            "isKey": false,
            "numCitedBy": 1257,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Newborns'-preferential-tracking-of-face-like-and-Johnson-Dziurawiec",
            "title": {
                "fragments": [],
                "text": "Newborns' preferential tracking of face-like stimuli and its subsequent decline"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41211372"
                        ],
                        "name": "A. Johnston",
                        "slug": "A.-Johnston",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Johnston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Johnston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51422577"
                        ],
                        "name": "H. Hill",
                        "slug": "H.-Hill",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49488925"
                        ],
                        "name": "Nicole Carman",
                        "slug": "Nicole-Carman",
                        "structuredName": {
                            "firstName": "Nicole",
                            "lastName": "Carman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicole Carman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 24
                            }
                        ],
                        "text": "It was demonstrated in [Johnston et al. 1992] that bottom lighting does indeed make it harder \nto identity familiar faces."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 4
                            }
                        ],
                        "text": "In [Johnston et al. 1992], experiments were conducted to explore \nwhether dif.culties with nega\u00adtive images and inverted images of faces arise because each of these manipula\u00adtions \nreverses the apparent direction of lighting, rendering a top-lit image of a face apparently lit from \nbelow."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 67
                            }
                        ],
                        "text": "Effect of lighting change [Bruce et al. 1998; Hill \nand Bruce 1996; Johnston et al. 1992]: It has long been informally observed that photographic negatives \nof faces are dif.cult to recognize."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46071043,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "073ff4bc0c1c2e34f4f22fa6c8c0c065e6c1ee0c",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "When information about three-dimensional shape obtained from shading and shadows is ambiguous, the visual system favours an interpretation of surface geometry which is consistent with illumination from above. If pictures of top-lit faces are rotated the resulting stimulus is both figurally inverted and illuminated from below. In this study the question of whether the effects of figural inversion and lighting orientation on face recognition are independent or interactive is addressed. Although there was a clear inversion effect for faces illuminated from the front and above, the inversion effect was found to be reduced or eliminated for faces illuminated from below. A strong inversion effect for photographic negatives was also found but in this case the effect was not dependent on the direction of illumination. These findings are interpreted as evidence to suggest that lighting faces from below disrupts the formation of surface-based representations of facial shape."
            },
            "slug": "Recognising-Faces:-Effects-of-Lighting-Direction,-Johnston-Hill",
            "title": {
                "fragments": [],
                "text": "Recognising Faces: Effects of Lighting Direction, Inversion, and Brightness Reversal"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The findings are interpreted as evidence to suggest that lighting faces from below disrupts the formation of surface-based representations of facial shape."
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2019875"
                        ],
                        "name": "A. Shio",
                        "slug": "A.-Shio",
                        "structuredName": {
                            "firstName": "Akio",
                            "lastName": "Shio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765522"
                        ],
                        "name": "J. Sklansky",
                        "slug": "J.-Sklansky",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Sklansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sklansky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 84
                            }
                        ],
                        "text": "More so\u00adphisticated methods use estimated .ow \n.elds for segmenting humans in mo\u00adtion [Shio and Sklansky 1991]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 129637437,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "833063952e8a337db7970e81a70b134d25d12675",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for segmenting monocular images of people in motion from a cinematic sequence of frames is described. This method is based on image intensities, motion, and an object model-i.e., a model of the image of a person in motion. Though each part of a person may move in different directions at any instant, the time averaged motion of all parts must converge to a global average value over a few seconds. People in an image may be occluded by other people, and usually it is not easy to detect their boundaries. These boundaries can be detected with motion information if they move in different directions, even if there are almost no apparent differences among object intensities or colors. Each image of a person in a scene usually can be divided into several parts, each with distinct intensities or colors. The parts of a person can be merged into a single group by an iterative merging algorithm based on the object model and the motion information because the parts move coherently. This merging is analogous to the property of perceptual grouping in human visual perception of motion. Experiments based on a sequence of complex real scenes produced results that are supportive of the authors approach to the segmentation of people in motion.<<ETX>>"
            },
            "slug": "Segmentation-of-people-in-motion-Shio-Sklansky",
            "title": {
                "fragments": [],
                "text": "Segmentation of people in motion"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE Workshop on Visual Motion"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35587467"
                        ],
                        "name": "Robert G. Uhl",
                        "slug": "Robert-G.-Uhl",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Uhl",
                            "middleNames": [
                                "G."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert G. Uhl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700665"
                        ],
                        "name": "N. Lobo",
                        "slug": "N.-Lobo",
                        "structuredName": {
                            "firstName": "Niels",
                            "lastName": "Lobo",
                            "middleNames": [
                                "da",
                                "Vitoria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lobo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "The rst step in [83] is feature detection using deformable templates, applied to both the sketch image and the real photograph images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 35
                            }
                        ],
                        "text": "2 Sketches and Infra-Red Images In [83, 84], face recognition based on sketches, which are quite common in law enforcement, is described."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27853261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f4cd82bab182b1312202fdf12818b63026f3487",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a theory and practical computations for automatically matching a police artist sketch to a set of true photographs. We locate facial features in both the sketch as well as the set of photograph images. Then, the sketch is photometrically standardized to facilitate comparison with a photo and then both the sketch and the photos are geometrically standardized. Finally, for matching, eigenanalysis is employed. Results using real police sketches and arrest photos are presented."
            },
            "slug": "A-framework-for-recognizing-a-facial-image-from-a-Uhl-Lobo",
            "title": {
                "fragments": [],
                "text": "A framework for recognizing a facial image from a police sketch"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A theory and practical computations for automatically matching a police artist sketch to a set of true photographs and results using real police sketches and arrest photos are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 156
                            }
                        ],
                        "text": ", AN be m \u00d7 3 matrices whose columns are images of object i (from the bootstrap set) that contain the same m pixels; then the bilinear energy/cost function [Freeman and Tenenbaum 2000] for an image ys of object y under illumination s is ( ys \u2212 N \u2211"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 148
                            }
                        ],
                        "text": "\u2026m \u00d7 3 matrices whose columns are images of object i (from the bootstrap set) that \ncontain the same m pixels; then the bilinear energy/cost func\u00adtion [Freeman and Tenenbaum 2000] for an \nimage ys of object y under illumination s is 2 N L ys - ai Aix, (14) i=1 which is a bilinear problem \nin the\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9492646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e85f7d59e37972ec52cbabfef0512588d87f125",
            "isKey": false,
            "numCitedBy": 860,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "Perceptual systems routinely separate content from style, classifying familiar words spoken in an unfamiliar accent, identifying a font or handwriting style across letters, or recognizing a familiar face or object seen under unfamiliar viewing conditions. Yet a general and tractable computational model of this ability to untangle the underlying factors of perceptual observations remains elusive (Hofstadter, 1985). Existing factor models (Mardia, Kent, & Bibby, 1979; Hinton & Zemel, 1994; Ghahramani, 1995; Bell & Sejnowski, 1995; Hinton, Dayan, Frey, & Neal, 1995; Dayan, Hinton, Neal, & Zemel, 1995; Hinton & Ghahramani, 1997) are either insufficiently rich to capture the complex interactions of perceptually meaningful factors such as phoneme and speaker accent or letter and font, or do not allow efficient learning algorithms. We present a general framework for learning to solve two-factor tasks using bilinear models, which provide sufficiently expressive representations of factor interactions but can nonetheless be fit to data using efficient algorithms based on the singular value decomposition and expectation-maximization. We report promising results on three different tasks in three different perceptual domains: spoken vowel classification with a benchmark multi-speaker database, extrapolation of fonts to unseen letters, and translation of faces to novel illuminants."
            },
            "slug": "Separating-Style-and-Content-with-Bilinear-Models-Tenenbaum-Freeman",
            "title": {
                "fragments": [],
                "text": "Separating Style and Content with Bilinear Models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A general framework for learning to solve two-factor tasks using bilinear models, which provide sufficiently expressive representations of factor interactions but can nonetheless be fit to data using efficient algorithms based on the singular value decomposition and expectation-maximization are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2904067,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d50d0e2af0b45cc7ed25fe4aa97af900c9bd32a",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for locating quasi-frontal views of human faces in cluttered scenes is presented. The algorithm works by coupling a set of local feature detectors with a statistical model of the mutual distances between facial features it is invariant with respect to translation, rotation (in the plane), and scale and can handle partial occlusions of the face. On a challenging database with complicated and varied backgrounds, the algorithm achieved a correct localization rate of 95% in images where the face appeared quasi-frontally.<<ETX>>"
            },
            "slug": "Finding-faces-in-cluttered-scenes-using-random-Leung-Burl",
            "title": {
                "fragments": [],
                "text": "Finding faces in cluttered scenes using random labeled graph matching"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An algorithm for locating quasi-frontal views of human faces in cluttered scenes is presented and it is found that it is invariant with respect to translation, rotation, and scale and can handle partial occlusions of the face."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2397742"
                        ],
                        "name": "H. Moon",
                        "slug": "H.-Moon",
                        "structuredName": {
                            "firstName": "Hankyu",
                            "lastName": "Moon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Moon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766793"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17796293,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e96760d4f2ae09e9f0905c907ec3ffa9a7c39bd",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach to accurately detecting two-dimensional (2-D) shapes. The cross section of the shape boundary is modeled as a step function. We first derive a one-dimensional (1-D) optimal step edge operator, which minimizes both the noise power and the mean squared error between the input and the filter output. This operator is found to be the derivative of the double exponential (DODE) function, originally derived by Ben-Arie and Rao. We define an operator for shape detection by extending the DODE filter along the shape's boundary contour. The responses are accumulated at the centroid of the operator to estimate the likelihood of the presence of the given shape. This method of detecting a shape is in fact a natural extension of the task of edge detection at the pixel level to the problem of global contour detection. This simple filtering scheme also provides a tool for a systematic analysis of edge-based shape detection. We investigate how the error is propagated by the shape geometry. We have found that, under general assumptions, the operator is locally linear at the peak of the response. We compute the expected shape of the response and derive some of its statistical properties. This enables us to predict both its localization and detection performance and adjust its parameters according to imaging conditions and given performance specifications. Applications to the problem of vehicle detection in aerial images, human facial feature detection, and contour tracking in video are presented."
            },
            "slug": "Optimal-edge-based-shape-detection-Moon-Chellappa",
            "title": {
                "fragments": [],
                "text": "Optimal edge-based shape detection"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "An approach to accurately detecting two-dimensional (2-D) shapes by extending the DODE filter along the shape's boundary contour by compute the expected shape of the response and derive some of its statistical properties."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983127"
                        ],
                        "name": "C. Nastar",
                        "slug": "C.-Nastar",
                        "structuredName": {
                            "firstName": "Chahab",
                            "lastName": "Nastar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Nastar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Tech. rep. \nTR-506, MIT Media Lab, Mas\u00adsachusetts, Institute of Technology, Cambridge, MA. SUNG,K."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Tech. rep. TR-440, MIT Me\u00addia Lab, Massachusetts Institute of \nTechnology, Cambridge, MA. JOHNSTON, A., HILL, H., AND CARMAN, N. 1992."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "MIT AI Lab memo 1537."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "MIT Press, Cambridge, MA. HUANG, J., HEISELE,B., AND BLANZ, V. 2003."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 145
                            }
                        ],
                        "text": "The Sep96 evaluation tested the follow\u00ading 10 algorithms: \nan algorithm from Excalibur Corpora\u00adtion (Carlsbad, CA)(Sept. 1996); two algorithms from MIT Media Labo\u00adratory \n(Sept. 1996) [Moghaddam et al. 1996; Turk and Pentland 1991]; three linear discriminant analysis\u00adbased \nalgorithms from Michigan State University [Swets and Weng 1996b] (Sept. 1996) and the University of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997); a gray-scale projection algorithm \nfrom Rutgers University [Wilder 1994] (Sept. 1996); an Elastic Graph Matching algorithm from the University \nof Southern Cali\u00adfornia [Okada et al. 1998; Wiskott et al. 1997] (March 1997); a baseline PCA algorithm \n[Moon and Phillips 2001; Turk and Pentland 1991]; and a baseline normalized correlation matching algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 79
                            }
                        ],
                        "text": "Three of the algorithms performed very well: probabilistic eigenface from MIT [Moghaddam et al. 1996], \nsub\u00adspace LDA from UMD [Zhao et al. 1998, 1999], and Elastic Graph Matching from USC [Wiskott et al. \n1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 149
                            }
                        ],
                        "text": "\u2026follow\u00ading 10 algorithms: \nan algorithm from Excalibur Corpora\u00adtion (Carlsbad, CA)(Sept. 1996); two algorithms from MIT Media Labo\u00adratory \n(Sept. 1996) [Moghaddam et al. 1996; Turk and Pentland 1991]; three linear discriminant analysis\u00adbased \nalgorithms from Michigan State University [Swets and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 6
                            }
                        ],
                        "text": "1996) [44, 169] Three Linear Discriminant Analysis based algorithms from Michigan State University [56] (Sept."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 607,
                                "start": 604
                            }
                        ],
                        "text": "Table V. Internet \nResources for Research and Databases Research pointers Face recognition homepage www.cs.rug.nl/~peterkr/FACE/frhp.html \nFace detection homepage home.t-online.de/home/Robert.Frischholz/face.htm Facial analysis homepage mambo.ucsc.edu/psl/fanl.html \nFacial animiation homepage mambo.ucsc.edu/psl/fan.html Face databases FERET database http://www.itl.nist.gov/iad/humanid/feret/ \nXM2TVS database http://www.ee.surrey.ac.uk/Research/VSSP/xm2vtsdb/ UT Dallas database http://www.utdallas.edu/dept/bbs/FACULTY \nPAGES/otoole/ database.htm Notre Dame database http://www.nd.edu/~cvrl/HID-data.html MIT face databases \nftp://whitechapel.media.mit.edu/pub/images/ Shimon Edelman s face database ftp://ftp.wisdom.weizmann.ac.il/pub/FaceBase/ \nCMU face detection database www.ius.cs.cmu.edu/IUS/dylan usr0/har/faces/test/ CMU PIE database www.ri.cmu.edu/projects/project \n418.html Stirling face database pics.psych.stir.ac.uk M2VTS multimodal database www.tele.ucl.ac.be/M2VTS/ \nYale face database cvc.yale.edu/projects/yalefaces/yalefaces.html Yale face database B cvc.yale.edu/projects/yalefacesB/yalefacesB.html \nHarvard face database hrl.harvard.edu/pub/faces Weizmann face database www.wisdom.weizmann.ac.il/~yael/ \nUMIST face database images.ee.umist.ac.uk/danny/database.html Purdue University face database rvl1.ecn.purdue.edu/~aleix/aleix \nface DB.html Olivetti face database www.cam-orl.co.uk/facedatabase.html Oulu physics-based face database \nwww.ee.oulu../research/imag/color/pbfd.html  Earlier methods focused on constructing invariant features \n[Wiskott et al. 1997] or synthesizing a prototypical view (frontal view) after a full model is extracted \nfrom the input image [Lanitis et al. 1995].22 Such methods work well for small rota\u00adtion angles, but \nthey fail when the angle is large, say 60., causing some important features to be invisible."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 131
                            }
                        ],
                        "text": "The series of tests has allowed advances in algorithm de\u00advelopment to \nbe quanti.ed for exam\u00adple, the performance improvements in the MIT algorithms between March 1995 and \nSeptember 1996, and in the UMD al\u00adgorithms between September 1996 and March 1997."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 78
                            }
                        ],
                        "text": "Three of the algorithms performed very well: Probabilistic Eigenface from MIT [169], Subspace LDA from UMD [60, 63], and Elastic Graph Matching from USC [79]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "MIT AI Lab, Mas\u00adsachusetts Institute of Technology, Cambridge, MA. BEYMER,D.J."
                    },
                    "intents": []
                }
            ],
            "corpusId": 914689,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "355fa6af4450c73041310d7545fadb486dcb6211",
            "isKey": true,
            "numCitedBy": 172,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a probabilistic similarity measure for direct image matching based on a Bayesian analysis of image deformations. We model two classes of variation in object appearance: intra-object and extra-object. The probability density functions for each class are then estimated from training data and used to compute a similarity measure based on the a posteriori probabilities. Furthermore, we use a novel representation for characterizing image differences using a deformable technique for obtaining pixel-wise correspondences. This representation, which is based on a deformable 3D mesh in XYI-space, is then experimentally compared with two simpler representations: intensity differences and optical flow. The performance advantage of our deformable matching technique is demonstrated using a typically hard test set drawn from the US Army's FERET face database."
            },
            "slug": "A-Bayesian-similarity-measure-for-direct-image-Moghaddam-Nastar",
            "title": {
                "fragments": [],
                "text": "A Bayesian similarity measure for direct image matching"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A probabilistic similarity measure for direct image matching based on a Bayesian analysis of image deformations is proposed and a novel representation for characterizing image differences using a deformable technique for obtaining pixel-wise correspondences is used."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2037776"
                        ],
                        "name": "D. Reisfeld",
                        "slug": "D.-Reisfeld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Reisfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Reisfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47620675"
                        ],
                        "name": "Y. Yeshurun",
                        "slug": "Y.-Yeshurun",
                        "structuredName": {
                            "firstName": "Yehezkel",
                            "lastName": "Yeshurun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yeshurun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62756592,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2118c6e85f68a08c3bfe08aa05006c5db0564ca8",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Locating facial features is crucial for various face recognition schemes. The authors suggest a robust facial feature detector based on a generalized symmetry interest operator. No special tuning is required if the face occupies 15-60% of the image. The operator was tested on a large face data base with a success rate of over 95%.<<ETX>>"
            },
            "slug": "Robust-detection-of-facial-features-by-generalized-Reisfeld-Yeshurun",
            "title": {
                "fragments": [],
                "text": "Robust detection of facial features by generalized symmetry"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A robust facial feature detector based on a generalized symmetry interest operator that was tested on a large face data base with a success rate of over 95%."
            },
            "venue": {
                "fragments": [],
                "text": "[1992] Proceedings. 11th IAPR International Conference on Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107436317"
                        ],
                        "name": "J. Davis",
                        "slug": "J.-Davis",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Davis",
                            "middleNames": [
                                "Wade"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2202067,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "421d7f83356fdcdf190865325d4aa638b0e9c39f",
            "isKey": false,
            "numCitedBy": 1448,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter introduces the subject of statistical pattern recognition (SPR). It starts by considering how features are defined and emphasizes that the nearest neighbor algorithm achieves error rates comparable with those of an ideal Bayes\u2019 classifier. The concepts of an optimal number of features, representativeness of the training data, and the need to avoid overfitting to the training data are stressed. The chapter shows that methods such as the support vector machine and artificial neural networks are subject to these same training limitations, although each has its advantages. For neural networks, the multilayer perceptron architecture and back-propagation algorithm are described. The chapter distinguishes between supervised and unsupervised learning, demonstrating the advantages of the latter and showing how methods such as clustering and principal components analysis fit into the SPR framework. The chapter also defines the receiver operating characteristic, which allows an optimum balance between false positives and false negatives to be achieved."
            },
            "slug": "Statistical-Pattern-Recognition-Davis",
            "title": {
                "fragments": [],
                "text": "Statistical Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This chapter introduces the subject of statistical pattern recognition (SPR) by considering how features are defined and emphasizes that the nearest neighbor algorithm achieves error rates comparable with those of an ideal Bayes\u2019 classifier."
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678633"
                        ],
                        "name": "Gregory Hager",
                        "slug": "Gregory-Hager",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Hager",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory Hager"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18750721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5fe83c9ac8424c8220d9c46d92582427d6ad68e",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Historically, SSD or correlation-based visual tracking algorithms have been sensitive to changes in illumination and shading across the target region. This paper describes methods for implementing SSD tracking that is both insensitive to illumination variations and computationally efficient. We first describe a vector-space formulation of the tracking problem, showing how to recover geometric deformations. We then show that the same vector space formulation can be used to account for changes in illumination. We combine geometry and illumination into an algorithm that tracks large image regions on live video sequences using no more computation than would be required to trade with no accommodation for illumination changes. We present experimental results which compare the performance of SSD tracking with and without illumination compensation."
            },
            "slug": "Real-time-tracking-of-image-regions-with-changes-in-Hager-Belhumeur",
            "title": {
                "fragments": [],
                "text": "Real-time tracking of image regions with changes in geometry and illumination"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper combines geometry and illumination into an algorithm that tracks large image regions on live video sequences using no more computation than would be required to trade with no accommodation for illumination changes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144975752"
                        ],
                        "name": "V. Bruce",
                        "slug": "V.-Bruce",
                        "structuredName": {
                            "firstName": "Vicki",
                            "lastName": "Bruce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Bruce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052767688"
                        ],
                        "name": "M. Burton",
                        "slug": "M.-Burton",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Burton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4791576"
                        ],
                        "name": "N. Dench",
                        "slug": "N.-Dench",
                        "structuredName": {
                            "firstName": "Neal",
                            "lastName": "Dench",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dench"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 17
                            }
                        ],
                        "text": "Distinctiveness [Bruce et al. 1994]: Stud\u00adies show that distinctive faces are bet\u00adter retained in memory \nand are rec\u00adognized better and faster than typical faces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 17
                            }
                        ],
                        "text": "\u2014Distinctiveness [Bruce et al. 1994]: Studies show that distinctive faces are better retained in memory and are recognized better and faster than typical faces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39787441,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "8c86faa9c051846d53b10a57c844196804fd339c",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this study we examine the relationship between objective aspects of facial appearance and facial \u201cdistinctiveness\u201d. Specifically, we examine whether the extent to which a face deviates from \u201caverage\u201d correlates with rated distinctiveness and measures of memorability. We find that, provided the faces are rated with hair concealed, reasonable correlations can be achieved between their physical deviation and their rated distinctiveness. More modest correlations are obtained between physical deviation and the extent to which faces are remembered, either correctly or falsely, after previous study. Furthermore, memory ratings obtained to \u201ctarget\u201d faces when they have been previously seen (i.e. \u201chits\u201d) do not show the expected negative correlation with the scores obtained to the same faces when acting as distractors (i.e. \u201cfalse positives\u201d), though each correlates with rated distinctiveness. This confirms the theory of Vokey and Read (1992) that the typicality/distinctiveness dimension can be broken down into two orthogonal components: \u201cmemorability\u201d and \u201ccontext-free familiarity\u201d."
            },
            "slug": "What's-Distinctive-about-a-Distinctive-Face-Bruce-Burton",
            "title": {
                "fragments": [],
                "text": "What's Distinctive about a Distinctive Face?"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is found that, provided the faces are rated with hair concealed, reasonable correlations can be achieved between their physical deviation and their rated distinctiveness, confirming the theory of Vokey and Read (1992) that the typicality/distinctiveness dimension can be broken down into two orthogonal components: \u201cmemorability\u201d and \u201ccontext-free familiarity\u201d."
            },
            "venue": {
                "fragments": [],
                "text": "The Quarterly journal of experimental psychology. A, Human experimental psychology"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 182167,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "242a7d569973248beba082e17a32815bc5b2b359",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Image \"appearance\" may change over time due to a variety of causes such as: 1) object or camera motion; 2) generic photometric events including variations in illumination (e.g. shadows) and specular reflections; and 3) \"iconic changes\" which are specific to the objects being viewed and include complex occlusion events and changes in the material properties of the objects. We propose a general framework for representing and recovering these \"appearance changes\" in an image sequence as a \"mixture\" of different causes. The approach generalizes previous work on optical flow to provide a richer description of image events and more reliable estimates of image motion."
            },
            "slug": "A-framework-for-modeling-appearance-change-in-image-Black-Fleet",
            "title": {
                "fragments": [],
                "text": "A framework for modeling appearance change in image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes a general framework for representing and recovering appearance changes in an image sequence as a \"mixture\" of different causes that generalizes previous work on optical flow to provide a richer description of image events and more reliable estimates of image motion."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2417905"
                        ],
                        "name": "H. Ellis",
                        "slug": "H.-Ellis",
                        "structuredName": {
                            "firstName": "Hadyn",
                            "lastName": "Ellis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ellis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26638884,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "3d326e5b5aeda13050539daeb364ce9f594d945e",
            "isKey": false,
            "numCitedBy": 277,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Following a review of the stimulus and subject factors which have been found to affect recognition faces, the question of whether this process can be considered a special one is dealt with. Evidence from studies involving the development of face recognition, the recognition of inverted faces, and the clinical condition prosopagnosia is considered, and in each case found to be inadequate for the unequivocal conclusion that the processes underlying face recognition are qualitatively different from those employed in recognizing other pictorial material."
            },
            "slug": "Recognizing-faces.-Ellis",
            "title": {
                "fragments": [],
                "text": "Recognizing faces."
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Evidence from studies involving the development of face recognition, the recognition of inverted faces, and the clinical condition prosopagnosia is considered, and in each case found to be inadequate for the unequivocal conclusion that the processes underlying face recognition are qualitatively different from those employed in recognizing other pictorial material."
            },
            "venue": {
                "fragments": [],
                "text": "British journal of psychology"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087095606"
                        ],
                        "name": "A. Young",
                        "slug": "A.-Young",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Young",
                            "middleNames": [
                                "W"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2417905"
                        ],
                        "name": "H. Ellis",
                        "slug": "H.-Ellis",
                        "structuredName": {
                            "firstName": "Hadyn",
                            "lastName": "Ellis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ellis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 161257994,
            "fieldsOfStudy": [
                "History"
            ],
            "id": "2cb8c262ba41bb446b9250299f4f917f8ddc8dcd",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Handbook-of-Research-on-Face-Processing-Young-Ellis",
            "title": {
                "fragments": [],
                "text": "Handbook of Research on Face Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9794074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4302d843e008bdc4444e7fb161044a9c60b7c01d",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach for analysis and representation of facial dynamics for recognition of facial expressions from image sequences is proposed. The algorithms we develop utilize optical flow computation to identify the direction of rigid and non-rigid motions that are caused by human, facial expressions. A mid-level symbolic representation that is motivated by linguistic and psychological considerations is developed. Recognition of six facial expressions, as well as eye blinking, on a large set of image sequences is reported.<<ETX>>"
            },
            "slug": "Computing-spatio-temporal-representations-of-human-Yacoob-Davis",
            "title": {
                "fragments": [],
                "text": "Computing spatio-temporal representations of human faces"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "An approach for analysis and representation of facial dynamics for recognition of facial expressions from image sequences is proposed and a mid-level symbolic representation that is motivated by linguistic and psychological considerations is developed."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5058247"
                        ],
                        "name": "J. Bigun",
                        "slug": "J.-Bigun",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Bigun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bigun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2100878"
                        ],
                        "name": "B. Duc",
                        "slug": "B.-Duc",
                        "structuredName": {
                            "firstName": "Beno\u00eet",
                            "lastName": "Duc",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Duc"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3276986"
                        ],
                        "name": "F. Smeraldi",
                        "slug": "F.-Smeraldi",
                        "structuredName": {
                            "firstName": "Fabrizio",
                            "lastName": "Smeraldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Smeraldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061647120"
                        ],
                        "name": "S. Fischer",
                        "slug": "S.-Fischer",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064024597"
                        ],
                        "name": "Aleksej Makarov",
                        "slug": "Aleksej-Makarov",
                        "structuredName": {
                            "firstName": "Aleksej",
                            "lastName": "Makarov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aleksej Makarov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 42
                            }
                        ],
                        "text": "Multimodal methods Video- and audio-based [Bigun et al. 1998; Choudhury et al. 1999]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 48
                            }
                        ],
                        "text": "They have been used in many multimodal systems [Bigun et al. 1998; Choudhury et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 258
                            }
                        ],
                        "text": "\u2026et al. 1997; Moghaddam and Pentland 1997; Okada et al. 1998; Penev and Atick 1996; \nWechsler et al. 1997; Wiskott et al. 1997] Tracking-enhanced [Edwards et al. 1998; McKenna and Gong 1997, \n1998; Steffens et al. 1998] Multimodal methods Video-and audio-based [Bigun et al. 1998; Choudhury et \nal."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12905280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9d30863b51e6dbd066d5c5e3c6af599dec2b431",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper deals with the elements of a multi-modal person authentication systems. Test procedures for evaluating machine experts as well as machine supervisors based on leave-one-out principle are described. Two independent machine experts on person authentication are presented along with their individual performances. These experts consisted of a face (Gabor features) and a speaker (LPC features) authentication algorithm trained on the M2VTS multi-media database. The expert opinions are combined yielding far better performances by using a trained supervisor based on Bayesian statistics than individual modalities aggregated by averaging."
            },
            "slug": "Multi-Modal-Person-Authentication-Bigun-Duc",
            "title": {
                "fragments": [],
                "text": "Multi-Modal Person Authentication"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Two independent machine experts on person authentication are presented along with their individual performances, yielding far better performances by using a trained supervisor based on Bayesian statistics than individual modalities aggregated by averaging."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187218"
                        ],
                        "name": "A. J. Bell",
                        "slug": "A.-J.-Bell",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Bell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 268
                            }
                        ],
                        "text": "\u2026Bartlett, H. Lades, and T. Sejnowski.) \nthat can be viewed as independent image features for a given set of training im\u00adages [Bell and Sejnowski \n1995], and the second is used to .nd image .lters that produce statistically independent out\u00adputs (a \nfactorial code method) [Bell and Se\u00adjnowski 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 229
                            }
                        ],
                        "text": "that can be viewed as independent image features for a given set of training images [Bell and Sejnowski 1995], and the second is used to find image filters that produce statistically independent outputs (a factorial code method) [Bell and Sejnowski 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6219133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca1d23be869380ac9e900578c601c2d1febcc0c9",
            "isKey": false,
            "numCitedBy": 2373,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-\u201cindependent-components\u201d-of-natural-scenes-are-Bell-Sejnowski",
            "title": {
                "fragments": [],
                "text": "The \u201cindependent components\u201d of natural scenes are edge filters"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143661366"
                        ],
                        "name": "M. Seibert",
                        "slug": "M.-Seibert",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Seibert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Seibert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2038179"
                        ],
                        "name": "A. Waxman",
                        "slug": "A.-Waxman",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Waxman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waxman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62620674,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40a82a182d11d53db1be2b8ea5dc0cc5a3adcc07",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We summarize a recently developed modular neural system which exploits sequences of 2D views for learning and recognizing 3D objects. An aspect network is an unsupervised module of our complete artificial vision system for detecting and learning the view transitions (as the appearance of a rotating object changes), and for later recognizing objects from sequences of views. By processing sequences of views, the system accumulates evidence over time, thereby increasing the confidence of its recognition decisions. Also, when new views are revealed following views recognized previously by an aspect network during the course of observation, the new views and view-transitions are used to refine the evolving 3D object representation automatically. Recognition is possible even from novel (previously unexperienced) view sequences. The objects used for illustration are model aircraft in flight. The computations are formulated as differential equations among analog nodes and synapses to model the temporal dynamics explicitly."
            },
            "slug": "Combining-evidence-from-multiple-views-of-3-D-Seibert-Waxman",
            "title": {
                "fragments": [],
                "text": "Combining evidence from multiple views of 3-D objects"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A recently developed modular neural system which exploits sequences of 2D views for learning and recognizing 3D objects and which recognition is possible even from novel (previously unexperienced) view sequences is summarized."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2973523"
                        ],
                        "name": "T. Akimoto",
                        "slug": "T.-Akimoto",
                        "structuredName": {
                            "firstName": "Takaaki",
                            "lastName": "Akimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Akimoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34857543"
                        ],
                        "name": "Y. Suenaga",
                        "slug": "Y.-Suenaga",
                        "structuredName": {
                            "firstName": "Yasuhito",
                            "lastName": "Suenaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Suenaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145356886"
                        ],
                        "name": "R. Wallace",
                        "slug": "R.-Wallace",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Wallace",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Wallace"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15210583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8463d15dd6820e58b3b0db8e9e40878e0e3108d",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Model-based encoding of human facial features for narrowband visual communication is described. Based on an already prepared 3D human model, this coding method detects and understands a person's body motion and facial expressions. It expresses the essential information as compact codes and transmits it. At the receiving end, this code becomes the basis for modifying the 3D model of the person and thereby generating lifelike human images. The feature extraction used by the system to acquire data for regions or edges that express the eyes, nose, mouth, and outlines of the face and hair is discussed. The way in which the system creates a 3D model of the person by using the features extracted in the first part to modify a generic head model is also discussed.<<ETX>>"
            },
            "slug": "Automatic-creation-of-3D-facial-models-Akimoto-Suenaga",
            "title": {
                "fragments": [],
                "text": "Automatic creation of 3D facial models"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "Model-based encoding of human facial features for narrowband visual communication based on an already prepared 3D human model detects and understands a person's body motion and facial expressions and becomes the basis for modifying the 3D model of the person and thereby generating lifelike human images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Computer Graphics and Applications"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144721252"
                        ],
                        "name": "H. Nagel",
                        "slug": "H.-Nagel",
                        "structuredName": {
                            "firstName": "Hans-Hellmut",
                            "lastName": "Nagel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nagel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 207116210,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "abf753b4625513e1442f54da31f1ab0a383d55d5",
            "isKey": false,
            "numCitedBy": 106,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Many investigations of image sequences can be understood on the basis of a few concepts for which computational approaches become increasingly available. The estimation of optical flow fields is discussed, exhibiting a common foundation for feature-based and differential approaches. The interpretation of optical flow fields is mostly concerned so far with approaches which infer the 3-D structure of a rigid point configuration in 3-D space and its relative motion with respect to the image sensor from an image sequence. The combination of stereo and motion provides additional incentives to evaluate image sequences, especially for the control of robots and autonomous vehicles. Advances in all these areas lead to the desire to describe the spatio-temporal development recorded by an image sequence not only at the level of geometry, but also at higher conceptual levels, for example by natural language descriptions."
            },
            "slug": "Image-Sequences-Ten-(Octal)-Years-from-towards-a-Nagel",
            "title": {
                "fragments": [],
                "text": "Image Sequences - Ten (Octal) Years - from phenomenology towards a Theoretical Foundation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The estimation of optical flow fields is discussed, exhibiting a common foundation for feature-based and differential approaches, and the desire to describe the spatio-temporal development recorded by an image sequence not only at the level of geometry, but also at higher conceptual levels."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109825670"
                        ],
                        "name": "A. D. Wilson",
                        "slug": "A.-D.-Wilson",
                        "structuredName": {
                            "firstName": "Ashley",
                            "lastName": "Wilson",
                            "middleNames": [
                                "Danielle"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. D. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 753848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "024de79de38c386e1bde33055aa38f607feffe6c",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "A state-based method for learning visual behavior from image sequences is presented. The technique is novel for its incorporation of multiple representations into the Hidden Markov Model framework. Independent representations of the instantaneous visual input at each state of the Markov model are estimated concurrently with the learning of the temporal characteristics. Measures of the degree to which each representation describes the input are combined to determine an input's overall membership to a state. We exploit two constraints allowing application of the technique to view-based gesture recognition: gestures are modal in the space of possible human motion, and gestures are viewpoint-dependent. The recovery of the visual behavior of a number of simple gestures with a small number of low resolution image sequences is shown."
            },
            "slug": "Learning-visual-behavior-for-gesture-analysis-Wilson-Bobick",
            "title": {
                "fragments": [],
                "text": "Learning visual behavior for gesture analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A state-based method for learning visual behavior from image sequences that exploits two constraints allowing application of the technique to view-based gesture recognition: gestures are modal in the space of possible human motion, and gestures are viewpoint-dependent."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Symposium on Computer Vision - ISCV"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3082093"
                        ],
                        "name": "M. Tarr",
                        "slug": "M.-Tarr",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Tarr",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tarr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153905429"
                        ],
                        "name": "H. B\u00fclthoff",
                        "slug": "H.-B\u00fclthoff",
                        "structuredName": {
                            "firstName": "H",
                            "lastName": "B\u00fclthoff",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. B\u00fclthoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 140
                            }
                        ],
                        "text": "These two problems have been documented in many evaluations of FRT systems [4, 181] and in the divided opinions of the psychology community [24, 23, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 32
                            }
                        ],
                        "text": "Viewpoint-invariant recognition?[23, 24]: Much work in visual object recognition (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10224760,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "0222c160339366e9cfd1372db0a059d1435b12ce",
            "isKey": false,
            "numCitedBy": 338,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Is human object recognition viewpoint dependent or viewpoint invariant under \"everyday\" conditions? I. Biederman and P.C. Gerhardstein (1993) argued that viewpoint-invariant mechanisms are used almost exclusively. However, our analysis indicates that (a) their conditions for immediate viewpoint invariance lack the generality to characterize a wide range of recognition phenomena, (b) the extensive body of viewpoint-dependent results cannot be dismissed as processing \"by-products\" or \"experimental artifacts,\" and (c) geon structural descriptions cannot coherently account for category recognition, the domain they are intended to explain. The weight of current evidence supports an exemplar-based multiple-views mechanism as an important component of both exemplar-specific and categorical recognition."
            },
            "slug": "Is-human-object-recognition-better-described-by-or-Tarr-B\u00fclthoff",
            "title": {
                "fragments": [],
                "text": "Is human object recognition better described by geon structural descriptions or by multiple views? Comment on Biederman and Gerhardstein (1993)."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The weight of current evidence supports an exemplar-based multiple-views mechanism as an important component of both exemplar specific and categorical recognition, the domain they are intended to explain."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology. Human perception and performance"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31857045"
                        ],
                        "name": "E. Hildreth",
                        "slug": "E.-Hildreth",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Hildreth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hildreth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 24
                            }
                        ],
                        "text": "We list here only books [86, 87, 106, 107, 108, 109] and review papers [110, 111, 112]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62198913,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "c416a885cc36515740ef8dfa9220366fa2a379f8",
            "isKey": false,
            "numCitedBy": 660,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nComputer scientists designing machine vision systems, psychologists working in visual perception, visual neurophysiologists, and theoretical biologists will derive a deeper understanding of visual function - in particular the computations that the human visual system uses to analyze motion-from the important research reported in this book. \nThe organization of movement in the changing image that reaches the eye provides our visual system with a valuable source of information for analyzing the structure of our surroundings. This book examines the measurement of this movement and the use of relative movement to locate the boundaries of physical objects in the environment. It investigates the nature of the computations that are necessary to perform this analysis by any vision system, biological or artificial. \nThe author first defines the goals of these visual tasks, reveals the properties of the physical world that a vision system can rely upon to achieve such goals, and suggests general methods that can be used to carry out the tasks. From the general methods, she designs algorithms specifying a particular sequence of computations that a vision system can execute to perform these visual tasks. These algorithms are implemented on a computer system under a variety of circumstances. Combined with the traditional approaches of psychology and neurophysiology, this computational approach provides an exciting analysis of visual function, raising many new questions about the human vision system for further investigation. \nEllen Catherine Hildreth received her doctorate from MIT. She is a Research Scientist in the MIT Artificial Intelligence Laboratory and associate director of theCenter for Biological Information Processing at the Whitaker College of Health Sciences, Technology, and Management. The Measurement of Visual Motion is an ACM Distinguished Dissertation."
            },
            "slug": "Measurement-of-Visual-Motion-Hildreth",
            "title": {
                "fragments": [],
                "text": "Measurement of Visual Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Combined with the traditional approaches of psychology and neurophysiology, this computational approach provides an exciting analysis of visual function, raising many new questions about the human vision system for further investigation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705627"
                        ],
                        "name": "J. Aggarwal",
                        "slug": "J.-Aggarwal",
                        "structuredName": {
                            "firstName": "Jake",
                            "lastName": "Aggarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aggarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3023166"
                        ],
                        "name": "N. Nandhakumar",
                        "slug": "N.-Nandhakumar",
                        "structuredName": {
                            "firstName": "Nagaraj",
                            "lastName": "Nandhakumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nandhakumar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53680608,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "a03c5a0bbe99c87a6fdcb5ea8c37cbc776fde993",
            "isKey": false,
            "numCitedBy": 766,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent developments are reviewed in the computation of motion and structure of objects in a scene from a sequence of images. Two distinct paradigms are highlighted: (i) the feature-based approach and (ii) the optical-flow-based approach. The comparative merits/demerits of these approaches are discussed. The current status of research in these areas is reviewed and future research directions are indicated. >"
            },
            "slug": "On-the-computation-of-motion-from-sequences-of-Aggarwal-Nandhakumar",
            "title": {
                "fragments": [],
                "text": "On the computation of motion from sequences of images-A review"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Two distinct paradigms are highlighted: (i) the feature- based approach and (ii) the optical-flow-based approach: the comparative merits/demerits of these approaches are discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144730291"
                        ],
                        "name": "J. Bartlett",
                        "slug": "J.-Bartlett",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bartlett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bartlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117570265"
                        ],
                        "name": "J. Searcy",
                        "slug": "J.-Searcy",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Searcy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Searcy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 34
                            }
                        ],
                        "text": "An excellent ex\u00adample is given in \n[Bartlett and Searcy 1993] using the Thatcher illusion [Thompson 1980]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 33
                            }
                        ],
                        "text": "An excellent example is given in [Bartlett and Searcy 1993] using the \u201cThatcher illusion\u201d [Thompson 1980]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17115861,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "cd02e4e8d634c47d223efcc871d06ebf07b5c6d6",
            "isKey": false,
            "numCitedBy": 435,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "If the mouth and eyes of a face are inverted, the altered construction appears grotesque when upright, but not when upside-down. Three studies of this \"Thatcher illusion\" employed faces that were grotesque when upright because: (a) their eyes and mouths had been inverted (\"Thatcherized\" faces), (b) their eyes and mouths had been moved (spatially distorted faces), or (c) they had grotesque posed expressions. Inversion reduced the apparent grotesqueness of both Thatcherized and spatially distorted faces, but not grotesque-expression faces. Moreover, Thatcherized and distorted faces, although not grotesque-expression faces, were judged as more similar to normal, smiling faces when face-pairs were inverted than when they were upright. Similarity ratings to inverted face-pairs were correlated with latencies of response to these pairs in a task that encouraged attention to components (e.g., mouths, eyes) rather than wholistic properties. Similarity ratings to upright face-pairs showed no such correlation, and this and other findings suggested that although similarity ratings to upright faces are based on wholistic information, similarity ratings to inverted faces are based largely on components. The Thatcher illusion reflects a disruption of encoding of wholistic information when faces are inverted."
            },
            "slug": "Inversion-and-Configuration-of-Faces-Bartlett-Searcy",
            "title": {
                "fragments": [],
                "text": "Inversion and Configuration of Faces"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Similarity ratings to inverted face-pairs were correlated with latencies of response to these pairs in a task that encouraged attention to components (e.g., mouths, eyes) rather than wholistic properties, and this and other findings suggested that although similarity ratings to upright faces are based onWholistic information, similarity Ratings to inverted faces arebased largely on components."
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38995786"
                        ],
                        "name": "S. Pigeon",
                        "slug": "S.-Pigeon",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Pigeon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pigeon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698047"
                        ],
                        "name": "L. Vandendorpe",
                        "slug": "L.-Vandendorpe",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Vandendorpe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vandendorpe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 67
                            }
                        ],
                        "text": "The XM2VTS database is an expan\u00adsion of the earlier M2VTS database [Pigeon and Vandendorpe \n1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 30862659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20edcc51b1cfbaf7ee54f99c013f48453c1059aa",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the use of the profile shape to recognize human faces. In order to test the intrinsic efficiency of profile authentication, we will make use of a method that directly works on the profile contour encoded as x-y coordinates. This way, the performance rated here will only depend on the ability of the profile view to dissociate faces and not on the choice of a given set of profile features and/or the quality of their extraction."
            },
            "slug": "Profile-Authentication-Using-a-Chamfer-Matching-Pigeon-Vandendorpe",
            "title": {
                "fragments": [],
                "text": "Profile Authentication Using a Chamfer Matching Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This paper investigates the use of the profile shape to recognize human faces by using a method that directly works on the profile contour encoded as x-y coordinates and will test the intrinsic efficiency of profile authentication."
            },
            "venue": {
                "fragments": [],
                "text": "AVBPA"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3355150"
                        ],
                        "name": "P. Tsai",
                        "slug": "P.-Tsai",
                        "structuredName": {
                            "firstName": "Ping-Sing",
                            "lastName": "Tsai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Tsai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 141
                            }
                        ],
                        "text": "Finally, the fourth column shows real images that \nare close to the prototype images [Zhao and Chellappa 2000]. local SFS algorithm [Tsai and Shah 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 90
                            }
                        ],
                        "text": "The second column shows \nprototype images rendered using the local SFS algorithm [Tsai and Shah 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17868996,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f68c631ddbf84da95383adae87f25f2694407ae",
            "isKey": false,
            "numCitedBy": 324,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Shape-from-shading-using-linear-approximation-Tsai-Shah",
            "title": {
                "fragments": [],
                "text": "Shape from shading using linear approximation"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21790076"
                        ],
                        "name": "J. Sergent",
                        "slug": "J.-Sergent",
                        "structuredName": {
                            "firstName": "Justine",
                            "lastName": "Sergent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sergent"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 16
                            }
                        ],
                        "text": "Recent studies [Sergent 1986] have shown that, depending on the spe\u00adci.c recognition task, \nthe low, band\u00adpass and high-frequency components may play different roles."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 170
                            }
                        ],
                        "text": "For example gender classi.cation \ncan be successfully accomplished using low-frequency com\u00adponents only, while identi.cation re\u00adquires \nthe use of high-frequency com\u00adponents [Sergent 1986]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 68
                            }
                        ],
                        "text": "The role \nof spatial frequency analysis [Ginsburg 1978; Harmon 1973; Sergent 1986]: Earlier studies [Ginsburg 1978; \nHarmon 1973] concluded that informa\u00adtion in low spatial frequency bands plays a dominant role in face \nrecog\u00adnition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 143136705,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "614708b9fe5aae1bb1b3a4463c3bb2e4365a99e9",
            "isKey": false,
            "numCitedBy": 205,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "One basic principle of science, which typically applies to psychology, suggests that one should never seek to explain a psychological fact by a mechanism at a higher level if it can be explained by one at a lower level (Morgan, 1894). This seems to be a reasonable principle, and it compels us to attempt to specify and understand the nature of the preliminary operations that underlie a given process. Such a principle is quite relevant to the problem of face perception, and it is with early visual processes, as well as their implications for later operations, that the present chapter will be concerned. It would be misleading, however, to begin with the idea that one can account for most of the processes underlying perception by considering only these early processes, and this is especially true of face perception. For one thing, perception is a process resulting from the interaction of the incoming information and mental states or cerebral structures, and it is therefore necessary to understand the nature and characteristics of this interaction to explain perceptual processes. For another, the human face is an extremely familiar multidimensional pattern, and our frequent exposure to such a stimulus has enabled us to develop certain processing mechanisms, which some authors (e.g, Goldstein & Chance, 1981) have referred to as \u201cschemata,\u201d that allow access to consistent dimensions which facilitate perception and memory."
            },
            "slug": "Microgenesis-of-Face-Perception-Sergent",
            "title": {
                "fragments": [],
                "text": "Microgenesis of Face Perception"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2995060"
                        ],
                        "name": "D. Swets",
                        "slug": "D.-Swets",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Swets",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Swets"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145926447"
                        ],
                        "name": "J. Weng",
                        "slug": "J.-Weng",
                        "structuredName": {
                            "firstName": "Juyang",
                            "lastName": "Weng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 144
                            }
                        ],
                        "text": "\u2026between a point and the feature line linking two stored sample points [Li \nand Lu 1999]; Fisher\u00adfaces [Belhumeur et al. 1997; Liu and Wechsler 2001; Swets and Weng 1996b; Zhao \net al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA) [Fisher 1938]; Bayesian methods, \nwhich use a\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 3
                            }
                        ],
                        "text": "In Wechsler et al. [1997], a fully auto\u00admatic person authentication system was described \nwhich included video break, face detection, and authentication modules."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 400,
                                "start": 384
                            }
                        ],
                        "text": "Using principal-component \nanalysis (PCA), many face recognition techniques have been developed: eigenfaces [Turk and Pentland 1991], \nwhich use a nearest\u00adneighbor classi.er; feature-line-based methods, which replace the point-to-point \ndistance with the distance between a point and the feature line linking two stored sample points [Li \nand Lu 1999]; Fisher\u00adfaces [Belhumeur et al. 1997; Liu and Wechsler 2001; Swets and Weng 1996b; Zhao \net al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA) [Fisher 1938]; Bayesian methods, \nwhich use a probabilistic distance metric [Moghaddam and Pentland 1997]; and SVM methods, which use a \nsupport vector machine as the classi.er [Phillips 1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 115
                            }
                        ],
                        "text": "An evolution pursuit-(EP-) based adap\u00adtive \nrepresentation and its application to face recognition were presented in Liu and Wechsler [2000a]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "In Face Recognition: \nFrom The\u00adory to Applications, H. Wechsler, P. J. Phillips, V. Bruce, F. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 120
                            }
                        ],
                        "text": "Face recognition systems using Linear/Fisher Discriminant Analysis [55] as the classi er have also been very successful [56, 57, 58, 59, 60, 61, 62, 63]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 304,
                                "start": 284
                            }
                        ],
                        "text": "The Sep96 evaluation tested the follow\u00ading 10 algorithms: \nan algorithm from Excalibur Corpora\u00adtion (Carlsbad, CA)(Sept. 1996); two algorithms from MIT Media Labo\u00adratory \n(Sept. 1996) [Moghaddam et al. 1996; Turk and Pentland 1991]; three linear discriminant analysis\u00adbased \nalgorithms from Michigan State University [Swets and Weng 1996b] (Sept. 1996) and the University of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997); a gray-scale projection algorithm \nfrom Rutgers University [Wilder 1994] (Sept. 1996); an Elastic Graph Matching algorithm from the University \nof Southern Cali\u00adfornia [Okada et al. 1998; Wiskott et al. 1997] (March 1997); a baseline PCA algorithm \n[Moon and Phillips 2001; Turk and Pentland 1991]; and a baseline normalized correlation matching algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 549,
                                "start": 533
                            }
                        ],
                        "text": "Categorization of Still Face Recognition Techniques Approach Representative work Holistic \nmethods Principal-component analysis (PCA) Eigenfaces Direct application of PCA [Craw and Cameron 1996; \nKirby and Sirovich 1990; Turk and Pentland 1991] Probabilistic eigenfaces Two-class problem with prob. \nmeasure [Moghaddam and Pentland 1997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and Wechsler 2000a] Feature lines Point-to-line distance based [Li \nand Lu 1999] ICA ICA-based feature analysis [Bartlett et al. 1998] Other representations LDA/FLD LDA/FLD \non raw image [Etemad and Chellappa 1997] PDBNN Probabilistic decision based NN [Lin et al. 1997] Feature-based \nmethods Pure geometry methods Earlier methods [Kanade 1973; Kelly 1970]; recent methods [Cox et al. 1996; \nManjunath et al. 1992] Dynamic link architecture Graph matching methods [Okada et al. 1998; Wiskott et \nal."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Applications, H. Wechsler, P. J. Phillips, V. Bruce, \nF. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 142
                            }
                        ],
                        "text": "Toward \nthat end, EP implements strategies characteristic of ge\u00adnetic algorithms (GAs) for searching the so-called \nenhanced FLD (EFM) approach [Liu and Wechsler 2000b]. space of possible solutions to determine the optimal \nbasis."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 282
                            }
                        ],
                        "text": "Four methods are compared: 1) a correlation-based method, 2) a variant of the linear subspace method suggested in [66], 3) an eigenface method [43, 44], and 4) a Fisher-face method which uses subspace projection prior to LDA projection to avoid the possible singularity in Sw as in [56, 57]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 142
                            }
                        ],
                        "text": "\u2026\n(Sept. 1996) [Moghaddam et al. 1996; Turk and Pentland 1991]; three linear discriminant analysis\u00adbased \nalgorithms from Michigan State University [Swets and Weng 1996b] (Sept. 1996) and the University of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997);\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "In \nFace Recognition: From Theory to Applica\u00adtions, H. Wechsler, P. J. Phillips, V. Bruce, F. F. Soulie, \nand T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 121
                            }
                        ],
                        "text": "Face recognition systems using LDA/FLD have also been very suc\u00adcessful [Belhumeur et al. 1997; \nEtemad and Chellappa 1997; Swets and Weng 1996b; Zhao et al. 1998; Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 233
                            }
                        ],
                        "text": "Categorization of Video-Based \nFace Recognition Techniques Approach Representative work Still-image methods Basic methods [Turk and \nPentland 1991; Lin et al. 1997; Moghaddam and Pentland 1997; Okada et al. 1998; Penev and Atick 1996; \nWechsler et al. 1997; Wiskott et al. 1997] Tracking-enhanced [Edwards et al. 1998; McKenna and Gong 1997, \n1998; Steffens et al. 1998] Multimodal methods Video-and audio-based [Bigun et al. 1998; Choudhury et \nal."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 148
                            }
                        ],
                        "text": "One ex\u00adample is the Probabilistic Decision-Based Neural Network \n(PDBNN) method [Lin et al. 1997] and the other is the evolution pursuit (EP) method [Liu and Wechsler \n2000a]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 144
                            }
                        ],
                        "text": "\u2026eigenfaces Two-class problem with prob. \nmeasure [Moghaddam and Pentland 1997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Applications, H. Wechsler, P. J. Phillips, V. Bruce, F. F. Soulie, \nand T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "1996) [44, 169] Three Linear Discriminant Analysis based algorithms from Michigan State University [56] (Sept."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 348,
                                "start": 344
                            }
                        ],
                        "text": "of the determinant of the between-class scatter matrix of the projected samples to the within-class scatter matrix of the projected samples: J (T ) = jT TSbT j jT TSwT j: (11) Let us denote the optimal projection matrix which maximizes J (T ) by W ; then W can be obtained by solving the generalized eigenvalue problem [65] SbW = SwW W (12) In [56], a face image retrieval system is reported based on discriminant analysis of the eigenfeatures, and in [57], a framework based on LDA for general object recognition is described."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 52
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Applications,H. Wechsler, P. J. \nPhillips, V. Bruce, F. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 22
                            }
                        ],
                        "text": "Like existing methods [56, 58], this method consists of two steps: rst the face image is projected into a face subspace via Principal Component Analysis (PCA), where the subspace dimension is carefully chosen, and then the PCA projection vectors are projected into the LDA to construct a linear classi er in the subspace."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Ap\u00adplications, H. Wechsler, P. J. Phillips, \nV. Bruce, F. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 182
                            }
                        ],
                        "text": "In a recent comprehensive FERET evaluation [3, 4, 5, 6], aimed at evaluating di erent systems using the same, large database containing thousands of images, the systems described in [33, 44, 56, 60, 79], as well as others were evaluated."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10952196,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e28e81e757009d2f76b8674e0da431f5845884a",
            "isKey": true,
            "numCitedBy": 1773,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the automatic selection of features from an image training set using the theories of multidimensional discriminant analysis and the associated optimal linear projection. We demonstrate the effectiveness of these most discriminating features for view-based class retrieval from a large database of widely varying real-world objects presented as \"well-framed\" views, and compare it with that of the principal component analysis."
            },
            "slug": "Using-Discriminant-Eigenfeatures-for-Image-Swets-Weng",
            "title": {
                "fragments": [],
                "text": "Using Discriminant Eigenfeatures for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This paper describes the automatic selection of features from an image training set using the theories of multidimensional discriminant analysis and the associated optimal linear projection, and demonstrates the effectiveness of these most discriminating features for view-based class retrieval from a large database of widely varying real-world objects."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2913552"
                        ],
                        "name": "Baoxin Li",
                        "slug": "Baoxin-Li",
                        "structuredName": {
                            "firstName": "Baoxin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Baoxin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27392909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5db266d0bb1a2f09a3fc3c87e38386d82704455e",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to simultaneous tracking and verification in video data is presented. The approach is based on posterior estimation using sequential Monte Carlo methods. Visual tracking, which is in essence a temporal correspondence problem, is solved through probability density propagation, with the density being defined over a proper state space characterizing the object configuration. Verification is realized through hypothesis testing using the estimated posterior density. In its most basic form, verification can be performed as follows. Given measurement Z and two hypothesis H/sub 1/ and H/sub 0/, we first estimate posterior probabilities P(H/sub 0/|Z) and P(H/sub 1/|Z); and choose the one with the larger posterior probability as the true hypothesis. Applications of the approach are illustrated with experiments devised to evaluated the performance. The idea is first tested on synthetic data, and then experiments with real video sequences are presented."
            },
            "slug": "Simultaneous-tracking-and-verification-via-Li-Chellappa",
            "title": {
                "fragments": [],
                "text": "Simultaneous tracking and verification via sequential posterior estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "An approach to simultaneous tracking and verification in video data is presented based on posterior estimation using sequential Monte Carlo methods, which is first tested on synthetic data, and then experiments with real video sequences are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49168578"
                        ],
                        "name": "J. Phillips",
                        "slug": "J.-Phillips",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Phillips",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144975752"
                        ],
                        "name": "V. Bruce",
                        "slug": "V.-Bruce",
                        "structuredName": {
                            "firstName": "Vicki",
                            "lastName": "Bruce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Bruce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66890955"
                        ],
                        "name": "F. F. Souli\u00e9",
                        "slug": "F.-F.-Souli\u00e9",
                        "structuredName": {
                            "firstName": "Fran\u00e7oise",
                            "lastName": "Souli\u00e9",
                            "middleNames": [
                                "Fogelman"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. F. Souli\u00e9"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 218
                            }
                        ],
                        "text": "This observation has been extended to show that movement helps in the recognition of familiar faces under a range of di erent types of degradations | negated, inverted, or thresholded (shown as black-and-white images) [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "Is face perception the result of wholistic or feature analysis? [15] Both wholistic and feature information are crucial for the perception and recognition of faces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 190
                            }
                        ],
                        "text": "This observation has been extended to show that \nmovement helps in the recognition of familiar faces shown under a range of different types of degradations \nnegated, inverted, or thresholded [Bruce et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 140
                            }
                        ],
                        "text": "These two problems have been documented in many evaluations of FRT systems [4, 181] and in the divided opinions of the psychology community [24, 23, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 52
                            }
                        ],
                        "text": "Movement and face recognition [O Toole et al. 2002; Bruce et al. 1998; Knight and Johnston \n1997]: A recent study [Knight and Johnston 1997] showed that fa\u00admous faces are easier to recognize when \nshown in moving sequences than in still photographs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 13
                            }
                        ],
                        "text": "[Bruce 1988; Bruce \net al. 1998]: Both holistic and feature information are crucial for the percep\u00adtion and recognition of \nfaces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 24
                            }
                        ],
                        "text": "E ect of lighting change[12, 15, 27]: It has long been informally observed that photographic negatives of faces are di cult to recognize."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 29
                            }
                        ],
                        "text": "Movement and face recognition[15, 28]: A recent intriguing study [28] shows that famous faces are easier to recognize when shown in moving sequences than in still photographs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 27
                            }
                        ],
                        "text": "Effect of lighting change [Bruce et al. 1998; Hill \nand Bruce 1996; Johnston et al. 1992]: It has long been informally observed that photographic negatives \nof faces are dif.cult to recognize."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60461382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bfec6ad5ab86f9a7bf96184c2c58950a4d5876a8",
            "isKey": true,
            "numCitedBy": 553,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Face-Recognition:-From-Theory-to-Applications-Phillips-Bruce",
            "title": {
                "fragments": [],
                "text": "Face Recognition: From Theory to Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39664966"
                        ],
                        "name": "C. Liu",
                        "slug": "C.-Liu",
                        "structuredName": {
                            "firstName": "Chengjun",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143979395"
                        ],
                        "name": "H. Wechsler",
                        "slug": "H.-Wechsler",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wechsler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wechsler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 142
                            }
                        ],
                        "text": "\u2026et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and Wechsler 2000a] Feature lines Point-to-line distance based [Li \nand Lu 1999] ICA ICA-based feature analysis [Bartlett et al. 1998] Other\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 148
                            }
                        ],
                        "text": "One ex\u00adample is the Probabilistic Decision-Based Neural Network \n(PDBNN) method [Lin et al. 1997] and the other is the evolution pursuit (EP) method [Liu and Wechsler \n2000a]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 142
                            }
                        ],
                        "text": "Toward \nthat end, EP implements strategies characteristic of ge\u00adnetic algorithms (GAs) for searching the so-called \nenhanced FLD (EFM) approach [Liu and Wechsler 2000b]. space of possible solutions to determine the optimal \nbasis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14252536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc25de199fd6b74c9c3ad67ac64e9ff7f2e435b3",
            "isKey": false,
            "numCitedBy": 268,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces two new coding schemes, probabilistic reasoning models (PRM) and enhanced FLD (Fisher linear discriminant) models (EFM), for indexing and retrieval of large image databases with applications to face recognition. The unifying theme of the new schemes is that of lowering the space dimension (\"data compression\") subject to increased fitness for the discrimination index."
            },
            "slug": "Robust-coding-schemes-for-indexing-and-retrieval-Liu-Wechsler",
            "title": {
                "fragments": [],
                "text": "Robust coding schemes for indexing and retrieval from large face databases"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "Two new coding schemes are introduced, probabilistic reasoning models (PRM) and enhanced FLD (Fisher linear discriminant) models (EFM), for indexing and retrieval of large image databases with applications to face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "Four methods are compared: 1) a correlation-based method, 2) a variant of the linear subspace method suggested in [66], 3) an eigenface method [43, 44], and 4) a Fisher-face method which uses subspace projection prior to LDA projection to avoid the possible singularity in Sw as in [56, 57]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 61
                            }
                        ],
                        "text": "This method is an extension of the 3D linear subspace method [66, 67] and also requires three aligned training images acquired under di erent lighting conditions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 154
                            }
                        ],
                        "text": "3 Class-Based Approaches Under the assumptions of Lambertian surfaces and no shadowing, a 3D linear illumination subspace for a person was constructed in [66, 67, 184, 185] for a xed viewpoint, using three aligned faces/images acquired under di erent lighting conditions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120989821,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "39c1352a5b70ad3c2dbe29f5f0ceebf163b414bd",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 193,
            "paperAbstract": {
                "fragments": [],
                "text": "The report addresses the problem of visual recognition under two sources of variability: geometric and photometric. The geometric deals with the relation between 3D objects and their views under orthographic and perspective projection. The photometric deals with the relation between 3D matte objects and their images under changing illumination conditions. Taken together, an alignment-based method is presented for recognizing objects viewed from arbitrary viewing positions and illuminated by arbitrary settings of light sources."
            },
            "slug": "Geometry-and-Photometry-in-3D-Visual-Recognition-Shashua",
            "title": {
                "fragments": [],
                "text": "Geometry and Photometry in 3D Visual Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721434"
                        ],
                        "name": "W. Martin",
                        "slug": "W.-Martin",
                        "structuredName": {
                            "firstName": "Worthy",
                            "lastName": "Martin",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705627"
                        ],
                        "name": "J. Aggarwal",
                        "slug": "J.-Aggarwal",
                        "structuredName": {
                            "firstName": "Jake",
                            "lastName": "Aggarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aggarwal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 24
                            }
                        ],
                        "text": "We list here only books [86, 87, 106, 107, 108, 109] and review papers [110, 111, 112]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118733844,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "16aa66a78dffa1fb1ab637d1901ae2d57f953142",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Bounding Constraint Propagation for Optical Flow Estimation.- 1.1 Introduction.- 1.2 The Gradient Constraint Equation.- 1.3 Gradient-Based Algorithms.- 1.4 Coping with Smoothness Violations.- 1.4.1 Thresholding for Smoothness.- 1.4.2 Continuous Adaptation to Errors.- 1.5 Results.- 1.6 Discussion.- 2 Image Flow: Fundamentals and Algorithms.- 2.1 Introduction.- 2.1.1 Background.- 2.1.2 Applications for Image Flow.- 2.1.3 Summary.- 2.2 Simple Image Flows.- 2.2.1 Image Flow Equation for Simple Flows.- 2.2.2 Algorithms for Simple Image Flows.- 2.2.3 Summary of Simple Image Flows.- 2.3 Discontinuous Image Flow.- 2.3.1 Surfaces and Projections.- 2.3.2 Image Irradiance Discontinuities.- 2.3.3 Velocity Field Discontinuities.- 2.3.4 Validity of the Image Flow Equation.- 2.3.5 Related Work.- 2.4 Analysis of Discontinuous Image Flows.- 2.4.1 Discontinuities in Continuous Image Functions.- 2.4.2 Sampling of Discontinuous Image Flows.- 2.4.3 Directional Selectivity.- 2.4.4 Summary of Discontinuous Image Flows.- 2.5 Algorithms for Discontinuous Image Flows.- 2.5.1 Background.- 2.5.2 Problem Statement.- 2.5.3 Constraint Line Clustering.- 2.5.4 Summary.- 2.6 Smoothing Discontinuous Image Flows.- 2.6.1 Motion Boundary Detection.- 2.6.2 Velocity Field Smoothing.- 2.6.3 Interleaved Detection and Smoothing.- 2.7 Summary and Conclusions.- 3 A Computational Approach to the Fusion of Stereopsis and Kineopsis.- 3.1 Introduction.- 3.2 Integrating Optical Flow to Stereopsis for Motion.- 3.3 Perception of Rigid Objects in Motion.- 3.4 Examples.- 3.5 Summary.- 4 The Empirical Study of Structure from Motion.- 4.1 Introduction.- 4.2 Viewer-Centered vs. Object-Centered Depth.- 4.2.1 Orthographic Projections of Rotation in Depth.- 4.2.2 Recovery of Structure from Velocity Gradients.- 4.3 The Correspondence Problem.- 4.3.1 Point Configurations.- 4.3.2 Contour Deformation.- 4.3.3 Texture Deformation.- 4.4 Rigidity.- 4.5 Perception of Self Motion.- 4.6 A Theory of Observers.- 4.7 An Empirical Test of Constraints.- 4.8 Summary and Conclusions.- 5 Motion Estimation Using More Than Two Images.- 5.1 Introduction.- 5.2 General Description of the Method.- 5.2.1 Establishing the Equations.- 5.2.2 Simplifying the Equations.- 5.2.3 Solving the Equations.- 5.2.4 Calculating the Motion Parameters.- 5.2.5 Advantages of this Approach.- 5.2.6 Limitations of Our Approach.- 5.3 Results.- 5.3.1 Synthetic Test Data.- 5.3.2 Real Test Data.- 5.4 Comparison with Other Methods.- 5.4.1 Error Analysis.- 5.5 Conclusions.- 6 An Experimental Investigation of Estimation Approaches for Optical Flow Fields.- 6.1 Introduction.- 6.2 Feature Based Estimation.- 6.2.1 The Monotonicity Operator.- 6.2.2 From Feature Positions to Optical Flow Vectors.- 6.2.3 Test Sequence.- 6.2.4 Moving Object Detection.- 6.2.5 Performance Analysis of the Monotonicity Operator.- 6.2.6 Robustness of the Monotonicity Operator Against Parameter Changes.- 6.2.7 Reduction to Two Classes.- 6.3 Analytical Approach for the Estimation of Optical Flow Vector Fields.- 6.3.1 The \"Oriented Smoothness\" Constraint.- 6.3.2 Evaluation at Local Extrema of the Picture Function.- 6.4 Discussion.- 7 The Incremental Rigidity Scheme and Long-Range Motion Correspondence.- 7.1 The Rigidity-Based Recovery of Structure from Motion.- 7.1.1 The Perception of Structure from Motion by Human Observers.- 7.1.2 Computational Studies of the Recovery of Structure from Motion.- 7.1.3 Additional Requirements for the Recovery of Structure from Motion.- 7.1.4 A Hypothesis: Maximizing Rigidity Relative to the Current Internal Model.- 7.2 The Incremental Rigidity Scheme.- 7.2.1 The Basic Scheme.- 7.2.2 Possible Modifications.- 7.2.3 Implementation.- 7.3 Experimental Results.- 7.3.1 Rigid Motion.- 7.3.2 Non-Rigid Motion.- 7.4 Additional Properties of the Incremental Rigidity Scheme.- 7.4.1 Orthographic and Perspective Projections.- 7.4.2 The Effect of the Number of Points.- 7.4.3 On Multiple Objects.- 7.4.4 Convergence to the Local Minimum.- 7.5 Possible Implications to the Long-Range Motion Correspondence Process.- 7.6 Summary.- 8 Some Problems with Correspondence.- 8.1 Introduction.- 8.2 Determining Correspondence.- 8.3 Correspondence in Computer Vision.- 8.3.1 Correspondence in Stereopsis Algorithms.- 8.3.2 Correspondence in Temporal Matching Algorithms.- 8.4 An Experiment on Correspondence.- 8.5 Conclusions.- 9 Recovering Connectivity from Moving Point-Light Displays.- 9.1 Introduction.- 9.2 Motion Information is a Minimal Stimulus Condition for the Perception of Form.- 9.3 Processing Models for Recovering Form from Motion.- 9.4 Do Fixed-Axis Models Predict Human Performance?.- 9.5 Human Implementation of Additional Processing Constraints.- 9.5.1 Centers of Moment.- 9.5.2 Occlusion's Effect on Depth Order and Implicit Form.- 9.5.3 Common Motion as Grouping Factor.- 9.5.4 Proximity.- 9.5.5 Familiarity.- 9.6 Incompatibilities Between Human Performance and Models Seeking Local Rigidity.- 9.6.1 Human Capabilities That Exceed Fixed-Axis Models: The Local Rigidity Assumption.- 9.6.2 Human Performance Limitations.- 9.7 Conclusion.- 10 Algorithms for Motion Estimation Based on Three-Dimensional Correspondences.- 10.1 Introduction.- 10.2 Direct Linear Method.- 10.3 Method Based on Translation Invariants.- 10.4 Axis-Angle Method.- 10.5 The Screw Decomposition Method.- 10.6 Improved Motion Estimation Algorithms.- 10.7 Comparing the Linear and Nonlinear Methods.- 10.8 Simulation Results for Three-Point Methods.- 10.9 Some Recent Related Results.- 11 Towards a Theory of Motion Understanding in Man and Machine.- 11.1 Introduction.- 11.2 The Time Complexity of Visual Perception.- 11.2.1 The Role of Time in Vision.- 11.2.2 The Nature of the Computational Problem.- 11.2.3 Implications.- 11.3 Measurement and Hierarchical Representations in Early Vision.- 11.3.1 What is Measurement?.- 11.3.2 Directional Information and its Measurement.- 11.3.3 Hierarchical Processing.- 11.3.4 Construction of Orientation or Velocity Selective Filters.- 11.4 Biological Research.- 11.5 Machine Research.- Author Index."
            },
            "slug": "Motion-Understanding:-Robot-and-Human-Vision-Martin-Aggarwal",
            "title": {
                "fragments": [],
                "text": "Motion Understanding: Robot and Human Vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706204"
                        ],
                        "name": "I. Kakadiaris",
                        "slug": "I.-Kakadiaris",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Kakadiaris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kakadiaris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711560"
                        ],
                        "name": "Dimitris N. Metaxas",
                        "slug": "Dimitris-N.-Metaxas",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Metaxas",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimitris N. Metaxas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784213"
                        ],
                        "name": "R. Bajcsy",
                        "slug": "R.-Bajcsy",
                        "structuredName": {
                            "firstName": "Ruzena",
                            "lastName": "Bajcsy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bajcsy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 3
                            }
                        ],
                        "text": "In [146, 147] the body is modeled by rigid segments that meet at joints."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1098914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d0a4a2b5333c3cbffdb3cb82062772c5aea9a29",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel, robust, integrated approach to segmentation shape and motion estimation of articulated objects. Initially, we assume the object consists of a single part, and we fit a deformable model to the given data using our physics-based framework. As the object attains new postures, we decide based on certain criteria if and when to replace the initial model with two new models. These criteria are based on the model's state and the given data. We then fit the models to the data using a novel algorithm for assigning forces from the data to the two models, which allows partial overlap between them and determination of joint location. This approach is applied iteratively until all the object's moving parts are identified. Furthermore, we define new global deformations and we demonstrate our technique in a series of experiments, where Kalman filtering is employed to account for noise and occlusion.<<ETX>>"
            },
            "slug": "Active-part-decomposition,-shape-and-motion-of-a-Kakadiaris-Metaxas",
            "title": {
                "fragments": [],
                "text": "Active part-decomposition, shape and motion estimation of articulated objects: a physics-based approach"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A novel, robust, integrated approach to segmentation shape and motion estimation of articulated objects using a novel algorithm for assigning forces from the data to the two models, which allows partial overlap between them and determination of joint location."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144429686"
                        ],
                        "name": "James W. Davis",
                        "slug": "James-W.-Davis",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Davis",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James W. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14441872,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f165b4573c158c2beb9a2af54357232955cf2ae1",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A new view based approach to the representation and recognition of action is presented. The basis of the representation is a motion history image (MHI)-a static image where intensity is a function of the recency of motion in a sequence. We develop a recognition method which uses both binary and scalar valued versions of the MHI as temporal templates to match against stored instances of actions. The method automatically performs temporal segmentation, as invariant to linear changes in speed, and runs in real time on a standard platform. The applications we have begun to develop include simple room monitoring and an interactive game."
            },
            "slug": "Real-time-recognition-of-activity-using-temporal-Bobick-Davis",
            "title": {
                "fragments": [],
                "text": "Real-time recognition of activity using temporal templates"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A recognition method is developed which uses both binary and scalar valued versions of the MHI as temporal templates to match against stored instances of actions to perform temporal segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Third IEEE Workshop on Applications of Computer Vision. WACV'96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 15
                            }
                        ],
                        "text": "More recently, [150] presents a new visual motion estimation technique that is able to accurately recover high-degree-of-freedom articulated human body con gurations in video sequences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2751624,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f6a3dea66b539d75c30fb24ecefe627bbb0c3a9",
            "isKey": false,
            "numCitedBy": 882,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper demonstrates a new visual motion estimation technique that is able to recover high degree-of-freedom articulated human body configurations in complex video sequences. We introduce the use of a novel mathematical technique, the product of exponential maps and twist motions, and its integration into a differential motion estimation. This results in solving simple linear systems, and enables us to recover robustly the kinematic degrees-of-freedom in noise and complex self occluded configurations. We demonstrate this on several image sequences of people doing articulated full body movements, and visualize the results in re-animating an artificial 3D human model. We are also able to recover and re-animate the famous movements of Eadweard Muybridge's motion studies from the last century. To the best of our knowledge, this is the first computer vision based system that is able to process such challenging footage and recover complex motions with such high accuracy."
            },
            "slug": "Tracking-people-with-twists-and-exponential-maps-Bregler-Malik",
            "title": {
                "fragments": [],
                "text": "Tracking people with twists and exponential maps"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This paper demonstrates a new visual motion estimation technique that is able to recover high degree-of-freedom articulated human body configurations in complex video sequences, and is the first computer vision based system able to process such challenging footage and recover complex motions with such high accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151490155"
                        ],
                        "name": "Ken-ichi Tanaka",
                        "slug": "Ken-ichi-Tanaka",
                        "structuredName": {
                            "firstName": "Ken-ichi",
                            "lastName": "Tanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ken-ichi Tanaka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145434530"
                        ],
                        "name": "J. Ohta",
                        "slug": "J.-Ohta",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Ohta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ohta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109665"
                        ],
                        "name": "K. Kyuma",
                        "slug": "K.-Kyuma",
                        "structuredName": {
                            "firstName": "Kazuo",
                            "lastName": "Kyuma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kyuma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1762073,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59c9d35a342ad4e9540d4fa37f7bbaf35913994b",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The appeal of computer games may be enhanced by vision-based user inputs. The high speed and low cost requirements for near-term, mass-market game applications make system design challenging. The response time of the vision interface should be less than a video frame time and the interface should cost less than $50 U.S. We meet these constraints with algorithms tailored to particular hardware. We have developed a special detector, called the artificial retina chip, which allows for fast, on-chip image processing. We describe two algorithms, based on image moments and orientation histograms, which exploit the capabilities of the chip to provide interactive response to the player's hand or body positions at 10 msec frame time and at low-cost. We show several possible game interactions."
            },
            "slug": "Computer-vision-for-computer-games-Freeman-Tanaka",
            "title": {
                "fragments": [],
                "text": "Computer vision for computer games"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Two algorithms are described, based on image moments and orientation histograms, which exploit the capabilities of the chip to provide interactive response to the player's hand or body positions at 10 msec frame time and at low-cost."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187218"
                        ],
                        "name": "A. J. Bell",
                        "slug": "A.-J.-Bell",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Bell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 140
                            }
                        ],
                        "text": "(Courtesy of M. Bartlett, H. Lades, and T. Sejnowski.) \nthat can be viewed as independent image features for a given set of training im\u00adages [Bell and Sejnowski \n1995], and the second is used to .nd image .lters that produce statistically independent out\u00adputs (a \nfactorial code method) [Bell and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 270
                            }
                        ],
                        "text": "\u2026(their supports extend over the entire grid of images), LFA kernels (Figure12) \nK (xi, y) at selected grids xi have local support.10 10These kernels (Figure 12) indexed by grids xi \nare similar to the ICA kernels in the .rst ICA system architecture [Bartlett et al. 1998; Bell and Sejnowski \n1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 84
                            }
                        ],
                        "text": "that can be viewed as independent image features for a given set of training images [Bell and Sejnowski 1995], and the second is used to find image filters that produce statistically independent outputs (a factorial code method) [Bell and Sejnowski 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1701422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d7d0e8c4791700defd4b0df82a26b50055346e0",
            "isKey": false,
            "numCitedBy": 8758,
            "numCiting": 121,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive a new self-organizing learning algorithm that maximizes the information transferred in a network of nonlinear units. The algorithm does not assume any knowledge of the input distributions, and is defined here for the zero-noise limit. Under these conditions, information maximization has extra properties not found in the linear case (Linsker 1989). The nonlinearities in the transfer function are able to pick up higher-order moments of the input distributions and perform something akin to true redundancy reduction between units in the output representation. This enables the network to separate statistically independent components in the inputs: a higher-order generalization of principal components analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to 10 speakers. We also show that a variant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech signal). Finally, we derive dependencies of information transfer on time delays. We suggest that information maximization provides a unifying framework for problems in \"blind\" signal processing."
            },
            "slug": "An-Information-Maximization-Approach-to-Blind-and-Bell-Sejnowski",
            "title": {
                "fragments": [],
                "text": "An Information-Maximization Approach to Blind Separation and Blind Deconvolution"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is suggested that information maximization provides a unifying framework for problems in \"blind\" signal processing and dependencies of information transfer on time delays are derived."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 260
                            }
                        ],
                        "text": "\u2026and A. Pentland.) eigenfaces appear more similar to the standard eigenfaces \nthan the intraper\u00adsonal ones, the intrapersonal eigenfaces represent subtle variations due mostly to \nexpression and lighting, suggesting that they are more critical for identi.ca\u00adtion [Moghaddam and Pentland \n1997]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 198
                            }
                        ],
                        "text": "Most of the systems reviewed here focus \non the sub\u00adtask of recognition, but others also in\u00adclude automatic face detection and feature extraction, \nmaking them fully automatic systems [Lin et al. 1997; Moghaddam and Pentland 1997; Wiskott et al. 1997]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [33], the eigenface method based on simple subspace-restricted norms is extended to use a probabilistic measure of similarity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 142
                            }
                        ],
                        "text": "We have observed that the multiclass face recognition problem can be converted into a two-class \ndetection problem by using image differences [Moghaddam and Pentland 1997]; and the face de\u00adtection problem \ncan be converted into a multiclass recognition problem by us\u00ading additional nonface clusters\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 154
                            }
                        ],
                        "text": "The neural network method based on Elastic Bunch Graph Matching [79], the statistical method based on subspace LDA [60], and the probabilistic PCA method [33] were adjudged to be among the top three, with each method showing di erent levels of performance on di erent subsets of sequestered images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 123
                            }
                        ],
                        "text": "Many \nmethods re\u00adviewed in Section 3 belong to this category: eigenfaces [Turk and Pentland 1991], probabilistic \neigenfaces [Moghaddam and Pentland 1997], the EBGM method [Okada et al. 1998; Wiskott et al. 1997], and \nthe PDBNN method [Lin et al. 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 123
                            }
                        ],
                        "text": "The EBGM sys\u00adtem [Wiskott et al. 1997], the subspace \nLDA system [Zhao et al. 1998], and the probabilistic eigenface system [Moghad\u00addam and Pentland 1997] \nwere judged to be among the top three, with each method showing different levels of performance on different \nsubsets of sequestered images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 149
                            }
                        ],
                        "text": "\u2026of Video-Based \nFace Recognition Techniques Approach Representative work Still-image methods Basic methods [Turk and \nPentland 1991; Lin et al. 1997; Moghaddam and Pentland 1997; Okada et al. 1998; Penev and Atick 1996; \nWechsler et al. 1997; Wiskott et al. 1997] Tracking-enhanced [Edwards et al.\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 107
                            }
                        ],
                        "text": "Comparison of dual eigenfaces \nand stan\u00addard eigenfaces: (a) intrapersonal, (b) extraper\u00adsonal, (c) standard [Moghaddam and Pentland \n1997]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 173
                            }
                        ],
                        "text": "\u20262001; Swets and Weng 1996b; Zhao \net al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA) [Fisher 1938]; Bayesian methods, \nwhich use a probabilistic distance metric [Moghaddam and Pentland 1997]; and SVM methods, which use a \nsupport vector machine as the classi.er [Phillips 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 143
                            }
                        ],
                        "text": "\u2026of PCA [Craw and Cameron 1996; \nKirby and Sirovich 1990; Turk and Pentland 1991] Probabilistic eigenfaces Two-class problem with prob. \nmeasure [Moghaddam and Pentland 1997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 39
                            }
                        ],
                        "text": "For technical details, please refer to [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 179
                            }
                        ],
                        "text": "Using a probabilistic measure \nof sim\u00adilarity, instead of the simple Euclidean distance used with eigenfaces [Turk and Pentland 1991], \nthe standard eigenface approach was extended [Moghaddam and Pentland 1997] to a Bayesian approach."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 182
                            }
                        ],
                        "text": "In a recent comprehensive FERET evaluation [3, 4, 5, 6], aimed at evaluating di erent systems using the same, large database containing thousands of images, the systems described in [33, 44, 56, 60, 79], as well as others were evaluated."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 483975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b312560b79929540734067e58de46966b96130",
            "isKey": true,
            "numCitedBy": 1684,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for unimodal distributions) and a mixture-of-Gaussians model (for multimodal distributions). Those probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition and coding. Our learning technique is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects, such as hands."
            },
            "slug": "Probabilistic-Visual-Learning-for-Object-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic Visual Learning for Object Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An unsupervised technique for visual learning is presented, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143942359"
                        ],
                        "name": "M. Rosenblum",
                        "slug": "M.-Rosenblum",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Rosenblum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rosenblum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069324532"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 145637328,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b82984419868beff9512ddf4e1ec314c44174df7",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "A radial basis function network architecture is developed that learns the correlation of facial feature motion patterns and human emotions. We describe a hierarchical approach which at the highest level identifies emotions, at the mid level determines motion of facial features, and at the low level recovers motion directions. Individual emotion networks were trained to recognize the 'smile' and 'surprise' emotions. Each emotion network was trained by viewing a set of sequences of one emotion for many subjects. The trained neural network was then tested for retention, extrapolation and rejection ability. Success rates were about 88% for retention, 73% for extrapolation, and 79% for rejection.<<ETX>>"
            },
            "slug": "Human-emotion-recognition-from-motion-using-a-basis-Rosenblum-Yacoob",
            "title": {
                "fragments": [],
                "text": "Human emotion recognition from motion using a radial basis function network architecture"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7692238"
                        ],
                        "name": "F. Galton",
                        "slug": "F.-Galton",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Galton",
                            "middleNames": [
                                "Sir"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Galton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4128778,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "39256e057a9ddb729b4b073125c872c44be2290d",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "I. IT is strange that we should not have acquired more power of describing form and personal features than we actually possess. For my own part I have frequently chafed under the sense of inability to verbally explain hereditary resemblances and types of features, and to describe irregular outlines of many different kinds, which I will not now particularize. At last I tried to relieve myself as far as might be from this embarrasment, and took considerable trouble, and made many experiments. The net result is that while there appear to be many ways of approximately effecting what is wanted, it is difficult as yet to select the best of them with enough assurance to justify a plunge into a rather serious undertaking. According to the French proverb, the better has thus far proved an enemy to the passably good, so I cannot go much into detail at present, but will chiefly dwell on general principles."
            },
            "slug": "Personal-Identification-and-Description-Galton",
            "title": {
                "fragments": [],
                "text": "Personal Identification and Description"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1888
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49555086"
                        ],
                        "name": "L. Sirovich",
                        "slug": "L.-Sirovich",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Sirovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sirovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053520352"
                        ],
                        "name": "M. Kirby",
                        "slug": "M.-Kirby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kirby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kirby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 122
                            }
                        ],
                        "text": "Starting from the successful low\u00addimensional \nreconstruction of faces using KL or PCA projections [Kirby and Sirovich 1990; Sirovich and Kirby 1987], \neigenpictures have been one of the major driving forces behind face representa\u00adtion, detection, and recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 156
                            }
                        ],
                        "text": "One good example is the successful use of the truncated PCA expansion to approximate the frontal face \nimages in a linear sub\u00adspace [Kirby and Sirovich 1990; Sirovich and Kirby 1987]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 103
                            }
                        ],
                        "text": "There has been renewed interest in the use of the Karhunen-Loeve (KL) expansion for the representation [42, 43] and recognition [44, 45] of faces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 106
                            }
                        ],
                        "text": "One of the most widely used repre\u00adsentations of the face region is eigen\u00adpictures [Kirby and \nSirovich 1990; Sirovich and Kirby 1987], which are based on principal component analy\u00adsis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[42] considered the problem of KL representation of cropped face images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 982857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a62d0cca2fabf1d6f6ee15e4c14cef415b657d1",
            "isKey": true,
            "numCitedBy": 2592,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is presented for the representation of (pictures of) faces. Within a specified framework the representation is ideal. This results in the characterization of a face, to within an error bound, by a relatively low-dimensional vector. The method is illustrated in detail by the use of an ensemble of pictures taken for this purpose."
            },
            "slug": "Low-dimensional-procedure-for-the-characterization-Sirovich-Kirby",
            "title": {
                "fragments": [],
                "text": "Low-dimensional procedure for the characterization of human faces."
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A method is presented for the representation of faces that results in the characterization of a face, to within an error bound, by a relatively low-dimensional vector."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 124
                            }
                        ],
                        "text": "Recently, a general method of ap\u00adproximating Lambertian re.ectance us\u00ading second-order spherical harmonics \nhas been reported [Basri and Jacobs 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2891906,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "66e6a411a7342203ebbc22fbe9a3740b744d7cbc",
            "isKey": false,
            "numCitedBy": 858,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We prove that the set of all reflectance functions (the mapping from surface normals to intensities) produced by Lambertian objects under distant, isotropic lighting lies close to a 9D linear subspace. This implies that the images of a convex Lambertian object obtained under a wide variety of lighting conditions can be approximated accurately with a low-dimensional linear subspace, explaining prior empirical results. We also provide a simple analytic characterization of this linear space. We obtain these results by representing lighting using spherical harmonics and describing the effects of Lambertian materials as the analog of a convolution. These results allow us to construct algorithms for object recognition based on linear methods as well as algorithms that use convex optimization to enforce non-negative lighting functions."
            },
            "slug": "Lambertian-reflectance-and-linear-subspaces-Basri-Jacobs",
            "title": {
                "fragments": [],
                "text": "Lambertian reflectance and linear subspaces"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "It is proved that the set of all reflectance functions (the mapping from surface normals to intensities) produced by Lambertian objects under distant, isotropic lighting lies close to a 9D linear subspace, implying that the images of a convex Lambertian object obtained under a wide variety of lighting conditions can be approximated accurately with a low-dimensional linear sub space."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750924"
                        ],
                        "name": "Demetri Terzopoulos",
                        "slug": "Demetri-Terzopoulos",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Terzopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Demetri Terzopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398261"
                        ],
                        "name": "K. Waters",
                        "slug": "K.-Waters",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Waters",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Waters"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 160
                            }
                        ],
                        "text": "Feature boundary tracking attempts \nto track and accurately delineate the shape of the facial feature, for example, to track the contours \nof the lips and mouth [Terzopoulos and Waters 1993]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 34
                            }
                        ],
                        "text": "1993] and facial feature tracking [Terzopoulos and Waters 1993; Yuille and Hallinan 1992]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 118
                            }
                        ],
                        "text": "Early efforts focused on the .rst two problems: head \ntracking [Azarbayejani et al. 1993] and facial feature track\u00ading [Terzopoulos and Waters 1993; Yuille \nand Hallinan 1992]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 159
                            }
                        ],
                        "text": "Feature boundary tracking attempts to track and accurately delineate the shape of the facial feature, for example, to track the contours of the lips and mouth [Terzopoulos and Waters 1993]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15057830,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f77296f889b56d871b9ba9408338dbfd9a0cdeb3",
            "isKey": true,
            "numCitedBy": 614,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to the analysis of dynamic facial images for the purposes of estimating and resynthesizing dynamic facial expressions is presented. The approach exploits a sophisticated generative model of the human face originally developed for realistic facial animation. The face model which may be simulated and rendered at interactive rates on a graphics workstation, incorporates a physics-based synthetic facial tissue and a set of anatomically motivated facial muscle actuators. The estimation of dynamical facial muscle contractions from video sequences of expressive human faces is considered. An estimation technique that uses deformable contour models (snakes) to track the nonrigid motions of facial features in video images is developed. The technique estimates muscle actuator controls with sufficient accuracy to permit the face model to resynthesize transient expressions. >"
            },
            "slug": "Analysis-and-Synthesis-of-Facial-Image-Sequences-Terzopoulos-Waters",
            "title": {
                "fragments": [],
                "text": "Analysis and Synthesis of Facial Image Sequences Using Physical and Anatomical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An estimation technique that uses deformable contour models (snakes) to track the nonrigid motions of facial features in video images is developed and estimates muscle actuator controls with sufficient accuracy to permit the face model to resynthesize transient expressions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122368479"
                        ],
                        "name": "Ming-Chao Chiang",
                        "slug": "Ming-Chao-Chiang",
                        "structuredName": {
                            "firstName": "Ming-Chao",
                            "lastName": "Chiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Chao Chiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32163276"
                        ],
                        "name": "T. Boult",
                        "slug": "T.-Boult",
                        "structuredName": {
                            "firstName": "Terrance",
                            "lastName": "Boult",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Boult"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 95
                            }
                        ],
                        "text": "One possible way to improve the quality of face images is to apply super-resolution techniques [99, 100, 101, 102]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6228966,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "8fddaebe477f6a41cb4387b98f8e433dc7aed260",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Until now, all super-resolution algorithms have presumed that the images were taken under the same illumination conditions. This paper introduces a new approach to super-resolution, based on edge models and a local blur estimate, which circumvents these difficulties. The paper presents the theory and the experimental results using the new approach."
            },
            "slug": "Local-blur-estimation-and-super-resolution-Chiang-Boult",
            "title": {
                "fragments": [],
                "text": "Local blur estimation and super-resolution"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A new approach to super-resolution, based on edge models and a local blur estimate, which circumvents these difficulties by assuming that the images were taken under the same illumination conditions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760976"
                        ],
                        "name": "P. McLauchlan",
                        "slug": "P.-McLauchlan",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "McLauchlan",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. McLauchlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "91799708"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47139824"
                        ],
                        "name": "A. Fitzgibbon",
                        "slug": "A.-Fitzgibbon",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Fitzgibbon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fitzgibbon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 66
                            }
                        ],
                        "text": "To overcome the difficulty of feature tracking, bundle adjustment [Triggs et al. 2000] can be used to obtain better and more robust results."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1354186,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1cf6c415f598273ff4b3c03a1597e30402800a99",
            "isKey": false,
            "numCitedBy": 3988,
            "numCiting": 212,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is a survey of the theory and methods of photogrammetric bundle adjustment, aimed at potential implementors in the computer vision community. Bundle adjustment is the problem of refining a visual reconstruction to produce jointly optimal structure and viewing parameter estimates. Topics covered include: the choice of cost function and robustness; numerical optimization including sparse Newton methods, linearly convergent approximations, updating and recursive methods; gauge (datum) invariance; and quality control. The theory is developed for general robust cost functions rather than restricting attention to traditional nonlinear least squares."
            },
            "slug": "Bundle-Adjustment-A-Modern-Synthesis-Triggs-McLauchlan",
            "title": {
                "fragments": [],
                "text": "Bundle Adjustment - A Modern Synthesis"
            },
            "venue": {
                "fragments": [],
                "text": "Workshop on Vision Algorithms"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145271456"
                        ],
                        "name": "A. Azarbayejani",
                        "slug": "A.-Azarbayejani",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Azarbayejani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Azarbayejani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144152544"
                        ],
                        "name": "B. Horowitz",
                        "slug": "B.-Horowitz",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Horowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 63
                            }
                        ],
                        "text": "Early efforts focused on the .rst two problems: head \ntracking [Azarbayejani et al. 1993] and facial feature track\u00ading [Terzopoulos and Waters 1993; Yuille \nand Hallinan 1992]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29709046,
            "fieldsOfStudy": [
                "Engineering",
                "Physics"
            ],
            "id": "a6dbca57a75e7104b421f5bb38858357299d93d5",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A recursive estimation technique for recovering the 3-D motion and pointwise structure of an object is presented. It is based on the use of relative orientation constraints in a local coordinate frame. By carefully formulating the problem to propagate all constraints and to use the minimal number of parameters, an estimator is obtained which is remarkably accurate, stable, and fast-conveying. Numerous experiments using both real and synthetic data demonstrate structure recovery with a typical error of 1.5% and typical motion recovery errors of 1% in translation and 2/spl deg/ in rotation.<<ETX>>"
            },
            "slug": "Recursive-estimation-of-structure-and-motion-using-Azarbayejani-Horowitz",
            "title": {
                "fragments": [],
                "text": "Recursive estimation of structure and motion using relative orientation constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A recursive estimation technique for recovering the 3-D motion and pointwise structure of an object is presented which is remarkably accurate, stable, and fast-conveying."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1327952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce8008cce8e8b8c40d4d3c5c667ecf9cbeac9fb1",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 128,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent neurological studies indicate that the role of emotion in human cognition is essentiall emotions are not a luxury. Instead, emotions play a critical role in rational decision-making, in perception, in human interaction, and in human intelligence. These facts, combined with abilities computers are acquiring in expressing and recognizing aaect, open new areas for research. This paper deenes key issues in \\aaective computing,\" computing that relates to, arises from, or deliberately innuences emotions. New models are suggested for computer recognition of human emotion , and both theoretical and practical applications are described for learning, human-computer interaction , perceptual information retrieval, creative a r t s and entertainment, human health, and machine intelligence. Signiicant potential advances in emotion and cognition theory hinge on the development of af-fective computing, especially in the form of wearable computers. This paper establishes challenges and future directions for this emerging eld. Nothing in life is to be feared. It is only to be understood. { Marie Curie Emotions have a stigma in sciencee they are believed to be inherently non-scientiic. Scientiic principles are derived from rational thought, logical arguments, testable hypotheses, and repeatable experiments. There is room alongside science for \\non-interfering\" emotions such as those involved in curiosity, frustration, and the pleasure of discovery. In fact, much s c i-entiic research funded by defense budgets has been essentially prompted by fear. Nonetheless, emotions are generally regarded as wreaking havoc on reasoning. Although emotions pervade science, their role has been marginalized. Why bring emotion or aaect into any of the deliberate tools of science? Moreover, shouldn't emotion be completely avoided when considering properties to associate with computers? After all, computers control signiicant parts of our lives { the phone system, the stock m a r k et, nuclear power plants, airplane ights, and more. Who wants a computer to be able to \\feel angry\" at them? To feel contempt for any living thing? In this paper I will set forth key issues in what I call \\af-fective computing,\" computing that relates to, arises from, or deliberately innuences emotions. I will elaborate further on this deenition and its implications below. The topic of emotion is a diicult one to treat scientiically, but that is precisely what needs to be done. In this paper I will illustrate ways in which aaective computing can break new ground in the scientiic study of emotions. I will suggest computational models for aaect \u2026"
            },
            "slug": "Aaective-Computing-Picard",
            "title": {
                "fragments": [],
                "text": "Aaective Computing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Key issues in what is called \"af-fective computing,\" computing that relates to, arises from, or deliberately innuences emotions, are set forth and new models are suggested for computer recognition of human emotion."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712839"
                        ],
                        "name": "K. Aizawa",
                        "slug": "K.-Aizawa",
                        "structuredName": {
                            "firstName": "Kiyoharu",
                            "lastName": "Aizawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Aizawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2320082"
                        ],
                        "name": "C. Choi",
                        "slug": "C.-Choi",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Choi",
                            "middleNames": [
                                "Seok"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698996"
                        ],
                        "name": "H. Harashima",
                        "slug": "H.-Harashima",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Harashima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Harashima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750392"
                        ],
                        "name": "T. Huang",
                        "slug": "T.-Huang",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61329376,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a20e989c4d427f205646167e6289a91bc0ca602",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Model-based coding is a new framework for image compression [1, 11, 15, 33]. In contrast to the conventional waveform coding schemes which encode and reproduce waveforms of image signals, model-based coding makes use of 3-D properties of the objects in the scene, and analyzes and transmits parameters for the objects. Because the encoder transmits only the required parameters, extremely low bit rate image transmission can be potentially realized."
            },
            "slug": "Human-Facial-Motion-Analysis-and-Synthesis-with-to-Aizawa-Choi",
            "title": {
                "fragments": [],
                "text": "Human Facial Motion Analysis and Synthesis with Application to Model-Based Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Model-based coding makes use of 3-D properties of the objects in the scene, and analyzes and transmits parameters for the objects, and because the encoder transmits only the required parameters, extremely low bit rate image transmission can be potentially realized."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739786"
                        ],
                        "name": "B. Girod",
                        "slug": "B.-Girod",
                        "structuredName": {
                            "firstName": "Bernd",
                            "lastName": "Girod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Girod"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59797208,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "dbb8571c4ffb60599248e5bececcb6fd1319a0ca",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Read more and get great! That's what the book enPDFd motion analysis and image sequence processing will give for every reader to read this book. This is an on-line book provided in this website. Even this book becomes a choice of someone to read, many in the world also loves it so much. As what we talk, when you read more every page of this motion analysis and image sequence processing, what you will obtain is something great."
            },
            "slug": "Motion-Analysis-and-Image-Sequence-Processing-Girod",
            "title": {
                "fragments": [],
                "text": "Motion Analysis and Image Sequence Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "When you read more every page of this motion analysis and image sequence processing, what you will obtain is something great."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2099763"
                        ],
                        "name": "J. Healey",
                        "slug": "J.-Healey",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Healey",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Healey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6160829"
                        ],
                        "name": "J. Seger",
                        "slug": "J.-Seger",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Seger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Seger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054314891"
                        ],
                        "name": "R. Picard",
                        "slug": "R.-Picard",
                        "structuredName": {
                            "firstName": "Roz",
                            "lastName": "Picard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Picard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "Another example is the detection of a driver's tiredness [98] by monitoring the driver's facial expressions and head movements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16741029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4000b2406f8a8ef01afc054318b33b79d9e4512",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A system for quantifying the physiological features of emotional stress is being developed for use during a driving task. Two prototypes, using sensors that measure the driver's skin conductance, respiration, muscle activity, and heart activity are presented. The first system allows sampling rates of 200 Hz on two fast channels and 20 Hz on six additional channels. It uses a wearable computer to do real-time processing on the signals and has an attached digital camera which was used to capture images of the driver's facial expression once every minute. The second system uses a car-based computer that allows a sampling rate of 1984 samples per second on eight channels. This system uses multiple video cameras to continuously capture the driver's facial expression and road conditions. The data is then synchronized with the physiological signals using a video quad-splitter. The methods for extracting physiological features in the driving environment are discussed, including measurement of the skin conductance orienting response, muscle activity, pulse, and respiration patterns. Preliminary studies show how using multiple modalities of sensors can help discriminate reactions to driving events and how individual's response to similar driving conditions can vary from day to day."
            },
            "slug": "Quantifying-driver-stress:-developing-a-system-for-Healey-Seger",
            "title": {
                "fragments": [],
                "text": "Quantifying driver stress: developing a system for collecting and processing bio-metric signals in natural situations."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Preliminary studies show how using multiple modalities of sensors can help discriminate reactions to driving events and how individual's response to similar driving conditions can vary from day to day."
            },
            "venue": {
                "fragments": [],
                "text": "Biomedical sciences instrumentation"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 175
                            }
                        ],
                        "text": "The tracking problem has been formulated as a Bayesian inference \nprob\u00adlem and sequential importance sampling (SIS) [Liu and Chen 1998] (one form of SIS is called Condensation \n[Isard and Blake 1996] in the computer vision literature) proposed as an empirical solution to the inference \nproblem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 103
                            }
                        ],
                        "text": "The approach is based on posterior probability density estimation using sequential Monte Carlo methods [162, 163]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8369379,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c5a0951cea300222834497c8e12ac2be99cd11e",
            "isKey": false,
            "numCitedBy": 1435,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of tracking curves in dense visual clutter is a challenging one. Trackers based on Kalman filters are of limited use; because they are based on Gaussian densities which are unimodal, they cannot represent simultaneous alternative hypotheses. Extensions to the Kalman filter to handle multiple data associations work satisfactorily in the simple case of point targets, but do not extend naturally to continuous curves. A new, stochastic algorithm is proposed here, the Condensation algorithm \u2014 Conditional Density Propagation over time. It uses \u2018factored sampling\u2019, a method previously applied to interpretation of static images, in which the distribution of possible interpretations is represented by a randomly generated set of representatives. The Condensation algorithm combines factored sampling with learned dynamical models to propagate an entire probability distribution for object position and shape, over time. The result is highly robust tracking of agile motion in clutter, markedly superior to what has previously been attainable from Kalman filtering. Notwithstanding the use of stochastic methods, the algorithm runs in near real-time."
            },
            "slug": "Contour-Tracking-by-Stochastic-Propagation-of-Isard-Blake",
            "title": {
                "fragments": [],
                "text": "Contour Tracking by Stochastic Propagation of Conditional Density"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The Condensation algorithm combines factored sampling with learned dynamical models to propagate an entire probability distribution for object position and shape, over time, and is markedly superior to what has previously been attainable from Kalman filtering."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2417905"
                        ],
                        "name": "H. Ellis",
                        "slug": "H.-Ellis",
                        "structuredName": {
                            "firstName": "Hadyn",
                            "lastName": "Ellis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ellis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 101
                            }
                        ],
                        "text": "The issues that are of potential interest to designers are: Is face recognition a dedicated process? [13, 14]: Evidence for the existence of a dedicated face processing system comes from three sources [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 93
                            }
                        ],
                        "text": "Evidence for the existence of a dedicated face \nprocess\u00ading system comes from several sources [Ellis 1986]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 160
                            }
                        ],
                        "text": "\u2026with issues such as \nwhether face perception is a dedicated process (this issue is still be\u00ading debated in the psychology \ncommunity [Biederman and Kalocsai 1998; Ellis 1986; Gauthier et al. 1999; Gauthier and Logo\u00adthetis 2000]) \nand whether it is done holis\u00adtically or by local feature analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 30
                            }
                        ],
                        "text": "[Biederman and Kalocsai 1998; Ellis 1986; Gauthier et \nal."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60855458,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "1e5463c34a4c799140ee6e965225ac7daadc2c8e",
            "isKey": true,
            "numCitedBy": 57,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "These proceedings of the first international conference devoted entirely to matters concerning the identification of faces and the interpretation of facial expressions are timely: interest in the human face as a stimulus object in psychological research has grown quite dramatically in recent years as figure 1 clearly illustrates."
            },
            "slug": "Introduction-to-Aspects-of-Face-Processing:-Ten-in-Ellis",
            "title": {
                "fragments": [],
                "text": "Introduction to Aspects of Face Processing: Ten Questions in Need of Answers"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "These proceedings of the first international conference devoted entirely to matters concerning the identification of faces and the interpretation of facial expressions are timely."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750924"
                        ],
                        "name": "Demetri Terzopoulos",
                        "slug": "Demetri-Terzopoulos",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Terzopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Demetri Terzopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809905"
                        ],
                        "name": "A. Witkin",
                        "slug": "A.-Witkin",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Witkin",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Witkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143602141"
                        ],
                        "name": "M. Kass",
                        "slug": "M.-Kass",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kass"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 101
                            }
                        ],
                        "text": "Non-rigid Motion Analysis A nal area of relevance to FRT is the motion analysis of non-rigid objects [117, 118, 119, 120]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 46
                            }
                        ],
                        "text": ", to track the contours of the lips and mouth [117, 122]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41036513,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0cca1fa6cf2ac8d9e43d5d7d69f96fc178000c2a",
            "isKey": false,
            "numCitedBy": 937,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Constraints-on-Deformable-Models:-Recovering-3D-and-Terzopoulos-Witkin",
            "title": {
                "fragments": [],
                "text": "Constraints on Deformable Models: Recovering 3D Shape and Nonrigid Motion"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053520352"
                        ],
                        "name": "M. Kirby",
                        "slug": "M.-Kirby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kirby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kirby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49555086"
                        ],
                        "name": "L. Sirovich",
                        "slug": "L.-Sirovich",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Sirovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sirovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 143
                            }
                        ],
                        "text": "\u2026Approach Representative work Holistic \nmethods Principal-component analysis (PCA) Eigenfaces Direct application of PCA [Craw and Cameron 1996; \nKirby and Sirovich 1990; Turk and Pentland 1991] Probabilistic eigenfaces Two-class problem with prob. \nmeasure [Moghaddam and Pentland 1997]\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 130
                            }
                        ],
                        "text": "One good example is the successful use of the truncated PCA expansion to approximate the frontal face images in a linear subspace [Kirby and Sirovich 1990; Sirovich and Kirby 1987]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 55
                            }
                        ],
                        "text": "Among appearance-based holistic approaches, eigenfaces [Kirby and Sirovich 1990; Turk and Pentland 1991] and Fisherfaces [Belhumeur et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 56
                            }
                        ],
                        "text": "Among appearance-based holistic approaches, \neigenfaces [Kirby and Sirovich 1990; Turk and Pentland 1991] and Fisher\u00adfaces [Belhumeur et al. 1997; \nEtemad and Chellappa 1997; Zhao et al. 1998] have proved to be effective in experiments with large databases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 96
                            }
                        ],
                        "text": "Starting from the successful lowdimensional reconstruction of faces using KL or PCA projections [Kirby and Sirovich 1990; Sirovich and Kirby 1987], eigenpictures have been one of the major driving forces behind face representation, detection, and recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 174
                            }
                        ],
                        "text": "For better approximation of face images outside the training set, using an extended training set that adds mirror-imaged faces was shown to achieve lower approximation error [Kirby and Sirovich 1990]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 97
                            }
                        ],
                        "text": "Starting from the successful low\u00addimensional \nreconstruction of faces using KL or PCA projections [Kirby and Sirovich 1990; Sirovich and Kirby 1987], \neigenpictures have been one of the major driving forces behind face representa\u00adtion, detection, and recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 175
                            }
                        ],
                        "text": "For better approximation of face images outside the training set, using an extended training set \nthat adds mirror-imaged faces was shown to achieve lower approxima\u00adtion error [Kirby and Sirovich 1990]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 131
                            }
                        ],
                        "text": "One good example is the successful use of the truncated PCA expansion to approximate the frontal face \nimages in a linear sub\u00adspace [Kirby and Sirovich 1990; Sirovich and Kirby 1987]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 81
                            }
                        ],
                        "text": "One of the most widely used repre\u00adsentations of the face region is eigen\u00adpictures [Kirby and \nSirovich 1990; Sirovich and Kirby 1987], which are based on principal component analy\u00adsis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 80
                            }
                        ],
                        "text": "One of the most widely used representations of the face region is eigenpictures [Kirby and Sirovich 1990; Sirovich and Kirby 1987], which are based on principal component analysis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 570648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66d75a5fe9e1b6511c5135d68e9ce8c0da5a7374",
            "isKey": true,
            "numCitedBy": 2853,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion. This results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix, without increasing the complexity of the calculation. The resulting approximation of faces projected from outside of the data set onto this optimal basis is improved on average. >"
            },
            "slug": "Application-of-the-Karhunen-Loeve-Procedure-for-the-Kirby-Sirovich",
            "title": {
                "fragments": [],
                "text": "Application of the Karhunen-Loeve Procedure for the Characterization of Human Faces"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion, which results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32913617"
                        ],
                        "name": "M. L\u00e9vesque",
                        "slug": "M.-L\u00e9vesque",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "L\u00e9vesque",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. L\u00e9vesque"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 215711504,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "0842bc47d833df488aa391aa2b8854013f9da195",
            "isKey": false,
            "numCitedBy": 1766,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "discusses the characterization of the products of these newly isolated oncogenes. Each of these reviews concludes by examining the directions for future experiments; the subsequent article then often describes that research. The series of four articles permits the reader to get a sense of the length of time, the number of researchers, and the huge effort necessary to make significant advances. The book is written at a level which can be understood by anyone with some background in biology. It assumes very little, and most articles are self-explanatory. As Friedberg is careful to point out, this book is not meant to cover all of cancer biology rigorously or comprehensively, but instead to convey several important concepts. As such, it is an excellent, easily read volume for anyone, especially students, wishing to learn about cancer biology; it would be very useful as a fast overview of the field which will make subsequent reading of more detailed articles much easier. So well written and easy to read that it is both enjoyable and informative, this book is highly recommended to anyone interested in learning about cancer biology."
            },
            "slug": "Perception-L\u00e9vesque",
            "title": {
                "fragments": [],
                "text": "Perception"
            },
            "venue": {
                "fragments": [],
                "text": "The Yale Journal of Biology and Medicine"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144658464"
                        ],
                        "name": "V. Pavlovic",
                        "slug": "V.-Pavlovic",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Pavlovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Pavlovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49664054"
                        ],
                        "name": "Rajeev Sharma",
                        "slug": "Rajeev-Sharma",
                        "structuredName": {
                            "firstName": "Rajeev",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rajeev Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2136462,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5773f91e688011c6960b4884e187a7e8c8a565f3",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years there has been tremendous progress in 3-D, immersive display and virtual reality (VR) technologies. Scientific visualization af data is one of many applications that has benefited from this progress. To fully exploit the potential of these applications in the new environment there is a need for \"natural\" interfaces that allow the manipulation of such displays without burdensome attachments. This paper describes the use of visual hand gesture analysis enhanced with speech recognition for developing a bimodal gesture/speech interface for controlling a 3-D display. The interface augments an existing application, VMD, which is a VR visual computing environment for molecular biologists. The free hand gestures are used for manipulating the 3-D graphical display together with a set of speech commands. We concentrate on the visual gesture analysis techniques used in developing this interface. The dual modality of gesture/speech is found to greatly aid the interaction capability."
            },
            "slug": "Gestural-interface-to-a-visual-computing-for-Pavlovic-Sharma",
            "title": {
                "fragments": [],
                "text": "Gestural interface to a visual computing environment for molecular biologists"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The use of visual hand gesture analysis enhanced with speech recognition for developing a bimodal gesture/speech interface for controlling a 3-D display augments an existing application, VMD, which is a VR visual computing environment for molecular biologists."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14497446,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8dbb7a71d67fbc1b8afa16aec6b34e788a74050c",
            "isKey": false,
            "numCitedBy": 766,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a probabilistic decomposition of human dynamics at multiple abstractions, and shows how to propagate hypotheses across space, time, and abstraction levels. Recognition in this framework is the succession of very general low level grouping mechanisms to increased specific and learned model based grouping techniques at higher levels. Hard decision thresholds are delayed and resolved by higher level statistical models and temporal context. Low-level primitives are areas of coherent motion found by EM clustering, mid-level categories are simple movements represented by dynamical systems, and high-level complex gestures are represented by Hidden Markov Models as successive phases of ample movements. We show how such a representation can be learned from training data, and apply It to the example of human gait recognition."
            },
            "slug": "Learning-and-recognizing-human-dynamics-in-video-Bregler",
            "title": {
                "fragments": [],
                "text": "Learning and recognizing human dynamics in video sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A probabilistic decomposition of human dynamics at multiple abstractions is described, and how to propagate hypotheses across space, time, and abstraction levels is shown."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40442568"
                        ],
                        "name": "A. Ginsburg",
                        "slug": "A.-Ginsburg",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Ginsburg",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ginsburg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 40
                            }
                        ],
                        "text": "\u2014The role of spatial frequency analysis [Ginsburg 1978; Harmon 1973; Sergent 1986]: Earlier studies [Ginsburg 1978; Harmon 1973] concluded that information in low spatial frequency bands plays a dominant role in face recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 40
                            }
                        ],
                        "text": "The role \nof spatial frequency analysis [Ginsburg 1978; Harmon 1973; Sergent 1986]: Earlier studies [Ginsburg 1978; \nHarmon 1973] concluded that informa\u00adtion in low spatial frequency bands plays a dominant role in face \nrecog\u00adnition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61042990,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "a68101b8122101e7db6b20dcf5c89df85393f38a",
            "isKey": false,
            "numCitedBy": 205,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Visual perception was investigated using spatial filters that are constrained by biological data. This report has four major parts: (1) a theoretical background to Fourier analysis; (2) a review of the literature relating to the spatial filtering characteristics of mammalian visual systems; (3) visual information processing in terms of spatial filtering; (4) the relating of contrast sensitivity to the identification of complex objects. The common denominator to all the investigations is spatial filtering. The major goal of the dissertation was the attempt to explain certain aspects of visual perception using a single concept: filtering. (Author)"
            },
            "slug": "Visual-Information-Processing-Based-on-Spatial-by-Ginsburg",
            "title": {
                "fragments": [],
                "text": "Visual Information Processing Based on Spatial Filters Constrained by Biological Data."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The major goal of the dissertation was the attempt to explain certain aspects of visual perception using a single concept: filtering."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144549270"
                        ],
                        "name": "M. Brand",
                        "slug": "M.-Brand",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Brand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3243878"
                        ],
                        "name": "Rahul Bhotika",
                        "slug": "Rahul-Bhotika",
                        "structuredName": {
                            "firstName": "Rahul",
                            "lastName": "Bhotika",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rahul Bhotika"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 122
                            }
                        ],
                        "text": "Some of the newest model-based tracking methods calculate the 3D motions and deformations directly from image intensities [Brand and Bhotika 2001], thus eliminating the information-lossy intermediate representations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 123
                            }
                        ],
                        "text": "Some of the newest model-based tracking methods cal\u00adculate the 3D motions and deformations \ndirectly from image intensities [Brand and Bhotika 2001], thus eliminating the information-lossy intermediate \nrepresen\u00adtations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8252744,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "794f13128f9048f806d9465e0816c3c3eb3d1f9b",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce linear methods for model-based tracking of nonrigid 3D objects and for acquiring such models from video. 3D motions and flexions are calculated directly from image intensities without information-lossy intermediate results. Measurement uncertainty is quantified and fully propagated through the inverse model to yield posterior mean (PM) and/or mode (MAP) pose estimates. A Bayesian framework manages uncertainty, accommodates priors, and gives confidence measures. We obtain highly accurate and robust closed-form estimators by minimizing information loss from non-reversible (inner-product and least-squares) operations, and, when unavoidable, performing such operations with the appropriate error norm. For model acquisition, we show how to refine a crude or generic model to fit the video subject. We demonstrate with tracking, model refinement, and super-resolution texture lifting from low-quality low-resolution video."
            },
            "slug": "Flexible-flow-for-3D-nonrigid-tracking-and-shape-Brand-Bhotika",
            "title": {
                "fragments": [],
                "text": "Flexible flow for 3D nonrigid tracking and shape recovery"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This work introduces linear methods for model-based tracking of nonrigid 3D objects and for acquiring such models from video and shows how to refine a crude or generic model to fit the video subject."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2266180"
                        ],
                        "name": "E. S. Big\u00fcn",
                        "slug": "E.-S.-Big\u00fcn",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Big\u00fcn",
                            "middleNames": [
                                "Saers"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. S. Big\u00fcn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775110"
                        ],
                        "name": "J. Big\u00fcn",
                        "slug": "J.-Big\u00fcn",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Big\u00fcn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Big\u00fcn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2100878"
                        ],
                        "name": "B. Duc",
                        "slug": "B.-Duc",
                        "structuredName": {
                            "firstName": "Beno\u00eet",
                            "lastName": "Duc",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Duc"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061647120"
                        ],
                        "name": "S. Fischer",
                        "slug": "S.-Fischer",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fischer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5805407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "280a7177e1319b089ca3fb314f838348c9e74980",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm functioning as a supervisor module in a multi expert decision making machine. It uses the Bayes theory in order to estimate the biases of individual expert opinions. These are then used to calibrate and conciliate expert opinions to one opinion. We present a framework for simulating decision strategies using expert opinions whose properties are easily modifiable. By using real data coming from a person authentication system using image and speech data we were able to confirm that the proposed supervisor improves the quality of individual expert decisions by reaching success rates of 99.5 %."
            },
            "slug": "Expert-Conciliation-for-Multi-Modal-Person-Systems-Big\u00fcn-Big\u00fcn",
            "title": {
                "fragments": [],
                "text": "Expert Conciliation for Multi Modal Person Authentication Systems by Bayesian Statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "By using real data coming from a person authentication system using image and speech data, it is confirmed that the proposed supervisor improves the quality of individual expert decisions by reaching success rates of 99.5 %."
            },
            "venue": {
                "fragments": [],
                "text": "AVBPA"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2459012"
                        ],
                        "name": "S. Mika",
                        "slug": "S.-Mika",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Mika",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mika"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152597562"
                        ],
                        "name": "Gunnar R\u00e4tsch",
                        "slug": "Gunnar-R\u00e4tsch",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "R\u00e4tsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gunnar R\u00e4tsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4080509"
                        ],
                        "name": "B. Scholkopf",
                        "slug": "B.-Scholkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Scholkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Scholkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150175872"
                        ],
                        "name": "K.R. Mullers",
                        "slug": "K.R.-Mullers",
                        "structuredName": {
                            "firstName": "K.R.",
                            "lastName": "Mullers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K.R. Mullers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 135
                            }
                        ],
                        "text": "Other techniques have also been used to construct the discriminating basis in the identity surface: kernel discriminant analysis (KDA) [Mika et al. 1999] was used to compute a nonlinear discriminating basis, and a dynamic face model is used to extract a shape-and-pose-free facial texture pattern."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 130
                            }
                        ],
                        "text": "Other techniques have also been used to \nconstruct the discriminating basis in the identity surface: kernel discriminant analysis (KDA) [Mika \net al. 1999] was used to compute a nonlinear discriminat\u00ading basis, and a dynamic face model is used \nto extract a shape-and-pose-free fa\u00adcial texture pattern."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 136
                            }
                        ],
                        "text": "Other techniques have also been used to \nconstruct the discriminating basis in the identity surface: kernel discriminant analysis (KDA) [Mika \net al. 1999] was used to compute a nonlinear discriminat\u00ading basis, and a dynamic face model is used \nto extract a shape-and-pose-free fa\u00adcial texture\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "To further suppress within-class variations, the shape-and-pose-free tex\u00adture patterns were further projected \ninto a KDA feature space."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Recognition rates were 100% and 93.9%, using 10 and \n2 KDA (kernel discriminant analysis) vectors, re\u00adspectively."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8473401,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e43d731d638f769f12f8ab413d14a77a761856c",
            "isKey": true,
            "numCitedBy": 2897,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A non-linear classification technique based on Fisher's discriminant is proposed. The main ingredient is the kernel trick which allows the efficient computation of Fisher discriminant in feature space. The linear classification in feature space corresponds to a (powerful) non-linear decision function in input space. Large scale simulations demonstrate the competitiveness of our approach."
            },
            "slug": "Fisher-discriminant-analysis-with-kernels-Mika-R\u00e4tsch",
            "title": {
                "fragments": [],
                "text": "Fisher discriminant analysis with kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A non-linear classification technique based on Fisher's discriminant which allows the efficient computation of Fisher discriminant in feature space and large scale simulations demonstrate the competitiveness of this approach."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70331487"
                        ],
                        "name": "D. Metaxes",
                        "slug": "D.-Metaxes",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Metaxes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Metaxes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750924"
                        ],
                        "name": "Demetri Terzopoulos",
                        "slug": "Demetri-Terzopoulos",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Terzopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Demetri Terzopoulos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 101
                            }
                        ],
                        "text": "Non-rigid Motion Analysis A nal area of relevance to FRT is the motion analysis of non-rigid objects [117, 118, 119, 120]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118075465,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "25505a1fd25b917f2d7692b879217bad9c7fa59b",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors paper presents an approach for recursively estimating 3D object shape and general nonrigid motion, which makes use of physically based dynamic models. The models provide global deformation parameters which represent the salient shape features of natural parts, and local deformation parameters which capture shape details. The equations of motion governing the models, augmented by point-to-point constraints, make them responsive to externally applied forces. The authors extend this system of differential equations to formulate a shape and nonrigid motion estimator, a nonlinear Kalman filter, that recursively transforms the discrepancy between the data and the estimated model state into generalized forces while formally accounting for uncertainty in the observations. A Riccati update process maintains a covariance matrix that adjusts the forces in accordance with the system dynamics and the current and prior observations. The estimator applies the transformed forces to adjust the translational, rotational, and deformational degrees of freedom such that the model evolves as consistently as possible with the noisy data. The authors present model fitting and motion tracking experiments of articulated flexible objects from real and synthetic noise-corrupted 3D data.<<ETX>>"
            },
            "slug": "Recursive-estimation-of-shape-and-nonrigid-motion-Metaxes-Terzopoulos",
            "title": {
                "fragments": [],
                "text": "Recursive estimation of shape and nonrigid motion"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE Workshop on Visual Motion"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3355150"
                        ],
                        "name": "P. Tsai",
                        "slug": "P.-Tsai",
                        "structuredName": {
                            "firstName": "Ping-Sing",
                            "lastName": "Tsai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Tsai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 116
                            }
                        ],
                        "text": "Figure 15 shows some comparisons between rendered images obtained using this method and using a local SFS algorithm [190]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35992216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f82588a000dc9ad3353a2ddf7525e53d2aedf56a",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for computing depth from a single shaded image is presented. Discrete approximations for p and q using finite differences are used, and the reflectance in Z/sub ij/ is linearized. The method is faster, since each operation is purely local. In addition, it gives good results for spherical surfaces, in contrast to other linear methods.<<ETX>>"
            },
            "slug": "A-fast-linear-shape-from-shading-Tsai-Shah",
            "title": {
                "fragments": [],
                "text": "A fast linear shape from shading"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A method for computing depth from a single shaded image usingrete approximations for p and q using finite differences are used, and the reflectance in Z/sub ij/ is linearized."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 222292199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10055eb6f2f711a36d9aa8f759d3b3f01ebddb5d",
            "isKey": false,
            "numCitedBy": 6561,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Various Aspects of Memory.- 1.1 On the Purpose and Nature of Biological Memory.- 1.1.1 Some Fundamental Concepts.- 1.1.2 The Classical Laws of Association.- 1.1.3 On Different Levels of Modelling.- 1.2 Questions Concerning the Fundamental Mechanisms of Memory.- 1.2.1 Where Do the Signals Relating to Memory Act Upon?.- 1.2.2 What Kind of Encoding is Used for Neural Signals?.- 1.2.3 What are the Variable Memory Elements?.- 1.2.4 How are Neural Signals Addressed in Memory?.- 1.3 Elementary Operations Implemented by Associative Memory.- 1.3.1 Associative Recall.- 1.3.2 Production of Sequences from the Associative Memory.- 1.3.3 On the Meaning of Background and Context.- 1.4 More Abstract Aspects of Memory.- 1.4.1 The Problem of Infinite-State Memory.- 1.4.2 Invariant Representations.- 1.4.3 Symbolic Representations.- 1.4.4 Virtual Images.- 1.4.5 The Logic of Stored Knowledge.- 2. Pattern Mathematics.- 2.1 Mathematical Notations and Methods.- 2.1.1 Vector Space Concepts.- 2.1.2 Matrix Notations.- 2.1.3 Further Properties of Matrices.- 2.1.4 Matrix Equations.- 2.1.5 Projection Operators.- 2.1.6 On Matrix Differential Calculus.- 2.2 Distance Measures for Patterns.- 2.2.1 Measures of Similarity and Distance in Vector Spaces.- 2.2.2 Measures of Similarity and Distance Between Symbol Strings.- 2.2.3 More Accurate Distance Measures for Text.- 3. Classical Learning Systems.- 3.1 The Adaptive Linear Element (Adaline).- 3.1.1 Description of Adaptation by the Stochastic Approximation.- 3.2 The Perceptron.- 3.3 The Learning Matrix.- 3.4 Physical Realization of Adaptive Weights.- 3.4.1 Perceptron and Adaline.- 3.4.2 Classical Conditioning.- 3.4.3 Conjunction Learning Switches.- 3.4.4 Digital Representation of Adaptive Circuits.- 3.4.5 Biological Components.- 4. A New Approach to Adaptive Filters.- 4.1 Survey of Some Necessary Functions.- 4.2 On the \"Transfer Function\" of the Neuron.- 4.3 Models for Basic Adaptive Units.- 4.3.1 On the Linearization of the Basic Unit.- 4.3.2 Various Cases of Adaptation Laws.- 4.3.3 Two Limit Theorems.- 4.3.4 The Novelty Detector.- 4.4 Adaptive Feedback Networks.- 4.4.1 The Autocorrelation Matrix Memory.- 4.4.2 The Novelty Filter.- 5. Self-Organizing Feature Maps.- 5.1 On the Feature Maps of the Brain.- 5.2 Formation of Localized Responses by Lateral Feedback.- 5.3 Computational Simplification of the Process.- 5.3.1 Definition of the Topology-Preserving Mapping.- 5.3.2 A Simple Two-Dimensional Self-Organizing System.- 5.4 Demonstrations of Simple Topology-Preserving Mappings.- 5.4.1 Images of Various Distributions of Input Vectors.- 5.4.2 \"The Magic TV\".- 5.4.3 Mapping by a Feeler Mechanism.- 5.5 Tonotopic Map.- 5.6 Formation of Hierarchical Representations.- 5.6.1 Taxonomy Example.- 5.6.2 Phoneme Map.- 5.7 Mathematical Treatment of Self-Organization.- 5.7.1 Ordering of Weights.- 5.7.2 Convergence Phase.- 5.8 Automatic Selection of Feature Dimensions.- 6. Optimal Associative Mappings.- 6.1 Transfer Function of an Associative Network.- 6.2 Autoassociative Recall as an Orthogonal Projection.- 6.2.1 Orthogonal Projections.- 6.2.2 Error-Correcting Properties of Projections.- 6.3 The Novelty Filter.- 6.3.1 Two Examples of Novelty Filter.- 6.3.2 Novelty Filter as an Autoassociative Memory.- 6.4 Autoassociative Encoding.- 6.4.1 An Example of Autoassociative Encoding.- 6.5 Optimal Associative Mappings.- 6.5.1 The Optimal Linear Associative Mapping.- 6.5.2 Optimal Nonlinear Associative Mappings.- 6.6 Relationship Between Associative Mapping, Linear Regression, and Linear Estimation.- 6.6.1 Relationship of the Associative Mapping to Linear Regression.- 6.6.2 Relationship of the Regression Solution to the Linear Estimator.- 6.7 Recursive Computation of the Optimal Associative Mapping.- 6.7.1 Linear Corrective Algorithms.- 6.7.2 Best Exact Solution (Gradient Projection).- 6.7.3 Best Approximate Solution (Regression).- 6.7.4 Recursive Solution in the General Case.- 6.8 Special Cases.- 6.8.1 The Correlation Matrix Memory.- 6.8.2 Relationship Between Conditional Averages and Optimal Estimator.- 7. Pattern Recognition.- 7.1 Discriminant Functions.- 7.2 Statistical Formulation of Pattern Classification.- 7.3 Comparison Methods.- 7.4 The Subspace Methods of Classification.- 7.4.1 The Basic Subspace Method.- 7.4.2 The Learning Subspace Method (LSM).- 7.5 Learning Vector Quantization.- 7.6 Feature Extraction.- 7.7 Clustering.- 7.7.1 Simple Clustering (Optimization Approach).- 7.7.2 Hierarchical Clustering (Taxonomy Approach).- 7.8 Structural Pattern Recognition Methods.- 8. More About Biological Memory.- 8.1 Physiological Foundations of Memory.- 8.1.1 On the Mechanisms of Memory in Biological Systems.- 8.1.2 Structural Features of Some Neural Networks.- 8.1.3 Functional Features of Neurons.- 8.1.4 Modelling of the Synaptic Plasticity.- 8.1.5 Can the Memory Capacity Ensue from Synaptic Changes?.- 8.2 The Unified Cortical Memory Model.- 8.2.1 The Laminar Network Organization.- 8.2.2 On the Roles of Interneurons.- 8.2.3 Representation of Knowledge Over Memory Fields.- 8.2.4 Self-Controlled Operation of Memory.- 8.3 Collateral Reading.- 8.3.1 Physiological Results Relevant to Modelling.- 8.3.2 Related Modelling.- 9. Notes on Neural Computing.- 9.1 First Theoretical Views of Neural Networks.- 9.2 Motives for the Neural Computing Research.- 9.3 What Could the Purpose of the Neural Networks be?.- 9.4 Definitions of Artificial \"Neural Computing\" and General Notes on Neural Modelling.- 9.5 Are the Biological Neural Functions Localized or Distributed?.- 9.6 Is Nonlinearity Essential to Neural Computing?.- 9.7 Characteristic Differences Between Neural and Digital Computers.- 9.7.1 The Degree of Parallelism of the Neural Networks is Still Higher than that of any \"Massively Parallel\" Digital Computer.- 9.7.2 Why the Neural Signals Cannot be Approximated by Boolean Variables.- 9.7.3 The Neural Circuits do not Implement Finite Automata.- 9.7.4 Undue Views of the Logic Equivalence of the Brain and Computers on a High Level.- 9.8 \"Connectionist Models\".- 9.9 How can the Neural Computers be Programmed?.- 10. Optical Associative Memories.- 10.1 Nonholographic Methods.- 10.2 General Aspects of Holographic Memories.- 10.3 A Simple Principle of Holographic Associative Memory.- 10.4 Addressing in Holographic Memories.- 10.5 Recent Advances of Optical Associative Memories.- Bibliography on Pattern Recognition.- References."
            },
            "slug": "Self-Organization-and-Associative-Memory-Kohonen",
            "title": {
                "fragments": [],
                "text": "Self-Organization and Associative Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The purpose and nature of Biological Memory, as well as some of the aspects of Memory Aspects, are explained."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50564384"
                        ],
                        "name": "G. Edwards",
                        "slug": "G.-Edwards",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "Edwards",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2230657,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76b532e2cb573fdf29f3ae68dc1372f3319c93c2",
            "isKey": false,
            "numCitedBy": 3787,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new method of matching statistical models of appearance to images. A set of model parameters control modes of shape and gray-level variation learned from a training set. We construct an efficient iterative matching algorithm by learning the relationship between perturbations in the model parameters and the induced image errors."
            },
            "slug": "Active-Appearance-Models-Cootes-Edwards",
            "title": {
                "fragments": [],
                "text": "Active Appearance Models"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A new method of matching statistical models of appearance to images by learning the relationship between perturbations in the model parameters and the induced image errors is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Two HyperBF networks [75] were trained, one for each gender."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14892653,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "089a76dbc62a06ad30ae1925530e8733e850268e",
            "isKey": false,
            "numCitedBy": 3701,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of the approximation of nonlinear mapping, (especially continuous mappings) is considered. Regularization theory and a theoretical framework for approximation (based on regularization techniques) that leads to a class of three-layer networks called regularization networks are discussed. Regularization networks are mathematically related to the radial basis functions, mainly used for strict interpolation tasks. Learning as approximation and learning as hypersurface reconstruction are discussed. Two extensions of the regularization approach are presented, along with the approach's corrections to splines, regularization, Bayes formulation, and clustering. The theory of regularization networks is generalized to a formulation that includes task-dependent clustering and dimensionality reduction. Applications of regularization networks are discussed. >"
            },
            "slug": "Networks-for-approximation-and-learning-Poggio-Girosi",
            "title": {
                "fragments": [],
                "text": "Networks for approximation and learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21451088"
                        ],
                        "name": "P. Ekman",
                        "slug": "P.-Ekman",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Ekman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ekman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 53
                            }
                        ],
                        "text": "versally associated with distinct facial expressions [132]: happiness, sadness, surprise, fear, anger, and disgust."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31542887,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "612b6f9e5e16ead6ea5d4b8001ed05a25d7e6d81",
            "isKey": false,
            "numCitedBy": 367,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Evidence on universals in facial expression of emotion and renewed controversy about how to interpret that evidence is discussed. New findings on the capability of voluntary facial action to generate changes in both autonomic and central nervous system activity are presented, as well as a discussion of the possible mechanisms relevant to this phenomenon. Finally, new work on the nature of smiling is reviewed which shows that it is possible to distinguish the smile when enjoyment is occurring from other types of smiling. Implications for the differences between voluntary and involuntary expression are considered."
            },
            "slug": "Facial-expressions-of-emotion:-an-old-controversy-Ekman",
            "title": {
                "fragments": [],
                "text": "Facial expressions of emotion: an old controversy and new findings."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "New work on the nature of smiling shows that it is possible to distinguish the smile when enjoyment is occurring from other types of smiling, and implications for the differences between voluntary and involuntary expression are considered."
            },
            "venue": {
                "fragments": [],
                "text": "Philosophical transactions of the Royal Society of London. Series B, Biological sciences"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34712076"
                        ],
                        "name": "C. Stauffer",
                        "slug": "C.-Stauffer",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Stauffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Stauffer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2801291"
                        ],
                        "name": "R. Romano",
                        "slug": "R.-Romano",
                        "structuredName": {
                            "firstName": "Raquel",
                            "lastName": "Romano",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Romano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107410732"
                        ],
                        "name": "L. Lee",
                        "slug": "L.-Lee",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17957171,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "7c05eb1563da0a3f8fa31363f4d8ecae40b7e3ce",
            "isKey": false,
            "numCitedBy": 667,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a vision system that monitors activity in a site over extended periods of time. The system uses a distributed set of sensors to cover the site, and an adaptive tracker detects multiple moving objects in the sensors. Our hypothesis is that motion tracking is sufficient to support a range of computations about site activities. We demonstrate using the tracked motion data to calibrate the distributed sensors, to construct rough site models, to classify detected objects, to learn common patterns of activity for different object classes, and to detect unusual activities."
            },
            "slug": "Using-adaptive-tracking-to-classify-and-monitor-in-Grimson-Stauffer",
            "title": {
                "fragments": [],
                "text": "Using adaptive tracking to classify and monitor activities in a site"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A vision system that monitors activity in a site over extended periods of time using tracked motion data to calibrate the distributed sensors, to construct rough site models, to classify detected objects, to learn common patterns of activity for different object classes, and to detect unusual activities."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144152544"
                        ],
                        "name": "B. Horowitz",
                        "slug": "B.-Horowitz",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Horowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 90
                            }
                        ],
                        "text": "In [148] motion templates are used to track people, in [149] color blobs are used, and in [119] nonrigid models are used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 101
                            }
                        ],
                        "text": "Non-rigid Motion Analysis A nal area of relevance to FRT is the motion analysis of non-rigid objects [117, 118, 119, 120]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5863271,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "f244c6d0f9abe7564a48653eb6726c814bb5fd27",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The elastic properties of real materials provide constraint on the types of non-rigid motion that can occur, and thus allow overconstrained estimates of 3-D non-rigid motion from optical flow data. It is shown that by modeling and simulating the physics of non-rigid motion it is possible to obtain good estimates of both object shape and velocity. Examples using grey-scale and X-ray imagery are presented, including an example of tracking a complex articulated figure.<<ETX>>"
            },
            "slug": "Recovery-of-non-rigid-motion-and-structure-Horowitz-Pentland",
            "title": {
                "fragments": [],
                "text": "Recovery of non-rigid motion and structure"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that by modeling and simulating the physics of non-rigid motion it is possible to obtain good estimates of both object shape and velocity."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52533369"
                        ],
                        "name": "R. Yin",
                        "slug": "R.-Yin",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Yin",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Yin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 144148773,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "ea0ab7b33afe8f496239d8f22cec28af48ad6da8",
            "isKey": false,
            "numCitedBy": 2424,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Compared memory for faces with memory for other classes of familar and complex objects which, like faces, are also customarily seen only in 1 orientation (mono-oriented). Performance of 4 students was tested when the inspection and test series were presented in the same orientation, either both upri"
            },
            "slug": "Looking-at-Upside-down-Faces-Yin",
            "title": {
                "fragments": [],
                "text": "Looking at Upside-down Faces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144873562"
                        ],
                        "name": "R. Bellman",
                        "slug": "R.-Bellman",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Bellman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bellman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 258,
                                "start": 254
                            }
                        ],
                        "text": "Noting that the number of images M usually available for computing the covariance matrix of the data is much less than the row or column dimensionality of the covariance matrix, leading to singularity of the matrix, a standard method from linear algebra [46] is used that calculates only the M eigenvectors that do not belong to the null space of the degenerate matrix."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120700370,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c610130bbea84fa87db186d502ca93c6007b8510",
            "isKey": false,
            "numCitedBy": 3428,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Foreword Preface to the Second Edition Preface 1. Maximization, Minimization, and Motivation 2. Vectors and Matrices 3. Diagonalization and Canonical Forms for Symmetric Matrices 4. Reduction of General Symmetric Matrices to Diagonal Form 5. Constrained Maxima 6. Functions of Matrices 7. Variational Description of Characteristic Roots 8. Inequalities 9. Dynamic Programming 10. Matrices and Differential Equations 11. Explicit Solutions and Canonical Forms 12. Symmetric Function, Kronecker Products and Circulants 13. Stability Theory 14. Markoff Matrices and Probability Theory 15. Stochastic Matrices 16. Positive Matrices, Perron's Theorem, and Mathematical Economics 17. Control Processes 18. Invariant Imbedding 19. Numerical Inversion of the Laplace Transform and Tychonov Regularization Appendix A. Linear Equations and Rank Appendix B. The Quadratic Form of Selberg Appendix C. A Method of Hermite Appendix D. Moments and Quadratic Forms Index."
            },
            "slug": "Introduction-to-Matrix-Analysis-Bellman",
            "title": {
                "fragments": [],
                "text": "Introduction to Matrix Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This book discusses Maximization, Minimization, and Motivation, which is concerned with the optimization of Symmetric Matrices, and its applications in Programming and Mathematical Economics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1960
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145271456"
                        ],
                        "name": "A. Azarbayejani",
                        "slug": "A.-Azarbayejani",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Azarbayejani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Azarbayejani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738894"
                        ],
                        "name": "T. Starner",
                        "slug": "T.-Starner",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Starner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Starner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144152544"
                        ],
                        "name": "B. Horowitz",
                        "slug": "B.-Horowitz",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Horowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 63
                            }
                        ],
                        "text": "Early efforts focused on the first two problems: head tracking [Azarbayejani et al. 1993] and facial feature tracking [Terzopoulos and Waters 1993; Yuille and Hallinan 1992]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 63
                            }
                        ],
                        "text": "Early efforts focused on the .rst two problems: head \ntracking [Azarbayejani et al. 1993] and facial feature track\u00ading [Terzopoulos and Waters 1993; Yuille \nand Hallinan 1992]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10074380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7bfa4190f8e4b746855adf8da214d5fdad8ede2",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Interactive graphics systems that are driven by visual input are discussed. The underlying computer vision techniques and a theoretical formulation that addresses issues of accuracy, computational efficiency, and compensation for display latency are presented. Experimental results quantitatively compare the accuracy of the visual technique with traditional sensing. An extension to the basic technique to include structure recovery is discussed. >"
            },
            "slug": "Visually-Controlled-Graphics-Azarbayejani-Starner",
            "title": {
                "fragments": [],
                "text": "Visually Controlled Graphics"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "Interactive graphics systems that are driven by visual input and an extension to the basic technique to include structure recovery is discussed, quantitatively comparing the accuracy of the visual technique with traditional sensing."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939761"
                        ],
                        "name": "P. S. Penev",
                        "slug": "P.-S.-Penev",
                        "structuredName": {
                            "firstName": "Penio",
                            "lastName": "Penev",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. S. Penev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281877"
                        ],
                        "name": "J. Atick",
                        "slug": "J.-Atick",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Atick",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Atick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 28
                            }
                        ],
                        "text": "To explore this redundancy, LFA is used to \nextract to\u00adpographic local features from the global PCA modes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 69
                            }
                        ],
                        "text": "LFA is an interesting biologically in\u00adspired feature analysis method [Penev and Atick 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "It has been argued that practical \nsys\u00adtems should use a hybrid of PCA and LFA (Appendix B in Penev and Atick [1996])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 171
                            }
                        ],
                        "text": "In the hybrid method category, we will brie.y review \nthe modular eigenface method [Pentland et al. 1994], a hybrid representation based on PCA and local feature \nanalysis (LFA) [Penev and Atick 1996], a .exible appearance model-based method [Lanitis et al. 1995], \nand a recent development [Huang et al. 2003] along this direction."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "Two interesting points are \ndemonstrated in this paper: (1) using the same number of kernels, the perceptual reconstruction quality \nof LFA based on the optimal set of grids is better than that of PCA; the mean square error is 227, and \n184 for a particular input; (2) keeping the second PCA eigenmodel in LFA reconstruction re\u00adduces the \nmean square error to 152, sug\u00adgesting the hybrid use of PCA and LFA."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 153
                            }
                        ],
                        "text": "For a limited class of objects such as face images that are normalized with respect to scale, trans\u00adlation, \nand rotation, the redundancy is even greater [Penev and Atick 1996; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 45
                            }
                        ],
                        "text": "LFA kernels K (xi , y) at different grids xi [Penev and Atick 1996]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 119
                            }
                        ],
                        "text": "Unlike PCA kernels <i which contain no \ntopographic information (their supports extend over the entire grid of images), LFA kernels (Figure12) \nK (xi, y) at selected grids xi have local support.10 10These kernels (Figure 12) indexed by grids xi \nare similar to the ICA kernels in the .rst ICA system architecture [Bartlett et al. 1998; Bell and Sejnowski \n1995]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 77
                            }
                        ],
                        "text": "1994], a hybrid representation based on PCA and local feature analysis (LFA) [Penev and Atick 1996], a flexible appearance model-based method [Lanitis et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 146
                            }
                        ],
                        "text": "For a limited class of objects such as faces which are correctly aligned and scaled, this suggests that even lower dimensionality can be expected [Penev and Atick 1996]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "LFA is claimed to be used in Visionics s commercial system FaceIt (Table \nII)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 144
                            }
                        ],
                        "text": "\u2026Representative work Still-image methods Basic methods [Turk and \nPentland 1991; Lin et al. 1997; Moghaddam and Pentland 1997; Okada et al. 1998; Penev and Atick 1996; \nWechsler et al. 1997; Wiskott et al. 1997] Tracking-enhanced [Edwards et al. 1998; McKenna and Gong 1997, \n1998; Steffens et\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 147
                            }
                        ],
                        "text": "For a lim\u00adited class of objects such as faces which are correctly \naligned and scaled, this sug\u00adgests that even lower dimensionality can be expected [Penev and Atick 1996]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 149
                            }
                        ],
                        "text": "\u2026methods [Lawrence et al. 1997] Hybrid methods Modular \neigenfaces Eigenfaces and eigenmodules [Pentland et al. 1994] Hybrid LFA Local feature method [Penev \nand Atick 1996] Shape-normalized Flexible appearance models [Lanitis et al. 1995] Component-based Face \nregion and components [Huang et al.\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "No results on recognition performance \nbased on LFA were reported."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 189
                            }
                        ],
                        "text": "It seems to be better to estimate eigen\u00admodes/eigenfaces \nthat have large eigen\u00advalues (and so are more robust against noise), while for estimating higher-order \neigenmodes it is better to use LFA."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 68
                            }
                        ],
                        "text": "LFA is an interesting biologically inspired feature analysis method [Penev and Atick 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 272
                            }
                        ],
                        "text": "1997] Hidden Markov model HMM methods [Ne.an and Hayes 1998; Samaria 1994; Samaria and Young 1994] \nConvolution Neural Network SOM learning based CNN methods [Lawrence et al. 1997] Hybrid methods Modular \neigenfaces Eigenfaces and eigenmodules [Pentland et al. 1994] Hybrid LFA Local feature method [Penev \nand Atick 1996] Shape-normalized Flexible appearance models [Lanitis et al. 1995] Component-based Face \nregion and components [Huang et al. 2003] analysis (ICA) is argued to have more representative power \nthan PCA, and hence may provide better recognition per\u00adformance than PCA [Bartlett et al. 1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 152
                            }
                        ],
                        "text": "For a limited class of objects such as face images that are normalized with respect to scale, translation, and rotation, the redundancy is even greater [Penev and Atick 1996; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 147
                            }
                        ],
                        "text": "\u2026we will brie.y review \nthe modular eigenface method [Pentland et al. 1994], a hybrid representation based on PCA and local feature \nanalysis (LFA) [Penev and Atick 1996], a .exible appearance model-based method [Lanitis et al. 1995], \nand a recent development [Huang et al. 2003] along this\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9885372,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75c979c57b2319f98d793920c92a5ac51207791b",
            "isKey": true,
            "numCitedBy": 774,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "Low-dimensional representations of sensory signals are key to solving many of the computational problems encountered in high-level vision. Principal component analysis (PCA) has been used in the pa..."
            },
            "slug": "Local-feature-analysis:-A-general-statistical-for-Penev-Atick",
            "title": {
                "fragments": [],
                "text": "Local feature analysis: A general statistical theory for object representation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Low-dimensional representations of sensory signals are key to solving many of the computational problems encountered in high-level vision."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145884505"
                        ],
                        "name": "V. Cherkassky",
                        "slug": "V.-Cherkassky",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Cherkassky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Cherkassky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 249
                            }
                        ],
                        "text": "In order to increase the generalization ability of EP, a balance \nis sought between min\u00adimizing the empirical risk encountered during training and narrowing the con\u00ad.dence \ninterval for reducing the guaran\u00adteed risk during future testing on unseen data [Vapnik 1995]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 157
                            }
                        ],
                        "text": "In addition, the \nface region was added to the nine components to form a single feature vector (a hybrid method), which \nwas later trained by a SVM clas\u00adsifer [Vapnik 1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206755547,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "e64fecbaf4d75e0dd6711f8f335c8a53da9fd360",
            "isKey": false,
            "numCitedBy": 3182,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "If you really want to be smarter, reading can be one of the lots ways to evoke and realize. Many people who like reading will have more knowledge and experiences. Reading can be a way to gain information from economics, politics, science, fiction, literature, religion, and many others. As one of the part of book categories, the nature of statistical learning theory always becomes the most wanted book. Many people are absolutely searching for this book. It means that many love to read this kind of book."
            },
            "slug": "The-Nature-Of-Statistical-Learning-Theory-Cherkassky",
            "title": {
                "fragments": [],
                "text": "The Nature Of Statistical Learning Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "As one of the part of book categories, the nature of statistical learning theory always becomes the most wanted book."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50740237"
                        ],
                        "name": "Jun S. Liu",
                        "slug": "Jun-S.-Liu",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Liu",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun S. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "79735252"
                        ],
                        "name": "Rong Chen",
                        "slug": "Rong-Chen",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 6
                            }
                        ],
                        "text": "Since SIS has dif.culty in high-dimensional spaces, a reparame\u00adterization that captures essentially \nonly the difference was used to facilitate the computation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 114
                            }
                        ],
                        "text": "The tracking problem has been formulated as a Bayesian inference problem and sequential importance sampling (SIS) [Liu and Chen 1998] (one form of SIS is called Condensation [Isard and Blake 1996] in the computer vision literature) proposed as an empirical solution to the inference problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "The SIS algorithm is used to approximate the posterior distribution \nof the motion vector, the identity variable, and the exemplar index."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "A computa\u00adtionally \nef.cient sequential importance sampling (SIS) algorithm is used to esti\u00admate the posterior distribution."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 115
                            }
                        ],
                        "text": "The tracking problem has been formulated as a Bayesian inference \nprob\u00adlem and sequential importance sampling (SIS) [Liu and Chen 1998] (one form of SIS is called Condensation \n[Isard and Blake 1996] in the computer vision literature) proposed as an empirical solution to the inference \nproblem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15817579,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9873a6453ec35a65596263d66529131cba188e60",
            "isKey": true,
            "numCitedBy": 2125,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We provide a general framework for using Monte Carlo methods in dynamic systems and discuss its wide applications. Under this framework, several currently available techniques are studied and generalized to accommodate more complex features. All of these methods are partial combinations of three ingredients: importance sampling and resampling, rejection sampling, and Markov chain iterations. We provide guidelines on how they should be used and under what circumstance each method is most suitable. Through the analysis of differences and connections, we consolidate these methods into a generic algorithm by combining desirable features. In addition, we propose a general use of Rao-Blackwellization to improve performance. Examples from econometrics and engineering are presented to demonstrate the importance of Rao\u2013Blackwellization and to compare different Monte Carlo procedures."
            },
            "slug": "Sequential-Monte-Carlo-methods-for-dynamic-systems-Liu-Chen",
            "title": {
                "fragments": [],
                "text": "Sequential Monte Carlo methods for dynamic systems"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A general framework for using Monte Carlo methods in dynamic systems and a general use of Rao-Blackwellization is proposed to improve performance and to compare different Monte Carlo procedures."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2173900"
                        ],
                        "name": "K. Messer",
                        "slug": "K.-Messer",
                        "structuredName": {
                            "firstName": "Kieron",
                            "lastName": "Messer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Messer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801638"
                        ],
                        "name": "J. Kittler",
                        "slug": "J.-Kittler",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Kittler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kittler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678373"
                        ],
                        "name": "J. Luettin",
                        "slug": "J.-Luettin",
                        "structuredName": {
                            "firstName": "Juergen",
                            "lastName": "Luettin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Luettin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2488626"
                        ],
                        "name": "G. Ma\u00eetre",
                        "slug": "G.-Ma\u00eetre",
                        "structuredName": {
                            "firstName": "Gilbert",
                            "lastName": "Ma\u00eetre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ma\u00eetre"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 206
                            }
                        ],
                        "text": "\u2026\nempirical evaluations of face recog\u00adnition techniques (FRT), including the FERET [Phillips et al. 1998b, \n2000; Rizvi et al. 1998], FRVT 2000 [Blackburn et al. 2001], FRVT 2002 [Phillips et al. 2003], and XM2VTS \n[Messer et al. 1999] pro\u00adtocols, and many commercially available systems (Table II)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 32
                            }
                        ],
                        "text": "The XM2VTS multimodal database [Messer et al. \n1999] contains four recordings of 295 subjects taken over a pe\u00adriod of 4 months."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 86
                            }
                        ],
                        "text": "Fortunately, relatively \nlarge video databases exist, for example, the XM2TV database [Messer et al. 1999], the BANCA database \n[Bailly-Bailliere et al. 2003], and the addition of video into the FERET and FRVT2002 16Stereo is less \nsensitive to illumination change but still has dif.culty in\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 58
                            }
                        ],
                        "text": "Even though current \nmachine recognition systems have reached a certain level of maturity, their success is limited by the \nconditions imposed by many real applications."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15312675,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "b62628ac06bbac998a3ab825324a41a11bc3a988",
            "isKey": true,
            "numCitedBy": 1458,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Keywords: vision Reference EPFL-CONF-82502 URL: ftp://ftp.idiap.ch/pub/papers/vision/avbpa99.pdf Record created on 2006-03-10, modified on 2017-05-10"
            },
            "slug": "XM2VTSDB:-The-Extended-M2VTS-Database-Messer-Matas",
            "title": {
                "fragments": [],
                "text": "XM2VTSDB: The Extended M2VTS Database"
            },
            "tldr": {
                "abstractSimilarityScore": 31,
                "text": "This poster presents a poster presenting a probabilistic procedure for estimating the response of the immune system to laser-spot assisted surgery to treat central giant cell granuloma."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398965769"
                        ],
                        "name": "Y. Abu-Mostafa",
                        "slug": "Y.-Abu-Mostafa",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Abu-Mostafa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Abu-Mostafa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784553"
                        ],
                        "name": "D. Psaltis",
                        "slug": "D.-Psaltis",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Psaltis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Psaltis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "This capability has also been demonstrated using optical hardware [73]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 119353923,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "23a9c0f4bb4be98fd3a861e1013bcff927665d89",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Reference EPFL-ARTICLE-158542doi:10.1038/scientificamerican0387-88View record in Web of Science Record created on 2010-11-25, modified on 2017-05-10"
            },
            "slug": "Optical-neural-computers-Abu-Mostafa-Psaltis",
            "title": {
                "fragments": [],
                "text": "Optical neural computers"
            },
            "tldr": {
                "abstractSimilarityScore": 32,
                "text": "This poster presents a probabilistic procedure to characterize the response of the immune system to repeated exposure to EPFL\u2019s Tournaisian\u2013Seiden\u2013Bouchut\u2013Boyaval virus."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51921883"
                        ],
                        "name": "Refractor",
                        "slug": "Refractor",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Refractor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Refractor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 77
                            }
                        ],
                        "text": "[Biederman 1987]) has been cast within a theoretical framework introduced in [Marr 1982] in which different views of objects are analyzed in a way which allows access to (largely) viewpointinvariant descriptions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 158
                            }
                        ],
                        "text": "\u2026al. 1997; Tarr and Bulthoff 1995]: Much work in vi\u00adsual object \nrecognition (e.g. [Biederman 1987]) has been cast within a theo\u00adretical framework introduced in [Marr \n1982] in which different views of ob\u00adjects are analyzed in a way which allows access to (largely) viewpoint\u00adinvariant \ndescriptions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 208793436,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "c3a24b0b38922c4f3a825edb97cc470a4ca7af75",
            "isKey": false,
            "numCitedBy": 3113,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Vision-Refractor",
            "title": {
                "fragments": [],
                "text": "Vision"
            },
            "venue": {
                "fragments": [],
                "text": "The Lancet"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 156
                            }
                        ],
                        "text": "In addition, the face region was added to the nine components to form a single feature vector (a hybrid method), which was later trained by a SVM classifer [Vapnik 1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 249
                            }
                        ],
                        "text": "In order to increase the generalization ability of EP, a balance is sought between minimizing the empirical risk encountered during training and narrowing the confidence interval for reducing the guaranteed risk during future testing on unseen data [Vapnik 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 249
                            }
                        ],
                        "text": "In order to increase the generalization ability of EP, a balance \nis sought between min\u00adimizing the empirical risk encountered during training and narrowing the con\u00ad.dence \ninterval for reducing the guaran\u00adteed risk during future testing on unseen data [Vapnik 1995]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 157
                            }
                        ],
                        "text": "In addition, the \nface region was added to the nine components to form a single feature vector (a hybrid method), which \nwas later trained by a SVM clas\u00adsifer [Vapnik 1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": true,
            "numCitedBy": 38757,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114755201"
                        ],
                        "name": "Michael D. Kelly",
                        "slug": "Michael-D.-Kelly",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kelly",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael D. Kelly"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 79
                            }
                        ],
                        "text": ", the distances between important points) in faces or face profiles, were used [Bledsoe 1964; Kanade 1973; Kelly 1970]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "[Kelly 1970], or the distances and angles between eye corners, mouth extrema, nostrils, and chin top [Kanade 1973]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 144
                            }
                        ],
                        "text": "\u2026and Chellappa 1997] PDBNN Probabilistic decision based NN [Lin et al. 1997] Feature-based \nmethods Pure geometry methods Earlier methods [Kanade 1973; Kelly 1970]; recent methods [Cox et al. 1996; \nManjunath et al. 1992] Dynamic link architecture Graph matching methods [Okada et al. 1998;\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 174
                            }
                        ],
                        "text": "Most earlier methods belong to the cat\u00adegory of structural matching methods, us\u00ading the width \nof the head, the distances between the eyes and from the eyes to the mouth, etc. [Kelly 1970], or the \ndistances and angles between eye corners, mouth extrema, nostrils, and chin top [Kanade 1973]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 38
                            }
                        ],
                        "text": "Pure geometry methods Earlier methods [Kanade 1973; Kelly 1970]; recent"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 84
                            }
                        ],
                        "text": "But re\u00adsearch on automatic machine recogni\u00adtion of faces really started in the 1970s [Kelly \n1970] and after the seminal work of Kanade [1973]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 83
                            }
                        ],
                        "text": "But research on automatic machine recognition of faces really started in the 1970s [Kelly 1970] and after the seminal work of Kanade [1973]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 240
                            }
                        ],
                        "text": "As a result, during the early and mid-1970s, typical \npattern clas\u00adsi.cation techniques, which use measured attributes of features (e.g., the distances between \nimportant points) in faces or face pro.les, were used [Bledsoe 1964; Kanade 1973; Kelly 1970]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 148
                            }
                        ],
                        "text": "Many methods in the structural matching category \nhave been proposed, including many early methods based on geometry of local features [Kanade 1973; Kelly \n1970] as well as 1D [Samaria and Young 1994] and pseudo-2D [Samaria 1994] HMM methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61019110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccee2d0459b7eed40796d65d79b900abe638748a",
            "isKey": true,
            "numCitedBy": 223,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Visual-identification-of-people-by-computer-Kelly",
            "title": {
                "fragments": [],
                "text": "Visual identification of people by computer"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 227
                            }
                        ],
                        "text": "Most of the systems reviewed here focus \non the sub\u00adtask of recognition, but others also in\u00adclude automatic face detection and feature extraction, \nmaking them fully automatic systems [Lin et al. 1997; Moghaddam and Pentland 1997; Wiskott et al. 1997]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 126
                            }
                        ],
                        "text": "\u2026Oulu physics-based face database \nwww.ee.oulu../research/imag/color/pbfd.html  Earlier methods focused on constructing invariant features \n[Wiskott et al. 1997] or synthesizing a prototypical view (frontal view) after a full model is extracted \nfrom the input image [Lanitis\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 189
                            }
                        ],
                        "text": "Many \nmethods re\u00adviewed in Section 3 belong to this category: eigenfaces [Turk and Pentland 1991], probabilistic \neigenfaces [Moghaddam and Pentland 1997], the EBGM method [Okada et al. 1998; Wiskott et al. 1997], and \nthe PDBNN method [Lin et al. 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 80
                            }
                        ],
                        "text": "\u2014an Elastic Graph Matching algorithm from the University of Southern California [Okada et al. 1998; Wiskott et al. 1997] (March 1997);"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 169
                            }
                        ],
                        "text": "Many methods reviewed in Section 3 belong to this category: eigenfaces [Turk and Pentland 1991], probabilistic eigenfaces [Moghaddam and Pentland 1997], the EBGM method [Okada et al. 1998; Wiskott et al. 1997], and the PDBNN method [Lin et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 17
                            }
                        ],
                        "text": "The EBGM sys\u00adtem [Wiskott et al. 1997], the subspace \nLDA system [Zhao et al. 1998], and the probabilistic eigenface system [Moghad\u00addam and Pentland 1997] \nwere judged to be among the top three, with each method showing different levels of performance on different \nsubsets of sequestered images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 140
                            }
                        ],
                        "text": "We review several \nrepresenta\u00adtive methods here: (1) a view-based eigen\u00adface method [Pentland et al. 1994], (2) a graph \nmatching-based method [Wiskott et al. 1997], (3) a linear class-based method [Blanz and Vetter 1999; \nVetter and Poggio 1997], (4) a vectorized im\u00adage representation based method\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 616,
                                "start": 597
                            }
                        ],
                        "text": "The Sep96 evaluation tested the follow\u00ading 10 algorithms: \nan algorithm from Excalibur Corpora\u00adtion (Carlsbad, CA)(Sept. 1996); two algorithms from MIT Media Labo\u00adratory \n(Sept. 1996) [Moghaddam et al. 1996; Turk and Pentland 1991]; three linear discriminant analysis\u00adbased \nalgorithms from Michigan State University [Swets and Weng 1996b] (Sept. 1996) and the University of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997); a gray-scale projection algorithm \nfrom Rutgers University [Wilder 1994] (Sept. 1996); an Elastic Graph Matching algorithm from the University \nof Southern Cali\u00adfornia [Okada et al. 1998; Wiskott et al. 1997] (March 1997); a baseline PCA algorithm \n[Moon and Phillips 2001; Turk and Pentland 1991]; and a baseline normalized correlation matching algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 16
                            }
                        ],
                        "text": "The EBGM system [Wiskott et al. 1997], the subspace LDA system [Zhao et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 74
                            }
                        ],
                        "text": "(Notice how this method is similar \nto the EBGM system [Okada et al. 1998; Wiskott et al. 1997] except that gray-scale compo\u00adnents are used \ninstead of Gabor wavelets.)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 114
                            }
                        ],
                        "text": "One of the most \nsuccessful of these systems is the Elas\u00adtic Bunch Graph Matching (EBGM) sys\u00adtem [Okada et al. 1998; Wiskott \net al. 1997], which is based on DLA [Buhmann et al. 1990; Lades et al. 1993]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 75
                            }
                        ],
                        "text": "The DLA architecture was recently extended to Elastic Bunch Graph Matching [Wiskott et al. 1997] (Figure 10)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 81
                            }
                        ],
                        "text": "One of the most successful systems in this category is the graph matching system [Okada et al. 1998; Wiskott et al. 1997], which is based on the Dynamic Link Architecture (DLA) [Buhmann et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 188
                            }
                        ],
                        "text": "Three of the algorithms performed very well: probabilistic eigenface from MIT [Moghaddam et al. 1996], \nsub\u00adspace LDA from UMD [Zhao et al. 1998, 1999], and Elastic Graph Matching from USC [Wiskott et al. \n1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 76
                            }
                        ],
                        "text": "The DLA architecture was recently ex\u00adtended to Elastic Bunch Graph Match\u00ading [Wiskott et al. 1997] (Figure \n10)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 148
                            }
                        ],
                        "text": "\u2026Basic methods [Turk and \nPentland 1991; Lin et al. 1997; Moghaddam and Pentland 1997; Okada et al. 1998; Penev and Atick 1996; \nWechsler et al. 1997; Wiskott et al. 1997] Tracking-enhanced [Edwards et al. 1998; McKenna and Gong 1997, \n1998; Steffens et al. 1998] Multimodal methods Video-and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 94
                            }
                        ],
                        "text": "One of the most successful of these systems is the Elastic Bunch Graph Matching (EBGM) system [Okada et al. 1998; Wiskott et al. 1997], which is based on DLA [Buhmann et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 143
                            }
                        ],
                        "text": "\u2026\nfrom Rutgers University [Wilder 1994] (Sept. 1996); an Elastic Graph Matching algorithm from the University \nof Southern Cali\u00adfornia [Okada et al. 1998; Wiskott et al. 1997] (March 1997); a baseline PCA algorithm \n[Moon and Phillips 2001; Turk and Pentland 1991]; and a baseline normalized\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "However, for veri.cation, \nthe equal error rates were 2% and 14% for USC, and 1% and 12% for UMD."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 44
                            }
                        ],
                        "text": "Compared to invariant-feature-based methods [Wiskott et al. 1997], multiview-based methods of face detection and recognition seem to be able to achieve better results when the angle of out-of-plane rotation is large (35\u25e6)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "The Bochum/USC Face Recognition System and how it \nfared in the FERET Phase III Test."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 40
                            }
                        ],
                        "text": "Feature-based graph matching approaches [Wiskott et al. 1997] have also been quite successful."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 101
                            }
                        ],
                        "text": "One of the most successful systems in \nthis cate\u00adgory is the graph matching system [Okada et al. 1998; Wiskott et al. 1997], which is based \non the Dynamic Link Architec\u00adture (DLA) [Buhmann et al. 1990; Lades et al. 1993]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 180
                            }
                        ],
                        "text": "Most of the systems reviewed here focus on the subtask of recognition, but others also include automatic face detection and feature extraction, making them fully automatic systems [Lin et al. 1997; Moghaddam and Pentland 1997; Wiskott et al. 1997]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 41
                            }
                        ],
                        "text": "Feature-based graph matching approaches [Wiskott et al. 1997] have also been quite suc\u00adcessful."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 54
                            }
                        ],
                        "text": "(Notice how this method is similar to the EBGM system [Okada et al. 1998; Wiskott et al. 1997] except that gray-scale components are used instead of Gabor wavelets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 45
                            }
                        ],
                        "text": "Compared to invariant-feature-based methods [Wiskott \net al. 1997], multiview-based methods of face detection and recognition seem to be able to achieve better \nresults when the an\u00adgle of out-of-plane rotation is large (35.)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "For identi.cation, on the fb and duplicate \nprobes, the USC scores were 94% and 59%, and the UMD scores were 96% and 47%."
                    },
                    "intents": []
                }
            ],
            "corpusId": 30523165,
            "fieldsOfStudy": [],
            "id": "6f01963039d0a921b1930b4563d1601ff36b971f",
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recognition by Elastic Bunch Graph Matching"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 57
                            }
                        ],
                        "text": "LDA training is \ncarried out via scatter matrix analysis [Fukunaga 1989]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "The leave-one-out strategy [64] was employed for classi cation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "LDA training is carried out via scatter matrix analysis [64]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 94
                            }
                        ],
                        "text": "Covariances \nonly in the principal subspace are estimated for use in the Mahalanobis distance [Fukunaga 1989]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical Pattern Recognition, New York"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 131
                            }
                        ],
                        "text": "analysis (ICA) is argued to have more representative power than PCA, and hence may provide better recognition performance than PCA [Bartlett et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 157
                            }
                        ],
                        "text": "Based on the argument that for tasks such as face recognition much of the important \ninformation is contained in high-order statistics, it has been pro\u00adposed [Bartlett et al. 1998] to use \nICA to extract features for face recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 156
                            }
                        ],
                        "text": "Based on the argument that for tasks such as face recognition much of the important information is contained in high-order statistics, it has been proposed [Bartlett et al. 1998] to use ICA to extract features for face recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 170
                            }
                        ],
                        "text": "Comparison of basis images using \ntwo architectures for performing ICA: (a) 25 indepen\u00addent components of Architecture I, (b) 25 independent \ncomponents of Architecture II [Bartlett et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 53
                            }
                        ],
                        "text": "factorial code in the columns of the output matrix U [Bartlett et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 271
                            }
                        ],
                        "text": "\u2026Atick 1996] Shape-normalized Flexible appearance models [Lanitis et al. 1995] Component-based Face \nregion and components [Huang et al. 2003] analysis (ICA) is argued to have more representative power \nthan PCA, and hence may provide better recognition per\u00adformance than PCA [Bartlett et al. 1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 248
                            }
                        ],
                        "text": "\u2026(their supports extend over the entire grid of images), LFA kernels (Figure12) \nK (xi, y) at selected grids xi have local support.10 10These kernels (Figure 12) indexed by grids xi \nare similar to the ICA kernels in the .rst ICA system architecture [Bartlett et al. 1998; Bell and Sejnowski \n1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 143
                            }
                        ],
                        "text": "\u2026\npursuit Enhanced GA learning [Liu and Wechsler 2000a] Feature lines Point-to-line distance based [Li \nand Lu 1999] ICA ICA-based feature analysis [Bartlett et al. 1998] Other representations LDA/FLD LDA/FLD \non raw image [Etemad and Chellappa 1997] PDBNN Probabilistic decision based NN\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 108
                            }
                        ],
                        "text": "Performing source separation on the \npixels produces a factorial code in the columns of the output matrix U [Bartlett et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Independent component representation for face recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, SPIE Symposium on Electronic Imaging: Science and Technology. 528\u2013539."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 4
                            }
                        ],
                        "text": "The XM2VTS database differs from the M2VTS database primarily in the number of subjects \n(295 rather than 37)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 476,
                                "start": 470
                            }
                        ],
                        "text": "This is evidenced by the emer\u00adgence of face recognition \nconferences such as the International Conference on Audio\u00adand Video-Based Authentication (AVBPA) since \n1997 and the International Con\u00adference on Automatic Face and Gesture Recognition (AFGR) since 1995, system\u00adatic \nempirical evaluations of face recog\u00adnition techniques (FRT), including the FERET [Phillips et al. 1998b, \n2000; Rizvi et al. 1998], FRVT 2000 [Blackburn et al. 2001], FRVT 2002 [Phillips et al. 2003], and XM2VTS \n[Messer et al. 1999] pro\u00adtocols, and many commercially available systems (Table II)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 4
                            }
                        ],
                        "text": "The XM2VTS Protocol Multimodal methods19 are a very promis\u00ading \napproach to user-friendly (hence ac\u00adceptable), highly secure personal veri.ca\u00adtion."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 7
                            }
                        ],
                        "text": "In the XM2VTS database, \nthe .rst shot is a speaking head shot."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 22
                            }
                        ],
                        "text": "\u00adcation results on the XM2VTS database."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 4
                            }
                        ],
                        "text": "The XM2VTS database is an expan\u00adsion of the earlier M2VTS database [Pigeon and Vandendorpe \n1999]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 132
                            }
                        ],
                        "text": "The M2VTS Lau\u00adsanne protocol was designed to evaluate the performance of vision-and \nspeech\u00adbased person authentication systems on the XM2VTS database."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 4
                            }
                        ],
                        "text": "The XM2VTS database \nwas acquired using a Sony VX1000E digital camcorder and a DHR1000UX digital VCR."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 106
                            }
                        ],
                        "text": "We describe here the most important face databases and their associated evaluation methods, \nin\u00adcluding the XM2VTS and BANCA [Bailly-Bailliere et al. 2003] database."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 218
                            }
                        ],
                        "text": "This is evidenced by the emergence of face recognition conferences such as AFGR [1] and AVBPA [2], and systematic empirical evaluations of face recognition techniques (FRT), including the FERET [3, 4, 5, 6] and XM2VTS [7] protocols."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "XM2VTSDB: The Extended M2VTS Database."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 122
                            }
                        ],
                        "text": "Two of the most important face databases and their associated evalua\u00adtion methods have been reviewed: \nthe FERET, FRVT, and XM2VTS protocols."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 86
                            }
                        ],
                        "text": "Fortunately, relatively \nlarge video databases exist, for example, the XM2TV database [Messer et al. 1999], the BANCA database \n[Bailly-Bailliere et al. 2003], and the addition of video into the FERET and FRVT2002 16Stereo is less \nsensitive to illumination change but still has dif.culty in\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 25
                            }
                        ],
                        "text": "The results of the M2VTS/XM2VTS projects can be used for a broad range \nof applications."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 206
                            }
                        ],
                        "text": "\u2026\nempirical evaluations of face recog\u00adnition techniques (FRT), including the FERET [Phillips et al. 1998b, \n2000; Rizvi et al. 1998], FRVT 2000 [Blackburn et al. 2001], FRVT 2002 [Phillips et al. 2003], and XM2VTS \n[Messer et al. 1999] pro\u00adtocols, and many commercially available systems (Table II)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 32
                            }
                        ],
                        "text": "The XM2VTS multimodal database [Messer et al. \n1999] contains four recordings of 295 subjects taken over a pe\u00adriod of 4 months."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "The XM2VTS multimodal database [7] contains four recordings of 295 subjects taken over a period of four months."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 109
                            }
                        ],
                        "text": "To emphasize \nthe importance of system evaluation, three sets of evalua\u00adtions were described: FERET, FRVT, and XM2VTS."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 103
                            }
                        ],
                        "text": "The M2VTS database contains .ve shots of each subject taken at sessions over a \nperiod of 3 months; the XM2VTS database contains eight shots of each subject taken at four sessions over \na period of 4 months (so that each session contains two repetitions of the sequence)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 212
                            }
                        ],
                        "text": "This is evidenced by the emergence of face recognition conferences such as AFGR [1] and AVBPA [2], and systematic empirical evaluations of face recognition techniques, including the FERET [3, 4, 5, 6] and XM2VTS [7] protocols."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "XM2VTSDB: The  Extended M2VTS Database,\" in Proceedings, International Conference on Audio-  and Video-Based Person Authentication"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[90] describes a system for video-based face recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 161
                            }
                        ],
                        "text": "After over twenty years of research on image sequence analysis [86, 87, 88, 89], only a little of that research had been applied to the face recognition problem [90, 91, 92, 93, 94, 95] up to the mid-nineties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "Detection and segmentation of face images is based on motion; the details are not described in [90] and it is indicated that the segmentation results can be imperfect."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "Video provides temporal continuity [90]; this allows reuse of classi cation information obtained from high-quality frames in processing low-quality frames."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Unconstrained Face Recognition from Im-  age"
            },
            "venue": {
                "fragments": [],
                "text": "Sequences,\" in Proceedings, International Conference on Automatic Face and  Gesture Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 167
                            }
                        ],
                        "text": "The earliest work on face recognition can \nbe traced back at least to the 1950s in psy\u00adchology [Bruner and Tagiuri 1954] and to the 1960s in the \nengineering literature [Bledsoe 1964]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 264
                            }
                        ],
                        "text": "\u2026exist, for example, .ngerprint analysis and retinal \nor iris scans, these methods rely on the cooperation of the participants, whereas a personal identi.cation \nsystem based on analysis of frontal or pro.le images of the face is often effective without the partici\u00adpant \ns cooperation or knowledge."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 150
                            }
                        ],
                        "text": "\u2026cards Drivers licenses, entitlement programs Immigration, national ID, \npassports, voter registration Welfare fraud Information security TV Parental control, personal device \nlogon, desktop logon Application security, database security, .le encryption Intranet security, internet \naccess, medical\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 213
                            }
                        ],
                        "text": "As a result, during the early and mid-1970s, typical \npattern clas\u00adsi.cation techniques, which use measured attributes of features (e.g., the distances between \nimportant points) in faces or face pro.les, were used [Bledsoe 1964; Kanade 1973; Kelly 1970]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 353,
                                "start": 345
                            }
                        ],
                        "text": "Available Table I. Typical Applications of Face Recognition \n Areas Speci.c applications Entertainment Video game, virtual reality, training programs Human-robot-interaction, \nhuman-computer-interaction Smart cards Drivers licenses, entitlement programs Immigration, national ID, \npassports, voter registration Welfare fraud Information security TV Parental control, personal device \nlogon, desktop logon Application security, database security, .le encryption Intranet security, internet \naccess, medical records Secure trading terminals Law enforcement and surveillance Advanced video surveillance, \nCCTV control Portal control, postevent analysis Shoplifting, suspect tracking and investigation Table \nII."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The model method in facial recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Panoramic research Inc"
            },
            "year": 1964
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "Many methods have been proposed for face recognition based on image intensities [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[9] gave a thorough survey of FRT at that time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "For a comprehensive review of this subject see [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "1 Basic techniques in video-based face processing In [9], four computer vision areas were mentioned as being important for video-based face recognition: segmentation of moving objects (humans) from a video sequence; structure estimation; 3-D models for faces; and non-rigid motion analysis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sirohey, \\Human and Machine Recognition of  Faces"
            },
            "venue": {
                "fragments": [],
                "text": "A Survey,\" Proc. IEEE,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 280
                            }
                        ],
                        "text": "\u2026draw\u00adings do not contain as much information as photographs, but they manage to cap\u00adture \nthe important characteristics of a face; experiments based on nonordinary faces comparing the usefulness \nof line\u00addrawing caricatures and unexaggerated line drawings decidedly favor the former [Bruce 1988]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Facial expression[29]: Based on neurophysiological studies, it seems that analysis of facial expressions is accomplished in parallel to face recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 36
                            }
                        ],
                        "text": "For example, .ndings in psychology [Bruce 1988; Shepherd et al. 1981] about \nthe rela\u00adtive importance of different facial features have been noted in the engineering liter\u00adature \n[Etemad and Chellappa 1997]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 58
                            }
                        ],
                        "text": "Such view has been \nlong held in the psychology community [Bruce 1988]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 43
                            }
                        ],
                        "text": "Ranking of signi.cance of facial features [Bruce 1988; Shepherd et al. \n1981]: Hair, face outline, eyes, and mouth (not nec\u00adessarily in this order) have been de\u00adtermined to \nbe important for perceiv\u00ading and remembering faces [Shepherd et al. 1981]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 1
                            }
                        ],
                        "text": "[Bruce 1988; Bruce \net al. 1998]: Both holistic and feature information are crucial for the percep\u00adtion and recognition of \nfaces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 27
                            }
                        ],
                        "text": "Caricatures [Brennan 1985; Bruce 1988; Perkins 1975]: A caricature can be for\u00admally \nde.ned [Perkins 1975] as a sym\u00adbol that exaggerates measurements rel\u00adative to any measure which varies \nfrom one person to another."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 214
                            }
                        ],
                        "text": "In face recogni\u00adtion using pro.les (which may be im\u00adportant in mugshot \nmatching applica\u00adtions, where pro.les can be extracted from side views), a distinctive nose shape could \nbe more important than the eyes or mouth [Bruce 1988]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 20
                            }
                        ],
                        "text": "Facial expressions [Bruce 1988]: Based on neurophysiological \nstudies, it seems that analysis of facial expressions is ac\u00adcomplished in parallel to face recogni\u00adtion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognizing Faces, London: Lawrence"
            },
            "venue": {
                "fragments": [],
                "text": "Erlbaum Associates,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 121
                            }
                        ],
                        "text": "Among appearance-based holistic approaches, eigenfaces [Kirby and Sirovich 1990; Turk and Pentland 1991] and Fisherfaces [Belhumeur et al. 1997; Etemad and Chellappa 1997; Zhao et al. 1998] have proved to be effective in experiments with large databases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 119
                            }
                        ],
                        "text": "It is well known that even holistic matching methods, for example, eigenfaces [Turk and Pentland 1991] and Fisherfaces [Belhumeur et al. 1997], need accurate locations of key facial features such as eyes, nose, and mouth to normalize the detected face [Martinez 2002; Yang et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 122
                            }
                        ],
                        "text": "Among appearance-based holistic approaches, \neigenfaces [Kirby and Sirovich 1990; Turk and Pentland 1991] and Fisher\u00adfaces [Belhumeur et al. 1997; \nEtemad and Chellappa 1997; Zhao et al. 1998] have proved to be effective in experiments with large databases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 166
                            }
                        ],
                        "text": "The authors re\u00adported improved face recognition perfor\u00admance \nas compared to eigenfaces [Turk and Pentland 1991], and better gen\u00aderalization capability than Fisherfaces \n[Belhumeur et al. 1997]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 145
                            }
                        ],
                        "text": "\u2026the point-to-point \ndistance with the distance between a point and the feature line linking two stored sample points [Li \nand Lu 1999]; Fisher\u00adfaces [Belhumeur et al. 1997; Liu and Wechsler 2001; Swets and Weng 1996b; Zhao \net al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA)\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 71
                            }
                        ],
                        "text": "Face recognition systems using LDA/FLD have also been very suc\u00adcessful [Belhumeur et al. 1997; \nEtemad and Chellappa 1997; Swets and Weng 1996b; Zhao et al. 1998; Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 150
                            }
                        ],
                        "text": "\u2026Pentland 1991] Probabilistic eigenfaces Two-class problem with prob. \nmeasure [Moghaddam and Pentland 1997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 447,
                                "start": 361
                            }
                        ],
                        "text": "Using principal-component analysis (PCA), many face recognition techniques have been developed: eigenfaces [Turk and Pentland 1991], which use a nearestneighbor classifier; feature-line-based methods, which replace the point-to-point distance with the distance between a point and the feature line linking two stored sample points [Li and Lu 1999]; Fisherfaces [Belhumeur et al. 1997; Liu and Wechsler 2001; Swets and Weng 1996b; Zhao et al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA) [Fisher 1938]; Bayesian methods, which use a probabilistic distance metric [Moghaddam and Pentland 1997]; and SVM methods, which use a support vector machine as the classifier [Phillips 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 165
                            }
                        ],
                        "text": "The authors reported improved face recognition performance as compared to eigenfaces [Turk and Pentland 1991], and better generalization capability than Fisherfaces [Belhumeur et al. 1997]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 120
                            }
                        ],
                        "text": "It is well known that even holistic matching \nmethods, for example, eigenfaces [Turk and Pentland 1991] and Fisherfaces [Belhumeur et al. 1997], need \naccurate locations of key facial features such as eyes, nose, and mouth to normal\u00adize the detected face \n[Martinez 2002; Yang et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 70
                            }
                        ],
                        "text": "Face recognition systems using LDA/FLD have also been very successful [Belhumeur et al. 1997; Etemad and Chellappa 1997; Swets and Weng 1996b; Zhao et al. 1998; Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Eigenfaces vs"
            },
            "venue": {
                "fragments": [],
                "text": "Fisherfaces: Recognition using class specific linear projection. IEEE Trans. Patt. Anal. Mach. Intell. 19, 711\u2013720."
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 356,
                                "start": 348
                            }
                        ],
                        "text": "This is evidenced by the emer\u00adgence of face recognition \nconferences such as the International Conference on Audio\u00adand Video-Based Authentication (AVBPA) since \n1997 and the International Con\u00adference on Automatic Face and Gesture Recognition (AFGR) since 1995, system\u00adatic \nempirical evaluations of face recog\u00adnition techniques (FRT), including the FERET [Phillips et al. 1998b, \n2000; Rizvi et al. 1998], FRVT 2000 [Blackburn et al. 2001], FRVT 2002 [Phillips et al. 2003], and XM2VTS \n[Messer et al. 1999] pro\u00adtocols, and many commercially available systems (Table II)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 687,
                                "start": 679
                            }
                        ],
                        "text": "Using principal-component \nanalysis (PCA), many face recognition techniques have been developed: eigenfaces [Turk and Pentland 1991], \nwhich use a nearest\u00adneighbor classi.er; feature-line-based methods, which replace the point-to-point \ndistance with the distance between a point and the feature line linking two stored sample points [Li \nand Lu 1999]; Fisher\u00adfaces [Belhumeur et al. 1997; Liu and Wechsler 2001; Swets and Weng 1996b; Zhao \net al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA) [Fisher 1938]; Bayesian methods, \nwhich use a probabilistic distance metric [Moghaddam and Pentland 1997]; and SVM methods, which use a \nsupport vector machine as the classi.er [Phillips 1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 69
                            }
                        ],
                        "text": "In Face Recognition: \nFrom The\u00adory to Applications, H. Wechsler, P. J. Phillips, V. Bruce, F. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 47
                            }
                        ],
                        "text": "In the recent com\u00adprehensive \nFERET evaluations [Phillips et al. 2000; Phillips et al. 1998b; Rizvi et al. 1998], aimed at evaluating \ndif\u00adferent systems using the same large database containing thousands of images, the systems described \nin Moghaddam and Pentland [1997]; Swets and Weng [1996b]; Turk and Pentland [1991]; Wiskott et al. [1997]; \nZhao et al. [1998], as well as others, were evaluated."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 715,
                                "start": 698
                            }
                        ],
                        "text": "The Sep96 evaluation tested the follow\u00ading 10 algorithms: \nan algorithm from Excalibur Corpora\u00adtion (Carlsbad, CA)(Sept. 1996); two algorithms from MIT Media Labo\u00adratory \n(Sept. 1996) [Moghaddam et al. 1996; Turk and Pentland 1991]; three linear discriminant analysis\u00adbased \nalgorithms from Michigan State University [Swets and Weng 1996b] (Sept. 1996) and the University of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997); a gray-scale projection algorithm \nfrom Rutgers University [Wilder 1994] (Sept. 1996); an Elastic Graph Matching algorithm from the University \nof Southern Cali\u00adfornia [Okada et al. 1998; Wiskott et al. 1997] (March 1997); a baseline PCA algorithm \n[Moon and Phillips 2001; Turk and Pentland 1991]; and a baseline normalized correlation matching algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 127
                            }
                        ],
                        "text": "An Elastic Graph Matching algorithm from the University of Southern California [79, 171] (March 1997) A baseline PCA algorithm [44, 172, 173] A baseline normalized correlation matching algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 85
                            }
                        ],
                        "text": "Different implemen\u00adtations of a PCA-based face recogni\u00adtion algorithm were compared in Moon \nand Phillips [2001]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 193
                            }
                        ],
                        "text": "A large performance improvement of this prob\u00adabilistic matching technique over stan\u00addard \nnearest-neighbor eigenspace match\u00ading was reported using large face datasets including the FERET database \n[Phillips et al. 2000]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 279
                            }
                        ],
                        "text": "Authors addresses: W. Zhao, \nVision Technologies Lab, Sarnoff Corporation, Princeton, NJ 08543-5300; email: wzhao@sarnoff.com; R. \nChellappa and A. Rosenfeld, Center for Automation Research, University of Maryland, College Park, MD \n20742-3275; email: {rama,ar}@cfar.umd.edu; P. J. Phillips, National Institute of Standards and Technology, \nGaithersburg, MD 20899; email: jonathon@nist.gov."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 46
                            }
                        ],
                        "text": "The Face Recogni\u00adtion Vendor Test (FRVT) 2002 [Phillips \net al. 2003]18 was a large-scale evalua\u00adtion of automatic face recognition technol\u00adogy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 486,
                                "start": 478
                            }
                        ],
                        "text": "Categorization of Still Face Recognition Techniques Approach Representative work Holistic \nmethods Principal-component analysis (PCA) Eigenfaces Direct application of PCA [Craw and Cameron 1996; \nKirby and Sirovich 1990; Turk and Pentland 1991] Probabilistic eigenfaces Two-class problem with prob. \nmeasure [Moghaddam and Pentland 1997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and Wechsler 2000a] Feature lines Point-to-line distance based [Li \nand Lu 1999] ICA ICA-based feature analysis [Bartlett et al. 1998] Other representations LDA/FLD LDA/FLD \non raw image [Etemad and Chellappa 1997] PDBNN Probabilistic decision based NN [Lin et al. 1997] Feature-based \nmethods Pure geometry methods Earlier methods [Kanade 1973; Kelly 1970]; recent methods [Cox et al. 1996; \nManjunath et al. 1992] Dynamic link architecture Graph matching methods [Okada et al. 1998; Wiskott et \nal."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 78
                            }
                        ],
                        "text": "Some of the advantages/disadvantages of different biometrics are described \nin Phillips et al. [1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 258
                            }
                        ],
                        "text": "The second FERET evaluation was adminis\u00ad 17http://www.itl.nist.gov/iad/humanid/feret/. \ntered in March 1995; it consisted of a sin\u00adgle test that measured identi.cation per\u00adformance from a gallery \nof 817 individ\u00aduals, and included 463 duplicates in the probe set [Phillips et al. 1998b]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 69
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Applications, H. Wechsler, P. J. Phillips, V. Bruce, \nF. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 69
                            }
                        ],
                        "text": "In \nFace Recognition: From Theory to Applica\u00adtions, H. Wechsler, P. J. Phillips, V. Bruce, F. F. Soulie, \nand T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 162
                            }
                        ],
                        "text": "Re\u00adcently, more extensive evaluations using commercial systems and thousands of im\u00adages have been \nperformed in the FRVT 2000 [Blackburn et al. 2001] and FRVT 2002 [Phillips et al. 2003] tests."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 48
                            }
                        ],
                        "text": "For details \nof the three FERET evaluations, see Phillips et al. [2000, 1998b] and Rizvi et al. [1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 114
                            }
                        ],
                        "text": "The vector comparison varies in different implementations and can \nin.uence the system s performance dramatically [Moon and Phillips 2001]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 69
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Applications, H. Wechsler, P. J. Phillips, V. Bruce, F. F. Soulie, \nand T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 18
                            }
                        ],
                        "text": "Moon and Phillips [172, 173] systematically compared di erent 31"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 80
                            }
                        ],
                        "text": "\u00adculty was documented in the FERET and FRVT test reports [Blackburn et al. 2001; Phillips \net al. 2002b, 2003], and was sug\u00adgested as a major research issue."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 64
                            }
                        ],
                        "text": "The .rst FERET evaluation \ntest was administered in August 1994 [Phillips et al. 1998b]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 68
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Applications,H. Wechsler, P. J. \nPhillips, V. Bruce, F. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 69
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Ap\u00adplications, H. Wechsler, P. J. Phillips, \nV. Bruce, F. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 33
                            }
                        ],
                        "text": "The se\u00adries of FERET evaluations [Phillips et al. 2000b, 1998; Rizvi et al. 1998]17 \nattracted nine institutions and companies to partic\u00adipate."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analysis of PCA-Based Face Recognition Algorithms,\"  in Empirical Evaluation Techniques in Computer Vision (K"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2995060"
                        ],
                        "name": "D. Swets",
                        "slug": "D.-Swets",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Swets",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Swets"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145926447"
                        ],
                        "name": "J. Weng",
                        "slug": "J.-Weng",
                        "structuredName": {
                            "firstName": "Juyang",
                            "lastName": "Weng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 144
                            }
                        ],
                        "text": "\u2026between a point and the feature line linking two stored sample points [Li \nand Lu 1999]; Fisher\u00adfaces [Belhumeur et al. 1997; Liu and Wechsler 2001; Swets and Weng 1996b; Zhao \net al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA) [Fisher 1938]; Bayesian methods, \nwhich use a\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 3
                            }
                        ],
                        "text": "In Wechsler et al. [1997], a fully auto\u00admatic person authentication system was described \nwhich included video break, face detection, and authentication modules."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 400,
                                "start": 384
                            }
                        ],
                        "text": "Using principal-component \nanalysis (PCA), many face recognition techniques have been developed: eigenfaces [Turk and Pentland 1991], \nwhich use a nearest\u00adneighbor classi.er; feature-line-based methods, which replace the point-to-point \ndistance with the distance between a point and the feature line linking two stored sample points [Li \nand Lu 1999]; Fisher\u00adfaces [Belhumeur et al. 1997; Liu and Wechsler 2001; Swets and Weng 1996b; Zhao \net al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA) [Fisher 1938]; Bayesian methods, \nwhich use a probabilistic distance metric [Moghaddam and Pentland 1997]; and SVM methods, which use a \nsupport vector machine as the classi.er [Phillips 1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 115
                            }
                        ],
                        "text": "An evolution pursuit-(EP-) based adap\u00adtive \nrepresentation and its application to face recognition were presented in Liu and Wechsler [2000a]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "In Face Recognition: \nFrom The\u00adory to Applications, H. Wechsler, P. J. Phillips, V. Bruce, F. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 304,
                                "start": 284
                            }
                        ],
                        "text": "The Sep96 evaluation tested the follow\u00ading 10 algorithms: \nan algorithm from Excalibur Corpora\u00adtion (Carlsbad, CA)(Sept. 1996); two algorithms from MIT Media Labo\u00adratory \n(Sept. 1996) [Moghaddam et al. 1996; Turk and Pentland 1991]; three linear discriminant analysis\u00adbased \nalgorithms from Michigan State University [Swets and Weng 1996b] (Sept. 1996) and the University of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997); a gray-scale projection algorithm \nfrom Rutgers University [Wilder 1994] (Sept. 1996); an Elastic Graph Matching algorithm from the University \nof Southern Cali\u00adfornia [Okada et al. 1998; Wiskott et al. 1997] (March 1997); a baseline PCA algorithm \n[Moon and Phillips 2001; Turk and Pentland 1991]; and a baseline normalized correlation matching algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 549,
                                "start": 533
                            }
                        ],
                        "text": "Categorization of Still Face Recognition Techniques Approach Representative work Holistic \nmethods Principal-component analysis (PCA) Eigenfaces Direct application of PCA [Craw and Cameron 1996; \nKirby and Sirovich 1990; Turk and Pentland 1991] Probabilistic eigenfaces Two-class problem with prob. \nmeasure [Moghaddam and Pentland 1997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and Wechsler 2000a] Feature lines Point-to-line distance based [Li \nand Lu 1999] ICA ICA-based feature analysis [Bartlett et al. 1998] Other representations LDA/FLD LDA/FLD \non raw image [Etemad and Chellappa 1997] PDBNN Probabilistic decision based NN [Lin et al. 1997] Feature-based \nmethods Pure geometry methods Earlier methods [Kanade 1973; Kelly 1970]; recent methods [Cox et al. 1996; \nManjunath et al. 1992] Dynamic link architecture Graph matching methods [Okada et al. 1998; Wiskott et \nal."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Applications, H. Wechsler, P. J. Phillips, V. Bruce, \nF. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 142
                            }
                        ],
                        "text": "Toward \nthat end, EP implements strategies characteristic of ge\u00adnetic algorithms (GAs) for searching the so-called \nenhanced FLD (EFM) approach [Liu and Wechsler 2000b]. space of possible solutions to determine the optimal \nbasis."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 142
                            }
                        ],
                        "text": "\u2026\n(Sept. 1996) [Moghaddam et al. 1996; Turk and Pentland 1991]; three linear discriminant analysis\u00adbased \nalgorithms from Michigan State University [Swets and Weng 1996b] (Sept. 1996) and the University of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997);\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "In \nFace Recognition: From Theory to Applica\u00adtions, H. Wechsler, P. J. Phillips, V. Bruce, F. F. Soulie, \nand T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 121
                            }
                        ],
                        "text": "Face recognition systems using LDA/FLD have also been very suc\u00adcessful [Belhumeur et al. 1997; \nEtemad and Chellappa 1997; Swets and Weng 1996b; Zhao et al. 1998; Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 233
                            }
                        ],
                        "text": "Categorization of Video-Based \nFace Recognition Techniques Approach Representative work Still-image methods Basic methods [Turk and \nPentland 1991; Lin et al. 1997; Moghaddam and Pentland 1997; Okada et al. 1998; Penev and Atick 1996; \nWechsler et al. 1997; Wiskott et al. 1997] Tracking-enhanced [Edwards et al. 1998; McKenna and Gong 1997, \n1998; Steffens et al. 1998] Multimodal methods Video-and audio-based [Bigun et al. 1998; Choudhury et \nal."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 148
                            }
                        ],
                        "text": "One ex\u00adample is the Probabilistic Decision-Based Neural Network \n(PDBNN) method [Lin et al. 1997] and the other is the evolution pursuit (EP) method [Liu and Wechsler \n2000a]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 144
                            }
                        ],
                        "text": "\u2026eigenfaces Two-class problem with prob. \nmeasure [Moghaddam and Pentland 1997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Applications, H. Wechsler, P. J. Phillips, V. Bruce, F. F. Soulie, \nand T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 52
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Applications,H. Wechsler, P. J. \nPhillips, V. Bruce, F. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Ap\u00adplications, H. Wechsler, P. J. Phillips, \nV. Bruce, F. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16456691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ca615e39db86897bf2cc628a5362d8d7297ac00",
            "isKey": true,
            "numCitedBy": 65,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The method we have been using is based on our Self-Organizing Hierarchical Optimal Subspace Learning and Inference Framework (SHOSLIF). It uses the theories of linear discriminant projection for automatic optimal feature selection in each of the internal nodes of a Space-Tessellation Tree. In this paper, we present our recent study on the applicability of the approach to variability in position, size, and 3D orientation. In the work presented here, we require \"well-framed\" images os input for recognition. By well-framed images we mean that only a relatively small variation in the size, position, and orientation of the objects in the input images is allowed. We report the experimental results that show the performance difference between the subspaces of linear discriminant analysis and the principle component analysis and the effect of using a tree as opposed to a flat eigenspace."
            },
            "slug": "Discriminant-analysis-and-eigenspace-partition-tree-Swets-Weng",
            "title": {
                "fragments": [],
                "text": "Discriminant analysis and eigenspace partition tree for face and object recognition from views"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents the experimental results that show the performance difference between the subspaces of linear discriminant analysis and the principle component analysis, and the effect of using a tree as opposed to a flat eigenspace."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "demonstrated on FERET datasets [63] and the MPEG-7 content set [69] in a proposal to MPEG-7 on robust face descriptors [70, 71]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 198
                            }
                        ],
                        "text": "Some authors have argued that there exists a uni\u00adversal \nface subspace of .xed dimension; hence for holistic recognition, image size does not matter as long as \nit exceeds the subspace dimensionality [Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 120
                            }
                        ],
                        "text": "Face recognition systems using Linear/Fisher Discriminant Analysis [55] as the classi er have also been very successful [56, 57, 58, 59, 60, 61, 62, 63]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 178
                            }
                        ],
                        "text": "To address the \nissue of varying albedo, a direct 2D-to-2D approach was proposed based on the assumption that front-view \nfaces are symmetric and making use of a generic 3D model [Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 126
                            }
                        ],
                        "text": "Three of the algorithms performed very well: probabilistic eigenface from MIT [Moghaddam et al. 1996], \nsub\u00adspace LDA from UMD [Zhao et al. 1998, 1999], and Elastic Graph Matching from USC [Wiskott et al. \n1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 52
                            }
                        ],
                        "text": "Improved \nrecognition results based on subspace LDA [Zhao et al. 1999] were reported on a small database consist\u00ading \nof frontal and quasipro.le images of 115 novel objects (size 48\u00d742)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 161
                            }
                        ],
                        "text": "Face recognition systems using LDA/FLD have also been very suc\u00adcessful [Belhumeur et al. 1997; \nEtemad and Chellappa 1997; Swets and Weng 1996b; Zhao et al. 1998; Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 138
                            }
                        ],
                        "text": "However, it has been demonstrated that the image size can be very small for holistic face recognition: \n12 \u00d7 11 for the subspace LDA system [Zhao et al. 1999], 14\u00d710 for the PDBNN system [Lin et al. 1997], \nand 18 \u00d7 24 for human percep\u00adtion [Bachmann 1991]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 199
                            }
                        ],
                        "text": "Using the Yale and Weizmann databases (Table V), signi.cant performance im\u00adprovements were reported when \nthe pro\u00adtotype images were used in a subspace LDA system in place of the original in\u00adput images [Zhao \net al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 65
                            }
                        ],
                        "text": "One way to unify PCA and LDA is to use regularized \nsubspace LDA [Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 44
                            }
                        ],
                        "text": "On the other hand, the \nsubspace LDA method [Zhao et al. 1999] works well for both large and small images, for example, 96 \u00d7 \n84 or 12 \u00d7 11."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 107
                            }
                        ],
                        "text": "Three of the algorithms performed very well: Probabilistic Eigenface from MIT [169], Subspace LDA from UMD [60, 63], and Elastic Graph Matching from USC [79]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Subspace Linear Discriminant Analy-  sis for Face Recognition,\" Technical Report CAR-TR-914, Center for Automation  Research"
            },
            "venue": {
                "fragments": [],
                "text": "University of Maryland,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 6
                            }
                        ],
                        "text": "Also, [103] tracks 2D features in 3D by deforming them, while [116] relies on direct comparison of a 3D model to the image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[103] tracks xed feature points (eyes, nose tip), while[116] tracks only points with high Hessian values."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 16
                            }
                        ],
                        "text": "For example, in [103] a face modeling system which estimates facial features and texture from a video stream is described."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 34
                            }
                        ],
                        "text": "Two tracking systems described in [103, 116] model faces completely with texture and geometry."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mixture of Eigenfeatures for Real-Time  Structure from Texture,\" Technical Report TR-440"
            },
            "venue": {
                "fragments": [],
                "text": "MIT Media Laboratory,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 16
                            }
                        ],
                        "text": "Recent studies [Sergent 1986] have shown that, depending on the spe\u00adci.c recognition task, \nthe low, band\u00adpass and high-frequency components may play different roles."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Later studies [22] showed that, depending on the recognition task, the low-, bandpass and high-frequency components may play di erent roles."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 170
                            }
                        ],
                        "text": "For example gender classi.cation \ncan be successfully accomplished using low-frequency com\u00adponents only, while identi.cation re\u00adquires \nthe use of high-frequency com\u00adponents [Sergent 1986]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 68
                            }
                        ],
                        "text": "The role \nof spatial frequency analysis [Ginsburg 1978; Harmon 1973; Sergent 1986]: Earlier studies [Ginsburg 1978; \nHarmon 1973] concluded that informa\u00adtion in low spatial frequency bands plays a dominant role in face \nrecog\u00adnition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Microgenesis of Face Perception,\" in Aspects of Face Processing (H"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 131
                            }
                        ],
                        "text": "However, with\u00adout \naccurate face and feature location, no\u00adticeable degradation in recognition perfor\u00admance is observed [Martinez \n2002; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 80
                            }
                        ],
                        "text": "Other \nheuristic methods based on frontal-face symmetry have also been proposed [Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 175
                            }
                        ],
                        "text": "For a limited class of objects such as face images that are normalized with respect to scale, trans\u00adlation, \nand rotation, the redundancy is even greater [Penev and Atick 1996; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 40
                            }
                        ],
                        "text": "They can be divided into three classes \n[Zhao 1999]: (1) multiview im\u00adage methods, when multiview database images of each person are available; \n(2) hybrid methods, when multiview training images are available during training but only one database \nimage per person is available during recognition;\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [52], a heuristic method based on face symmetry was proposed to enhance system performance under lighting changes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 235
                            }
                        ],
                        "text": "This claim has been supported by limited experiments \nusing normal\u00adized face images of different sizes, for 12Early work using range images was reported in \nGordon [1991]. example, from 12 \u00d7 11 to 48 \u00d7 42, to obtain different face subspaces [Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 171
                            }
                        ],
                        "text": "This is true even for holistic matching methods, since accurate location of key facial fea\u00adtures \nsuch as eyes is required to normal\u00adize the detected face [Yang et al. 2002; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 206
                            }
                        ],
                        "text": "In many systems, good recognition results are dependent on accurate feature (eyes, mouth) registration, and performance degradation is observed if the feature locations are not determined accurately enough [52]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 49
                            }
                        ],
                        "text": "These approaches \ncan be divided into four types [Zhao 1999]: (1) heuristic methods, for example, discarding the leading \nprincipal components; (2) im\u00adage comparison methods in which appro\u00adpriate image representations and distance \nmeasures are used; (3) class-based meth\u00adods using multiple images\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 100
                            }
                        ],
                        "text": "To assess the pose problem more sys\u00adtematically, an attempt has been made to classify pose problems [Zhao \n1999; Zhao and Chellappa 2000b]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 86
                            }
                        ],
                        "text": "A weighted distance metric \nin the pro\u00adjection space z was used to improve per\u00adformance [Zhao 1999].8 Finally, the LDA 7This makes \nsense because the .nal classi.cation is carried out in the projection space z by comparison with prestored \nprojection vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improving the Robustness of Face Recognition,\" in Proceedings, Inter-  national Conference on Audio- and Video-Based Person Authentication"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 69
                            }
                        ],
                        "text": "In the recent com\u00adprehensive \nFERET evaluations [Phillips et al. 2000; Phillips et al. 1998b; Rizvi et al. 1998], aimed at evaluating \ndif\u00adferent systems using the same large database containing thousands of images, the systems described \nin Moghaddam and Pentland [1997]; Swets and Weng [1996b];\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 149
                            }
                        ],
                        "text": "\u2026on Automatic Face and Gesture Recognition (AFGR) since 1995, system\u00adatic \nempirical evaluations of face recog\u00adnition techniques (FRT), including the FERET [Phillips et al. 1998b, \n2000; Rizvi et al. 1998], FRVT 2000 [Blackburn et al. 2001], FRVT 2002 [Phillips et al. 2003], and XM2VTS \n[Messer et\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 258
                            }
                        ],
                        "text": "The second FERET evaluation was adminis\u00ad 17http://www.itl.nist.gov/iad/humanid/feret/. \ntered in March 1995; it consisted of a sin\u00adgle test that measured identi.cation per\u00adformance from a gallery \nof 817 individ\u00aduals, and included 463 duplicates in the probe set [Phillips et al. 1998b]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "The .rst FERET evaluation \ntest was administered in August 1994 [Phillips et al. 1998b]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 33
                            }
                        ],
                        "text": "The se\u00adries of FERET evaluations [Phillips et al. 2000b, 1998; Rizvi et al. 1998]17 \nattracted nine institutions and companies to partic\u00adipate."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Biometric Image Processing and Recognition\", in Proceedings, European Signal Processing Conference"
            },
            "venue": {
                "fragments": [],
                "text": "\\Biometric Image Processing and Recognition\", in Proceedings, European Signal Processing Conference"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 32
                            }
                        ],
                        "text": "The series of FERET evaluations [3, 4, 5, 6] attracted many institutions and companies to participate."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 194
                            }
                        ],
                        "text": "This is evidenced by the emergence of face recognition conferences such as AFGR [1] and AVBPA [2], and systematic empirical evaluations of face recognition techniques (FRT), including the FERET [3, 4, 5, 6] and XM2VTS [7] protocols."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 75
                            }
                        ],
                        "text": "These two problems have been documented in many evaluations of FRT systems [4, 181] and in the divided opinions of the psychology community [24, 23, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 188
                            }
                        ],
                        "text": "This is evidenced by the emergence of face recognition conferences such as AFGR [1] and AVBPA [2], and systematic empirical evaluations of face recognition techniques, including the FERET [3, 4, 5, 6] and XM2VTS [7] protocols."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 43
                            }
                        ],
                        "text": "In a recent comprehensive FERET evaluation [3, 4, 5, 6], aimed at evaluating di erent systems using the same, large database containing thousands of images, the systems described in [33, 44, 56, 60, 79], as well as others were evaluated."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The FERET Evaluation Method-  ology for Face-Recognition Algorithms,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Com-  puter Vision and Pattern Recognition,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 99
                            }
                        ],
                        "text": "Compared to feature-based methods and template-matching \nmethods, appearance\u00ador image-based methods [Rowley et al. 1998; Sung and Poggio 1997] that train machine \nsystems on large numbers of samples have achieved the best results."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[38, 39] and the example-based learning approach of Sung and Poggio [30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 107
                            }
                        ],
                        "text": "Treating face detection as a two-class classi.cation problem helps to reduce false positives \ndramatically [Rowley et al. 1998; Sung and Poggio 1997] while maintaining true positives."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 39
                            }
                        ],
                        "text": "For technical details, please refer to [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "To handle faces at di erent angles, in [39] the authors propose using a router neural net to detect the angles of the faces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rotational Invariant Neural Network-  Based Face Detection,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and  Pattern Recognition,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 69
                            }
                        ],
                        "text": "In the recent com\u00adprehensive \nFERET evaluations [Phillips et al. 2000; Phillips et al. 1998b; Rizvi et al. 1998], aimed at evaluating \ndif\u00adferent systems using the same large database containing thousands of images, the systems described \nin Moghaddam and Pentland [1997]; Swets and Weng [1996b];\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 149
                            }
                        ],
                        "text": "\u2026on Automatic Face and Gesture Recognition (AFGR) since 1995, system\u00adatic \nempirical evaluations of face recog\u00adnition techniques (FRT), including the FERET [Phillips et al. 1998b, \n2000; Rizvi et al. 1998], FRVT 2000 [Blackburn et al. 2001], FRVT 2002 [Phillips et al. 2003], and XM2VTS \n[Messer et\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 258
                            }
                        ],
                        "text": "The second FERET evaluation was adminis\u00ad 17http://www.itl.nist.gov/iad/humanid/feret/. \ntered in March 1995; it consisted of a sin\u00adgle test that measured identi.cation per\u00adformance from a gallery \nof 817 individ\u00aduals, and included 463 duplicates in the probe set [Phillips et al. 1998b]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "The .rst FERET evaluation \ntest was administered in August 1994 [Phillips et al. 1998b]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "The advantages/disadvantages of di erent biometrics are described in [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 33
                            }
                        ],
                        "text": "The se\u00adries of FERET evaluations [Phillips et al. 2000b, 1998; Rizvi et al. 1998]17 \nattracted nine institutions and companies to partic\u00adipate."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Biometric Image Processing and  Recognition\", in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "European Signal Processing Conference,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 92
                            }
                        ],
                        "text": "In the recent com\u00adprehensive \nFERET evaluations [Phillips et al. 2000; Phillips et al. 1998b; Rizvi et al. 1998], aimed at evaluating \ndif\u00adferent systems using the same large database containing thousands of images, the systems described \nin Moghaddam and Pentland [1997]; Swets and Weng [1996b];\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 136
                            }
                        ],
                        "text": "Measuring the performance of FRT in a framework that models real-world settings was one of the three primary goals of the FERET program [166, 167, 168, 5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 32
                            }
                        ],
                        "text": "The series of FERET evaluations [3, 4, 5, 6] attracted many institutions and companies to participate."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 194
                            }
                        ],
                        "text": "This is evidenced by the emergence of face recognition conferences such as AFGR [1] and AVBPA [2], and systematic empirical evaluations of face recognition techniques (FRT), including the FERET [3, 4, 5, 6] and XM2VTS [7] protocols."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 148
                            }
                        ],
                        "text": "\u2026Recognition (AFGR) since 1995, system\u00adatic \nempirical evaluations of face recog\u00adnition techniques (FRT), including the FERET [Phillips et al. 1998b, \n2000; Rizvi et al. 1998], FRVT 2000 [Blackburn et al. 2001], FRVT 2002 [Phillips et al. 2003], and XM2VTS \n[Messer et al. 1999] pro\u00adtocols, and\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 60
                            }
                        ],
                        "text": "2 Evaluation For details of the three FERET evaluations see [166, 167, 168, 5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 188
                            }
                        ],
                        "text": "This is evidenced by the emergence of face recognition conferences such as AFGR [1] and AVBPA [2], and systematic empirical evaluations of face recognition techniques, including the FERET [3, 4, 5, 6] and XM2VTS [7] protocols."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 43
                            }
                        ],
                        "text": "In a recent comprehensive FERET evaluation [3, 4, 5, 6], aimed at evaluating di erent systems using the same, large database containing thousands of images, the systems described in [33, 44, 56, 60, 79], as well as others were evaluated."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 62
                            }
                        ],
                        "text": "The se\u00adries of FERET evaluations [Phillips et al. 2000b, 1998; Rizvi et al. 1998]17 \nattracted nine institutions and companies to partic\u00adipate."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Veri cation Protocol and Statistical Per-  formance Analysis for Face Recognition Algorithms,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Con-  ference on Computer Vision and Pattern Recognition,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 3
                            }
                        ],
                        "text": "In [Hill and Bruce 1996], the importance of top lighting for face recognition was demonstrated using a different task: matching surface images of faces to determine whether they were identical."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 27
                            }
                        ],
                        "text": "\u2014Effect of lighting change [Bruce et al. 1998; Hill and Bruce 1996; Johnston et al. 1992]: It has long been informally observed that photographic negatives of faces are difficult to recognize."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 46
                            }
                        ],
                        "text": "Effect of lighting change [Bruce et al. 1998; Hill \nand Bruce 1996; Johnston et al. 1992]: It has long been informally observed that photographic negatives \nof faces are dif.cult to recognize."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 4
                            }
                        ],
                        "text": "In [Hill and Bruce 1996], the importance of top lighting for face recognition \nwas demon\u00adstrated using a different task: match\u00ading surface images of faces to determine whether they \nwere identical."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Effects of lighting on matching facial surfaces"
            },
            "venue": {
                "fragments": [],
                "text": "J. Exp. Psych.: Human Percept. Perform. 22, 986\u20131004."
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 94
                            }
                        ],
                        "text": "Finally, the fourth column shows real images that \nare close to the prototype images [Zhao and Chellappa 2000]. local SFS algorithm [Tsai and Shah 1994]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 172
                            }
                        ],
                        "text": "Among appearance-based holistic approaches, \neigenfaces [Kirby and Sirovich 1990; Turk and Pentland 1991] and Fisher\u00adfaces [Belhumeur et al. 1997; \nEtemad and Chellappa 1997; Zhao et al. 1998] have proved to be effective in experiments with large databases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 187
                            }
                        ],
                        "text": "For example, .ndings in psychology [Bruce 1988; Shepherd et al. 1981] about \nthe rela\u00adtive importance of different facial features have been noted in the engineering liter\u00adature \n[Etemad and Chellappa 1997]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Experimental re\u00adsults using images/videos collected at UMD, NIST/USF, and CMU with pose/illumination \nvariations have illus\u00adtrated the effectiveness of this approach in both still-to-video and video-to-video \nscenarios with appropriate model choices."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 64
                            }
                        ],
                        "text": "The EBGM sys\u00adtem [Wiskott et al. 1997], the subspace \nLDA system [Zhao et al. 1998], and the probabilistic eigenface system [Moghad\u00addam and Pentland 1997] \nwere judged to be among the top three, with each method showing different levels of performance on different \nsubsets of sequestered images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 120
                            }
                        ],
                        "text": "Face recognition systems using Linear/Fisher Discriminant Analysis [55] as the classi er have also been very successful [56, 57, 58, 59, 60, 61, 62, 63]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 10
                            }
                        ],
                        "text": "In Li and Chellappa [2001], a face ver\u00adi.cation system based on tracking facial features \nwas presented."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 396,
                                "start": 389
                            }
                        ],
                        "text": "The Sep96 evaluation tested the follow\u00ading 10 algorithms: \nan algorithm from Excalibur Corpora\u00adtion (Carlsbad, CA)(Sept. 1996); two algorithms from MIT Media Labo\u00adratory \n(Sept. 1996) [Moghaddam et al. 1996; Turk and Pentland 1991]; three linear discriminant analysis\u00adbased \nalgorithms from Michigan State University [Swets and Weng 1996b] (Sept. 1996) and the University of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997); a gray-scale projection algorithm \nfrom Rutgers University [Wilder 1994] (Sept. 1996); an Elastic Graph Matching algorithm from the University \nof Southern Cali\u00adfornia [Okada et al. 1998; Wiskott et al. 1997] (March 1997); a baseline PCA algorithm \n[Moon and Phillips 2001; Turk and Pentland 1991]; and a baseline normalized correlation matching algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 167
                            }
                        ],
                        "text": "The authors selected the dimension\u00adality of the universal face subspace based on the \ncharacteristics of the eigenvectors (face-like or not) instead of the eigenval\u00adues [Zhao et al. 1998], \nas is commonly done."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 25
                            }
                        ],
                        "text": "In 1995, a review paper [Chellappa \net al. 1995] gave a thorough survey of FRT at that time."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 65
                            }
                        ],
                        "text": "Some details about \nthe tracking algo\u00adrithm are as follows [Li and Chellappa 2001]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 12
                            }
                        ],
                        "text": "In Zhao and Chellappa [2000b], \na uni.ed approach was proposed to solving both the pose and illumination problems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 147
                            }
                        ],
                        "text": "\u2026analysis\u00adbased \nalgorithms from Michigan State University [Swets and Weng 1996b] (Sept. 1996) and the University of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997); a gray-scale projection algorithm \nfrom Rutgers University [Wilder 1994] (Sept. 1996); an\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 129
                            }
                        ],
                        "text": "Authors addresses: W. Zhao, \nVision Technologies Lab, Sarnoff Corporation, Princeton, NJ 08543-5300; email: wzhao@sarnoff.com; R. \nChellappa and A. Rosenfeld, Center for Automation Research, University of Maryland, College Park, MD \n20742-3275; email: {rama,ar}@cfar.umd.edu; P. J. Phillips, National Institute of Standards and Technology, \nGaithersburg, MD 20899; email: jonathon@nist.gov."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 70
                            }
                        ],
                        "text": "This method is a natural \nextension of the method proposed in Zhao and Chellappa [2000] to handle the illumination problem."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 22
                            }
                        ],
                        "text": "These meth\u00adods [Li and Chellappa \n2001; Li et al. 2001a] coherently exploit both spatial in\u00adformation (in each frame) and temporal in\u00adformation \n(such as the trajectories of fa\u00adcial features)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 150
                            }
                        ],
                        "text": "\u2026and the feature line linking two stored sample points [Li \nand Lu 1999]; Fisher\u00adfaces [Belhumeur et al. 1997; Liu and Wechsler 2001; Swets and Weng 1996b; Zhao \net al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA) [Fisher 1938]; Bayesian methods, \nwhich use a probabilistic distance\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 741,
                                "start": 734
                            }
                        ],
                        "text": "Categorization of Still Face Recognition Techniques Approach Representative work Holistic \nmethods Principal-component analysis (PCA) Eigenfaces Direct application of PCA [Craw and Cameron 1996; \nKirby and Sirovich 1990; Turk and Pentland 1991] Probabilistic eigenfaces Two-class problem with prob. \nmeasure [Moghaddam and Pentland 1997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and Wechsler 2000a] Feature lines Point-to-line distance based [Li \nand Lu 1999] ICA ICA-based feature analysis [Bartlett et al. 1998] Other representations LDA/FLD LDA/FLD \non raw image [Etemad and Chellappa 1997] PDBNN Probabilistic decision based NN [Lin et al. 1997] Feature-based \nmethods Pure geometry methods Earlier methods [Kanade 1973; Kelly 1970]; recent methods [Cox et al. 1996; \nManjunath et al. 1992] Dynamic link architecture Graph matching methods [Okada et al. 1998; Wiskott et \nal."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 126
                            }
                        ],
                        "text": "Three of the algorithms performed very well: probabilistic eigenface from MIT [Moghaddam et al. 1996], \nsub\u00adspace LDA from UMD [Zhao et al. 1998, 1999], and Elastic Graph Matching from USC [Wiskott et al. \n1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 143
                            }
                        ],
                        "text": "Face recognition systems using LDA/FLD have also been very suc\u00adcessful [Belhumeur et al. 1997; \nEtemad and Chellappa 1997; Swets and Weng 1996b; Zhao et al. 1998; Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 145
                            }
                        ],
                        "text": "\u2026problem with prob. \nmeasure [Moghaddam and Pentland 1997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and Wechsler 2000a] Feature\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 62
                            }
                        ],
                        "text": "1999] Spatiotemporal methods Feature trajectory-based [Li and Chellappa 2001; Li et al. 2001a] Video-to \nvideo methods [Zhou et al. 2003] while Strom et al. [1999] tracked only points with high Hessian values."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "However, for veri.cation, \nthe equal error rates were 2% and 14% for USC, and 1% and 12% for UMD."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 83
                            }
                        ],
                        "text": "Tracking also plays a key role in spatiotemporal-based recognition methods [Li and Chellappa 2001; Li \net al. 2001a] which directly use the tracking in\u00adformation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 52
                            }
                        ],
                        "text": "Basic Techniques \nof Video-Based Face Recognition In Chellappa et al. [1995], four computer vision areas were mentioned \nas being im\u00adportant for video-based face recognition: segmentation of moving objects (humans) from a \nvideo sequence; structure estima\u00adtion; 3D models for faces; and nonrigid mo\u00adtion analysis."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 96
                            }
                        ],
                        "text": "A recent paper on using .ow\u00adbased SfM techniques for face modeling is A. K. R. Chowdhury, and R. Chellappa \n[2003]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 120
                            }
                        ],
                        "text": "To assess the pose problem more sys\u00adtematically, an attempt has been made to classify pose problems [Zhao \n1999; Zhao and Chellappa 2000b]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 75
                            }
                        ],
                        "text": "8Weighted metrics have also been used in the pure LDA approach [Etemad and Chellappa \n1997] and the Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 196
                            }
                        ],
                        "text": "The series of tests has allowed advances in algorithm de\u00advelopment to \nbe quanti.ed for exam\u00adple, the performance improvements in the MIT algorithms between March 1995 and \nSeptember 1996, and in the UMD al\u00adgorithms between September 1996 and March 1997."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "For identi.cation, on the fb and duplicate \nprobes, the USC scores were 94% and 59%, and the UMD scores were 96% and 47%."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 195
                            }
                        ],
                        "text": "The .rst row shows the .rst .ve pure LDA basis images \nW ; the second row shows the .rst .ve subspace LDA basis images W <; the average face and .rst four eigenfaces \n< are shown on the third row [Zhao et al. 1998].  their respective means mi: Ci =E[(x(.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 85
                            }
                        ],
                        "text": "Numerous methods have been proposed for face recognition based on image in\u00adtensities [Chellappa et al. \n1995]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Empirical Performance Analysis  of Linear Discriminant Classi ers,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer  Vision and Pattern Recognition,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 46
                            }
                        ],
                        "text": "Effect of lighting change [Bruce et al. 1998; Hill \nand Bruce 1996; Johnston et al. 1992]: It has long been informally observed that photographic negatives \nof faces are dif.cult to recognize."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [27], the importance of top lighting for face recognition, using the task of matching surface images of faces for identity, is demonstrated."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 24
                            }
                        ],
                        "text": "E ect of lighting change[12, 15, 27]: It has long been informally observed that photographic negatives of faces are di cult to recognize."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 4
                            }
                        ],
                        "text": "In [Hill and Bruce 1996], the importance of top lighting for face recognition \nwas demon\u00adstrated using a different task: match\u00ading surface images of faces to determine whether they \nwere identical."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "E ects of Lighting on Matching Facial Surfaces,"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of  Experimental Psychology: Human Perception and Performance,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 131
                            }
                        ],
                        "text": "However, with\u00adout \naccurate face and feature location, no\u00adticeable degradation in recognition perfor\u00admance is observed [Martinez \n2002; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 80
                            }
                        ],
                        "text": "Other \nheuristic methods based on frontal-face symmetry have also been proposed [Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 175
                            }
                        ],
                        "text": "For a limited class of objects such as face images that are normalized with respect to scale, trans\u00adlation, \nand rotation, the redundancy is even greater [Penev and Atick 1996; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 40
                            }
                        ],
                        "text": "They can be divided into three classes \n[Zhao 1999]: (1) multiview im\u00adage methods, when multiview database images of each person are available; \n(2) hybrid methods, when multiview training images are available during training but only one database \nimage per person is available during recognition;\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 235
                            }
                        ],
                        "text": "This claim has been supported by limited experiments \nusing normal\u00adized face images of different sizes, for 12Early work using range images was reported in \nGordon [1991]. example, from 12 \u00d7 11 to 48 \u00d7 42, to obtain different face subspaces [Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 171
                            }
                        ],
                        "text": "This is true even for holistic matching methods, since accurate location of key facial fea\u00adtures \nsuch as eyes is required to normal\u00adize the detected face [Yang et al. 2002; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 49
                            }
                        ],
                        "text": "These approaches \ncan be divided into four types [Zhao 1999]: (1) heuristic methods, for example, discarding the leading \nprincipal components; (2) im\u00adage comparison methods in which appro\u00adpriate image representations and distance \nmeasures are used; (3) class-based meth\u00adods using multiple images\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 100
                            }
                        ],
                        "text": "To assess the pose problem more sys\u00adtematically, an attempt has been made to classify pose problems [Zhao \n1999; Zhao and Chellappa 2000b]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 86
                            }
                        ],
                        "text": "A weighted distance metric \nin the pro\u00adjection space z was used to improve per\u00adformance [Zhao 1999].8 Finally, the LDA 7This makes \nsense because the .nal classi.cation is carried out in the projection space z by comparison with prestored \nprojection vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Improving the Robustness of Face Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Audio-and Video-Based Person Authentication"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 62
                            }
                        ],
                        "text": "This method is an extension of the 3D linear subspace method [Hallinan 1994; Shashua 1994] and has the \nsame drawback, requiring at least three aligned training images acquired under different lighting con\u00additions \nper person."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 112
                            }
                        ],
                        "text": "An interesting comparison was made between the \nproposed method and the 3D linear illumination subspace methods [Hallinan 1994; Shashua 1994]; the 3D \nlinear methods are just .rst-order harmonic approximations without the DC components."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 154
                            }
                        ],
                        "text": "3 Class-Based Approaches Under the assumptions of Lambertian surfaces and no shadowing, a 3D linear illumination subspace for a person was constructed in [66, 67, 184, 185] for a xed viewpoint, using three aligned faces/images acquired under di erent lighting conditions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 61
                            }
                        ],
                        "text": "This method is an extension of the 3D linear subspace method [66, 67] and also requires three aligned training images acquired under di erent lighting conditions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "Experiments were performed on a database of 500 images described in [67] and a database of 176 images created at Yale."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Low-Dimensional Representation of Human Faces for Arbitrary  Lighting Conditions,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and  Pattern Recognition,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "The systems presented in [76] and [77] were based on the Dynamic Link Architecture (DLA)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Both [76] and [77] used Gabor based wavelets for the features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 178
                            }
                        ],
                        "text": "One of the most successful systems in \nthis cate\u00adgory is the graph matching system [Okada et al. 1998; Wiskott et al. 1997], which is based \non the Dynamic Link Architec\u00adture (DLA) [Buhmann et al. 1990; Lades et al. 1993]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 159
                            }
                        ],
                        "text": "One of the most \nsuccessful of these systems is the Elas\u00adtic Bunch Graph Matching (EBGM) sys\u00adtem [Okada et al. 1998; Wiskott \net al. 1997], which is based on DLA [Buhmann et al. 1990; Lades et al. 1993]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Size and Distortion Invariant Ob-  ject Recognition by Hierarchiacal Graph Matching,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International  Joint Conference on Neural Networks,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 42
                            }
                        ],
                        "text": "\u2014Is face recognition a dedicated process? [Biederman and Kalocsai 1998; Ellis 1986; Gauthier et al. 1999; Gauthier and Logothetis 2000]: It is traditionally believed that face recognition is a dedicated process different from other object recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 194
                            }
                        ],
                        "text": "\u2026with issues such as \nwhether face perception is a dedicated process (this issue is still be\u00ading debated in the psychology \ncommunity [Biederman and Kalocsai 1998; Ellis 1986; Gauthier et al. 1999; Gauthier and Logo\u00adthetis 2000]) \nand whether it is done holis\u00adtically or by local feature analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 13
                            }
                        ],
                        "text": "According to [Gauthier and Logothetis 2000], recent neuroimaging studies in humans indicate that level of categorization and expertise interact to produce the specification for faces in the middle fusiform gyrus."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 14
                            }
                        ],
                        "text": "Accord\u00ading to [Gauthier and Logothetis 2000], recent neuroimaging \nstudies in humans indicate that level of categorization and expertise interact to produce the speci\u00ad.cation \nfor faces in the middle fusiform gyrus.3 Hence it is possible that the en\u00adcoding scheme used for faces \nmay also be\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 187
                            }
                        ],
                        "text": "Psychophysicists and neuroscientists have been concerned with issues such as whether face perception is a dedicated process (this issue is still being debated in the psychology community [Biederman and Kalocsai 1998; Ellis 1986; Gauthier et al. 1999; Gauthier and Logothetis 2000]) and whether it is done holistically or by local feature analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 6
                            }
                        ],
                        "text": "1999; Gauthier and Logothetis 2000]: It is traditionally be\u00adlieved that face recognition is a dedi\u00adcated \nprocess different from other ob\u00adject recognition tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Is face recognition so unique after All? J"
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Neuropsych. 17, 125\u2013142."
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 131
                            }
                        ],
                        "text": "However, with\u00adout \naccurate face and feature location, no\u00adticeable degradation in recognition perfor\u00admance is observed [Martinez \n2002; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 80
                            }
                        ],
                        "text": "Other \nheuristic methods based on frontal-face symmetry have also been proposed [Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 175
                            }
                        ],
                        "text": "For a limited class of objects such as face images that are normalized with respect to scale, trans\u00adlation, \nand rotation, the redundancy is even greater [Penev and Atick 1996; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 40
                            }
                        ],
                        "text": "They can be divided into three classes \n[Zhao 1999]: (1) multiview im\u00adage methods, when multiview database images of each person are available; \n(2) hybrid methods, when multiview training images are available during training but only one database \nimage per person is available during recognition;\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 235
                            }
                        ],
                        "text": "This claim has been supported by limited experiments \nusing normal\u00adized face images of different sizes, for 12Early work using range images was reported in \nGordon [1991]. example, from 12 \u00d7 11 to 48 \u00d7 42, to obtain different face subspaces [Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 171
                            }
                        ],
                        "text": "This is true even for holistic matching methods, since accurate location of key facial fea\u00adtures \nsuch as eyes is required to normal\u00adize the detected face [Yang et al. 2002; Zhao 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 49
                            }
                        ],
                        "text": "These approaches \ncan be divided into four types [Zhao 1999]: (1) heuristic methods, for example, discarding the leading \nprincipal components; (2) im\u00adage comparison methods in which appro\u00adpriate image representations and distance \nmeasures are used; (3) class-based meth\u00adods using multiple images\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 100
                            }
                        ],
                        "text": "To assess the pose problem more sys\u00adtematically, an attempt has been made to classify pose problems [Zhao \n1999; Zhao and Chellappa 2000b]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 86
                            }
                        ],
                        "text": "A weighted distance metric \nin the pro\u00adjection space z was used to improve per\u00adformance [Zhao 1999].8 Finally, the LDA 7This makes \nsense because the .nal classi.cation is carried out in the projection space z by comparison with prestored \nprojection vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust Image Based 3D Face Recognition, Ph.D. dissertation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 4
                            }
                        ],
                        "text": "In [Johnston et al. 1992], experiments were conducted to explore \nwhether dif.culties with nega\u00adtive images and inverted images of faces arise because each of these manipula\u00adtions \nreverses the apparent direction of lighting, rendering a top-lit image of a face apparently lit from \nbelow."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "For example, a possible engineering explanation of the lighting e ect illustrated in [12] is as follows: for familiar faces a 3D model is usually built in memory; when the actual lighting direction is opposite to the usually assumed direction, a shape-from-shading algorithm recovers incorrect structural information and hence makes recognition of faces harder."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [12], experiments were conducted to explore whether di culties with negative images of faces, and inverted images of faces, arise because each of these manipulations reverses the apparent direction of lighting, rendering a top-lit image of a face as if lit from below."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 24
                            }
                        ],
                        "text": "It was demonstrated in [Johnston et al. 1992] that bottom lighting does indeed make it harder \nto identity familiar faces."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 24
                            }
                        ],
                        "text": "E ect of lighting change[12, 15, 27]: It has long been informally observed that photographic negatives of faces are di cult to recognize."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 67
                            }
                        ],
                        "text": "Effect of lighting change [Bruce et al. 1998; Hill \nand Bruce 1996; Johnston et al. 1992]: It has long been informally observed that photographic negatives \nof faces are dif.cult to recognize."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognizing Faces: E ects of Lighting  Direction"
            },
            "venue": {
                "fragments": [],
                "text": "Inversion and Brightness Reversal,\" Cognition,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 62
                            }
                        ],
                        "text": "Also, [103] tracks 2D features in 3D by deforming them, while [116] relies on direct comparison of a 3D model to the image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 55
                            }
                        ],
                        "text": "[103] tracks xed feature points (eyes, nose tip), while[116] tracks only points with high Hessian values."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [116], real-time 3D modeling and tracking of faces is described; a generic 3D head model is aligned to match frontal views of the face in a video sequence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 34
                            }
                        ],
                        "text": "Two tracking systems described in [103, 116] model faces completely with texture and geometry."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Real Time Tracking and Modeling  of Faces: An EKF-based Analysis by Synthesis Approach,\" Technical Report TR"
            },
            "venue": {
                "fragments": [],
                "text": "MIT Media Laboratory,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 144
                            }
                        ],
                        "text": "\u2026between a point and the feature line linking two stored sample points [Li \nand Lu 1999]; Fisher\u00adfaces [Belhumeur et al. 1997; Liu and Wechsler 2001; Swets and Weng 1996b; Zhao \net al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA) [Fisher 1938]; Bayesian methods, \nwhich use a\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 3
                            }
                        ],
                        "text": "In Wechsler et al. [1997], a fully auto\u00admatic person authentication system was described \nwhich included video break, face detection, and authentication modules."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 400,
                                "start": 384
                            }
                        ],
                        "text": "Using principal-component \nanalysis (PCA), many face recognition techniques have been developed: eigenfaces [Turk and Pentland 1991], \nwhich use a nearest\u00adneighbor classi.er; feature-line-based methods, which replace the point-to-point \ndistance with the distance between a point and the feature line linking two stored sample points [Li \nand Lu 1999]; Fisher\u00adfaces [Belhumeur et al. 1997; Liu and Wechsler 2001; Swets and Weng 1996b; Zhao \net al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA) [Fisher 1938]; Bayesian methods, \nwhich use a probabilistic distance metric [Moghaddam and Pentland 1997]; and SVM methods, which use a \nsupport vector machine as the classi.er [Phillips 1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 115
                            }
                        ],
                        "text": "An evolution pursuit-(EP-) based adap\u00adtive \nrepresentation and its application to face recognition were presented in Liu and Wechsler [2000a]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "In Face Recognition: \nFrom The\u00adory to Applications, H. Wechsler, P. J. Phillips, V. Bruce, F. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 120
                            }
                        ],
                        "text": "Face recognition systems using Linear/Fisher Discriminant Analysis [55] as the classi er have also been very successful [56, 57, 58, 59, 60, 61, 62, 63]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 304,
                                "start": 284
                            }
                        ],
                        "text": "The Sep96 evaluation tested the follow\u00ading 10 algorithms: \nan algorithm from Excalibur Corpora\u00adtion (Carlsbad, CA)(Sept. 1996); two algorithms from MIT Media Labo\u00adratory \n(Sept. 1996) [Moghaddam et al. 1996; Turk and Pentland 1991]; three linear discriminant analysis\u00adbased \nalgorithms from Michigan State University [Swets and Weng 1996b] (Sept. 1996) and the University of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997); a gray-scale projection algorithm \nfrom Rutgers University [Wilder 1994] (Sept. 1996); an Elastic Graph Matching algorithm from the University \nof Southern Cali\u00adfornia [Okada et al. 1998; Wiskott et al. 1997] (March 1997); a baseline PCA algorithm \n[Moon and Phillips 2001; Turk and Pentland 1991]; and a baseline normalized correlation matching algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 549,
                                "start": 533
                            }
                        ],
                        "text": "Categorization of Still Face Recognition Techniques Approach Representative work Holistic \nmethods Principal-component analysis (PCA) Eigenfaces Direct application of PCA [Craw and Cameron 1996; \nKirby and Sirovich 1990; Turk and Pentland 1991] Probabilistic eigenfaces Two-class problem with prob. \nmeasure [Moghaddam and Pentland 1997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and Wechsler 2000a] Feature lines Point-to-line distance based [Li \nand Lu 1999] ICA ICA-based feature analysis [Bartlett et al. 1998] Other representations LDA/FLD LDA/FLD \non raw image [Etemad and Chellappa 1997] PDBNN Probabilistic decision based NN [Lin et al. 1997] Feature-based \nmethods Pure geometry methods Earlier methods [Kanade 1973; Kelly 1970]; recent methods [Cox et al. 1996; \nManjunath et al. 1992] Dynamic link architecture Graph matching methods [Okada et al. 1998; Wiskott et \nal."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Applications, H. Wechsler, P. J. Phillips, V. Bruce, \nF. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 142
                            }
                        ],
                        "text": "Toward \nthat end, EP implements strategies characteristic of ge\u00adnetic algorithms (GAs) for searching the so-called \nenhanced FLD (EFM) approach [Liu and Wechsler 2000b]. space of possible solutions to determine the optimal \nbasis."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 282
                            }
                        ],
                        "text": "Four methods are compared: 1) a correlation-based method, 2) a variant of the linear subspace method suggested in [66], 3) an eigenface method [43, 44], and 4) a Fisher-face method which uses subspace projection prior to LDA projection to avoid the possible singularity in Sw as in [56, 57]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 142
                            }
                        ],
                        "text": "\u2026\n(Sept. 1996) [Moghaddam et al. 1996; Turk and Pentland 1991]; three linear discriminant analysis\u00adbased \nalgorithms from Michigan State University [Swets and Weng 1996b] (Sept. 1996) and the University of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997);\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "In \nFace Recognition: From Theory to Applica\u00adtions, H. Wechsler, P. J. Phillips, V. Bruce, F. F. Soulie, \nand T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 121
                            }
                        ],
                        "text": "Face recognition systems using LDA/FLD have also been very suc\u00adcessful [Belhumeur et al. 1997; \nEtemad and Chellappa 1997; Swets and Weng 1996b; Zhao et al. 1998; Zhao et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 233
                            }
                        ],
                        "text": "Categorization of Video-Based \nFace Recognition Techniques Approach Representative work Still-image methods Basic methods [Turk and \nPentland 1991; Lin et al. 1997; Moghaddam and Pentland 1997; Okada et al. 1998; Penev and Atick 1996; \nWechsler et al. 1997; Wiskott et al. 1997] Tracking-enhanced [Edwards et al. 1998; McKenna and Gong 1997, \n1998; Steffens et al. 1998] Multimodal methods Video-and audio-based [Bigun et al. 1998; Choudhury et \nal."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 148
                            }
                        ],
                        "text": "One ex\u00adample is the Probabilistic Decision-Based Neural Network \n(PDBNN) method [Lin et al. 1997] and the other is the evolution pursuit (EP) method [Liu and Wechsler \n2000a]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 144
                            }
                        ],
                        "text": "\u2026eigenfaces Two-class problem with prob. \nmeasure [Moghaddam and Pentland 1997] Fisherfaces/subspace LDA FLD on eigenspace [Belhumeur et al. 1997; \nSwets and Weng 1996b; Zhao et al. 1998] SVM Two-class problem based on SVM [Phillips 1998] Evolution \npursuit Enhanced GA learning [Liu and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Applications, H. Wechsler, P. J. Phillips, V. Bruce, F. F. Soulie, \nand T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 456,
                                "start": 452
                            }
                        ],
                        "text": "of the determinant of the between-class scatter matrix of the projected samples to the within-class scatter matrix of the projected samples: J (T ) = jT TSbT j jT TSwT j: (11) Let us denote the optimal projection matrix which maximizes J (T ) by W ; then W can be obtained by solving the generalized eigenvalue problem [65] SbW = SwW W (12) In [56], a face image retrieval system is reported based on discriminant analysis of the eigenfeatures, and in [57], a framework based on LDA for general object recognition is described."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 52
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Applications,H. Wechsler, P. J. \nPhillips, V. Bruce, F. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "In Face Recognition: From Theory to Ap\u00adplications, H. Wechsler, P. J. Phillips, \nV. Bruce, F. F. Soulie, and T. S. Huang, Eds."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminant Analysis and Eigenspace Partition Tree for  Face and Object Recognition fromViews,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference  on Automatic Face and Gesture Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[128] demonstrated successful facial expression recognition in extensive laboratory experiments involving 40 subjects as well as in television and movie sequences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [128], a tracking system based on local parameterized models is used for recognizing facial expressions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 132
                            }
                        ],
                        "text": "Feature region tracking addresses the simpler problem of tracking a region such as a bounding box that surrounds the facial feature [128]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tracking and Recognizing Facial Expressions in Image  Sequences, Using Local Parametrized Models of Image Motion,"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report  CS-TR-3401,"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113881386"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "R",
                                "obert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 203705211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71d67283157475c4e6460c52408c00e9f6b8d2fe",
            "isKey": false,
            "numCitedBy": 2357,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-morphable-model-for-the-synthesis-of-3D-faces-Turk",
            "title": {
                "fragments": [],
                "text": "A morphable model for the synthesis of 3D faces"
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH 1999"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "148954033"
                        ],
                        "name": "\u5171\u7acb\u51fa\u7248\u682a\u5f0f\u4f1a\u793e",
                        "slug": "\u5171\u7acb\u51fa\u7248\u682a\u5f0f\u4f1a\u793e",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\u5171\u7acb\u51fa\u7248\u682a\u5f0f\u4f1a\u793e",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u5171\u7acb\u51fa\u7248\u682a\u5f0f\u4f1a\u793e"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 199984869,
            "fieldsOfStudy": [],
            "id": "64cfe81049b1ba5828f81aa0d665cde80b1e6e9d",
            "isKey": false,
            "numCitedBy": 1221,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30fb\u30b5\u30a4\u30a8\u30f3\u30b9-:-ACM-computing-surveys-\u5171\u7acb\u51fa\u7248\u682a\u5f0f\u4f1a\u793e",
            "title": {
                "fragments": [],
                "text": "\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30fb\u30b5\u30a4\u30a8\u30f3\u30b9 : ACM computing surveys"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678200"
                        ],
                        "name": "J. Bruner",
                        "slug": "J.-Bruner",
                        "structuredName": {
                            "firstName": "J\u00e9r\u00f4me",
                            "lastName": "Bruner",
                            "middleNames": [
                                "Seymour"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bruner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16836886"
                        ],
                        "name": "R. Tagiuri",
                        "slug": "R.-Tagiuri",
                        "structuredName": {
                            "firstName": "Renato",
                            "lastName": "Tagiuri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tagiuri"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 191
                            }
                        ],
                        "text": "\u2026exist, for example, .ngerprint analysis and retinal \nor iris scans, these methods rely on the cooperation of the participants, whereas a personal identi.cation \nsystem based on analysis of frontal or pro.le images of the face is often effective without the partici\u00adpant \ns cooperation or knowledge."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 146212264,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "41d85e989edf6110504f992dd645e26389be6dbe",
            "isKey": false,
            "numCitedBy": 557,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "THE-PERCEPTION-OF-PEOPLE-Bruner-Tagiuri",
            "title": {
                "fragments": [],
                "text": "THE PERCEPTION OF PEOPLE"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1954
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068932761"
                        ],
                        "name": "J. Shepherd",
                        "slug": "J.-Shepherd",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Shepherd",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shepherd"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 141151290,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "1cdcd08a03a50174fe3188c0df164fbc317cc25c",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Studies-of-cue-saliency-Shepherd",
            "title": {
                "fragments": [],
                "text": "Studies of cue saliency"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144308522"
                        ],
                        "name": "J. Watts",
                        "slug": "J.-Watts",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Watts",
                            "middleNames": [
                                "M.",
                                "Jr."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Watts"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 113231691,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "6d26d851e5b83f6dea2f195a66502338461704f9",
            "isKey": false,
            "numCitedBy": 356,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Analysis-and-synthesis-Watts",
            "title": {
                "fragments": [],
                "text": "Analysis and synthesis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49353544"
                        ],
                        "name": "R. Fisher",
                        "slug": "R.-Fisher",
                        "structuredName": {
                            "firstName": "Rory",
                            "lastName": "Fisher",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 139
                            }
                        ],
                        "text": "\u2026[Belhumeur et al. 1997; Liu and Wechsler 2001; Swets and Weng 1996b; Zhao \net al. 1998] which use linear/Fisher discriminant analysis (FLD/LDA) [Fisher 1938]; Bayesian methods, \nwhich use a probabilistic distance metric [Moghaddam and Pentland 1997]; and SVM methods, which use a\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 85013676,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "3bbec310cdce1fd06ea198a91c160a594611a87a",
            "isKey": false,
            "numCitedBy": 862,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "THE-STATISTICAL-UTILIZATION-OF-MULTIPLE-Fisher",
            "title": {
                "fragments": [],
                "text": "THE STATISTICAL UTILIZATION OF MULTIPLE MEASUREMENTS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1938
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586918"
                        ],
                        "name": "D. Stork",
                        "slug": "D.-Stork",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stork",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stork"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32533286"
                        ],
                        "name": "M. Hennecke",
                        "slug": "M.-Hennecke",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Hennecke",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hennecke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62963960,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cffcccb8686e13ffc51902455aed624186920478",
            "isKey": false,
            "numCitedBy": 206,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speechreading-by-Humans-and-Machines-Stork-Hennecke",
            "title": {
                "fragments": [],
                "text": "Speechreading by Humans and Machines"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64321642,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ac243459eb0a0ab8a102ec7137ba1ad7f367e9a",
            "isKey": false,
            "numCitedBy": 557,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-Pattern-Recognition-Fukunaga",
            "title": {
                "fragments": [],
                "text": "Statistical Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Handbook of Pattern Recognition and Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096470352"
                        ],
                        "name": "Peter L. Hallinan",
                        "slug": "Peter-L.-Hallinan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hallinan",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter L. Hallinan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 34
                            }
                        ],
                        "text": "1993] and facial feature tracking [Terzopoulos and Waters 1993; Yuille and Hallinan 1992]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 64095949,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53d690032bea58545159972402930c331628f8d4",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Deformable-templates-Yuille-Hallinan",
            "title": {
                "fragments": [],
                "text": "Deformable templates"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60735762,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71c0f082a41c7f0b102c3ca9e4cf6b31f361d06a",
            "isKey": false,
            "numCitedBy": 4228,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Introduction-to-statistical-pattern-recognition-Fukunaga",
            "title": {
                "fragments": [],
                "text": "Introduction to statistical pattern recognition (2nd ed.)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 79
                            }
                        ],
                        "text": ", the distances between important points) in faces or face profiles, were used [Bledsoe 1964; Kanade 1973; Kelly 1970]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 101
                            }
                        ],
                        "text": "[Kelly 1970], or the distances and angles between eye corners, mouth extrema, nostrils, and chin top [Kanade 1973]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 38
                            }
                        ],
                        "text": "Pure geometry methods Earlier methods [Kanade 1973; Kelly 1970]; recent"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59895060,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0892bb0b8209cf0d7be9ee3041eac9e27f1499fd",
            "isKey": false,
            "numCitedBy": 340,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-recognition-of-human-faces-Kanade",
            "title": {
                "fragments": [],
                "text": "Computer recognition of human faces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51064498"
                        ],
                        "name": "Zhengyou Zhang",
                        "slug": "Zhengyou-Zhang",
                        "structuredName": {
                            "firstName": "Zhengyou",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengyou Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59829574,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fd8cfdabc36fee91338a74ec367dd028d93b59e",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "3D-Dynamic-Scene-Analysis-Zhang-Faugeras",
            "title": {
                "fragments": [],
                "text": "3D Dynamic Scene Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143920486"
                        ],
                        "name": "F. Samaria",
                        "slug": "F.-Samaria",
                        "structuredName": {
                            "firstName": "Ferdinando",
                            "lastName": "Samaria",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Samaria"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 65
                            }
                        ],
                        "text": "Kelly 1970] as well as 1D [Samaria and Young 1994] and pseudo-2D [Samaria 1994] HMM methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 169
                            }
                        ],
                        "text": "Without finding the exact locations of facial features, Hidden Markov Model(HMM-) based methods use strips of pixels that cover the forehead, eye, nose, mouth, and chin [Nefian and Hayes 1998; Samaria 1994; Samaria and Young 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60852986,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf6884b04be618ab9154609f9e62e73c86ad3feb",
            "isKey": false,
            "numCitedBy": 309,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Face-recognition-using-Hidden-Markov-Models-Samaria",
            "title": {
                "fragments": [],
                "text": "Face recognition using Hidden Markov Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7351757"
                        ],
                        "name": "L. D. Harmon",
                        "slug": "L.-D.-Harmon",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Harmon",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D. Harmon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 56
                            }
                        ],
                        "text": "The role of spatial frequency analysis: Earlier studies [20, 21] concluded that information in low spatial frequency bands plays a dominant role in face recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5325266,
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "id": "4115b6ea2691118e157999d5924fee54edc52c27",
            "isKey": false,
            "numCitedBy": 393,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-recognition-of-faces.-Harmon",
            "title": {
                "fragments": [],
                "text": "The recognition of faces."
            },
            "venue": {
                "fragments": [],
                "text": "Scientific American"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1484027981"
                        ],
                        "name": "P. Thompson",
                        "slug": "P.-Thompson",
                        "structuredName": {
                            "firstName": "Pete",
                            "lastName": "Thompson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Thompson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 32492890,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "251ff66577e04d493170cb969e4a1d7979eb5480",
            "isKey": false,
            "numCitedBy": 631,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Margaret-Thatcher:-A-New-Illusion-Thompson",
            "title": {
                "fragments": [],
                "text": "Margaret Thatcher: A New Illusion"
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5083719"
                        ],
                        "name": "R. F.",
                        "slug": "R.-F.",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "F.",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. F."
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4134792,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9cb87e945b81a526a59e19e2e27d494d88b56e23",
            "isKey": false,
            "numCitedBy": 2286,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Mathematical-Statistics-R.",
            "title": {
                "fragments": [],
                "text": "Mathematical Statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1944
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49353544"
                        ],
                        "name": "R. Fisher",
                        "slug": "R.-Fisher",
                        "structuredName": {
                            "firstName": "Rory",
                            "lastName": "Fisher",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29084021,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "ab21376e43ac90a4eafd14f0f02a0c87502b6bbf",
            "isKey": false,
            "numCitedBy": 13266,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "THE-USE-OF-MULTIPLE-MEASUREMENTS-IN-TAXONOMIC-Fisher",
            "title": {
                "fragments": [],
                "text": "THE USE OF MULTIPLE MEASUREMENTS IN TAXONOMIC PROBLEMS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1936
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144881353"
                        ],
                        "name": "D. Perkins",
                        "slug": "D.-Perkins",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Perkins",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Perkins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 39
                            }
                        ],
                        "text": "Caricatures [Brennan 1985; Bruce 1988; Perkins 1975]: A caricature can be for\u00admally \nde.ned [Perkins 1975] as a sym\u00adbol that exaggerates measurements rel\u00adative to any measure which varies \nfrom one person to another."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31140513,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "a0360def5675bc09e572922ba05b4fe21a0e4029",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Definition-of-Caricature-and-Caricature-and-Perkins",
            "title": {
                "fragments": [],
                "text": "A Definition of Caricature and Caricature and Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145778742"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Juang",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60838227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "81d734347d5d6732be09493180387bd640d3490f",
            "isKey": false,
            "numCitedBy": 625,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-tutorial-on-Hidden-Markov-Models-Rabiner-Juang",
            "title": {
                "fragments": [],
                "text": "A tutorial on Hidden Markov Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136478"
                        ],
                        "name": "P. Grother",
                        "slug": "P.-Grother",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Grother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Grother"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 75
                            }
                        ],
                        "text": "Previous work on the evaluation of OCR and ngerprint classi cation systems [164, 165] provided insights into how the evaluation of algorithms and systems can be performed e ciently."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60882981,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b103253be683ed1b502764678181682ecd7cca74",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We report recognition results for several pattern classifiers trained and tested on disjoint sets of 30620 digits selected from the first 500 writers of NIST Special Database 3. The classifiers are ubiquitous in traditional pattern recognition literature (minimum distance, maximum a posteriori, nearest neighbor) as well as neural network literature (multilayer perceptron, radial basis functions, probabilistic neural network). For the purpose of valid comparison of classifiers fixed sets of Karhunen-Loeve Transforms, were used as features. These were produced from images preprocessed using the fixed methods for size and orientation normalization. The \u201cKmeans\u201d clustering algorithm is used to produce subclasses thereby supervising training and aiding recognition. Graphical displays of classification and associated confidences illustrate classifier complexity. Recognition error rates for all the classifiers are tabulated as a function of feature vector dimension. Computational and memory requirements of the different classifiers are also compared."
            },
            "slug": "Comparison-of-Handprinted-Digit-Classifiers-Grother",
            "title": {
                "fragments": [],
                "text": "Comparison of Handprinted Digit Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "Recognition results for several pattern classifiers trained and tested on disjoint sets of 30620 digits selected from the first 500 writers of NIST Special Database 3.0 are reported."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2498129"
                        ],
                        "name": "G. Granlund",
                        "slug": "G.-Granlund",
                        "structuredName": {
                            "firstName": "G\u00f6sta",
                            "lastName": "Granlund",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Granlund"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5598902,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cac4acd9a721a9075393c4273270e444f1bd2f6b",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-Sequence-Analysis-Granlund",
            "title": {
                "fragments": [],
                "text": "Image Sequence Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "DAGM-Symposium"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 63
                            }
                        ],
                        "text": "Early efforts focused on the .rst two problems: head \ntracking [Azarbayejani et al. 1993] and facial feature track\u00ading [Terzopoulos and Waters 1993; Yuille \nand Hallinan 1992]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 236467223,
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IEEE TRANS. ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 Face Photo-Sketch Synthesis and Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 71
                            }
                        ],
                        "text": "We list here only books [86, 87, 106, 107, 108, 109] and review papers [110, 111, 112]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the Computation of Motion from Se-  quences of Images,"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Duc, \\Face Authentication using Morphological Dynamical Link Architecture"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Audio-and Video-Based Person Authentication"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 24
                            }
                        ],
                        "text": "Methods are proposed in [130, 131] to solve the varying appearance problem in tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Framework for Modelling Appearance  Change in Image Sequences,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Com-  puter Vision,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 65
                            }
                        ],
                        "text": "Several experiments have been conducted using the rst four shots [175, 176, 177, 178, 179, 180], with the goals of investigating text-dependent speaker veri cation from speech text-independent speaker veri cation from speech facial feature extraction and tracking from moving images veri cation from an overall frontal view veri cation from lip shape veri cation from depth information (obtained using structured light) veri cation from a pro le synchronization of speech and lip movement 39"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bigun, \\Person Authentication by Fusing  Face and Speech Recognition,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Audio-  and Video-Based Person Authentication,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 61
                            }
                        ],
                        "text": "Early e orts focussed on the rst two problems: head tracking [126, 127] and facial feature tracking [121, 122]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 63
                            }
                        ],
                        "text": "Early efforts focused on the .rst two problems: head \ntracking [Azarbayejani et al. 1993] and facial feature track\u00ading [Terzopoulos and Waters 1993; Yuille \nand Hallinan 1992]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recursive Estimation of Struc-  ture and Motion Using Relative Orientation Constraints,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE  Conference on Computer Vision and Pattern Recognition,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 21
                            }
                        ],
                        "text": "person are available [191, 192, 193, 194], 2) hybrid methods when multiple images are available during training but only one database image per person is available during recognition [80, 195, 196, 197], and 3) single image based methods when no training is carried out."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Accurate  and Robust Face Identi cation Scheme,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference  on Pattern Recognition,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "M2VTS Multimodal Face Database"
            },
            "venue": {
                "fragments": [],
                "text": "M2VTS Multimodal Face Database"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 109
                            }
                        ],
                        "text": "This was experimentally observed in [181] using a dataset of 25 individuals, and was theoretically proved in [182] for systems based on eigenface projection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 61
                            }
                        ],
                        "text": "This method is a natural extension of the method proposed in [182] to handle the illumination problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 54
                            }
                        ],
                        "text": "To overcome the constant albedo issue, the authors of [68, 182] proposed using a varying albedo re ectance model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust Face Recognition using Symmetric Shape-  from-Shading,\" Technical Report CAR-TR-919, Center for Automation Research"
            },
            "venue": {
                "fragments": [],
                "text": "University of Maryland,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A definition of caricature and recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Stud. Anthro. Vis. Commun"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 234
                            }
                        ],
                        "text": "However, it has been demonstrated that the image size can be very small for holistic face recognition: \n12 \u00d7 11 for the subspace LDA system [Zhao et al. 1999], 14\u00d710 for the PDBNN system [Lin et al. 1997], \nand 18 \u00d7 24 for human percep\u00adtion [Bachmann 1991]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 40
                            }
                        ],
                        "text": "1997], and 18 \u00d7 24 for human perception [Bachmann 1991]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Identification of spatially quantized tachistoscopic images of faces: How many pixels does it take to carry identity? European J"
            },
            "venue": {
                "fragments": [],
                "text": "Cog. Psych. 3, 87\u2013103."
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 65
                            }
                        ],
                        "text": "Several experiments have been conducted using the rst four shots [175, 176, 177, 178, 179, 180], with the goals of investigating text-dependent speaker veri cation from speech text-independent speaker veri cation from speech facial feature extraction and tracking from moving images veri cation from an overall frontal view veri cation from lip shape veri cation from depth information (obtained using structured light) veri cation from a pro le synchronization of speech and lip movement 39"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shape Normalization for Face Recognition,\" in Proceedings,  International Conference on Audio- and Video-Based Person Authentication, pp"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 58
                            }
                        ],
                        "text": "3D Models for Faces 3D models of faces have been employed [113, 114, 115] in the model-based image compression literature by several research groups."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Facial Motion Analysis and Synthesis with Applica-  tion to Model-Based Coding,\" in Motion Analysis and Image Sequence Processing  (M"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 79
                            }
                        ],
                        "text": "Many papers on this subject have appeared over the past 15 years; examples are [156, 157, 158]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lip reading: Automatic Visual Recognition of Spoken  Words,"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report 117, MIT Media Laboratory,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 249
                            }
                        ],
                        "text": "\u2026methods are less sensi\u00adtive to variations in illumination and viewpoint \nand to inaccuracy in face local\u00ad 1There have been recent advances on 3D face recogni\u00adtion in situations \nwhere range data acquired through structured light can be matched reliably [Bronstein et al. 2003]. ization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 265
                            }
                        ],
                        "text": "\u2026\nBioID sensor fusion http://www.bioid.com Visionsphere Technologies http://www.visionspheretech.com/menu.htm \nBiometric Systems, Inc. http://www.biometrica.com/ FaceSnap Recoder http://www.facesnap.de/htdocs/english/index2.html \nSpotIt for face composite http://spotit.itc.it/SpotIt.html Fig."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3D face recognition using geometric invariants"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Audio-and Video-Based Person Authen- tication"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A comparison of two computer-based face recognition systems with human perceptions of faces"
            },
            "venue": {
                "fragments": [],
                "text": "Vis. Res"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A comparison of two computer-based face recognition systems with human perceptions of faces"
            },
            "venue": {
                "fragments": [],
                "text": "Vis. Res"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Accurate and Robust Face Identiication Scheme"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 65
                            }
                        ],
                        "text": "More recently, a method based on a quotient image was introduced [187]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Quotient Image: Class Based Re-rendering  and Recognition with Varying Illuminations,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on  Computer Vision and Pattern Recognition,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tracking and recognizing facial expressions in image sequences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Beymer, \\Face Recognition Under Varying Pose"
            },
            "venue": {
                "fragments": [],
                "text": "Beymer, \\Face Recognition Under Varying Pose"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 44
                            }
                        ],
                        "text": "A recently proposed image comparison method [183] used a new measure robust to illumination change."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Comparing Images under Variable  Illumination,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and Pattern  Recognition,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[50] proposes an edge-based approach to accurately detecting two-dimensional shapes including faces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Edge-Based Shape Detection,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Image Processing,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 101
                            }
                        ],
                        "text": "Non-rigid Motion Analysis A nal area of relevance to FRT is the motion analysis of non-rigid objects [117, 118, 119, 120]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modeling, Analysis and Visualization of Non-rigid Object Motion,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Pattern Recognition,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 199
                            }
                        ],
                        "text": "Research on human emotion recognition has been extended to a new area | a ective computing [124], in which cues such as facial expressions and body movements, as well as psychological data, are used [125]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Picard, \\A ective Pattern Classi cation,\" Technical Report  TR-473"
            },
            "venue": {
                "fragments": [],
                "text": "MIT Media Laboratory,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face recognition based on depth maps and surface curvature Geometric Methods in Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "SPIE Proceedings"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 101
                            }
                        ],
                        "text": "Non-rigid Motion Analysis A nal area of relevance to FRT is the motion analysis of non-rigid objects [117, 118, 119, 120]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modeling, Analysis and Visualization of Non-rigid Object Motion,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Pattern Recognition,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 199
                            }
                        ],
                        "text": "Research on human emotion recognition has been extended to a new area | a ective computing [124], in which cues such as facial expressions and body movements, as well as psychological data, are used [125]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Picard, \\A ective Pattern Classi cation,\" Technical Report  TR-473"
            },
            "venue": {
                "fragments": [],
                "text": "MIT Media Laboratory,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nandhakumar, \\Empirical Performance Analysis of Linear Discriminant Classiiers"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 56
                            }
                        ],
                        "text": "The role of spatial frequency analysis: Earlier studies [20, 21] concluded that information in low spatial frequency bands plays a dominant role in face recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 40
                            }
                        ],
                        "text": "The role \nof spatial frequency analysis [Ginsburg 1978; Harmon 1973; Sergent 1986]: Earlier studies [Ginsburg 1978; \nHarmon 1973] concluded that informa\u00adtion in low spatial frequency bands plays a dominant role in face \nrecog\u00adnition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visual Information Processing Based on Spatial Filters Con-  strained by Biological Data,\" AMRL"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report,"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Invariant Features for 3D Gesture Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Analysis Techniques for Image Sequences"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Pattern Recognition"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "One of the earliest demonstrations of NN for face recall applications used Kohonen's associative map [72]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Self-Organization and Associative Memory, Berlin: Springer-Verlag"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 79
                            }
                        ],
                        "text": "Many papers on this subject have appeared over the past 15 years; examples are [156, 157, 158]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic Lipreading to Enchance Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "PhD Thesis,"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[74] describes an NN approach to gender classi cation using a vector of sixteen numerical attributes such as eyebrow thickness, widths of nose and mouth, six chin radii, etc."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "HyperBF Networks for Gender Classi cation,\" in Pro-  ceedings"
            },
            "venue": {
                "fragments": [],
                "text": "DARPA Image Understanding Workshop,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Shape Normalization for Face Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Audio-and Video-Based Person Authentication"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 106
                            }
                        ],
                        "text": "Early ap\u00adproaches focused on individual features; for example, \na template-based approach was described in [Hallinan 1991] to de\u00adtect and recognize the human eye in \na frontal face."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "SPIE Proceedings Geometric Methods in Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "SPIE Proceedings Geometric Methods in Computer Vision"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modelling face dynamics across view and over time"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings , International Conference on Computer Vision"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 71
                            }
                        ],
                        "text": "We list here only books [86, 87, 106, 107, 108, 109] and review papers [110, 111, 112]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analysis Techniques for Image Sequences,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "Interna-  tional Conference on Pattern Recognition,"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 71
                            }
                        ],
                        "text": "Flow eld based methods for segmenting humans in motion are reported in [105]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 84
                            }
                        ],
                        "text": "More so\u00adphisticated methods use estimated .ow \n.elds for segmenting humans in mo\u00adtion [Shio and Sklansky 1991]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Segmentation of People in Motion,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE  Workshop on Visual Motion,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 67
                            }
                        ],
                        "text": "The XM2VTS database is an expan\u00adsion of the earlier M2VTS database [Pigeon and Vandendorpe \n1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 65
                            }
                        ],
                        "text": "Several experiments have been conducted using the rst four shots [175, 176, 177, 178, 179, 180], with the goals of investigating text-dependent speaker veri cation from speech text-independent speaker veri cation from speech facial feature extraction and tracking from moving images veri cation from an overall frontal view veri cation from lip shape veri cation from depth information (obtained using structured light) veri cation from a pro le synchronization of speech and lip movement 39"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pro le Authentication Using a Chamfer Matching  Algorithm,\" in Proceedings, International Conference on Audio- and Video-Based  Person Authentication"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 39
                            }
                        ],
                        "text": "For technical details, please refer to [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Finding Faces in Cluttered Scene using  Random Labeled Graph Matching,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on  Computer Vision,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Faceless identification"
            },
            "venue": {
                "fragments": [],
                "text": "Face Recognition: From Theory to Applications"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Received July"
            },
            "venue": {
                "fragments": [],
                "text": "Received July"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 39
                            }
                        ],
                        "text": "For technical details, please refer to [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Detection with Information-Based Max-  imum Discriminant,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and  Pattern Recognition,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 118
                            }
                        ],
                        "text": "Newly developed segmentation methods locate the face and estimate its pose simultaneously without extracting features [Gu et al. 2001; Li et al. 2001b]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 33
                            }
                        ],
                        "text": "The multiview dynamic face model [Li et al. 2001b] consists of a sparse Point Distribution Model (PDM) [Cootes et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modelling face dynamics across view and over time"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Computer Vision."
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 27
                            }
                        ],
                        "text": "This method is extended in [197] to include an additive error term for better synthesis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 183
                            }
                        ],
                        "text": "person are available [191, 192, 193, 194], 2) hybrid methods when multiple images are available during training but only one database image per person is available during recognition [80, 195, 196, 197], and 3) single image based methods when no training is carried out."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Novel 3-D Objects Under New Illumination  and Viewing Position Using a Small Number of Example Views or Even a Single  View,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and Pattern Recog-  nition,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Charles Darwin\u2019s The Expression of the Emotions in Man and Animals, Third Edition, with Introduction, Afterwords and Commentaries by Paul Ekman"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 39
                            }
                        ],
                        "text": "Caricatures [Brennan 1985; Bruce 1988; Perkins 1975]: A caricature can be for\u00admally \nde.ned [Perkins 1975] as a sym\u00adbol that exaggerates measurements rel\u00adative to any measure which varies \nfrom one person to another."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\A Deenition of Caricature and Recognition,\" Studies in the Anthropology of Visual Communication"
            },
            "venue": {
                "fragments": [],
                "text": "\\A Deenition of Caricature and Recognition,\" Studies in the Anthropology of Visual Communication"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[51] presents a method of extracting pertinent feature points from a face image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 176
                            }
                        ],
                        "text": "\u20261997] PDBNN Probabilistic decision based NN [Lin et al. 1997] Feature-based \nmethods Pure geometry methods Earlier methods [Kanade 1973; Kelly 1970]; recent methods [Cox et al. 1996; \nManjunath et al. 1992] Dynamic link architecture Graph matching methods [Okada et al. 1998; Wiskott et \nal."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [51], a Gabor wavelet based feature extraction method is proposed for face recognition which is robust to smallangle rotations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Feature Based Approach  to Face Recognition,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and  Pattern Recognition,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 58
                            }
                        ],
                        "text": "3D Models for Faces 3D models of faces have been employed [113, 114, 115] in the model-based image compression literature by several research groups."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model-Based Image Sequence Coding,\" inMotion Analysis  and Image Sequence Processing (M"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [154], a vision system is described that monitors activities in a site over extended periods of time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adaptive Tracking  to Classify and Monitor Activities in a Site,\\ in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on  Computer Vision and Pattern Recognition,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Malsburg, \\A Feature Based Approach to Face Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lades, and C. v. d. Malsburg, \\Size and Distortion Invariant Object Recognition by Hierarchiacal Graph Matching"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Joint Conference on Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[142] described a general framework for learning-based hand sign recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning-based Hand Sign Recognition,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Automatic Face and Gesture Recognition,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 161
                            }
                        ],
                        "text": "After over twenty years of research on image sequence analysis [86, 87, 88, 89], only a little of that research had been applied to the face recognition problem [90, 91, 92, 93, 94, 95] up to the mid-nineties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "An access control system based on person authentication is described in [91]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 165
                            }
                        ],
                        "text": "\u2026et al. 1997; Moghaddam and Pentland 1997; Okada et al. 1998; Penev and Atick 1996; \nWechsler et al. 1997; Wiskott et al. 1997] Tracking-enhanced [Edwards et al. 1998; McKenna and Gong 1997, \n1998; Steffens et al. 1998] Multimodal methods Video-and audio-based [Bigun et al. 1998; Choudhury et \nal."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Non-intrusive Person Authentication for Access Con-  trol by Visual Tracking and Face Recognition,\" in Proceedings, International Con-  ference on Audio- and Video-Based Person Authentication"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 44
                            }
                        ],
                        "text": "In the engineering literature, early e orts [123, 135] were based on analysis of the optical ow eld of the image sequence, which provides clues to the spatial changes in the facial features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Emotion Recognition from Mo-  tion Using a Radial Basis Function Network Architecture,\" in Proceedings, Work-  shop on Motion of Non-rigid and Articulated Objects"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 3
                            }
                        ],
                        "text": "In [146, 147] the body is modeled by rigid segments that meet at joints."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Towards 3D Model-Based Tracking and Recogni-  tion of Human Movement: A Multi-View Approach,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International  Conference on Automatic Face and Gesture Recognition,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 91
                            }
                        ],
                        "text": "A template-based ap\u00adproach to detecting the eyes and mouth in real images was \npresented in [Yuille et al. 1992]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 17
                            }
                        ],
                        "text": "Some of the work [121, 122] is potentially useful in face recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 100
                            }
                        ],
                        "text": "Early e orts focussed on the rst two problems: head tracking [126, 127] and facial feature tracking [121, 122]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Templates,\" in Active Vision (A. Blake and  A"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 47
                            }
                        ],
                        "text": "Video-Based Object Segmentation Early attempts [44, 104] at segmenting moving faces from an image sequence used simple pixel-based change detection procedures based on di erence images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evidence from Multiple Views of 3-D  Objects,"
            },
            "venue": {
                "fragments": [],
                "text": "in SPIE Proceedings,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic modelling of local Appearance and spatial reationships for object recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings , IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Malsburg, \\Face Recognition and Gender Determination"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Workshop on Automatic Face and Gesture Recognition"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [152] a real-time system (the W 4 system) for detecting/tracking people and monitoring their activities in an outdoor environment is described."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "W 4 | Who, Where, When, What: A  Real-Time System for Detecting and Tracking People,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "Interna-  tional Conference on Automatic Face and Gesture Recognition,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[143] applied an elastic graph matching based approach to gesture recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust Classi cation of Hand Posture against  Complex Background,"
            },
            "venue": {
                "fragments": [],
                "text": "in Proceedings, International Conference on Automatic  Face and Gesture Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 161
                            }
                        ],
                        "text": "After over twenty years of research on image sequence analysis [86, 87, 88, 89], only a little of that research had been applied to the face recognition problem [90, 91, 92, 93, 94, 95] up to the mid-nineties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "System For Tracking and Rec-  ognizing Multiple People with Multiple Cameras,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International  Conference on Audio- and Video-Based Person Authentication,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Charles Darwin's The Expression of the Emotions in Man and Animals, Third Edition, with Introduction, Afterwords and Commentaries by Paul Ekman"
            },
            "venue": {
                "fragments": [],
                "text": "Charles Darwin's The Expression of the Emotions in Man and Animals, Third Edition, with Introduction, Afterwords and Commentaries by Paul Ekman"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 95
                            }
                        ],
                        "text": "One possible way to improve the quality of face images is to apply super-resolution techniques [99, 100, 101, 102]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Scheme for Accquiring Very High Res-  olution Images using Multiple Cameras,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference  on Acoustics, Speech and Signal Processing,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 95
                            }
                        ],
                        "text": "More recently, an illumination-cone\u00adbased \n[Belhumeur and Kriegman 1997] image synthesis method [Georghiades et al. 1999] has been proposed to han\u00addle \nboth pose and illumination problems in face recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 21
                            }
                        ],
                        "text": "person are available [191, 192, 193, 194], 2) hybrid methods when multiple images are available during training but only one database image per person is available during recognition [80, 195, 196, 197], and 3) single image based methods when no training is carried out."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 60
                            }
                        ],
                        "text": "More recently, an illumination-based image synthesis method [194] has been proposed to handle both pose and illumination problems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Illumination-Based Image  Synthesis: Creating Novel Images of Human Faces Under Di ering Pose and Light-  ing,\" in Proceedings, Workshop on Multi-View Modeling and Analysis of Visual  Scenes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Comparative Performance of Classiication Methods for Fingerprints"
            },
            "venue": {
                "fragments": [],
                "text": "\\Comparative Performance of Classiication Methods for Fingerprints"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Elagin, \\Face Similarity Space as Perceived by Humans and Artiical Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 171
                            }
                        ],
                        "text": "5 Speechreading: enhancing speech recognition Visual facial cues have been found to be valuable for enhancing speech recognition system performance under noisy conditions [155]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hennecke, \\Speechreading: An Overview of Image Process-  ing, Feature Extraction, Sensory Integration, and Pattern Recognition Techniques,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Automatic Face and Gesture Recogni-  tion,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 65
                            }
                        ],
                        "text": "Several experiments have been conducted using the rst four shots [175, 176, 177, 178, 179, 180], with the goals of investigating text-dependent speaker veri cation from speech text-independent speaker veri cation from speech facial feature extraction and tracking from moving images veri cation from an overall frontal view veri cation from lip shape veri cation from depth information (obtained using structured light) veri cation from a pro le synchronization of speech and lip movement 39"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Conciliation for  Multi-Modal Person Authentication Systems by Bayesian Statistics,\" in Proceed-  ings, International Conference on Audio- and Video-Based Person Authentication,  pp"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Viewbased active appearance models"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 55
                            }
                        ],
                        "text": "In [148] motion templates are used to track people, in [149] color blobs are used, and in [119] nonrigid models are used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 7
                            }
                        ],
                        "text": "P nder [149] is a real-time person tracking system which uses a multi-class statistical model of color and shape to segment the person from the background."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "nder: Real-Time Track-  ing of the Human Body,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. on Pattern Analysis and Machine Intel-  ligence,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 79
                            }
                        ],
                        "text": "1996 and March 1997) A gray-scale projection algorithm from Rutgers University [170] (Sept."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 509,
                                "start": 491
                            }
                        ],
                        "text": "The Sep96 evaluation tested the follow\u00ading 10 algorithms: \nan algorithm from Excalibur Corpora\u00adtion (Carlsbad, CA)(Sept. 1996); two algorithms from MIT Media Labo\u00adratory \n(Sept. 1996) [Moghaddam et al. 1996; Turk and Pentland 1991]; three linear discriminant analysis\u00adbased \nalgorithms from Michigan State University [Swets and Weng 1996b] (Sept. 1996) and the University of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997); a gray-scale projection algorithm \nfrom Rutgers University [Wilder 1994] (Sept. 1996); an Elastic Graph Matching algorithm from the University \nof Southern Cali\u00adfornia [Okada et al. 1998; Wiskott et al. 1997] (March 1997); a baseline PCA algorithm \n[Moon and Phillips 2001; Turk and Pentland 1991]; and a baseline normalized correlation matching algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 140
                            }
                        ],
                        "text": "\u2026of Mary\u00adland \n[Etemad and Chellappa 1997; Zhao et al. 1998] (Sept. 1996 and March 1997); a gray-scale projection algorithm \nfrom Rutgers University [Wilder 1994] (Sept. 1996); an Elastic Graph Matching algorithm from the University \nof Southern Cali\u00adfornia [Okada et al. 1998; Wiskott et\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recognition Using Transform Coding of Gray Scale Projection  and the Neural Tree Network,\" in Arti cial Neural Networks with Applications in  Speech and Vision (R.J"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Caricatures [18]: Perkins [19] formally de nes a caricature as \\a symbol that exaggerates measurements relative to any measure which varies from one person to another\"."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perceiving and Recognizing Faces,"
            },
            "venue": {
                "fragments": [],
                "text": "Mind and Language,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "Good results were obtained in experiments on a database (the extended M2VTS database [54]) containing 295 subjects."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Acquisition of a Large Database for Biomeatric  Identity Veri cation,\" in BIOSIGNAL"
            },
            "venue": {
                "fragments": [],
                "text": "Technical University of Brno, Czech  Republic,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 28
                            }
                        ],
                        "text": "Hidden Markov Models (HMMs) [137] are the most commonly used tool for gesture recognition."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tutorial on Hidden Markov Models and Selected Publications in  Speech Recognition,"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "An excellent example is given in [16] using the \\Thatcher illusion\" [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 34
                            }
                        ],
                        "text": "An excellent ex\u00adample is given in \n[Bartlett and Searcy 1993] using the Thatcher illusion [Thompson 1980]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inversion and Con guration of Faces,"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psy-  chology,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 46
                            }
                        ],
                        "text": "Effect of lighting change [Bruce et al. 1998; Hill \nand Bruce 1996; Johnston et al. 1992]: It has long been informally observed that photographic negatives \nof faces are dif.cult to recognize."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 4
                            }
                        ],
                        "text": "In [Hill and Bruce 1996], the importance of top lighting for face recognition \nwas demon\u00adstrated using a different task: match\u00ading surface images of faces to determine whether they \nwere identical."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\EEects of Lighting on Matching Facial Surfaces"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Experimental Psychology: Human Perception and Performance"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Face Detection: A Survey,\" submitted to Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "\\Face Detection: A Survey,\" submitted to Pattern Recognition"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust Image Based 3D Face Recognition 69] \\Description of MPEG-7 Content Set"
            },
            "venue": {
                "fragments": [],
                "text": "Robust Image Based 3D Face Recognition 69] \\Description of MPEG-7 Content Set"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Malsburg, \\Robust Classiication of Hand Posture against Complex Background"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[138] used HMMs to recognize gestures in binary image sequences, using a rotation-invariant representation the images and a neural net."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recursive Identi cation of Gesture Inputs  Using Hidden Markov Model,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "Workshop on Applications of Com-  puter Vision,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "A generalized symmetry operator is used in [47] to nd the eyes and mouth in a face."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "The symmetry operator locates points in the image corresponding to high values of a symmetry measure discussed in detail in [47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Detection of Facial Features by General-  ized Symmetry,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Pattern Recognition,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 79
                            }
                        ],
                        "text": "Many papers on this subject have appeared over the past 15 years; examples are [156, 157, 158]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust Face Feature Analysis for Automation  Speechreading and Character Animation,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Confer-  ence on Automatic Face and Gesture Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visual information processing based on spatial filters constrained by biological data. AMRL Tech. rep"
            },
            "venue": {
                "fragments": [],
                "text": "Visual information processing based on spatial filters constrained by biological data. AMRL Tech. rep"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 65
                            }
                        ],
                        "text": "Several experiments have been conducted using the rst four shots [175, 176, 177, 178, 179, 180], with the goals of investigating text-dependent speaker veri cation from speech text-independent speaker veri cation from speech facial feature extraction and tracking from moving images veri cation from an overall frontal view veri cation from lip shape veri cation from depth information (obtained using structured light) veri cation from a pro le synchronization of speech and lip movement 39"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wassner, \\Acoustic-Labial Speaker Ver-  i cation,\" in Proceedings, International Conference on Audio- and Video-Based  Person Authentication"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 44
                            }
                        ],
                        "text": "In the engineering literature, early e orts [123, 135] were based on analysis of the optical ow eld of the image sequence, which provides clues to the spatial changes in the facial features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 114
                            }
                        ],
                        "text": "Another application of non-rigid motion to faces to is the recognition of facial expressions from image sequences [123]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computing Spatio-Temporal Representations of Hu-  man Faces,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and Pattern  Recognition,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[53] describes a robust and accurate feature localization method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Salient Features for Real-Time Face  Veri cation,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Audio- and Video-Based  Person Authentication,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Optical Neural Computers Scientiic American"
            },
            "venue": {
                "fragments": [],
                "text": "\\Optical Neural Computers Scientiic American"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Expressions of Emotion: An Old Controversy and New Findings"
            },
            "venue": {
                "fragments": [],
                "text": "Philosophical Transactions of the Royal Society of London"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 71
                            }
                        ],
                        "text": "We list here only books [86, 87, 106, 107, 108, 109] and review papers [110, 111, 112]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Sequences|Ten (Octal) Years | From Phenomenology To-  wards a Theoretical Foundation,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Pat-  tern Recognition,"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [153] the W 4 system was extended to include a stereo matching module."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "4S: A Real-Time System for Detecting  and Tracking People in 2.5D,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "European Conference on Computer  Vision,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 17
                            }
                        ],
                        "text": "[Bie\u00adderman 1987; Hill et al. 1997; Tarr and Bulthoff 1995]: Much work in vi\u00adsual object \nrecognition (e.g. [Biederman 1987]) has been cast within a theo\u00adretical framework introduced in [Marr \n1982] in which different views of ob\u00adjects are analyzed in a way which allows access to (largely)\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[26] show that generalization even from one pro le viewpoint to another is poor, though generalization from one 3/4 view to the other is very good."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 143
                            }
                        ],
                        "text": "Generalization even from one pro.le viewpoint to another is poor, though generalization from one three-quarter \nview to the other is very good [Hill et al. 1997]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information and Viewpoint Dependence"
            },
            "venue": {
                "fragments": [],
                "text": "Face Recognition,\" Cognition,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kriegman, \\Illumination-Based Image Synthesis: Creating Novel Images of Human Faces Under Diiering Pose and Lighting"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, Workshop on Multi-View Modeling and Analysis of Visual Scenes"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\A Scheme for Accquiring Very High Resolution Images using Multiple Cameras"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visionics Coporation, FaceIt Developer Kit Version 2"
            },
            "venue": {
                "fragments": [],
                "text": "Visionics Coporation, FaceIt Developer Kit Version 2"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 158
                            }
                        ],
                        "text": "\u2026al. 1997; Tarr and Bulthoff 1995]: Much work in vi\u00adsual object \nrecognition (e.g. [Biederman 1987]) has been cast within a theo\u00adretical framework introduced in [Marr \n1982] in which different views of ob\u00adjects are analyzed in a way which allows access to (largely) viewpoint\u00adinvariant \ndescriptions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vision. W. H. Freeman"
            },
            "venue": {
                "fragments": [],
                "text": "Vision. W. H. Freeman"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [141], this approach was extended to use 3D measurements obtained from a stereo system as features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In-  variant Features for 3D Gesture Recognition,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Con-  ference on Automatic Face and Gesture Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 219
                            }
                        ],
                        "text": "For example, in a totally noncooperative environment, such as a robbery, the face of the robber is typically covered, and the only way to perform faceless identification might be to analyize body motion characteristics [Klasen and Li 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Faceless identification"
            },
            "venue": {
                "fragments": [],
                "text": "Face Recognition: From Theory to Applications, H. Wechsler, P. J. Phillips, V. Bruce, F. F. Soulie, and T. S. Huang, Eds. Springer-Verlag, Berlin, Germany, 513\u2013527."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tracking and recognizing facial expressions in image sequences ACM Computing Surveys Face Recognition: A Literature Survey using local parametrized models of image motion"
            },
            "venue": {
                "fragments": [],
                "text": "Tracking and recognizing facial expressions in image sequences ACM Computing Surveys Face Recognition: A Literature Survey using local parametrized models of image motion"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Effects of lighting on matching facial surfaces"
            },
            "venue": {
                "fragments": [],
                "text": "J. Exp. Psych.: Human Percept. Perform"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [151], many levels of representation based on mixture models, EM, recursive Kalman and Markov estimation are used to learn and recognize human dynamics."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning and Recognizing Human Dynamics in Video Sequence,\" in  Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and Pattern Recognition,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[144] describes the use of hand gesture analysis in combination with speech recognition in a bi-modal interface for controlling a 3D display."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gestural Interface to a Visual Com-  puting Environment for Molecular Biologists,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Con-  ference on Automatic Face and Gesture Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Redlich, \\Statistical Approach to Shape from Shading: Reconstruction of Three-Dimensional Face Surfaces from Single Two-dimensional images"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Redlich, \\Statistical Approach to Shape from Shading: Reconstruction of Three-Dimensional Face Surfaces from Single Two-dimensional images"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "A recent survey paper on face detection is [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hjelmas, \\Face Detection: A Survey,\" submitted to Pattern  Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\HyperBF Networks for Gender Classiication"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings , DARPA Image Understanding Workshop"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [148] motion templates are used to track people, in [149] color blobs are used, and in [119] nonrigid models are used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Real-Time Recognition of Activity Using Temporal  Templates,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Workshop on Applications of Computer"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analysis and Visualization of Non-rigid Object Motion"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Pattern Recognition"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the International Conferences on Automatic Face and Gesture Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the International Conferences on Automatic Face and Gesture Recognition"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 51
                            }
                        ],
                        "text": "One of the most \nsuccessful of these systems is the Elas\u00adtic Bunch Graph Matching (EBGM) sys\u00adtem [Okada et al. 1998; Wiskott \net al. 1997], which is based on DLA [Buhmann et al. 1990; Lades et al. 1993]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 46
                            }
                        ],
                        "text": "The DLA architecture was recently ex\u00adtended to Elastic Bunch Graph Match\u00ading [Wiskott et al. 1997] (Figure \n10)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 80
                            }
                        ],
                        "text": "The DLA architecture has been recently extended to Elastic Bunch Graph Matching [78, 79]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recognition  and Gender Determination,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Workshop on Automatic  Face and Gesture Recognition,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 24
                            }
                        ],
                        "text": "Methods are proposed in [130, 131] to solve the varying appearance problem in tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Real-Time Tracking of Image Regions with  Changes in Geometry and Illumination,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Com-  puter Vision and Pattern Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 94
                            }
                        ],
                        "text": "1 Multi-Image Based Approaches One of the earliest examples of the rst class of approaches is [193], where a templatebased correlation matching scheme is proposed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 41
                            }
                        ],
                        "text": "Earlier work \non multiview-based meth\u00adods [Beymer 1993] was extended to ex\u00adplore the prior class information that is \nspeci.c to a face class and can be learned from a set of prototypes [Beymer 1993, 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 21
                            }
                        ],
                        "text": "person are available [191, 192, 193, 194], 2) hybrid methods when multiple images are available during training but only one database image per person is available during recognition [80, 195, 196, 197], and 3) single image based methods when no training is carried out."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recognition Under Varying Pose,\" Technical Report 1461"
            },
            "venue": {
                "fragments": [],
                "text": "MIT  AI Laboratory,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Is face recognition so unique after All?"
            },
            "venue": {
                "fragments": [],
                "text": "J. Cogn. Neuropsych"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Independent component representation for face recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, SPIE Symposium on Electronic Imaging: Science and Technology"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Support vector machines applied to face fecognition"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Neural Inform. Process. Syst"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 75
                            }
                        ],
                        "text": "Previous work on the evaluation of OCR and ngerprint classi cation systems [164, 165] provided insights into how the evaluation of algorithms and systems can be performed e ciently."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Comparative Performance of Classi cation  Methods for Fingerprints,"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report, National Institute of Standards and  Technology,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Person Authentication by Fusing Face and Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Audioand Video-Based Person Authentication"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings, International Conference on Audio-and Video-Based Person Authentication"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Audio-and Video-Based Person Authentication"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Candela, \\Comparison of Handprinted Digit Classiiers"
            },
            "venue": {
                "fragments": [],
                "text": "Candela, \\Comparison of Handprinted Digit Classiiers"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 76
                            }
                        ],
                        "text": "More recently, a uni ed framework called the bilinear model was proposed in [188]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 115
                            }
                        ],
                        "text": "Better rendered results are obtained with this method than when using methods such as the bi-linear model approach [188]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learing Bilinear Models for Two-Factor  Problems in Vision,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and  Pattern Recognition,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 186
                            }
                        ],
                        "text": "3D face models have been used for synthesizing face images under di erent appearances/lightings/expressions in the computer graphics, computer vision, and model-based coding communities [81, 122, 200]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Creation of 3D Facial  Models,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Computer Graphics and Applications,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2] Proceedings of the International Conferences on Audio-and Video-Based Person Authentication"
            },
            "venue": {
                "fragments": [],
                "text": "2] Proceedings of the International Conferences on Audio-and Video-Based Person Authentication"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Phillips, \\Analysis of PCA-Based Face Recognition Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Phillips, \\Analysis of PCA-Based Face Recognition Algorithms"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2] Proceedings of the International Conferences on Audio-and Video-Based Person Authentication"
            },
            "venue": {
                "fragments": [],
                "text": "2] Proceedings of the International Conferences on Audio-and Video-Based Person Authentication"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "On the other hand, better machine systems can provide better tools for conducting studies in psychology and neuroscience [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Elagin, \\Face Similarity Space as Perceived by  Humans and Arti cal Systems,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Au-  tomatic Face and Gesture Recognition,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 34
                            }
                        ],
                        "text": "An excellent ex\u00adample is given in \n[Bartlett and Searcy 1993] using the Thatcher illusion [Thompson 1980]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Inversion and Connguration of Faces"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "S: A Real-Time System for Detecting and Tracking People in 2.5D"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, European Conference on Computer Vision"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 48
                            }
                        ],
                        "text": "For example, an interactive computer/smart room [96, 97] can recognize such behavior and initiate appropriate action."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kyuma, \\Computer Vision for Com-  puter Games,\" in Proceedings"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Automatic Face and  Gesture Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Learning-based Hand Sign Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [161], a generic approach to simultaneous object tracking and veri cation is proposed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Simultaneous Tracking and Veri cation via Sequential  Posterior Estimation,\" submitted to"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and  Pattern Recognition,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speechreading by Humans and Machines, Berlin:  Springer-Verlag"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kriegman, \\Eigenfaces vs. Fisherfaces: Recognition Using Class Speciic Linear Projection"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. on Pattern Analysis and Machine Intelligence"
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 167,
            "methodology": 170,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 419,
        "totalPages": 42
    },
    "page_url": "https://www.semanticscholar.org/paper/Face-recognition:-A-literature-survey-Zhao-Chellappa/28312c3a47c1be3a67365700744d3d6665b86f22?sort=total-citations"
}