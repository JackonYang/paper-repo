{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461897"
                        ],
                        "name": "S. S. Bukhari",
                        "slug": "S.-S.-Bukhari",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Bukhari",
                            "middleNames": [
                                "Saqib"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Bukhari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3290619"
                        ],
                        "name": "M. A. Azawi",
                        "slug": "M.-A.-Azawi",
                        "structuredName": {
                            "firstName": "Mayce",
                            "lastName": "Azawi",
                            "middleNames": [
                                "Ibrahim",
                                "Ali",
                                "Al"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Azawi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10505962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86dc413ef69fb7e77608cca0683b558ab7fda7af",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Segmentation of a document image into text and non-text regions is an important preprocessing step for a variety of document image analysis tasks, like improving OCR, document compression etc. Most of the state-of-the-art document image segmentation approaches perform segmentation using pixel-based or zone(block)-based classification. Pixel-based classification approaches are time consuming, whereas block-based methods heavily depend on the accuracy of block segmentation step. In contrast to the state-of-the-art document image segmentation approaches, our segmentation approach introduces connected component based classification, thereby not requiring a block segmentation beforehand. Here we train a self-tunable multi-layer perceptron (MLP) classifier for distinguishing between text and non-text connected components using shape and context information as a feature vector. Experimental results prove the effectiveness of our proposed algorithm. We have evaluated our method on subset of UW-III, ICDAR 2009 page segmentation competition test images and circuit diagrams datasets and compared its results with the state-of-the-art leptonica's page segmentation algorithm."
            },
            "slug": "Document-image-segmentation-using-discriminative-Bukhari-Azawi",
            "title": {
                "fragments": [],
                "text": "Document image segmentation using discriminative learning over connected components"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work trains a self-tunable multi-layer perceptron (MLP) classifier for distinguishing between text and non-text connected components using shape and context information as a feature vector to introduce connected component based classification."
            },
            "venue": {
                "fragments": [],
                "text": "DAS '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308281"
                        ],
                        "name": "D. Bloomberg",
                        "slug": "D.-Bloomberg",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Bloomberg",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bloomberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62269638,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "df7124a46d9eb276e6e653763fd7762949753f6e",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "An image-based approach to document image analysis is presented. The methods are motivated by a merged view of shape and textural image properties at multiple scales. The principal binary image operations are morphological and multiresolution. The generalized opening is introduced for extraction of both shape and texture from an image. Threshold reduction operations are introduced for performing efficient and controllable shape and texture transformations between resolution levels. Some problems, such as halftone or dark area segmentation, can be in large part solved by a sequence of threshold reductions. Aspects of the approach are illustrated by the problem of identifying italic and bold words in text, using word-level extraction at lowered resolution. The computational costs of the basic operations are given, so that algorithm efficienc y can be estimated, and the importance of operating at the lowest feasable resolution is demonstrated. For example, word segmentation and halftone extraction proceed in excess of 1.5x10 image pixels/second on a Sun Sparcstation2 ."
            },
            "slug": "Multiresolution-Morphological-Approach-to-Document-Bloomberg",
            "title": {
                "fragments": [],
                "text": "Multiresolution Morphological Approach to Document Image Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "An image-based approach to document image analysis is presented, motivated by a merged view of shape and textural image properties at multiple scales, and the computational costs of the basic operations are given, so that algorithm efficiencies can be estimated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145470231"
                        ],
                        "name": "Kwan Y. Wong",
                        "slug": "Kwan-Y.-Wong",
                        "structuredName": {
                            "firstName": "Kwan",
                            "lastName": "Wong",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kwan Y. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34896449"
                        ],
                        "name": "R. Casey",
                        "slug": "R.-Casey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Casey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Casey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1880661"
                        ],
                        "name": "F. Wahl",
                        "slug": "F.-Wahl",
                        "structuredName": {
                            "firstName": "Friedrich",
                            "lastName": "Wahl",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wahl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "Wong et al.3 presented a classical page segmentation approach by smearing."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "Wong et al.(3) presented a classical page segmentation approach by smearing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15921038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7abca302c74d2f5adfd323a28e26d40b019df2b5",
            "isKey": false,
            "numCitedBy": 594,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper outlines the requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing. Several critical functions have been investigated and the technical approaches are discussed. The first is the segmentation and classification of digitized printed documents into regions of text and images. A nonlinear, run-length smoothing algorithm has been used for this purpose. By using the regular features of text lines, a linear adaptive classification scheme discriminates text regions from others. The second technique studied is an adaptive approach to the recognition of the hundreds of font styles and sizes that can occur on printed documents. A preclassifier is constructed during the input process and used to speed up a well-known pattern-matching method for clustering characters from an arbitrary print source into a small sample of prototypes. Experimental results are included."
            },
            "slug": "Document-Analysis-System-Wong-Casey",
            "title": {
                "fragments": [],
                "text": "Document Analysis System"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "The requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing, are outlined and several critical functions have been investigated and the technical approaches are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IBM J. Res. Dev."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51027911"
                        ],
                        "name": "Daniel Keysers",
                        "slug": "Daniel-Keysers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Keysers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Keysers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16742704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56234dd12764334bf79f5d5678da22954961033c",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a simple, fast, and accurate system for document image zone classification \u2014 an important subproblem of document image analysis \u2014 that results from a detailed analysis of different features. Using a novel combination of known algorithms, we achieve a very competitive error rate of 1.46% (n = 13811) in comparison to (Wang et al., 2006) who report an error rate of 1.55% (n = 24177) using more complicated techniques. The experiments were performed on zones extracted from the widely used UW-III database, which is representative of images of scanned journal pages and contains ground-truthed real-world data."
            },
            "slug": "Document-image-zone-classification-a-simple-Keysers-Shafait",
            "title": {
                "fragments": [],
                "text": "Document image zone classification - a simple high-performance approach"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A simple, fast, and accurate system for document image zone classification \u2014 an important subproblem of document image analysis \u2014 that results from a detailed analysis of different features is described."
            },
            "venue": {
                "fragments": [],
                "text": "VISAPP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803149"
                        ],
                        "name": "A. Antonacopoulos",
                        "slug": "A.-Antonacopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Antonacopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Antonacopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980669"
                        ],
                        "name": "S. Pletschacher",
                        "slug": "S.-Pletschacher",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Pletschacher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pletschacher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144322499"
                        ],
                        "name": "D. Bridson",
                        "slug": "D.-Bridson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bridson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bridson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070747525"
                        ],
                        "name": "C. Papadopoulos",
                        "slug": "C.-Papadopoulos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Papadopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papadopoulos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 33282851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b76f6734e87bcd7bf9f96c41156aa259e2429f7",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an objective comparative evalua-tion of layout analysis methods in realistic circumstances. It describes the Page Segmentation competition (modus operandi, dataset and evaluation methodology) held in the context of ICDAR2009 and presents the results of the evaluation of four submitted methods. Two state-of-the art methods are also compared as well as the three methods from the ICDA2007 Page Segmentation competition. The results indicate that although methods continue to mature, there is still a considerable need to develop robust methods that deal with everyday documents."
            },
            "slug": "ICDAR-2009-Page-Segmentation-Competition-Antonacopoulos-Pletschacher",
            "title": {
                "fragments": [],
                "text": "ICDAR 2009 Page Segmentation Competition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The results indicate that although methods continue to mature, there is still a considerable need to develop robust methods that deal with everyday documents."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3181078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c582c2971395c3957a4152956081bb52e78be259",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an improved zone content classification method. Motivated by our novel background-analysis-based table identification research, we added two new features to the feature vector from one previously published method [7]. The new features are the total area of large horizontal and large vertical blank blocks and the number of text glyphs in the zone. A binary decision tree is used to assign a zone class on the basis of its feature vector. The training and testing data sets for the algorithm include images drawn from the UWCDROM-III document image database. The classifier is able to classify each given scientific and technical document zone into one of the nine classes, text classes (of font size pt and font size pt), math, table, halftone, map/drawing, ruling, logo, and others. The improved zone classification method raised the accuracy rate to from and reduced the median false alarm rate to from . 1 Problem Statement Let ! be a set of zone entities. Let \" be a set of content labels, such as text, table, math, etc. The function #%$&!(')\" associates each element of * with a label. The function +,$-!.'0/ specifies measurements made on each element of ! , where / is the measurement space. The zone content classification problem can be formulated as follows: Given a zone set ! and a content label set \" , find a classification function #1$2!3'4\" , that has the maximum probability: 576 # 6 !98;: + 6 !98 8 (1) In our current approach, we assume conditional independence between the zone classifications, so the probability in Equation 1 may be decomposed as 576 # 6 !98;: + 6 !98 8= @ A B 576 # 6DC 8;: + 6DC 8 8 (2) The problem can be solved by maximizing each individual probability 576 # 6DC 8;: + 6DC 8 8 in Equation 2, where CFE ! . In our zone content classification experiment, the elements in set ! are zone groundtruth entities from UWCDROM III document image database [6]. The elements of set \" are text with font size GIH J pt, text with font size KLH M pt, math, table, halftone, map/drawing, ruling, logo, and others. + 6DC 8 is a feature vector generated for C , where CNE ! . We used a decision tree classifier to compute the probability in Equation 2 and make the assignment. 2 Related Work and Paper Organization A complete document image understanding system can transform paper documents into a hierarchical representation of their structure and content. The transformed document representation enables document interchange, editing, browsing, indexing, filing and retrieval. The zone classification technique plays the key role in the success of such a document understanding system. Not only is it useful for successive applications such as OCR, table understanding, etc, but it can be used to assist and validate document segmentation. In the literature, Sivaramakrishnan et. al [7] extracted features for each zone such as run length mean and variance, spatial mean and variance, fraction of the total number of black pixels in the zone, and the zone width ratio for each zone. They used the decision tree classifier to assign a zone class on the basis of its feature vector. They did their experiments on MPO M document images from UWCDROM I image database. Liang et. al [5] developed a feature based zone classifier using only the knowledge of the widths and the heights of the connected components within a given zone. Le et. al [4] proposed an automated labeling of zones from scanned images with labels such as titles, authors, affiliations and abstracts. The labeling is based on features calculated from optical character recognition(OCR) output, neural network models, machine learning methods, and a set of rules that is derived from an analysis of the page layout for each journal and from generic typesetting knowledge for English text. We developed a novel background-analysis-based table identification technique. We repeated Sivaramakrishnan et. al\u2019s work [7] on a larger database with a goal to improve its performance on table zone classification. Although some background analysis techniques can be found in the literature([1],[2]), none of them, to our knowledge, has been used in the table identification problem. We added two new features: the total area of large horizontal and vertical blank blocks and the number of text glyphs in the given zone, to the original feature vector. We improved the accuracy rate and reduced the false alarm rates for most of the nine classes. The rest of this paper is divided into Q sections. section 3 gives the definitions of large horizontal and large vertical blank blocks. The two new features are described in section 4. A brief introduction to the decision tree classifier is given in section 5. The experimental results are reported in section 6. Our conclusion and statement of future work are discussed in section 7."
            },
            "slug": "IMPROVEMENT-OF-ZONE-CONTENT-CLASSIFICATION-BY-USING-Wang-Phillips",
            "title": {
                "fragments": [],
                "text": "IMPROVEMENT OF ZONE CONTENT CLASSIFICATION BY USING BACKGROUND ANALYSIS"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The improved zone content classification method raised the accuracy rate and reduced the median false alarm rate and the total area of large horizontal and large vertical blank blocks and the number of text glyphs in the zone."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694191"
                        ],
                        "name": "J. Hull",
                        "slug": "J.-Hull",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hull",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hull"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58317587,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a76e38292960c7fc7576463225938fe74131611",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Several significant sets of labeled samples of image data are surveyed that can be used in the development of algorithms for offline and online handwriting recognition as well as for machine printed text recognition. The method used to gather each data set, the numbers of samples they contain, and the associated truth data are discussed. In the domain of offline handwriting, the CEDAR, NIST, and CENPARMI data sets are pre\u00ad sented. These contain primarily isolated digits and alphabetic characters. The UNIPEN data set of online handwriting was collected from a number of independent sources and it contains individual characters as well as handwritten phrases. The University of Wash\u00ad ington document image databases are also discussed. They contain a large number of English and Japanese document images that were selected from a range of publications."
            },
            "slug": "DATA-SETS-FOR-OCR-AND-DOCUMENT-IMAGE-UNDERSTANDING-Guyon-Haralick",
            "title": {
                "fragments": [],
                "text": "DATA SETS FOR OCR AND DOCUMENT IMAGE UNDERSTANDING RESEARCH"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Several significant sets of labeled samples of image data are surveyed that can be used in the development of algorithms for offline and online handwriting recognition as well as for machine printed text recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31742772"
                        ],
                        "name": "Michael A. Moll",
                        "slug": "Michael-A.-Moll",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Moll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Moll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144692946"
                        ],
                        "name": "Chang An",
                        "slug": "Chang-An",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "An",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang An"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16765674,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "343df7eac0b7b8066e81ebc178e2106e6681e482",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss problems in developing policies for ground truthing document images for pixel-accurate segmentation. First, we describe ground truthing policies that apply to four different scales: (1) paragraph, (2) text line, (3) character, and (4) pixel. We then analyze difficult and/or ambiguous cases that will challenge any policy, e.g. blank space, overlapping content, etc. Experiments have shown the benefit of using \"tighter'' zones that capture more detail (e.g., at the text line level, instead of paragraph). We show that tighter ground truth does significantly improve classification results, by 45% in recent experiments. It is important to face the fact that a pixel-accurate segmentation can be better than manually obtained ground truth. In practice, perfectly accurate pixel-level ground truth may not be achievable of course, but we believe it is important to explore methods to semi-automatically improve existing ground truth."
            },
            "slug": "Truthing-for-Pixel-Accurate-Segmentation-Moll-Baird",
            "title": {
                "fragments": [],
                "text": "Truthing for Pixel-Accurate Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that tighter ground truth does significantly improve classification results, by 45% in recent experiments, and it is important to face the fact that a pixel-accurate segmentation can be better than manually obtained ground truth."
            },
            "venue": {
                "fragments": [],
                "text": "2008 The Eighth IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Leptonica : An open source C library for efficient image processing and image analysis operations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Truthing for pixel-accurate segmentation, \" in [Document Analysis Systems, the Eighth IAPR Int"
            },
            "venue": {
                "fragments": [],
                "text": "Truthing for pixel-accurate segmentation, \" in [Document Analysis Systems, the Eighth IAPR Int"
            },
            "year": 2008
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 10,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Improved-document-image-segmentation-algorithm-Bukhari-Shafait/680691b631baeecb70d31403fc6f9e2560e9f574?sort=total-citations"
}