{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3453447"
                        ],
                        "name": "J. Mundy",
                        "slug": "J.-Mundy",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Mundy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mundy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108385944"
                        ],
                        "name": "Jane Liu",
                        "slug": "Jane-Liu",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jane Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2417659"
                        ],
                        "name": "Nic Pillow",
                        "slug": "Nic-Pillow",
                        "structuredName": {
                            "firstName": "Nic",
                            "lastName": "Pillow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nic Pillow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144760431"
                        ],
                        "name": "Charlie Rothwell",
                        "slug": "Charlie-Rothwell",
                        "structuredName": {
                            "firstName": "Charlie",
                            "lastName": "Rothwell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charlie Rothwell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2326267"
                        ],
                        "name": "S. Utcke",
                        "slug": "S.-Utcke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Utcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Utcke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18028987,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d117a8aa2bd465b9a4a9428bb0d237f693ceb86",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In any object recognition system a major and primary task is to associate those image features, within an image of a complex scene, that arise from an individual object. The key idea here is that a geometric class defined in 3D induces relationships in the image which must hold between points on the image outline (the perspective projection of the object). The resulting image constraints enable both identification and grouping of image features belonging to objects of that class. The classes include surfaces of revolution, canal surfaces (pipes) and polyhedra. Recognition proceeds by first recognising an object as belonging to one of the classes (for example a surface of revolution) and subsequently identifying the object (for example as a particular vase). This differs from conventional object recognition systems where recognition is generally targetted at particular objects. These classes also support the computation of 3D invariant descriptions including symmetry axes, canonical coordinate frames and projective signatures. The constraints and grouping methods are viewpoint invariant, and proceed with no information on object pose. We demonstrate the effectiveness of this class-based grouping on real, cluttered scenes using grouping algorithms developed for rotationally symmetric surfaces, canal-surfaces and polyhedra.<<ETX>>"
            },
            "slug": "Class-based-grouping-in-perspective-images-Zisserman-Mundy",
            "title": {
                "fragments": [],
                "text": "Class-based grouping in perspective images"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The key idea here is that a geometric class defined in 3D induces relationships in the image which must hold between points on the image outline (the perspective projection of the object) to enable both identification and grouping of image features belonging to objects of that class."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11177752,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d22d9a73eba33ce685e42b413867ea6411f0dab",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "While there have been great strides in the development of systems to recognize 3D objects in images using viewpoint independent features, we have yet to develop algorithms for recognizing complex curved objects from large model databases; in part, the difficulty arises because image features are viewpoint dependent. Consequently, we must either develop viewer centered representations or have methods for directly relating viewpoint dependent features to 3D models. Aspect graphs, which enumerate all topologically distinct line drawings, may be too weak by themselves to support recognition. However, they can be used to control the search for image-model correspondences when coupled with the constraints afforded by viewpoint dependent features. When objects are represented by algebraic surfaces, these constraints can be expressed as systems of polynomial equations which can be solved using well established techniques. Alternatively, a new representation has been proposed called HOT Curves. Like representations based on geometric invariance, HOT Curves encode the relationship of image features for a particular 3D object. The representation can be constructed directly from a set of images, the features are viewpoint dependent, and indexing schemes are supported."
            },
            "slug": "Representations-for-Recognizing-Complex-Curved-3D-Kriegman-Ponce",
            "title": {
                "fragments": [],
                "text": "Representations for Recognizing Complex Curved 3D Objects"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new representation has been proposed called HOT Curves that encodes the relationship of image features for a particular 3D object and can be constructed directly from a set of images, the features are viewpoint dependent, and indexing schemes are supported."
            },
            "venue": {
                "fragments": [],
                "text": "Object Representation in Computer Vision"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8444417,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16cd53fc27e6721c383e070e93d81a6995bcb3f8",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital libraries of images and video are rapidly growing in size and availability. To avoid the expense and limitations of text, there is considerable interest in navigation by perceptual and other automatically extractable attributes. Unfortunately, the relevance of an attribute for a query is not always obvious. Queries which go beyond explicit color, shape, and positional cues must incorporate multiple features in complex ways. This dissertation uses machine learning to automatically select and combine features to satisfy a query, based on positive and negative examples from the user. The learning algorithm does not just learn during the course of one session: it learns continuously, across sessions. The learner improves its learning ability by dynamically modifying its inductive bias, based on experience over multiple sessions. Experiments demonstrate the ability to assist image classiication, segmentation, and annotation (labeling of image regions). The common theme of this work, applied to computer vision, database retrieval, and machine learning, is building in enough exibility to allow adaptation to changing goals."
            },
            "slug": "An-image-database-browser-that-learns-from-user-Minka",
            "title": {
                "fragments": [],
                "text": "An image database browser that learns from user interaction"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This dissertation uses machine learning to automatically select and combine features to satisfy a query, based on positive and negative examples from the user, to build in enough exibility to allow adaptation to changing goals."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768792"
                        ],
                        "name": "Yihong Gong",
                        "slug": "Yihong-Gong",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780232"
                        ],
                        "name": "M. Sakauchi",
                        "slug": "M.-Sakauchi",
                        "structuredName": {
                            "firstName": "Masao",
                            "lastName": "Sakauchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sakauchi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39757590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7662750ec9fe570b072f4429313fa4a79451abc6",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract In this paper, we present a new and effective method for detecting regions matching a given color, along with the features of the region surfaces. We adopt the HVC color coordinates in our method because of its ability to completely separate the luminant and chromatic components of colors. A second-order basis function is introduced to pick up the pixels matching the specified color features. The convolution operation involving the basis function is incorporated to diminish the influence of noise and increase the integrity of the detected regions. Efforts are made to remarkably reduce the running time for successive region detection of the same image. Various experimental results show the effectiveness of the proposed method in handling images under shade, highlight, sharp contrast, and other nonuniform illumination conditions."
            },
            "slug": "Detection-of-Regions-Matching-Specified-Chromatic-Gong-Sakauchi",
            "title": {
                "fragments": [],
                "text": "Detection of Regions Matching Specified Chromatic Features"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experimental results show the effectiveness of the proposed method in handling images under shade, highlight, sharp contrast, and other nonuniform illumination conditions."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31164312"
                        ],
                        "name": "R. Gershon",
                        "slug": "R.-Gershon",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Gershon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gershon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723930"
                        ],
                        "name": "A. Jepson",
                        "slug": "A.-Jepson",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Jepson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jepson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727853"
                        ],
                        "name": "John K. Tsotsos",
                        "slug": "John-K.-Tsotsos",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tsotsos",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John K. Tsotsos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30307259,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "ef37fb86a4fc0f3d3f65b36a5450ce76cb3f23fa",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The task of distinguishing material changes from shadow boundaries in chromatic images is discussed. Although there have been previous attempts at providing solutions to this problem, the assumptions that were adopted were too restrictive. Using a simple reflection model, we show that the ambient illumination cannot be assumed to have the same spectral characteristics as the incident illumination, since it may lead to the classification of shadow boundaries as material changes. In such cases, we show that it is necessary to take into account the spectral properties of the ambient illumination in order to develop a technique that is more robust and stable than previous techniques. This technique uses a biologically motivated model of color vision and, in particular, a set of chromatic-opponent and double-opponent center-surround operators. We apply this technique to simulated test patterns as well as to a chromatic image. It is shown that, given some knowledge about the strength of the ambient illumination, this method provides a better classification of shadow boundaries and material changes."
            },
            "slug": "Ambient-illumination-and-the-determination-of-Gershon-Jepson",
            "title": {
                "fragments": [],
                "text": "Ambient illumination and the determination of material changes."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that, given some knowledge about the strength of the ambient illumination, this method provides a better classification of shadow boundaries and material changes."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The hypothesis that the object is present is then verified using the estimate of appearance [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8989489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d781d5e651e12bf666cf993ae307db785113b9ae",
            "isKey": false,
            "numCitedBy": 951,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed. It is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views. For objects with sharp edges, the linear combination representation is exact. For objects with smooth boundaries, it is an approximation that often holds over a wide range of viewing angles. Rigid transformations (with or without scaling) can be distinguished from more general linear transformations of the object by testing certain constraints placed on the coefficients of the linear combinations. Three alternative methods of determining the transformation that matches a model to a given image are proposed. >"
            },
            "slug": "Recognition-by-Linear-Combinations-of-Models-Ullman-Basri",
            "title": {
                "fragments": [],
                "text": "Recognition by Linear Combinations of Models"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed and it is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 107
                            }
                        ],
                        "text": "The constraints on human dynamics can be exploited to locate moving people in images [43] or to track them [46, 18] The resulting gures can then be labelled to various degrees of granularity, leading to inferences 4"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34873540,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92f98b189cec1220d479e3079b942e71b244aa65",
            "isKey": false,
            "numCitedBy": 597,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Model-based-vision:-a-program-to-see-a-walking-Hogg",
            "title": {
                "fragments": [],
                "text": "Model-based vision: a program to see a walking person"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10251113"
                        ],
                        "name": "C. Jacobs",
                        "slug": "C.-Jacobs",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jacobs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37737599"
                        ],
                        "name": "A. Finkelstein",
                        "slug": "A.-Finkelstein",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Finkelstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Finkelstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 42
                            }
                        ],
                        "text": "Appearance based matching is also used in [8], which describes a system that forms a wavelet based decomposition of an image and matches based on the coarse-scale appearance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7884491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e9bd47e9fa53e8719aba15e4367096317d45f74",
            "isKey": false,
            "numCitedBy": 835,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for searching in an image database using a query image that is similar to the intended target. The query image may be a hand-drawn sketch or a (potentially low-quality) scan of the image to be retrieved. Our searching algorithm makes use of multiresolution wavelet decompositions of the query and database images. The coefficients of these decompositions are distilled into small \u201csignatures\u201d for each image. We introduce an \u201cimage querying metric\u201d that operates on these signatures. This metric essentially compares how many significant wavelet coefficients the query has in common with potential targets. The metric includes parameters that can be tuned, using a statistical analysis, to accommodate the kinds of image distortions found in different types of image queries. The resulting algorithm is simple, requires very little storage overhead for the database of signatures, and is fast enough to be performed on a database of 20,000 images at interactive rates (on standard desktop machines) as a query is sketched. Our experiments with hundreds of queries in databases of 1000 and 20,000 images show dramatic improvement, in both speed and success rate, over using a conventional L1, L2, or color histogram norm. CR"
            },
            "slug": "Fast-multiresolution-image-querying-Jacobs-Finkelstein",
            "title": {
                "fragments": [],
                "text": "Fast multiresolution image querying"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An \u201cimage querying metric\u201d is introduced that operates on how many significant wavelet coefficients the query has in common with potential targets, and includes parameters that can be tuned, using a statistical analysis, to accommodate the kinds of image distortions found in different types of image queries."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143867195"
                        ],
                        "name": "I. Weiss",
                        "slug": "I.-Weiss",
                        "structuredName": {
                            "firstName": "Isaac",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Weiss"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 170
                            }
                        ],
                        "text": "These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include [14, 26, 48, 52, 54, 60, 30, 24])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35353036,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9d802142acfacf70c251e2b2776bab89039394be",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A major goal of computer vision is object recognition, which involves matching of images of an object, obtained from different, unknown points of view. Since there are infinitely many points of view, one is faced with the problem of a search in a multidimensional parameter space. A related problem is the stereo reconstruction of 3-D surfaces from multiple 2-d images. The author proposes to solve these fundamental problems by using geometrical properties of the visible shape that are invariant to a change in the point of view. To obtain such invariants, he starts from classical theories for differential and algebraic invariants not previously used in image understanding. As they stand, these theories are not directly applicable to vision. He suggests extensions and adaptations of these methods to the needs of machine vision. He then studies general projective transformations, which include both perspective and orthographic projections as special cases.<<ETX>>"
            },
            "slug": "Projective-invariants-of-shapes-Weiss",
            "title": {
                "fragments": [],
                "text": "Projective invariants of shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The author starts from classical theories for differential and algebraic invariants not previously used in image understanding, and studies general projective transformations, which include both perspective and orthographic projections as special cases."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141915"
                        ],
                        "name": "W. Niblack",
                        "slug": "W.-Niblack",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Niblack",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Niblack"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50281905"
                        ],
                        "name": "R. Barber",
                        "slug": "R.-Barber",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Barber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712308"
                        ],
                        "name": "W. Equitz",
                        "slug": "W.-Equitz",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Equitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Equitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712991"
                        ],
                        "name": "M. Flickner",
                        "slug": "M.-Flickner",
                        "structuredName": {
                            "firstName": "Myron",
                            "lastName": "Flickner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Flickner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123856769"
                        ],
                        "name": "E. Glasman",
                        "slug": "E.-Glasman",
                        "structuredName": {
                            "firstName": "Eduardo",
                            "lastName": "Glasman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Glasman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143867341"
                        ],
                        "name": "D. Petkovic",
                        "slug": "D.-Petkovic",
                        "structuredName": {
                            "firstName": "Dragutin",
                            "lastName": "Petkovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Petkovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70341848"
                        ],
                        "name": "P. Yanker",
                        "slug": "P.-Yanker",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Yanker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Yanker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702392"
                        ],
                        "name": "C. Faloutsos",
                        "slug": "C.-Faloutsos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Faloutsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faloutsos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690237"
                        ],
                        "name": "G. Taubin",
                        "slug": "G.-Taubin",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Taubin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Taubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "The best-known such system is QBIC [15], which allows an opera-tor to specify various properties of a desired image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "Niblack, W., Barber, R, Equitz, W., Flickner, M., Glasman, E., Petkovic, D., andYanker, P. (1993) \\The QBIC project: querying images by content using colour,texture and shape,\" IS and T/SPIE 1993 Intern."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "The best-known image database system is QBIC [36], which allows an operator to specify various properties of a desired image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "Photobook [17] largely shares QBIC's model of\nan image as a collage of at, homogenous frontally presented regions, but incor-porates more sophisticated representations of texture and a degree of automaticsegmentation."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14145220,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "824aac4970a4d149b35c19a9d2d2dec4c994688e",
            "isKey": true,
            "numCitedBy": 2235,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In the query by image content (QBIC) project we are studying methods to query large on-line image databases using the images' content as the basis of the queries. Examples of the content we use include color, texture, and shape of image objects and regions. Potential applications include medical (`Give me other images that contain a tumor with a texture like this one'), photo-journalism (`Give me images that have blue at the top and red at the bottom'), and many others in art, fashion, cataloging, retailing, and industry. Key issues include derivation and computation of attributes of images and objects that provide useful query functionality, retrieval methods based on similarity as opposed to exact match, query by image example or user drawn image, the user interfaces, query refinement and navigation, high dimensional database indexing, and automatic and semi-automatic database population. We currently have a prototype system written in X/Motif and C running on an RS/6000 that allows a variety of queries, and a test database of over 1000 images and 1000 objects populated from commercially available photo clip art images. In this paper we present the main algorithms for color texture, shape and sketch query that we use, show example query results, and discuss future directions."
            },
            "slug": "QBIC-project:-querying-images-by-content,-using-and-Niblack-Barber",
            "title": {
                "fragments": [],
                "text": "QBIC project: querying images by content, using color, texture, and shape"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The main algorithms for color texture, shape and sketch query that are presented, show example query results, and discuss future directions are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735767"
                        ],
                        "name": "Margaret M. Fleck",
                        "slug": "Margaret-M.-Fleck",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "Fleck",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Margaret M. Fleck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "a All operations use a fast multi-ring approximation to the median filter [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13003371,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d9c6014fa2a0a00970b60d04a00a594bb17e5685",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new algorithm for locating the boundaries of textured regions (both step changes and outliers) using a robust estimator. Previous robust image filters perform poorly on binary images, blur edges, round corners, and run slowly. The author avoids artifacts on binary images by modelling them as continuous and interpolating values. Information is combined directly between non-adjacent locations to prevent blurring. Corners are sharpened by relabelling mis-classified pixels. The algorithm is made as fast as a Marr-Hildreth edge finder by restructuring the estimator as a series of 2D image operations, using new multi-ring order statistic operators, and running most of the estimator on a randomly sampled image.<<ETX>>"
            },
            "slug": "Practical-edge-finding-with-a-robust-estimator-Fleck",
            "title": {
                "fragments": [],
                "text": "Practical edge finding with a robust estimator"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper presents a new algorithm for locating the boundaries of textured regions (both step changes and outliers) using a robust estimator that is made as fast as a Marr-Hildreth edge finder by restructuring the estimator as a series of 2D image operations."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9705274,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f66e7cdeabe3e59cb22a131a4a28a6b5b7b0fcc",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract (white paper presented at the NSF Workshop on Visual Information Management, MIT, June 1995) We propose the development of a world wide web image search engine that crawls the web collecting information about the images it finds, computes the appropriate image decompositions and indices, and stores this extracted information for searches based on image content. Indexing and searching images need not require solving the image understanding problem. Instead, the general approach should be to provide an arsenal of image decompositions and discriminants that can be precomputed for images. At search time, users can select a weighted subset of these decompositions to be used for computing image similarity measurements. While this approach avoids the search-time-dependent problem of labeling what is important in images, it still holds several important problems that require further research in the area of query by image content. We briefly explore some of these problems as they pertain to shape."
            },
            "slug": "World-Wide-Web-Image-Search-Engines-Sclaroff",
            "title": {
                "fragments": [],
                "text": "World Wide Web Image Search Engines"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A world wide web image search engine that crawls the web collecting information about the images it finds, computes the appropriate image decompositions and indices, and stores this extracted information for searches based on image content is proposed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690237"
                        ],
                        "name": "G. Taubin",
                        "slug": "G.-Taubin",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Taubin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Taubin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145700259"
                        ],
                        "name": "D. Cooper",
                        "slug": "D.-Cooper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cooper",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cooper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123307724,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a315634c70307836f6d413c38ace331a8da694cf",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Toward the development of an object recognition and positioning system, able to deal with arbitrary shaped objects in cluttered environments, we introduce methods for checking the match of two arbitrary curves in 2D or surfaces in 3D, when each of these subobjects (i.e., regions) is in arbitrary position, and we also show how to efficiently compute explicit expressions for the coordinate transformation which makes two matching subobjects (i.e., regions) coincide. This is to be used for comparing an arbitrarily positioned subobject of sensed data with objects in a data base, where each stored object is described in some \u201cstandard\u201d position. In both cases, matching and positioning, results are invariant with respect to viewer coordinate system, i.e., invariant to the arbitrary location and orientation of the object in the data set, or, more generally, to affine transformations of the objects in the data set, which means translation, rotation, and different stretchings in two (or three) directions, and these techniques apply to both 2D and 3D problems. The 3D Euclidean case is useful for the recognition and positioning of solid objects from range data, and the 2D affine case for the recognition and positioning of solid objects from projections, e.g., from curves in a single image, and in motion estimation. The matching of arbitrarily shaped regions is done by computing for each region a vector of centered moments. These vectors are viewpointdependent, but the dependence on the viewpoint is algebraic and well known. We then compute moment invariants, i.e., algebraic functions of the moments that are invariant to Euclidean or affine transformations of the data set. We present a new family of computationally efficient algorithms, based on matrix computations, for the evaluation of both Euclidean and affine algebraic moment invariants of data sets. The use of moment invariants greatly reduces the computation required for the matching, and hence initial object recognition. The approach to determining and computing these moment invariants is different than those used by the vision community previously. The method for computing the coordinate transformation which makes the two matching regions coincide provides an estimate of object position. The estimation of the matching transformation is based on the same matrix computation techniques introduced for the computation of invariants, it involves simple manipulations of the moment vectors, it neither requires costly iterative methods, nor going back to the data set. The use of geometric invariants in this application is equivalent to specifying a center and an orientation for an arbitrary data constellation in a region. These geometric invariant methods appear to be very important for dealing with the situation of a large number of different possible objects in the presence of occlusion and clutter. As we point out in this paper, each moment invariant also defines an algebraic invariant, i.e., an invariant algebraic function of the coefficients of the best fitting polynomial to the data. Hence, this paper also introduces a new design and computation approach to algebraic invariants."
            },
            "slug": "Object-recognition-based-on-moment-(or-algebraic)-Taubin-Cooper",
            "title": {
                "fragments": [],
                "text": "Object recognition based on moment (or algebraic) invariants"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new family of computationally efficient algorithms, based on matrix computations, are presented for the evaluation of both Euclidean and affine algebraic moment invariants of data sets, reducing the computation required for the matching, and hence initial object recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3260570"
                        ],
                        "name": "Virginia E. Ogle",
                        "slug": "Virginia-E.-Ogle",
                        "structuredName": {
                            "firstName": "Virginia",
                            "lastName": "Ogle",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Virginia E. Ogle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145345023"
                        ],
                        "name": "M. Stonebraker",
                        "slug": "M.-Stonebraker",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Stonebraker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stonebraker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 11
                            }
                        ],
                        "text": "Similarly, Chabot [16] uses a combination of visual appearance andtext-based cues to retrieve images, but depends strongly on text cues to identifyobjects."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "Further examples of systems that identify materials using low-level image properties include Virage [59], Candid [10, 23] and Chabot [37]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 50
                            }
                        ],
                        "text": "Ogle, Virginia E. and Michael Stonebraker (1995) \\Chabot: Retrieval from a Re-lational Database of Images,\" Computer 28/9, pp. 40{48.17."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11195120,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c17ee327e563536f8adaf214eb6d3bde33b73dd6",
            "isKey": true,
            "numCitedBy": 818,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Selecting from a large, expanding collection of images requires carefully chosen search criteria. We present an approach that integrates a relational database retrieval system with a color analysis technique. The Chabot project was initiated at our university to study storage and retrieval of a vast collection of digitized images. These images are from the State of California Department of Water Resources. The goal was to integrate a relational database retrieval system with content analysis techniques that would give our querying system a better method for handling images. Our simple color analysis method, if used in conjunction with other search criteria, improves our ability to retrieve images efficiently. The best result is obtained when text-based search criteria are combined with content-based criteria and when a coarse granularity is used for content analysis. >"
            },
            "slug": "Chabot:-Retrieval-from-a-Relational-Database-of-Ogle-Stonebraker",
            "title": {
                "fragments": [],
                "text": "Chabot: Retrieval from a Relational Database of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This work presents an approach that integrates a relational database retrieval system with a color analysis technique, and shows how a coarse granularity is used for content analysis improves the ability to retrieve images efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2904067,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d50d0e2af0b45cc7ed25fe4aa97af900c9bd32a",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for locating quasi-frontal views of human faces in cluttered scenes is presented. The algorithm works by coupling a set of local feature detectors with a statistical model of the mutual distances between facial features it is invariant with respect to translation, rotation (in the plane), and scale and can handle partial occlusions of the face. On a challenging database with complicated and varied backgrounds, the algorithm achieved a correct localization rate of 95% in images where the face appeared quasi-frontally.<<ETX>>"
            },
            "slug": "Finding-faces-in-cluttered-scenes-using-random-Leung-Burl",
            "title": {
                "fragments": [],
                "text": "Finding faces in cluttered scenes using random labeled graph matching"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An algorithm for locating quasi-frontal views of human faces in cluttered scenes is presented and it is found that it is invariant with respect to translation, rotation, and scale and can handle partial occlusions of the face."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729041"
                        ],
                        "name": "J. Canny",
                        "slug": "J.-Canny",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Canny",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Canny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Sheffield's version of Canny's [3] edge detector, with relatively high smoothing and contrast thresholds, is applied to these skin areas to obtain a set of connected edge curves."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13284142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcf9fc4e23b45345c2404ce7d6cb0fc9dea2c9ec",
            "isKey": false,
            "numCitedBy": 27661,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge."
            },
            "slug": "A-Computational-Approach-to-Edge-Detection-Canny",
            "title": {
                "fragments": [],
                "text": "A Computational Approach to Edge Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "There is a natural uncertainty principle between detection and localization performance, which are the two main goals, and with this principle a single operator shape is derived which is optimal at any scale."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388700951"
                        ],
                        "name": "Tomas Lozano-Perez",
                        "slug": "Tomas-Lozano-Perez",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Lozano-Perez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Lozano-Perez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 93
                            }
                        ],
                        "text": "Appropriate feature correspondences can be obtained by various forms of search (for example, [19, 17])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14484943,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1230072567fed362e7a39bb8bc83c867c0c1a9f5",
            "isKey": false,
            "numCitedBy": 550,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses how local measurements of positions and surface normals may be used to identify and locate overlapping objects. The objects are modeled as polyhedra (or polygons) having up to six degrees of positional freedom relative to the sensors. The approach operates by examining all hypotheses about pairings between sensed data and object surfaces and efficiently discarding inconsistent ones by using local constraints on: distances between faces, angles between face normals, and angles (relative to the surface normals) of vectors between sensed points. The method described here is an extension of a method for recognition and localization of nonoverlapping parts previously described in [18] and [15]."
            },
            "slug": "Localizing-Overlapping-Parts-by-Searching-the-Tree-Grimson-Lozano-Perez",
            "title": {
                "fragments": [],
                "text": "Localizing Overlapping Parts by Searching the Interpretation Tree"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The approach operates by examining all hypotheses about pairings between sensed data and object surfaces and efficiently discarding inconsistent ones by using local constraints on distances between faces, angles between face normals, and angles of vectors between sensed points."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 182
                            }
                        ],
                        "text": "The main features on a human face appear in much the same form in most images, enabling techniques based on principal component analysis or neural networks proposed by, for example, [41, 53, 49, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7164794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088eb2d102c6bb486f5270d0b2adff76961994cf",
            "isKey": false,
            "numCitedBy": 2061,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system."
            },
            "slug": "Example-Based-Learning-for-View-Based-Human-Face-Sung-Poggio",
            "title": {
                "fragments": [],
                "text": "Example-Based Learning for View-Based Human Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An example-based learning approach for locating vertical frontal views of human faces in complex scenes and shows empirically that the distance metric adopted for computing difference feature vectors, and the \"nonface\" clusters included in the distribution-based model, are both critical for the success of the system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20954521"
                        ],
                        "name": "S. S. Layne",
                        "slug": "S.-S.-Layne",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Layne",
                            "middleNames": [
                                "Shatford"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Layne"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "1 Objects and materials Many notions of image content have been used to organize collections of images [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13501643,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "bd2036b4736a6d99b593f09c482df00efc929307",
            "isKey": false,
            "numCitedBy": 205,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This article discusses some of the intellectual issues involved in the indexing of visual or pictorial images, postulating that the indexing of images should provide access to images based on the attributes of those images, and provide access to useful groupings of images, not simply access to individual images. The attributes of images can be divided into four categories: \u201cBiographical\u201d attributes, Subject attributes, Exemplified attributes, and Relationship attributes. When creating groupings of images, it is important to consider the following issues or questions: When should the grouping occur? What are the groupings based on? What level of detail is necessary? and What groupings will be useful? More research is needed into the ways images are sought and the reasons that they are useful. \u00a9 1994 John Wiley & Sons, Inc."
            },
            "slug": "Some-Issues-in-the-Indexing-of-Images-Layne",
            "title": {
                "fragments": [],
                "text": "Some Issues in the Indexing of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This article discusses some of the intellectual issues involved in the indexing of visual or pictorial images, postulating that the indexed images should provide access to images based on the attributes of those images, and provides access to useful groupings of images, not simply access to individual images."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738591"
                        ],
                        "name": "T. Binford",
                        "slug": "T.-Binford",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Binford",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Binford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 29
                            }
                        ],
                        "text": "Notable exceptions appear in [7, 5, 35, 64], which attempt to code relationships between various forms of volumetric primitive, where the description is in terms of the nature of the primitives involved and of their geometric relationship."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10878162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4dd5ad87ccf9b8493625e38514e2f37ab9ce99cb",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Description-and-Recognition-of-Curved-Objects-Nevatia-Binford",
            "title": {
                "fragments": [],
                "text": "Description and Recognition of Curved Objects"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502152"
                        ],
                        "name": "A. Treisman",
                        "slug": "A.-Treisman",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Treisman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Treisman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "known to use for fast (preattentive) triage [ 19 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2368075,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "5188b8d12e1011e67c3b63eabca2df20c78b1c7b",
            "isKey": false,
            "numCitedBy": 753,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Preattentive-processing-in-vision-Treisman",
            "title": {
                "fragments": [],
                "text": "Preattentive processing in vision"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738894"
                        ],
                        "name": "T. Starner",
                        "slug": "T.-Starner",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Starner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Starner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 136280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0bf5d558220d39698ce96d59ee5772e8e1a0663",
            "isKey": false,
            "numCitedBy": 2234,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe experiments with eigenfaces for recognition and interactive search in a large-scale face database. Accurate visual recognition is demonstrated using a database of O(10/sup 3/) faces. The problem of recognition under general viewing orientation is also examined. A view-based multiple-observer eigenspace technique is proposed for use in face recognition under variable pose. In addition, a modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields higher recognition rates as well as a more robust framework for face recognition. An automatic feature extraction technique using feature eigentemplates is also demonstrated.<<ETX>>"
            },
            "slug": "View-based-and-modular-eigenspaces-for-face-Pentland-Moghaddam",
            "title": {
                "fragments": [],
                "text": "View-based and modular eigenspaces for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer, which yields higher recognition rates as well as a more robust framework for face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 182
                            }
                        ],
                        "text": "The main features on a human face appear in much the same form in most images, enabling techniques based on principal component analysis or neural networks proposed by, for example, [41, 53, 49, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 676887,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6af749b2b813af20c2f26962249fafdccdc6a1e",
            "isKey": false,
            "numCitedBy": 477,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image, and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with another state-of-the-art face detection system are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Human-Face-Detection-in-Visual-Scenes-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Human Face Detection in Visual Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that uses a bootstrap algorithm for training, which adds false detections into the training set as training progresses, and has better performance in terms of detection and false-positive rates than other state-of-the-art face detection systems."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46827615"
                        ],
                        "name": "Demas Sanger",
                        "slug": "Demas-Sanger",
                        "structuredName": {
                            "firstName": "Demas",
                            "lastName": "Sanger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Demas Sanger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2181047"
                        ],
                        "name": "H. Haneishi",
                        "slug": "H.-Haneishi",
                        "structuredName": {
                            "firstName": "Hideaki",
                            "lastName": "Haneishi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Haneishi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145308667"
                        ],
                        "name": "Y. Miyake",
                        "slug": "Y.-Miyake",
                        "structuredName": {
                            "firstName": "Yoichi",
                            "lastName": "Miyake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Miyake"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "Color information is used in [50] to segment skin regions for face identi cation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 99832963,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c21f66b2b01d16b472752e85c10f042012b9ed56",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We have proposed a new and simple method for light source discrimination and facial pattern detection from negative color film. The illumination source types were discriminated by stretching the original primary intensities with the standardized scaling factors and mean sorting classification of the scaled values. Skin-color regions were extracted on the basis of statistical probability analysis of pixels'lightness and chromaticities measured in skin-color regions and were segmented by using binary digital image processing. We detected the facial patterns from these regions using the knowledge-based multistep filtering of their mensuration pattern variables. The discrimination and the detection experiments gave 95.3 and 100 % correct results, respectively. Verification of this method was shown by the experimental results. The proposed techniques are significant for exposure control, skin-color region segmentation, facial pattern detection, and color control automation in color reproduction from negative color film"
            },
            "slug": "Method-for-light-source-discrimination-and-facial-Sanger-Haneishi",
            "title": {
                "fragments": [],
                "text": "Method for light source discrimination and facial pattern detection from negative color films"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The proposed techniques are significant for exposure control, skin-color region segmentation, facial pattern detection, and color control automation in color reproduction from negative color film."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721539"
                        ],
                        "name": "Hsi-Jian Lee",
                        "slug": "Hsi-Jian-Lee",
                        "structuredName": {
                            "firstName": "Hsi-Jian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsi-Jian Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2637837"
                        ],
                        "name": "Zen Chen",
                        "slug": "Zen-Chen",
                        "structuredName": {
                            "firstName": "Zen",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zen Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "finding people in static images, though [ 9 ] shows that a stick-figure group can"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8802053,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d0ce887604a00a282574fd63b0392444d8ce13e",
            "isKey": false,
            "numCitedBy": 212,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Determination-of-3D-human-body-postures-from-a-view-Lee-Chen",
            "title": {
                "fragments": [],
                "text": "Determination of 3D human body postures from a single view"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642074"
                        ],
                        "name": "R. Price",
                        "slug": "R.-Price",
                        "structuredName": {
                            "firstName": "Rosanne",
                            "lastName": "Price",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Price"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398826750"
                        ],
                        "name": "Suliman Al-Hawamdeh",
                        "slug": "Suliman-Al-Hawamdeh",
                        "structuredName": {
                            "firstName": "Suliman",
                            "lastName": "Al-Hawamdeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Suliman Al-Hawamdeh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19461089,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cafa7e8d5cd37de9b213ceb15b1130554d6aa8cd",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Relevance feedback techniques have been success fully applied to document retrieval systems (DRS) to refine queries and document representations. This paper represents a first attempt to apply and optimise relevance feedback techniques to improve retrieval in a text-based image archival system. The design exploits the rapid assessment possible with image data to facilitate query refinement and collect large amounts of relevance feedback data This data can then be used to extend incomplete image descriptions, thus ameliorat ing problems associated with text annotation of images. Visu ally oriented relevance feedback and query modification is implemented using direct mampulation of icons. An algorithm designed for dynamic modification of image descriptions based on relevance feedback is proposed, implemented, and experi mentally tested. Initial experiments show significant improve ments and demonstrate the potential of using these tech niques for image retrieval applications."
            },
            "slug": "Applying-relevance-feedback-to-a-photo-archival-Price-Chua",
            "title": {
                "fragments": [],
                "text": "Applying relevance feedback to a photo archival system"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This paper represents a first attempt to apply and optimise relevance feedback techniques to improve retrieval in a text-based image archival system and exploits the rapid assessment possible with image data to facilitate query refinement and collect large amounts of relevance feedback data."
            },
            "venue": {
                "fragments": [],
                "text": "J. Inf. Sci."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72419159"
                        ],
                        "name": "R. Brooks",
                        "slug": "R.-Brooks",
                        "structuredName": {
                            "firstName": "Rodney",
                            "lastName": "Brooks",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brooks"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The reason we have achieved such good performance, and expect even better performance in the future, is that we use object models quite different from those commonly used in computer vision (though similar to proposals in [2, 14])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Sets of points forming regions with roughly straight axes (\"ribbons\" [2]) are found using an algorithm based on the Hough transformation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2011964,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8831f3095686131a98731d6806abdc75c6baebd",
            "isKey": false,
            "numCitedBy": 809,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Symbolic-Reasoning-Among-3-D-Models-and-2-D-Images-Brooks",
            "title": {
                "fragments": [],
                "text": "Symbolic Reasoning Among 3-D Models and 2-D Images"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1995364"
                        ],
                        "name": "Claudette C\u00e9dras",
                        "slug": "Claudette-C\u00e9dras",
                        "structuredName": {
                            "firstName": "Claudette",
                            "lastName": "C\u00e9dras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claudette C\u00e9dras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103012"
                        ],
                        "name": "M. Shah",
                        "slug": "M.-Shah",
                        "structuredName": {
                            "firstName": "Mubarak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shah"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17413587,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d19e866a7b807fe749bd3748a7499f8d5ef5df15",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Motion-based recognition deals with the recognition of objects or motions directly from the motion information extracted from a sequence of images. There are two main steps in this approach. The first consists of finding an appropriate representation for the objects or motions, from the motion cues of the sequence, and then organize them into useful representations. The second step consists of the matching of some unknown input with a model. This paper provides a review of recent developments in motion-based recognition.<<ETX>>"
            },
            "slug": "A-survey-of-motion-analysis-from-moving-light-C\u00e9dras-Shah",
            "title": {
                "fragments": [],
                "text": "A survey of motion analysis from moving light displays"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper provides a review of recent developments in motion-based recognition and finds an appropriate representation for the objects or motions from the motion cues of the sequence, and then organize them into useful representations."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706614"
                        ],
                        "name": "J. Connell",
                        "slug": "J.-Connell",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Connell",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Connell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120971205"
                        ],
                        "name": "M. Brady",
                        "slug": "M.-Brady",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brady",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brady"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2025699,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35cf177b0e0803d32d831f99af17d59c71b080f2",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Generating-and-Generalizing-Models-of-Visual-Connell-Brady",
            "title": {
                "fragments": [],
                "text": "Generating and Generalizing Models of Visual Objects"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144248008"
                        ],
                        "name": "K. Akita",
                        "slug": "K.-Akita",
                        "structuredName": {
                            "firstName": "Koichiro",
                            "lastName": "Akita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Akita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 127
                            }
                        ],
                        "text": "Typical systems group regions into stick gures by combining reasoning about gravity[28] or knowledge about background material [2] with motion cues, to form and fuse image ribbons."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33099756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c74c4ee1466a7c083ab70fdccfbb3e4e4226c364",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-sequence-analysis-of-real-world-human-motion-Akita",
            "title": {
                "fragments": [],
                "text": "Image sequence analysis of real world human motion"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3453447"
                        ],
                        "name": "J. Mundy",
                        "slug": "J.-Mundy",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Mundy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mundy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "An extensive bibliography of this approach appears in [ 12 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117429742,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5ad56913c7b703eefde3ec61dd2ede2b7131ec23",
            "isKey": false,
            "numCitedBy": 696,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 Foundations: algebraic invariants - invariant theory and enumerative combinatorics of young tableaux, Shreeram S. Abhyankar, geometric interpretation of joint conic invariants, Joseph L. Mundy, et al, an experimental evaluation of projective invariants, Christopher Coelho, et al the projection of two non-coplanar conics, Stephen J. Maybank the non-existence of general-case view-invariants, J. Brian Burns, et al invariants of non-algebraic curves - noise resistant invariants of curves, Isaac Weiss, semi-differential invariants, Luc J. Van Gool, et al, projective invariants for curves in two and three dimensions, Michael H. Brill, et al, numerical evaluation of differential and semi-differential invariants, Christopher Brown, recognizing general curved objects efficiently, Andrew Zisserman, et al fitting affine invariant conics to curves, Deepak Kapur and Joseph L. Mundy, projectively invariant decomposition of planar shapes, Stefan Carlsson invariants from multiple views - invariant linear methods in photogrammetry and model-matching, Eamon B. Barrett, et al semi-differential invariants for nonplanar curves, Luc J. Van Gool, et al disambiguating stereo matches with spatio-temporal surfaces, Olivier Faugeras and Theo Papadopoulo. Part 2 Applications: transformation invariant indexing, Haim J. Wolfson and Yehezkel Lamdan affine invariants for model-based recognition, John E. Hopcroft, et al object recognition based on moment (or algebraic) invariants, Gabriel Taubin and David B. Cooper fast recognition using algebraic invariants, Charles A. Rothwell, et al toward 3D curved object recognition from image contours, Jean Ponce and David J. Kriegman relative positioning with uncalibrated cameras, Roger Mohr, et al. Appendix: projective geometry for machine vision, Joseph L. Mundy and Andrew Zisserman."
            },
            "slug": "Geometric-invariance-in-computer-vision-Mundy-Zisserman",
            "title": {
                "fragments": [],
                "text": "Geometric invariance in computer vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052391642"
                        ],
                        "name": "J. O'Rourke",
                        "slug": "J.-O'Rourke",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "O'Rourke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O'Rourke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699200"
                        ],
                        "name": "N. Badler",
                        "slug": "N.-Badler",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Badler",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Badler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15680007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9df0428c30b8aab4f7e6f367e70126efdfb8fc45",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "A system capable of analyzing image sequences of human motion is described. The system is structured as a feedback loop between high and low levels: predictions are made at the semantic level and verifications are sought at the image level. The domain of human motion lends itself to a model-driven analysis, and the system includes a detailed model of the human body. All information extracted from the image is interpreted through a constraint network based on the structure of the human model. A constraint propagation operator is defined and its theoretical properties outlined. An implementation of this operator is described, and results of the analysis system for short image sequences are presented."
            },
            "slug": "Model-based-image-analysis-of-human-motion-using-O'Rourke-Badler",
            "title": {
                "fragments": [],
                "text": "Model-based image analysis of human motion using constraint propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A system capable of analyzing image sequences of human motion is described, structured as a feedback loop between high and low levels: predictions are made at the semantic level and verifications are sought at the image level."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144760431"
                        ],
                        "name": "Charlie Rothwell",
                        "slug": "Charlie-Rothwell",
                        "structuredName": {
                            "firstName": "Charlie",
                            "lastName": "Rothwell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charlie Rothwell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3453447"
                        ],
                        "name": "J. Mundy",
                        "slug": "J.-Mundy",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Mundy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mundy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14449399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3759b348e7ea26e6bb66409ce2133bc1e846c7ba",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Projectively invariant shape descriptors allow fast indexing into model libraries without the need for pose computation or camera calibration. Progress in building a model-based vision system for plane objects that uses algebraic projective invariants is described. A brief account of these descriptors is given, and the recognition system is described, giving examples of the invariant techniques working on real images.<<ETX>>"
            },
            "slug": "Efficient-model-library-access-by-projectively-Rothwell-Zisserman",
            "title": {
                "fragments": [],
                "text": "Efficient model library access by projectively invariant indexing functions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Progress in building a model-based vision system for plane objects that uses algebraic projective invariants and the recognition system is described, giving examples of the invariant techniques working on real images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49967740"
                        ],
                        "name": "S. Ahmad",
                        "slug": "S.-Ahmad",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Ahmad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ahmad"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9076218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "774b47614297ff6377cc9ff6c4962989e9237430",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a computer vision system for tracking human hands. The algorithms used to extract the 3D position, and planar orientation of the hand, and the joint angles of the fingers are described. The combined system is able to track a natural hand at 30 frames per second on a standard workstation with no special image processing hardware other than a frame grabber. The tracker has been used as an interface for navigating around virtual worlds.<<ETX>>"
            },
            "slug": "A-usable-real-time-3D-hand-tracker-Ahmad",
            "title": {
                "fragments": [],
                "text": "A usable real-time 3D hand tracker"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "The algorithms used to extract the 3D position, and planar orientation of the hand, and the joint angles of the fingers are described and the combined system is able to track a natural hand at 30 frames per second on a standard workstation with no special image processing hardware other than a frame grabber."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 28th Asilomar Conference on Signals, Systems and Computers"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120971205"
                        ],
                        "name": "M. Brady",
                        "slug": "M.-Brady",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brady",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brady"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3358140"
                        ],
                        "name": "H. Asada",
                        "slug": "H.-Asada",
                        "structuredName": {
                            "firstName": "Haruo",
                            "lastName": "Asada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Asada"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "Pairs of edge points with a near-parallel local symmetry [1] are found by a straightforward algorithm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120786138,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d1fab670ebf598792e849a3bb72fd065e059407",
            "isKey": false,
            "numCitedBy": 394,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel representation of two-dimensional shape that we call smoothed local symmetries (SLS). Smoothed local symmetries represent both the bounding contour of a shape fragment and the region that it occupies. In this paper we develop the main features of the SLS repre sentation and describe an implemented algorithm that com putes it. The performance of the algorithm is illustrated for a set of tools. We conclude by sketching a method for deter mining the articulation of a shape into subshapes."
            },
            "slug": "Smoothed-Local-Symmetries-and-Their-Implementation-Brady-Asada",
            "title": {
                "fragments": [],
                "text": "Smoothed Local Symmetries and Their Implementation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The main features of the SLS repre sentation are developed and an implemented algorithm that com putes it is described and illustrated for a set of tools."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17009967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3740a2ab2936c2d87f6a3d8b742841a383ba502",
            "isKey": false,
            "numCitedBy": 502,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer sensing of hand and limb motion is an important problem for applications in human computer interaction and computer graphics. We describe a framework for local trading of self occluding motion, in which one part of an object obstructs the visibility of another. Our approach uses a kinematic model to predict occlusions and windowed templates to track partially occluded objects. We present offline 3D tracking results for hand motion with significant self occlusion.<<ETX>>"
            },
            "slug": "Model-based-tracking-of-self-occluding-articulated-Rehg-Kanade",
            "title": {
                "fragments": [],
                "text": "Model-based tracking of self-occluding articulated objects"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work describes a framework for local trading of self occluding motion, in which one part of an object obstructs the visibility of another, using a kinematic model to predict occlusions and windowed templates to track partially occluded objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145286523"
                        ],
                        "name": "K. Rohr",
                        "slug": "K.-Rohr",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Rohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rohr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 107
                            }
                        ],
                        "text": "The constraints on human dynamics can be exploited to locate moving people in images [43] or to track them [46, 18] The resulting gures can then be labelled to various degrees of granularity, leading to inferences 4"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122238372,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92ab4fc76e2f085dde81626794b79b5e9d1d00e0",
            "isKey": false,
            "numCitedBy": 491,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The interpretation of the movements of articulated bodies in image sequences is one of the most challenging problems in computer vision. In this contribution, we introduce a model-based approach for the recognition of pedestrians. We represent the human body by a 3D-model consisting of cylinders, whereas for modelling the movement of walking we use data from medical motion studies. The estimation of model parameters in consecutive images is done by applying a Kalman filter. Experimental results are shown for synthetic as well as for real image data."
            },
            "slug": "Towards-model-based-recognition-of-human-movements-Rohr",
            "title": {
                "fragments": [],
                "text": "Towards model-based recognition of human movements in image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A model-based approach for the recognition of pedestrians is introduced and the human body is represented by a 3D-model consisting of cylinders, whereas for modelling the movement of walking the authors use data from medical motion studies."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46975541"
                        ],
                        "name": "Barry Taylor",
                        "slug": "Barry-Taylor",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barry Taylor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59833520,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "2f9dd1cde9850a71484af4734946a2a09cfdcfd5",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper proposes a formal account of Aristotle's trichotomy of verbs, in terms of properties of their continuous tensings, into S(\u2018state\u2019)-verbs, K(\u2018kinesis\u2019)-verbs, and E-(\u2018energeia\u2019)-verbs. Within a Fregean tense framework in which predicates are relativized to times, an account of the continuous tenses is presented and a preliminary account of the trichotomy devised, which permits an illuminating analogy to be drawn between the temporal properties of E- and K-verbs and the spatial properties of stuffs and substances. This analogy is drawn upon in constructing a sophisticated version of the preliminary theory accommodating more of the linguistic data."
            },
            "slug": "Tense-and-continuity-Taylor",
            "title": {
                "fragments": [],
                "text": "Tense and continuity"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An illuminating analogy to be drawn between the temporal properties of E- and K-verbs and the spatial properties of stuffs and substances is drawn in constructing a sophisticated version of the preliminary theory accommodating more of the linguistic data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2782750"
                        ],
                        "name": "J. Peregrin",
                        "slug": "J.-Peregrin",
                        "structuredName": {
                            "firstName": "Jaroslav",
                            "lastName": "Peregrin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Peregrin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 55580011,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "6721215c5f1929091fa1c6e798b367145b25a910",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "L'A. tente de demontrer que l'alliance entre la linguistique et la philosophie, et plus precisement entre la semantique et la metaphysique, est plutot delicate, malgre son caractere apparemment fructueux, dans la mesure ou elle engendre des cercles vicieux dangereux. En effet, les linguistes ont tendance a expliquer certains phenomenes en se basant sur certaines entites ou certaines doctrines philosophiques, dont l'explication repose a son tour sur les phenomenes linguistiques expliques. Par exemple, les linguistes tentent parfois d'expliquer des mots tels que necessaire en se referant simplement a des mondes possibles dont ils ne s'inquietent pas de la nature reelle parce qu'elle est expliquee par les philosophes. Toutefois, les philosophes se situant apres le tournant linguistique ayant touche la pensee philosophique souhaiteraient reduire l'explication des mondes possibles a l'explication du discours sur les mondes possibles, ce qui n'est rien d'autre que le discours linguistique, ou logico-linguistique, sur les mots tels que necessaire"
            },
            "slug": "LINGUISTICS-AND-PHILOSOPHY-Peregrin",
            "title": {
                "fragments": [],
                "text": "LINGUISTICS AND PHILOSOPHY"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113044621"
                        ],
                        "name": "L. Spier",
                        "slug": "L.-Spier",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Spier",
                            "middleNames": [
                                "."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Spier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15342629"
                        ],
                        "name": "A. Hallowell",
                        "slug": "A.-Hallowell",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Hallowell",
                            "middleNames": [
                                "Irving"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hallowell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116232749"
                        ],
                        "name": "Stanley S. Newman",
                        "slug": "Stanley-S.-Newman",
                        "structuredName": {
                            "firstName": "Stanley",
                            "lastName": "Newman",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stanley S. Newman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 144589610,
            "fieldsOfStudy": [
                "Linguistics",
                "Psychology"
            ],
            "id": "d6d81aa1193a507cfea2de7a0b0d16a444a7cf33",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The interconnection between language, culture, and personality is the theme of these essays dedicated to the memory of Edward Sapir, and written by his former students."
            },
            "slug": "Language,-culture,-and-personality-:-essays-in-of-Spier-Hallowell",
            "title": {
                "fragments": [],
                "text": "Language, culture, and personality : essays in memory of Edward Sapir"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1942
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11920722"
                        ],
                        "name": "C. Tenny",
                        "slug": "C.-Tenny",
                        "structuredName": {
                            "firstName": "Carol",
                            "lastName": "Tenny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tenny"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 170437644,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "54aa7bcb3ad8dda689762ec1c40348c300dfa017",
            "isKey": false,
            "numCitedBy": 379,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Thesis (Ph. D.)--Massachusetts Institute of Technology, Dept. of Linguistics and Philosophy, 1987."
            },
            "slug": "Grammaticalizing-aspect-and-affectedness-Tenny",
            "title": {
                "fragments": [],
                "text": "Grammaticalizing aspect and affectedness"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152883679"
                        ],
                        "name": "J. Ashley",
                        "slug": "J.-Ashley",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Ashley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ashley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "The best-known such system is QBIC [15], which allows an opera-tor to specify various properties of a desired image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "Niblack, W., Barber, R, Equitz, W., Flickner, M., Glasman, E., Petkovic, D., andYanker, P. (1993) \\The QBIC project: querying images by content using colour,texture and shape,\" IS and T/SPIE 1993 Intern."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "Photobook [17] largely shares QBIC's model of\nan image as a collage of at, homogenous frontally presented regions, but incor-porates more sophisticated representations of texture and a degree of automaticsegmentation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "Region segmentation is largely manual, but the most recent versions of QBIC [3] contain simple automated segmentation facilities."
                    },
                    "intents": []
                }
            ],
            "corpusId": 59778742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aaec4bdc654cdac76aa39a9f145995bf092a8f09",
            "isKey": true,
            "numCitedBy": 108,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-and-Semi-Automatic-Methods-for-Image-and-Ashley",
            "title": {
                "fragments": [],
                "text": "Automatic and Semi-Automatic Methods for Image Annotation and Retrieval in QBIC"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 11
                            }
                        ],
                        "text": "Similarly, Chabot [16] uses a combination of visual appearance andtext-based cues to retrieve images, but depends strongly on text cues to identifyobjects."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Similarly, Chabot [16] uses a combination of visual appearance and text-based cues to retrieve images, but depends strongly on text cues to identify objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 50
                            }
                        ],
                        "text": "Ogle, Virginia E. and Michael Stonebraker (1995) \\Chabot: Retrieval from a Re-lational Database of Images,\" Computer 28/9, pp. 40{48.17."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chabot: Retrieval from a Re lational Database of Images,\" Computer 28/9"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38893714"
                        ],
                        "name": "D. Alman",
                        "slug": "D.-Alman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Alman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Alman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "The color of a human's skin is created by a combination of blood (red) and melanin (yellow, brown) [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121736180,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "5347d7de16a658a434de1a430e7767b607c2dd4c",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Colour\u2014Why-the-World-Isn't-Grey,-by-Hazel-Rossotti,-Alman",
            "title": {
                "fragments": [],
                "text": "Colour\u2014Why the World Isn't Grey, by Hazel Rossotti, Princeton University Press, Princeton, 1985, 239 pp., paperbound. Price $9.95"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145749008"
                        ],
                        "name": "G. H. Jacobs",
                        "slug": "G.-H.-Jacobs",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. H. Jacobs"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 82488167,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "94497494c6c5f945b2dd3821c839dae6089dea74",
            "isKey": false,
            "numCitedBy": 361,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Comparative-Color-Vision-Jacobs",
            "title": {
                "fragments": [],
                "text": "Comparative Color Vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35206821"
                        ],
                        "name": "P. Kelly",
                        "slug": "P.-Kelly",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Kelly",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kelly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143712097"
                        ],
                        "name": "T. M. Cannon",
                        "slug": "T.-M.-Cannon",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Cannon",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. M. Cannon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754328"
                        ],
                        "name": "D. Hush",
                        "slug": "D.-Hush",
                        "structuredName": {
                            "firstName": "Don",
                            "lastName": "Hush",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hush"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40427218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "81e3941f75eb589ac102dded7f15a81f56fcab5a",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "CANDID (comparison algorithm for navigating digital image databases) was developed to enable content-based retrieval of digital imagery from large databases using a query-by- example methodology. A user provides an example image to the system, and images in the database that are similar to that example are retrieved. The development of CANDID was inspired by the N-gram approach to document fingerprinting, where a `global signature' is computed for every document in a database and these signatures are compared to one another to determine the similarity between any two documents. CANDID computes a global signature for every image in a database, where the signature is derived from various image features such as localized texture, shape, or color information. A distance between probability density functions of feature vectors is then used to compare signatures. In this paper, we present CANDID and highlight two results from our current research: subtracting a `background' signature from every signature in a database in an attempt to improve system performance when using inner-product similarity measures, and visualizing the contribution of individual pixels in the matching process. These ideas are applicable to any histogram-based comparison technique."
            },
            "slug": "Query-by-image-example:-the-comparison-algorithm-Kelly-Cannon",
            "title": {
                "fragments": [],
                "text": "Query by image example: the comparison algorithm for navigating digital image databases (CANDID) approach"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Two results from the current research are presented: subtracting a `background' signature from every signature in a database in an attempt to improve system performance when using inner-product similarity measures, and visualizing the contribution of individual pixels in the matching process."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 264
                            }
                        ],
                        "text": "These images frequently lack textual labels adequate to identify their content but can be e ectively detected using simple visual cues (color, texture, simple shape features), of the type that the human visual system is known to use for fast (preattentive) triage [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Preattentive Processing in Vision,\" Com"
            },
            "venue": {
                "fragments": [],
                "text": "Vis. Grap. Im.  Proc"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computer Vision and Pattern Recognition pp"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision and Pattern Recognition pp"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 93
                            }
                        ],
                        "text": "Appropriate feature correspondences can be obtained by various forms of search (for example, [19, 17])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object recognition using alignment,"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. ICCV-  1,"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J. \\Object Recognition by AAne Invariant Matching Proceedings CVPR"
            },
            "venue": {
                "fragments": [],
                "text": "J. \\Object Recognition by AAne Invariant Matching Proceedings CVPR"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "Typical systems group regions into stick gures by combining reasoning about gravity[28] or knowledge about background material [2] with motion cues, to form and fuse image ribbons."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "First sight: a human body labelling system,"
            },
            "venue": {
                "fragments": [],
                "text": "PAMI,  17,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 206
                            }
                        ],
                        "text": "Current part-based recognition systems are strongly oriented to recovering cross-sectional information, and do not treat the case where there are many parts with few or no individual distinguishing features[22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "From an intensity image to 3D segmented descrip tions,\" ICPR, 1994.  This article was processed using the  LATEX macro package with ECCV'96 style"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\The Topology of Boundaries,\" in press, Artiicial Intelli- gence"
            },
            "venue": {
                "fragments": [],
                "text": "\\The Topology of Boundaries,\" in press, Artiicial Intelli- gence"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Computer Identiication of Visual Surfaces"
            },
            "venue": {
                "fragments": [],
                "text": "Comp. Vis. Im. Proc"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "This article was processed using the L A T E X macro package with ECCV'96 style"
            },
            "venue": {
                "fragments": [],
                "text": "This article was processed using the L A T E X macro package with ECCV'96 style"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "(1994) \\Detecting and localization of face on digital images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition Letters"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Topology of Boundaries,\" in press, Arti cial Intelli-  gence"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 170
                            }
                        ],
                        "text": "These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include [14, 26, 48, 52, 54, 60, 30, 24])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rothwell,  \\Invariant Descriptors for 3D Recognition and Pose,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Patt. Anal. and  Mach. Intelligence,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc SIGGRAPH-95"
            },
            "venue": {
                "fragments": [],
                "text": "Proc SIGGRAPH-95"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "The hypothesis that the object is present is then veri ed using the estimate of appearance [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognition by linear combination of models"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE PAMI,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Structural indexing: eecient 3D object recognition"
            },
            "venue": {
                "fragments": [],
                "text": "\\Structural indexing: eecient 3D object recognition"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 170
                            }
                        ],
                        "text": "These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include [14, 26, 48, 52, 54, 60, 30, 24])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object recognition based on moment (or algebraic)  invariants,\" in J.L"
            },
            "venue": {
                "fragments": [],
                "text": "Mundy and A.P. Zisserman (ed.s)Geometric Invariance in Computer  Vision, MIT Press,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Iowa City Press Citizen, \\White Hous\u00e8couples' set oo indecency program"
            },
            "venue": {
                "fragments": [],
                "text": "Iowa City Press Citizen, \\White Hous\u00e8couples' set oo indecency program"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 113
                            }
                        ],
                        "text": "If the marked regions cover at least 30% 3 All operations use a fast multi-ring approximation to the median lter [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Practical edge nding with a robust estimator,"
            },
            "venue": {
                "fragments": [],
                "text": "Proc.  of the IEEE Conf. on Computer Vision and Pattern Recognition,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 170
                            }
                        ],
                        "text": "These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include [14, 26, 48, 52, 54, 60, 30, 24])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Representations for recognising complex curved 3D ob-  jects,"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. International NSF-ARPA workshop on object representation in computer  vision,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "(1994) \\Example-based Learning from View-based Human Face Detection\" MIT A.I. Lab Memo No"
            },
            "venue": {
                "fragments": [],
                "text": "(1994) \\Example-based Learning from View-based Human Face Detection\" MIT A.I. Lab Memo No"
            },
            "year": 1521
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Invariant Descriptors for 3D Recognition and Pose"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Patt. Anal. and Mach. Intelligence"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\EEcient Recognition of rotationally symmetric surfaces and straight homogenous generalized cylinders"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE conference on Computer Vision and Pattern Recognition '93"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 170
                            }
                        ],
                        "text": "These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include [14, 26, 48, 52, 54, 60, 30, 24])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object Recognition by A ne Invariant  Matching,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "Hands have been segmented using color [1] and tracked using on a kinematic model [45]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model-based tracking of self-occluding articulated ob-  jects,\" International Conference on Computer Vision pp 612-617"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Detection of Regions Matching"
            },
            "venue": {
                "fragments": [],
                "text": "Speci ed Chromatic Features,\" Comp. Vis. Im. Underst"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\The QBIC project: querying images by c o n tent using colour, texture and shape"
            },
            "venue": {
                "fragments": [],
                "text": "IS and T/SPIE 1993 Intern. Symp. Electr. Imaging: Science a n d T echnology, Conference 1908, Storage and Retrieval for Image and Video Databases"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Projective Invariants of Shapes Proceeding DARPA Image Understanding Workshop"
            },
            "venue": {
                "fragments": [],
                "text": "\\Projective Invariants of Shapes Proceeding DARPA Image Understanding Workshop"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 182
                            }
                        ],
                        "text": "The main features on a human face appear in much the same form in most images, enabling techniques based on principal component analysis or neural networks proposed by, for example, [41, 53, 49, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Detecting and localization of face on digital images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern  Recognition Letters"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 29
                            }
                        ],
                        "text": "Notable exceptions appear in [7, 5, 35, 64], which attempt to code relationships between various forms of volumetric primitive, where the description is in terms of the nature of the primitives involved and of their geometric relationship."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "From an intensity image to 3D segmented descriptions,"
            },
            "venue": {
                "fragments": [],
                "text": "ICPR,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 170
                            }
                        ],
                        "text": "These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include [14, 26, 48, 52, 54, 60, 30, 24])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rothwell, \\E cient Recogni-  tion of rotationally symmetric surfaces and straight homogenous generalized cylinders,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "This distinction and a similar distinction for actions, are well-known in linguistics and philosophy (dating back at least to [61]) where they are used to predict di erences in the behavior of nouns and verbs (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Relation of Habitual Thought and Behavior to Lan-  guage,\" in Leslie Spier, ed., Language, culture, and personality, essays in memory of  Edward"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1941
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\ The QBIC project : querying images by content using colour , texture and shape , \" IS and T / SPIE 1993 Intern"
            },
            "venue": {
                "fragments": [],
                "text": "Symp . Electr . Imaging : Science and Technology , Conference 1908 , Storage and Retrieval for Image and VideoDatabases"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 170
                            }
                        ],
                        "text": "These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include [14, 26, 48, 52, 54, 60, 30, 24])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "E cient Model Library  Access by Projectively Invariant Indexing Functions,\" Computer Vision and Pattern  Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MacFormat, issue no. 28 with CD-Rom"
            },
            "venue": {
                "fragments": [],
                "text": "MacFormat, issue no. 28 with CD-Rom"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ") \\Human Face Detection in Visual Scenes\" To Appear in: Neural Information Processing Systems"
            },
            "venue": {
                "fragments": [],
                "text": ") \\Human Face Detection in Visual Scenes\" To Appear in: Neural Information Processing Systems"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Photobook [17] largely shares QBIC's model of"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Photobook: content-based manipu lation of image databases,\" MIT Media Lab Perceptual Computing"
            },
            "venue": {
                "fragments": [],
                "text": "TR No. 255,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 213
                            }
                        ],
                        "text": "All of the approaches described rely heavily on speci c, detailed geometry, known (or easily determined) correspondences, and either the existence of a single object on a uniform, known background (in the case of [34]) or the prospect of relatively clear segmentation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 265
                            }
                        ],
                        "text": "An alternative approach computes a feature vector from a compressed version of the image and uses a minimum distance classi er to match this feature vector to feature vectors computed from images of objects in a range of positions under various lighting conditions [34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visual learning and recognition of 3D objects from ap-  pearance,\" to appear"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Computer Vision,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 170
                            }
                        ],
                        "text": "These invariants can then be used as an index for a model library (examples of various combinations of geometry, imaging transformations, and indexing strategies include [14, 26, 48, 52, 54, 60, 30, 24])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Structural indexing: e cient 3D object recognition,\" PAMI"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 265
                            }
                        ],
                        "text": "An alternative approach computes a feature vector from a compressed version of the image and uses a minimum distance classi er to match this feature vector to feature vectors computed from images of objects in a range of positions under various lighting conditions [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visual learning and recognition of 3D objects from  appearance,\" to appear"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Computer Vision,"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 32,
            "methodology": 10
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 85,
        "totalPages": 9
    },
    "page_url": "https://www.semanticscholar.org/paper/Finding-Naked-People-Fleck-Forsyth/4ccda575c3c3e96bb99522c5a8ab158474a9f2f3?sort=total-citations"
}