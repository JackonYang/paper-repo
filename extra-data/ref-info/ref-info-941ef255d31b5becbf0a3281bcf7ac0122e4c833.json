{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2403454"
                        ],
                        "name": "E. Baum",
                        "slug": "E.-Baum",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Baum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Baum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19460515,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a7404527c3a6aa542ea183da9c821efda05a2afc",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm which trains networks using examples and queries is proposed. In a query, the algorithm supplies a y and is told t(y) by an oracle. Queries appear to be available in practice for most problems of interest, e.g. by appeal to a human expert. The author's algorithm is proved to PAC learn in polynomial time the class of target functions defined by layered, depth two, threshold nets having n inputs connected to k hidden threshold units connected to one or more output units, provided k=/<4. While target functions and input distributions can be described for which the algorithm will fail for larger k, it appears likely to work well in practice. Tests of a variant of the algorithm have consistently and rapidly learned random nets of this type. Computational efficiency figures are given. The algorithm can also be proved to learn intersections of k half-spaces in R(n) in time polynomial in both n and k. A variant of the algorithm can learn arbitrary depth layered threshold networks with n inputs and k units in the first hidden layer in time polynomial in the larger of n and k but exponential in the smaller of the two."
            },
            "slug": "Neural-net-algorithms-that-learn-in-polynomial-time-Baum",
            "title": {
                "fragments": [],
                "text": "Neural net algorithms that learn in polynomial time from examples and queries"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The author's algorithm is proved to PAC learn in polynomial time the class of target functions defined by layered, depth two, threshold nets having n inputs connected to k hidden threshold units connected to one or more output units, provided k=/<4."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8992604"
                        ],
                        "name": "E. Levin",
                        "slug": "E.-Levin",
                        "structuredName": {
                            "firstName": "Esther",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Levin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759839"
                        ],
                        "name": "S. Solla",
                        "slug": "S.-Solla",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Solla",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Solla"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15012839,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b10440620da8a43a1b97e3da4b1ff13746306475",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of learning a general input-output relation using a layered neural network is discussed in a statistical framework. By imposing the consistency condition that the error minimization be equivalent to a likelihood maximization for training the network, the authors arrive at a Gibbs distribution on a canonical ensemble of networks with the same architecture. This statistical description enables them to evaluate the probability of a correct prediction of an independent example, after training the network on a given training set. The prediction probability is highly correlated with the generalization ability of the network, as measured outside the training set. This suggests a general and practical criterion for training layered networks by minimizing prediction errors. The authors demonstrate the utility of this criterion for selecting the optimal architecture in the continuity problem. As a theoretical application of the statistical formalism, they discuss the question of learning curves and estimate the sufficient training size needed for correct generalization, in a simple example.<<ETX>>"
            },
            "slug": "Consistent-inference-of-probabilities-in-layered-Tishby-Levin",
            "title": {
                "fragments": [],
                "text": "Consistent inference of probabilities in layered networks: predictions and generalizations"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The problem of learning a general input-output relation using a layered neural network is discussed in a statistical framework and the authors arrive at a Gibbs distribution on a canonical ensemble of networks with the same architecture."
            },
            "venue": {
                "fragments": [],
                "text": "International 1989 Joint Conference on Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076815081"
                        ],
                        "name": "Seung",
                        "slug": "Seung",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Seung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30053069"
                        ],
                        "name": "Sompolinsky",
                        "slug": "Sompolinsky",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Sompolinsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sompolinsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30093773"
                        ],
                        "name": "Tishby",
                        "slug": "Tishby",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tishby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7394722,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2498a4e1755f047accc06a6e0fab0b0eb1b37ae0",
            "isKey": false,
            "numCitedBy": 393,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "number of examples P used for training. The theory implies that, for a reduction in eg that remains finite in the large-N limit, P should generally scale as nN, where N is the number of independently adjustable weights in the network. We show that for smooth networks, i.e., those with continuously varying weights and smooth transfer functions, the generalization curve asymptotically obeys an inverse power law. In contrast, for nonsmooth networks other behaviors can appear, depending on the nature of the nonlinearities as well as the realizability of the rule. In particular, a discontinuous learning transition from a state of poor to a state of perfect generalization can occur in nonsmooth networks learning realizable rules. We illustrate both gradual and continuous learning with a detailed analytical and numerical study of several single-layer perceptron models. Comparing with the exact replica theory of perceptron learning, we find that for realizable rules the high-temperature and annealed theories provide very good approximations to the generalization performance. Assuming this to hold for multilayer networks as well, we propose a classification of possible asymptotic forms of learning curves in general realizable models. For unrealizable rules we find that the above approximations fail in general to predict correctly the shapes of the generalization curves. Another indication of the important role of quenched disorder for unrealizable rules is that the generalization error is not necessarily a monotonically increasing function of temperature. Also, unrealizable rules can possess genuine spin-glass phases indicative of degenerate minima separated by high barriers."
            },
            "slug": "Statistical-mechanics-of-learning-from-examples.-Seung-Sompolinsky",
            "title": {
                "fragments": [],
                "text": "Statistical mechanics of learning from examples."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that for smooth networks, i.e., those with continuously varying weights and smooth transfer functions, the generalization curve asymptotically obeys an inverse power law, while for nonsmooth networks other behaviors can appear, depending on the nature of the nonlinearities as well as the realizability of the rule."
            },
            "venue": {
                "fragments": [],
                "text": "Physical review. A, Atomic, molecular, and optical physics"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29996782"
                        ],
                        "name": "Opper",
                        "slug": "Opper",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Opper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084880812"
                        ],
                        "name": "Haussler",
                        "slug": "Haussler",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haussler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40821171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40ea198170b7e6af50b4e269b3a4d3cd86e2d1ad",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The generalization error of the Bayes optimal classification algorithm when learning a perceptron from noise-free random training examples is calculated exactly using methods of statistical mechanics. It is shown that if an assumption of replica symmetry is made, then, in the thermodynamic limit, the error of the Bayes optimal algorithm is less than the error of a canonical stochastic learning algorithm, by a factor approaching \\ensuremath{\\surd}2 as the ratio of the number of training examples to perceptron weights grows. In addition, it is shown that approximations to the generalization error of the Bayes optimal algorithm can be achieved by learning algorithms that use a two-layer neutral net to learn a perceptron."
            },
            "slug": "Generalization-performance-of-Bayes-optimal-for-a-Opper-Haussler",
            "title": {
                "fragments": [],
                "text": "Generalization performance of Bayes optimal classification algorithm for learning a perceptron."
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "It is shown that approximations to the generalization error of the Bayes optimal algorithm can be achieved by learning algorithms that use a two-layer neutral net to learn a perceptron."
            },
            "venue": {
                "fragments": [],
                "text": "Physical review letters"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69052801"
                        ],
                        "name": "T. Watkin",
                        "slug": "T.-Watkin",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Watkin",
                            "middleNames": [
                                "L.",
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Watkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31873701"
                        ],
                        "name": "A. Rau",
                        "slug": "A.-Rau",
                        "structuredName": {
                            "firstName": "Albrecht",
                            "lastName": "Rau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rau"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120686463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8b1c2a1c21406daee5ac5282fe0f49d23e18487",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A technique is introduced for analysing the learning process of perceptrons which continually select their own examples (the most efficient training algorithm yet devised). The authors predict a 42% reduction in the number of examples 'wasted' in training an Ising perceptron, compared to the case in which examples are random. Optimally stable spherical perceptrons may also be taught significantly more efficiently, and their results compare well with an existing numerical simulation."
            },
            "slug": "Selecting-examples-for-perceptrons-Watkin-Rau",
            "title": {
                "fragments": [],
                "text": "Selecting examples for perceptrons"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A technique is introduced for analysing the learning process of perceptrons which continually select their own examples (the most efficient training algorithm yet devised), which predicts a 42% reduction in the number of examples 'wasted' in training an Ising perceptron."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48085756"
                        ],
                        "name": "E. Gardner",
                        "slug": "E.-Gardner",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Gardner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gardner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6362891"
                        ],
                        "name": "B. Derrida",
                        "slug": "B.-Derrida",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Derrida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Derrida"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 123610677,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "65d3c09ba1b660de1bda83de31ef96d2c69d474a",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The optimal storage properties of three different neural network models are studied. For two of these models the architecture of the network is a perceptron with +or-J interactions, whereas for the third model the output can be an arbitrary function of the inputs. Analytic bounds and numerical estimates of the optimal capacities and of the minimal fraction of errors are obtained for the first two models. The third model can be solved exactly and the exact solution is compared to the bounds and to the results of numerical simulations used for the two other models."
            },
            "slug": "Three-unfinished-works-on-the-optimal-storage-of-Gardner-Derrida",
            "title": {
                "fragments": [],
                "text": "Three unfinished works on the optimal storage capacity of networks"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The optimal storage properties of three different neural network models are studied and one model can be solved exactly and the exact solution is compared to the bounds and to the results of numerical simulations used for the two other models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144345775"
                        ],
                        "name": "W. Kinzel",
                        "slug": "W.-Kinzel",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Kinzel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kinzel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2585013"
                        ],
                        "name": "P. Rujan",
                        "slug": "P.-Rujan",
                        "structuredName": {
                            "firstName": "Pal",
                            "lastName": "Rujan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Rujan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119938348,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e449143111fa4a270aa36d1515ca9bba9b172304",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that the generalization ability of simple Perceptron-like devices is strongly enhanced by allowing the network itself to select the training examples. Analytic and numerical results are obtained for the Hebb and for the optimal Perceptron learning rule, respectively."
            },
            "slug": "Improving-a-Network-Generalization-Ability-by-Kinzel-Rujan",
            "title": {
                "fragments": [],
                "text": "Improving a Network Generalization Ability by Selecting Examples"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "It is shown that the generalization ability of simple Perceptron-like devices is strongly enhanced by allowing the network itself to select the training examples."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40325722"
                        ],
                        "name": "V. Fedorov",
                        "slug": "V.-Fedorov",
                        "structuredName": {
                            "firstName": "Valerii",
                            "lastName": "Fedorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Fedorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2636336"
                        ],
                        "name": "W. J. Studden",
                        "slug": "W.-J.-Studden",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Studden",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. J. Studden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98701042"
                        ],
                        "name": "E. Klimko",
                        "slug": "E.-Klimko",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Klimko",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Klimko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121909870,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "65c1a71c5307492782177a9799bef2cdf539ea00",
            "isKey": false,
            "numCitedBy": 2567,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Theory-Of-Optimal-Experiments-Fedorov-Studden",
            "title": {
                "fragments": [],
                "text": "Theory Of Optimal Experiments"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58744436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e3034bed8631249e26344149d8fad77e4ac854a",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Proceedings-of-the-fifth-annual-workshop-on-theory-Haussler",
            "title": {
                "fragments": [],
                "text": "Proceedings of the fifth annual workshop on Computational learning theory"
            },
            "venue": {
                "fragments": [],
                "text": "COLT 1992"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical theory of learning a rule"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks and Spin Glasses"
            },
            "year": 1990
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 10,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Query-by-committee-Seung-Opper/941ef255d31b5becbf0a3281bcf7ac0122e4c833?sort=total-citations"
}