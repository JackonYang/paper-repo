{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34830449"
                        ],
                        "name": "M. Sondhi",
                        "slug": "M.-Sondhi",
                        "structuredName": {
                            "firstName": "Man",
                            "lastName": "Sondhi",
                            "middleNames": [
                                "Mohan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sondhi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46254718,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "090f3ea5bc188bbb03aec02aba9ed9c7b38ff870",
            "isKey": false,
            "numCitedBy": 1082,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present several of the salient theoretical and practical issues associated with modeling a speech signal as a probabilistic function of a (hidden) Markov chain. First we give a concise review of the literature with emphasis on the Baum-Welch algorithm. This is followed by a detailed discussion of three issues not treated in the literature: alternatives to the Baum-Welch algorithm; critical facets of the implementation of the algorithms, with emphasis on their numerical properties; and behavior of Markov models on certain artificial but realistic problems. Special attention is given to a particular class of Markov models, which we call \u201cleft-to-right\u201d models. This class of models is especially appropriate for isolated word recognition. The results of the application of these methods to an isolated word, speaker-independent speech recognition experiment are given in a companion paper."
            },
            "slug": "An-introduction-to-the-application-of-the-theory-of-Levinson-Rabiner",
            "title": {
                "fragments": [],
                "text": "An introduction to the application of the theory of probabilistic functions of a Markov process to automatic speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This paper presents several of the salient theoretical and practical issues associated with modeling a speech signal as a probabilistic function of a (hidden) Markov chain, and focuses on a particular class of Markov models, which are especially appropriate for isolated word recognition."
            },
            "venue": {
                "fragments": [],
                "text": "The Bell System Technical Journal"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102981024"
                        ],
                        "name": "A. Poritz",
                        "slug": "A.-Poritz",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Poritz",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Poritz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32413326,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1e6f96bee0a7b78402866e1461d00a72612dcc69",
            "isKey": false,
            "numCitedBy": 252,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for modelling time series is presented and then applied to the analysis of the speech signal. A time series is represented as a sample sequence generated by a finite state hidden Markov model with output densities parameterized by linear prediction polynomials and error variances. These objects are defined and their properties developed. The theory culminates in a theorem that provides a computationally efficient iterative scheme to improve the model. The theorem has been used to create models from speech signals of considerable length. One such model is examined with emphasis on the relationship between states of the model and traditional classes of speech events. A use of the method is illustrated by an application to the talker verification problem."
            },
            "slug": "Linear-predictive-hidden-Markov-models-and-the-Poritz",
            "title": {
                "fragments": [],
                "text": "Linear predictive hidden Markov models and the speech signal"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A method for modelling time series is presented and then applied to the analysis of the speech signal, resulting in a theorem that provides a computationally efficient iterative scheme to improve the model."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15553242,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "436f38dc28ca25af965b202ebe0e27c747888da6",
            "isKey": false,
            "numCitedBy": 332,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a signal modeling technique based upon finite mixture autoregressive probabilistic functions of Markov chains is developed and applied to the problem of speech recognition, particularly speaker-independent recognition of isolated digits. Two types of mixture probability densities are investigated: finite mixtures of Gaussian autoregressive densities (GAM) and nearest-neighbor partitioned finite mixtures of Gaussian autoregressive densities (PGAM). In the former (GAM), the observation density in each Markov state is simply a (stochastically constrained) weighted sum of Gaussian autoregressive densities, while in the latter (PGAM) it involves nearest-neighbor decoding which in effect, defines a set of partitions on the observation space. In this paper we discuss the signal modeling methodology and give experimental results on speaker independent recognition of isolated digits. We also discuss the potential use of the modeling technique for other applications."
            },
            "slug": "Mixture-autoregressive-hidden-Markov-models-for-Juang-Rabiner",
            "title": {
                "fragments": [],
                "text": "Mixture autoregressive hidden Markov models for speech signals"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The signal modeling methodology is discussed and experimental results on speaker independent recognition of isolated digits are given and the potential use of the modeling technique for other applications are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8461145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a529e0a5a796001e466ddf305b7c66abef90ce41",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper gives a unified theoretical view of the Dynamic Time Warping (DTW) and the Hidden Markov Model (HMM) techniques for speech recognition problems. The application of hidden Markov models in speech recognition is discussed. We show that the conventional dynamic time-warping algorithm with Linear Predictive (LP) signal modeling and distortion measurements can be formulated in a strictly statistical framework. It is further shown that the DTW/LP method is implicitly associated with a specific class of Markov models and is equivalent to the probability maximization procedures for Gaussian autoregressive multivariate probabilistic functions of the underlying Markov model. This unified view offers insights into the effectiveness of the probabilistic models in speech recognition applications."
            },
            "slug": "On-the-hidden-Markov-model-and-dynamic-time-warping-Juang",
            "title": {
                "fragments": [],
                "text": "On the hidden Markov model and dynamic time warping for speech recognition \u2014 A unified view"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A unified theoretical view of the Dynamic Time Warping (DTW) and the Hidden Markov Model (HMM) techniques for speech recognition problems is given and offers insights into the effectiveness of the probabilistic models in speech recognition applications."
            },
            "venue": {
                "fragments": [],
                "text": "AT&T Bell Laboratories Technical Journal"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34830449"
                        ],
                        "name": "M. Sondhi",
                        "slug": "M.-Sondhi",
                        "structuredName": {
                            "firstName": "Man",
                            "lastName": "Sondhi",
                            "middleNames": [
                                "Mohan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sondhi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35749818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e90c15e0de8b5452c6291359e98ddc099e3b93f6",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we extend previous work on isolated-word recognition based on hidden Markov models by replacing the discrete symbol representation of the speech signal with a continuous Gaussian mixture density. In this manner the inherent quantization error introduced by the discrete representation is essentially eliminated. The resulting recognizer was tested on a vocabulary of the ten digits across a wide range of talkers and test conditions and shown to have an error rate comparable to that of the best template recognizers and significantly lower than that of the discrete symbol hidden Markov model system. We discuss several issues involved in the training of the continuous density models and in the implementation of the recognizer."
            },
            "slug": "Recognition-of-isolated-digits-using-hidden-Markov-Rabiner-Juang",
            "title": {
                "fragments": [],
                "text": "Recognition of isolated digits using hidden Markov models with continuous mixture densities"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper extends previous work on isolated-word recognition based on hidden Markov models by replacing the discrete symbol representation of the speech signal with a continuous Gaussian mixture density, thereby eliminating the inherent quantization error introduced by the discrete representation."
            },
            "venue": {
                "fragments": [],
                "text": "AT&T Technical Journal"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34830449"
                        ],
                        "name": "M. Sondhi",
                        "slug": "M.-Sondhi",
                        "structuredName": {
                            "firstName": "Man",
                            "lastName": "Sondhi",
                            "middleNames": [
                                "Mohan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sondhi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 25179305,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8acf7cb1d476ba09b401b0c13abe81d4b96d128e",
            "isKey": false,
            "numCitedBy": 343,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present an approach to speaker-independent, isolated word recognition in which the well-known techniques of vector quantization and hidden Markov modeling are combined with a linear predictive coding analysis front end. This is done in the framework of a standard statistical pattern recognition model. Both the vector quantizer and the hidden Markov models need to be trained for the vocabulary being recognized. Such training results in a distinct hidden Markov model for each word of the vocabulary. Classification consists of computing the probability of generating the test word with each word model and choosing the word model that gives the highest probability. There are several factors, in both the vector quantizer and the hidden Markov modeling, that affect the performance of the overall word recognition system, including the size of the vector quantizer, the structure of the hidden Markov model, the ways of handling insufficient training data, etc. The effects, on recognition accuracy, of many of these factors are discussed in this paper. The entire recognizer (training and testing) has been evaluated on a 10-word digits vocabulary. For training, a set of 100 talkers spoke each of the digits one time. For testing, an independent set of 100 tokens of each of the digits was obtained. The overall recognition accuracy was found to be 96.5 percent for the 100-talker test set. These results are comparable to those obtained in earlier work, using a dynamic time-warping recognition algorithm with multiple templates per digit. It is also shown that the computation and storage requirements of the new recognizer were an order of magnitude less than that required for a conventional pattern recognition system using linear prediction with dynamic time warping."
            },
            "slug": "On-the-application-of-vector-quantization-and-to-Rabiner-Levinson",
            "title": {
                "fragments": [],
                "text": "On the application of vector quantization and hidden Markov models to speaker-independent, isolated word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper presents an approach to speaker-independent, isolated word recognition in which the well-known techniques of vector quantization and hidden Markov modeling are combined with a linear predictive coding analysis front end in the framework of a standard statistical pattern recognition model."
            },
            "venue": {
                "fragments": [],
                "text": "The Bell System Technical Journal"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829859"
                        ],
                        "name": "E. Neuburg",
                        "slug": "E.-Neuburg",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Neuburg",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Neuburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 119813540,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "3a22351902820cb877ac4c611c1d5a320fcf393c",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The classical statistical models for phonetic text view phonemes as states of a Markov chain of some low order. There is a model\u2010building method which produces models that lie between these classical models and the combinatorial model of O'Connor and Trimm. To produce the new models, one hypothesizes the existence of an underlying Markov chain of low order with some small number n of states, and assumes that the probability distribution of phonetic symbols is a function of the state of the underlying chain. Given n, the model\u2010building method involves a computer hill\u2010climbing procedure on a corpus of phonetic text to find the maximum\u2010likelihood model for that text and that n. This paper describes the method and the results of a large number of ascents on a certain corpus of text. The models developed show strong linguistic features; for example, for text segmented only by silences between phoneme strings, the vowels, consonants, and boundary symbols are statistically identified with 15% errors. With text s..."
            },
            "slug": "Markov-Models-for-Phonetic-Text-Neuburg",
            "title": {
                "fragments": [],
                "text": "Markov Models for Phonetic Text"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103072546"
                        ],
                        "name": "J. Eagon",
                        "slug": "J.-Eagon",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Eagon",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eagon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14153120,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "69fc8c03d21e22e30d6642824c37158b314f36c3",
            "isKey": false,
            "numCitedBy": 1122,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Summary. The object of this note is to prove the theorem below and sketch two applications, one to statistical estimation for (proba-bilistic) functions of Markov processes [l] and one to Blakley's model for ecology [4]. 2. Result. THEOREM. Let P(x)=P({xij}) be a polynomial with nonnegative coefficients homogeneous of degree d in its variables {##}. Let x= {##} be any point of the domain D: ## \u00a7:(), ]pLi ## = 1, i = l, \u2022 \u2022 \u2022 , p, j=l, \u2022 \u2022 \u2022 , q%. For x= {xij} \u00a3\u00a3> let 3(#) = 3{##} denote the point of D whose i, j coordinate is (dP\\ \\ f \u00ab dP 3(*)<i = (Xij 7\u2014) / 2* *<i \u2014 \\ dXij\\(X)// ,-i dXij (\u00bb> Then P(3(x))>P(x) unless 3(x)=x. Notation, fi will denote a doubly indexed array of nonnegative integers: fx= {M#}> i = l> \u2022 \u2022 \u2022 > <lu i=l, \u2022 \u2022 \u2022 , A #* then denotes Ilf-iH\u00ee-i^* Similarly, c M is an abbreviation for C[ MiJ }. The polynomial P({xij}) is then written P(x) = ]CM V^-In our notation : (1) 3(&)*i = (Z) \u00abWnys*) / JLH CpiiijX\u00bb."
            },
            "slug": "An-inequality-with-applications-to-statistical-for-Baum-Eagon",
            "title": {
                "fragments": [],
                "text": "An inequality with applications to statistical estimation for probabilistic functions of Markov processes and to a model for ecology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065228513"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2213649"
                        ],
                        "name": "C. Wellekens",
                        "slug": "C.-Wellekens",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wellekens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wellekens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7842515,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "999aa520f3f5523286613d17a349d8a0935bbcc1",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The principles of classification applied to the representation of the words in a vocabulary lead to the clustering of the acoustic vectors into prototype vectors. For a small number of prototypes, recognition scores comparable to those observed with unclustered vocabularies are obtained with a highly reduced computation time. Two different forms (deterministic and stochastic) of the single-level recognition method for concatenated words are described and the improvements obtained by vector quantization are put into evidence. The use of prototypes in the training phase of the finite stochastic automata representing a vocabulary word is also described."
            },
            "slug": "Connected-digit-recognition-using-vector-Bourlard-Wellekens",
            "title": {
                "fragments": [],
                "text": "Connected digit recognition using vector quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Two different forms (deterministic and stochastic) of the single-level recognition method for concatenated words are described and the improvements obtained by vector quantization are put into evidence."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144153201"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Baker",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61904772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c180f387357d9302a558bcd643209831744c639b",
            "isKey": false,
            "numCitedBy": 604,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper briefly describes the major features of the DRAGON speech understanding system. DRAGON makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech. The model--that of a probabilistic function of a Markov process--is very flexible and leads to features which allow DRAGON to function despite high error rates from individual knowledge sources. Repeated use of a simple abstract model produces a system which is simple in structure, but powerful in capabilities."
            },
            "slug": "The-DRAGON-system--An-overview-Baker",
            "title": {
                "fragments": [],
                "text": "The DRAGON system--An overview"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper briefly describes the major features of the DRAGON speech understanding system, which makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31408841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32a175b36ec7f2f08cb3dfac30ce141e144ec9e9",
            "isKey": false,
            "numCitedBy": 991,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical methods useful in automatic recognition of continuous speech are described. They concern modeling of a speaker and of an acoustic processor, extraction of the models' statistical parameters and hypothesis search procedures and likelihood computations of linguistic decoding. Experimental results are presented that indicate the power of the methods."
            },
            "slug": "Continuous-speech-recognition-by-statistical-Jelinek",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition by statistical methods"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "Experimental results are presented that indicate the power of the methods and concern modeling of a speaker and of an acoustic processor, extraction of the models' statistical parameters and hypothesis search procedures and likelihood computations of linguistic decoding."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2292570"
                        ],
                        "name": "T. Crystal",
                        "slug": "T.-Crystal",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Crystal",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Crystal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2205088,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "1e2a5485133b56468b654fe7d28f920b12f5580c",
            "isKey": false,
            "numCitedBy": 674,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "If you get the printed book in on-line book store, you may also find the same problem. So, you must move store to store and search for the available there. But, it will not happen here. The book that we will offer right here is the soft file concept. This is what make you can easily find and get this linear prediction of speech by reading this site. We offer you the best product, always and always."
            },
            "slug": "Linear-prediction-of-speech-Crystal",
            "title": {
                "fragments": [],
                "text": "Linear prediction of speech"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The book that the authors will offer right here is the soft file concept, which make you can easily find and get this linear prediction of speech by reading this site."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398430244"
                        ],
                        "name": "D. Andelman",
                        "slug": "D.-Andelman",
                        "structuredName": {
                            "firstName": "Dov",
                            "lastName": "Andelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Andelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2326869"
                        ],
                        "name": "J. Reeds",
                        "slug": "J.-Reeds",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Reeds",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Reeds"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43743804,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "3ef4ec3a5606b23275e191aafff2ef1e9356b716",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A general cryptanalysis method is presented based on statistical estimation theory. It is applied to two systems of practical interest: rotor machines and substitution-permutation networks. To cryptanalyze these systems, the finite keyspace is imbedded in a continuous set and the key estimate is a proper quantization of the continuous maximum likelihood estimate. Promising cryptanalysis results of a rotor machine under a ciphertext only attack and a substitution-permutation network under a known plaintext attack are presented."
            },
            "slug": "On-the-cryptanalysis-of-rotor-machines-and-networks-Andelman-Reeds",
            "title": {
                "fragments": [],
                "text": "On the cryptanalysis of rotor machines and substitution - permutation networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A general cryptanalysis method is presented based on statistical estimation theory and results of a rotor machine under a ciphertext only attack and a substitution-permutation network under a known plaintext attack are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101775270"
                        ],
                        "name": "T. Petrie",
                        "slug": "T.-Petrie",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Petrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Petrie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102329511"
                        ],
                        "name": "George W. Soules",
                        "slug": "George-W.-Soules",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Soules",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George W. Soules"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063108982"
                        ],
                        "name": "Norman Weiss",
                        "slug": "Norman-Weiss",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Norman Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122568650,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3092a4929bdb3d6a8fe53f162586b7431b5ff8a4",
            "isKey": false,
            "numCitedBy": 4551,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Maximization-Technique-Occurring-in-the-Analysis-Baum-Petrie",
            "title": {
                "fragments": [],
                "text": "A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62282319,
            "fieldsOfStudy": [],
            "id": "d87a423334afb20747c367b2d907069d7f3b4ed2",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The viterbi algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "75_F'75) was born in Brooklyn, NY, On Sept"
            },
            "venue": {
                "fragments": [],
                "text": "He received the S.B. and S.M. degrees simultaneously in June 1964, and the Ph.D. degree in electrical engineering in June 1967, all from the Massachusetts Institute of Technology"
            },
            "year": 1943
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Markov Models for Phonetic Text , \" 3"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An Inequality with Applications to Statistical Prediction for Functions of Markov Processes and to a Model for Ecology , \" Bull"
            },
            "venue": {
                "fragments": [],
                "text": "Amer . Math . Soc ."
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "~~:?t\u00b7)\\:;,~,:;<"
            },
            "venue": {
                "fragments": [],
                "text": "~~:?t\u00b7)\\:;,~,:;<"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rutg~rslJrijYei~i~.is,an eq~al opport~D!;ty~atfitr)\"\\Cltiye:aStiQ{I,~mpl()Y~r~i;.t;': \",}k'.t\u00b7"
            },
            "venue": {
                "fragments": [],
                "text": "'"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rabiner is a member of Eta Kappa Nu, Sigma Xi, Tau Beta Pi, The National Academy of Engineering, and a Fellow of both the"
            },
            "venue": {
                "fragments": [],
                "text": "Rabiner is a member of Eta Kappa Nu, Sigma Xi, Tau Beta Pi, The National Academy of Engineering, and a Fellow of both the"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An Inequality with Applications to Statistical Prediction for Functions of Markov . Processes and to a Model for Ecology"
            },
            "venue": {
                "fragments": [],
                "text": "Bull . Amer . Math . Soc ."
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "~::;:;t~> H~"
            },
            "venue": {
                "fragments": [],
                "text": "~::;:;t~> H~"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 23,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/An-introduction-to-hidden-Markov-models-Rabiner-Juang/9d076613d7c36dbda4a6ff42fbdd076604b96630?sort=total-citations"
}