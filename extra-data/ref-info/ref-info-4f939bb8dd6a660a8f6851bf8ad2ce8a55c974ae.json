{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563432"
                        ],
                        "name": "Wojciech Zaremba",
                        "slug": "Wojciech-Zaremba",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Zaremba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wojciech Zaremba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143627859"
                        ],
                        "name": "Joan Bruna",
                        "slug": "Joan-Bruna",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Bruna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan Bruna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761978"
                        ],
                        "name": "D. Erhan",
                        "slug": "D.-Erhan",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Erhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Erhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153440022"
                        ],
                        "name": "Ian J. Goodfellow",
                        "slug": "Ian-J.-Goodfellow",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Goodfellow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian J. Goodfellow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 173
                            }
                        ],
                        "text": "In practice, the best networks require enormous datasets which are further expanded by affine transformations [7, 13] yet are sensitive to imperceptible image perturbations [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 604334,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad",
            "isKey": false,
            "numCitedBy": 8881,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. \nFirst, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks. \nSecond, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input."
            },
            "slug": "Intriguing-properties-of-neural-networks-Szegedy-Zaremba",
            "title": {
                "fragments": [],
                "text": "Intriguing properties of neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is found that there is no distinction between individual highlevel units and random linear combinations of high level units, according to various methods of unit analysis, and it is suggested that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768120"
                        ],
                        "name": "T. Jebara",
                        "slug": "T.-Jebara",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Jebara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jebara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32448864"
                        ],
                        "name": "I. Kondor",
                        "slug": "I.-Kondor",
                        "structuredName": {
                            "firstName": "Imre",
                            "lastName": "Kondor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kondor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A few applications are discussed by Kondor [12], and they are also used in determinantal point processes [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122829893,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "502b8a16d779761a03a6d33ff122c040bb23ac12",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis explores applications of non-commutative harmonic analysis to machine learning. In particular, we address learning on groups and learning in a way that is invariant to a group. The former arises in learning rankings and matchings, in both cases, the group being the symmetric group. The application we explore in detail is the identity management problem in multi-object tracking. The latter arises in many contexts, none more immediate than invariance to translation, rotation, scaling, etc., in computer vision. In this domain we derive a new system of translation and rotation invariant features for images, and introduce a new system of invariants applicable to any compact group, which we call the skew spectrum. \nThe ideas behind harmonic analysis (commutative or non-commutative) run very deep, and one of the main messages of the thesis is that algebra can unravel structure in data which might otherwise be overlooked. All this would not be of much use to practitioners, however, were it not for a family of recently developed algorithms, chief amongst them fast Fourier transforms, which are finally starting to make it possible to scale up algebraic methods to the size of real-world problems. Much of our work revolves around carefully tailoring fast Fourier transforms to solve specialized tasks demanded by applications. \nThe thesis includes background material in both machine learning and algebra, so it can serve as a primer for researchers familiar with one field but not the other."
            },
            "slug": "Group-theoretical-methods-in-machine-learning-Jebara-Kondor",
            "title": {
                "fragments": [],
                "text": "Group theoretical methods in machine learning"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This thesis explores applications of non-commutative harmonic analysis to machine learning and addresses learning on groups and learning in a way that is invariant to a group, including a new system of invariants applicable to any compact group, which is called the skew spectrum."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8729431"
                        ],
                        "name": "Sida I. Wang",
                        "slug": "Sida-I.-Wang",
                        "structuredName": {
                            "firstName": "Sida",
                            "lastName": "Wang",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sida I. Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 156
                            }
                        ],
                        "text": "We share with other researchers the hypothesis that explanatory factors cannot be disentangled unless they are represented in an appropriate symmetry space [4, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 51
                            }
                        ],
                        "text": "Methods for learning transformations from examples [24, 11] could potentially benefit from being embedded in a deep symmetry network."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6138085,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20f0357688876fa4662f806f985779dce6e24f3c",
            "isKey": true,
            "numCitedBy": 838,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The artificial neural networks that are used to recognize shapes typically use one or more layers of learned feature detectors that produce scalar outputs. By contrast, the computer vision community uses complicated, hand-engineered features, like SIFT [6], that produce a whole vector of outputs including an explicit representation of the pose of the feature. We show how neural networks can be used to learn features that output a whole vector of instantiation parameters and we argue that this is a much more promising way of dealing with variations in position, orientation, scale and lighting than the methods currently employed in the neural networks community. It is also more promising than the hand-engineered features currently used in computer vision because it provides an efficient way of adapting the features to the domain."
            },
            "slug": "Transforming-Auto-Encoders-Hinton-Krizhevsky",
            "title": {
                "fragments": [],
                "text": "Transforming Auto-Encoders"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is argued that neural networks can be used to learn features that output a whole vector of instantiation parameters and this is a much more promising way of dealing with variations in position, orientation, scale and lighting than the methods currently employed in the neural networks community."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "The NORB dataset [16] contains 2\u00d7 108\u00d7 108 pixel stereoscopic images of 50 toys in five categories: quadrupeds, human figures, airplanes, trucks, and cars."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 712708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f354310098e09c1e1dc88758fca36767fd9d084d",
            "isKey": false,
            "numCitedBy": 1306,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We assess the applicability of several popular learning methods for the problem of recognizing generic visual categories with invariance to pose, lighting, and surrounding clutter. A large dataset comprising stereo image pairs of 50 uniform-colored toys under 36 azimuths, 9 elevations, and 6 lighting conditions was collected (for a total of 194,400 individual images). The objects were 10 instances of 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. Five instances of each category were used for training, and the other five for testing. Low-resolution grayscale images of the objects with various amounts of variability and surrounding clutter were used for training and testing. Nearest neighbor methods, support vector machines, and convolutional networks, operating on raw pixels or on PCA-derived features were tested. Test error rates for unseen object instances placed on uniform backgrounds were around 13% for SVM and 7% for convolutional nets. On a segmentation/recognition task with highly cluttered images, SVM proved impractical, while convolutional nets yielded 16/7% error. A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second."
            },
            "slug": "Learning-methods-for-generic-object-recognition-to-LeCun-Huang",
            "title": {
                "fragments": [],
                "text": "Learning methods for generic object recognition with invariance to pose and lighting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second and proved impractical, while convolutional nets yielded 16/7% error."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[10]), interpolating the map, and pooling a region of the map."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "Like deformable part models [10], symnets can model and penalize relative transformations that compose up the hierarchy, but can also capture additional symmetries."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14327585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "860a9d55d87663ca88e74b3ca357396cd51733d0",
            "isKey": false,
            "numCitedBy": 2616,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a discriminatively trained, multiscale, deformable part model for object detection. Our system achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge. It also outperforms the best results in the 2007 challenge in ten out of twenty categories. The system relies heavily on deformable parts. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL challenge. Our system also relies heavily on new methods for discriminative training. We combine a margin-sensitive approach for data mining hard negative examples with a formalism we call latent SVM. A latent SVM, like a hidden CRF, leads to a non-convex training problem. However, a latent SVM is semi-convex and the training problem becomes convex once latent information is specified for the positive examples. We believe that our training methods will eventually make possible the effective use of more latent information such as hierarchical (grammar) models and models involving latent three dimensional pose."
            },
            "slug": "A-discriminatively-trained,-multiscale,-deformable-Felzenszwalb-McAllester",
            "title": {
                "fragments": [],
                "text": "A discriminatively trained, multiscale, deformable part model"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A discriminatively trained, multiscale, deformable part model for object detection, which achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge and outperforms the best results in the 2007 challenge in ten out of twenty categories."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "Much of the vision literature is devoted to features that reduce or remove the effects of certain symmetry groups, e.g., [18, 17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5258236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9f836d28f52ad260213d32224a6d227f8e8849a",
            "isKey": false,
            "numCitedBy": 16256,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "slug": "Object-recognition-from-local-scale-invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale-invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145347688"
                        ],
                        "name": "S. Baker",
                        "slug": "S.-Baker",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83165362"
                        ],
                        "name": "Iain Matthews",
                        "slug": "Iain-Matthews",
                        "structuredName": {
                            "firstName": "Iain",
                            "lastName": "Matthews",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iain Matthews"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "In our experiments with deep affine nets, we follow the forward compositional (FC) warp [3] to align filters with the image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 186689463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "389110a28961ebe80d8856cd204f8d8305a260ef",
            "isKey": false,
            "numCitedBy": 3039,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Since the Lucas-Kanade algorithm was proposed in 1981 image alignment has become one of the most widely used techniques in computer vision. Applications range from optical flow and tracking to layered motion, mosaic construction, and face coding. Numerous algorithms have been proposed and a wide variety of extensions have been made to the original formulation. We present an overview of image alignment, describing most of the algorithms and their extensions in a consistent framework. We concentrate on the inverse compositional algorithm, an efficient algorithm that we recently proposed. We examine which of the extensions to Lucas-Kanade can be used with the inverse compositional algorithm without any significant loss of efficiency, and which cannot. In this paper, Part 1 in a series of papers, we cover the quantity approximated, the warp update rule, and the gradient descent approximation. In future papers, we will cover the choice of the error function, how to allow linear appearance variation, and how to impose priors on the parameters."
            },
            "slug": "Lucas-Kanade-20-Years-On:-A-Unifying-Framework-Baker-Matthews",
            "title": {
                "fragments": [],
                "text": "Lucas-Kanade 20 Years On: A Unifying Framework"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An overview of image alignment is presented, describing most of the algorithms and their extensions in a consistent framework and concentrating on the inverse compositional algorithm, an efficient algorithm that was recently proposed."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 51
                            }
                        ],
                        "text": "Methods for learning transformations from examples [24, 11] could potentially benefit from being embedded in a deep symmetry network."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12366835,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5127759530ce213f488af2859190697770f557f3",
            "isKey": false,
            "numCitedBy": 1188,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Invariant features of temporally varying signals are useful for analysis and classification. Slow feature analysis (SFA) is a new method for learning invariant or slowly varying features from a vectorial input signal. It is based on a nonlinear expansion of the input signal and application of principal component analysis to this expanded signal and its time derivative. It is guaranteed to find the optimal solution within a family of functions directly and can learn to extract a large number of decor-related features, which are ordered by their degree of invariance. SFA can be applied hierarchically to process high-dimensional input signals and extract complex features. SFA is applied first to complex cell tuning properties based on simple cell output, including disparity and motion. Then more complicated input-output functions are learned by repeated application of SFA. Finally, a hierarchical network of SFA modules is presented as a simple model of the visual system. The same unstructured network can learn translation, size, rotation, contrast, or, to a lesser degree, illumination invariance for one-dimensional objects, depending on only the training stimulus. Surprisingly, only a few training objects suffice to achieve good generalization to new objects. The generated representation is suitable for object recognition. Performance degrades if the network is trained to learn multiple invariances simultaneously."
            },
            "slug": "Slow-Feature-Analysis:-Unsupervised-Learning-of-Wiskott-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Slow Feature Analysis: Unsupervised Learning of Invariances"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Slow feature analysis (SFA) is a new method for learning invariant or slowly varying features from a vectorial input signal that is guaranteed to find the optimal solution within a family of functions directly and can learn to extract a large number of decor-related features, which are ordered by their degree of invariance."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 110
                            }
                        ],
                        "text": "In practice, the best networks require enormous datasets which are further expanded by affine transformations [7, 13] yet are sensitive to imperceptible image perturbations [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 169
                            }
                        ],
                        "text": "Since symnets are a clean generalization of convnets, they should benefit from the learning, regularization, and efficiency techniques used by state-of-the-art networks [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195908774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "isKey": false,
            "numCitedBy": 80944,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
            },
            "slug": "ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever",
            "title": {
                "fragments": [],
                "text": "ImageNet classification with deep convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895356"
                        ],
                        "name": "D. Ciresan",
                        "slug": "D.-Ciresan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Ciresan",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ciresan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2514691"
                        ],
                        "name": "U. Meier",
                        "slug": "U.-Meier",
                        "structuredName": {
                            "firstName": "Ueli",
                            "lastName": "Meier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Meier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 110
                            }
                        ],
                        "text": "In practice, the best networks require enormous datasets which are further expanded by affine transformations [7, 13] yet are sensitive to imperceptible image perturbations [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2161592,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "398c296d0cc7f9d180f84969f8937e6d3a413796",
            "isKey": false,
            "numCitedBy": 3369,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible, wide and deep artificial neural network architectures can. Small (often minimal) receptive fields of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance. On a traffic sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classification benchmarks."
            },
            "slug": "Multi-column-deep-neural-networks-for-image-Ciresan-Meier",
            "title": {
                "fragments": [],
                "text": "Multi-column deep neural networks for image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "On the very competitive MNIST handwriting benchmark, this method is the first to achieve near-human performance and improves the state-of-the-art on a plethora of common image classification benchmarks."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467703"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 156
                            }
                        ],
                        "text": "We share with other researchers the hypothesis that explanatory factors cannot be disentangled unless they are represented in an appropriate symmetry space [4, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 393948,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "184ac0766262312ba76bbdece4e7ffad0aa8180b",
            "isKey": true,
            "numCitedBy": 8748,
            "numCiting": 285,
            "paperAbstract": {
                "fragments": [],
                "text": "The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning."
            },
            "slug": "Representation-Learning:-A-Review-and-New-Bengio-Courville",
            "title": {
                "fragments": [],
                "text": "Representation Learning: A Review and New Perspectives"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Recent work in the area of unsupervised feature learning and deep learning is reviewed, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2237194"
                        ],
                        "name": "B. Drost",
                        "slug": "B.-Drost",
                        "structuredName": {
                            "firstName": "Bertram",
                            "lastName": "Drost",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Drost"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983310"
                        ],
                        "name": "M. Ulrich",
                        "slug": "M.-Ulrich",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Ulrich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ulrich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145587210"
                        ],
                        "name": "Nassir Navab",
                        "slug": "Nassir-Navab",
                        "structuredName": {
                            "firstName": "Nassir",
                            "lastName": "Navab",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nassir Navab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46505857"
                        ],
                        "name": "Slobodan Ilic",
                        "slug": "Slobodan-Ilic",
                        "structuredName": {
                            "firstName": "Slobodan",
                            "lastName": "Ilic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Slobodan Ilic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 169
                            }
                        ],
                        "text": "There are a number of algorithms that solve for a maximal feature location in symmetry space but they are not efficient when the feature weights are frequently adjusted [9, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12971705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e1f786e79ad9f03436563b4fac53bfde789c697",
            "isKey": false,
            "numCitedBy": 723,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of recognizing free-form 3D objects in point clouds. Compared to traditional approaches based on point descriptors, which depend on local information around points, we propose a novel method that creates a global model description based on oriented point pair features and matches that model locally using a fast voting scheme. The global model description consists of all model point pair features and represents a mapping from the point pair feature space to the model, where similar features on the model are grouped together. Such representation allows using much sparser object and scene point clouds, resulting in very fast performance. Recognition is done locally using an efficient voting scheme on a reduced two-dimensional search space. We demonstrate the efficiency of our approach and show its high recognition performance in the case of noise, clutter and partial occlusions. Compared to state of the art approaches we achieve better recognition rates, and demonstrate that with a slight or even no sacrifice of the recognition performance our method is much faster then the current state of the art approaches."
            },
            "slug": "Model-globally,-match-locally:-Efficient-and-robust-Drost-Ulrich",
            "title": {
                "fragments": [],
                "text": "Model globally, match locally: Efficient and robust 3D object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel method is proposed that creates a global model description based on oriented point pair features and matches that model locally using a fast voting scheme, which allows using much sparser object and scene point clouds, resulting in very fast performance."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143627859"
                        ],
                        "name": "Joan Bruna",
                        "slug": "Joan-Bruna",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Bruna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan Bruna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746242"
                        ],
                        "name": "S. Mallat",
                        "slug": "S.-Mallat",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Mallat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mallat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Scattering networks [6] are cascades of wavelet decompositions designed to be invariant to particular Lie groups, where translation and rotation invariance have been demonstrated so far."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1996316,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30e2e85b7cf2e85f8965ec74b03f569caa2b5cdd",
            "isKey": false,
            "numCitedBy": 881,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "A wavelet scattering network computes a translation invariant image representation which is stable to deformations and preserves high-frequency information for classification. It cascades wavelet transform convolutions with nonlinear modulus and averaging operators. The first network layer outputs SIFT-type descriptors, whereas the next layers provide complementary invariant information that improves classification. The mathematical analysis of wavelet scattering networks explains important properties of deep convolution networks for classification. A scattering representation of stationary processes incorporates higher order moments and can thus discriminate textures having the same Fourier power spectrum. State-of-the-art classification results are obtained for handwritten digits and texture discrimination, with a Gaussian kernel SVM and a generative PCA classifier."
            },
            "slug": "Invariant-Scattering-Convolution-Networks-Bruna-Mallat",
            "title": {
                "fragments": [],
                "text": "Invariant Scattering Convolution Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The mathematical analysis of wavelet scattering networks explains important properties of deep convolution networks for classification."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Convolutional neural networks (convnets) [16], the current state-of-the-art method for object recognition, capture only one type of invariance (translation); the rest have to be approximated via it and standard features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35260,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38207506"
                        ],
                        "name": "Taehee Lee",
                        "slug": "Taehee-Lee",
                        "structuredName": {
                            "firstName": "Taehee",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taehee Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715959"
                        ],
                        "name": "Stefano Soatto",
                        "slug": "Stefano-Soatto",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Soatto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefano Soatto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 90
                            }
                        ],
                        "text": "It has been shown that if we could remove these factors, recognition would be much easier [2, 17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10642392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae22e9b89072ba8d8e2cc942f8b7302fc85fb7fa",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Video-based-descriptors-for-object-recognition-Lee-Soatto",
            "title": {
                "fragments": [],
                "text": "Video-based descriptors for object recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "Our adaptation of a representation to work in symmetry space is similar in some respects to the use of tangent distance in nearest-neighbor classifiers [22]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 11382731,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8314dda1ec43ce57ff877f8f02ed89acb68ca035",
            "isKey": true,
            "numCitedBy": 581,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Memory-based classification algorithms such as radial basis functions or K-nearest neighbors typically rely on simple distances (Euclidean, dot product...), which are not particularly meaningful on pattern vectors. More complex, better suited distance measures are often expensive and rather ad-hoc (elastic matching, deformable templates). We propose a new distance measure which (a) can be made locally invariant to any set of transformations of the input and (b) can be computed efficiently. We tested the method on large handwritten character databases provided by the Post Office and the NIST. Using invariances with respect to translation, rotation, scaling, shearing and line thickness, the method consistently outperformed all other systems tested on the same databases."
            },
            "slug": "Efficient-Pattern-Recognition-Using-a-New-Distance-Simard-LeCun",
            "title": {
                "fragments": [],
                "text": "Efficient Pattern Recognition Using a New Transformation Distance"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new distance measure which can be made locally invariant to any set of transformations of the input and can be computed efficiently is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761978"
                        ],
                        "name": "D. Erhan",
                        "slug": "D.-Erhan",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Erhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Erhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32837403"
                        ],
                        "name": "J. Bergstra",
                        "slug": "J.-Bergstra",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "1 MNIST-rot MNIST-rot [15] consists of 28x28 pixel greyscale images: 10(4) for training, 2 \u00d7 10(3) for validation, and 5\u00d7 10(4) for testing."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14805281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8012351bc5ebce4a4b3039bbbba3ce393bc3315",
            "isKey": false,
            "numCitedBy": 973,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, several learning algorithms relying on models with deep architectures have been proposed. Though they have demonstrated impressive performance, to date, they have only been evaluated on relatively simple problems such as digit recognition in a controlled environment, for which many machine learning algorithms already report reasonable results. Here, we present a series of experiments which indicate that these models show promise in solving harder learning problems that exhibit many factors of variation. These models are compared with well-established algorithms such as Support Vector Machines and single hidden-layer feed-forward neural networks."
            },
            "slug": "An-empirical-evaluation-of-deep-architectures-on-of-Larochelle-Erhan",
            "title": {
                "fragments": [],
                "text": "An empirical evaluation of deep architectures on problems with many factors of variation"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A series of experiments indicate that these models with deep architectures show promise in solving harder learning problems that exhibit many factors of variation."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500336"
                        ],
                        "name": "Alex Kulesza",
                        "slug": "Alex-Kulesza",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Kulesza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Kulesza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685978"
                        ],
                        "name": "B. Taskar",
                        "slug": "B.-Taskar",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Taskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taskar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "Methods for learning transformations from examples [24, 11] could potentially benefit from being embedded in a deep symmetry network."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 51975610,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "48a17d25d76f9bdf90fdd86d2b3e2739e5bb8016",
            "isKey": false,
            "numCitedBy": 767,
            "numCiting": 177,
            "paperAbstract": {
                "fragments": [],
                "text": "Determinantal point processes (DPPs) are elegant probabilistic models of repulsion that arise in quantum physics and random matrix theory. In contrast to traditional structured models like Markov random fields, which become intractable and hard to approximate in the presence of negative correlations, DPPs offer efficient and exact algorithms for sampling, marginalization, conditioning, and other inference tasks. While they have been studied extensively by mathematicians, giving rise to a deep and beautiful theory, DPPs are relatively new in machine learning. Determinantal Point Processes for Machine Learning provides a comprehensible introduction to DPPs, focusing on the intuitions, algorithms, and extensions that are most relevant to the machine learning community, and shows how DPPs can be applied to real-world applications like finding diverse sets of high-quality search results, building informative summaries by selecting diverse sentences from documents, modeling non-overlapping human poses in images or video, and automatically building timelines of important news stories. It presents the general mathematical background to DPPs along with a range of modeling extensions, efficient algorithms, and theoretical results that aim to enable practical modeling and learning."
            },
            "slug": "Determinantal-Point-Processes-for-Machine-Learning-Kulesza-Taskar",
            "title": {
                "fragments": [],
                "text": "Determinantal Point Processes for Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Determinantal Point Processes for Machine Learning provides a comprehensible introduction to DPPs, focusing on the intuitions, algorithms, and extensions that are most relevant to the machine learning community, and shows how they can be applied to real-world applications."
            },
            "venue": {
                "fragments": [],
                "text": "Found. Trends Mach. Learn."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398965769"
                        ],
                        "name": "Y. Abu-Mostafa",
                        "slug": "Y.-Abu-Mostafa",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Abu-Mostafa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Abu-Mostafa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 202
                            }
                        ],
                        "text": "In particular, theory suggests that a symnet will have better sample complexity than another classifier on a dataset if it is based on a symmetry group that generates variations present in that dataset [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 227
                            }
                        ],
                        "text": "If a data distribution D(x, y) has the property that all the elements of an orbit share the same label y, S imposes a constraint on the hypothesis class of a learner, effectively lowering its VC-dimension and sample complexity [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207701407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed0c5a44d2e1f9a3a284ee0e6bcff4978c8654bc",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning from hints is a generalization of learning from examples that allows for a variety of information about the unknown function to be used in the learning process. In this paper, we use the VC dimension, an established tool for analyzing learning from examples, to analyze learning from hints. In particular, we show how the VC dimension is affected by the introduction of a hint. We also derive a new quantity that defines a VC dimension for the hint itself. This quantity is used to estimate the number of examples needed to \"absorb\" the hint. We carry out the analysis for two types of hints, invariances and catalysts. We also describe how the same method can be applied to other types of hints."
            },
            "slug": "Hints-and-the-VC-Dimension-Abu-Mostafa",
            "title": {
                "fragments": [],
                "text": "Hints and the VC Dimension"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The VC dimension is shown to be affected by the introduction of a hint, and a new quantity is derived that defines a VC dimension for the hint itself, used to estimate the number of examples needed to \"absorb\" the hint."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114295631"
                        ],
                        "name": "F. Lu",
                        "slug": "F.-Lu",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736641"
                        ],
                        "name": "E. Milios",
                        "slug": "E.-Milios",
                        "structuredName": {
                            "firstName": "Evangelos",
                            "lastName": "Milios",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Milios"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 169
                            }
                        ],
                        "text": "There are a number of algorithms that solve for a maximal feature location in symmetry space but they are not efficient when the feature weights are frequently adjusted [9, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5977910,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d747fc986b5240b85fada117d26c48f00a9faf02",
            "isKey": false,
            "numCitedBy": 920,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A mobile robot exploring an unknown environment has no absolute frame of reference for its position, other than features it detects through its sensors. Using distinguishable landmarks is one possible approach, but it requires solving the object recognition problem. In particular, when the robot uses two-dimensional laser range scans for localization, it is difficult to accurately detect and localize landmarks in the environment (such as corners and occlusions) from the range scans.In this paper, we develop two new iterative algorithms to register a range scan to a previous scan so as to compute relative robot positions in an unknown environment, that avoid the above problems. The first algorithm is based on matching data points with tangent directions in two scans and minimizing a distance function in order to solve the displacement between the scans. The second algorithm establishes correspondences between points in the two scans and then solves the point-to-point least-squares problem to compute the relative pose of the two scans. Our methods work in curved environments and can handle partial occlusions by rejecting outliers."
            },
            "slug": "Robot-Pose-Estimation-in-Unknown-Environments-by-2D-Lu-Milios",
            "title": {
                "fragments": [],
                "text": "Robot pose estimation in unknown environments by matching 2D range scans"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Two new iterative algorithms to register a range scan to a previous scan so as to compute relative robot positions in an unknown environment, that avoid the above problems."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2780262"
                        ],
                        "name": "Mathias Niepert",
                        "slug": "Mathias-Niepert",
                        "structuredName": {
                            "firstName": "Mathias",
                            "lastName": "Niepert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mathias Niepert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "Symmetries in graphical models [21] lead to effective lifted probabilistic inference algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2502799,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6caa4df9970c262f47384e28aaa2ba43cd07966c",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach to detecting and utilizing symmetries in probabilistic graphical models with two main contributions. First, we present a scalable approach to computing generating sets of permutation groups representing the symmetries of graphical models. Second, we introduce orbital Markov chains, a novel family of Markov chains leveraging model symmetries to reduce mixing times. We establish an insightful connection between model symmetries and rapid mixing of orbital Markov chains. Thus, we present the first lifted MCMC algorithm for probabilistic graphical models. Both analytical and empirical results demonstrate the effectiveness and efficiency of the approach."
            },
            "slug": "Markov-Chains-on-Orbits-of-Permutation-Groups-Niepert",
            "title": {
                "fragments": [],
                "text": "Markov Chains on Orbits of Permutation Groups"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work presents the first lifted MCMC algorithm for probabilistic graphical models, and establishes an insightful connection between model symmetries and rapid mixing of orbital Markov chains."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "78769965"
                        ],
                        "name": "W. Miller",
                        "slug": "W.-Miller",
                        "structuredName": {
                            "firstName": "Willard",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Miller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "We propose deep symmetry networks, a generalization of convnets based on symmetry group theory [20] that makes it possible to capture a broad variety of invariances, and correspondingly improves generalization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "A symmetry of an object is a transformation that leaves certain properties of that object intact [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122399919,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ece01f890a6de5a8969a366527ff0f3b156aca56",
            "isKey": false,
            "numCitedBy": 481,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Symmetry-groups-and-their-applications-Miller",
            "title": {
                "fragments": [],
                "text": "Symmetry groups and their applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2796350"
                        ],
                        "name": "P. Diaconis",
                        "slug": "P.-Diaconis",
                        "structuredName": {
                            "firstName": "Persi",
                            "lastName": "Diaconis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Diaconis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "Symmetry group theory has made a limited number of appearances in machine learning [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118750811,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d1ccb1fa7dc12d24c21151b88673fb24bfe9fe6a",
            "isKey": false,
            "numCitedBy": 1472,
            "numCiting": 265,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Group-representations-in-probability-and-statistics-Diaconis",
            "title": {
                "fragments": [],
                "text": "Group representations in probability and statistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11102536"
                        ],
                        "name": "F. Anselmi",
                        "slug": "F.-Anselmi",
                        "structuredName": {
                            "firstName": "Fabio",
                            "lastName": "Anselmi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Anselmi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700356"
                        ],
                        "name": "Joel Z. Leibo",
                        "slug": "Joel-Z.-Leibo",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Leibo",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joel Z. Leibo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690976"
                        ],
                        "name": "L. Rosasco",
                        "slug": "L.-Rosasco",
                        "structuredName": {
                            "firstName": "Lorenzo",
                            "lastName": "Rosasco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rosasco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2243801"
                        ],
                        "name": "Jim Mutch",
                        "slug": "Jim-Mutch",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Mutch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jim Mutch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2844530"
                        ],
                        "name": "A. Tacchetti",
                        "slug": "A.-Tacchetti",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Tacchetti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tacchetti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[2] constructs features invariant to a symmetry group by using statistics of dot products with group orbits."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 90
                            }
                        ],
                        "text": "It has been shown that if we could remove these factors, recognition would be much easier [2, 17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13822711,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "557ccc743b90d18e313ff7d3448524f96aa4d519",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 135,
            "paperAbstract": {
                "fragments": [],
                "text": "Representations that are invariant to translation, scale and other transformations, can considerably reduce the sample complexity of learning, allowing recognition of new object classes from very few examples|a hallmark of human recognition. Empirical estimates of one-dimensional projections of the distribution induced by a group of ane transformations are proven to represent a unique and invariant signature associated with an image. We show how projections yielding invariant signatures for future images can be learned automatically, and updated continuously, during unsupervised visual experience. A module performing ltering and pooling, like simple and complex cells as proposed by Hubel and Wiesel, can compute such estimates. Under this view, a pooling stage estimates a one-dimensional probability distribution. Invariance from observations through a restricted window is equivalent to a sparsity property w.r.t. to a transformation, which yields templates that are a) Gabor for optimal simultaneous invariance to translation and scale or b) very specic for complex, class-dependent transformations such as rotation in depth of faces. Hierarchical architectures consisting of this basic Hubel-Wiesel module inherit its properties of invariance, stability, and discriminability while capturing the compositional organization of the visual world in terms of wholes and parts, and are invariant to complex transformations that may only be locally ane. The theory applies to several existing deep learning convolutional architectures for image and speech recognition. It also suggests that the main computational goal of the ventral stream of visual cortex is to provide a hierarchical representation of new objects/images which is invariant to transformations, stable, and discriminative for recognition|and that this representation may be continuously learned in an unsupervised way during development and natural visual experience."
            },
            "slug": "Unsupervised-Learning-of-Invariant-Representations-Anselmi-Leibo",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Invariant Representations in Hierarchical Architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Empirical estimates of one-dimensional projections of the distribution induced by a group of ane transformations are proven to represent a unique and invariant signature associated with an image, and it is shown how projections yielding invariant signatures for future images can be learned automatically, and updated continuously, during unsupervised visual experience."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 1
                            }
                        ],
                        "text": "We propose deep symmetry networks, a generalization of convnets based on symmetry group theory [20] that makes it possible to capture a broad variety of invariances, and correspondingly improves generalization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Intriguing properties of neural networks. International Conference on Learning Representations"
            },
            "venue": {
                "fragments": [],
                "text": "Intriguing properties of neural networks. International Conference on Learning Representations"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "We modified the Theano [5] implementation of convolutional networks so that the network consisted of a single layer of convolution and maxpooling followed by a hidden layer of 500 units and then softmax classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theano: a CPU and GPU math expression compiler"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the Python for Scientific Computing Conference,"
            },
            "year": 2010
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 21,
            "methodology": 3,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 26,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Deep-Symmetry-Networks-Gens-Domingos/4f939bb8dd6a660a8f6851bf8ad2ce8a55c974ae?sort=total-citations"
}