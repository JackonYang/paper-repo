{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143616982"
                        ],
                        "name": "Ana Rebelo",
                        "slug": "Ana-Rebelo",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Rebelo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana Rebelo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 169
                            }
                        ],
                        "text": "Symbols indicating the choice of tones, their duration, and the way they are performed are important because they form this written language that we call music notation [81]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62343684,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "146f9444d07c413cd06a6e6e9ac175b62930f256",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "Many music works produced in the past are currently available only as original manuscripts or as photocopies. Their preservation has entailed a vast amount of research in the last years. The digitalization has been commonly used as a possible preservation method which comprises setting up a digital copy. Despite the fact of an easy accessibility in a machine-readable format, which encourages browsing, retrieval, search and analysis and, most importantly, the preservation of endangered works, while providing a generalized access to digital content, actually it only keeps a portion of the information. Several systems have been presented in order to ful ll the lack of a tool able to analyse and perform semantic search operations. Carrying this task manually is very time consuming and error prone. While optical music recognition systems usually perform well on printed scores, the processing of handwritten musical scores by computers remains far from ideal. One of the fundamental stages in the optical music recognition is the detection and subsequent removal of sta lines. In this project we investigate a general-purpose, knowledge-free method for the automatic detection of music sta lines based on stable paths approach. Lines a ected by curvature, discontinuities, and inclination are robustly detected. A sta removal algorithm is also developed by adapting an existing line removal approach to use the stable paths algorithm at the detection stage. Experimental results show that the proposed technique consistently outperforms well-established algorithms. The developed approach will be integrated, as future work, in a web based system providing seamless access to browsing, retrieval, search and analysis of submitted scores. Symbol detection is also crucial for a good performance in an optical music recognition system. In this work we propose a segmentation method based on the hierarchical decomposition of music sheets. The symbols are split into four di erent types to facilitate their extraction. Since we are working with handwritten scores many situations may occur. The work degradation, highly handwritten di erent types as well as other possible undesirable discontinuities are situations to take into account. One way to diminish these situations in the classi cation process is to create a database where several distortions are simulated. So, a new methodology is presented where elastic matching is used in conjunction with several classi ers, for instance neural networks and hidden Markov models. A profound comparative study is made about classi ers with and without the elastic matching applied to handwritten scores. It is expected that the obtained results outperform the actual state of the art."
            },
            "slug": "New-methodologies-towards-an-automatic-optical-of-Rebelo",
            "title": {
                "fragments": [],
                "text": "New methodologies towards an automatic optical recognition of handwritten musical scores"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new methodology is presented where elastic matching is used in conjunction with several classi ers, for instance neural networks and hidden Markov models, and it is expected that the obtained results outperform the actual state of the art."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2901129"
                        ],
                        "name": "L. Tard\u00f3n",
                        "slug": "L.-Tard\u00f3n",
                        "structuredName": {
                            "firstName": "Lorenzo",
                            "lastName": "Tard\u00f3n",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Tard\u00f3n"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50280422"
                        ],
                        "name": "S. Sammartino",
                        "slug": "S.-Sammartino",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Sammartino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sammartino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3139251"
                        ],
                        "name": "I. Barbancho",
                        "slug": "I.-Barbancho",
                        "structuredName": {
                            "firstName": "Isabel",
                            "lastName": "Barbancho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Barbancho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116900142"
                        ],
                        "name": "V. G\u00f3mez",
                        "slug": "V.-G\u00f3mez",
                        "structuredName": {
                            "firstName": "Ver\u00f3nica",
                            "lastName": "G\u00f3mez",
                            "middleNames": [
                                "Romero"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. G\u00f3mez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058578527"
                        ],
                        "name": "Antonio Oliver",
                        "slug": "Antonio-Oliver",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Oliver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antonio Oliver"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "[28, 68, 31, 89]) and common parts on the row and column histograms for each pair of symbols [98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 68
                            }
                        ],
                        "text": "In the OMR field, several re- search works have used this technique [45, 76, 17, 83, 98]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "\u2013 other technique can be found in [98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 239
                            }
                        ],
                        "text": "Other techniques for finding staff lines include the grouping of vertical columns based on their spacing, thickness and vertical position on the image [85], rule-based classification of thin horizontal line segments [60], and line tracing [73, 88, 98]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "\u2013 KNNs, Mahalanobis distance and Fisher discriminant: [98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [98] the symbols are extracted using a connected components process and small"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "[41, 45, 64, 34, 98]) and morphological operations [45] are the most common techniques for preprocessing music scores."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207734248,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0f877e02581975923d3d66b28f533ba55ec45f0",
            "isKey": true,
            "numCitedBy": 47,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "An Optical Music Recognition (OMR) system especially adapted for handwritten musical scores of the XVII-th and the early XVIII-th centuries written in white mensural notation is presented. The system performs a complete sequence of analysis stages: the input is the RGB image of the score to be analyzed and, after a preprocessing that returns a black and white image with corrected rotation, the staves are processed to return a score without staff lines; then, a music symbol processing stage isolates the music symbols contained in the score and, finally, the classification process starts to obtain the transcription in a suitable electronic format so that it can be stored or played. This work will help to preserve our cultural heritage keeping the musical information of the scores in a digital format that also gives the possibility to perform and distribute the original music contained in those scores."
            },
            "slug": "Optical-Music-Recognition-for-Scores-Written-in-Tard\u00f3n-Sammartino",
            "title": {
                "fragments": [],
                "text": "Optical Music Recognition for Scores Written in White Mensural Notation"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "An Optical Music Recognition (OMR) system especially adapted for handwritten musical scores of the XVII-th and the early XVIII-th centuries written in white mensural notation is presented and will help to preserve the cultural heritage keeping the musical information of the scores in a digital format."
            },
            "venue": {
                "fragments": [],
                "text": "EURASIP J. Image Video Process."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793817"
                        ],
                        "name": "P. Bellini",
                        "slug": "P.-Bellini",
                        "structuredName": {
                            "firstName": "Pierfrancesco",
                            "lastName": "Bellini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bellini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1985733"
                        ],
                        "name": "I. Bruno",
                        "slug": "I.-Bruno",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Bruno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Bruno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808730"
                        ],
                        "name": "P. Nesi",
                        "slug": "P.-Nesi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Nesi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Nesi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 101
                            }
                        ],
                        "text": "present a sophisticated use of projection techniques combined in order to improve the basic approach [2, 5, 89, 7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 75
                            }
                        ],
                        "text": "Other authors have chosen to apply projections to detect primitive symbols [74, 41, 5, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 64
                            }
                        ],
                        "text": "tion phase, while neural networks is the classifier selected in [66, 62, 5, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 103
                            }
                        ],
                        "text": "Notwithstanding, there are authors who suggested algorithms without the need to remove the staff lines [68, 5, 58, 45, 93, 76, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 124
                            }
                        ],
                        "text": "Usually, the primitive segmentation step is made along with the classification task [89, 100]; however there are exceptions [41, 5, 7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "\u2013 Grammar: [74], [73], [24], [4], [85], [7]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "\u2013 Combination of projection techniques: [2], [5], [89], [7]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 58226857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56f24aced776537dcb6d817557540a2ab0c16445",
            "isKey": true,
            "numCitedBy": 14,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical music recognition is a key problem for coding western music sheets in the digital world. This problem has been addressed in several manners, obtaining suitable results only when simple music constructs are processed. To this end, several different strategies have been followed to pass from the simple music sheet image to a complete and consistent representation of music notation symbols (symbolic music notation or representation). Typically, image processing, pattern recognition, and symbolic reconstruction are the technologies that have to be considered and applied in several manners; the architecture of the so called OMR (optical music recognition) systems. In this chapter, the O3MR (object oriented optical music recognition) system is presented. It allows producing from the image of a music sheet the symbolic representation and saving it in XML format (WEDELMUSIC XML and MUSICXML). The algorithms used in this process are those of the image processing, image segmentation, neural network pattern recognition, and symbolic reconstruction and reasoning. Most of the solutions can be applied in other fields of image understanding. The development of the O3MR solution with all its algorithms has been partially supported by the European Commission in the IMUTUS Research and Development project, while the related music notation editor has been partially funded by the research and development WEDELMUSIC project of the European Commission. Chapter V Optical Music Recognition: Architecture and Algorithms Pierfrancesco Bellini University of Florence, Italy Ivan Bruno University of Florence, Italy Paolo Nesi University of Florence, Italy Copyright \u00a9 2008, IGI Global, distributing in print or electronic forms without written permission of IGI Global is prohibited. Optical Music Recognition: Architecture and Algorithms"
            },
            "slug": "Optical-Music-Recognition:-Architecture-and-Bellini-Bruno",
            "title": {
                "fragments": [],
                "text": "Optical Music Recognition: Architecture and Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "In this chapter, the O3MR (object oriented optical music recognition) system is presented and it allows producing from the image of a music sheet the symbolic representation and saving it in XML format (WEDELMUSIC XML and MUSICXML)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143748132"
                        ],
                        "name": "D. Bainbridge",
                        "slug": "D.-Bainbridge",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bainbridge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bainbridge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066731260"
                        ],
                        "name": "T. Bell",
                        "slug": "T.-Bell",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Bell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Similarly, Bellini et al. [6] proposed two assessment models focused on basic and composite symbols to measure the results of the OMR algorithms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 22
                            }
                        ],
                        "text": "In a more recent work Bainbridge and Bell [4] incorporated a basic graph in CANTOR system according to each musical feature\u2019s position (x, y)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Bainbridge and Bell [4] incorporated a basic graph in CANTOR system according to each musical feature\u2019s position"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 233
                            }
                        ],
                        "text": "Several surveys and summaries have been presented to the scientific community: Kassler [53] reviewed two of the first dissertations on OMR, Blostein and Baird [9] published an overview of OMR systems developed between 1966 and 1992, Bainbridge and Bell [3] published a generic framework for OMR (subsequently adopted by many researchers in this field), and both Homenda [47] and Rebelo et al. [83] presented pattern recognition studies applied to music notation."
                    },
                    "intents": []
                }
            ],
            "corpusId": 38830472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcda1e784373854a2dc84974b3dcb12ab6b639c2",
            "isKey": true,
            "numCitedBy": 39,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical music recognition (OMR) systems are used to convert music scanned from paper into a format suitable for playing or editing on a computer. These systems generally have two phases: recognizing the graphical symbols (such as note\u2010heads and lines) and determining the musical meaning and relationships of the symbols (such as the pitch and rhythm of the notes). In this paper we explore the second phase and give a two\u2010step approach that admits an economical representation of the parsing rules for the system. The approach is flexible and allows the system to be extended to new notations with little effort\u2014the current system can parse common music notation, Sacred Harp notation and plainsong. It is based on a string grammar and a customizable graph that specifies relationships between musical objects. We observe that this graph can be related to printing as well as recognizing music notation, bringing the opportunity for cross\u2010fertilization between the two areas of research. Copyright \u00a9 2003 John Wiley & Sons, Ltd."
            },
            "slug": "A-music-notation-construction-engine-for-optical-Bainbridge-Bell",
            "title": {
                "fragments": [],
                "text": "A music notation construction engine for optical music recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is observed that this graph can be related to printing as well as recognizing music notation, bringing the opportunity for cross\u2010fertilization between the two areas of research."
            },
            "venue": {
                "fragments": [],
                "text": "Softw. Pract. Exp."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143616982"
                        ],
                        "name": "Ana Rebelo",
                        "slug": "Ana-Rebelo",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Rebelo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana Rebelo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40040755"
                        ],
                        "name": "A. Capela",
                        "slug": "A.-Capela",
                        "structuredName": {
                            "firstName": "Artur",
                            "lastName": "Capela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Capela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2127546884"
                        ],
                        "name": "J.F.P. da Costa",
                        "slug": "J.F.P.-da-Costa",
                        "structuredName": {
                            "firstName": "J.F.P.",
                            "lastName": "da Costa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J.F.P. da Costa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144453899"
                        ],
                        "name": "C. Guedes",
                        "slug": "C.-Guedes",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Guedes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Guedes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717754"
                        ],
                        "name": "E. Carrapatoso",
                        "slug": "E.-Carrapatoso",
                        "structuredName": {
                            "firstName": "Eurico",
                            "lastName": "Carrapatoso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Carrapatoso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41187526"
                        ],
                        "name": "J. Cardoso",
                        "slug": "J.-Cardoso",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Cardoso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cardoso"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17158526,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21b652b097b9cb1a5c04e2ed9fbeb47b6fc8bf22",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Many music works produced in the past still exist only as original manuscripts or as photocopies. Preserving them entails their digitalization and consequent accessibility in a digital format easy-to-manage. The manual process to carry out this task is very time consuming and error prone. Optical music recognition (OMR) is a form of structured document image analysis where music symbols are isolated and identified so that the music can be conveniently processed. While OMR systems perform well on printed scores, current methods for reading handwritten musical scores by computers remain far from ideal. One of the fundamental stages of this process is the staff line detection. In this paper a new method for the automatic detection of music stave lines based on a shortest path approach is presented. Lines with some curvature, discontinuities, and inclination are robustly detected. The proposed algorithm behaves favourably when compared experimentally with well-established algorithms."
            },
            "slug": "A-Shortest-Path-Approach-for-Staff-Line-Detection-Rebelo-Capela",
            "title": {
                "fragments": [],
                "text": "A Shortest Path Approach for Staff Line Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new method for the automatic detection of music stave lines based on a shortest path approach is presented and lines with some curvature, discontinuities, and inclination are robustly detected."
            },
            "venue": {
                "fragments": [],
                "text": "Third International Conference on Automated Production of Cross Media Content for Multi-Channel Distribution (AXMEDIS'07)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143616982"
                        ],
                        "name": "Ana Rebelo",
                        "slug": "Ana-Rebelo",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Rebelo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana Rebelo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2828598"
                        ],
                        "name": "F. Paszkiewicz",
                        "slug": "F.-Paszkiewicz",
                        "structuredName": {
                            "firstName": "Filipe",
                            "lastName": "Paszkiewicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Paszkiewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144453899"
                        ],
                        "name": "C. Guedes",
                        "slug": "C.-Guedes",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Guedes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Guedes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136076"
                        ],
                        "name": "A. Mar\u00e7al",
                        "slug": "A.-Mar\u00e7al",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Mar\u00e7al",
                            "middleNames": [
                                "R.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mar\u00e7al"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3698192"
                        ],
                        "name": "Jaime S. Cardoso",
                        "slug": "Jaime-S.-Cardoso",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Cardoso",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaime S. Cardoso"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 54219557,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85b55c82298790a4fde4f6ff0340505d7659f8b7",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical Music Recognition (OMR) systems are an important tool for the automatic recognition of digitized music scores. However, handwritten musical scores are especially problematic for an automatic recognition. They have irregularities that go from heterogeneous illumination to variability in symbols shape and complexity inherent to music structure. These issues cause serious difficulties when one wants a robust OMR system facilitating search, retrieval and analysis operations. To transform the paper-based music scores and manuscripts into a machine-readable symbolic format several consistent algorithms are needed. In this paper a method for music symbols extraction in handwritten and printed scores is presented. This technique tries to incorporate musical rules as prior knowledge in the segmentation process in order to overcome the state of the art results."
            },
            "slug": "A-Method-for-Music-Symbols-Extraction-based-on-Rebelo-Paszkiewicz",
            "title": {
                "fragments": [],
                "text": "A Method for Music Symbols Extraction based on Musical Rules"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This technique tries to incorporate musical rules as prior knowledge in the segmentation process in order to overcome the state of the art results."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793817"
                        ],
                        "name": "P. Bellini",
                        "slug": "P.-Bellini",
                        "structuredName": {
                            "firstName": "Pierfrancesco",
                            "lastName": "Bellini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bellini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1985733"
                        ],
                        "name": "I. Bruno",
                        "slug": "I.-Bruno",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Bruno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Bruno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808730"
                        ],
                        "name": "P. Nesi",
                        "slug": "P.-Nesi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Nesi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Nesi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17129563,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13a7eb01a432e740a6b6419edeccd179eb2f584d",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "68 Computer Music Journal As digitization and information technologies advance, document analysis and optical-characterrecognition technologies have become more widely used. Optical Music Recognition (OMR), also commonly known as OCR (Optical Character Recognition) for Music, was first attempted in the 1960s (Pruslin 1966). Standard OCR techniques cannot be used in music-score recognition, because music notation has a two-dimensional structure. In a staff, the horizontal position denotes different durations of notes, and the vertical position defines the height of the note (Roth 1994). Models for nonmusical OCR assessment have been proposed and largely used (Kanai et al. 1995; Ventzislav 2003). An ideal system that could reliably read and \u201cunderstand\u201d music notation could be used in music production for educational and entertainment applications. OMR is typically used today to accelerate the conversion from image music sheets into a symbolic music representation that can be manipulated, thus creating new and revised music editions. Other applications use OMR systems for educational purposes (e.g., IMUTUS; see www.exodus.gr/imutus), generating customized versions of music exercises. A different use involves the extraction of symbolic music representations to be used as incipits or as descriptors in music databases and related retrieval systems (Byrd 2001). OMR systems can be classified on the basis of the granularity chosen to recognize the music score\u2019s symbols. The architecture of an OMR system is tightly related to the methods used for symbol extraction, segmentation, and recognition. Generally, the music-notation recognition process can be divided into four main phases: (1) the segmentation of the score image to detect and extract symbols; (2) the recognition of symbols; (3) the reconstruction of music information; and (4) the construction of the symbolic music notation model to represent the information (Bellini, Bruno, and Nesi 2004). Music notation may present very complex constructs and several styles. This problem has been recently addressed by the MUSICNETWORK and Motion Picture Experts Group (MPEG) in their work on Symbolic Music Representation (www .interactivemusicnetwork.org/mpeg-ahg). Many music-notation symbols exist, and they can be combined in different ways to realize several complex configurations, often without using well-defined formatting rules (Ross 1970; Heussenstamm 1987). Despite various research systems for OMR (e.g., Prerau 1970; Tojo and Aoyama 1982; Rumelhart, Hinton, and McClelland 1986; Fujinaga 1988, 1996; Carter 1989, 1994; Kato and Inokuchi 1990; Kobayakawa 1993; Selfridge-Field 1993; Ng and Boyle 1994, 1996; Couasnon and Camillerapp 1995; Bainbridge and Bell 1996, 2003; Modayur 1996; Cooper, Ng, and Boyle 1997; Bellini and Nesi 2001; McPherson 2002; Bruno 2003; Byrd 2006) as well as commercially available products, optical music recognition\u2014and more generally speaking, music recognition\u2014is a research field affected by many open problems. The meaning of \u201cmusic recognition\u201d changes depending on the kind of applications and goals (Blostein and Carter 1992): audio generation from a musical score, music indexing and searching in a library database, music analysis, automatic transcription of a music score into parts, transcoding a score into interchange data formats, etc. For such applications, we must employ common tools to provide answers to questions such as \u201cWhat does a particular percentagerecognition rate that is claimed by this particular algorithm really mean?\u201d and \u201cMay I invoke a common methodology to compare different OMR tools on the basis of my music?\u201d As mentioned in Blostein and Carter (1992) and Miyao and Haralick (2000), there is no standard for expressing the results of the OMR process. Assessing Optical Music Recognition Tools"
            },
            "slug": "Assessing-Optical-Music-Recognition-Tools-Bellini-Bruno",
            "title": {
                "fragments": [],
                "text": "Assessing Optical Music Recognition Tools"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Optical Music Recognition is typically used today to accelerate the conversion from image music sheets into a symbolic music representation that can be manipulated, thus creating new and revised music editions."
            },
            "venue": {
                "fragments": [],
                "text": "Computer Music Journal"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2091914757"
                        ],
                        "name": "N. P. Carter",
                        "slug": "N.-P.-Carter",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Carter",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. P. Carter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53850504,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "a3ae4cbb32299693839f4631c09378597d792d3c",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Computers are used to manipulate music in various forms, for example digital sound recordings, digitized images of printed scores and music representational language (M.R.L.) encodings. This work is concerned with producing M.R.L. data automatically from existing printed music scores. A review of work undertaken in the field of manipulating printed music by computer is provided. This shows that software which permits production of high-quality scores is commercially available, but the necessary data has to be entered using some form of keyboard, possibly in conjunction with a pointing device. It is desirable, for reasons detailed in this work, to be able to convert the musical information contained in the enormous quantity of existing music into computer-readable form. The only practical method for achieving this is via an automatic system. Such an automatic system must cope with the variations in format, content and print-quality of existing scores. Background material relating to previous work on pattern recognition of various types of binary image is included, with a section covering the subject of automatic recognition of printed music. An original system for automatic recognition of printed music developed by the author is described. This is designed to be widely applicable and hence is, in effect, omnifont and size-independent, with significant tolerance of noise, limited rotation, broken print and distortion. Numerous illustrations showing the application of the system are included, together with proposals for future areas of development."
            },
            "slug": "Automatic-recognition-of-printed-music-in-the-of-Carter",
            "title": {
                "fragments": [],
                "text": "Automatic recognition of printed music in the context of electronic publishing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An original system for automatic recognition of printed music developed by the author is described, designed to be widely applicable and hence is, in effect, omnifont and size-independent, with significant tolerance of noise, limited rotation, broken print and distortion."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49406443"
                        ],
                        "name": "Eric Nichols",
                        "slug": "Eric-Nichols",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Nichols",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Nichols"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145985085"
                        ],
                        "name": "Donald Byrd",
                        "slug": "Donald-Byrd",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Byrd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald Byrd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 987333,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "046e5be7d600c607eb3a3e485c3ef6941bed77db",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical music recognition (OMR) is one of the most promising tools for generating large-scale, distributable libraries of musical data. Much OMR work has focussed on instrumental music, avoiding a special challenge vocal music poses for OMR: lyric recognition. Lyrics complicate the page layout, making it more difficult to identify the regions of the page that carry musical notation. Furthermore, users expect a complete OMR process for vocal music to include recognition of the lyrics, reunification of syllables when they have been separated, and alignment of these lyrics with the recognised music. Unusual layouts and inconsistent practises for syllabification, however, make lyric recognition more challenging than traditional optical character recognition (OCR). This paper surveys historical approaches to lyric recognition, outlines open challenges, and presents a new approach to extracting text lines in medieval manuscripts, one of the frontiers of OMR research today."
            },
            "slug": "Lyric-Extraction-and-Recognition-on-Digital-Images-Nichols-Byrd",
            "title": {
                "fragments": [],
                "text": "Lyric Extraction and Recognition on Digital Images of Early Music Sources"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Historical approaches to lyric recognition are surveyed, open challenges are outlined, and a new approach to extracting text lines in medieval manuscripts is presented, one of the frontiers of OMR research today."
            },
            "venue": {
                "fragments": [],
                "text": "ISMIR"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153350"
                        ],
                        "name": "N. Luth",
                        "slug": "N.-Luth",
                        "structuredName": {
                            "firstName": "Nailja",
                            "lastName": "Luth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Luth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 54
                            }
                        ],
                        "text": "algorithms without the need to remove the staff lines [5,7,45, 58,68,76,93]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13420963,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d902b57083e080c89c763fc4d231e0d4af5f2ca",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The music scores of the 18th century and earlier were produced only in a manual way. The important problem of the current registration of old historical music scores lies in the identification of the corresponding writer to estimate who did the notation writing or drawing. We are developing efficient identification of a writer's hand. This identification is based on the automated image analysis approach. The theoretical manual identification is being developed at the Institute for Musicology at the University of Rostock. First tests of an analogue approach were applied on chosen music notations. These tests indicate that the recognition problem can be sufficiently solved only by computer-aided assistance. Our research activities are concentrated on the development of an automated identification of writers by analysing the notation graphic features. In our article we describe an approach for the automated image analysis and understanding as applied to digitised music scores. This approach is aimed at solving the automated identification of writers as a result of digital music notation matching."
            },
            "slug": "Automatic-identification-of-music-notations-Luth",
            "title": {
                "fragments": [],
                "text": "Automatic identification of music notations"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An approach for the automated image analysis and understanding as applied to digitised music scores aimed at solving the automated identification of writers as a result of digital music notation matching is described."
            },
            "venue": {
                "fragments": [],
                "text": "Second International Conference on Web Delivering of Music, 2002. WEDELMUSIC 2002. Proceedings."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686569"
                        ],
                        "name": "A. Forn\u00e9s",
                        "slug": "A.-Forn\u00e9s",
                        "structuredName": {
                            "firstName": "Alicia",
                            "lastName": "Forn\u00e9s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Forn\u00e9s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143826881"
                        ],
                        "name": "J. Llad\u00f3s",
                        "slug": "J.-Llad\u00f3s",
                        "structuredName": {
                            "firstName": "Josep",
                            "lastName": "Llad\u00f3s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Llad\u00f3s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143911121"
                        ],
                        "name": "Gemma S\u00e1nchez",
                        "slug": "Gemma-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Gemma",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gemma S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 33
                            }
                        ],
                        "text": "The research work carried out by [96, 36, 37] applied this technique to their OMR procedures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 88
                            }
                        ],
                        "text": "In most of the proposed works, the music sheets were scanned at a resolution of 300 dpi [45, 64, 34, 89, 55, 26, 17, 83, 37]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206776809,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6574248c80be07f041d46adb2c9dd252fc0b962e",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Writer identification consists in determining the writer of a piece of handwriting from a set of writers. In this paper we present a system for writer identification in old handwritten music scores which uses only music notation to determine the author. The steps of the proposed system are the following. First of all, the music sheet is preprocessed for obtaining a music score without the staff lines. Afterwards, four different methods for generating texture images from music symbols are applied. Every approach uses a different spatial variation when combining the music symbols to generate the textures. Finally, Gabor filters and Grey-scale Co-ocurrence matrices are used to obtain the features. The classification is performed using a k-NN classifier based on Euclidean distance. The proposed method has been tested on a database of old music scores from the 17th to 19th centuries, achieving encouraging identification rates."
            },
            "slug": "On-the-Use-of-Textural-Features-for-Writer-in-Old-Forn\u00e9s-Llad\u00f3s",
            "title": {
                "fragments": [],
                "text": "On the Use of Textural Features for Writer Identification in Old Handwritten Music Scores"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A system for writer identification in old handwritten music scores which uses only music notation to determine the author and has been tested on a database of old music scores from the 17th to 19th centuries, achieving encouraging identification rates."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40040755"
                        ],
                        "name": "A. Capela",
                        "slug": "A.-Capela",
                        "structuredName": {
                            "firstName": "Artur",
                            "lastName": "Capela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Capela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3698192"
                        ],
                        "name": "Jaime S. Cardoso",
                        "slug": "Jaime-S.-Cardoso",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Cardoso",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaime S. Cardoso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143616982"
                        ],
                        "name": "Ana Rebelo",
                        "slug": "Ana-Rebelo",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Rebelo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana Rebelo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144453899"
                        ],
                        "name": "C. Guedes",
                        "slug": "C.-Guedes",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Guedes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Guedes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The work developed in [14] is the beginning of a web-based system that will provide broad access to a wide corpus of handwritten unpublished music encoded in digital format."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 20020058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc4bc8b9db92975173df0c326746867dd504c881",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Many music works produced in the last century still exist only as original manuscripts or as photocopies. Preserving them entails their digitalization and consequent accessibility in a digital format easy-to-manage which encourages browsing, retrieval, search and analysis while providing a generalized access to the digital material. The manual process to carry out this task is very time consuming and error prone. Automatic optical music recognition (OMR) has emerged as a partial solution to this problem. However, the full potential of this process only reveals itself when integrated in a system that provides seamless access to browsing, retrieval, search and analysis. We address this demand by proposing a modular, flexible and scalable framework that fully integrates the abovementioned functionalities. A web based system to carry out the automatic recognition process, allowing the creation and management of a music corpus, while providing generalized access to it, is a unique and innovative approach to the problem. A prototype has been implemented and is being used as a test platform for OMR algorithms."
            },
            "slug": "Integrated-Recognition-System-for-Music-Scores-Capela-Cardoso",
            "title": {
                "fragments": [],
                "text": "Integrated Recognition System for Music Scores"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A modular, flexible and scalable framework that fully integrates the abovementioned functionalities to carry out the automatic recognition process, allowing the creation and management of a music corpus, while providing generalized access to it."
            },
            "venue": {
                "fragments": [],
                "text": "ICMC"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686569"
                        ],
                        "name": "A. Forn\u00e9s",
                        "slug": "A.-Forn\u00e9s",
                        "structuredName": {
                            "firstName": "Alicia",
                            "lastName": "Forn\u00e9s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Forn\u00e9s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143826881"
                        ],
                        "name": "J. Llad\u00f3s",
                        "slug": "J.-Llad\u00f3s",
                        "structuredName": {
                            "firstName": "Josep",
                            "lastName": "Llad\u00f3s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Llad\u00f3s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143911121"
                        ],
                        "name": "Gemma S\u00e1nchez",
                        "slug": "Gemma-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Gemma",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gemma S\u00e1nchez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5735737,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e467c19cf26f28586db506605d545bfa345629e",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical Music Recognition consists in the identification of music information from images of scores. In this paper, we propose a method for the early stages of the recognition: segmentation of staff lines and graphical primitives in handwritten scores. After introducing our work with modern musical scores (where projections and Hough Transform are effectively used), an approach to deal with ancient handwritten scores is exposed. The recognition of such these old scores is more difficult due to paper degradation and the lack of a standard in musical notation. Our method has been tested with several scores of 19th century with high performance rates."
            },
            "slug": "Primitive-Segmentation-in-Old-Handwritten-Music-Forn\u00e9s-Llad\u00f3s",
            "title": {
                "fragments": [],
                "text": "Primitive Segmentation in Old Handwritten Music Scores"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method for the early stages of the recognition: segmentation of staff lines and graphical primitives in handwritten scores forOptical Music Recognition is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30232020"
                        ],
                        "name": "M. Ferrand",
                        "slug": "M.-Ferrand",
                        "structuredName": {
                            "firstName": "Miguel",
                            "lastName": "Ferrand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ferrand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145757714"
                        ],
                        "name": "Jo\u00e3o Leite",
                        "slug": "Jo\u00e3o-Leite",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Leite",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00e3o Leite"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120873965"
                        ],
                        "name": "A. Cardoso",
                        "slug": "A.-Cardoso",
                        "structuredName": {
                            "firstName": "Am\u00edlcar",
                            "lastName": "Cardoso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cardoso"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "More research works produced in the past use abductive constraint logic programming (ACLP) [33] and sorted lists that connect all inter-related symbols [20]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "In [33] an ACLP system, which integrates into a single framework abductive logic programming (ALP) and constraint logic programming (CLP), is proposed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "\u2013 Abductive Constraint Logic Programming: [33]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "More research works produced in the past use Abductive Constraint Logic Programming (ACLP) [33] and sorted lists that connect all inter-related symbols [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15078363,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c60fcdeea9ad902defb66555d65ce0ede6ca1762",
            "isKey": true,
            "numCitedBy": 6,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose a hybrid system that bridges the gap between traditional image processing methods, used for low-level object recognition, and abductive constraint logic programming used for high-level musical interpretation. Optical Music Recognition (OMR) is the automatic recognition of a scanned page of printed music. All such systems are evaluated by their rate of successful recognition; therefore a reliable OMR program should be able to detect and eventually correct its own recognition errors. Since we are interested in dealing with polyphonic music, some additional complexity is introduced as several concurrent voices and simultaneous musical events may occur. In RIEM, the OMR system we are developing, when events are inaccurately recognized they will generate inconsistencies in the process of voice separation. Furthermore if some events are missing a consistent voice separation may not even be possible. In this work we propose an improved architecture for RIEM to allow the system to hypothesize on possible missing events, to overcome the major failure in the voice assignment due to minor recognition failures. We formalize the process of voice assignment and present a practical implementation using Abductive Constraint Logic Programming. Once we abduce these missing events and know where to look for them in the original score image, we may provide the proper feedback to the recognition algorithms, relaxing the recognition thresholds gradually, until some minimum quality recognition criteria is reached."
            },
            "slug": "Hypotethical-Reasoning:-an-application-to-Optical-Ferrand-Leite",
            "title": {
                "fragments": [],
                "text": "Hypotethical Reasoning: an application to Optical Music Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "An improved architecture for RIEM is proposed to allow the system to hypothesize on possible missing events, to overcome the major failure in the voice assignment due to minor recognition failures, and to present a practical implementation using Abductive Constraint Logic Programming."
            },
            "venue": {
                "fragments": [],
                "text": "APPIA-GULP-PRODE"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145152576"
                        ],
                        "name": "G. S. Choudhury",
                        "slug": "G.-S.-Choudhury",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Choudhury",
                            "middleNames": [
                                "Sayeed"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. S. Choudhury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69461178"
                        ],
                        "name": "M. Droetboom",
                        "slug": "M.-Droetboom",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Droetboom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Droetboom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2214944"
                        ],
                        "name": "T. DiLauro",
                        "slug": "T.-DiLauro",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "DiLauro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. DiLauro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190426"
                        ],
                        "name": "Ichiro Fujinaga",
                        "slug": "Ichiro-Fujinaga",
                        "structuredName": {
                            "firstName": "Ichiro",
                            "lastName": "Fujinaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ichiro Fujinaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936973"
                        ],
                        "name": "Brian Harrington",
                        "slug": "Brian-Harrington",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Harrington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Harrington"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[20] proposed the extraction of symbol features, such as width, height, area, number"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "More research works produced in the past use Abductive Constraint Logic Programming (ACLP) [33] and sorted lists that connect all inter-related symbols [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5665689,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8ad561dc286eff564dff70e8df414ce0ab8219d",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "An adaptive optical music recognition system is being developed as part of an experiment in creating a comprehensive framework of tools to manage the workflow of large-scale digitization projects. This framework will support the path from physical object and/or digitized material into a digital library repository, and offer effective tools for incorporating metadata and perusing the content of the resulting multimedia objects. The project involves digitization of the Lester S. Levy Collection of Sheet Music (Milton S. Eisenhower Library, Johns Hopkins University). In Phase One, images of the music and lyrics, and color images of the covers of the Levy Collection were digitized and a database of text index records was created. Phase Two consists of converting the digitized music to computer-readable music notation format along with full-text lyrics, generating sound renditions, and creating metadata to enhance search capabilities. During Phase One, the researchers at the Eisenhower Library created a database of text index records, images of the music and lyrics and color images of the cover sheets from the Levy Collection. This database is available to the general public at http://levysheetmusic.mse.jhu.edu. Currently, the Collection can be searched in three modes. First, users can search by subject, a keyword search on the text record. Each of the pieces has been indexed for the subject of the song and/or cover image. Users may also browse the Collection by the topical arrangement of the physical collection. In Phase Two, an adaptive optical music recognition (AOMR) software (Fujinaga 1997) is used to convert the TIFF image of scanned sheet music into computer readable-formats, which includes GUIDO and MIDI files along with full-text of the lyrics. These digital objects will be deposited into the data repository along with the scanned sheet music TIFF, JPEG and thumbnail, and associated metadata. The AOMR software offers five important advantages over similar commercial offerings. First, it can be run in batch processing mode, an essential feature for the Levy Collection given its large number of music sheets. It is important to note that most commercial software is intended for the casual user and does not scale for a large number of objects. Second, the software is written in C and therefore is portable across platforms. Third, the software can \u201clearn\u201d to recognize different music symbols\u2014an issue considering the diversity of the Levy Collection and the universe of notated music, in general. Fourth, the software is open-sourced. Finally, this software can separate full-text lyrics that can be further processed using optical character recognition (OCR) technology. The AOMR process is divided into two major sections: symbol classification and musical semantic interpretation. The first step in the interpretation phase is to connect all inter-related symbols. In addition, many rhythmic errors can also be corrected by adjusting the metric placement of notes relative to their vertical alignment with notes in other parts. An interactive graphic editor suitable to be interfaced with the AOMR program is being developed jointly with the group working on the GUIDO editor (Renz 2000). The purpose of this editor is to correct any errors generated by the AOMR so that the corrected version then can be converted to GUIDO format. To enable powerful search and retrieval as well as user-friendly navigational mechanism, Phase Two of the Levy Project will include a strong metadata component. Commonly defined as \u201cdata about data,\u201d metadata is structured representational information. The kinds of metadata important for Levy include descriptive (to enable searching, browsing and identification of items), structural (to enable the creation of an interface for optimum browsing and navigation), and administrative (to manage the digital components of the collection and aid users in identification of items). To further enhance the scholarly value of the Levy Collection, a web interface will be developed for a music research toolkit, for example, Humdrum (Huron 1997). These toolkits are software tools intended to assist in music research and are suitable for use in a wide variety of computer-based musical investigations, such as motivic, stylistic, and melodic analysis and concordance studies. We also propose to extend plans for developing automated means of mining authoritative name information and creating even richer name indexes. The entire project is an experiment in developing a comprehensive framework of tools to manage the workflow of large-scale digitization projects. This framework will support the path from physical object and/or digitized material into a digital library repository, and offer effective tools for incorporating metadata and perusing the content of the resulting multimedia objects. The Levy Collection, with its large size and availability in digital format, is an ideal subject for development and evaluation of this proposed framework."
            },
            "slug": "Optical-Music-Recognition-System-within-a-Project-Choudhury-Droetboom",
            "title": {
                "fragments": [],
                "text": "Optical Music Recognition System within a Large-Scale Digitization Project"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "An adaptive optical music recognition system is being developed as part of an experiment in creating a comprehensive framework of tools to manage the workflow of large-scale digitization projects, and will support the path from physical object and/or digitized material into a digital library repository, and offer effective tools for incorporating metadata and perusing the content of the resulting multimedia objects."
            },
            "venue": {
                "fragments": [],
                "text": "ISMIR"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "134261147"
                        ],
                        "name": "K. Ng",
                        "slug": "K.-Ng",
                        "structuredName": {
                            "firstName": "Kim-chu",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35061525"
                        ],
                        "name": "R. Boyle",
                        "slug": "R.-Boyle",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Boyle",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Boyle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 126
                            }
                        ],
                        "text": "In [41], the k-nearest neighbor rule is used in the classification phase, while neural networks is the classifier selected in [5,7,62,66]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8292565,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0437201ce1fdcaee8ccb7943ad8de6cfeac063f0",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recognition-and-reconstruction-of-primitives-in-Ng-Boyle",
            "title": {
                "fragments": [],
                "text": "Recognition and reconstruction of primitives in music scores"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686569"
                        ],
                        "name": "A. Forn\u00e9s",
                        "slug": "A.-Forn\u00e9s",
                        "structuredName": {
                            "firstName": "Alicia",
                            "lastName": "Forn\u00e9s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Forn\u00e9s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143826881"
                        ],
                        "name": "J. Llad\u00f3s",
                        "slug": "J.-Llad\u00f3s",
                        "structuredName": {
                            "firstName": "Josep",
                            "lastName": "Llad\u00f3s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Llad\u00f3s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143911121"
                        ],
                        "name": "Gemma S\u00e1nchez",
                        "slug": "Gemma-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Gemma",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gemma S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 33
                            }
                        ],
                        "text": "The research work carried out by [96, 36, 37] applied this technique to their OMR procedures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 43276594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "802dbc149de6eaa332cc146fa6d2ce4524db855c",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "The aim of writer identification is determining the writer of a piece of handwriting from a set of writers. In this paper we present a system for writer identification in old handwritten music scores. Even though an important amount of compositions contains handwritten text in the music scores, the aim of our work is to use only music notation to determine the author. The steps of the system proposed are the following. First of all, the music sheet is preprocessed and normalized for obtaining a single binarized music line, without the staff lines. Afterwards, 100 features are extracted for every music line, which are subsequently used in a k-NN classifier that compares every feature vector with prototypes stored in a database. By applying feature selection and extraction methods on the original feature set, the performance is increased. The proposed method has been tested on a database of old music scores from the 17th to 19th centuries, achieving a recognition rate of about 95%."
            },
            "slug": "Writer-Identification-in-Old-Handwritten-Music-Forn\u00e9s-Llad\u00f3s",
            "title": {
                "fragments": [],
                "text": "Writer Identification in Old Handwritten Music Scores"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A system for writer identification in old handwritten music scores that uses only music notation to determine the author and has been tested on a database of old music scores from the 17th to 19th centuries."
            },
            "venue": {
                "fragments": [],
                "text": "2008 The Eighth IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73133324"
                        ],
                        "name": "C. Brisset",
                        "slug": "C.-Brisset",
                        "structuredName": {
                            "firstName": "Corinne",
                            "lastName": "Brisset",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Brisset"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 11
                            }
                        ],
                        "text": "Cou \u0308asnon [24, 23] also based their works on a grammar, which is essentially a description of the relations between the graphical objects and a parser, which is the introduction of musical context with syntactic or semantic information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 116
                            }
                        ],
                        "text": "The authors argue that their method overcame the complexity imposed in the parser development operation proposed in [24, 23]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "\u2013 Grammar: [74], [73], [24], [4], [85], [7]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10213034,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7da7b3b4cb4ff262691863e5104c975d3f67b1b",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical Music Recognition is a particular form of document analysis in which there is much knowledge about document structure. Indeed there exists an important set of rules for musical notation, but current systems do not fully use them. We propose a new solution using a grammar to guide the segmentation of the graphical objects and their recognition. The grammar is essentially a description of the relations (relative position and size, adjacency, etc) between the graphical objects. Inspired by Deenite Clause Grammar techniques, the grammar can be directly implemented in Prolog, a higher-order dialect of Prolog. Moreover, the translation from the grammar into Prolog code can be done automatically. Our approach is justiied by the rst encouraging results obtained with a prototype for music score recognition."
            },
            "slug": "Using-Logic-Programming-Languages-For-Optical-Music-Brisset",
            "title": {
                "fragments": [],
                "text": "Using Logic Programming Languages For Optical Music Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A new solution using a grammar to guide the segmentation of the graphical objects and their recognition, inspired by Deenite Clause Grammar techniques and directly implemented in Prolog, a higher-order dialect of Prolog."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789181"
                        ],
                        "name": "Bertrand Co\u00fcasnon",
                        "slug": "Bertrand-Co\u00fcasnon",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Co\u00fcasnon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bertrand Co\u00fcasnon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760753"
                        ],
                        "name": "J. Camillerapp",
                        "slug": "J.-Camillerapp",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Camillerapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Camillerapp"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 11
                            }
                        ],
                        "text": "Cou \u0308asnon [24, 23] also based their works on a grammar, which is essentially a description of the relations between the graphical objects and a parser, which is the introduction of musical context with syntactic or semantic information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 116
                            }
                        ],
                        "text": "The authors argue that their method overcame the complexity imposed in the parser development operation proposed in [24, 23]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16740341,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02143c9cffc49ac78423d04c308a9d2872aadb93",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical Music Recognition is a form of document analysis for which a priori knowledge is particularly important. Musical notation is governed by a substantial set of rules, but current systems fail to use them adequately. In complex scores, existing systems cannot overcome the well-known segmentation problems of document analysis, due mainly to the high density of music information. This paper proposes a new method of recognition which uses a grammar in order to formalize the syntactic rules and represent the context. However, where objects touch, there is a discrepancy between the way the existing knowledge (grammar) will describe an object and the way it is recognized, since touching objects have to be segmented first. Following a description of the grammar, this paper shall go on to propose the use of an operator to modify the way the grammar parses the image so that the system can deal with certain touching objects (e.g. where an accidental touches a notehead)."
            },
            "slug": "A-way-to-separate-knowledge-from-program-in-to-Co\u00fcasnon-Camillerapp",
            "title": {
                "fragments": [],
                "text": "A way to separate knowledge from program in structured document analysis: application to optical music recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new method of recognition is proposed which uses a grammar in order to formalize the syntactic rules and represent the context and the use of an operator to modify the way the grammar parses the image so that the system can deal with certain touching objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3698192"
                        ],
                        "name": "Jaime S. Cardoso",
                        "slug": "Jaime-S.-Cardoso",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Cardoso",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaime S. Cardoso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40040755"
                        ],
                        "name": "A. Capela",
                        "slug": "A.-Capela",
                        "structuredName": {
                            "firstName": "Artur",
                            "lastName": "Capela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Capela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143616982"
                        ],
                        "name": "Ana Rebelo",
                        "slug": "Ana-Rebelo",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Rebelo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana Rebelo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144453899"
                        ],
                        "name": "C. Guedes",
                        "slug": "C.-Guedes",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Guedes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Guedes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2013 Graph-theoretic framework: [82, 16, 17]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17767821,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c662b261835a329674898793a37123dd0eec2ee2",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The preservation of many music works produced in the past entails their digitalization and consequent accessibility in an easy-to-manage digital format. Carrying this task manually is very time consuming and error prone. While optical music recognition systems usually perform well on printed scores, the processing of handwritten musical scores by computers remain far from ideal. One of the fundamental stages to carry out this task is the staff line detection. In this paper a new method for the automatic detection of music staff lines based on a connected path approach is presented. Lines affected by curvature, discontinuities, and inclination are robustly detected. Experimental results show that the proposed technique consistently outperforms well-established algorithms."
            },
            "slug": "A-connected-path-approach-for-staff-detection-on-a-Cardoso-Capela",
            "title": {
                "fragments": [],
                "text": "A connected path approach for staff detection on a music score"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A new method for the automatic detection of music staff lines based on a connected path approach is presented and results show that the proposed technique consistently outperforms well-established algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "2008 15th IEEE International Conference on Image Processing"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143686714"
                        ],
                        "name": "Kazuhiko Yamamoto",
                        "slug": "Kazuhiko-Yamamoto",
                        "structuredName": {
                            "firstName": "Kazuhiko",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuhiko Yamamoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20661771,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ceaabecf9e51ea41133eee63abea62f5e469200",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Document image analysis is the automatic computer interpretation of images of printed and handwritten documents, including text, drawings, maps, music scores, etc. Research in this field supports a rapidly growing international industry. This is the first book to offer a broad selection of state-of-the-art research papers, including authoritative critical surveys of the literature, and parallel studies of the architectureof complete high-performance printed-document reading systems. A unique feature is the extended section on music notation, an ideal vehicle for international sharing of basic research. Also, the collection includes important new work on line drawings, handwriting, character and symbol recognition, and basic methodological issues. The IAPR 1990 Workshop on Syntactic and Structural Pattern Recognition is summarized,including the reports of its expert working groups, whose debates provide a fascinating perspective on the field. The book is an excellent text for a first-year graduate seminar in document image analysis,and is likely to remain a standard reference in the field for years."
            },
            "slug": "Structured-Document-Image-Analysis-Baird-Bunke",
            "title": {
                "fragments": [],
                "text": "Structured Document Image Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This is the first book to offer a broad selection of state-of-the-art research papers, including authoritative critical surveys of the literature, and parallel studies of the architecture of complete high-performance printed-document reading systems."
            },
            "venue": {
                "fragments": [],
                "text": "Springer Berlin Heidelberg"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2988434"
                        ],
                        "name": "L. Pugin",
                        "slug": "L.-Pugin",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Pugin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pugin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13479529"
                        ],
                        "name": "J. Burgoyne",
                        "slug": "J.-Burgoyne",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Burgoyne",
                            "middleNames": [
                                "Ashley"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burgoyne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190426"
                        ],
                        "name": "Ichiro Fujinaga",
                        "slug": "Ichiro-Fujinaga",
                        "structuredName": {
                            "firstName": "Ichiro",
                            "lastName": "Fujinaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ichiro Fujinaga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[77] presented a comparative evaluation of image binarization algorithms applied to sixteenth-century music scores."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7472838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d5d703e0172df1e37bc9db9309f3333a865bcfb",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical music recognition (OMR) systems are promising tools for the creation of searchable digital music libraries. Using an adaptive OMR system for early music prints based on hidden Markov models, we leverage an edit distance evaluation metric to improve recognition accuracy. Baseline results are computed with new labeled training and test sets drawn from a diverse group of prints. We present two experiments based on this evaluation technique. The first resulted in a significant improvement to the feature extraction function for these images. The second is a goal-directed comparison of several popular adaptive binarization algorithms, which are often evaluated only subjectively. Accuracy increased by as much as 55% for some pages, and the experiments suggest several avenues for further research."
            },
            "slug": "Goal-directed-evaluation-for-the-improvement-of-on-Pugin-Burgoyne",
            "title": {
                "fragments": [],
                "text": "Goal-directed evaluation for the improvement of optical music recognition on early music prints"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work uses an adaptive OMR system for early music prints based on hidden Markov models to improve recognition accuracy and presents a goal-directed comparison of several popular adaptive binarization algorithms, which are often evaluated only subjectively."
            },
            "venue": {
                "fragments": [],
                "text": "JCDL '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143748132"
                        ],
                        "name": "D. Bainbridge",
                        "slug": "D.-Bainbridge",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bainbridge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bainbridge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066731260"
                        ],
                        "name": "T. Bell",
                        "slug": "T.-Bell",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Bell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Similarly, Bellini et al. [6] proposed two assessment models focused on basic and composite symbols to measure the results of the OMR algorithms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 22
                            }
                        ],
                        "text": "In a more recent work Bainbridge and Bell [4] incorporated a basic graph in CANTOR system according to each musical feature\u2019s position (x, y)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 233
                            }
                        ],
                        "text": "Several surveys and summaries have been presented to the scientific community: Kassler [53] reviewed two of the first dissertations on OMR, Blostein and Baird [9] published an overview of OMR systems developed between 1966 and 1992, Bainbridge and Bell [3] published a generic framework for OMR (subsequently adopted by many researchers in this field), and both Homenda [47] and Rebelo et al. [83] presented pattern recognition studies applied to music notation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "Baird [9] published an overview of OMR systems developed between 1966 and 1992, Bainbridge and Bell [3] pub-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18602074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e7b3859813a746f9b16a584ecb024103fce48cb",
            "isKey": true,
            "numCitedBy": 169,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes the challenges posed by optical musicrecognition \u2013 a topic in computer science that aims to convert scannedpages of music into an on-line format. First, the problem is described;then a generalised framework for software is presented that emphasises keystages that must be solved: staff line identification, musical objectlocation, musical feature classification, and musical semantics. Next,significant research projects in the area are reviewed, showing how eachfits the generalised framework. The article concludes by discussingperhaps the most open question in the field: how to compare the accuracy and success of rival systems, highlighting certain steps thathelp ease the task."
            },
            "slug": "The-Challenge-of-Optical-Music-Recognition-Bainbridge-Bell",
            "title": {
                "fragments": [],
                "text": "The Challenge of Optical Music Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The challenges posed by optical music recognition are described, and a generalised framework for software is presented that emphasises key stages that must be solved: staff line identification, musical object location, musical feature classification, and musical semantics."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Humanit."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13479529"
                        ],
                        "name": "J. Burgoyne",
                        "slug": "J.-Burgoyne",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Burgoyne",
                            "middleNames": [
                                "Ashley"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burgoyne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2988434"
                        ],
                        "name": "L. Pugin",
                        "slug": "L.-Pugin",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Pugin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pugin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084153186"
                        ],
                        "name": "Greg Eustace",
                        "slug": "Greg-Eustace",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Eustace",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Eustace"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190426"
                        ],
                        "name": "Ichiro Fujinaga",
                        "slug": "Ichiro-Fujinaga",
                        "structuredName": {
                            "firstName": "Ichiro",
                            "lastName": "Fujinaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ichiro Fujinaga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [12] they worked with a set of 8,000 images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2016527,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "770f7d843ab1a36ba2431f22494208bfc971357c",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Binarisation of greyscale images is a critical step in optical music recognition (OMR) preprocessing. Binarising music documents is particularly challenging because of the nature of music notation, even more so when the sources are degraded, e.g., with ink bleed-through from the other side of the page. This paper presents a comparative evaluation of 25 binarisation algorithms tested on a set of 100 music pages. A real-world OMR infrastructure for early music (Aruspix) was used to perform an objective, goaldirected evaluation of the algorithms\u2019 performance. Our results differ significantly from the ones obtained in studies on non-music documents, which highlights the importance of developing tools specific to our community."
            },
            "slug": "A-Comparative-Survey-of-Image-Binarisation-for-on-Burgoyne-Pugin",
            "title": {
                "fragments": [],
                "text": "A Comparative Survey of Image Binarisation Algorithms for Optical Recognition on Degraded Musical Sources"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A comparative evaluation of 25 binarisation algorithms tested on a set of 100 music pages and results differ significantly from the ones obtained in studies on non-music documents, which highlights the importance of developing tools specific to the OMR community."
            },
            "venue": {
                "fragments": [],
                "text": "ISMIR"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2988434"
                        ],
                        "name": "L. Pugin",
                        "slug": "L.-Pugin",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Pugin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pugin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13479529"
                        ],
                        "name": "J. Burgoyne",
                        "slug": "J.-Burgoyne",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Burgoyne",
                            "middleNames": [
                                "Ashley"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burgoyne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190426"
                        ],
                        "name": "Ichiro Fujinaga",
                        "slug": "Ichiro-Fujinaga",
                        "structuredName": {
                            "firstName": "Ichiro",
                            "lastName": "Fujinaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ichiro Fujinaga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 3
                            }
                        ],
                        "text": "In [76,78] the segmentation task is based on Hidden Markov models (HMMs)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11334533,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8be5dec6b1ff46dd24d941b2515dbad9d84a46f9",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite steady improvement in optical music recognition (OMR), early documents remain challenging because of the high variability in their contents. In this paper, we present an original approach using maximum a posteriori (MAP) adaptation to improve an OMR tool for early typographic prints dynamically based on hidden Markov models. Taking advantage of the fact that during the normal usage of any OMR tool, errors will be corrected, and thus ground-truth produced, the system can be adapted in real-time. We experimented with five 16th-century music prints using 250 pages of music and two procedures in applying MAP adaptation. With only a handful of pages, both recall and precision rates improved even when the baseline was above 95 percent."
            },
            "slug": "MAP-Adaptation-to-Improve-Optical-Music-Recognition-Pugin-Burgoyne",
            "title": {
                "fragments": [],
                "text": "MAP Adaptation to Improve Optical Music Recognition of Early Music Documents Using Hidden Markov Models"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "An original approach using maximum a posteriori (MAP) adaptation to improve an OMR tool for early typographic prints dynamically based on hidden Markov models takes advantage of the fact that during the normal usage of any O MR tool, errors will be corrected, and thus ground-truth produced, the system can be adapted in real-time."
            },
            "venue": {
                "fragments": [],
                "text": "ISMIR"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2988434"
                        ],
                        "name": "L. Pugin",
                        "slug": "L.-Pugin",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Pugin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pugin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 3
                            }
                        ],
                        "text": "In [76,78] the segmentation task is based on Hidden Markov models (HMMs)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 54
                            }
                        ],
                        "text": "algorithms without the need to remove the staff lines [5,7,45, 58,68,76,93]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 67
                            }
                        ],
                        "text": "Other resolutions were also considered: 600 dpi [56,87] or 400 dpi [76,96]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 66
                            }
                        ],
                        "text": "In the OMR field, several research works have used this technique [16,45,76,83,98]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8062787,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "400c0d072e12f7d21742009b927be3a222dcf5ab",
            "isKey": true,
            "numCitedBy": 49,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Music printed with movable type (typographic music) from the 16th and 17th centuries contains specific graphic features. In this paper, we present a technique and associated experiments for performing optical music recognition on such music prints using Hidden Markov Models (HMM). Our original approach avoids the difficult and unreliable re moval of staff lines usually required before processing. Th e modeling of symbols on the staff is based on low-level simple features. We show that, using our technique, these features are robust enough to obtain good recognition rates eve n with poor quality images scanned from microfilm of originals. The music content retrieved by the optical recognitio process can be put to significant use in, for example, the creation of searchable digital music libraries."
            },
            "slug": "Optical-Music-Recognition-of-Early-Typographic-Pugin",
            "title": {
                "fragments": [],
                "text": "Optical Music Recognition of Early Typographic Prints using Hidden Markov Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3698192"
                        ],
                        "name": "Jaime S. Cardoso",
                        "slug": "Jaime-S.-Cardoso",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Cardoso",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaime S. Cardoso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40040755"
                        ],
                        "name": "A. Capela",
                        "slug": "A.-Capela",
                        "structuredName": {
                            "firstName": "Artur",
                            "lastName": "Capela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Capela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143616982"
                        ],
                        "name": "Ana Rebelo",
                        "slug": "Ana-Rebelo",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Rebelo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana Rebelo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144453899"
                        ],
                        "name": "C. Guedes",
                        "slug": "C.-Guedes",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Guedes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Guedes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107251416"
                        ],
                        "name": "J. P. Costa",
                        "slug": "J.-P.-Costa",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Costa",
                            "middleNames": [
                                "Pinto",
                                "da"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. P. Costa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [16], the authors proposed a graph-theoretic framework where the staff line is the result of a global optimization problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 128
                            }
                        ],
                        "text": "Database by Christoph Dalitz,9 the CVC-MUSCIMA Database by Alicia FornTs10 and the Handwritten Score Database by Jaime Cardoso11[16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 88
                            }
                        ],
                        "text": "In most of the proposed works, the music sheets were scanned at a resolution of 300 dpi [16,26,35,37,45,55,64,83,89]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "[16,26,32,41, 89]) \u2014the other technique can be found in [98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 66
                            }
                        ],
                        "text": "In the OMR field, several research works have used this technique [16,45,76,83,98]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5797994,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c730cc618fb7490095afdd52e7de0091062e525b",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The preservation of musical works produced in the past requires their digitalization and transformation into a machine-readable format. The processing of handwritten musical scores by computers remains far from ideal. One of the fundamental stages to carry out this task is the staff line detection. We investigate a general-purpose, knowledge-free method for the automatic detection of music staff lines based on a stable path approach. Lines affected by curvature, discontinuities, and inclination are robustly detected. Experimental results show that the proposed technique consistently outperforms well-established algorithms."
            },
            "slug": "Staff-Detection-with-Stable-Paths-Cardoso-Capela",
            "title": {
                "fragments": [],
                "text": "Staff Detection with Stable Paths"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work investigates a general-purpose, knowledge-free method for the automatic detection of music staff lines based on a stable path approach that consistently outperforms well-established algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075174497"
                        ],
                        "name": "Gabriel Taubman",
                        "slug": "Gabriel-Taubman",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Taubman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gabriel Taubman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792217"
                        ],
                        "name": "O. Jenkins",
                        "slug": "O.-Jenkins",
                        "structuredName": {
                            "firstName": "Odest",
                            "lastName": "Jenkins",
                            "middleNames": [
                                "Chadwicke"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Jenkins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399419990"
                        ],
                        "name": "J. Hughes",
                        "slug": "J.-Hughes",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hughes",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hughes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 151
                            }
                        ],
                        "text": "Choudhury et al. [20] proposed the extraction of symbol features, such as width, height, area, number of holes, and low-order central moments, whereas Taubman [99] preferred to extract standard moments, centralized moments, normalized moments, and Hu moments."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "of holes and low-order central moments, whereas Taubman [99] preferred to extract standard moments, centralized moments, normalized moments and Hu moments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [99] the symbols are recognized using statistical moments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14799093,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "6067bede9d30addff3417184c1e4f58566604a8f",
            "isKey": true,
            "numCitedBy": 16,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Current methods of digitizing handwritten music for typesetting remain far from ideal despite many years for music typesetting programs to mature. There are essentially two categories of programs in this area. The first of these categories contains programs such as Sibelius [Sibelius 2005] which make no distinction between note pitch and note duration, forcing the user to enter both pitch and duration with the same mouse click. This method is time consuming and frustrating, especially if notes of differing durations must be entered often such as the rhythm in Figure 1."
            },
            "slug": "MusicHand-:-A-Handwritten-Music-Recognition-System-Taubman-Jenkins",
            "title": {
                "fragments": [],
                "text": "MusicHand : A Handwritten Music Recognition System"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767674"
                        ],
                        "name": "F. Rossant",
                        "slug": "F.-Rossant",
                        "structuredName": {
                            "firstName": "Florence",
                            "lastName": "Rossant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Rossant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695917"
                        ],
                        "name": "I. Bloch",
                        "slug": "I.-Bloch",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Bloch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Bloch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "For printed music documents, a good methodology was proposed in [89]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Rossant and Bloch [89] proposed an OMR system with two stages: detection of the isolated objects and computation of hypotheses, both using low-level preprocessing, and final correct decision based on high-level processing which includes contextual information and music writing rules."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "[28,31, 68,89]) and common parts on the row and column histograms for each pair of symbols [98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [89] a fuzzy model supported on a robust symbol detection and template matching was developed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 110
                            }
                        ],
                        "text": "More recent works present a sophisticated use of projection techniques combined to improve the basic approach [2,5,7,89]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 88
                            }
                        ],
                        "text": "In most of the proposed works, the music sheets were scanned at a resolution of 300 dpi [16,26,35,37,45,55,64,83,89]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "[16,26,32,41, 89]) \u2014the other technique can be found in [98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 29
                            }
                        ],
                        "text": "with the classification task [89,100]; however, there are"
                    },
                    "intents": []
                }
            ],
            "corpusId": 16692240,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b874c79a64c4f1de291d1b420928f7b75feb135",
            "isKey": true,
            "numCitedBy": 66,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a system for optical music recognition (OMR) in case of monophonic typeset scores. After clarifying the difficulties specific to this domain, we propose appropriate solutions at both image analysis level and high-level interpretation. Thus, a recognition and segmentation method is designed, that allows dealing with common printing defects and numerous symbol interconnections. Then, musical rules are modeled and integrated, in order to make a consistent decision. This high-level interpretation step relies on the fuzzy sets and possibility framework, since it allows dealing with symbol variability, flexibility, and imprecision of music rules, and merging all these heterogeneous pieces of information. Other innovative features are the indication of potential errors and the possibility of applying learning procedures, in order to gain in robustness. Experiments conducted on a large data base show that the proposed method constitutes an interesting contribution to OMR."
            },
            "slug": "Robust-and-Adaptive-OMR-System-Including-Fuzzy-of-Rossant-Bloch",
            "title": {
                "fragments": [],
                "text": "Robust and Adaptive OMR System Including Fuzzy Modeling, Fusion of Musical Rules, and Possible Error Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A recognition and segmentation method is designed, that allows dealing with common printing defects and numerous symbol interconnections, and musical rules are modeled and integrated, in order to make a consistent decision."
            },
            "venue": {
                "fragments": [],
                "text": "EURASIP J. Adv. Signal Process."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2795257"
                        ],
                        "name": "C. Fremerey",
                        "slug": "C.-Fremerey",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Fremerey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fremerey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116144530"
                        ],
                        "name": "Meinard M\u00fcller",
                        "slug": "Meinard-M\u00fcller",
                        "structuredName": {
                            "firstName": "Meinard",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meinard M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34979912"
                        ],
                        "name": "F. Kurth",
                        "slug": "F.-Kurth",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Kurth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kurth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461182"
                        ],
                        "name": "M. Clausen",
                        "slug": "M.-Clausen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Clausen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Clausen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 110
                            }
                        ],
                        "text": "Other procedures try to automatically synchronize sheet music scanned with a corresponding CD audio recording [27,38,56] using a matching between OMR algorithms and digital signal processing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1723320,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8851e5e2102300d95867a1c8c80d62c2ad9ebbf1",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "ABSTRACTSignic ant digitization efforts have resulted in large mul ti-modal music collections comprising visual (scanned sheetmusic) as well as acoustic material (audio recordings).In this paper, we present a novel procedure for mappingscanned pages of sheet music to a given collection of au-dio recordings by identifying musically corresponding au-dioclips. Tothisend,boththescannedimagesaswellastheaudiorecordingsarer sttransformedintoacommonfeaturerepresentation using optical music recognition (OMR) andmethods from digital signal processing, respectively. Basedon this common representation, a direct comparison of thetwo different types of data is facilitated. This allows for asearch of scan-based queries in the audio collection. We re-port on systematic experiments conducted on the corpus ofBeethoven's piano sonatas showing that our mapping pro-cedure works with high precision across the two types ofmusic data in the case that there are no severe OMR errors.The proposed mapping procedure is relevant in a real-worldapplication scenario at the Bavarian State Library for auto-maticallyidentifyingandannotatingscannedsheetmusicbymeans of already available annotated audio material.1 INTRODUCTIONThe last years have seen increasing efforts in building uplarge digital music collections. These collections typicallycontain various types of data ranging from audio data suchasCDrecordingstoimagedatasuchasscannedsheetmusic,thus concerning both the auditorial and the visual modal-ities. In view of multimodal searching, navigation, andbrowsing applications across the various types of data, onerequires powerful tools that support the process of analyz-ing,correlating,andannotatingtheavailablematerial. Inthecase of digitized audio recordings, r st services have beenestablished to automate the annotation process by identify-ing each recording and assigning available metadata such astitle, artist, or lyrics. Here, the metadata is drawn from spe-cialized annotation databases provided by commercial ser-vices such as Gracenote [6] or DE-PARCON [9].Opposed to acoustic music data, which is increasinglyavailable in digital formats, most sheet music is still pro-duced and sold in printed form. In the last years, dig-ital music libraries have started to systematically digitizetheir holdings of sheet music resulting in a large numberof scanned raster images. To make the raw image dataavailable to content-based retrieval and browsing, meth-ods for automatically extracting and annotating semanti-cally meaningful entities contained in the scanned docu-ments are needed. In this context, optical music recogni-tion (OMR) [3] is a key task. Here, the goal is to convertscannedsheetmusicintoacomputerreadablesymbolicmu-sic format such as MIDI or MusicXML [13]. Even thoughsignic ant progress has been made in the last years, cur-rentOMRalgorithmsaresubstantiallyerror-prone,resultingin systematic errors that require subsequent correction [2].Similarly, there is still a high demand for reliable solutionsfor the more general task of automatic sheet music annota-tion in the digital library community.In this paper, we present a novel approach for automat-ically annotating scanned pages of sheet music with meta-data. Ourapproachisbasedonanewprocedureformappingthe scanned sheet music pages to an existing collection ofannotated audio recordings. The mapping allows for iden-tifying and subsequently annotating the scans based on themetadata and annotations that are already available for theaudio recordings. In particular, as it is the case in the spe-cic application scenario at the Bavarian State Library, weassume the existence of an audio collection containing an-notated digitized audio recordings for all pieces to be con-sidered in the sheet music digitization process. The con-version of both the audio recordings (by employing l teringmethods) and the scanned images (by employing OMR) toa common feature representation allows for a direct com-parison of the two different types of data. Using the featuresequence obtained from a few consecutive staves or an en-tire page of the scanned sheet music as query, we computethe top match within the documents of the audio database.The top match typically lies within a musically correspond-ing audio recording, which then allows for identifying thescanned page and for transferring all available audio anno-"
            },
            "slug": "Automatic-Mapping-of-Scanned-Sheet-Music-to-Audio-Fremerey-M\u00fcller",
            "title": {
                "fragments": [],
                "text": "Automatic Mapping of Scanned Sheet Music to Audio Recordings"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel procedure for mappingsanned pages of sheet music to a given collection of au-dio recordings by identifying musically corresponding au-dioclips using optical music recognition (OMR) and methods from digital signal processing, respectively is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ISMIR"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717204"
                        ],
                        "name": "Roland G\u00f6cke",
                        "slug": "Roland-G\u00f6cke",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "G\u00f6cke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roland G\u00f6cke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Goecke [45] applies template matching to extract musical symbols."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "[41,45,96,98]), blurring [45], de-skewing (e."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 88
                            }
                        ],
                        "text": "In most of the proposed works, the music sheets were scanned at a resolution of 300 dpi [16,26,35,37,45,55,64,83,89]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "[35,41,45,64,98]), and morphological operations [45] are the most common techniques for preprocessing music scores."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 66
                            }
                        ],
                        "text": "In the OMR field, several research works have used this technique [16,45,76,83,98]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 54
                            }
                        ],
                        "text": "algorithms without the need to remove the staff lines [5,7,45, 58,68,76,93]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17189879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0becf150902ad48e080d0572dd5ef26686d442c6",
            "isKey": true,
            "numCitedBy": 23,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "17th and 18th century music scores were copied and distributed in a manual way. Music historians are interested in how the compositions were distributed or in other words, who copied the compositions when and where. Such information may also help to determine the composer when a piece of unknown origin is found. In this paper, we present ongoing work on the development of a software system to analyse such documents automatically and to aid the musicologists in their task to register handwritten music scores. In particular, we focus on the application and adaptation of image processing methods to separate music symbols for the identification task from irrelevant elements."
            },
            "slug": "Building-a-system-for-writer-identification-on-G\u00f6cke",
            "title": {
                "fragments": [],
                "text": "Building a system for writer identification on handwritten music scores"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105099447"
                        ],
                        "name": "R. Randriamahefa",
                        "slug": "R.-Randriamahefa",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Randriamahefa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Randriamahefa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722115"
                        ],
                        "name": "J. Cocquerez",
                        "slug": "J.-Cocquerez",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Cocquerez",
                            "middleNames": [
                                "Pierre"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cocquerez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759609"
                        ],
                        "name": "C. Fluhr",
                        "slug": "C.-Fluhr",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Fluhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fluhr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069793156"
                        ],
                        "name": "F. Pepin",
                        "slug": "F.-Pepin",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Pepin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Pepin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401985509"
                        ],
                        "name": "S. Philipp-Foliguet",
                        "slug": "S.-Philipp-Foliguet",
                        "structuredName": {
                            "firstName": "Sylvie",
                            "lastName": "Philipp-Foliguet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Philipp-Foliguet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 117
                            }
                        ],
                        "text": "The simplest approach consists of finding local maxima on the horizontal projection of the black pixels of the image [41,79]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[79] proposed a structural method based on the construction of graphs for each symbol."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 37905844,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "2a4c7fb6f6bd7e14efc355462e6f34184f9202e6",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The different steps to recognize printed music are described. The first step is to detect and to eliminate the staff lines. A robust method based on finding regions where are only the staff lines, linking between them the staff lines pieces in these regions is used. After staff lines elimination, symbols are isolated and a representation called attributed graph is constructed for each symbol. Thinning, polygonalization, spurious segments cleaning, and segment fusion are performed. A first classification, separating all notes with black heads from others, is performed. To recognize notes with black heads (beamed group or quarter notes), a straightforward structural approach using this representation is sufficient and efficient in most cases. In the ambiguous cases (chord or black head linked to two stems), an ellipse matching method is used. To recognize half notes and bar lines, a structural method using the graph is used.<<ETX>>"
            },
            "slug": "Printed-music-recognition-Randriamahefa-Cocquerez",
            "title": {
                "fragments": [],
                "text": "Printed music recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The different steps to recognize printed music are described, and a straightforward structural approach using this representation is sufficient and efficient in most cases."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793817"
                        ],
                        "name": "P. Bellini",
                        "slug": "P.-Bellini",
                        "structuredName": {
                            "firstName": "Pierfrancesco",
                            "lastName": "Bellini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bellini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1985733"
                        ],
                        "name": "I. Bruno",
                        "slug": "I.-Bruno",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Bruno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Bruno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808730"
                        ],
                        "name": "P. Nesi",
                        "slug": "P.-Nesi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Nesi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Nesi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 54
                            }
                        ],
                        "text": "algorithms without the need to remove the staff lines [5,7,45, 58,68,76,93]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 126
                            }
                        ],
                        "text": "In [41], the k-nearest neighbor rule is used in the classification phase, while neural networks is the classifier selected in [5,7,62,66]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 75
                            }
                        ],
                        "text": "Other authors have chosen to apply projections to detect primitive symbols [5,7,41,74]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 110
                            }
                        ],
                        "text": "More recent works present a sophisticated use of projection techniques combined to improve the basic approach [2,5,7,89]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206864346,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "e397c9a65893bb0a1f05ba46a9a0f64d1614fc59",
            "isKey": true,
            "numCitedBy": 50,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The optical music recognition problem has been addressed in several ways, obtaining suitable results only when simple music constructs are processed. The most critical phase of the optical music recognition process is the first analysis of the image sheet. The first analysis consists of segmenting the acquired sheet into smaller parts which may be processed to recognize the basic symbols. The segmentation module of the O/sup 3/ MR system (Object Oriented Optical Music Recognition) system is presented. The proposed approach is based on the adoption of projections for the extraction of basic symbols that constitute a graphic element of the music notation. A set of examples is also included."
            },
            "slug": "Optical-music-sheet-segmentation-Bellini-Bruno",
            "title": {
                "fragments": [],
                "text": "Optical music sheet segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The segmentation module of the O/sup 3/ MR system (Object Oriented Optical Music Recognition) system is presented and the proposed approach is based on the adoption of projections for the extraction of basic symbols that constitute a graphic element of the music notation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings First International Conference on WEB Delivering of Music. WEDELMUSIC 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34979912"
                        ],
                        "name": "F. Kurth",
                        "slug": "F.-Kurth",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Kurth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kurth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116144530"
                        ],
                        "name": "Meinard M\u00fcller",
                        "slug": "Meinard-M\u00fcller",
                        "structuredName": {
                            "firstName": "Meinard",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meinard M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2795257"
                        ],
                        "name": "C. Fremerey",
                        "slug": "C.-Fremerey",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Fremerey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fremerey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157245184"
                        ],
                        "name": "Yoon-ha Chang",
                        "slug": "Yoon-ha-Chang",
                        "structuredName": {
                            "firstName": "Yoon-ha",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoon-ha Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461182"
                        ],
                        "name": "M. Clausen",
                        "slug": "M.-Clausen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Clausen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Clausen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 48
                            }
                        ],
                        "text": "Other resolutions were also considered: 600 dpi [56,87] or 400 dpi [76,96]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 110
                            }
                        ],
                        "text": "Other procedures try to automatically synchronize sheet music scanned with a corresponding CD audio recording [27,38,56] using a matching between OMR algorithms and digital signal processing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14697719,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0164ee9973c92a15a71c0d19684bac430f4cb48",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a procedure for automatically synchronizing scanned sheet music with a corresponding CD audio recording, where suitable regions (given in pixels) of the scanned digital images are linked to time positions of the audio file. In a first step, we extract note parameters and 2D position information from the scanned images using standard software for optical music recognition (OMR). We then use a chroma-based synchronization algorithm to align the note parameters to the given audio recording. Our experiments show that even though the output of current OMR software is often erroneous, the music parameters extracted from the digital images still suffice to derive a reasonable alignment with the audio data stream. The resulting link structure can be used to highlight the current position in the scanned score or to automatically turn pages during playback of an audio recording. Such functionalities have been realized as plug-in for the SyncPlayer, which is a free prototypical software framework for bringing together various MIR techniques and applications."
            },
            "slug": "Automated-Synchronization-of-Scanned-Sheet-Music-Kurth-M\u00fcller",
            "title": {
                "fragments": [],
                "text": "Automated Synchronization of Scanned Sheet Music with Audio Recordings"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "This paper presents a procedure for automatically synchronizing scanned sheet music with a corresponding CD audio recording, where suitable regions of the scanned digital images are linked to time positions of the audio file."
            },
            "venue": {
                "fragments": [],
                "text": "ISMIR"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2988434"
                        ],
                        "name": "L. Pugin",
                        "slug": "L.-Pugin",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Pugin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pugin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Other resolutions were also considered: 600 dpi [87, 56] or 400dpi [76, 96]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Notwithstanding, there are authors who suggested algorithms without the need to remove the staff lines [68, 5, 58, 45, 93, 76, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In [76, 78] the segmentation task is based on Hidden Markov Models"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[45, 76, 17, 83])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In the OMR field, several research works have used this technique [45, 76, 17, 83, 98]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2013 Hidden Markov Models: [76]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11859533,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "2fa50f5b2ce0d1cf67ca1405a09600f19082d80c",
            "isKey": true,
            "numCitedBy": 61,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Music printed with movable type (typographic music) from the 16th and 17th centuries contains specific graphic features. In this paper, we present a technique and associated experiments for performing optical music recognition on such music prints using Hidden Markov Models (HMM). Our original approach avoids the difficult and unreliable removal of staff lines usually required before processing. The modeling of symbols on the staff is based on low-level simple features. We show that, using our technique, these features are robust enough to obtain good recognition rates even with poor quality images scanned from microfilm of originals. The music content retrieved by the optical recognition process can be put to significant use in, for example, the creation of searchable digital music libraries."
            },
            "slug": "Optical-Music-Recognitoin-of-Early-Typographic-Pugin",
            "title": {
                "fragments": [],
                "text": "Optical Music Recognitoin of Early Typographic Prints using Hidden Markov Models"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This paper presents a technique and associated experiments for performing optical music recognition on such music prints using Hidden Markov Models (HMM), and shows that these features are robust enough to obtain good recognition rates even with poor quality images scanned from microfilm of originals."
            },
            "venue": {
                "fragments": [],
                "text": "ISMIR"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1885811"
                        ],
                        "name": "Fubito Toyama",
                        "slug": "Fubito-Toyama",
                        "structuredName": {
                            "firstName": "Fubito",
                            "lastName": "Toyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fubito Toyama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14457342"
                        ],
                        "name": "K. Shoji",
                        "slug": "K.-Shoji",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Shoji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shoji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2142437"
                        ],
                        "name": "J. Miyamichi",
                        "slug": "J.-Miyamichi",
                        "structuredName": {
                            "firstName": "Juichi",
                            "lastName": "Miyamichi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Miyamichi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 29
                            }
                        ],
                        "text": "with the classification task [89,100]; however, there are"
                    },
                    "intents": []
                }
            ],
            "corpusId": 20295134,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "058145f9fea66f436be70742a1b26d31c4e8aa15",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "To build a music database efficiently, an automatic score recognition system is a critical component. Many previous methods are applicable only to some simple music scores. In case of complex music scores it becomes difficult to detect symbols correctly because of noise and connection between symbols included in the scores. In this paper, we propose a score recognition method which is applicable to the complex music scores. Symbol candidates are detected by template matching. From these candidates correct symbols are selected by considering their relative positions and mutual connections. Under the presence of noise and connected symbols, the proposed method outperformed \"Score Maker\" which is an optical music score recognition software"
            },
            "slug": "Symbol-Recognition-of-Printed-Piano-Scores-with-Toyama-Shoji",
            "title": {
                "fragments": [],
                "text": "Symbol Recognition of Printed Piano Scores with Touching Symbols"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A score recognition method which is applicable to the complex music scores and outperformed \"Score Maker\" which is an optical music score recognition software."
            },
            "venue": {
                "fragments": [],
                "text": "18th International Conference on Pattern Recognition (ICPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149815080"
                        ],
                        "name": "Anjan Dutta",
                        "slug": "Anjan-Dutta",
                        "structuredName": {
                            "firstName": "Anjan",
                            "lastName": "Dutta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anjan Dutta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144167309"
                        ],
                        "name": "U. Pal",
                        "slug": "U.-Pal",
                        "structuredName": {
                            "firstName": "Umapada",
                            "lastName": "Pal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Pal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686569"
                        ],
                        "name": "A. Forn\u00e9s",
                        "slug": "A.-Forn\u00e9s",
                        "structuredName": {
                            "firstName": "Alicia",
                            "lastName": "Forn\u00e9s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Forn\u00e9s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143826881"
                        ],
                        "name": "J. Llad\u00f3s",
                        "slug": "J.-Llad\u00f3s",
                        "structuredName": {
                            "firstName": "Josep",
                            "lastName": "Llad\u00f3s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Llad\u00f3s"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[32] proposed a similar but simpler procedure than previous ones."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 38
                            }
                        ],
                        "text": "\u2013 Methods for linking staff segments: [63, 95, 32]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8438425,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7ff4ec396cd353265db2791d6b3b87f672d1e50",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Staff removal is an important preprocessing step of the Optical Music Recognition (OMR). The process aims to remove the stafflines from a musical document and retain only the musical symbols, later these symbols are used effectively to identify the music information. This paper proposes a simple but robust method to remove stafflines from printed musical scores. In the proposed methodology we have considered a staffline segment as a horizontal linkage of vertical black runs with uniform height. We have used the neighbouring properties of a staffline segment to validate it as a true segment. We have considered the dataset along with the deformations described in \\cite{ex8} for evaluation purpose. From experimentation we have got encouraging results."
            },
            "slug": "An-Efficient-Staff-Removal-Approach-from-Printed-Dutta-Pal",
            "title": {
                "fragments": [],
                "text": "An Efficient Staff Removal Approach from Printed Musical Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "In the proposed methodology, a staffline segment is considered as a horizontal linkage of vertical black runs with uniform height to validate it as a true segment."
            },
            "venue": {
                "fragments": [],
                "text": "2010 20th International Conference on Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686569"
                        ],
                        "name": "A. Forn\u00e9s",
                        "slug": "A.-Forn\u00e9s",
                        "structuredName": {
                            "firstName": "Alicia",
                            "lastName": "Forn\u00e9s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Forn\u00e9s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7855312"
                        ],
                        "name": "S. Escalera",
                        "slug": "S.-Escalera",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Escalera",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Escalera"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143826881"
                        ],
                        "name": "J. Llad\u00f3s",
                        "slug": "J.-Llad\u00f3s",
                        "structuredName": {
                            "firstName": "Josep",
                            "lastName": "Llad\u00f3s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Llad\u00f3s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143911121"
                        ],
                        "name": "Gemma S\u00e1nchez",
                        "slug": "Gemma-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Gemma",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gemma S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143601910"
                        ],
                        "name": "P. Radeva",
                        "slug": "P.-Radeva",
                        "structuredName": {
                            "firstName": "Petia",
                            "lastName": "Radeva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Radeva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144627115"
                        ],
                        "name": "O. Pujol",
                        "slug": "O.-Pujol",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Pujol",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Pujol"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[35] pro- posed a classifier procedure for handwritten symbols using the Adaboost method with a Blurred Shape Model descrip- tor."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14879932,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f39999b3cd0b0b6ecf22e68d23059a6a5d801497",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the major difficulties of handwriting recognition is the variability among symbols because of the different writer styles. In this paper we introduce the boosting of blurred shape models with error correction, which is a robust approach for describing and recognizing handwritten symbols tolerant to this variability. A symbol is described by a probability density function of blurred shape model that encodes the probability of pixel densities of image regions. Then, to learn the most distinctive features among symbol classes, boosting techniques are used to maximize the separability among the blurred shape models. Finally, the set of binary boosting classifiers is embedded in the framework of Error Correcting Output Codes (ECOC). Our approach has been evaluated in two benchmarking scenarios consisting of handwritten symbols. Compared with state-of-the-art descriptors, our method shows higher tolerance to the irregular deformations induced by handwritten strokes."
            },
            "slug": "Handwritten-Symbol-Recognition-by-a-Boosted-Blurred-Forn\u00e9s-Escalera",
            "title": {
                "fragments": [],
                "text": "Handwritten Symbol Recognition by a Boosted Blurred Shape Model with Error Correction"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper introduces the boosting of blurred shape models with error correction, which is a robust approach for describing and recognizing handwritten symbols tolerant to this variability."
            },
            "venue": {
                "fragments": [],
                "text": "IbPRIA"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080948362"
                        ],
                        "name": "Chen Genfang",
                        "slug": "Chen-Genfang",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Genfang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chen Genfang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48284436"
                        ],
                        "name": "Z. Wenjun",
                        "slug": "Z.-Wenjun",
                        "structuredName": {
                            "firstName": "Zhang",
                            "lastName": "Wenjun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Wenjun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121289813"
                        ],
                        "name": "Wang Qiuqiu",
                        "slug": "Wang-Qiuqiu",
                        "structuredName": {
                            "firstName": "Wang",
                            "lastName": "Qiuqiu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wang Qiuqiu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[41, 45, 64, 34, 17, 43, 98]), noise removal (e."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2013 MIDI: [68, 33, 31, 64, 43, 20, 98]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 790715,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "6a143ed14bbd09bdaa43f1116e9d0929ef30a2b4",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The basic rule of musical notation for image processing is analyzed, in this paper. Using the structuring elements of musical notation and the basic algorithms of mathematical morphology, a new recognizing for the musical information of digital musical score is presented, and then the musical information is transformed to MIDI file for the communication and restoration of musical score. The results of experiment show that the statistic average value of recognition rate for musical information from digital musical score is 94.4%, and can be satisfied the practical applied demand, and it is a new way for applications of digital library, musical education, musical theory analysis and so on."
            },
            "slug": "Pick-up-the-Musical-Information-from-Digital-Score-Genfang-Wenjun",
            "title": {
                "fragments": [],
                "text": "Pick-up the Musical Information from Digital Musical Score Based on Mathematical Morphology and Music Notation"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The results of experiment show that the statistic average value of recognition rate for musical information from digital musical score is 94.4%, and can be satisfied the practical applied demand, and is a new way for applications of digital library, musical education, musical theory analysis and so on."
            },
            "venue": {
                "fragments": [],
                "text": "2009 First International Workshop on Education Technology and Computer Science"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2942493"
                        ],
                        "name": "I. Knopke",
                        "slug": "I.-Knopke",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Knopke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Knopke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145985085"
                        ],
                        "name": "Donald Byrd",
                        "slug": "Donald-Byrd",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Byrd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald Byrd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "For example, Byrd and Schindele [13] and Knopke and Byrd [55] use a voting system with a comparison algorithm to merge the best features of several OMR algorithms to produce better results."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 88
                            }
                        ],
                        "text": "In most of the proposed works, the music sheets were scanned at a resolution of 300 dpi [16,26,35,37,45,55,64,83,89]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 90
                            }
                        ],
                        "text": "Studies have been carried out to overcome this limitation by merging multiple OMR systems [13,55]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16152626,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6b1e29d2b5bbabc4186eada972453fee5fc0466",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents work towards a \u201cmusicdiff\u201d program for comparing files representing different versions of the same piece, primarily in the context of comparing versions produced by different optical music recognition (OMR) programs. Previous work by the current authors and others strongly suggests that using multiple recognizers will make it possible to improve OMR accuracy substantially. The basic methodology requires several stages: documents must be scanned and submitted to several OMR programs, programs whose strengths and weaknesses have previously been evaluated in detail. We discuss techniques we have implemented for normalization, alignment and rudimentary error correction. We also describe a visualization tool for comparing multiple versions on a measure-by-measure basis."
            },
            "slug": "Towards-Musicdiff:-A-Foundation-for-Improved-Music-Knopke-Byrd",
            "title": {
                "fragments": [],
                "text": "Towards Musicdiff: A Foundation for Improved Optical Music Recognition Using Multiple Recognizers"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents work towards a \u201cmusicdiff\u201d program for comparing files representing different versions of the same piece, primarily in the context of comparing versions produced by different optical music recognition (OMR) programs."
            },
            "venue": {
                "fragments": [],
                "text": "ISMIR"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2527920"
                        ],
                        "name": "Douglas E. Zongker",
                        "slug": "Douglas-E.-Zongker",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Zongker",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douglas E. Zongker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 185
                            }
                        ],
                        "text": "The full set of training patterns extracted from the database of scores was augmented with replicas of the existing patterns, transformed according to the elastic deformation technique [50]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 93826,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b927708cdcc17d71c308ebc7052269063e879044",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the application of deformable templates to recognition of handprinted digits. Two characters are matched by deforming the contour of one to fit the edge strengths of the other, and a dissimilarity measure is derived from the amount of deformation needed, the goodness of fit of the edges, and the interior overlap between the deformed shapes. Classification using the minimum dissimilarity results in recognition rates up to 99.25 percent on a 2,000 character subset of NIST Special Database 1. Additional experiments on an independent test data were done to demonstrate the robustness of this method. Multidimensional scaling is also applied to the 2,000/spl times/2,000 proximity matrix, using the dissimilarity measure as a distance, to embed the patterns as points in low-dimensional spaces. A nearest neighbor classifier is applied to the resulting pattern matrices. The classification accuracies obtained in the derived feature space demonstrate that there does exist a good low-dimensional representation space. Methods to reduce the computational requirements, the primary limiting factor of this method, are discussed."
            },
            "slug": "Representation-and-Recognition-of-Handwritten-Using-Jain-Zongker",
            "title": {
                "fragments": [],
                "text": "Representation and Recognition of Handwritten Digits Using Deformable Templates"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The application of deformable templates to recognition of handprinted digits shows that there does exist a good low-dimensional representation space and methods to reduce the computational requirements, the primary limiting factor, are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3698192"
                        ],
                        "name": "Jaime S. Cardoso",
                        "slug": "Jaime-S.-Cardoso",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Cardoso",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaime S. Cardoso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143616982"
                        ],
                        "name": "Ana Rebelo",
                        "slug": "Ana-Rebelo",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Rebelo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana Rebelo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11526965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "020554e147e334593bb2a4dc78a09ecd81bc3be4",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The optical recognition of handwritten musical scores by computers remains far from ideal. Most OMR algorithms rely on an estimation of the staff line thickness and the vertical line distance within the same staff. Subsequent operation can use these values as references, dismissing the need for some predetermined threshold values. In this work we improve on previous conventional estimates for these two reference lengths. We start by proposing a new method for binarized music scores and then extend the approach for gray-level music scores. An experimental study with 50 images is used to assess the interest of the novel method."
            },
            "slug": "Robust-Staffline-Thickness-and-Distance-Estimation-Cardoso-Rebelo",
            "title": {
                "fragments": [],
                "text": "Robust Staffline Thickness and Distance Estimation in Binary and Gray-Level Music Scores"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes a new method for binarized music scores and extends the approach for gray-level music scores, improving on previous conventional estimates for these two reference lengths."
            },
            "venue": {
                "fragments": [],
                "text": "2010 20th International Conference on Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31901592"
                        ],
                        "name": "J. Riley",
                        "slug": "J.-Riley",
                        "structuredName": {
                            "firstName": "Jenn",
                            "lastName": "Riley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Riley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190426"
                        ],
                        "name": "Ichiro Fujinaga",
                        "slug": "Ichiro-Fujinaga",
                        "structuredName": {
                            "firstName": "Ichiro",
                            "lastName": "Fujinaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ichiro Fujinaga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 48
                            }
                        ],
                        "text": "Other resolutions were also considered: 600 dpi [56,87] or 400 dpi [76,96]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12223477,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "5a2a34264ebb19250a872247e93f5eee904a77ca",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Like other complex visual articles with small details, musical scores are difficult to capture and present well in digital form. This article presents methods that can be used to reproduce detail and tone from printed scores for creating archival images, based on best practices commonly used by the library community. Capture decisions should be made with a clear idea of the purpose of the imaging project yet be flexible enough to fulfill unanticipated future uses. Options and recommendations for file formats for archival storage, Web delivery and printing of musical materials are discussed."
            },
            "slug": "Recommended-best-practices-for-digital-image-of-Riley-Fujinaga",
            "title": {
                "fragments": [],
                "text": "Recommended best practices for digital image capture of musical scores"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Methods that can be used to reproduce detail and tone from printed scores for creating archival images, based on best practices commonly used by the library community are presented."
            },
            "venue": {
                "fragments": [],
                "text": "OCLC Syst. Serv."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523280"
                        ],
                        "name": "J. Roach",
                        "slug": "J.-Roach",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Roach",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Roach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143811250"
                        ],
                        "name": "J. E. Tatem",
                        "slug": "J.-E.-Tatem",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Tatem",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. E. Tatem"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44738211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70e0e3c79ff26dbb3d20d69be7c41ab2baa0aa72",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Using-domain-knowledge-in-low-level-visual-to-An-Roach-Tatem",
            "title": {
                "fragments": [],
                "text": "Using domain knowledge in low-level visual processing to interpret handwritten music: An experiment"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145985085"
                        ],
                        "name": "Donald Byrd",
                        "slug": "Donald-Byrd",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Byrd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald Byrd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35020073"
                        ],
                        "name": "M. Schindele",
                        "slug": "M.-Schindele",
                        "structuredName": {
                            "firstName": "Megan",
                            "lastName": "Schindele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schindele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "For example, Byrd and Schindele [13] and Knopke and Byrd [55] use a voting system with a comparison algorithm to merge the best features of several OMR algorithms to produce better results."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 90
                            }
                        ],
                        "text": "Studies have been carried out to overcome this limitation by merging multiple OMR systems [13,55]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17001893,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc1dec80eb15dd9e0f4b1da06024a9b41b04ded9",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "OMR (Optical Music Recognition) programs have been available for years, but they still leave much to be desired in terms of accuracy. We studied the feasibility of achieving substantially better accuracy by using the output of several programs to \u201ctriangulate\u201d and get better results than any of the individual programs; this multiplerecognizer approach has had some success with other media but, to our knowledge, has never been tried for music. A major obstacle is that the complexity of music notation is such that evaluating OMR accuracy is difficult for any but the simplest music. Nonetheless, existing programs have serious enough limitations that the multiplerecognizer approach is promising."
            },
            "slug": "Prospects-for-Improving-OMR-with-Multiple-Byrd-Schindele",
            "title": {
                "fragments": [],
                "text": "Prospects for Improving OMR with Multiple Recognizers"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work studied the feasibility of achieving substantially better accuracy by using the output of several programs to \u201ctriangulate\u201d and get better results than any of the individual programs."
            },
            "venue": {
                "fragments": [],
                "text": "ISMIR"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069293314"
                        ],
                        "name": "D. Damm",
                        "slug": "D.-Damm",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Damm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Damm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2795257"
                        ],
                        "name": "C. Fremerey",
                        "slug": "C.-Fremerey",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Fremerey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fremerey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34979912"
                        ],
                        "name": "F. Kurth",
                        "slug": "F.-Kurth",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Kurth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kurth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116144530"
                        ],
                        "name": "Meinard M\u00fcller",
                        "slug": "Meinard-M\u00fcller",
                        "structuredName": {
                            "firstName": "Meinard",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meinard M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461182"
                        ],
                        "name": "M. Clausen",
                        "slug": "M.-Clausen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Clausen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Clausen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 110
                            }
                        ],
                        "text": "Other procedures try to automatically synchronize sheet music scanned with a corresponding CD audio recording [27,38,56] using a matching between OMR algorithms and digital signal processing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7252759,
            "fieldsOfStudy": [
                "Art",
                "Computer Science"
            ],
            "id": "84c3b316a42e24139c347f4f43b753c0ca72cd74",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent digitization efforts have led to large music collections, which contain music documents of various modes comprising textual, visual and acoustic data. In this paper, we present a multimodal music player for presenting and browsing digitized music collections consisting of heterogeneous document types. In particular, we concentrate on music documents of two widely used types for representing a musical work, namely visual music representation (scanned images of sheet music) and associated interpretations (audio recordings). We introduce novel user interfaces for multimodal (audio-visual) music presentation as well as intuitive navigation and browsing. Our system offers high quality audio playback with time-synchronous display of the digitized sheet music associated to a musical work. Furthermore, our system enables a user to seamlessly crossfade between various interpretations belonging to the currently selected musical work."
            },
            "slug": "Multimodal-presentation-and-browsing-of-music-Damm-Fremerey",
            "title": {
                "fragments": [],
                "text": "Multimodal presentation and browsing of music"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper presents a multimodal music player for presenting and browsing digitized music collections consisting of heterogeneous document types, focusing on music documents of two widely used types for representing a musical work, namely visual music representation and associated interpretations."
            },
            "venue": {
                "fragments": [],
                "text": "ICMI '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31552046"
                        ],
                        "name": "K. MacMillan",
                        "slug": "K.-MacMillan",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "MacMillan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. MacMillan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2571259"
                        ],
                        "name": "M. Droettboom",
                        "slug": "M.-Droettboom",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Droettboom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Droettboom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190426"
                        ],
                        "name": "Ichiro Fujinaga",
                        "slug": "Ichiro-Fujinaga",
                        "structuredName": {
                            "firstName": "Ichiro",
                            "lastName": "Fujinaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ichiro Fujinaga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[59] adopted a learning-based approach in which the process im-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15544361,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e04dde1eeb034e8a543c5b8985e2f0221388f633",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "An optical music recognition system has been completely overhauled and reformatted into a new framework called Gamera. The new open-source software is not only designed to recognize various music notations, including handwritten scores, but can be used to develop systems that can recognize many other structured documents. Gamera is intended to be used by domain experts with particular knowledge of the documents to be recognized but without strong programming skills. Gamera contains image processing and recognition tools in an easy-to-use, interactive, graphical scripting environment. Additionally, the system can be extended through a C++ and Python plugins."
            },
            "slug": "Gamera:-Optical-music-recognition-in-a-new-shell-MacMillan-Droettboom",
            "title": {
                "fragments": [],
                "text": "Gamera: Optical music recognition in a new shell"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "An optical music recognition system has been completely overhauled and reformatted into a new framework called Gamera, designed to recognize various music notations, including handwritten scores, but can be used to develop systems that can recognize many other structured documents."
            },
            "venue": {
                "fragments": [],
                "text": "ICMC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271448"
                        ],
                        "name": "M. Szwoch",
                        "slug": "M.-Szwoch",
                        "structuredName": {
                            "firstName": "Mariusz",
                            "lastName": "Szwoch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Szwoch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 67
                            }
                        ],
                        "text": "Other resolutions were also considered: 600 dpi [56,87] or 400 dpi [76,96]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 20
                            }
                        ],
                        "text": "work carried out by [36,37,96] applied this technique to their OMR procedures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11942400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5eaaee68d0a4b01eeed884d00a58d8064c17ff4e",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an optical music recognition system Guido that can automatically recognize the main musical symbols of music scores that were scanned or taken by a digital camera. The application is based on object model of musical notation and uses linguistic approach for symbol interpretation and error correction. The system offers musical editor with a partially automatic error correction."
            },
            "slug": "Guido:-A-Musical-Score-Recognition-System-Szwoch",
            "title": {
                "fragments": [],
                "text": "Guido: A Musical Score Recognition System"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "An optical music recognition system Guido that can automatically recognize the main musical symbols of music scores that were scanned or taken by a digital camera is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2062664741"
                        ],
                        "name": "Telmo Pinto",
                        "slug": "Telmo-Pinto",
                        "structuredName": {
                            "firstName": "Telmo",
                            "lastName": "Pinto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Telmo Pinto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143616982"
                        ],
                        "name": "Ana Rebelo",
                        "slug": "Ana-Rebelo",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Rebelo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana Rebelo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688283"
                        ],
                        "name": "G. Giraldi",
                        "slug": "G.-Giraldi",
                        "structuredName": {
                            "firstName": "Gilson",
                            "lastName": "Giraldi",
                            "middleNames": [
                                "Antonio"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Giraldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3698192"
                        ],
                        "name": "Jaime S. Cardoso",
                        "slug": "Jaime-S.-Cardoso",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Cardoso",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaime S. Cardoso"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9371663,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a556c9bf0a2ada914015c03f77645923883fd83",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Image binarization is a common operation in the preprocessing stage in most Optical Music Recognition (OMR) systems. The choice of an appropriate binarization method for handwritten music scores is a difficult problem. Several works have already evaluated the performance of existing binarization processes in diverse applications. However, no goal-directed studies for music sheets documents were carried out. This paper presents a novel binarization method based in the content knowledge of the image. The method only needs the estimation of the staffline thickness and the vertical distance between two stafflines. This information is extracted directly from the gray level music score. The proposed binarization procedure is experimentally compared with several state of the art methods."
            },
            "slug": "Music-Score-Binarization-Based-on-Domain-Knowledge-Pinto-Rebelo",
            "title": {
                "fragments": [],
                "text": "Music Score Binarization Based on Domain Knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel binarization method based in the content knowledge of the image that only needs the estimation of the staffline thickness and the vertical distance between two stafflines to be implemented."
            },
            "venue": {
                "fragments": [],
                "text": "IbPRIA"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748249"
                        ],
                        "name": "I. Pratikakis",
                        "slug": "I.-Pratikakis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Pratikakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pratikakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2397702"
                        ],
                        "name": "S. Perantonis",
                        "slug": "S.-Perantonis",
                        "structuredName": {
                            "firstName": "Stavros",
                            "lastName": "Perantonis",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Perantonis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14839079,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15ea3d60d6cf29dfcf39836604b809cf52dbc91e",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Historical document collections are a valuable resource for human history. This paper proposes a novel digital image binarization scheme for low quality historical documents allowing further content exploitation in an efficient way. The proposed scheme consists of five distinct steps: a pre-processing procedure using a low-pass Wiener filter, a rough estimation of foreground regions using Niblack\u2019s approach, a background surface calculation by interpolating neighboring background intensities, a thresholding by combining the calculated background surface with the original image and finally a post-processing step in order to improve the quality of text regions and preserve stroke connectivity. The proposed methodology works with great success even in cases of historical manuscripts with poor quality, shadows, nonuniform illumination, low contrast, large signal- dependent noise, smear and strain. After testing the proposed method on numerous low quality historical manuscripts, it has turned out that our methodology performs better compared to current state-of-the-art adaptive thresholding techniques."
            },
            "slug": "An-Adaptive-Binarization-Technique-for-Low-Quality-Gatos-Pratikakis",
            "title": {
                "fragments": [],
                "text": "An Adaptive Binarization Technique for Low Quality Historical Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A novel digital image binarization scheme for low quality historical documents allowing further content exploitation in an efficient way and performs better compared to current state-of-the-art adaptive thresholding techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2051796"
                        ],
                        "name": "W. Homenda",
                        "slug": "W.-Homenda",
                        "structuredName": {
                            "firstName": "Wladyslaw",
                            "lastName": "Homenda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Homenda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12966003,
            "fieldsOfStudy": [
                "Art",
                "Computer Science"
            ],
            "id": "f5657c1226a516382878f8ffbfaa6eefe398d931",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents a pattern recognition study aimed on music notation recognition. The study is focused on practical aspect of optical music recognition; it presents a variety of methods applied in optical music recognition technology. The following logically separated stages of music notation recognition are distinguished: acquiring music notation structure, recognizing symbols of music notation, analyzing contextual information. The directions for OMR package development are drawn."
            },
            "slug": "Optical-Music-Recognition:-the-Case-Study-of-Homenda",
            "title": {
                "fragments": [],
                "text": "Optical Music Recognition: the Case Study of Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The paper presents a pattern recognition study aimed on music notation recognition that presents a variety of methods applied in optical music recognition technology and the directions for OMR package development are drawn."
            },
            "venue": {
                "fragments": [],
                "text": "CORES"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2051796"
                        ],
                        "name": "W. Homenda",
                        "slug": "W.-Homenda",
                        "structuredName": {
                            "firstName": "Wladyslaw",
                            "lastName": "Homenda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Homenda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764585"
                        ],
                        "name": "Marcin Luckner",
                        "slug": "Marcin-Luckner",
                        "structuredName": {
                            "firstName": "Marcin",
                            "lastName": "Luckner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcin Luckner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9324631,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23ed56989af4d7aac2cb5302906cac7a270c78bf",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a pattern recognition study aimed al music symbols recognition. The study is focused on classification methods of music symbols based on decision trees and clustering method applied to classes of music symbols that face classification problems. Classification is made on the basis of extracted features. A comparison of selected classifiers was made on some classes of nutation symbols distorted by a variety of factors as image noise, printing defects, different fonts, skew and curvature of scanning, overlapped symbols."
            },
            "slug": "Automatic-Knowledge-Acquisition:-Recognizing-Music-Homenda-Luckner",
            "title": {
                "fragments": [],
                "text": "Automatic Knowledge Acquisition: Recognizing Music Notation with Methods of Centroids and Classifications Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A comparison of selected classifiers was made on some classes of nutation symbols distorted by a variety of factors as image noise, printing defects, different fonts, skew and curvature of scanning, overlapped symbols."
            },
            "venue": {
                "fragments": [],
                "text": "The 2006 IEEE International Joint Conference on Neural Network Proceedings"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144404828"
                        ],
                        "name": "K. Reed",
                        "slug": "K.-Reed",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Reed",
                            "middleNames": [
                                "Todd"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Reed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723479"
                        ],
                        "name": "J. Parker",
                        "slug": "J.-Parker",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Parker",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Parker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "Other techniques for finding staff lines include the grouping of vertical columns based on their spacing, thickness, and vertical position on the image [85], rule-based classification of thin horizontal line segments [60], and line tracing [73,88,98]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [85] the segmentation process involves three stages: line and curves detection by LAGs,"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Reed and Parker [85] also uses LAGs to detect lines and curves."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27433817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc2878da3257677d174919ede5bfa3d41f71c3ae",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper provides an overview to the implementation of Lemon, a complete optical music recognition system. Among the techniques employed by the implementation are: template matching, the Hough transform, line adjacency graphs, character profiles, and graph grammars. Experimental results, including comparisons with commercial systems, are provided."
            },
            "slug": "Automatic-computer-recognition-of-printed-music-Reed-Parker",
            "title": {
                "fragments": [],
                "text": "Automatic computer recognition of printed music"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "An overview to the implementation of Lemon, a complete optical music recognition system, among the techniques employed are: template matching, the Hough transform, line adjacency graphs, character profiles, and graph grammars."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745606"
                        ],
                        "name": "A. Khashman",
                        "slug": "A.-Khashman",
                        "structuredName": {
                            "firstName": "Adnan",
                            "lastName": "Khashman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Khashman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3220828"
                        ],
                        "name": "B. \u015eekero\u011flu",
                        "slug": "B.-\u015eekero\u011flu",
                        "structuredName": {
                            "firstName": "Boran",
                            "lastName": "\u015eekero\u011flu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. \u015eekero\u011flu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "Sezan [91], Tsai [103], Khashman and Sekeroglu [54] ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7569110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fbd156d3987e692e30538bc69e0d71c3a5dff3",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Many thresholding-based image enhancement techniques have been developed and used for document analysis, where the simplicity and efficiency of thresholding makes it ideal to use for classifying layers within documents. However, the efficiency of these enhancement techniques can be impaired by the variation of grey levels in different documents, thus causing over-thresholding or under-thresholding. This paper presents a novel global singlestage thresholding method for separating background and foreground layers in text documents. The method finds an optimum thresholding value or exact separation point for each document using the relationship between luminance value and mean intensity of the document without considering peak values in the grey level histogram. The proposed method is implemented using 50 historical documents and five specifically designed words, and then compared to three other efficient and known thresholding methods. Experimental results suggest that the proposed method performs well for text separation and enhancement of document images."
            },
            "slug": "A-Novel-Thresholding-Method-for-Text-Separation-and-Khashman-\u015eekero\u011flu",
            "title": {
                "fragments": [],
                "text": "A Novel Thresholding Method for Text Separation and Document Enhancement"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel global singlestage thresholding method for separating background and foreground layers in text documents using the relationship between luminance value and mean intensity of the document without considering peak values in the grey level histogram is presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271448"
                        ],
                        "name": "M. Szwoch",
                        "slug": "M.-Szwoch",
                        "structuredName": {
                            "firstName": "Mariusz",
                            "lastName": "Szwoch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Szwoch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 24
                            }
                        ],
                        "text": "The methods proposed in [63, 95] operate on a set of staff segments, with methods for linking two segments horizontally and vertically and merging two overlapped segments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 41
                            }
                        ],
                        "text": "[26] is an improvement on the methods of [63, 95]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 38
                            }
                        ],
                        "text": "\u2013 Methods for linking staff segments: [63, 95, 32]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 26258353,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a206cdfade70da6888931f51ae5820f887470fb3",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper an algorithm for music staves detection is presented. The algorithm bases on horizontal projections in local windows of a score image and farther processing of resulting histograms and their connections. Experiments carried out, proved high efficiency of presented algorithm and its robustness in case of non-ideal staff lines: skew and with barrel and pincushion distortions. The algorithm allows for usage of acquisition devices alternative to scanner such as digital cameras."
            },
            "slug": "A-Robust-Detector-for-Distorted-Music-Staves-Szwoch",
            "title": {
                "fragments": [],
                "text": "A Robust Detector for Distorted Music Staves"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The algorithm allows for usage of acquisition devices alternative to scanner such as digital cameras and its robustness in case of non-ideal staff lines: skew and with barrel and pincushion distortions is proved."
            },
            "venue": {
                "fragments": [],
                "text": "CAIP"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2571259"
                        ],
                        "name": "M. Droettboom",
                        "slug": "M.-Droettboom",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Droettboom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Droettboom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190426"
                        ],
                        "name": "Ichiro Fujinaga",
                        "slug": "Ichiro-Fujinaga",
                        "structuredName": {
                            "firstName": "Ichiro",
                            "lastName": "Fujinaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ichiro Fujinaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31552046"
                        ],
                        "name": "K. MacMillan",
                        "slug": "K.-MacMillan",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "MacMillan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. MacMillan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2013 Fusion of musical rules and heuristics: [28], [68], [31], [89]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[66, 85, 62, 20, 31, 45, 83, 98])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2013 MIDI: [68, 33, 31, 64, 43, 20, 98]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2013 GUIDO: [31, 96, 20]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1675881,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "d915c9eca7ad93c38a2ac0d795e1faba270fd9ad",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A system to convert digitized sheet music into a symbolic music representation is presented. A pragmatic approach is used that conceptualizes this primarily two-dimensional structural recognition problem as a one-dimensional one. The transparency of the implementation owes a great deal to its implementation in a dynamic, object-oriented language. This systemis a part of a locally developed end-to-end solution for the conversion of digitized sheet music into symbolic form."
            },
            "slug": "Optical-Music-Interpretation-Droettboom-Fujinaga",
            "title": {
                "fragments": [],
                "text": "Optical Music Interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A system to convert digitized sheet music into a symbolic music representation is presented that conceptualizes this primarily two-dimensional structural recognition problem as a one-dimensional one."
            },
            "venue": {
                "fragments": [],
                "text": "SSPR/SPR"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258400"
                        ],
                        "name": "\u00d8. Trier",
                        "slug": "\u00d8.-Trier",
                        "structuredName": {
                            "firstName": "\u00d8ivind",
                            "lastName": "Trier",
                            "middleNames": [
                                "Due"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00d8. Trier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 13
                            }
                        ],
                        "text": "According to [101, 102], Otsu\u2019s procedure is ranked as the best and the fastest of these methods [70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15780310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3a74fe4e79add9de4803a825b6eae013215dfe7",
            "isKey": false,
            "numCitedBy": 731,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a methodology for evaluation of low-level image analysis methods, using binarization (two-level thresholding) as an example. Binarization of scanned gray scale images is the first step in most document image analysis systems. Selection of an appropriate binarization method for an input image domain is a difficult problem. Typically, a human expert evaluates the binarized images according to his/her visual criteria. However, to conduct an objective evaluation, one needs to investigate how well the subsequent image analysis steps will perform on the binarized image. We call this approach goal-directed evaluation, and it can be used to evaluate other low-level image processing methods as well. Our evaluation of binarization methods is in the context of digit recognition, so we define the performance of the character recognition module as the objective measure. Eleven different locally adaptive binarization methods were evaluated, and Niblack's method gave the best performance."
            },
            "slug": "Goal-Directed-Evaluation-of-Binarization-Methods-Trier-Jain",
            "title": {
                "fragments": [],
                "text": "Goal-Directed Evaluation of Binarization Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper presents a methodology for evaluation of low-level image analysis methods, using binarization (two-level thresholding) as an example, and defines the performance of the character recognition module as the objective measure."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190426"
                        ],
                        "name": "Ichiro Fujinaga",
                        "slug": "Ichiro-Fujinaga",
                        "structuredName": {
                            "firstName": "Ichiro",
                            "lastName": "Fujinaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ichiro Fujinaga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 7
                            }
                        ],
                        "text": "One of Fujinaga\u2019s first works focused on the characterization of music notation by means of a context-free and L L(k) grammar."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "Fujinaga [41] incorporates a set of image processing techniques in the algorithm, including run-length coding (RLC), connected-component analysis, and projections."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "The same idea of active learning was suggested by Fujinaga [40] in which a method to"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 50
                            }
                        ],
                        "text": "The same idea of active learning was suggested by Fujinaga [40] in which a method to learn new music symbols and handwritten music notations based on the combination of a k-nearest neighbor classifier with a genetic algorithm was proposed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 254
                            }
                        ],
                        "text": "A. Rebelo (B) \u00b7 F. Paszkiewicz \u00b7 C. Guedes \u00b7 J. S. Cardoso FEUP, INESC Porto, Porto, Portugal e-mail: arebelo@inescporto.pt\nF. Paszkiewicz e-mail: filipe.asp@gmail.com\nC. Guedes e-mail: carlosguedes@mac.com\nJ. S. Cardoso e-mail: jaime.cardoso@inescporto.pt\nI. Fujinaga Schulich School of Music, McGill University, Montreal, Canada e-mail: ich@music.mcgill.ca\nA. R. S. Marcal FCUP, CICGE, Porto, Portugal e-mail: andre.marcal@fc.up.pt\npresents a reference scheme for any researcher wanting to compare new OMR algorithms against well-known ones."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14342115,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c8ff8d7dbbc922716df351f73ff4658ca7ae149",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The learning process of an adaptive optical music recognition system (AOMR) is described here. By combining k-nearest neighbor classifier and genetic algorithm, the system can learn to recognize new music symbols and handwritten music notations, and it also continually improves the accuracy in recognizing these objects. Given the wide range of music notation styles, these are essential characteristics of a music recognizer."
            },
            "slug": "Exemplar-based-Learning-in-Adaptive-Optical-Music-Fujinaga",
            "title": {
                "fragments": [],
                "text": "Exemplar-based Learning in Adaptive Optical Music Recognition System"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "The learning process of an adaptive optical music recognition system (AOMR) is described here, by combining k-nearest neighbor classifier and genetic algorithm, which can learn to recognize new music symbols and handwritten music notations and continually improves the accuracy in recognizing these objects."
            },
            "venue": {
                "fragments": [],
                "text": "ICMC"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271448"
                        ],
                        "name": "M. Szwoch",
                        "slug": "M.-Szwoch",
                        "structuredName": {
                            "firstName": "Mariusz",
                            "lastName": "Szwoch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Szwoch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2127740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78c934ff450f46d432573b5cb6891811501afc76",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a methodology for automatic accuracy evaluation in optical music recognition (OMR) applications is proposed. Presented approach assumes using ground truth images together with digital music scores describing their content. The automatic evaluation algorithm measures differences between the tested score and the reference one, both stored in MusicXML format. Some preliminary test results of this approach are presented based on the algorithm's implementation in OMR Guido application."
            },
            "slug": "Using-MusicXML-to-Evaluate-Accuracy-of-OMR-Systems-Szwoch",
            "title": {
                "fragments": [],
                "text": "Using MusicXML to Evaluate Accuracy of OMR Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A methodology for automatic accuracy evaluation in optical music recognition (OMR) applications is proposed using ground truth images together with digital music scores describing their content stored in MusicXML format."
            },
            "venue": {
                "fragments": [],
                "text": "Diagrams"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745606"
                        ],
                        "name": "A. Khashman",
                        "slug": "A.-Khashman",
                        "structuredName": {
                            "firstName": "Adnan",
                            "lastName": "Khashman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Khashman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3220828"
                        ],
                        "name": "B. \u015eekero\u011flu",
                        "slug": "B.-\u015eekero\u011flu",
                        "structuredName": {
                            "firstName": "Boran",
                            "lastName": "\u015eekero\u011flu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. \u015eekero\u011flu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23591492,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d4f6699d0a8b7e4e02c0df6db98a66cf9ac6280",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Thresholding is a simple and efficient method for image enhancement and segmentation of grayscale documents, where the relationship of pixel values in the documents can provide an effective single point for the separation of the background and foreground layers. Document analysis and effective separation of text may provide useful data for electronic storage systems and libraries. This paper presents a novel method namely, mass-difference thresholding (MDTh) for enhancement and text separation from documents. MDTh will be implemented using 30 documents that have various levels of noise and color. A comparison will be drawn between MDTh and five other well known and efficient thresholding methods. Experimental results suggest that the developed method performs well, thus providing a fast and efficient method for text separation."
            },
            "slug": "Novel-Thresholding-Method-for-Document-Analysis-Khashman-\u015eekero\u011flu",
            "title": {
                "fragments": [],
                "text": "Novel Thresholding Method for Document Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experimental results suggest that the developed method performs well, thus providing a fast and efficient method for text separation, and a comparison will be drawn between MDTh and five other well known and efficient thresholding methods."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE International Conference on Industrial Technology"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711390"
                        ],
                        "name": "G. Leedham",
                        "slug": "G.-Leedham",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Leedham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Leedham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144284504"
                        ],
                        "name": "Yan Chen",
                        "slug": "Yan-Chen",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1845280"
                        ],
                        "name": "Kalyan Takru",
                        "slug": "Kalyan-Takru",
                        "structuredName": {
                            "firstName": "Kalyan",
                            "lastName": "Takru",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kalyan Takru"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1944319"
                        ],
                        "name": "Joie Hadi Nata Tan",
                        "slug": "Joie-Hadi-Nata-Tan",
                        "structuredName": {
                            "firstName": "Joie",
                            "lastName": "Tan",
                            "middleNames": [
                                "Hadi",
                                "Nata"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joie Hadi Nata Tan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066299019"
                        ],
                        "name": "Li Mian",
                        "slug": "Li-Mian",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Mian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Mian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14211788,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0074008a56670885076d51b5b75335981c89f548",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of techniques have previously been proposedfor effective thresholding of document images. In this papertwo new thresholding techniques are proposed andcompared against some existing algorithms.The algorithms were evaluated on four types ofdifficult' document images where considerablebackground noise or variation in contrast and illuminationexists. The quality of the thresholding was assessed usingthe Precision and Recall analysis of the resultant words inthe foreground.The conclusion is that no single algorithm works well forall types of image but some work better than others forparticular types of images suggesting that improvedperformance can be obtained by automatic selection orcombination of appropriate algorithm(s) for the type ofdocument image under investigation."
            },
            "slug": "Comparison-of-some-thresholding-algorithms-for-in-Leedham-Chen",
            "title": {
                "fragments": [],
                "text": "Comparison of some thresholding algorithms for text/background segmentation in difficult document images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "No single algorithm works well for all types of image but some work better than others for particular types of images suggesting that improved performance can be obtained by automatic selection or combination of appropriate algorithm(s) for the type of document image under investigation."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103271"
                        ],
                        "name": "C. Dalitz",
                        "slug": "C.-Dalitz",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Dalitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Dalitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2571259"
                        ],
                        "name": "M. Droettboom",
                        "slug": "M.-Droettboom",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Droettboom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Droettboom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3273120"
                        ],
                        "name": "B. Pranzas",
                        "slug": "B.-Pranzas",
                        "structuredName": {
                            "firstName": "Bastian",
                            "lastName": "Pranzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Pranzas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190426"
                        ],
                        "name": "Ichiro Fujinaga",
                        "slug": "Ichiro-Fujinaga",
                        "structuredName": {
                            "firstName": "Ichiro",
                            "lastName": "Fujinaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ichiro Fujinaga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12541342,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8b897895e0727defd091ba744b104fb04f8d52d",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a quantitative comparison of different algorithms for the removal of stafflines from music images. It contains a survey of previously proposed algorithms and suggests a new skeletonization-based approach. We define three different error metrics, compare the algorithms with respect to these metrics, and measure their robustness with respect to certain image defects. Our test images are computer-generated scores on which we apply various image deformations typically found in real-world data. In addition to modern western music notation, our test set also includes historic music notation such as mensural notation and lute tablature. Our general approach and evaluation methodology is not specific to staff removal but applicable to other segmentation problems as well."
            },
            "slug": "A-Comparative-Study-of-Staff-Removal-Algorithms-Dalitz-Droettboom",
            "title": {
                "fragments": [],
                "text": "A Comparative Study of Staff Removal Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A quantitative comparison of different algorithms for the removal of stafflines from music images is presented and a new skeletonization-based approach is suggested."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143655949"
                        ],
                        "name": "M. Albuquerque",
                        "slug": "M.-Albuquerque",
                        "structuredName": {
                            "firstName": "Marcelo",
                            "lastName": "Albuquerque",
                            "middleNames": [
                                "Portes",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Albuquerque"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145327322"
                        ],
                        "name": "I. Esquef",
                        "slug": "I.-Esquef",
                        "structuredName": {
                            "firstName": "Israel",
                            "lastName": "Esquef",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Esquef"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829806"
                        ],
                        "name": "Aline da Rocha Gesualdi",
                        "slug": "Aline-da-Rocha-Gesualdi",
                        "structuredName": {
                            "firstName": "Aline",
                            "lastName": "Gesualdi",
                            "middleNames": [
                                "da",
                                "Rocha"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aline da Rocha Gesualdi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3141932"
                        ],
                        "name": "M. Albuquerque",
                        "slug": "M.-Albuquerque",
                        "structuredName": {
                            "firstName": "M\u00e1rcio",
                            "lastName": "Albuquerque",
                            "middleNames": [
                                "Portes",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Albuquerque"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11451263,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "330405a99574c0cbd7e09d24de1353315788689b",
            "isKey": false,
            "numCitedBy": 459,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-thresholding-using-Tsallis-entropy-Albuquerque-Esquef",
            "title": {
                "fragments": [],
                "text": "Image thresholding using Tsallis entropy"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3126026"
                        ],
                        "name": "I. Leplumey",
                        "slug": "I.-Leplumey",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Leplumey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Leplumey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760753"
                        ],
                        "name": "J. Camillerapp",
                        "slug": "J.-Camillerapp",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Camillerapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Camillerapp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2915873"
                        ],
                        "name": "G. Lorette",
                        "slug": "G.-Lorette",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Lorette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lorette"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "The dash detector [57] is one of a few works that try to handle discontinuities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26129516,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "73dbace1ca1789f6b3dd0b1ca9ff5533355de276",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for the automatic recognition of music staves based on a prediction-and-check technique is presented in order to extract staves. It can detect lines with some curvature, discontinuities, and inclination. Lines are asserted to be a part of a staff if they can be grouped by five, thus completing the staff. This last phase also identifies additional staff lines.<<ETX>>"
            },
            "slug": "A-robust-detector-for-music-staves-Leplumey-Camillerapp",
            "title": {
                "fragments": [],
                "text": "A robust detector for music staves"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "A method for the automatic recognition of music staves based on a prediction-and-check technique is presented in order to extract staves that can detect lines with some curvature, discontinuities, and inclination."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2850022"
                        ],
                        "name": "M. Sezgin",
                        "slug": "M.-Sezgin",
                        "structuredName": {
                            "firstName": "Mehmet",
                            "lastName": "Sezgin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sezgin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145940271"
                        ],
                        "name": "B. Sankur",
                        "slug": "B.-Sankur",
                        "structuredName": {
                            "firstName": "B\u00fclent",
                            "lastName": "Sankur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sankur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8953108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4dafbbc0cd8eb3e9967dd6b8bfce216a4dd3c1fc",
            "isKey": false,
            "numCitedBy": 4553,
            "numCiting": 247,
            "paperAbstract": {
                "fragments": [],
                "text": "We conduct an exhaustive survey of image thresholding methods, categorize them, express their formulas under a uniform notation, and finally carry their performance comparison. The thresholding methods are categorized according to the information they are exploiting, such as histogram shape, measurement space clustering, entropy, object attributes, spatial correlation, and local gray-level surface. 40 selected thresholding methods from various categories are compared in the context of nondestructive testing applications as well as for document images. The comparison is based on the combined performance measures. We identify the thresholding algorithms that perform uniformly better over nonde- structive testing and document image applications. \u00a9 2004 SPIE and IS&T. (DOI: 10.1117/1.1631316)"
            },
            "slug": "Survey-over-image-thresholding-techniques-and-Sezgin-Sankur",
            "title": {
                "fragments": [],
                "text": "Survey over image thresholding techniques and quantitative performance evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "40 selected thresholding methods from various categories are compared in the context of nondestructive testing applications as well as for document images, and the thresholding algorithms that perform uniformly better over nonde- structive testing and document image applications are identified."
            },
            "venue": {
                "fragments": [],
                "text": "J. Electronic Imaging"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141915"
                        ],
                        "name": "W. Niblack",
                        "slug": "W.-Niblack",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Niblack",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Niblack"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 32
                            }
                        ],
                        "text": "One of the most used methods is Niblack [69]\u2019s method which uses the mean and the standard deviation of the pixel\u2019s vicinity as local information for the threshold decision."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "most used method is Niblack [69]\u2019s method which uses the mean and the standard deviation of the pixel\u2019s vicinity as local information for the threshold decision."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "Niblack [69], Bernsen [8], Yanowitz and Bruckstein [104], ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60929037,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "43678765df1d0b4594f7a49298cf27d75e174787",
            "isKey": false,
            "numCitedBy": 1417,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-introduction-to-digital-image-processing-Niblack",
            "title": {
                "fragments": [],
                "text": "An introduction to digital image processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703931"
                        ],
                        "name": "D. Blostein",
                        "slug": "D.-Blostein",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Blostein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blostein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22281073,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "b2a55ca84f5985c7b602e46a8ec54208573c31ae",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The research literature concerning the automatic analysis of images of printed and handwritten music notation, for the period 1966 through 1990, is surveyed and critically examined."
            },
            "slug": "A-Critical-Survey-of-Music-Image-Analysis-Blostein-Baird",
            "title": {
                "fragments": [],
                "text": "A Critical Survey of Music Image Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The research literature concerning the automatic analysis of images of printed and handwritten music notation, for the period 1966 through 1990, is surveyed and critically examined."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47679004"
                        ],
                        "name": "A. Brink",
                        "slug": "A.-Brink",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Brink",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Brink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319463"
                        ],
                        "name": "N. Pendock",
                        "slug": "N.-Pendock",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Pendock",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Pendock"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "The best result was obtained with the Brink and Pendock [10]\u2019s method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33959709,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b3c8b0e4947a7cc706b1d267ce94af0c1eb7423",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Minimum-cross-entropy-threshold-selection-Brink-Pendock",
            "title": {
                "fragments": [],
                "text": "Minimum cross-entropy threshold selection"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69508860"
                        ],
                        "name": "J. N. Kapur",
                        "slug": "J.-N.-Kapur",
                        "structuredName": {
                            "firstName": "Jagat",
                            "lastName": "Kapur",
                            "middleNames": [
                                "Narain"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. N. Kapur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783015"
                        ],
                        "name": "P. Sahoo",
                        "slug": "P.-Sahoo",
                        "structuredName": {
                            "firstName": "Prasanna",
                            "lastName": "Sahoo",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sahoo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144821969"
                        ],
                        "name": "A. Wong",
                        "slug": "A.-Wong",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Wong",
                            "middleNames": [
                                "K.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[52], Sahoo et al."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13800606,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af7dcf5e823f6e1eaa4aff2afa2912585ea32147",
            "isKey": false,
            "numCitedBy": 3339,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-new-method-for-gray-level-picture-thresholding-of-Kapur-Sahoo",
            "title": {
                "fragments": [],
                "text": "A new method for gray-level picture thresholding using the entropy of the histogram"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1906633"
                        ],
                        "name": "Liang-Kai Huang",
                        "slug": "Liang-Kai-Huang",
                        "structuredName": {
                            "firstName": "Liang-Kai",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang-Kai Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150237483"
                        ],
                        "name": "Mao-Jiun J. Wang",
                        "slug": "Mao-Jiun-J.-Wang",
                        "structuredName": {
                            "firstName": "Mao-Jiun",
                            "lastName": "Wang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mao-Jiun J. Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[19], Huang and Wang [49], ."
                    },
                    "intents": []
                }
            ],
            "corpusId": 205014794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "890664d6e7861253bd8c36d0e9079f96c9f22d67",
            "isKey": false,
            "numCitedBy": 853,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-thresholding-by-minimizing-the-measures-of-Huang-Wang",
            "title": {
                "fragments": [],
                "text": "Image thresholding by minimizing the measures of fuzzines"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9403171"
                        ],
                        "name": "W. Guitang",
                        "slug": "W.-Guitang",
                        "structuredName": {
                            "firstName": "Wang",
                            "lastName": "Guitang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Guitang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3196146"
                        ],
                        "name": "Zhu Jianlin",
                        "slug": "Zhu-Jianlin",
                        "structuredName": {
                            "firstName": "Zhu",
                            "lastName": "Jianlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhu Jianlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80587072"
                        ],
                        "name": "Wei Qingchun",
                        "slug": "Wei-Qingchun",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Qingchun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Qingchun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9289135"
                        ],
                        "name": "Xin Huasheng",
                        "slug": "Xin-Huasheng",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Huasheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xin Huasheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9328238"
                        ],
                        "name": "Cao Peiliang",
                        "slug": "Cao-Peiliang",
                        "structuredName": {
                            "firstName": "Cao",
                            "lastName": "Peiliang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cao Peiliang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 51
                            }
                        ],
                        "text": "Niblack [69], Bernsen [8], Yanowitz and Bruckstein [104], ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17504378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbc6228618ea4d1e0728433fbac8ae949790449a",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "On the basis of analyzing the blur images with noise, this paper presents a new segmentation method which is based on the morphology method, fuzzy K-means algorithm and some parts operator of the Canny algorithm. Because of the Canny's good performance on good detection, good localization and only one response to a single edge, we introduce the course of Canny operator that calculating the value and direction of grads, non-maxima suppression to the grad value and lag threshold process into our post-treatment process. Through experiments, it is demonstrated that the image segmentation method in this paper is very effective."
            },
            "slug": "A-new-method-for-image-segmentation-Guitang-Jianlin",
            "title": {
                "fragments": [],
                "text": "A new method for image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A new segmentation method which is based on the morphology method, fuzzy K-means algorithm and some parts operator of the Canny algorithm, and the course of Canny operator that calculating the value and direction of grads, non-maxima suppression to the grad value and lag threshold process into the post-treatment process is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "2009 Asia-Pacific Conference on Computational Intelligence and Industrial Applications (PACIIA)"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783015"
                        ],
                        "name": "P. Sahoo",
                        "slug": "P.-Sahoo",
                        "structuredName": {
                            "firstName": "Prasanna",
                            "lastName": "Sahoo",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sahoo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153151572"
                        ],
                        "name": "Carrye Wilkins",
                        "slug": "Carrye-Wilkins",
                        "structuredName": {
                            "firstName": "Carrye",
                            "lastName": "Wilkins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carrye Wilkins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073634659"
                        ],
                        "name": "Jerry Yeager",
                        "slug": "Jerry-Yeager",
                        "structuredName": {
                            "firstName": "Jerry",
                            "lastName": "Yeager",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jerry Yeager"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[90], de Albuquerque et al."
                    },
                    "intents": []
                }
            ],
            "corpusId": 27743655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53e4349b6e585426389059c5107a366b8873eb67",
            "isKey": false,
            "numCitedBy": 388,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Threshold-selection-using-Renyi's-entropy-Sahoo-Wilkins",
            "title": {
                "fragments": [],
                "text": "Threshold selection using Renyi's entropy"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103271"
                        ],
                        "name": "C. Dalitz",
                        "slug": "C.-Dalitz",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Dalitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Dalitz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17508606,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15cb4f35b2196127ea4fc11c679953d92e987dec",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This survey summarizes proposals made in the pattern recognition literature for detecting uncertain patterns that should rather be rejected than classified by a classifier. Beyond reviewing methods applicable to distance based nearest neighbor classifiers, this article describes an interface for computing confidences, storing them with classified images and querying this information, as it is implemented in the Gamera framework for document analysis and recognition. Based on this interface, a method for detecting broken, touching, and unknown characters, as well as noise, is proposed. The method is applied to two historic prints, showing that this method works well for detecting broken and touching characters, but less reliable for identifying glyphs representing noise."
            },
            "slug": "Reject-Options-and-Confidence-Measures-for-kNN-Dalitz",
            "title": {
                "fragments": [],
                "text": "Reject Options and Confidence Measures for kNN Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An interface for computing confidences, storing them with classified images and querying this information, as it is implemented in the Gamera framework for document analysis and recognition is described, with a method for detecting broken, touching, and unknown characters, as well as noise."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145398051"
                        ],
                        "name": "N. Venkateswarlu",
                        "slug": "N.-Venkateswarlu",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Venkateswarlu",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Venkateswarlu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31760287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f19de32169e188eb83d7622772a9f644872b1fc7",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Implementation-of-some-image-thresholding-on-a-Venkateswarlu",
            "title": {
                "fragments": [],
                "text": "Implementation of some image thresholding algorithms on a connection machine-200"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157954135"
                        ],
                        "name": "Qiang Chen",
                        "slug": "Qiang-Chen",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31085136"
                        ],
                        "name": "Quansen Sun",
                        "slug": "Quansen-Sun",
                        "structuredName": {
                            "firstName": "Quansen",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quansen Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714602"
                        ],
                        "name": "P. Heng",
                        "slug": "P.-Heng",
                        "structuredName": {
                            "firstName": "Pheng-Ann",
                            "lastName": "Heng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Heng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2172868"
                        ],
                        "name": "D. Xia",
                        "slug": "D.-Xia",
                        "structuredName": {
                            "firstName": "Deshen",
                            "lastName": "Xia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Xia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5503952,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "045d5dbd00abf1a8f103083bdfc0e9a223c72fa0",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-double-threshold-image-binarization-method-based-Chen-Sun",
            "title": {
                "fragments": [],
                "text": "A double-threshold image binarization method based on edge detector"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5208597"
                        ],
                        "name": "M. Sezan",
                        "slug": "M.-Sezan",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Sezan",
                            "middleNames": [
                                "Ibrahim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sezan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 205114115,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8cb5fafb618f01911b5fad271daf45fe0fbf5d2",
            "isKey": false,
            "numCitedBy": 221,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Peak-Detection-Algorithm-and-its-Application-to-Sezan",
            "title": {
                "fragments": [],
                "text": "A Peak Detection Algorithm and its Application to Histogram-Based Image Data Reduction"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725624"
                        ],
                        "name": "D. Tsai",
                        "slug": "D.-Tsai",
                        "structuredName": {
                            "firstName": "Du-ming",
                            "lastName": "Tsai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tsai"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Histogram analysis Sezan [91], Tsai [103], Khashman and Sekeroglu [54] ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33176548,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bffb953d38bbdfb3551eab58113279d310310e93",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-fast-thresholding-selection-procedure-for-and-Tsai",
            "title": {
                "fragments": [],
                "text": "A fast thresholding selection procedure for multimodal and unimodal histograms"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809629"
                        ],
                        "name": "N. Otsu",
                        "slug": "N.-Otsu",
                        "structuredName": {
                            "firstName": "Nobuyuki",
                            "lastName": "Otsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Otsu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "According to [101, 102], Otsu\u2019s procedure is ranked as the best and the fastest of these methods [70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15326934,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "1d4816c612e38dac86f2149af667a5581686cdef",
            "isKey": false,
            "numCitedBy": 32882,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A nonparametric and unsupervised method ofautomatic threshold selection for picture segmentation is presented. An optimal threshold is selected by the discriminant criterion, namely, so as to maximize the separability of the resultant classes in gray levels. The procedure is very simple, utilizing only the zerothand the first-order cumulative moments of the gray-level histogram. It is straightforward to extend the method to multithreshold problems. Several experimental results are also presented to support the validity of the method."
            },
            "slug": "A-threshold-selection-method-from-gray-level-Otsu",
            "title": {
                "fragments": [],
                "text": "A threshold selection method from gray level histograms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258400"
                        ],
                        "name": "\u00d8. Trier",
                        "slug": "\u00d8.-Trier",
                        "structuredName": {
                            "firstName": "\u00d8ivind",
                            "lastName": "Trier",
                            "middleNames": [
                                "Due"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00d8. Trier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48717516"
                        ],
                        "name": "T. Taxt",
                        "slug": "T.-Taxt",
                        "structuredName": {
                            "firstName": "Torfinn",
                            "lastName": "Taxt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Taxt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 13
                            }
                        ],
                        "text": "According to [101, 102], Otsu\u2019s procedure is ranked as the best and the fastest of these methods [70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17374833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66126ec1fe61b833ae695db9c5bac54641fab482",
            "isKey": false,
            "numCitedBy": 451,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an evaluation of eleven locally adaptive binarization methods for gray scale images with low contrast, variable background intensity and noise. Niblack's method (1986) with the addition of the postprocessing step of Yanowitz and Bruckstein's method (1989) added performed the best and was also one of the fastest binarization methods. >"
            },
            "slug": "Evaluation-of-Binarization-Methods-for-Document-Trier-Taxt",
            "title": {
                "fragments": [],
                "text": "Evaluation of Binarization Methods for Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This paper presents an evaluation of eleven locally adaptive binarization methods for gray scale images with low contrast, variable background intensity and noise and Niblack's method with the addition of the postprocessing step of Yanowitz and Bruckstein's method (1989) performed the best and was also one of the fastest binarized methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48349282"
                        ],
                        "name": "G. Read",
                        "slug": "G.-Read",
                        "structuredName": {
                            "firstName": "Gardner",
                            "lastName": "Read",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Read"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61490188,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "ed2ec11bfd902be58784e83d5dbae9f11e331452",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A mass of diamond crystals in contact with a mass of eutectiferous silicon-rich alloy and a silicon nitride ceramic substrate are disposed in a container and placed within a pressure transmitting powder medium. Pressure is applied to the powder medium resulting in substantially isostatic pressure being applied to the container and its contents sufficient to dimensionally stabilize the container and its contents. The resulting shaped substantially isostatic system of powder-enveloped container is hot-pressed whereby fluid eutectiferous silicon-rich alloy is produced and infiltrated through the interstices between the diamond crystals and contacts the contacting face of the silicon nitride substrate sufficiently producing, upon cooling, an adherently bonded integral composite."
            },
            "slug": "Music-notation;:-A-manual-of-modern-practice-Read",
            "title": {
                "fragments": [],
                "text": "Music notation;: A manual of modern practice"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A mass of diamond crystals in contact with a mass of eutectiferous silicon-rich alloy and a silicon nitride ceramic substrate are disposed in a container and placed within a pressure transmitting powder medium to dimensionally stabilize the container and its contents."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802711"
                        ],
                        "name": "Yves Grandvalet",
                        "slug": "Yves-Grandvalet",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Grandvalet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yves Grandvalet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792962"
                        ],
                        "name": "A. Rakotomamonjy",
                        "slug": "A.-Rakotomamonjy",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Rakotomamonjy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rakotomamonjy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771345"
                        ],
                        "name": "Joseph Keshet",
                        "slug": "Joseph-Keshet",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Keshet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph Keshet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794818"
                        ],
                        "name": "S. Canu",
                        "slug": "S.-Canu",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Canu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Canu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 36
                            }
                        ],
                        "text": "of classifiers with a reject option [25,46,94]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5431868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ae06ae7126debdff634aab69a133d4c808c1f78",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of binary classification where the classifier may abstain instead of classifying each observation. The Bayes decision rule for this setup, known as Chow's rule, is defined by two thresholds on posterior probabilities. From simple desiderata, namely the consistency and the sparsity of the classifier, we derive the double hinge loss function that focuses on estimating conditional probabilities only in the vicinity of the threshold points of the optimal decision rule. We show that, for suitable kernel machines, our approach is universally consistent. We cast the problem of minimizing the double hinge loss as a quadratic program akin to the standard SVM optimization problem and propose an active set method to solve it efficiently. We finally provide preliminary experimental results illustrating the interest of our constructive approach to devising loss functions."
            },
            "slug": "Support-Vector-Machines-with-a-Reject-Option-Grandvalet-Rakotomamonjy",
            "title": {
                "fragments": [],
                "text": "Support Vector Machines with a Reject Option"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The problem of binary classification where the classifier may abstain instead of classifying each observation is considered, and the double hinge loss function that focuses on estimating conditional probabilities only in the vicinity of the threshold points of the optimal decision rule is derived."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3193922"
                        ],
                        "name": "N. Friel",
                        "slug": "N.-Friel",
                        "structuredName": {
                            "firstName": "Nial",
                            "lastName": "Friel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Friel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2282396"
                        ],
                        "name": "I. Molchanov",
                        "slug": "I.-Molchanov",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Molchanov",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Molchanov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33191060,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "f1cea7c9bc3a7095b90da32bb9fcfa8077a4584b",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-new-thresholding-technique-based-on-random-sets-Friel-Molchanov",
            "title": {
                "fragments": [],
                "text": "A new thresholding technique based on random sets"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3093358"
                        ],
                        "name": "S. Boukharouba",
                        "slug": "S.-Boukharouba",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Boukharouba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Boukharouba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31435428"
                        ],
                        "name": "J. Rebord\u00e3o",
                        "slug": "J.-Rebord\u00e3o",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Rebord\u00e3o",
                            "middleNames": [
                                "Manuel"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rebord\u00e3o"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145795476"
                        ],
                        "name": "P. Wendel",
                        "slug": "P.-Wendel",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Wendel",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Wendel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32267099,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "id": "41f5ecbd9f422cb666fd4d49b951f371e283aef6",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-amplitude-segmentation-method-based-on-the-of-an-Boukharouba-Rebord\u00e3o",
            "title": {
                "fragments": [],
                "text": "An amplitude segmentation method based on the distribution function of an image"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796298"
                        ],
                        "name": "B. Kapralos",
                        "slug": "B.-Kapralos",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Kapralos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kapralos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 32
                            }
                        ],
                        "text": "One of the most used methods is Niblack [69]\u2019s method which uses the mean and the standard deviation of the pixel\u2019s vicinity as local information for the threshold decision."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "most used methods is Niblack [69]\u2019s method which uses the mean and the standard deviation of the pixel\u2019s vicinity as local information for the threshold decision."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14314155,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "7ccfc40123609c95fb4153c89fbca483336be02e",
            "isKey": false,
            "numCitedBy": 773,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "ELIC 629, Fall 2005 Bill Kapralos ELIC 629, Fall 2005, Bill Kapralos Fall 2005 Image Enhancement in the Spatial Domain: Histograms, Arithmetic/Logic Operators, Basics of Spatial Filtering, Smoothing Spatial Filters Bill Kapralos Monday, October 17 2005 Overview (1): Before We Begin Administrative details Review \u2192 some questions to consider Histogram Processing Introduction Examples Arithmetic/Logic Operator Enhancement Image subtraction Image averaging"
            },
            "slug": "I-An-Introduction-to-Digital-Image-Processing-Kapralos",
            "title": {
                "fragments": [],
                "text": "I An Introduction to Digital Image Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064219241"
                        ],
                        "name": "Bertrand Co\u00fcasnon",
                        "slug": "Bertrand-Co\u00fcasnon",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Co\u00fcasnon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bertrand Co\u00fcasnon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 169571915,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "87862e71deae20cd81c24396081814f25491d662",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Cette these s'interesse a la reconnaissance optique de documents. Dans ce cadre, la fiabilite est importante afin que l'utilisateur n'ait pas a relire l'ensemble du document pour y detecter et corriger d'eventuelles erreurs residuelles. Cette fiabilite peut s'obtenir, d'une part en ameliorant la qualite de la reconnaissance, notamment en resolvant les problemes de segmentation, et d'autre part en faisant detecter par le systeme lui-meme les regions comportant des erreurs de reconnaissance. Pour atteindre ces deux objectifs, il faut utiliser la connaissance a priori, qui permet de regler certains problemes de segmentation et permet egalement de modeliser la redondance, ce qui autorise une detection d'erreurs. Le domaine d'etude choisi dans cette these est la reconnaissance de partitions musicales. Dans ce domaine la connaissance a priori est tres structuree et de nombreux problemes de segmentation (principalement lies a la densite de l'information) n'ont pas encore ete resolus par les methodes classiques presentees dans la litterature. Nous proposons pour ce type de documents a forte syntaxe, une nouvelle methode baptisee pmll, constituee d'un formalisme grammatical p permettant de modeliser la connaissance, et d'un analyseur mll autorisant une modification en cours d'analyse de la structure analysee. Cette modification permet d'introduire le contexte (niveau symbolique) dans la phase de segmentation (niveau numerique), afin d'ameliorer la reconnaissance. La methode pmll offre en plus les avantages de separer la connaissance (decrite sous la forme d'une grammaire) et le programme, et de produire automatiquement l'analyseur par compilation de la grammaire. Ces avantages facilitent largement la maitrise de l'introduction de connaissances complexes. A l'aide du formalisme p, nous avons ainsi pu definir une grammaire de la notation musicale. Le systeme presente est deja capable de reconnaitre des partitions d'orchestre a portees polyphoniques, en corrigeant certaines erreurs de segmentation (symboles touchant des notes) et en indiquant les zones comportant des erreurs"
            },
            "slug": "Segmentation-et-reconnaissance-de-documents-guidees-Co\u00fcasnon",
            "title": {
                "fragments": [],
                "text": "Segmentation et reconnaissance de documents guidees par la connaissance a priori : application aux partitions musicales"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753289"
                        ],
                        "name": "R. Sousa",
                        "slug": "R.-Sousa",
                        "structuredName": {
                            "firstName": "Ricardo",
                            "lastName": "Sousa",
                            "middleNames": [
                                "Gamelas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sousa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057345484"
                        ],
                        "name": "Beatriz Mora",
                        "slug": "Beatriz-Mora",
                        "structuredName": {
                            "firstName": "Beatriz",
                            "lastName": "Mora",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatriz Mora"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3698192"
                        ],
                        "name": "Jaime S. Cardoso",
                        "slug": "Jaime-S.-Cardoso",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Cardoso",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaime S. Cardoso"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 36
                            }
                        ],
                        "text": "of classifiers with a reject option [25,46,94]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1740111,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf39ccb9bad5217cee84bccb1aaf9bae98e84e5a",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we consider the problem of binary classification where the classifier may abstain instead of classifying each observation, leaving the critical items for human evaluation. This article motivates and presents a novel method to learn the reject region on complex data. Observations are replicated and then a single binary classifier determines the decision plane. The proposed method is an extension of a method available in the literature for the classification of ordinal data. Our method is compared with standard techniques on synthetic and real datasets, emphasizing the advantages of the proposed approach."
            },
            "slug": "An-Ordinal-Data-Method-for-the-Classification-with-Sousa-Mora",
            "title": {
                "fragments": [],
                "text": "An Ordinal Data Method for the Classification with Reject Option"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article motivates and presents a novel method to learn the reject region on complex data that is an extension of a method available in the literature for the classification of ordinal data."
            },
            "venue": {
                "fragments": [],
                "text": "2009 International Conference on Machine Learning and Applications"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3104325"
                        ],
                        "name": "P. Papapanagiotou",
                        "slug": "P.-Papapanagiotou",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Papapanagiotou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Papapanagiotou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2320148"
                        ],
                        "name": "Jacques D. Fleuriot",
                        "slug": "Jacques-D.-Fleuriot",
                        "structuredName": {
                            "firstName": "Jacques",
                            "lastName": "Fleuriot",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacques D. Fleuriot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110813747"
                        ],
                        "name": "Sean Wilson",
                        "slug": "Sean-Wilson",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Wilson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sean Wilson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37070480,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d66644bc4be9db4687d0833cb0544bc6b628405",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a diagrammatic approach to the formal verification of web-services composition. We present a set of graphical composition rules that map to proof steps in Classical Linear Logic (CLL) and can be used to drive the proof assistant HOL Light purely through interactive, diagrammatic reasoning. The end result is a verified, workflow-like diagram that provides a visual account of the composition process and of the information flow between the services making up the composite service. Our approach thus removes the need to interact directly with HOL Light and provides a mean of visualising and carrying out the whole verification process at an intuitive, yet fully rigorous, level."
            },
            "slug": "Diagrammatically-Driven-Formal-Verification-of-Papapanagiotou-Fleuriot",
            "title": {
                "fragments": [],
                "text": "Diagrammatically-Driven Formal Verification of Web-Services Composition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A set of graphical composition rules that map to proof steps in Classical Linear Logic and can be used to drive the proof assistant HOL Light purely through interactive, diagrammatic reasoning are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Diagrams"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110799561"
                        ],
                        "name": "Graham Jones",
                        "slug": "Graham-Jones",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143995861"
                        ],
                        "name": "B. Ong",
                        "slug": "B.-Ong",
                        "structuredName": {
                            "firstName": "Bee",
                            "lastName": "Ong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1985733"
                        ],
                        "name": "I. Bruno",
                        "slug": "I.-Bruno",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Bruno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Bruno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145513222"
                        ],
                        "name": "K. Ng",
                        "slug": "K.-Ng",
                        "structuredName": {
                            "firstName": "Kia",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[51] also sug- gest an evaluation approach with the following aspects: (1) a standard dataset for OMR or a set of standard terminology is needed in order to objectively and automatically evaluate the entire music score recognition system, (2) a definition of a set of rules and metrics, encompassing the key points to be considered in the evaluation process, and (3) the definition of different ratios for each kind of error."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[51] address several important shortcomings to take into consideration when comparing different OMR systems: (1) each available commercial OMR systems has its"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[51] presented a study in mu- sic imaging, which included digitalization, recognition and restoration, and also provided a well detailed list of hardware and software in OMR together with an evaluation of three OMR systems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 637,
                                "start": 633
                            }
                        ],
                        "text": "An effective and robust OMR system for printed and handwritten music scores can provide several advantages to the scientific community: (1) an automated and time-saving input method to transform paper-based music scores into a machine-readable symbolic format for several music softwares, (2) enable translations, for instance to Braille notations, (3) better access to music, (4) new functionalities and capabilities with interactive multimedia technologies, for instance association of scores and video excerpts, (5) playback, musical analysis, reprinting, editing, and digital archiving, and (6) preservation of cultural heritage [51]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 192087642,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "6fd06e69d4ad5d15d59bb28bdef63fab3ca10fc3",
            "isKey": true,
            "numCitedBy": 23,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optical-Music-Imaging:-Music-Document-Digitisation,-Jones-Ong",
            "title": {
                "fragments": [],
                "text": "Optical Music Imaging: Music Document Digitisation, Recognition, Evaluation, and Restoration"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 15
                            }
                        ],
                        "text": "As referred in [6] the meaning of music recognition depends on the goal in mind."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 169
                            }
                        ],
                        "text": "Several commercial OMR software have appeared, but none with a satisfactory performance in terms of precision and robustness, in particular for handwritten music scores [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 170
                            }
                        ],
                        "text": "14 As already mentioned in this article, there are several commercial OMR systems available15 and their recognition accuracy, as claimed by the distributor, is about 90% [6,51]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6] proposed two assessment models focused on basic and composite symbols to measure the results of the OMR algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "the OMR field, thus making it a reference for researchers [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Assessing optical music recognition"
            },
            "venue": {
                "fragments": [],
                "text": "tools. Comput Music J"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190426"
                        ],
                        "name": "Ichiro Fujinaga",
                        "slug": "Ichiro-Fujinaga",
                        "structuredName": {
                            "firstName": "Ichiro",
                            "lastName": "Fujinaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ichiro Fujinaga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 75
                            }
                        ],
                        "text": "Other authors have chosen to apply projections to detect primitive symbols [74, 41, 5, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 7
                            }
                        ],
                        "text": "One of Fujinaga\u2019s first works focused on the characterization of music notation by means of a context-free and L L(k) grammar."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "Fujinaga [41] incorporates a set of image processing techniques in the algorithm, including run-length coding (RLC), connected-component analysis, and projections."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "histogram Fujinaga [41] incorporates a set of image processing tech- niques in the algorithm, including run-length coding (RLC), connected-component analysis, and projections."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 117
                            }
                        ],
                        "text": "The simplest approach consists of finding local maxima on the horizontal projection of the black pixels of the image [41, 79]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 50
                            }
                        ],
                        "text": "The same idea of active learning was suggested by Fujinaga [40] in which a method to learn new music symbols and handwritten music notations based on the combination of a k-nearest neighbor classifier with a genetic algorithm was proposed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [41], the k-nearest neighbor rule is used in the classifica- tion phase, while neural networks is the classifier selected in [66, 62, 5, 7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 124
                            }
                        ],
                        "text": "Usually, the primitive segmentation step is made along with the classification task [89, 100]; however there are exceptions [41, 5, 7]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 254
                            }
                        ],
                        "text": "A. Rebelo (B) \u00b7 F. Paszkiewicz \u00b7 C. Guedes \u00b7 J. S. Cardoso FEUP, INESC Porto, Porto, Portugal e-mail: arebelo@inescporto.pt\nF. Paszkiewicz e-mail: filipe.asp@gmail.com\nC. Guedes e-mail: carlosguedes@mac.com\nJ. S. Cardoso e-mail: jaime.cardoso@inescporto.pt\nI. Fujinaga Schulich School of Music, McGill University, Montreal, Canada e-mail: ich@music.mcgill.ca\nA. R. S. Marcal FCUP, CICGE, Porto, Portugal e-mail: andre.marcal@fc.up.pt\npresents a reference scheme for any researcher wanting to compare new OMR algorithms against well-known ones."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "[41, 45, 64, 34, 98]) and morphological operations [45] are the most common techniques for preprocessing music scores."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 147788002,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "81d954e3226f381ad7131852bd99f46a01b3a5c5",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Staff-Detection-and-Removal-Fujinaga",
            "title": {
                "fragments": [],
                "text": "Staff Detection and Removal"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143616982"
                        ],
                        "name": "Ana Rebelo",
                        "slug": "Ana-Rebelo",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Rebelo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana Rebelo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1937913"
                        ],
                        "name": "G. Capela",
                        "slug": "G.-Capela",
                        "structuredName": {
                            "firstName": "Guilherme",
                            "lastName": "Capela",
                            "middleNames": [
                                "Artur"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Capela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3698192"
                        ],
                        "name": "Jaime S. Cardoso",
                        "slug": "Jaime-S.-Cardoso",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Cardoso",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaime S. Cardoso"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[83] carried out an investigation on four classification methods, namely support vector machines (SVMs), neural networks (NNs), nearest neighbor (kNN) and Hidden Markov Models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [83] the segmentation of the objects is"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 88
                            }
                        ],
                        "text": "In most of the proposed works, the music sheets were scanned at a resolution of 300 dpi [16,26,35,37,45,55,64,83,89]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[83] presented pattern recognition studies applied to music notation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "In this paper we use the framework outlined in [83]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 66
                            }
                        ],
                        "text": "In the OMR field, several research works have used this technique [16,45,76,83,98]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "in some approaches [83] noteheads are joined with stems and also with flags for the classification phase, in the segmenta-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[83] have created a dataset with 14 classes of printed and handwritten music symbols, each of them with 2,521 and 3,222 symbols, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 221114744,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "707ee18d4a02d067af46ed3ade7c2ac930c9b307",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optical-recognition-of-music-symbols-A-comparative-Rebelo-Capela",
            "title": {
                "fragments": [],
                "text": "Optical recognition of music symbols - A comparative study"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Document Anal. Recognit."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145513222"
                        ],
                        "name": "K. Ng",
                        "slug": "K.-Ng",
                        "structuredName": {
                            "firstName": "Kia",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064718045"
                        ],
                        "name": "David Cooper",
                        "slug": "David-Cooper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cooper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6343598"
                        ],
                        "name": "E. Stefani",
                        "slug": "E.-Stefani",
                        "structuredName": {
                            "firstName": "Ewan",
                            "lastName": "Stefani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Stefani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35061525"
                        ],
                        "name": "R. Boyle",
                        "slug": "R.-Boyle",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Boyle",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Boyle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067601038"
                        ],
                        "name": "Nick Bailey",
                        "slug": "Nick-Bailey",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Bailey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nick Bailey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2013 Mathematical morphological approach: [68], [34]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Notwithstanding, there are authors who suggested algorithms without the need to remove the staff lines [68, 5, 58, 45, 93, 76, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2013 MIDI: [68, 33, 31, 64, 43, 20, 98]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2013 Fusion of musical rules and heuristics: [28], [68], [31], [89]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In [68] a framework based on a mathematical morpho-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[68] have adopted the technique developed by Ridler and Calvard [86]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46390767,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "6cd486ccea5e9258914cfab3916705d27faa596d",
            "isKey": true,
            "numCitedBy": 21,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Embracing-the-Composer:-Optical-Recognition-of-Ng-Cooper",
            "title": {
                "fragments": [],
                "text": "Embracing the Composer: Optical Recognition of Handwritten Manuscripts"
            },
            "venue": {
                "fragments": [],
                "text": "ICMC"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "\u2013 Fusion of musical rules and heuristics: [28], [68], [31], [89]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Carter [18] and Dan [28] use a LAG to extract symbols."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "\u2013 Line Adjacency Graph: [18], [28], [85]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "[28, 68, 31, 89]) and common parts on the row and column histograms for each pair of symbols [98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Final year project report automatic optical music recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Technical report,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 3
                            }
                        ],
                        "text": "In [65,67,68] the process is also based on a low- and highlevel approaches to recognize music scores."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "[28,31, 68,89]) and common parts on the row and column histograms for each pair of symbols [98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [68] a framework based on a mathematical morphological approach commonly used in document imaging is proposed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 54
                            }
                        ],
                        "text": "algorithms without the need to remove the staff lines [5,7,45, 58,68,76,93]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[68] have adopted the technique developed by Ridler and Calvard [86]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "optical recognition of handwritten manuscripts"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the international computer music conference, pp 500\u2013503 123  190  Int J Multimed Info Retr"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731760"
                        ],
                        "name": "S. E. George",
                        "slug": "S.-E.-George",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "George",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. E. George"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [44] an overview of existing solutions to recognize the lyrics in Christian music sheets is described."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 192169307,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "b9a250a4d6ab3d07ad2e16dacb5843a976c7e3b6",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Lyric-Recognition-and-Christian-Music-George",
            "title": {
                "fragments": [],
                "text": "Lyric Recognition and Christian Music"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1955886"
                        ],
                        "name": "M. Kassler",
                        "slug": "M.-Kassler",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kassler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kassler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69028833"
                        ],
                        "name": "D. H. Pruslin",
                        "slug": "D.-H.-Pruslin",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Pruslin",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. H. Pruslin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805167"
                        ],
                        "name": "D. Prerau",
                        "slug": "D.-Prerau",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Prerau",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Prerau"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 192979471,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "f8125897c1cf188c91b8b225e9b57a30ee22751a",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optical-Character-Recognition-of-Printed-Music:-A-Kassler-Pruslin",
            "title": {
                "fragments": [],
                "text": "Optical Character-Recognition of Printed Music: A Review of Two Dissertations@@@Automatic Recognition of Sheet Music@@@Computer Pattern Recognition of Standard Engraved Music Notation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32025850"
                        ],
                        "name": "T. Ridler",
                        "slug": "T.-Ridler",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Ridler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ridler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 77
                            }
                        ],
                        "text": "Ng and Boyle [66] and Ng et al. [68] have adopted the technique developed by Ridler and Calvard [86]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "Clustering Otsu [70], Ridler and Calvard [86], Pinto et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "[68] have adopted the technique developed by Ridler and Calvard [86]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118436421,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18467119443c26a6d86f17781032cc71e5e5a424",
            "isKey": false,
            "numCitedBy": 2080,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Picture-thresholding-using-an-iterative-selection-Ridler",
            "title": {
                "fragments": [],
                "text": "Picture thresholding using an iterative selection method."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145513222"
                        ],
                        "name": "K. Ng",
                        "slug": "K.-Ng",
                        "structuredName": {
                            "firstName": "Kia",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "[41, 45, 64, 34, 98]) and morphological operations [45] are the most common techniques for preprocessing music scores."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 88
                            }
                        ],
                        "text": "In most of the proposed works, the music sheets were scanned at a resolution of 300 dpi [45, 64, 34, 89, 55, 26, 17, 83, 37]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 64208034,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "c3d0b65e7b2729249b2636238f8e8211f4596e45",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optical-Music-Analysis-for-Printed-Music-Score-and-Ng",
            "title": {
                "fragments": [],
                "text": "Optical Music Analysis for Printed Music Score and Handwritten Music Manuscript"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71462278"
                        ],
                        "name": "Ichlro FuJinaga",
                        "slug": "Ichlro-FuJinaga",
                        "structuredName": {
                            "firstName": "Ichlro",
                            "lastName": "FuJinaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ichlro FuJinaga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61611949,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "9cb4312cb1d7848c3bf094763fb56004397672fa",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optical-Music-Recognition-Using-Projections-FuJinaga",
            "title": {
                "fragments": [],
                "text": "Optical Music Recognition Using Projections"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1867505"
                        ],
                        "name": "S. Bilbao",
                        "slug": "S.-Bilbao",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Bilbao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bilbao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3203084"
                        ],
                        "name": "M. V. Walstijn",
                        "slug": "M.-V.-Walstijn",
                        "structuredName": {
                            "firstName": "Maarten",
                            "lastName": "Walstijn",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. V. Walstijn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "The work developed in [14] is the beginning of a web-based system that will provide broad access to a wide corpus of handwrit-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61095088,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "00cfd1558ce9cf87a92cc9e1b07d5fa97486afd5",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Proceedings-of-the-International-Computer-Music-Bilbao-Walstijn",
            "title": {
                "fragments": [],
                "text": "Proceedings of the International Computer Music Conference"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143748132"
                        ],
                        "name": "D. Bainbridge",
                        "slug": "D.-Bainbridge",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bainbridge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bainbridge"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60988508,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0a79b149786c6c3337020d2c5b80f8fc2a68334c",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Extensible-optical-music-recognition-Bainbridge",
            "title": {
                "fragments": [],
                "text": "Extensible optical music recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34593830"
                        ],
                        "name": "H. Miyao",
                        "slug": "H.-Miyao",
                        "structuredName": {
                            "firstName": "Hidetoshi",
                            "lastName": "Miyao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Miyao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737939"
                        ],
                        "name": "Y. Nakano",
                        "slug": "Y.-Nakano",
                        "structuredName": {
                            "firstName": "Yasuaki",
                            "lastName": "Nakano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Nakano"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Miyao and Nakano [62] use Hough Transform to detect staff lines."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 126
                            }
                        ],
                        "text": "In [41], the k-nearest neighbor rule is used in the classification phase, while neural networks is the classifier selected in [5,7,62,66]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60065508,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1df95fb2f1178e05e19f6ce0505311bb6ce6686",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Note-Symbol-Extraction-for-Printed-Piano-Scores-on-Miyao-Nakano",
            "title": {
                "fragments": [],
                "text": "Note Symbol Extraction for Printed Piano Scores Using Neural Networks (Special Issue on Character Recognition and Document Understanding)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703213"
                        ],
                        "name": "P. Fr\u00e4nti",
                        "slug": "P.-Fr\u00e4nti",
                        "structuredName": {
                            "firstName": "Pasi",
                            "lastName": "Fr\u00e4nti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fr\u00e4nti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148612899"
                        ],
                        "name": "Gavin Brown",
                        "slug": "Gavin-Brown",
                        "structuredName": {
                            "firstName": "Gavin",
                            "lastName": "Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gavin Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143888579"
                        ],
                        "name": "M. Loog",
                        "slug": "M.-Loog",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Loog",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Loog"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704343"
                        ],
                        "name": "Francisco Escolano",
                        "slug": "Francisco-Escolano",
                        "structuredName": {
                            "firstName": "Francisco",
                            "lastName": "Escolano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francisco Escolano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8111020"
                        ],
                        "name": "M. Pelillo",
                        "slug": "M.-Pelillo",
                        "structuredName": {
                            "firstName": "Marcello",
                            "lastName": "Pelillo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pelillo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "[28,31, 68,89]) and common parts on the row and column histograms for each pair of symbols [98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57892969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49bf89b3f7404c78b2c8bae5ade369ab2ae12116",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Proceedings-of-the-Joint-IAPR-International-on-and-Fr\u00e4nti-Brown",
            "title": {
                "fragments": [],
                "text": "Proceedings of the Joint IAPR International Workshop on Structural, Syntactic, and Statistical Pattern Recognition - Volume 8621"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700665"
                        ],
                        "name": "N. Lobo",
                        "slug": "N.-Lobo",
                        "structuredName": {
                            "firstName": "Niels",
                            "lastName": "Lobo",
                            "middleNames": [
                                "da",
                                "Vitoria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lobo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50433269"
                        ],
                        "name": "T. Kasparis",
                        "slug": "T.-Kasparis",
                        "structuredName": {
                            "firstName": "Takis",
                            "lastName": "Kasparis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kasparis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710171"
                        ],
                        "name": "F. Roli",
                        "slug": "F.-Roli",
                        "structuredName": {
                            "firstName": "Fabio",
                            "lastName": "Roli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Roli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145193332"
                        ],
                        "name": "J. Kwok",
                        "slug": "J.-Kwok",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Kwok",
                            "middleNames": [
                                "Tin-Yau"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kwok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085046"
                        ],
                        "name": "M. Georgiopoulos",
                        "slug": "M.-Georgiopoulos",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Georgiopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Georgiopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8492907"
                        ],
                        "name": "G. Anagnostopoulos",
                        "slug": "G.-Anagnostopoulos",
                        "structuredName": {
                            "firstName": "Georgios",
                            "lastName": "Anagnostopoulos",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Anagnostopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143888579"
                        ],
                        "name": "M. Loog",
                        "slug": "M.-Loog",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Loog",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Loog"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57104812,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fdabdc925944e7a807f04db2e64700ff2197126f",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Proceedings-of-the-2006-joint-IAPR-international-on-Lobo-Kasparis",
            "title": {
                "fragments": [],
                "text": "Proceedings of the 2006 joint IAPR international conference on Structural, Syntactic, and Statistical Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32606739"
                        ],
                        "name": "A. Andronico",
                        "slug": "A.-Andronico",
                        "structuredName": {
                            "firstName": "Alfio",
                            "lastName": "Andronico",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Andronico"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2129680"
                        ],
                        "name": "A. Ciampa",
                        "slug": "A.-Ciampa",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Ciampa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ciampa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "Andronico and Ciampa [1] and Prerau [74] were pioneers in this area."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34262070,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "642477b1af4150a894b4782df8ecc0c40d7881c9",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-Automatic-Pattern-Recognition-and-Acquisition-of-Andronico-Ciampa",
            "title": {
                "fragments": [],
                "text": "On Automatic Pattern Recognition and Acquisition of Printed Music"
            },
            "venue": {
                "fragments": [],
                "text": "ICMC"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34593830"
                        ],
                        "name": "H. Miyao",
                        "slug": "H.-Miyao",
                        "structuredName": {
                            "firstName": "Hidetoshi",
                            "lastName": "Miyao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Miyao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47471571"
                        ],
                        "name": "Masayuki Okamoto",
                        "slug": "Masayuki-Okamoto",
                        "structuredName": {
                            "firstName": "Masayuki",
                            "lastName": "Okamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masayuki Okamoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 41
                            }
                        ],
                        "text": "[26] is an improvement on the methods of [63,95]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 24
                            }
                        ],
                        "text": "The methods proposed in [63,95] operate on a set of staff segments, with methods for linking two segments"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 43611850,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abe40263253ac711f0873b8a7221f1d6a24258b4",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Stave-Extraction-for-Printed-Music-Scores-Using-DP-Miyao-Okamoto",
            "title": {
                "fragments": [],
                "text": "Stave Extraction for Printed Music Scores Using DP Matching"
            },
            "venue": {
                "fragments": [],
                "text": "J. Adv. Comput. Intell. Intell. Informatics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731760"
                        ],
                        "name": "S. E. George",
                        "slug": "S.-E.-George",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "George",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. E. George"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64074656,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "bdbdc77f0ef6363441b446349b08dc4390bb2248",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Visual-Perception-of-Music-Notation:-On-Line-and-George",
            "title": {
                "fragments": [],
                "text": "Visual Perception of Music Notation: On-Line and Off-Line Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Int J Multimed Info Ret"
            },
            "venue": {
                "fragments": [],
                "text": "Int J Multimed Info Ret"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reading sheet music. Master's thesis, Imperial College London"
            },
            "venue": {
                "fragments": [],
                "text": "Reading sheet music. Master's thesis, Imperial College London"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic thresholding of grey-level images Multipass approach to adaptive thresholding based image segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 8th International IEEE Conference CADSM"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "The best result was obtained with the Brink and Pendock [10]\u2019s method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Minimum crossentropy threshold selection"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "Niblack [69], Bernsen [8], Yanowitz and Bruckstein [104], ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic thresholding of grey - level images , 1986"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "[28,31, 68,89]) and common parts on the row and column histograms for each pair of symbols [98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Carter [18] and Dan [28] use a LAG to extract symbols."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Final year project report automatic optical music recognition, technical report"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Desaedeleer [30](13), in his open source project to perform OMR, has created 15 classes of"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Desaedeleer. Reading sheet music"
            },
            "venue": {
                "fragments": [],
                "text": "Master\u2019s thesis, Imperial College London, Technology and Medicine, University of London,"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "New methodologies torwads an automatic optical recognition of handwritten musical scores. Master's thesis"
            },
            "venue": {
                "fragments": [],
                "text": "New methodologies torwads an automatic optical recognition of handwritten musical scores. Master's thesis"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An adaptive binarisation technique for low quality historical documents. In: Document analysis systems VI"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture notes in computer science,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 37
                            }
                        ],
                        "text": "The research field of OMR began with Pruslin [75] and Prerau [73] and, since then, has undergone much important advancements."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "The research field of OMR began with Pruslin [75] and"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic recognition of sheet music"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "Several surveys and summaries have been presented to the scientific community: Kassler [53] reviewed two of the first dissertations on OMR, Blostein and Baird [9] published an overview of OMR systems developed between 1966 and 1992, Bainbridge and Bell [3] published a generic framework for OMR (subsequently adopted by many researchers in this field), and both Homenda [47] and Rebelo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 79
                            }
                        ],
                        "text": "Several surveys and summaries have been presented to the scientific community: Kassler [53] reviewed two of the first dissertations on OMR, Blostein and Baird [9] published an overview of OMR systems developed between 1966 and 1992, Bainbridge and Bell [3] published a generic framework for OMR (subsequently adopted by many researchers in this field), and both Homenda [47] and Rebelo et al. [83] presented pattern recognition studies applied to music notation."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optical character recognition of printed music: A review of two dissertations"
            },
            "venue": {
                "fragments": [],
                "text": "Technical report,"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 217
                            }
                        ],
                        "text": "Other techniques for finding staff lines include the grouping of vertical columns based on their spacing, thickness, and vertical position on the image [85], rule-based classification of thin horizontal line segments [60], and line tracing [73,88,98]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "Mahoney [60] builds a set of candidates to one or more symbol types and then uses descriptors to select the matching candidates."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic analysis of music score"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 103
                            }
                        ],
                        "text": "Notwithstanding, there are authors who suggested algorithms without the need to remove the staff lines [68, 5, 58, 45, 93, 76, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Defacing music score for improved recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 54
                            }
                        ],
                        "text": "algorithms without the need to remove the staff lines [5,7,45, 58,68,76,93]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Defacing music score for improved recognition. In: Abraham G, Rubinstein BIP (eds) Proceedings of the second Australian undergraduate students\u2019 computing conference"
            },
            "venue": {
                "fragments": [],
                "text": "Australian undergraduate students\u2019 computing conference,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Using grammars to segment and recognize music scores"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of DAS-94: International Association for Pattern Recognition Workshop on Document Analysis Systems,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic thresholding of grey-level images, 1986. In: Bieniecki W, Grabowski S (eds) Multi-pass approach to adaptive thresholding based image segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 8th international IEEE conference CADSM"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 3
                            }
                        ],
                        "text": "In [65, 67, 68] the process is also based on a lowand high-level approaches to recognize music scores."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Domain knowledge enhancement of optical music score recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Technical report,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optical character recognition of printed music: A review of two dissertations Optical music recognition for structural information from high-quality scanned music"
            },
            "venue": {
                "fragments": [],
                "text": "Optical character recognition of printed music: A review of two dissertations Optical music recognition for structural information from high-quality scanned music"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic recognition of sheet music, 1966. A critical survey of music image analysis Structured document image analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Automatic recognition of sheet music, 1966. A critical survey of music image analysis Structured document image analysis"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic analysis of music score images A critical survey of music image analysis Structured document image analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Automatic analysis of music score images A critical survey of music image analysis Structured document image analysis"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 9
                            }
                        ],
                        "text": "Co\u00fcasnon [22, 21] proposed a recognition process entirely controlled by grammar which formalizes the musical knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Using grammars to segment and recognize music scores"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Prerau [73] makes a distinction between notational gram-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 240
                            }
                        ],
                        "text": "Other techniques for finding staff lines include the grouping of vertical columns based on their spacing, thickness, and vertical position on the image [85], rule-based classification of thin horizontal line segments [60], and line tracing [73,88,98]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Prerau [73] and, since then, has undergone much impor-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computer pattern recognition of standard engraved music"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the Third International Conference on the Practical Application of Prolog"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Third International Conference on the Practical Application of Prolog"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optical character recognition of printed music: a review of two dissertations In: Vrist B (ed) Optical music recognition for structural information from high-quality scanned music"
            },
            "venue": {
                "fragments": [],
                "text": "Optical character recognition of printed music: a review of two dissertations In: Vrist B (ed) Optical music recognition for structural information from high-quality scanned music"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Int J Multimed Info Retr"
            },
            "venue": {
                "fragments": [],
                "text": "Int J Multimed Info Retr"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Burgoyne , and I . Fujinaga . MAP adaptation to improve optical music recognition of early music documents using Hidden Markov Models"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 8 th International Society for Music Information Retrieval"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An adaptive binarisation technique for low quality historical documents. In Document Analysis Systems VI, volume 3163 of Lecture Notes in Computer Science, pages 102\u2013113"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Entropic thresholding , 1989"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "Bainbridge [2] also implemented a grammar-based approach using DCG\u2019s to specify the relationships between the recognized musical shapes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "Bainbridge [2] uses PRIMitive Expression LAnguage (PRI-MELA) language, which was"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 110
                            }
                        ],
                        "text": "More recent works present a sophisticated use of projection techniques combined to improve the basic approach [2,5,7,89]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An extensible optical music recognition system"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the nineteenth Australasian computer science conference,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Using grammars to segment and recognize music scores. In: Proceedings of DAS-94: international association for pattern recognition workshop on document analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An adaptive binarisation technique for low quality historical documents In: Document analysis systems VI. Lecture notes in computer science"
            },
            "venue": {
                "fragments": [],
                "text": "An adaptive binarisation technique for low quality historical documents In: Document analysis systems VI. Lecture notes in computer science"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Support vector machines with a reject option Advances in neural information processing systems"
            },
            "venue": {
                "fragments": [],
                "text": "Support vector machines with a reject option Advances in neural information processing systems"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 3
                            }
                        ],
                        "text": "In [65,67,68] the process is also based on a low- and highlevel approaches to recognize music scores."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Domain knowledge enhancement of optical music score recognition, technical report"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "The research field of OMR began with Pruslin [75] and Prerau [73] and, since then, has undergone much important advancements."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic recognition of sheet music, 1966"
            },
            "venue": {
                "fragments": [],
                "text": "In Structured Document Image Analysis,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Using domain knowledge in lowlevel visual processing to interpret handwritten music: an experiment , 1988. A critical survey of music image analysis Structured document image analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Using domain knowledge in lowlevel visual processing to interpret handwritten music: an experiment , 1988. A critical survey of music image analysis Structured document image analysis"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optical music recognition using projections, 1988. A critical survey of music image analysis Structured document image analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Optical music recognition using projections, 1988. A critical survey of music image analysis Structured document image analysis"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computer pattern recognition of standard engraved music notation, 1970. A critical survey of music image analysis Structured document image analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Computer pattern recognition of standard engraved music notation, 1970. A critical survey of music image analysis Structured document image analysis"
            },
            "year": 1992
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 54,
            "methodology": 50,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 144,
        "totalPages": 15
    },
    "page_url": "https://www.semanticscholar.org/paper/Optical-music-recognition:-state-of-the-art-and-Rebelo-Fujinaga/46ec9789856ddab19e3d0011cadc08b419b533f3?sort=total-citations"
}