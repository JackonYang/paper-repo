{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749815"
                        ],
                        "name": "A. Sperduti",
                        "slug": "A.-Sperduti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sperduti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sperduti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678493"
                        ],
                        "name": "A. Starita",
                        "slug": "A.-Starita",
                        "structuredName": {
                            "firstName": "Antonina",
                            "lastName": "Starita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Starita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 35
                            }
                        ],
                        "text": "Recursive networks as presented in [24, 30, 33, 90] process tree structures as inputs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 86
                            }
                        ],
                        "text": "Various alternative training schemes have recently been adapted to recursive networks [8, 18, 90] and widespread successful applications of recursive networks can be found in the literature such as theorem proving [30], discourse representation theory [13], picture processing [18], document image classification [21], connectivity prediction for molecules [100], natural language parsing [92], protein structure prediction [73], and chemistry [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5942593,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e33eca03933caaec671e20692e79d1acc9527e1",
            "isKey": false,
            "numCitedBy": 486,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard neural networks and statistical methods are usually believed to be inadequate when dealing with complex structures because of their feature-based approach. In fact, feature-based approaches usually fail to give satisfactory solutions because of the sensitivity of the approach to the a priori selection of the features, and the incapacity to represent any specific information on the relationships among the components of the structures. However, we show that neural networks can, in fact, represent and classify structured patterns. The key idea underpinning our approach is the use of the so called \"generalized recursive neuron\", which is essentially a generalization to structures of a recurrent neuron. By using generalized recursive neurons, all the supervised networks developed for the classification of sequences, such as backpropagation through time networks, real-time recurrent networks, simple recurrent networks, recurrent cascade correlation networks, and neural trees can, on the whole, be generalized to structures. The results obtained by some of the above networks (with generalized recursive neurons) on the classification of logic terms are presented."
            },
            "slug": "Supervised-neural-networks-for-the-classification-Sperduti-Starita",
            "title": {
                "fragments": [],
                "text": "Supervised neural networks for the classification of structures"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that neural networks can, in fact, represent and classify structured patterns and all the supervised networks developed for the classification of sequences can, on the whole, be generalized to structures."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749815"
                        ],
                        "name": "A. Sperduti",
                        "slug": "A.-Sperduti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sperduti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sperduti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 35
                            }
                        ],
                        "text": "Recursive networks as presented in [24, 30, 33, 90] process tree structures as inputs."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6197973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5eb96540ef53b49eac2246d6b13635fe6e54451",
            "isKey": false,
            "numCitedBy": 467,
            "numCiting": 100,
            "paperAbstract": {
                "fragments": [],
                "text": "A structured organization of information is typically required by symbolic processing. On the other hand, most connectionist models assume that data are organized according to relatively poor structures, like arrays or sequences. The framework described in this paper is an attempt to unify adaptive models like artificial neural nets and belief nets for the problem of processing structured information. In particular, relations between data variables are expressed by directed acyclic graphs, where both numerical and categorical values coexist. The general framework proposed in this paper can be regarded as an extension of both recurrent neural networks and hidden Markov models to the case of acyclic graphs. In particular we study the supervised learning problem as the problem of learning transductions from an input structured space to an output structured space, where transductions are assumed to admit a recursive hidden statespace representation. We introduce a graphical formalism for representing this class of adaptive transductions by means of recursive networks, i.e., cyclic graphs where nodes are labeled by variables and edges are labeled by generalized delay elements. This representation makes it possible to incorporate the symbolic and subsymbolic nature of data. Structures are processed by unfolding the recursive network into an acyclic graph called encoding network. In so doing, inference and learning algorithms can be easily inherited from the corresponding algorithms for artificial neural networks or probabilistic graphical model."
            },
            "slug": "A-general-framework-for-adaptive-processing-of-data-Frasconi-Gori",
            "title": {
                "fragments": [],
                "text": "A general framework for adaptive processing of data structures"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The framework described in this paper is an attempt to unify adaptive models like artificial neural nets and belief nets for the problem of processing structured information, where relations between data variables are expressed by directed acyclic graphs, where both numerical and categorical values coexist."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4562073"
                        ],
                        "name": "C. Watkins",
                        "slug": "C.-Watkins",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Watkins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Watkins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 16
                            }
                        ],
                        "text": "In the articles [37, 102], the basic principle of composite kernels is introduced."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17875902,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dd9743183f07b7653cc0335fcc1042aa71032c6",
            "isKey": false,
            "numCitedBy": 232,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "There is much current interest in kernel methods for classi cation re gression PCA and other linear methods of data analysis Kernel methods may be particularly valuable for problems in which the input data is not readily described by explicit feature vectors One such problem is where input data consists of symbol sequences of di erent lengths and the re lationships between sequences are best captured by dynamic alignment scores This paper shows that the scores produced by certain dynamic align ment algorithms for sequences are in fact valid kernel functions This is proved by expressing the alignment scores explicitly as dot products Alignment kernels are potentially applicable to biological sequence data speech data and time series data The kernel construction may be extended from pair HMMs to pair probabilistic context free grammars Introduction Linear Methods using Kernel Functions Introduction Linear Methods using Kernel Functions In many types of machine learning the learner is given a training set of cases or examples a al A A denotes the set of all possible cases cases may be vectors pieces of text biological sequences sentences etc For supervised learning the cases are accompanied by a set of corresponding labels or values y yl The cases are mapped to feature vectors x xl X where the X is a real vector space termed the feature space The mapping from A to X is denoted by so that xi ai Sometimes the cases are given as feature vectors to start with in which case may be the identity mapping otherwise denotes the method of assigning numeric feature values to a case Once a feature vector xi has been de ned for each case ai it becomes pos sible to apply a wide range of linear methods such as support vector machines linear regression principal components analysis PCA and k means cluster analysis As shown in Vap for SV machines in for example Wah for linear re gression and in SSM for PCA and k means cluster analysis the calculations for all of these linear methods may be carried out using a dual rather than a primal formulation of the problem For example in linear least squares regression the primal formulation is to nd a coe cient vector that minimises kX yk whereX is the design matrix an l by d matrix in which the ith row is xi and each xi has d elements If l is larger than d the usual method of nding is to solve the normal equations XX Xy This requires the solution of a set of linear equations with coe cients given by the d d matrix XX The dual formulation is to nd a coe cient vector that minimises kXX yk so that one coe cient i is found for each case vector xi This requires the solution of a set of linear equations with coe cients given by the l l matrix XX Both methods lead to the same predicted value y for a new case x If there are more cases than features that is if l d the primal method is more economical because the d d matrix XX is smaller than the l l matrix XX For example if there are cases each described by a vector of measurements then the primal method requires solving a by system of linear equations while the dual method requires solving a by system which will have rank at most For such a problem the dual method has no advantage The potential advantage of the dual method for regression is that it can be applied to very large feature vectors The coe cient matrix XX contains the dot products of pairs of feature vectors the ijth element of XX is xi xj In the dual calculation it is only dot products of feature vectors that are used feature vectors never appear on their own As the feature vectors xi ai appear only in dot products it is often possible to avoid computing the feature vectors and to compute dot products directly in some economical fashion from the case descriptions ai instead A kernel is a function k that computes a dot product of feature vectors from the corresponding cases Applying Linear Methods to Structured Objects De nition A kernel is a function k such that for all a b A"
            },
            "slug": "Dynamic-Alignment-Kernels-Watkins",
            "title": {
                "fragments": [],
                "text": "Dynamic Alignment Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows that the scores produced by certain dynamic align ment algorithms for sequences are in fact valid kernel functions, proved by expressing the alignment scores explicitly as dot products."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683776"
                        ],
                        "name": "Nicola Cancedda",
                        "slug": "Nicola-Cancedda",
                        "structuredName": {
                            "firstName": "Nicola",
                            "lastName": "Cancedda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicola Cancedda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732180"
                        ],
                        "name": "\u00c9ric Gaussier",
                        "slug": "\u00c9ric-Gaussier",
                        "structuredName": {
                            "firstName": "\u00c9ric",
                            "lastName": "Gaussier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c9ric Gaussier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2788842"
                        ],
                        "name": "Cyril Goutte",
                        "slug": "Cyril-Goutte",
                        "structuredName": {
                            "firstName": "Cyril",
                            "lastName": "Goutte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cyril Goutte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2822140"
                        ],
                        "name": "J. Renders",
                        "slug": "J.-Renders",
                        "structuredName": {
                            "firstName": "Jean-Michel",
                            "lastName": "Renders",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Renders"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 156
                            }
                        ],
                        "text": "Further improvement of the efficiency and accuracy of the approaches can be obtained when using words instead of single symbols for document classification [14] or extending the methods to transduction tasks [103]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5424754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9c086c216968ba7b453b03841c723a1f41671ed",
            "isKey": false,
            "numCitedBy": 251,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of categorising documents using kernel-based methods such as Support Vector Machines. Since the work of Joachims (1998), there is ample experimental evidence that SVM using the standard word frequencies as features yield state-of-the-art performance on a number of benchmark problems. Recently, Lodhi et al. (2002) proposed the use of string kernels, a novel way of computing document similarity based of matching non-consecutive subsequences of characters. In this article, we propose the use of this technique with sequences of words rather than characters. This approach has several advantages, in particular it is more efficient computationally and it ties in closely with standard linguistic pre-processing techniques. We present some extensions to sequence kernels dealing with symbol-dependent and match-dependent decay factors, and present empirical evaluations of these extensions on the Reuters-21578 datasets."
            },
            "slug": "Word-Sequence-Kernels-Cancedda-Gaussier",
            "title": {
                "fragments": [],
                "text": "Word-Sequence Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article proposes the use of string kernels, a novel way of computing document similarity based of matching non-consecutive subsequences of characters with sequences of words rather than characters, and presents some extensions to sequence kernels dealing with symbol-dependent and match-dependent decay factors."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784450"
                        ],
                        "name": "M. Hagenbuchner",
                        "slug": "M.-Hagenbuchner",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Hagenbuchner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hagenbuchner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749815"
                        ],
                        "name": "A. Sperduti",
                        "slug": "A.-Sperduti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sperduti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sperduti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733691"
                        ],
                        "name": "A. Tsoi",
                        "slug": "A.-Tsoi",
                        "structuredName": {
                            "firstName": "Ah",
                            "lastName": "Tsoi",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tsoi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "Thereby, the SOM for structured data [32] constitutes the first recursive SOM which has also been proposed for tree structured data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 100
                            }
                        ],
                        "text": "Efficient compression schemes using characteristics of only the winner neuron have been proposed in [32, 91] which achieve comparable results as the recursive SOM but which are computationally much more efficient."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14473161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26d24fc001bc5a8bf375b2f35f4f2e222995165c",
            "isKey": false,
            "numCitedBy": 204,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent developments in the area of neural networks produced models capable of dealing with structured data. Here, we propose the first fully unsupervised model, namely an extension of traditional self-organizing maps (SOMs), for the processing of labeled directed acyclic graphs (DAGs). The extension is obtained by using the unfolding procedure adopted in recurrent and recursive neural networks, with the replicated neurons in the unfolded network comprising of a full SOM. This approach enables the discovery of similarities among objects including vectors consisting of numerical data. The capabilities of the model are analyzed in detail by utilizing a relatively large data set taken from an artificial benchmark problem involving visual patterns encoded as labeled DAGs. The experimental results demonstrate clearly that the proposed model is capable of exploiting both information conveyed in the labels attached to each node of the input DAGs and information encoded in the DAG topology."
            },
            "slug": "A-self-organizing-map-for-adaptive-processing-of-Hagenbuchner-Sperduti",
            "title": {
                "fragments": [],
                "text": "A self-organizing map for adaptive processing of structured data"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This work proposes the first fully unsupervised model, namely an extension of traditional self-organizing maps (SOMs), for the processing of labeled directed acyclic graphs (DAGs) by using the unfolding procedure adopted in recurrent and recursive neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143684647"
                        ],
                        "name": "B. Hammer",
                        "slug": "B.-Hammer",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Hammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Hammer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41231471"
                        ],
                        "name": "A. Micheli",
                        "slug": "A.-Micheli",
                        "structuredName": {
                            "firstName": "Alessio",
                            "lastName": "Micheli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Micheli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749815"
                        ],
                        "name": "A. Sperduti",
                        "slug": "A.-Sperduti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sperduti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sperduti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775909"
                        ],
                        "name": "M. Strickert",
                        "slug": "M.-Strickert",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Strickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Strickert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13069120,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69da44a0c76e99aa1fbfe8fb501f5e68774d772a",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recursive-self-organizing-network-models-Hammer-Micheli",
            "title": {
                "fragments": [],
                "text": "Recursive self-organizing network models"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693945"
                        ],
                        "name": "T. G\u00e4rtner",
                        "slug": "T.-G\u00e4rtner",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "G\u00e4rtner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. G\u00e4rtner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4471326,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56fd28e8db60a696adc5b0f7acb9ef41d9ce1ec4",
            "isKey": false,
            "numCitedBy": 485,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Kernel methods in general and support vector machines in particular have been successful in various learning tasks on data represented in a single table. Much 'real-world' data, however, is structured - it has no natural representation in a single table. Usually, to apply kernel methods to 'real-world' data, extensive pre-processing is performed to embed the data into areal vector space and thus in a single table. This survey describes several approaches of defining positive definite kernels on structured instances directly."
            },
            "slug": "A-survey-of-kernels-for-structured-data-G\u00e4rtner",
            "title": {
                "fragments": [],
                "text": "A survey of kernels for structured data"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This survey describes several approaches of defining positive definite kernels on structured instances directly on the basis of areal vector space and thus in a single table."
            },
            "venue": {
                "fragments": [],
                "text": "SKDD"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775909"
                        ],
                        "name": "M. Strickert",
                        "slug": "M.-Strickert",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Strickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Strickert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143684647"
                        ],
                        "name": "B. Hammer",
                        "slug": "B.-Hammer",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Hammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Hammer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2418273,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e5f2e0db62ae50d79d2bd48d965580f526dc3c1",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "For unsupervised sequence processing, standard self organizing maps (SOM) can be naturally extended by recurrent connections and explicit context representations. Known models are the temporal Kohonen map (TKM), recursive SOM, SOM for structured data (SOMSD), and HSOM for sequences (HSOM-S). We discuss and compare the capabilities of exemplary approaches to store different types of sequences. A new efficient model, the Merge-SOM (MSOM), is proposed, combining ideas of TKM and SOMSD, and which is well suited for processing sequences with dynamic multimodal densities."
            },
            "slug": "Neural-Gas-for-Sequences-Strickert-Hammer",
            "title": {
                "fragments": [],
                "text": "Neural Gas for Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A new efficient model, the Merge-SOM (MSOM), is proposed, combining ideas of TKM and SOMSD, and which is well suited for processing sequences with dynamic multimodal densities."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143684647"
                        ],
                        "name": "B. Hammer",
                        "slug": "B.-Hammer",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Hammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Hammer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41231471"
                        ],
                        "name": "A. Micheli",
                        "slug": "A.-Micheli",
                        "structuredName": {
                            "firstName": "Alessio",
                            "lastName": "Micheli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Micheli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749815"
                        ],
                        "name": "A. Sperduti",
                        "slug": "A.-Sperduti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sperduti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sperduti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775909"
                        ],
                        "name": "M. Strickert",
                        "slug": "M.-Strickert",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Strickert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Strickert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16346377,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49c5f901f22bcc90bfe186bc2cfe98541fd55699",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 94,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-general-framework-for-unsupervised-processing-of-Hammer-Micheli",
            "title": {
                "fragments": [],
                "text": "A general framework for unsupervised processing of structured data"
            },
            "venue": {
                "fragments": [],
                "text": "Neurocomputing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47690405"
                        ],
                        "name": "P. Moreno",
                        "slug": "P.-Moreno",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Moreno",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Moreno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35541734"
                        ],
                        "name": "Purdy Ho",
                        "slug": "Purdy-Ho",
                        "structuredName": {
                            "firstName": "Purdy",
                            "lastName": "Ho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Purdy Ho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699559"
                        ],
                        "name": "N. Vasconcelos",
                        "slug": "N.-Vasconcelos",
                        "structuredName": {
                            "firstName": "Nuno",
                            "lastName": "Vasconcelos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vasconcelos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6831693,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f73f60fb07a979e53beac26c92eaaafb644a648",
            "isKey": false,
            "numCitedBy": 497,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the last years significant efforts have been made to develop kernels that can be applied to sequence data such as DNA, text, speech, video and images. The Fisher Kernel and similar variants have been suggested as good ways to combine an underlying generative model in the feature space and discriminant classifiers such as SVM's. In this paper we suggest an alternative procedure to the Fisher kernel for systematically finding kernel functions that naturally handle variable length sequence data in multimedia domains. In particular for domains such as speech and images we explore the use of kernel functions that take full advantage of well known probabilistic models such as Gaussian Mixtures and single full covariance Gaussian models. We derive a kernel distance based on the Kullback-Leibler (KL) divergence between generative models. In effect our approach combines the best of both generative and discriminative methods and replaces the standard SVM kernels. We perform experiments on speaker identification/verification and image classification tasks and show that these new kernels have the best performance in speaker verification and mostly outperform the Fisher kernel based SVM's and the generative classifiers in speaker identification and image classification."
            },
            "slug": "A-Kullback-Leibler-Divergence-Based-Kernel-for-SVM-Moreno-Ho",
            "title": {
                "fragments": [],
                "text": "A Kullback-Leibler Divergence Based Kernel for SVM Classification in Multimedia Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper suggests an alternative procedure to the Fisher kernel for systematically finding kernel functions that naturally handle variable length sequence data in multimedia domains and derives a kernel distance based on the Kullback-Leibler (KL) divergence between generative models."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144042991"
                        ],
                        "name": "Jun Suzuki",
                        "slug": "Jun-Suzuki",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Suzuki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Suzuki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115075487"
                        ],
                        "name": "Yutaka Sasaki",
                        "slug": "Yutaka-Sasaki",
                        "structuredName": {
                            "firstName": "Yutaka",
                            "lastName": "Sasaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yutaka Sasaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38178548"
                        ],
                        "name": "E. Maeda",
                        "slug": "E.-Maeda",
                        "structuredName": {
                            "firstName": "Eisaku",
                            "lastName": "Maeda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Maeda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 196
                            }
                        ],
                        "text": "The more general data structure of directed acyclic graphs can be addressed in a similar way, counting the number of matching or partially matching subtrees of two given structures as proposed in [19, 94, 108] and also in (Micheli/Portera/Sperduti, this volume)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 20606,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "799cda5e1a6015dc5f0a2a14acf96e1fa7d300dc",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper devises a novel kernel function for structured natural language data. In the field of Natural Language Processing, feature extraction consists of the following two steps: (1) syntactically and semantically analyzing raw data, i.e., character strings, then representing the results as discrete structures, such as parse trees and dependency graphs with part-of-speech tags; (2) creating (possibly high-dimensional) numerical feature vectors from the discrete structures. The new kernels, called Hierarchical Directed Acyclic Graph (HDAG) kernels, directly accept DAGs whose nodes can contain DAGs. HDAG data structures are needed to fully reflect the syntactic and semantic structures that natural language data inherently have. In this paper, we define the kernel function and show how it permits efficient calculation. Experiments demonstrate that the proposed kernels are superior to existing kernel functions, e.g., sequence kernels, tree kernels, and bag-of-words kernels."
            },
            "slug": "Kernels-for-Structured-Natural-Language-Data-Suzuki-Sasaki",
            "title": {
                "fragments": [],
                "text": "Kernels for Structured Natural Language Data"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper defines the kernel function and shows how it permits efficient calculation and proposes new kernels, called Hierarchical Directed Acyclic Graph (HDAG) kernels, which directly accept DAGs whose nodes can contain D AGs."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 130
                            }
                        ],
                        "text": "Finally, for pairwise clustering there are mean-field methods which can be used to iteratively compute cluster-membership weights [39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15479156,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a58c3eafcc642ffa2e571e069e53f20bb1d1150",
            "isKey": false,
            "numCitedBy": 538,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "Partitioning a data set and extracting hidden structure from the data arises in different application areas of pattern recognition, speech and image processing. Pairwise data clustering is a combinatorial optimization method for data grouping which extracts hidden structure from proximity data. We describe a deterministic annealing approach to pairwise clustering which shares the robustness properties of maximum entropy inference. The resulting Gibbs probability distributions are estimated by mean-field approximation. A new structure-preserving algorithm to cluster dissimilarity data and to simultaneously embed these data in a Euclidian vector space is discussed which can be used for dimensionality reduction and data visualization. The suggested embedding algorithm which outperforms conventional approaches has been implemented to analyze dissimilarity data from protein analysis and from linguistics. The algorithm for pairwise data clustering is used to segment textured images."
            },
            "slug": "Pairwise-Data-Clustering-by-Deterministic-Annealing-Hofmann-Buhmann",
            "title": {
                "fragments": [],
                "text": "Pairwise Data Clustering by Deterministic Annealing"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A deterministic annealing approach to pairwise clustering is described which shares the robustness properties of maximum entropy inference and the resulting Gibbs probability distributions are estimated by mean-field approximation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143684647"
                        ],
                        "name": "B. Hammer",
                        "slug": "B.-Hammer",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Hammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Hammer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 94
                            }
                        ],
                        "text": "Thus, they share most of the dynamic properties and difficulties of simple recurrent networks [33, 36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 35
                            }
                        ],
                        "text": "Recursive networks as presented in [24, 30, 33, 90] process tree structures as inputs."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15529289,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a0f2f018956189edf636d41672a47fa90530450",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 151,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis examines so-called folding neural networks as a mechanism for machine learning. Folding networks form a generalization of partial recurrent neural networks such that they are able to deal with tree structured inputs instead of simple linear lists. In particular, they can handle classical formulas { they were proposed originally for this purpose. After a short explanation of the neural architecture we show that folding networks are well suited as a learning mechanism in principle. This includes three parts: the proof of their universal approximation ability, the aspect of information theoretical learnability, and the examination of the complexity of training. Approximation ability: It is shown that any measurable function can be approximated in probability. Explicit bounds on the number of neurons result if only a nite number of points is dealt with. These bounds are new results in the case of simple recurrent networks, too. Several restrictions occur if a function is to be approximated in the maximum norm. Afterwards, we consider brie y the topic of computability. It is shown that a sigmoidal recurrent neural network can compute any mapping in exponential time. However, if the computation is subject to noise almost the capability of tree automata arises. Information theoretical learnability: This part contains several contributions to distribution dependent learnability: The notation of PAC and PUAC learnability, consistent PAC/ PUAC learnability, and scale sensitive versions are considered. We nd equivalent characterizations of these terms and examine their respective relation answering in particular an open question posed by Vidyasagar. It is shown at which level learnability only because of an encoding trick is possible. Two approaches from the literature which can guarantee distribution dependent learnability if the VC dimension of the concept class is in nite are generalized to function classes: The function class is strati ed according to the input space or according to a so-called luckiness function which depends on the output of the learning algorithm and the concrete training data. Afterwards, the VC, pseudo-, and fat shattering dimension of folding networks are estimated: We improve some lower bounds for recurrent networks and derive new lower bounds for the pseudodimension and lower and upper bounds for folding networks in general. As a consequence, folding architectures are not distribution independent learnable. Distribution dependent learnability can be guaranteed. Explicit bounds on the number of examples which guarantee valid generalization can be derived using the two approaches mentioned above. We examine in which cases these bounds are polynomial. Furthermore, we construct an explicit example for a learning scenario where an exponential number of examples is necessary. Complexity: It is shown that training a xed folding architecture with perceptron activation function is polynomial. Afterwards, a decision problem, the so-called loading problem, which is correlated to neural network training is examined. For standard multilayer feed-forward networks the following situations turn out to be NP-hard: Concerning the perceptron activation function, a classical result from the literature, the NP-hardness for varying input dimension, is generalized to arbitrary multilayer architectures. Additionally, NP-hardness can be found if the input dimension is xed but the number of neurons may vary in at least two hidden layers. Furthermore, the NP-hardness is examined if the number of patterns and number of hidden neurons are correlated. We nish with a generalization of the classical NP result as mentioned above to the sigmoidal activation function which is used in practical applications."
            },
            "slug": "Learning-with-recurrent-neural-networks-Hammer",
            "title": {
                "fragments": [],
                "text": "Learning with recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This thesis examines so-called folding neural networks as a mechanism for machine learning such that they are able to deal with tree structured inputs instead of simple linear lists and shows that folding networks are well suited as a learning mechanism in principle."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144026427"
                        ],
                        "name": "Gareth M. James",
                        "slug": "Gareth-M.-James",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "James",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gareth M. James"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784682"
                        ],
                        "name": "T. Hastie",
                        "slug": "T.-Hastie",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Hastie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hastie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 152
                            }
                        ],
                        "text": "Thus, linear techniques such as principal component analysis or linear discriminants and non-parametric models have been transferred to functional data [15, 22, 42]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16050693,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "8bab09a269c12dcf071a9e70d09a91a571ec6fb7",
            "isKey": false,
            "numCitedBy": 287,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a technique for extending the classical method of linear discriminant analysis (LDA) to data sets where the predictor variables are curves or functions. This procedure, which we call functional linear discriminant analysis (FLDA), is particularly useful when only fragments of the curves are observed. All the techniques associated with LDA can be extended for use with FLDA. In particular FLDA can be used to produce classifications on new (test) curves, give an estimate of the discriminant function between classes and provide a one\u2010 or two\u2010dimensional pictorial representation of a set of curves. We also extend this procedure to provide generalizations of quadratic and regularized discriminant analysis."
            },
            "slug": "Functional-linear-discriminant-analysis-for-sampled-James-Hastie",
            "title": {
                "fragments": [],
                "text": "Functional linear discriminant analysis for irregularly sampled curves"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "FLDA can be used to produce classifications on new (test) curves, give an estimate of the discriminant function between classes and provide a one\u2010 or two\u2010dimensional pictorial representation of a set of curves."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3209133"
                        ],
                        "name": "C. Leslie",
                        "slug": "C.-Leslie",
                        "structuredName": {
                            "firstName": "Christina",
                            "lastName": "Leslie",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leslie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24982365"
                        ],
                        "name": "Dengyong Zhou",
                        "slug": "Dengyong-Zhou",
                        "structuredName": {
                            "firstName": "Dengyong",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dengyong Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766703"
                        ],
                        "name": "A. Elisseeff",
                        "slug": "A.-Elisseeff",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Elisseeff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Elisseeff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144458655"
                        ],
                        "name": "William Stafford Noble",
                        "slug": "William-Stafford-Noble",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Noble",
                            "middleNames": [
                                "Stafford"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Stafford Noble"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 208
                            }
                        ],
                        "text": "Further improvement of the efficiency and accuracy of the approaches can be obtained when using words instead of single symbols for document classification [14] or extending the methods to transduction tasks [103]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 566534,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67f3e2d4823b783fb6e2969f6fe01757f077dba3",
            "isKey": false,
            "numCitedBy": 252,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "MOTIVATION\nBuilding an accurate protein classification system depends critically upon choosing a good representation of the input sequences of amino acids. Recent work using string kernels for protein data has achieved state-of-the-art classification performance. However, such representations are based only on labeled data--examples with known 3D structures, organized into structural classes--whereas in practice, unlabeled data are far more plentiful.\n\n\nRESULTS\nIn this work, we develop simple and scalable cluster kernel techniques for incorporating unlabeled data into the representation of protein sequences. We show that our methods greatly improve the classification performance of string kernels and outperform standard approaches for using unlabeled data, such as adding close homologs of the positive examples to the training data. We achieve equal or superior performance to previously presented cluster kernel methods and at the same time achieving far greater computational efficiency.\n\n\nAVAILABILITY\nSource code is available at www.kyb.tuebingen.mpg.de/bs/people/weston/semiprot. The Spider matlab package is available at www.kyb.tuebingen.mpg.de/bs/people/spider.\n\n\nSUPPLEMENTARY INFORMATION\nwww.kyb.tuebingen.mpg.de/bs/people/weston/semiprot."
            },
            "slug": "Semi-supervised-Protein-Classification-Using-Weston-Leslie",
            "title": {
                "fragments": [],
                "text": "Semi-supervised Protein Classification Using Cluster Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work develops simple and scalable cluster kernel techniques for incorporating unlabeled data into the representation of protein sequences and achieves equal or superior performance to previously presented cluster kernel methods and at the same time achieving far greater computational efficiency."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 168
                            }
                        ],
                        "text": "Approaches which do not fall in these realms are, for example, the dynamic link architecture [57], extensions of associative memories for storing and retrieving graphs [55, 64], or selforganizing winner-takes-all classifiers for structures [46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30339982,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e2e07158c19e4a4596ed66bd252d9d05eb601ba",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pattern-recognition-by-labeled-graph-matching-Malsburg",
            "title": {
                "fragments": [],
                "text": "Pattern recognition by labeled graph matching"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34628173"
                        ],
                        "name": "K. Tsuda",
                        "slug": "K.-Tsuda",
                        "structuredName": {
                            "firstName": "Koji",
                            "lastName": "Tsuda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tsuda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716788"
                        ],
                        "name": "M. Kawanabe",
                        "slug": "M.-Kawanabe",
                        "structuredName": {
                            "firstName": "Motoaki",
                            "lastName": "Kawanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kawanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2414086"
                        ],
                        "name": "G. R\u00e4tsch",
                        "slug": "G.-R\u00e4tsch",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "R\u00e4tsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. R\u00e4tsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3029782"
                        ],
                        "name": "S. Sonnenburg",
                        "slug": "S.-Sonnenburg",
                        "structuredName": {
                            "firstName": "S\u00f6ren",
                            "lastName": "Sonnenburg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sonnenburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "The approach [96] proposes the tangent vector of log-odds or TOP-kernel, which is very similar to the Fisher kernel, but directly derived from a classification model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11013893,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84cccc9e14e49a6c56147e4cd36bda2ffd70b683",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, Jaakkola and Haussler (1999) proposed a method for constructing kernel functions from probabilistic models. Their so-called Fisher kernel has been combined with discriminative classifiers such as support vector machines and applied successfully in, for example, DNA and protein analysis. Whereas the Fisher kernel is calculated from the marginal log-likelihood, we propose the TOP kernel derived from tangent vectors of posterior log-odds. Furthermore, we develop a theoretical framework on feature extractors from probabilistic models and use it for analyzing the TOP kernel. In experiments, our new discriminative TOP kernel compares favorably to the Fisher kernel."
            },
            "slug": "A-New-Discriminative-Kernel-from-Probabilistic-Tsuda-Kawanabe",
            "title": {
                "fragments": [],
                "text": "A New Discriminative Kernel from Probabilistic Models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a new discriminative TOP kernel derived from tangent vectors of posterior log-odds and develops a theoretical framework on feature extractors from probabilistic models and uses it for analyzing the TOP kernel."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1957294"
                        ],
                        "name": "Siu-Yeung Cho",
                        "slug": "Siu-Yeung-Cho",
                        "structuredName": {
                            "firstName": "Siu-Yeung",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Siu-Yeung Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8590720"
                        ],
                        "name": "Z. Chi",
                        "slug": "Z.-Chi",
                        "structuredName": {
                            "firstName": "Zheru",
                            "lastName": "Chi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Chi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144250750"
                        ],
                        "name": "W. Siu",
                        "slug": "W.-Siu",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Siu",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Siu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733691"
                        ],
                        "name": "A. Tsoi",
                        "slug": "A.-Tsoi",
                        "structuredName": {
                            "firstName": "Ah",
                            "lastName": "Tsoi",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tsoi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 86
                            }
                        ],
                        "text": "Various alternative training schemes have recently been adapted to recursive networks [8, 18, 90] and widespread successful applications of recursive networks can be found in the literature such as theorem proving [30], discourse representation theory [13], picture processing [18], document image classification [21], connectivity prediction for molecules [100], natural language parsing [92], protein structure prediction [73], and chemistry [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2542801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "adc0e29f90cd9f70533f9902c32f396e38079eed",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Many researchers have explored the use of neural-network representations for the adaptive processing of data structures. One of the most popular learning formulations of data structure processing is backpropagation through structure (BPTS). The BPTS algorithm has been successful applied to a number of learning tasks that involve structural patterns such as logo and natural scene classification. The main limitations of the BPTS algorithm are attributed to slow convergence speed and the long-term dependency problem for the adaptive processing of data structures. In this paper, an improved algorithm is proposed to solve these problems. The idea of this algorithm is to optimize the free learning parameters of the neural network in the node representation by using least-squares-based optimization methods in a layer-by-layer fashion. Not only can fast convergence speed be achieved, but the long-term dependency problem can also be overcome since the vanishing of gradient information is avoided when our approach is applied to very deep tree structures."
            },
            "slug": "An-improved-algorithm-for-learning-long-term-in-of-Cho-Chi",
            "title": {
                "fragments": [],
                "text": "An improved algorithm for learning long-term dependency problems in adaptive processing of data structures"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The idea of this algorithm is to optimize the free learning parameters of the neural network in the node representation by using least-squares-based optimization methods in a layer-by-layer fashion, which can fast convergence speed be achieved, and the long-term dependency problem can be overcome."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727076"
                        ],
                        "name": "H. Lodhi",
                        "slug": "H.-Lodhi",
                        "structuredName": {
                            "firstName": "Huma",
                            "lastName": "Lodhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Lodhi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144884649"
                        ],
                        "name": "C. Saunders",
                        "slug": "C.-Saunders",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Saunders",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Saunders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4562073"
                        ],
                        "name": "C. Watkins",
                        "slug": "C.-Watkins",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Watkins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Watkins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 155
                            }
                        ],
                        "text": "Thereby, the approaches differ with respect to the weighting of matches, whether partial matches are allowed, and whether substrings need to be contiguous [59, 63]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 669209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f330f1f472f860212b980bb9be81eff884f7f0e1",
            "isKey": false,
            "numCitedBy": 1643,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel kernel for comparing two text documents. The kernel is an inner product in the feature space consisting of all subsequences of length k. A subsequence is any ordered sequence of k characters occurring in the text though not necessarily contiguously. The subsequences are weighted by an exponentially decaying factor of their full length in the text, hence emphasising those occurrences which are close to contiguous. A direct computation of this feature vector would involve a prohibitive amount of computation even for modest values of k, since the dimension of the feature space grows exponentially with k. The paper describes how despite this fact the inner product can be efficiently evaluated by a dynamic programming technique. A preliminary experimental comparison of the performance of the kernel compared with a standard word feature space kernel [6] is made showing encouraging results."
            },
            "slug": "Text-Classification-using-String-Kernels-Lodhi-Saunders",
            "title": {
                "fragments": [],
                "text": "Text Classification using String Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A novel kernel is introduced for comparing two text documents consisting of an inner product in the feature space consisting of all subsequences of length k, which can be efficiently evaluated by a dynamic programming technique."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2019029"
                        ],
                        "name": "Chad M. Cumby",
                        "slug": "Chad-M.-Cumby",
                        "structuredName": {
                            "firstName": "Chad",
                            "lastName": "Cumby",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chad M. Cumby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10251072,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9742f2fcf29f759f02ec0446c019eec5372a771",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Kernel methods have gained a great deal of popularity in the machine learning community as a method to learn indirectly in high-dimensional feature spaces. Those interested in relational learning have recently begun to cast learning from structured and relational data in terms of kernel operations. \n \nWe describe a general family of kernel functions built up from a description language of limited expressivity and use it to study the benefits and drawbacks of kernel learning in relational domains. Learning with kernels in this family directly models learning over an expanded feature space constructed using the same description language. This allows us to examine issues of time complexity in terms of learning with these and other relational kernels, and how these relate to generalization ability. The tradeoffs between using kernels in a very high dimensional implicit space versus a restricted feature space, is highlighted through two experiments, in bioinformatics and in natural language processing."
            },
            "slug": "On-Kernel-Methods-for-Relational-Learning-Cumby-Roth",
            "title": {
                "fragments": [],
                "text": "On Kernel Methods for Relational Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A general family of kernel functions built up from a description language of limited expressivity is described and used to study the benefits and drawbacks of kernel learning in relational domains."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144884649"
                        ],
                        "name": "C. Saunders",
                        "slug": "C.-Saunders",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Saunders",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Saunders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2916561"
                        ],
                        "name": "Alexei Vinokourov",
                        "slug": "Alexei-Vinokourov",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Vinokourov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei Vinokourov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13026481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21494ed027e1c067563776f63840565a6b2e6b0d",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we show how the generation of documents can be thought of as a k-stage Markov process, which leads to a Fisher kernel from which the n-gram and string kernels can be re-constructed. The Fisher kernel view gives a more flexible insight into the string kernel and suggests how it can be parametrised in a way that reflects the statistics of the training corpus. Furthermore, the probabilistic modelling approach suggests extending the Markov process to consider sub-sequences of varying length, rather than the standard fixed-length approach used in the string kernel. We give a procedure for determining which sub-sequences are informative features and hence generate a Finite State Machine model, which can again be used to obtain a Fisher kernel. By adjusting the parametrisation we can also influence the weighting received by the features. In this way we are able to obtain a logarithmic weighting in a Fisher kernel. Finally, experiments are reported comparing the different kernels using the standard Rag of Words kernel as a baseline."
            },
            "slug": "String-Kernels,-Fisher-Kernels-and-Finite-State-Saunders-Shawe-Taylor",
            "title": {
                "fragments": [],
                "text": "String Kernels, Fisher Kernels and Finite State Automata"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This paper shows how the generation of documents can be thought of as a k-stage Markov process, which leads to a Fisher kernel from which the n-gram and string kernels can be re-constructed, and suggests how the Fisher kernel view gives a more flexible insight into the string kernel."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2713667"
                        ],
                        "name": "S. G\u00fcnter",
                        "slug": "S.-G\u00fcnter",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "G\u00fcnter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. G\u00fcnter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 29
                            }
                        ],
                        "text": "At the same time, G\u00a8unter and Bunke [31] extended the SOM algorithm to\nattributed graphs by means of the edit distance and a generalization of the weighted mean of a set of graphs [49]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "At the same time, G \u0308 unter and Bunke [31] extended the SOM algorithm to ESANN'2004 proceedings - European Symposium on Artificial Neural Networks Bruges (Belgium), 28-30 April 2004, d-side publi."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33235442,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a25befdea5c72d099dd2a2f19f656053f96ab27c",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Self-organizing-map-for-clustering-in-the-graph-G\u00fcnter-Bunke",
            "title": {
                "fragments": [],
                "text": "Self-organizing map for clustering in the graph domain"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2834541"
                        ],
                        "name": "R. Kondor",
                        "slug": "R.-Kondor",
                        "structuredName": {
                            "firstName": "Risi",
                            "lastName": "Kondor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kondor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768120"
                        ],
                        "name": "T. Jebara",
                        "slug": "T.-Jebara",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Jebara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jebara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2682584,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e55cd4297a43cac83203ab7dee1fc2064e4a5ac",
            "isKey": false,
            "numCitedBy": 289,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In various application domains, including image recognition, it is natural to represent each example as a set of vectors. With a base kernel we can implicitly map these vectors to a Hilbert space and fit a Gaussian distribution to the whole set using Kernel PCA. We define our kernel between examples as Bhattacharyya's measure of affinity between such Gaussians. The resulting kernel is computable in closed form and enjoys many favorable properties, including graceful behavior under transformations, potentially justifying the vector set representation even in cases when more conventional representations also exist."
            },
            "slug": "A-Kernel-Between-Sets-of-Vectors-Kondor-Jebara",
            "title": {
                "fragments": [],
                "text": "A Kernel Between Sets of Vectors"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The kernel between examples is defined as Bhattacharyya's measure of affinity between Gaussians, which is computable in closed form and enjoys many favorable properties, including graceful behavior under transformations, potentially justifying the vector set representation even in cases when more conventional representations also exist."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 16
                            }
                        ],
                        "text": "In the articles [37, 102], the basic principle of composite kernels is introduced."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17702358,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "5ee0d8aeb2cb01ef4d8a858d234e72a7400c03ac",
            "isKey": false,
            "numCitedBy": 1371,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new method of constructing kernels on sets whose elements are discrete structures like strings, trees and graphs. The method can be applied iteratively to build a kernel on a innnite set from kernels involving generators of the set. The family of kernels generated generalizes the family of radial basis kernels. It can also be used to deene kernels in the form of joint Gibbs probability distributions. Kernels can be built from hidden Markov random elds, generalized regular expressions, pair-HMMs, or ANOVA de-compositions. Uses of the method lead to open problems involving the theory of innnitely divisible positive deenite functions. Fundamentals of this theory and the theory of reproducing kernel Hilbert spaces are reviewed and applied in establishing the validity of the method."
            },
            "slug": "Convolution-kernels-on-discrete-structures-Haussler",
            "title": {
                "fragments": [],
                "text": "Convolution kernels on discrete structures"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A new method of constructing kernels on sets whose elements are discrete structures like strings, trees and graphs is introduced, which can be applied iteratively to build a kernel on a innnite set from kernels involving generators of the set."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2756664"
                        ],
                        "name": "K. Sch\u00e4dler",
                        "slug": "K.-Sch\u00e4dler",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Sch\u00e4dler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sch\u00e4dler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681964"
                        ],
                        "name": "F. Wysotzki",
                        "slug": "F.-Wysotzki",
                        "structuredName": {
                            "firstName": "Fritz",
                            "lastName": "Wysotzki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wysotzki"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 51
                            }
                        ],
                        "text": "To meet the requirements of practical applications [9, 48, 83, 84, 95], weights are annotated to the vertices and edges of an association graph to express the similarities between pairs of items of both graphs being matched."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "Since then this approach has been applied to learn structural prototypes of chemical compounds [83], to predict mutagenicity [84], and to similarity based recognition of segmented images [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16100016,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05e0dd8bc01bd128c339bc619e70d7dbb5d3cfcb",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 121,
            "paperAbstract": {
                "fragments": [],
                "text": "Labeled graphs are an appropriate and popular representation of structured objects in many domains. If the labels describe the properties of real world objects and their relations, finding the best match between two graphs turns out to be the weakly defined, NP-complete task of establishing a mapping between them that maps similar parts onto each other preserving as much as possible of their overall structural correspondence. In this paper, former approaches of structural matching and constraint relaxation by spreading activation in neural networks and the method of solving optimization tasks using Hopfield-style nets are combined. The approximate matching task is reformulated as the minimization of a quadratic energy function. The design of the approach enables the user to change the parameters and the dynamics of the net so that knowledge about matching preferences is included easily and transparently. In the last section, some examples demonstrate the successful application of this approach in classification and learning in the domain of organic chemistry."
            },
            "slug": "Comparing-Structures-Using-a-Hopfield-Style-Neural-Sch\u00e4dler-Wysotzki",
            "title": {
                "fragments": [],
                "text": "Comparing Structures Using a Hopfield-Style Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The former approaches of structural matching and constraint relaxation by spreading activation in neural networks and the method of solving optimization tasks using Hopfield-style nets are combined."
            },
            "venue": {
                "fragments": [],
                "text": "Applied Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767359"
                        ],
                        "name": "Michelangelo Diligenti",
                        "slug": "Michelangelo-Diligenti",
                        "structuredName": {
                            "firstName": "Michelangelo",
                            "lastName": "Diligenti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michelangelo Diligenti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 317,
                                "start": 313
                            }
                        ],
                        "text": "Various alternative training schemes have recently been adapted to recursive networks [8, 18, 90] and widespread successful applications of recursive networks can be found in the literature such as theorem proving [30], discourse representation theory [13], picture processing [18], document image classification [21], connectivity prediction for molecules [100], natural language parsing [92], protein structure prediction [73], and chemistry [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9651365,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f634f59aacef0d5a45692c8ffc1970ff5e3d441",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Classification is an important problem in image document processing and is often a preliminary step toward recognition, understanding, and information extraction. In this paper, the problem is formulated in the framework of concept learning and each category corresponds to the set of image documents with similar physical structure. We propose a solution based on two algorithmic ideas. First, we obtain a structured representation of images based on labeled XY-trees (this representation informs the learner about important relationships between image subconstituents). Second, we propose a probabilistic architecture that extends hidden Markov models for learning probability distributions defined on spaces of labeled trees. Finally, a successful application of this method to the categorization of commercial invoices is presented."
            },
            "slug": "Hidden-Tree-Markov-Models-for-Document-Image-Diligenti-Frasconi",
            "title": {
                "fragments": [],
                "text": "Hidden Tree Markov Models for Document Image Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A structured representation of images based on labeled XY-trees is obtained and a probabilistic architecture that extends hidden Markov models for learning probability distributions defined on spaces of labeled trees is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2853244"
                        ],
                        "name": "P. Somervuo",
                        "slug": "P.-Somervuo",
                        "structuredName": {
                            "firstName": "Panu",
                            "lastName": "Somervuo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Somervuo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [52], this approach is used to visualize proteins based on a similarity measure which punishes mismatches in pairwise aligned sequences."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "A very elegant and general solution has been proposed by Kohonen in [52]: a batch-SOM algorithm can be applied to any type of data by setting the prototypes to the generalized median, i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14498485,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8f87a5ab16764e61aef3cbadcc52ca927bb392d",
            "isKey": false,
            "numCitedBy": 250,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "How-to-make-large-self-organizing-maps-for-data-Kohonen-Somervuo",
            "title": {
                "fragments": [],
                "text": "How to make large self-organizing maps for nonvectorial data"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143857271"
                        ],
                        "name": "Nigel P. Duffy",
                        "slug": "Nigel-P.-Duffy",
                        "structuredName": {
                            "firstName": "Nigel",
                            "lastName": "Duffy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nigel P. Duffy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 396794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6c7adc28e20d361d5c35aa9808094b10f6a34d1",
            "isKey": false,
            "numCitedBy": 932,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the application of kernel methods to Natural Language Processing (NLP) problems. In many NLP tasks the objects being modeled are strings, trees, graphs or other discrete structures which require some mechanism to convert them into feature vectors. We describe kernels for various natural language structures, allowing rich, high dimensional representations of these structures. We show how a kernel over trees can be applied to parsing using the voted perceptron algorithm, and we give experimental results on the ATIS corpus of parse trees."
            },
            "slug": "Convolution-Kernels-for-Natural-Language-Collins-Duffy",
            "title": {
                "fragments": [],
                "text": "Convolution Kernels for Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown how a kernel over trees can be applied to parsing using the voted perceptron algorithm, and experimental results on the ATIS corpus of parse trees are given."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688355"
                        ],
                        "name": "P. Suganthan",
                        "slug": "P.-Suganthan",
                        "structuredName": {
                            "firstName": "Ponnuthurai",
                            "lastName": "Suganthan",
                            "middleNames": [
                                "Nagaratnam"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Suganthan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714572"
                        ],
                        "name": "E. Teoh",
                        "slug": "E.-Teoh",
                        "structuredName": {
                            "firstName": "Eam",
                            "lastName": "Teoh",
                            "middleNames": [
                                "Khwang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Teoh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144725854"
                        ],
                        "name": "D. Mital",
                        "slug": "D.-Mital",
                        "structuredName": {
                            "firstName": "Dinesh",
                            "lastName": "Mital",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mital"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Two conceptual extensions to that issue are noteworthy to mention: Suganthan et al. [ 93 ] relaxed the two way constraints imposed on the permutation matrix to an one way constraint for retrieving several occurrences of a model in a scene in parallel."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In the work [72, 76, 87,  93 , 107] the graph matching problem is casted on the more principled statistical physics setting in terms of the mean-field theory and combined with self-amplification, softmax and penalty terms to improve solution quality and convergence properties."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11918459,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d541e96f3db3e836209bd4001e8710bed53e6f00",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pattern-recognition-by-graph-matching-using-the-MFT-Suganthan-Teoh",
            "title": {
                "fragments": [],
                "text": "Pattern recognition by graph matching using the Potts MFT neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145536952"
                        ],
                        "name": "J. Kandola",
                        "slug": "J.-Kandola",
                        "structuredName": {
                            "firstName": "Jaz",
                            "lastName": "Kandola",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kandola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9712014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41b807511a65feac98485427597f9b45c892595b",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The standard representation of text documents as bags of words suffers from well known limitations, mostly due to its inability to exploit semantic similarity between terms. Attempts to incorporate some notion of term similarity include latent semantic indexing [8], the use of semantic networks [9], and probabilistic methods [5]. In this paper we propose two methods for inferring such similarity from a corpus. The first one defines word-similarity based on document-similarity and viceversa, giving rise to a system of equations whose equilibrium point we use to obtain a semantic similarity measure. The second method models semantic relations by means of a diffusion process on a graph defined by lexicon and co-occurrence information. Both approaches produce valid kernel functions parametrised by a real number. The paper shows how the alignment measure can be used to successfully perform model selection over this parameter. Combined with the use of support vector machines we obtain positive results."
            },
            "slug": "Learning-Semantic-Similarity-Kandola-Shawe-Taylor",
            "title": {
                "fragments": [],
                "text": "Learning Semantic Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes two methods for inferring semantic similarity from a corpus by means of diffusion process on a graph defined by lexicon and co-occurrence information and shows how the alignment measure can be used to successfully perform model selection over this parameter."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3209133"
                        ],
                        "name": "C. Leslie",
                        "slug": "C.-Leslie",
                        "structuredName": {
                            "firstName": "Christina",
                            "lastName": "Leslie",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leslie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709847"
                        ],
                        "name": "E. Eskin",
                        "slug": "E.-Eskin",
                        "structuredName": {
                            "firstName": "Eleazar",
                            "lastName": "Eskin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Eskin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144458655"
                        ],
                        "name": "William Stafford Noble",
                        "slug": "William-Stafford-Noble",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Noble",
                            "middleNames": [
                                "Stafford"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Stafford Noble"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 155
                            }
                        ],
                        "text": "Thereby, the approaches differ with respect to the weighting of matches, whether partial matches are allowed, and whether substrings need to be contiguous [59, 63]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5112756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2aec4a2aa286a0093bf124482ed106f7e965ee8b",
            "isKey": false,
            "numCitedBy": 334,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a class of string kernels, called mismatch kernels, for use with support vector machines (SVMs) in a discriminative approach to the protein classification problem. These kernels measure sequence similarity based on shared occurrences of -length subsequences, counted with up to mismatches, and do not rely on any generative model for the positive training sequences. We compute the kernels efficiently using a mismatch tree data structure and report experiments on a benchmark SCOP dataset, where we show that the mismatch kernel used with an SVM classifier performs as well as the Fisher kernel, the most successful method for remote homology detection, while achieving considerable computational savings."
            },
            "slug": "Mismatch-String-Kernels-for-SVM-Protein-Leslie-Eskin",
            "title": {
                "fragments": [],
                "text": "Mismatch String Kernels for SVM Protein Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A class of string kernels, called mismatch kernels, are introduced for use with support vector machines (SVMs) in a discriminative approach to the protein classification problem, and show that the mismatch kernel used with an SVM classifier performs as well as the Fisher kernel, the most successful method for remote homology detection."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144779803"
                        ],
                        "name": "Y. Yao",
                        "slug": "Y.-Yao",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683574"
                        ],
                        "name": "G. Marcialis",
                        "slug": "G.-Marcialis",
                        "structuredName": {
                            "firstName": "Gian",
                            "lastName": "Marcialis",
                            "middleNames": [
                                "Luca"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Marcialis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710171"
                        ],
                        "name": "F. Roli",
                        "slug": "F.-Roli",
                        "structuredName": {
                            "firstName": "Fabio",
                            "lastName": "Roli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Roli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 61
                            }
                        ],
                        "text": "Thereby, recursive networks compete with kernel methods, see [106] and (Micheli/Portera/Sperduti, this volume)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15405877,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b51a22ed529707869a77070b25d770b36da46ea",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Combining-flat-and-structured-representations-for-Yao-Marcialis",
            "title": {
                "fragments": [],
                "text": "Combining flat and structured representations for fingerprint classification with recursive neural networks and support vector machines"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152303545"
                        ],
                        "name": "Jean-Philippe Vert",
                        "slug": "Jean-Philippe-Vert",
                        "structuredName": {
                            "firstName": "Jean-Philippe",
                            "lastName": "Vert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Philippe Vert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87339519"
                        ],
                        "name": "M. Kanehisa",
                        "slug": "M.-Kanehisa",
                        "structuredName": {
                            "firstName": "Minoru",
                            "lastName": "Kanehisa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kanehisa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8629843,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d74bfa3505b5350a7c84732f3d51cf9fd66bd8b3",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm to extract features from high-dimensional gene expression profiles, based on the knowledge of a graph which links together genes known to participate to successive reactions in metabolic pathways. Motivated by the intuition that biologically relevant features are likely to exhibit smoothness with respect to the graph topology, the algorithm involves encoding the graph and the set of expression profiles into kernel functions, and performing a generalized form of canonical correlation analysis in the corresponding reproducible kernel Hilbert spaces. \n \nFunction prediction experiments for the genes of the yeast S. Cerevisiae validate this approach by showing a consistent increase in performance when a state-of-the-art classifier uses the vector of features instead of the original expression profile to predict the functional class of a gene."
            },
            "slug": "Graph-Driven-Feature-Extraction-From-Microarray-and-Vert-Kanehisa",
            "title": {
                "fragments": [],
                "text": "Graph-Driven Feature Extraction From Microarray Data Using Diffusion Kernels and Kernel CCA"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This approach is validated by showing a consistent increase in performance when a state-of-the-art classifier uses the vector of features instead of the original expression profile to predict the functional class of a gene."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144020416"
                        ],
                        "name": "M. Bianchini",
                        "slug": "M.-Bianchini",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Bianchini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bianchini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47260481"
                        ],
                        "name": "F. Scarselli",
                        "slug": "F.-Scarselli",
                        "structuredName": {
                            "firstName": "Franco",
                            "lastName": "Scarselli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Scarselli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 139
                            }
                        ],
                        "text": "Several generalizations of basic recursive models to better fit these type data have been proposed: recursive networks for acyclic graphs ([7] and (Bianchini/Maggini/Sarti/Scarselli, this volume)), bicausal networks for protein secondary structure prediction [4], an extension of recursive networks to lattices applied to protein contact map prediction [73], and contextual models for graph structures [65]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 437255,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a062f11edf3270f9b702767dca5bacf8ac0bbe2",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Recursive neural networks are conceived for processing graphs and extend the well-known recurrent model for processing sequences. In Frasconi et al. (1998), recursive neural networks can deal only with directed ordered acyclic graphs (DOAGs), in which the children of any given node are ordered. While this assumption is reasonable in some applications, it introduces unnecessary constraints in others. In this paper, it is shown that the constraint on the ordering can be relaxed by using an appropriate weight sharing, that guarantees the independence of the network output with respect to the permutations of the arcs leaving from each node. The method can be used with graphs having low connectivity and, in particular, few outcoming arcs. Some theoretical properties of the proposed architecture are given. They guarantee that the approximation capabilities are maintained, despite the weight sharing."
            },
            "slug": "Processing-directed-acyclic-graphs-with-recursive-Bianchini-Gori",
            "title": {
                "fragments": [],
                "text": "Processing directed acyclic graphs with recursive neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "It is shown that the constraint on the ordering can be relaxed by using an appropriate weight sharing, that guarantees the independence of the network output with respect to the permutations of the arcs leaving from each node."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107836"
                        ],
                        "name": "Patrick Sturt",
                        "slug": "Patrick-Sturt",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Sturt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick Sturt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144073418"
                        ],
                        "name": "Fabrizio Costa",
                        "slug": "Fabrizio-Costa",
                        "structuredName": {
                            "firstName": "Fabrizio",
                            "lastName": "Costa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabrizio Costa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152862473"
                        ],
                        "name": "V. Lombardo",
                        "slug": "V.-Lombardo",
                        "structuredName": {
                            "firstName": "Vincenzo",
                            "lastName": "Lombardo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lombardo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 393,
                                "start": 389
                            }
                        ],
                        "text": "Various alternative training schemes have recently been adapted to recursive networks [8, 18, 90] and widespread successful applications of recursive networks can be found in the literature such as theorem proving [30], discourse representation theory [13], picture processing [18], document image classification [21], connectivity prediction for molecules [100], natural language parsing [92], protein structure prediction [73], and chemistry [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15571448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4ab5a707aeab5d52f162136bab86f3d2b1ff8ad",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-first-pass-structural-attachment-with-and-Sturt-Costa",
            "title": {
                "fragments": [],
                "text": "Learning first-pass structural attachment preferences with dynamic grammars and recursive neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056613623"
                        ],
                        "name": "John D. Lafferty",
                        "slug": "John-D.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John D. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072373204"
                        ],
                        "name": "Guy Lebanon",
                        "slug": "Guy-Lebanon",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Lebanon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guy Lebanon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2575165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c66b39731b2d759c13971a09a66c72ce21950ee7",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A new family of kernels for statistical learning is introduced that exploits the geometric structure of statistical models. Based on the heat equation on the Riemannian manifold defined by the Fisher information metric, information diffusion kernels generalize the Gaussian kernel of Euclidean space, and provide a natural way of combining generative statistical modeling with non-parametric discriminative learning. As a special case, the kernels give a new approach to applying kernel-based learning algorithms to discrete data. Bounds on covering numbers for the new kernels are proved using spectral theory in differential geometry, and experimental results are presented for text classification."
            },
            "slug": "Information-Diffusion-Kernels-Lafferty-Lebanon",
            "title": {
                "fragments": [],
                "text": "Information Diffusion Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Information diffusion kernels generalize the Gaussian kernel of Euclidean space, and provide a natural way of combining generative statistical modeling with non-parametric discriminative learning."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2184725"
                        ],
                        "name": "Tianping Chen",
                        "slug": "Tianping-Chen",
                        "structuredName": {
                            "firstName": "Tianping",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianping Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118061163"
                        ],
                        "name": "Hong Chen",
                        "slug": "Hong-Chen",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [17], it is shown that a specific one-hidden layer functional network provides universal approximation of nonlinear continuous operators."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 124660901,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "bf78dac29aef05c5ccbe3cc64afc254715c14698",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The main concern of this paper is to give several strong results on neural network representation in an explicit form. Under very mild conditions a functional defined on a compact set in C(a, b) or LP(a, b), spaces of infinite dimensions, can be approximated arbitrarily well by a neural network with one hidden layer. In particular, if U is a compact set in C(a, b), is a bounded sigmoidal function, and f is a continuous functional defined on U. then for all U E U, f(u) can be approximated by where e,, FzJ. 8, are real numbers. U(.,) is the value of U eval- uated at point zJ. These results are a significant development beyond earlier works, where theorems of approximating contin- uous functions defined on R\", a space of finite dimension by neural networks with one hidden layer, were given. Finally, all the results are shown applicable to the approximation of the output of dynamic systems at any particular time. I. INTRODUCTION"
            },
            "slug": "Networks-with-Application-to-Dynamic-Systems-Chen-Chen",
            "title": {
                "fragments": [],
                "text": "Networks with Application to Dynamic Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "Several strong results on neural network representation in an explicit form are given, under very mild conditions a functional defined on a compact set in C(a, b) or LP, spaces of infinite dimensions, can be approximated arbitrarily well by a neural network with one hidden layer."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2834541"
                        ],
                        "name": "R. Kondor",
                        "slug": "R.-Kondor",
                        "structuredName": {
                            "firstName": "Risi",
                            "lastName": "Kondor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kondor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5525836,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6320770fe216ebbba769b9f0a006669b616a03d0",
            "isKey": false,
            "numCitedBy": 888,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "The application of kernel-based learning algorithms has, so far, largely been confined to realvalued data and a few special data types, such as strings. In this paper we propose a general method of constructing natural families of kernels over discrete structures, based on the matrix exponentiation idea. In particular, we focus on generating kernels on graphs, for which we propose a special class of exponential kernels called diffusion kernels, which are based on the heat equation and can be regarded as the discretization of the familiar Gaussian kernel of Euclidean space."
            },
            "slug": "Diffusion-Kernels-on-Graphs-and-Other-Discrete-Kondor-Lafferty",
            "title": {
                "fragments": [],
                "text": "Diffusion Kernels on Graphs and Other Discrete Input Spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper proposes a general method of constructing natural families of kernels over discrete structures, based on the matrix exponentiation idea, and focuses on generating kernels on graphs, for which a special class of exponential kernels called diffusion kernels are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784294"
                        ],
                        "name": "Georgios Siolas",
                        "slug": "Georgios-Siolas",
                        "structuredName": {
                            "firstName": "Georgios",
                            "lastName": "Siolas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Georgios Siolas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389671466"
                        ],
                        "name": "Florence d'Alch\u00e9-Buc",
                        "slug": "Florence-d'Alch\u00e9-Buc",
                        "structuredName": {
                            "firstName": "Florence",
                            "lastName": "d'Alch\u00e9-Buc",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florence d'Alch\u00e9-Buc"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7366142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fea6177e7da873bd7f558b7c3928da6ffff8586",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a generative model for constructing continuous word representations using mixtures of probabilistic PCAs. Applied to co-occurrence data, the model performs word clustering and allows the visualization of each cluster in a reduced space. In combination with a simple document model, it permits the definition of low-dimensional Fisher scores which are used as document features. We investigate the models' potential through kernel-based methods using the corresponding Fisher kernels."
            },
            "slug": "Mixtures-of-Probabilistic-PCAs-and-Fisher-Kernels-Siolas-d'Alch\u00e9-Buc",
            "title": {
                "fragments": [],
                "text": "Mixtures of Probabilistic PCAs and Fisher Kernels for Word and Document Modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A generative model for constructing continuous word representations using mixtures of probabilistic PCAs and the definition of low-dimensional Fisher scores which are used as document features is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4637416"
                        ],
                        "name": "R. Kree",
                        "slug": "R.-Kree",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Kree",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kree"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17113858"
                        ],
                        "name": "A. Zippelius",
                        "slug": "A.-Zippelius",
                        "structuredName": {
                            "firstName": "Annette",
                            "lastName": "Zippelius",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zippelius"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 168
                            }
                        ],
                        "text": "Approaches which do not fall in these realms are, for example, the dynamic link architecture [57], extensions of associative memories for storing and retrieving graphs [55, 64], or selforganizing winner-takes-all classifiers for structures [46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121757971,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28e2c47e93942a159c573488460bc612333b8263",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors extend the architecture of the Hopfield network, such that it can recognise transformed versions of a set of learnt prototypes. As an example they construct a network which can generalise over all topologically equivalent representations of graphs or images. The construction is based on two coupled networks: a Hopfield network to store and retrieve patterns and a preprocessor to transform the input data."
            },
            "slug": "Recognition-of-topological-features-of-graphs-and-Kree-Zippelius",
            "title": {
                "fragments": [],
                "text": "Recognition of topological features of graphs and images in neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The authors extend the architecture of the Hopfield network, such that it can recognise transformed versions of a set of learnt prototypes, to construct a network which can generalise over all topologically equivalent representations of graphs or images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2126256522"
                        ],
                        "name": "A. Bua",
                        "slug": "A.-Bua",
                        "structuredName": {
                            "firstName": "Antonella",
                            "lastName": "Bua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698572"
                        ],
                        "name": "Fabrizio Santini",
                        "slug": "Fabrizio-Santini",
                        "structuredName": {
                            "firstName": "Fabrizio",
                            "lastName": "Santini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabrizio Santini"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38453326,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9af905708c142c7521ae372b864e454c2e1c4cf0",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Connectionist semantic modeling in natural language processing (a typical symbolic domain) is still a challenging problem. This paper introduces a novel technique, combining Discourse Representation Theory (DRT) with Recursive Neural Networks (RNN) in order to yield a neural model capable to discover properties and relationships among constituents of a knowledge-base expressed by natural language sentences. DRT transforms sequences of sentences into directed ordered acyclic graphs, while RNNs are trained to deal with such structured data. The acquired information allows the network to reply on questions, the answers of which are not directly expressed into the knowledge-base. A simple experimental demonstration, drawn from the context of a fairy tales is presented. Finally, on-going research direction are pointed-out."
            },
            "slug": "Recursive-Neural-Networks-Applied-to-Discourse-Bua-Gori",
            "title": {
                "fragments": [],
                "text": "Recursive Neural Networks Applied to Discourse Representation Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A novel technique is introduced, combining Discourse Representation Theory (DRT) with Recursive Neural Networks (RNN) in order to yield a neural model capable to discover properties and relationships among constituents of a knowledge-base expressed by natural language sentences."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145713876"
                        ],
                        "name": "S. Vishwanathan",
                        "slug": "S.-Vishwanathan",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Vishwanathan",
                            "middleNames": [
                                "V.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vishwanathan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "As an alternative, string kernels can directly be applied to the prefix representation of trees as proposed in [98]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5118862,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72a7e7bc1911b6a327c4614553bfcde98194d4ef",
            "isKey": false,
            "numCitedBy": 350,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new algorithm suitable for matching discrete objects such as strings and trees in linear time, thus obviating dynamic programming with quadratic time complexity. Furthermore, prediction cost in many cases can be reduced to linear cost in the length of the sequence to be classified, regardless of the number of support vectors. This improvement on the currently available algorithms makes string kernels a viable alternative for the practitioner."
            },
            "slug": "Fast-Kernels-for-String-and-Tree-Matching-Vishwanathan-Smola",
            "title": {
                "fragments": [],
                "text": "Fast Kernels for String and Tree Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A new algorithm suitable for matching discrete objects such as strings and trees in linear time is presented, thus obviating dynamic programming with quadratic time complexity and improvement on the currently available algorithms makes string kernels a viable alternative for the practitioner."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690590"
                        ],
                        "name": "W. Li",
                        "slug": "W.-Li",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8147588"
                        ],
                        "name": "N. Nasrabadi",
                        "slug": "N.-Nasrabadi",
                        "structuredName": {
                            "firstName": "Nasser",
                            "lastName": "Nasrabadi",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nasrabadi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 90
                            }
                        ],
                        "text": "Early work uses binary threshold units and fixed penalty terms to express the constraints [61, 62, 68]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9560295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ddcab4c4e8da2673ebb09aff5fa573acdda72271",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A model-based object recognition technique is presented. For each model, distinct features such as curvature points are extracted, and a graph consisting of a number of nodes connected by arcs is constructed. Therefore, each node in the graph represents a feature that has an assigned feature type and a numerical feature value, and an arc between two nodes shows the relationship or compatibility between the features such as distances between feature points. Objects recognition is formulated as matching a model graph with an input image graph. A Hopfield binary network is implemented to perform a subgraph isomorphism to obtain optimum compatible matching features between graphs. The compatibility is defined so that it will tolerate the ambiguity of preprocessed features. The algorithm is also extended to detect one object among several objects which could be touching or overlapping. Some simulation results are shown to evaluate the performance of the system.<<ETX>>"
            },
            "slug": "Object-recognition-based-on-graph-matching-by-a-Li-Nasrabadi",
            "title": {
                "fragments": [],
                "text": "Object recognition based on graph matching implemented by a Hopfield-style neural network"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A model-based object recognition technique is presented that is formulated as matching a model graph with an input image graph and a Hopfield binary network is implemented to obtain optimum compatible matching features between graphs."
            },
            "venue": {
                "fragments": [],
                "text": "International 1989 Joint Conference on Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683726"
                        ],
                        "name": "G. Barreto",
                        "slug": "G.-Barreto",
                        "structuredName": {
                            "firstName": "Guilherme",
                            "lastName": "Barreto",
                            "middleNames": [
                                "De",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Barreto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769779"
                        ],
                        "name": "A. Araujo",
                        "slug": "A.-Araujo",
                        "structuredName": {
                            "firstName": "Aluizio",
                            "lastName": "Araujo",
                            "middleNames": [
                                "Fausto",
                                "Ribeiro"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Araujo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2492622"
                        ],
                        "name": "S. C. Kremer",
                        "slug": "S.-C.-Kremer",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Kremer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. C. Kremer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11182640,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28a6e11472d63359f2bc1cc2ccbeba4b9aaa906b",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 192,
            "paperAbstract": {
                "fragments": [],
                "text": "Spatiotemporal connectionist networks (STCNs) comprise an important class of neural models that can deal with patterns distributed in both time and space. In this article, we widen the application domain of the taxonomy for supervised STCNs recently proposed by Kremer (2001) to the unsupervised case. This is possible through a reinterpretation of the state vector as a vector of latent (hidden) variables, as proposed by Meinicke (2000). The goal of this generalized taxonomy is then to provide a nonlinear generative framework for describing unsupervised spatiotemporal networks, making it easier to compare and contrast their representational and operational characteristics. Computational properties, representational issues, and learning are also discussed, and a number of references to the relevant source publications are provided. It is argued that the proposed approach is simple and more powerful than the previous attempts from a descriptive and predictive viewpoint. We also discuss the relation of this taxonomy with automata theory and state-space modeling and suggest directions for further work."
            },
            "slug": "A-Taxonomy-for-Spatiotemporal-Connectionist-The-Barreto-Araujo",
            "title": {
                "fragments": [],
                "text": "A Taxonomy for Spatiotemporal Connectionist Networks Revisited: The Unsupervised Case"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This article widens the application domain of the taxonomy for supervised STCNs recently proposed by Kremer (2001) to the unsupervised case, and argues that the proposed approach is simple and more powerful than the previous attempts from a descriptive and predictive viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145155628"
                        ],
                        "name": "P. Rodr\u00edguez",
                        "slug": "P.-Rodr\u00edguez",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Rodr\u00edguez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Rodr\u00edguez"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5165939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0585d60c1fe5b4c5fde208ecde015aacba8562e",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "It has been shown that if a recurrent neural network (RNN) learns to process a regular language, one can extract a finite-state machine (FSM) by treating regions of phase-space as FSM states. However, it has also been shown that one can construct an RNN to implement Turing machines by using RNN dynamics as counters. But how does a network learn languages that require counting? Rodriguez, Wiles, and Elman (1999) showed that a simple recurrent network (SRN) can learn to process a simple context-free language (CFL) by counting up and down. This article extends that to show a range of language tasks in which an SRN develops solutions that not only count but also copy and store counting information. In one case, the network stores information like an explicit storage mechanism. In other cases, the network stores information more indirectly in trajectories that are sensitive to slight displacements that depend on context. In this sense, an SRN can learn analog computation as a set of interdependent counters. This demonstrates how SRNs may be an alternative psychological model of language or sequence processing."
            },
            "slug": "Simple-Recurrent-Networks-Learn-Context-Free-and-by-Rodr\u00edguez",
            "title": {
                "fragments": [],
                "text": "Simple Recurrent Networks Learn Context-Free and Context-Sensitive Languages by Counting"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A range of language tasks are shown in which an SRN develops solutions that not only count but also copy and store counting information, demonstrating how SRNs may be an alternative psychological model of language or sequence processing."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103801794"
                        ],
                        "name": "Xiao-Yue Jiang",
                        "slug": "Xiao-Yue-Jiang",
                        "structuredName": {
                            "firstName": "Xiao-Yue",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao-Yue Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069666777"
                        ],
                        "name": "Andreas M\u00fcnger",
                        "slug": "Andreas-M\u00fcnger",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "M\u00fcnger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas M\u00fcnger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "attributed graphs by means of the edit distance and a generalization of the weighted mean of a set of graphs [49]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16820379,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4b173d00f344f6f4a4b860f3fd2bff9d48179ec",
            "isKey": false,
            "numCitedBy": 246,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "In object prototype learning and similar tasks, median computation is an important technique for capturing the essential information of a given set of patterns. We extend the median concept to the domain of graphs. In terms of graph distance, we introduce the novel concepts of set median and generalized median of a set of graphs. We study properties of both types of median graphs. For the more complex task of computing generalized median graphs, a genetic search algorithm is developed. Experiments conducted on randomly generated graphs demonstrate the advantage of generalized median graphs compared to set median graphs and the ability of our genetic algorithm to find approximate generalized median graphs in reasonable time. Application examples with both synthetic and nonsynthetic data are shown to illustrate the practical usefulness of the concept of median graphs."
            },
            "slug": "On-Median-Graphs:-Properties,-Algorithms,-and-Jiang-M\u00fcnger",
            "title": {
                "fragments": [],
                "text": "On Median Graphs: Properties, Algorithms, and Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work extends the median concept to the domain of graphs and introduces the novel concepts of set median and generalized median of a set of graphs, and studies properties of both types of median graphs."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2785830"
                        ],
                        "name": "H. Kashima",
                        "slug": "H.-Kashima",
                        "structuredName": {
                            "firstName": "Hisashi",
                            "lastName": "Kashima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kashima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34628173"
                        ],
                        "name": "K. Tsuda",
                        "slug": "K.-Tsuda",
                        "structuredName": {
                            "firstName": "Koji",
                            "lastName": "Tsuda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tsuda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35237557"
                        ],
                        "name": "Akihiro Inokuchi",
                        "slug": "Akihiro-Inokuchi",
                        "structuredName": {
                            "firstName": "Akihiro",
                            "lastName": "Inokuchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akihiro Inokuchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5129873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dfd92c808487049ab4c9b45db77e9055b9da5a2",
            "isKey": false,
            "numCitedBy": 808,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "A new kernel function between two labeled graphs is presented. Feature vectors are defined as the counts of label paths produced by random walks on graphs. The kernel computation finally boils down to obtaining the stationary state of a discrete-time linear system, thus is efficiently performed by solving simultaneous linear equations. Our kernel is based on an infinite dimensional feature space, so it is fundamentally different from other string or tree kernels based on dynamic programming. We will present promising empirical results in classification of chemical compounds."
            },
            "slug": "Marginalized-Kernels-Between-Labeled-Graphs-Kashima-Tsuda",
            "title": {
                "fragments": [],
                "text": "Marginalized Kernels Between Labeled Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A new kernel function between two labeled graphs that is based on an infinite dimensional feature space, so it is fundamentally different from other string or tree kernels based on dynamic programming and presents promising empirical results in classification of chemical compounds."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2408604"
                        ],
                        "name": "T. Voegtlin",
                        "slug": "T.-Voegtlin",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Voegtlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Voegtlin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 130
                            }
                        ],
                        "text": "The recursive SOM constitutes a more powerful though computationally quite complex model which relies on the whole map activation [99]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17451903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e0f9c313b093967e38b951f92535d5927c9e326",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recursive-self-organizing-maps-Voegtlin",
            "title": {
                "fragments": [],
                "text": "Recursive self-organizing maps"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791054"
                        ],
                        "name": "A. Sanfeliu",
                        "slug": "A.-Sanfeliu",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Sanfeliu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sanfeliu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97306284"
                        ],
                        "name": "K. Fu",
                        "slug": "K.-Fu",
                        "structuredName": {
                            "firstName": "King-Sun",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 157
                            }
                        ],
                        "text": "The GMP refers to finding a structure preserving correspondence between the vertices of two different graphs such that some similarity function is maximized [81, 86]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1087693,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea65866e3d1fd3e3e630005147e373ff7a886009",
            "isKey": false,
            "numCitedBy": 928,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "A method to determine a distance measure between two nonhierarchical attributed relational graphs is presented. In order to apply this distance measure, the graphs are characterised by descriptive graph grammars (DGG). The proposed distance measure is based on the computation of the minimum number of modifications required to transform an input graph into the reference one. Specifically, the distance measure is defined as the cost of recognition of nodes plus the number of transformations which include node insertion, node deletion, branch insertion, branch deletion, node label substitution and branch label substitution. The major difference between the proposed distance measure and the other ones is the consideration of the cost of recognition of nodes in the distance computation. In order to do this, the principal features of the nodes are described by one or several cost functions which are used to compute the similarity between the input nodes and the reference ones. Finally, an application of this distance measure to the recognition of lower case handwritten English characters is presented."
            },
            "slug": "A-distance-measure-between-attributed-relational-Sanfeliu-Fu",
            "title": {
                "fragments": [],
                "text": "A distance measure between attributed relational graphs for pattern recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A method to determine a distance measure between two nonhierarchical attributed relational graphs is presented and an application of this distance measure to the recognition of lower case handwritten English characters is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152303545"
                        ],
                        "name": "Jean-Philippe Vert",
                        "slug": "Jean-Philippe-Vert",
                        "structuredName": {
                            "firstName": "Jean-Philippe",
                            "lastName": "Vert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Philippe Vert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87339519"
                        ],
                        "name": "M. Kanehisa",
                        "slug": "M.-Kanehisa",
                        "structuredName": {
                            "firstName": "Minoru",
                            "lastName": "Kanehisa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kanehisa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "links genes which participate in successive reactions in metabolic pathways [97]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15998974,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db483038912798aa374e5083fbd4776c0f28e220",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Gene function prediction from microarray data is a rst step toward better understanding the machinery of the cell from relatively cheap and easy-to-produce data. In this paper we investigate whether the knowledge of many metabolic pathways and their catalyzing enzymes accumulated over the years can help improve the performance of classiers for this problem. The complex network of known biochemical reactions in the cell results in a representation where genes are nodes of a graph. Formulating the problem as a graph-driven features extraction problem, based on the simple idea that relevant features are likely to exhibit correlation with respect to the topology of the graph, we end up with an algorithm which involves encoding the network and the set of expression proles into kernel functions, and performing a regularized form of canonical correlation analysis in the corresponding reproducible kernel Hilbert spaces. Function prediction experiments for the genes of the yeast S. Cerevisiae validate this approach by showing a consistent increase in performance when a state-of-the-art classier uses the vector of features instead of the original expression prole to predict the functional class of a gene."
            },
            "slug": "Graph-driven-features-extraction-from-microarray-Vert-Kanehisa",
            "title": {
                "fragments": [],
                "text": "Graph-driven features extraction from microarray data"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper investigates whether the knowledge of many metabolic pathways and their catalyzing enzymes accumulated over the years can help improve the performance of classiers forGene function prediction from microarray data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143961030"
                        ],
                        "name": "J. Pr\u00edncipe",
                        "slug": "J.-Pr\u00edncipe",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Pr\u00edncipe",
                            "middleNames": [
                                "Carlos"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pr\u00edncipe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2290387"
                        ],
                        "name": "N. Euliano",
                        "slug": "N.-Euliano",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Euliano",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Euliano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9705075"
                        ],
                        "name": "S. Garani",
                        "slug": "S.-Garani",
                        "structuredName": {
                            "firstName": "Shayan",
                            "lastName": "Garani",
                            "middleNames": [
                                "Srinivasa"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Garani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 156
                            }
                        ],
                        "text": "Most unsupervised recursive models have been proposed only for temporal data, and they obey a simple dynamics given by leaky integrators or traveling waves [16, 74, 104]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16850987,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32c9e17b572f3d23e4e824160b8d33c79600b9e9",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Principles-and-networks-for-self-organization-in-Pr\u00edncipe-Euliano",
            "title": {
                "fragments": [],
                "text": "Principles and networks for self-organization in space-time"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41231471"
                        ],
                        "name": "A. Micheli",
                        "slug": "A.-Micheli",
                        "structuredName": {
                            "firstName": "Alessio",
                            "lastName": "Micheli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Micheli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727490"
                        ],
                        "name": "Diego Sona",
                        "slug": "Diego-Sona",
                        "structuredName": {
                            "firstName": "Diego",
                            "lastName": "Sona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diego Sona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749815"
                        ],
                        "name": "A. Sperduti",
                        "slug": "A.-Sperduti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sperduti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sperduti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12370239,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "443077eb859540108d3adb5f2fa42b394ddf2a06",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper propose a first approach to deal with contextual information in structured domains by recursive neural networks. The proposed model, i.e., contextual recursive cascade correlation (CRCC), a generalization of the recursive cascade correlation (RCC) model, is able to partially remove the causality assumption by exploiting contextual information stored in frozen units. We formally characterize the properties of CRCC showing that it is able to compute contextual transductions and also some causal supersource transductions that RCC cannot compute. Experimental results on controlled sequences and on a real-world task involving chemical structures confirm the computational limitations of RCC, while assessing the efficiency and efficacy of CRCC in dealing both with pure causal and contextual prediction tasks. Moreover, results obtained for the real-world task show the superiority of the proposed approach versus RCC when exploring a task for which it is not known whether the structural causality assumption holds."
            },
            "slug": "Contextual-processing-of-structured-data-by-cascade-Micheli-Sona",
            "title": {
                "fragments": [],
                "text": "Contextual processing of structured data by recursive cascade correlation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results obtained for the real-world task show the superiority of the proposed approach versus RCC when exploring a task for which it is not known whether the structural causality assumption holds, as well as assessing the efficiency and efficacy of CRCC in dealing both with pure causal and contextual prediction tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707908"
                        ],
                        "name": "B. Jain",
                        "slug": "B.-Jain",
                        "structuredName": {
                            "firstName": "Brijnesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681964"
                        ],
                        "name": "F. Wysotzki",
                        "slug": "F.-Wysotzki",
                        "structuredName": {
                            "firstName": "Fritz",
                            "lastName": "Wysotzki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wysotzki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 240
                            }
                        ],
                        "text": "Approaches which do not fall in these realms are, for example, the dynamic link architecture [57], extensions of associative memories for storing and retrieving graphs [55, 64], or selforganizing winner-takes-all classifiers for structures [46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14570430,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b80e9bc2c4f131e3f441a4771e239658cfddef9",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a winner-takes-all (WTA) classifier for structures represented by graphs. WTA classification follows the principle elimination of competition. The input structure is assigned to the class corresponding to the winner of the competition. In experiments we investigate the performance of the WTA classifier and compare it with the canonical maximum similarity (MS) classifier."
            },
            "slug": "A-Competitive-Winner-Takes-All-Architecture-for-and-Jain-Wysotzki",
            "title": {
                "fragments": [],
                "text": "A Competitive Winner-Takes-All Architecture for Classification and Pattern Recognition of Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A winner-takes-all (WTA) classifier for structures represented by graphs that follows the principle elimination of competition is proposed and the performance of the WTA classifier is investigated and compared with the canonical maximum similarity classifier."
            },
            "venue": {
                "fragments": [],
                "text": "GbRPR"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35380459"
                        ],
                        "name": "S. Gold",
                        "slug": "S.-Gold",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Gold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145257017"
                        ],
                        "name": "Anand Rangarajan",
                        "slug": "Anand-Rangarajan",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Rangarajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anand Rangarajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705072"
                        ],
                        "name": "E. Mjolsness",
                        "slug": "E.-Mjolsness",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Mjolsness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Mjolsness"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 3
                            }
                        ],
                        "text": "In [29, 47] simple competitive learning algorithms for clustering weighted graphs are proposed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3075273,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29017216d926309d2b428991ac1e9b0b2d261a2f",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Prior knowledge constraints are imposed upon a learning problem in the form of distance measures. Prototypical 2D point sets and graphs are learned by clustering with point-matching and graph-matching distance measures. The point-matching distance measure is approximately invariant under affine transformationstranslation, rotation, scale, and shearand permutations. It operates between noisy images with missing and spurious points. The graph-matching distance measure operates on weighted graphs and is invariant under permutations. Learning is formulated as an optimization problem. Large objectives so formulated ( million variables) are efficiently minimized using a combination of optimization techniquessoftassign, algebraic transformations, clocked objectives, and deterministic annealing."
            },
            "slug": "Learning-with-Preknowledge:-Clustering-with-Point-Gold-Rangarajan",
            "title": {
                "fragments": [],
                "text": "Learning with Preknowledge: Clustering with Point and Graph Matching Distance Measures"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The point-matching distance measure is approximately invariant under affine transformationstranslation, rotation, scale, and shearand permutations, and it operates between noisy images with missing and spurious points."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46356930"
                        ],
                        "name": "Petar D. Simic",
                        "slug": "Petar-D.-Simic",
                        "structuredName": {
                            "firstName": "Petar",
                            "lastName": "Simic",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Petar D. Simic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 12
                            }
                        ],
                        "text": "In the work [72, 76, 87, 93, 107] the graph matching problem is casted on the more principled statistical physics setting in terms of the mean-field theory and combined with self-amplification, softmax and penalty terms to improve solution quality and convergence properties."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18106757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dfc18acbdbdc1767968fcde31bae9fbcd63e2a7",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Some time ago Durbin and Willshaw proposed an interesting parallel algorithm (the \"elastic net\") for approximately solving some geometric optimization problems, such as the Traveling Salesman Problem. Recently it has been shown that their algorithm is related to neural networks of Hopfield and Tank, and that they both can be understood as the semiclassical approximation to statistical mechanics of related physical models. The main point of the elastic net algorithm is seen to be in the way one deals with the constraints when evaluating the effective cost function (free energy in the thermodynamic analogy), and not in its geometric foundation emphasized originally by Durbin and Willshaw. As a consequence, the elastic net algorithm is a special case of the more general physically based computations and can be generalized to a large class of nongeometric problems. In this paper we further elaborate on this observation, and generalize the elastic net to the quadratic assignment problem. We work out in detail its special case, the graph matching problem, because it is an important problem with many applications in computational vision and neural modeling. Simulation results on random graphs, and on structured (hand-designed) graphs of moderate size (20-100 nodes) are discussed."
            },
            "slug": "Constrained-Nets-for-Graph-Matching-and-Other-Simic",
            "title": {
                "fragments": [],
                "text": "Constrained Nets for Graph Matching and Other Quadratic Assignment Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The main point of the elastic net algorithm is seen to be in the way one deals with the constraints when evaluating the effective cost function (free energy in the thermodynamic analogy), and not in its geometric foundation emphasized originally by Durbin and Willshaw."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Comput."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707908"
                        ],
                        "name": "B. Jain",
                        "slug": "B.-Jain",
                        "structuredName": {
                            "firstName": "Brijnesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681964"
                        ],
                        "name": "F. Wysotzki",
                        "slug": "F.-Wysotzki",
                        "structuredName": {
                            "firstName": "Fritz",
                            "lastName": "Wysotzki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wysotzki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 3
                            }
                        ],
                        "text": "In [29, 47] simple competitive learning algorithms for clustering weighted graphs are proposed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "To give an example, the approach [47] suggests a structural perceptron for adaptive processing of graphs within a supervised and unsupervised setting."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 19686429,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0db583db0bde5d50527fea041ef59e68aa333003",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a structural perceptron for supervised and unsupervised learning on data represented in terms of attributed graphs. We integrate structural perceptrons into a multi-layer perceptron and competitive learning network to provide examples of supervised and unsupervised neural learning machines which are suited to process graphs. In first experiments the proposed algorithms were successfully applied to function regression, classification, and clustering."
            },
            "slug": "Structural-Perceptrons-for-Attributed-Graphs-Jain-Wysotzki",
            "title": {
                "fragments": [],
                "text": "Structural Perceptrons for Attributed Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A structural perceptron for supervised and unsupervised learning on data represented in terms of attributed graphs is proposed and the proposed algorithms were successfully applied to function regression, classification, and clustering."
            },
            "venue": {
                "fragments": [],
                "text": "SSPR/SPR"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516142"
                        ],
                        "name": "D. Tank",
                        "slug": "D.-Tank",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Tank",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tank"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 164
                            }
                        ],
                        "text": "Considerable interest in solving combinatorial optimization problems (COP) by means of neural networks has been initiated by the seminal paper of Hopfield and Tank [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36483354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a23da2c14f9355dd63a434b62cf5b28aeebc305",
            "isKey": false,
            "numCitedBy": 3037,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Highly-interconnected networks of nonlinear analog neurons are shown to be extremely effective in computing. The networks can rapidly provide a collectively-computed solution (a digital output) to a problem on the basis of analog input information. The problems to be solved must be formulated in terms of desired optima, often subject to constraints. The general principles involved in constructing networks to solve specific problems are discussed. Results of computer simulations of a network designed to solve a difficult but well-defined optimization problem-the Traveling-Salesman Problem-are presented and used to illustrate the computational power of the networks. Good solutions to this problem are collectively computed within an elapsed time of only a few neural time constants. The effectiveness of the computation involves both the nonlinear analog response of the neurons and the large connectivity among them. Dedicated networks of biological or microelectronic neurons could provide the computational capabilities described for a wide class of problems having combinatorial complexity. The power and speed naturally displayed by such collective networks may contribute to the effectiveness of biological information processing."
            },
            "slug": "\u201cNeural\u201d-computation-of-decisions-in-optimization-Hopfield-Tank",
            "title": {
                "fragments": [],
                "text": "\u201cNeural\u201d computation of decisions in optimization problems"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results of computer simulations of a network designed to solve a difficult but well-defined optimization problem-the Traveling-Salesman Problem-are presented and used to illustrate the computational power of the networks."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3029782"
                        ],
                        "name": "S. Sonnenburg",
                        "slug": "S.-Sonnenburg",
                        "structuredName": {
                            "firstName": "S\u00f6ren",
                            "lastName": "Sonnenburg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sonnenburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2414086"
                        ],
                        "name": "G. R\u00e4tsch",
                        "slug": "G.-R\u00e4tsch",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "R\u00e4tsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. R\u00e4tsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34719181"
                        ],
                        "name": "A. Jagota",
                        "slug": "A.-Jagota",
                        "structuredName": {
                            "firstName": "Arun",
                            "lastName": "Jagota",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jagota"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1501000,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "5250f8d7c8f86ae0afa7d3a658212f0b684f6664",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Splice sites are locations in DNA which separate protein-coding regions (exons) from noncoding regions (introns). Accurate splice site detectors thus form important components of computational gene finders. We pose splice site recognition as a classification problem with the classifier learnt from a labeled data set consisting of only local information around the potential splice site. Note that finding the correct position of splice sites without using global information is a rather hard task. We analyze the genomes of the nematode Caenorhabditis elegans and of humans using specially designed support vector kernels. One of the kernels is adapted from our previous work on detecting translation initiation sites in vertebrates and another uses an extension to the well-known Fisher-kernel. We find excellent performance on both data sets."
            },
            "slug": "New-Methods-for-Splice-Site-Recognition-Sonnenburg-R\u00e4tsch",
            "title": {
                "fragments": [],
                "text": "New Methods for Splice Site Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work analyzes the genomes of the nematode Caenorhabditis elegans and of humans using specially designed support vector kernels adapted from previous work on detecting translation initiation sites in vertebrates and another uses an extension to the well-known Fisher-kernel."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8147588"
                        ],
                        "name": "N. Nasrabadi",
                        "slug": "N.-Nasrabadi",
                        "structuredName": {
                            "firstName": "Nasser",
                            "lastName": "Nasrabadi",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nasrabadi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157336421"
                        ],
                        "name": "Wei Li",
                        "slug": "Wei-Li",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 90
                            }
                        ],
                        "text": "Early work uses binary threshold units and fixed penalty terms to express the constraints [61, 62, 68]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32693007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77eda247230e4c9392dd942e4f8fc41e5768b39c",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A model-based recognition method is introduced which is formulated as an optimization problem. An energy function is derived which represents the constraints on the best solution in order to find the best match. A two-dimensional binary Hopfield neural network is implemented to minimize the energy function. The state of each neuron in the Hopfield network represents the possibility of a match between a node in the model graph and a node in the scene graph.<<ETX>>"
            },
            "slug": "Object-recognition-by-a-Hopfield-neural-network-Nasrabadi-Li",
            "title": {
                "fragments": [],
                "text": "Object recognition by a Hopfield neural network"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "A model-based recognition method is introduced which is formulated as an optimization problem and an energy function is derived which represents the constraints on the best solution in order to find the best match."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8111020"
                        ],
                        "name": "M. Pelillo",
                        "slug": "M.-Pelillo",
                        "structuredName": {
                            "firstName": "Marcello",
                            "lastName": "Pelillo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pelillo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144003778"
                        ],
                        "name": "Kaleem Siddiqi",
                        "slug": "Kaleem-Siddiqi",
                        "structuredName": {
                            "firstName": "Kaleem",
                            "lastName": "Siddiqi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaleem Siddiqi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698824"
                        ],
                        "name": "S. Zucker",
                        "slug": "S.-Zucker",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Zucker",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Zucker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "This method has successfully been applied to match articulated and deformed shapes described by shock trees [71]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 82
                            }
                        ],
                        "text": "Association graph techniques have been applied to several graph matching problems [11, 71, 69, 77]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10762756,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6f6ea8ee1a0ae47a129f251268c94a076ff1f611",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 155,
            "paperAbstract": {
                "fragments": [],
                "text": "It is well-known that the problem of matching two relational structures can be posed as an equivalent problem of finding a maximal clique in a (derived) \"association graph.\" However, it is not clear how to apply this approach to computer vision problems where the graphs are hierarchically organized, i.e., are trees, since maximal cliques are not constrained to preserve the partial order. We provide a solution to the problem of matching two trees by constructing the association graph using the graph-theoretic concept of connectivity. We prove that, in the new formulation, there is a one-to-one correspondence between maximal cliques and maximal subtree isomorphisms. This allows us to cast the tree matching problem as an indefinite quadratic program using the Motzkin-Straus theorem, and we use \"replicator\" dynamical systems developed in theoretical biology to solve it. Such continuous solutions to discrete problems are attractive because they can motivate analog and biological implementations. The framework is also extended to the matching of attributed trees by using weighted association graphs. We illustrate the power of the approach by matching articulated and deformed shapes described by shock trees."
            },
            "slug": "Matching-Hierarchical-Structures-Using-Association-Pelillo-Siddiqi",
            "title": {
                "fragments": [],
                "text": "Matching Hierarchical Structures Using Association Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A solution to the problem of matching two trees, by constructing the association graph using the graph-theoretic concept of connectivity, and proving that in the new formulation there is a one-to-one correspondence between maximal cliques and maximal subtree isomorphisms."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769779"
                        ],
                        "name": "A. Araujo",
                        "slug": "A.-Araujo",
                        "structuredName": {
                            "firstName": "Aluizio",
                            "lastName": "Araujo",
                            "middleNames": [
                                "Fausto",
                                "Ribeiro"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Araujo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683726"
                        ],
                        "name": "G. Barreto",
                        "slug": "G.-Barreto",
                        "structuredName": {
                            "firstName": "Guilherme",
                            "lastName": "Barreto",
                            "middleNames": [
                                "De",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Barreto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10296573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcfa5ad19c69cca9586c876c5e6d51d218a7c7c1",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "A self-organizing neural net for learning and recall of complex temporal sequences is developed and applied to robot trajectory planning. We consider trajectories with both repeated and shared states. Both cases give rise to ambiguities during reproduction of stored trajectories which are resolved via temporal context information. Feedforward weights encode spatial features of the input trajectories, while the temporal order is learned by lateral weights through delayed Hebbian learning. After training, the net model operates in an anticipative fashion by always recalling the successor of the current input state. Redundancy in sequence representation improves noise and fault robustness. The net uses memory resources efficiently by reusing neurons that have previously stored repeated/shared states. Simulations have been carried out to evaluate the performance of the network in terms of trajectory reproduction, convergence time and memory usage, tolerance to fault and noise, and sensitivity to trajectory sampling rate. The results show that the model is fast, accurate, and robust. Its performance is discussed in comparison with other neural-networks models."
            },
            "slug": "Context-in-temporal-sequence-processing:-a-approach-Araujo-Barreto",
            "title": {
                "fragments": [],
                "text": "Context in temporal sequence processing: a self-organizing approach and its application to robotics"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A self-organizing neural net for learning and recall of complex temporal sequences is developed and applied to robot trajectory planning and its performance is discussed in comparison with other neural-networks models."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426007"
                        ],
                        "name": "R. Wang",
                        "slug": "R.-Wang",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Wang",
                            "middleNames": [
                                "Long"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143998435"
                        ],
                        "name": "Zheng Tang",
                        "slug": "Zheng-Tang",
                        "structuredName": {
                            "firstName": "Zheng",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zheng Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40474266"
                        ],
                        "name": "Q. Cao",
                        "slug": "Q.-Cao",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Cao",
                            "middleNames": [
                                "Ping"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Cao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 63
                            }
                        ],
                        "text": "Neural solutions which solely focus on the MCP can be found in [25, 43, 45, 101]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207669930,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "044355631d1cc611cf9c81f8bae7a6a222127cdc",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we present a solution to the maximum clique problem using a gradient-ascent learning algorithm of the Hopfield neural network. This method provides a near-optimum parallel algorithm for finding a maximum clique. To do this, we use the Hopfield neural network to generate a near-maximum clique and then modify weights in a gradient-ascent direction to allow the network to escape from the state of near-maximum clique to maximum clique or better. The proposed parallel algorithm is tested on two types of random graphs and some benchmark graphs from the Center for Discrete Mathematics and Theoretical Computer Science (DIMACS). The simulation results show that the proposed learning algorithm can find good solutions in reasonable computation time."
            },
            "slug": "An-Efficient-Approximation-Algorithm-for-Finding-a-Wang-Tang",
            "title": {
                "fragments": [],
                "text": "An Efficient Approximation Algorithm for Finding a Maximum Clique Using Hopfield Network Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A solution to the maximum clique problem using a gradient-ascent learning algorithm of the Hopfield neural network and the simulation results show that the proposed learning algorithm can find good solutions in reasonable computation time."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987548"
                        ],
                        "name": "A. Finch",
                        "slug": "A.-Finch",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Finch",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Finch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111010157"
                        ],
                        "name": "Richard C. Wilson",
                        "slug": "Richard-C.-Wilson",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Wilson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard C. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679753"
                        ],
                        "name": "E. Hancock",
                        "slug": "E.-Hancock",
                        "structuredName": {
                            "firstName": "Edwin",
                            "lastName": "Hancock",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hancock"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[23] extremized a non-quadratic energy function for graph matching to compute the similarity of two graphs and rectify structural errors at the same time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29472657,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "962d32cdae76ba5840de9a0a524ea88961971fbd",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "The contributions of this article are twofold. First, we develop a new nonquadratic energy function for graph matching. The starting point is a recently reported mixture model that gauges relational consistency using a series of exponential functions of the Hamming distances between graph neighborhoods. We compute the effective neighborhood potentials associated with the mixture model by identifying the single probability function of zero Kullback divergence. This new energy function is simply a weighted sum of graph Hamming distances. The second contribution is to locate matches by graduated assignment. Rather than solving the meanfield saddle-point equations, which are intractable for our nonquadratic energy function, we apply the soft-assign ansatz to the derivatives of our energy function. Here we introduce a novel departure from the standard graduated assignment formulation of graph matching by allowing the connection strengths of the data graph to update themselves. The aim is to provide a means by which the structure of the data graph can be updated so as to rectify structural errors. The method is evaluated experimentally and is shown to outperform its quadratic counterpart."
            },
            "slug": "An-Energy-Function-and-Continuous-Edit-Process-for-Finch-Wilson",
            "title": {
                "fragments": [],
                "text": "An Energy Function and Continuous Edit Process for Graph Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel departure from the standard graduated assignment formulation of graph matching by allowing the connection strengths of the data graph to update themselves is introduced, to provide a means by which the structure of theData graph can be updated so as to rectify structural errors."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809809"
                        ],
                        "name": "L. Shapiro",
                        "slug": "L.-Shapiro",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Shapiro",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Shapiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 157
                            }
                        ],
                        "text": "The GMP refers to finding a structure preserving correspondence between the vertices of two different graphs such that some similarity function is maximized [81, 86]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3361652,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6d7fce10da0ceb8332ec63cdb55e0ee5ce3645e",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Relational models are frequently used in high-level computer vision. Finding a correspondence between a relational model and an image description is an important operation in the analysis of scenes. In this paper the process of finding the correspondence is formalized by defining a general relational distance measure that computes a numeric distance between any two relational descriptions-a model and an image description, two models, or two image descriptions. The distance measure is proved to be a metric, and is illustrated with examples of distance between object models. A variant measure used in our past studies is shown not to be a metric."
            },
            "slug": "A-Metric-for-Comparing-Relational-Descriptions-Shapiro-Haralick",
            "title": {
                "fragments": [],
                "text": "A Metric for Comparing Relational Descriptions"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The process of finding the correspondence is formalized by defining a general relational distance measure that computes a numeric distance between any two relational descriptions-a model and an image description, two models, or two image descriptions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255005"
                        ],
                        "name": "Alessandro Vullo",
                        "slug": "Alessandro-Vullo",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Vullo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Vullo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 327386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b407dfcd313e4d93011fad22ccf2c4d70e66ae5",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "MOTIVATION\nWe focus on the prediction of disulfide bridges in proteins starting from their amino acid sequence and from the knowledge of the disulfide bonding state of each cysteine. The location of disulfide bridges is a structural feature that conveys important information about the protein main chain conformation and can therefore help towards the solution of the folding problem. Existing approaches based on weighted graph matching algorithms do not take advantage of evolutionary information. Recursive neural networks (RNN), on the other hand, can handle in a natural way complex data structures such as graphs whose vertices are labeled by real vectors, allowing us to incorporate multiple alignment profiles in the graphical representation of disulfide connectivity patterns.\n\n\nRESULTS\nThe core of the method is the use of machine learning tools to rank alternative disulfide connectivity patterns. We develop an ad-hoc RNN architecture for scoring labeled undirected graphs that represent connectivity patterns. In order to compare our algorithm with previous methods, we report experimental results on the SWISS-PROT 39 dataset. We find that using multiple alignment profiles allows us to obtain significant prediction accuracy improvements, clearly demonstrating the important role played by evolutionary information.\n\n\nAVAILABILITY\nThe Web interface of the predictor is available at http://neural.dsi.unifi.it/cysteines"
            },
            "slug": "Disulfide-connectivity-prediction-using-recursive-Vullo-Frasconi",
            "title": {
                "fragments": [],
                "text": "Disulfide connectivity prediction using recursive neural networks and evolutionary information"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Recursive neural networks (RNN) can handle in a natural way complex data structures such as graphs whose vertices are labeled by real vectors, allowing us to incorporate multiple alignment profiles in the graphical representation of disulfide connectivity patterns."
            },
            "venue": {
                "fragments": [],
                "text": "Bioinform."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47291997"
                        ],
                        "name": "J. Wiemer",
                        "slug": "J.-Wiemer",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Wiemer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wiemer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 156
                            }
                        ],
                        "text": "Most unsupervised recursive models have been proposed only for temporal data, and they obey a simple dynamics given by leaky integrators or traveling waves [16, 74, 104]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7334646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f34844f6c7f38ed611a069917aa8ec7bf4fe99bb",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "The new time-organized map (TOM) is presented for a better understanding of the self-organization and geometric structure of cortical signal representations. The algorithm extends the common self-organizing map (SOM) from the processing of purely spatial signals to the processing of spatiotemporal signals. The main additional idea of the TOM compared with the SOM is the functionally reasonable transfer of temporal signal distances into spatial signal distances in topographic neural representations. This is achieved by neural dynamics of propagating waves, allowing current and former signals to interact spatiotemporally in the neural network. Within a biologically plausible framework, the TOM algorithm (1) reveals how dynamic neural networks can self-organize to embed spatial signals in temporal context in order to realize functional meaningful invariances, (2) predicts time-organized representational structures in cortical areas representing signals with systematic temporal relation, and (3) suggests that the strength with which signals interact in the cortex determines the type of signal topology realized in topographic maps (e.g., spatially or temporally defined signal topology). Moreover, the TOM algorithm supports the explanation of topographic reorganizations based on time-to-space transformations (Wiemer, Spengler, Joublin, Stagge, & Wacquant, 2000)."
            },
            "slug": "The-Time-Organized-Map-Algorithm:-Extending-the-Map-Wiemer",
            "title": {
                "fragments": [],
                "text": "The Time-Organized Map Algorithm: Extending the Self-Organizing Map to Spatiotemporal Signals"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "The new time-organized map (TOM) is presented for a better understanding of the self-organization and geometric structure of cortical signal representations and suggests that the strength with which signals interact in the cortex determines the type of signal topology realized in topographic maps."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2861011"
                        ],
                        "name": "F. Rossi",
                        "slug": "F.-Rossi",
                        "structuredName": {
                            "firstName": "Fabrice",
                            "lastName": "Rossi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Rossi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403862587"
                        ],
                        "name": "B. Conan-Guez",
                        "slug": "B.-Conan-Guez",
                        "structuredName": {
                            "firstName": "Brieuc",
                            "lastName": "Conan-Guez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Conan-Guez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2721983"
                        ],
                        "name": "F. Fleuret",
                        "slug": "F.-Fleuret",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Fleuret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Fleuret"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 620450,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "b36d5600d55387382877b04bdb163d1d1105f260",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we study a natural extension of Multi Layer Perceptrons (MLP) to functional inputs. We show that fundamental results for numerical MLP can be extended to functional MLP. We obtain universal approximation results that show the expressive power of functional MLP is comparable to the one of numerical MLP. We obtain consistency results which imply that optimal parameters estimation for functional MLP is consistent."
            },
            "slug": "Theoretical-properties-of-functional-Multi-Layer-Rossi-Conan-Guez",
            "title": {
                "fragments": [],
                "text": "Theoretical properties of functional Multi Layer Perceptrons"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A natural extension of Multi Layer Perceptrons to functional inputs is studied, showing that fundamental results for numerical MLP can be extended to functional MLP and universal approximation results are obtained that show the expressive power of functionalMLP is comparable to the one of numericalMLP."
            },
            "venue": {
                "fragments": [],
                "text": "ESANN"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867541"
                        ],
                        "name": "M. Bod\u00e9n",
                        "slug": "M.-Bod\u00e9n",
                        "structuredName": {
                            "firstName": "Mikael",
                            "lastName": "Bod\u00e9n",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bod\u00e9n"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716264"
                        ],
                        "name": "Janet Wiles",
                        "slug": "Janet-Wiles",
                        "structuredName": {
                            "firstName": "Janet",
                            "lastName": "Wiles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Janet Wiles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 159
                            }
                        ],
                        "text": "A prime application of recurrent networks is language learning and a very clear discussion about possibilities and restrictions to learn languages is given in [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12817175,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df41e6edb0d57786f386901b8b2083b4795f08fb",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The long short-term memory (LSTM) is not the only neural network which learns a context sensitive language. Second-order sequential cascaded networks (SCNs) are able to induce means from a finite fragment of a context-sensitive language for processing strings outside the training set. The dynamical behavior of the SCN is qualitatively distinct from that observed in LSTM networks. Differences in performance and dynamics are discussed."
            },
            "slug": "On-learning-context-free-and-context-sensitive-Bod\u00e9n-Wiles",
            "title": {
                "fragments": [],
                "text": "On learning context-free and context-sensitive languages"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The long short-term memory (LSTM) is not the only neural network which learns a context sensitive language and second-order sequential cascaded networks are able to induce means from a finite fragment of a context-sensitive language for processing strings outside the training set."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2671293"
                        ],
                        "name": "M. Diekhans",
                        "slug": "M.-Diekhans",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Diekhans",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Diekhans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "The Fisher kernel constitutes an early and very prominent approach within this line [41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2048632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e2dd064daaac3603581ec65b580b7b5385e2c2b",
            "isKey": false,
            "numCitedBy": 556,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for detecting remote protein homologies is introduced and shown to perform well in classifying protein domains by SCOP superfamily. The method is a variant of support vector machines using a new kernel function. The kernel function is derived from a generative statistical model for a protein family, in this case a hidden Markov model. This general approach of combining generative models like HMMs with discriminative methods such as support vector machines may have applications in other areas of biosequence analysis as well."
            },
            "slug": "A-Discriminative-Framework-for-Detecting-Remote-Jaakkola-Diekhans",
            "title": {
                "fragments": [],
                "text": "A Discriminative Framework for Detecting Remote Protein Homologies"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A new method for detecting remote protein homologies is introduced and shown to perform well in classifying protein domains by SCOP superfamily using a new kernel function derived from a generative statistical model for a protein family, in this case a hidden Markov model."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Biol."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759124"
                        ],
                        "name": "C. Goller",
                        "slug": "C.-Goller",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Goller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Goller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35388031,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b19ab7f0d9a5ef60be7045bc80539590b00605a",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Automated deduction has a long tradition in computer science and most of the symbolic AI systems perform some kind of logic-based deductive inference. The central problem in automated deduction is the explosive growth of search spaces with deduction length. Methods of guiding and controlling the search process are indispensable. I will present a connectionist approach for learning search-control heuristics from examples of successful deductions. It originated in the context of the relatively new and still emerging eld of hybrid (symbolic/connectionist) systems. The goal of this eld is the identiication of strengths and weaknesses in the symbolic and the connectionist paradigms, and based on such insights, the design of hybrid systems that can beneet from the strengths of both. I begin with brieey comparing search-control heuristics for automated deduction systems with other methods that improve the eeciency of search, such as search strategies, calculus reenements and extensions, and analogical reasoning. The most important characteristics of heuristics are that they are simple and useful in most cases, however, they are not guaranteed to help. Search-control heuristics can be viewed as approximations to unknown and almost never realizable perfect search-control strategies. Approximation on the other hand is an inherent characteristic of connectionist methods, especially of the most successful and widespread backpropagation (BP) networks. Search-control heuristics for automated deduction systems are traditionally represented by heuristic evaluation functions for states or inference steps in the search space. These heuristic evaluation functions compute ratings for symbolic structures (e.g. graphs, trees, terms, formulas) of arbitrary size. Representing and processing the symbolic structures traditionally used in AI, belong to the most important and challenging open questions in the connectionist community. Most of the previous connectionist approaches for learning heuris-tic evaluation functions use a xed, a priori deened set of features for symbolic structures SF71, SE90, SE91, SG93, Gol94, Fuc96]. The deenition and selection of features, however, introduces a very strong bias and severely limits the class of relations that can be expressed and learned. It can be stated that the selection of a good set of features is already more than half the way to nding a good evaluation function. Compared to the feature-selection and deenition problem, the particular learning method which is applied is only of minor importance. I present a new and very powerful approach for adaptive structure processing which automatically nds the features which are relevant for the task at hand: folding architecture networks (FA-networks) \u2026"
            },
            "slug": "A-connectionist-approach-for-learning-heuristics-Goller",
            "title": {
                "fragments": [],
                "text": "A connectionist approach for learning search-control heuristics for automated deduction systems"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A connectionist approach for learning search-control heuristics for automated deduction systems with other methods that improve the eeciency of search, such as search strategies, calculus reenements and extensions, and analogical reasoning."
            },
            "venue": {
                "fragments": [],
                "text": "DISKI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2262254"
                        ],
                        "name": "Wei-Chung Lin",
                        "slug": "Wei-Chung-Lin",
                        "structuredName": {
                            "firstName": "Wei-Chung",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Chung Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2042765"
                        ],
                        "name": "Fong-Yuan Liao",
                        "slug": "Fong-Yuan-Liao",
                        "structuredName": {
                            "firstName": "Fong-Yuan",
                            "lastName": "Liao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fong-Yuan Liao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48540610"
                        ],
                        "name": "E. Tsao",
                        "slug": "E.-Tsao",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Tsao",
                            "middleNames": [
                                "Chen-Kuo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Tsao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2725951"
                        ],
                        "name": "Theresa Lingutla",
                        "slug": "Theresa-Lingutla",
                        "structuredName": {
                            "firstName": "Theresa",
                            "lastName": "Lingutla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Theresa Lingutla"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 90
                            }
                        ],
                        "text": "Early work uses binary threshold units and fixed penalty terms to express the constraints [61, 62, 68]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1458874,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e61745c754fd87932134e7cac196a7dfa54b8742",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A hierarchical approach is proposed for solving the surface and vertex correspondence problems in multiple-view-based 3D object-recognition systems. The proposed scheme is a coarse-to-fine search process, and a Hopfield network is used at each stage. Compared with conventional object-matching schemes, the proposed technique provides a more general and compact formulation of the problem and a solution more suitable for parallel implementation. At the coarse search stage, the surface matching scores between the input image and each object model in the database are computed through a Hopfield network and are used to select the candidates for further consideration. At the fine search stage, the object models selected from the previous stage are fed into another Hopfield network for vertex matching. The object model that has the best surface and vertex correspondences with the input image is finally singled out as the best matched model. Experimental results are reported using both synthetic and real range images to corroborate the proposed theory."
            },
            "slug": "A-hierarchical-multiple-view-approach-to-object-Lin-Liao",
            "title": {
                "fragments": [],
                "text": "A hierarchical multiple-view approach to three-dimensional object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A hierarchical approach is proposed for solving the surface and vertex correspondence problems in multiple-view-based 3D object-recognition systems and provides a more general and compact formulation of the problem and a solution more suitable for parallel implementation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144288586"
                        ],
                        "name": "A. Back",
                        "slug": "A.-Back",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Back",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Back"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2184725"
                        ],
                        "name": "Tianping Chen",
                        "slug": "Tianping-Chen",
                        "structuredName": {
                            "firstName": "Tianping",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianping Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "The approach [3] extends this result to multiple nonlinear operators."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5391327,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "685293f2a094a6d152e779e0a351f4d1a55a2009",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, there has been interest in the observed capabilities of some classes of neural networks with fixed weights to model multiple nonlinear dynamical systems. While this property has been observed in simulations, open questions exist as to how this property can arise. In this article, we propose a theory that provides a possible mechanism by which this multiple modeling phenomenon can occur."
            },
            "slug": "Universal-Approximation-of-Multiple-Nonlinear-by-Back-Chen",
            "title": {
                "fragments": [],
                "text": "Universal Approximation of Multiple Nonlinear Operators by Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A theory is proposed that provides a possible mechanism by which some classes of neural networks with fixed weights to model multiple nonlinear dynamical systems can occur."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144902513"
                        ],
                        "name": "P. Baldi",
                        "slug": "P.-Baldi",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Baldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8169197"
                        ],
                        "name": "S. Brunak",
                        "slug": "S.-Brunak",
                        "structuredName": {
                            "firstName": "S\u00f8ren",
                            "lastName": "Brunak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Brunak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2028880"
                        ],
                        "name": "G. Pollastri",
                        "slug": "G.-Pollastri",
                        "structuredName": {
                            "firstName": "Gianluca",
                            "lastName": "Pollastri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Pollastri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540925"
                        ],
                        "name": "G. Soda",
                        "slug": "G.-Soda",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Soda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Soda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 259
                            }
                        ],
                        "text": "Several generalizations of basic recursive models to better fit these type data have been proposed: recursive networks for acyclic graphs ([7] and (Bianchini/Maggini/Sarti/Scarselli, this volume)), bicausal networks for protein secondary structure prediction [4], an extension of recursive networks to lattices applied to protein contact map prediction [73], and contextual models for graph structures [65]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14431872,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "5a0bc896955dbe1fd2db321a754b2895d47355fc",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "In this chapter, we have proposed two novel architectures for dealing with sequence learning problems in which data is not obtained from physical measurements over time. The new architectures remove the causality assumption that characterize current connectionist approaches to learning sequential translations. Using bidirectional recurrent neural networks (BRNNs) on the protein secondary structure prediction task appears to be very promising. Our performance is very close to the best existing systems although our usage of profiles is not as sophisticated. One improvement of our prediction system could be obtained by using profiles from the TrEMBL database."
            },
            "slug": "Bidirectional-Dynamics-for-Protein-Secondary-Baldi-Brunak",
            "title": {
                "fragments": [],
                "text": "Bidirectional Dynamics for Protein Secondary Structure Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This chapter proposes two novel architectures for dealing with sequence learning problems in which data is not obtained from physical measurements over time, and using bidirectional recurrent neural networks on the protein secondary structure prediction task appears to be very promising."
            },
            "venue": {
                "fragments": [],
                "text": "Sequence Learning"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2492622"
                        ],
                        "name": "S. C. Kremer",
                        "slug": "S.-C.-Kremer",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Kremer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. C. Kremer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "A more detailed overview of recurrent network models can be found in [56]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6033894,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5db37967539988a32d66b2f64557ca505b4eb4f",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 126,
            "paperAbstract": {
                "fragments": [],
                "text": "This article reviews connectionist network architectures and training algorithms that are capable of dealing with patterns distributed across both space and timespatiotemporal patterns. It provides common mathematical, algorithmic, and illustrative frameworks for describing spatiotemporal networks, making it easier to compare and contrast their representational and operational characteristics. Computational power, representational issues, and learning are discussed. In additional references to the relevant source publications are provided. This article can serve as a guide to prospective users of spatiotemporal networks by providing an overview of the operational and representational alternatives available."
            },
            "slug": "Spatiotemporal-Connectionist-Networks:-A-Taxonomy-Kremer",
            "title": {
                "fragments": [],
                "text": "Spatiotemporal Connectionist Networks: A Taxonomy and Review"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "This article reviews connectionist network architectures and training algorithms that are capable of dealing with patterns distributed across both space and timespatiotemporal patterns to provide an overview of the operational and representational alternatives available."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34719181"
                        ],
                        "name": "A. Jagota",
                        "slug": "A.-Jagota",
                        "structuredName": {
                            "firstName": "Arun",
                            "lastName": "Jagota",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jagota"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 63
                            }
                        ],
                        "text": "Neural solutions which solely focus on the MCP can be found in [25, 43, 45, 101]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1218527,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18951306cb097f9451beed347cddfb71dbec3568",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "In a graph, a clique is a set of vertices such that every pair is connected by an edge. MAX-CLIQUE is the optimization problem of finding the largest clique in a given graph and is NP-hard, even to approximate well. Several real-world and theory problems can be modeled as MAX-CLIQUE. In this paper, we efficiently approximate MAX-CLIQUE in a special case of the Hopfield network whose stable states are maximal cliques. We present several energy-descent optimizing dynamics; both discrete (deterministic and stochastic) and continuous. One of these emulates, as special cases, two well-known greedy algorithms for approximating MAX-CLIQUE. We report on detailed empirical comparisons on random graphs and on harder ones. Mean-field annealing, an efficient approximation to simulated annealing, and a stochastic dynamics are the narrow but clear winners. All dynamics approximate much better than one which emulates a \"naive\" greedy heuristic."
            },
            "slug": "Approximating-maximum-clique-with-a-Hopfield-Jagota",
            "title": {
                "fragments": [],
                "text": "Approximating maximum clique with a Hopfield network"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper efficiently approximate MAX-CLIQUE in a special case of the Hopfield network whose stable states are maximal cliques, and presents several energy-descent optimizing dynamics; both discrete (deterministic and stochastic) and continuous."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2088368"
                        ],
                        "name": "F. Gers",
                        "slug": "F.-Gers",
                        "structuredName": {
                            "firstName": "Felix",
                            "lastName": "Gers",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Gers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2396681"
                        ],
                        "name": "D. Eck",
                        "slug": "D.-Eck",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Eck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Eck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 30459046,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ec6a10ba7d671128d2a72a4bcd308661dbdd277",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In response to Rodriguez's recent article (2001), we compare the performance of simple recurrent nets and long short-term memory recurrent nets on context-free and context-sensitive languages."
            },
            "slug": "Learning-Nonregular-Languages:-A-Comparison-of-and-Schmidhuber-Gers",
            "title": {
                "fragments": [],
                "text": "Learning Nonregular Languages: A Comparison of Simple Recurrent Networks and LSTM"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "In response to Rodriguez's recent article, this work compares the performance of simple recurrent nets and long short-term memory recurrent nets on context-free and context-sensitive languages."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8111020"
                        ],
                        "name": "M. Pelillo",
                        "slug": "M.-Pelillo",
                        "structuredName": {
                            "firstName": "Marcello",
                            "lastName": "Pelillo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pelillo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Recently, Pelillo [69] used the Replicator dynamics for solving the MCP within the same framework."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 82
                            }
                        ],
                        "text": "Association graph techniques have been applied to several graph matching problems [11, 71, 69, 77]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 995855,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "60f61aaf5be629029f86d79f3497c571427d69ac",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new energy-minimization framework for the graph isomorphism problem that is based on an equivalent maximum clique formulation. The approach is centered around a fundamental result proved by Motzkin and Straus in the mid-1960s, and recently expanded in various ways, which allows us to formulate the maximum clique problem in terms of a standard quadratic program. The attractive feature of this formulation is that a clear one-to-one correspondence exists between the solutions of the quadratic program and those in the original, combinatorial problem. To solve the program we use the so-called replicator equationsa class of straightforward continuous- and discrete-time dynamical systems developed in various branches of theoretical biology. We show how, despite their inherent inability to escape from local solutions, they nevertheless provide experimental results that are competitive with those obtained using more elaborate mean-field annealing heuristics."
            },
            "slug": "Replicator-Equations,-Maximal-Cliques,-and-Graph-Pelillo",
            "title": {
                "fragments": [],
                "text": "Replicator Equations, Maximal Cliques, and Graph Isomorphism"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A new energy-minimization framework for the graph isomorphism problem that is based on an equivalent maximum clique formulation that ensures a clear one-to-one correspondence exists between the solutions of the quadratic program and those in the original, combinatorial problem."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678170728"
                        ],
                        "name": "J. Kosowsky",
                        "slug": "J.-Kosowsky",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Kosowsky",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kosowsky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 12
                            }
                        ],
                        "text": "In the work [72, 76, 87, 93, 107] the graph matching problem is casted on the more principled statistical physics setting in terms of the mean-field theory and combined with self-amplification, softmax and penalty terms to improve solution quality and convergence properties."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5200734,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed223a6a3f853a6720406d6c22680e02e3953b9c",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years there has been significant interest in adapting techniques from statistical physics, in particular mean field theory, to provide deterministic heuristic algorithms for obtaining approximate solutions to optimization problems. Although these algorithms have been shown experimentally to be successful there has been little theoretical analysis of them. In this paper we demonstrate connections between mean field theory methods and other approaches, in particular, barrier function and interior point methods. As an explicit example, we summarize our work on the linear assignment problem. In this previous work we defined a number of algorithms, including deterministic annealing, for solving the assignment problem. We proved convergence, gave bounds on the convergence times, and showed relations to other optimization algorithms."
            },
            "slug": "Statistical-Physics-Algorithms-That-Converge-Yuille-Kosowsky",
            "title": {
                "fragments": [],
                "text": "Statistical Physics Algorithms That Converge"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Close connections are demonstrated between mean field theory methods and other approaches, in particular, barrier function and interior point methods, for obtaining approximate solutions to optimization problems."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2028880"
                        ],
                        "name": "G. Pollastri",
                        "slug": "G.-Pollastri",
                        "structuredName": {
                            "firstName": "Gianluca",
                            "lastName": "Pollastri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Pollastri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144902513"
                        ],
                        "name": "P. Baldi",
                        "slug": "P.-Baldi",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Baldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255005"
                        ],
                        "name": "Alessandro Vullo",
                        "slug": "Alessandro-Vullo",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Vullo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Vullo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59686741,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "beda10f681f6255dc5a8d43a4569f7a92815db0a",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop and test new machine learning methods for the prediction of topological representations of protein structures in the form of coarseor ne-grained contact or distance maps that are translation and rotation invariant. The methods are based on generalized input-output hidden Markov models (GIOHMMs) and generalized recursive neural networks (GRNNs). The methods are used to predict topology directly in the ne-grained case and, in the coarsegrained case, indirectly by rst learning how to score candidate graphs and then using the scoring function to search the space of possible con gurations. Computer simulations show that the predictors achieve state-of-the-art performance."
            },
            "slug": "Prediction-of-Protein-Topologies-Using-GIOHMMs-and-Pollastri-Baldi",
            "title": {
                "fragments": [],
                "text": "Prediction of Protein Topologies Using GIOHMMs and GRNNs"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "New machine learning methods based on generalized input-output hidden Markov models and generalized recursive neural networks for the prediction of topological representations of protein structures in the form of coarseor ne-grained contact or distance maps that are translation and rotation invariant are developed and tested."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS 2003"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2976737"
                        ],
                        "name": "G. J. Chappell",
                        "slug": "G.-J.-Chappell",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Chappell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. J. Chappell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400361607"
                        ],
                        "name": "John G. Taylor",
                        "slug": "John-G.-Taylor",
                        "structuredName": {
                            "firstName": "John G.",
                            "lastName": "Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John G. Taylor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 156
                            }
                        ],
                        "text": "Most unsupervised recursive models have been proposed only for temporal data, and they obey a simple dynamics given by leaky integrators or traveling waves [16, 74, 104]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12505690,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69870d32af1e7ad5fc0a06a11ef177be4e44b0fc",
            "isKey": false,
            "numCitedBy": 279,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-temporal-Koh\u00f6nen-map-Chappell-Taylor",
            "title": {
                "fragments": [],
                "text": "The temporal Koh\u00f6nen map"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751296"
                        ],
                        "name": "I. Bomze",
                        "slug": "I.-Bomze",
                        "structuredName": {
                            "firstName": "Immanuel",
                            "lastName": "Bomze",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Bomze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 108
                            }
                        ],
                        "text": "It uses the Motzkin-Strauss formulation of the maximum clique problem [67] and its spurious-free extensions [12, 28, 70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33853863,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a6a47682282bb6a31bcc7d447afafb1278972c93",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "As is well known, the problem of finding a maximum clique in a graph isNP-hard. Nevertheless, NP-hard problems may have easy instances. This paperproposes a new, global optimization algorithm which tries to exploit favourabledata constellations, focussing on the continuous problem formulation: maximizea quadratic form over the standard simplex. Some general connections of thelatter problem with dynamic principles of evolutionary game theory areestablished. As an immediate consequence, one obtains a procedure whichconsists (a) of an iterative part similar to interior-path methods based on theso-called replicator dynamics; and (b) a routine to escape from inefficient,locally optimal solutions. For the special case of finding a maximum clique ina graph where the quadratic form arises from a regularization of the adjacencematrix, part (b), i.e. escaping from maximal cliques not of maximal size, isaccomplished with block pivoting methods based on (large) independent sets,i.e. cliques of the complementary graph. A simulation study is included whichindicates that the resulting procedure indeed has some merits."
            },
            "slug": "Evolution-towards-the-Maximum-Clique-Bomze",
            "title": {
                "fragments": [],
                "text": "Evolution towards the Maximum Clique"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new, global optimization algorithm is proposed which tries to exploit favourabledata constellations, focussing on the continuous problem formulation: maximize a quadratic form over the standard simplex."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40124026"
                        ],
                        "name": "H. Cardot",
                        "slug": "H.-Cardot",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Cardot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Cardot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689530"
                        ],
                        "name": "F. Ferraty",
                        "slug": "F.-Ferraty",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Ferraty",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ferraty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145064630"
                        ],
                        "name": "P. Sarda",
                        "slug": "P.-Sarda",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Sarda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sarda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 152
                            }
                        ],
                        "text": "Thus, linear techniques such as principal component analysis or linear discriminants and non-parametric models have been transferred to functional data [15, 22, 42]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16132900,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "42e0a370814bec52294b63a3e6b79ef4c3a4b775",
            "isKey": false,
            "numCitedBy": 479,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Functional-linear-model-Cardot-Ferraty",
            "title": {
                "fragments": [],
                "text": "Functional linear model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145634459"
                        ],
                        "name": "M. Garey",
                        "slug": "M.-Garey",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Garey",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150444582"
                        ],
                        "name": "David S. Johnson",
                        "slug": "David-S.-Johnson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Johnson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David S. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Finding such correspondences is an NP-hard combinatorial problem [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2211006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdede1e17c947540b50e6e2db9e8467ddc6e7336",
            "isKey": false,
            "numCitedBy": 47653,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Horn formulae play a prominent role in artificial intelligence and logic programming. In this paper we investigate the problem of optimal compression of propositional Horn production rule knowledge bases. The standard approach to this problem, consisting in the removal of redundant rules from a knowledge base, leads to an \"irredundant\" but not necessarily optimal knowledge base. We prove here that the number of rules in any irredundant Horn knowledge base involving n propositional variables is at most n 0 1 times the minimum possible number of rules. In order to formalize the optimal compression problem, we define a Boolean function of a knowledge base as being the function whose set of true points is the set of models of the knowledge base. In this way the optimal compression of production rule knowledge bases becomes a problem of Boolean function minimization. In this paper we prove that the minimization of Horn functions (i.e. Boolean functions associated to Horn knowledge bases) is..."
            },
            "slug": "Computers-and-Intractability:-A-Guide-to-the-Theory-Garey-Johnson",
            "title": {
                "fragments": [],
                "text": "Computers and Intractability: A Guide to the Theory of NP-Completeness"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This is the second edition of a quarterly column the purpose of which is to provide a continuing update to the list of problems (NP-complete and harder) presented by M. R. Garey and myself in the authors' book \u2018\u2018Computers and Intractability: A Guide to the Theory of NP-Completeness\u2019\u2019."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737289"
                        ],
                        "name": "A. Torsello",
                        "slug": "A.-Torsello",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Torsello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torsello"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679753"
                        ],
                        "name": "E. Hancock",
                        "slug": "E.-Hancock",
                        "structuredName": {
                            "firstName": "Edwin",
                            "lastName": "Hancock",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hancock"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19103376,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd2ce4a6422506fc2d4499bbe7c983cd51e91b1d",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates an approach to tree edit distance problem with weighted nodes. We show that any tree obtained with a sequence of cut and relabel operations is a subtree of the transitive closure of the original tree. Furthermore, we show that the necessary condition for any subtree to be a solution can be reduced to a clique problem in a derived structure. Using this idea we transform the tree edit distance problem into a series of maximum weight clique problems and then we use relaxation labeling to find an approximate solution."
            },
            "slug": "Efficiently-Computing-Weighted-Tree-Edit-Distance-Torsello-Hancock",
            "title": {
                "fragments": [],
                "text": "Efficiently Computing Weighted Tree Edit Distance Using Relaxation Labeling"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This paper shows that any tree obtained with a sequence of cut and relabel operations is a subtree of the transitive closure of the original tree and shows that the necessary condition for any subtree to be a solution can be reduced to a clique problem in a derived structure."
            },
            "venue": {
                "fragments": [],
                "text": "EMMCVPR"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3068454"
                        ],
                        "name": "Patrice Horaud",
                        "slug": "Patrice-Horaud",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Horaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrice Horaud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145420319"
                        ],
                        "name": "M. J. Hannah",
                        "slug": "M.-J.-Hannah",
                        "structuredName": {
                            "firstName": "Marsja",
                            "lastName": "Hannah",
                            "middleNames": [
                                "Jo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. J. Hannah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 82
                            }
                        ],
                        "text": "Association graph techniques have been applied to several graph matching problems [11, 71, 69, 77]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 24281625,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "debdc594d1fcefbdad7a914eab463615123582c2",
            "isKey": false,
            "numCitedBy": 479,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a system that recognizes objects in a jumble, verifies them, and then determines some essential configurational information, such as which ones are on top. The approach is to use three-dimensional models of the objects to find them in range data. The matching strategy starts with a distinctive edge feature, such as the edge at the end of a cylindrical part, and then \"grows\" a match by add ing compatible features one at a time. (The order of features to be considered is predetermined by an interactive, off-line, feature-selection process.) Once a sufficient number of com patible features has been detected to allow a hypothesis to be formed, the verification procedure evaluates it by comparing the measured range data with data predicted according to the hypothesis. When all the objects in the scene have been hy pothesized and verified in this manner, a configuration- understanding procedure determines which objects are on top of others by analyzing the patterns of range data predicted from all the hypotheses. We also present experimental results of the system's performance in recognizing and locating castings in a bin."
            },
            "slug": "3DPO:-A-Three-Dimensional-Part-Orientation-System-Bolles-Horaud",
            "title": {
                "fragments": [],
                "text": "3DPO: A Three- Dimensional Part Orientation System"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This paper presents a system that recognizes objects in a jumble, verifies them, and then determines some essential configurational information, such as which ones are on top, by analyzing the patterns of range data predicted from all the hypotheses."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734576"
                        ],
                        "name": "A. Bianucci",
                        "slug": "A.-Bianucci",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Bianucci",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bianucci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41231471"
                        ],
                        "name": "A. Micheli",
                        "slug": "A.-Micheli",
                        "structuredName": {
                            "firstName": "Alessio",
                            "lastName": "Micheli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Micheli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749815"
                        ],
                        "name": "A. Sperduti",
                        "slug": "A.-Sperduti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sperduti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sperduti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678493"
                        ],
                        "name": "A. Starita",
                        "slug": "A.-Starita",
                        "structuredName": {
                            "firstName": "Antonina",
                            "lastName": "Starita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Starita"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 86
                            }
                        ],
                        "text": "Various alternative training schemes have recently been adapted to recursive networks [8, 18, 90] and widespread successful applications of recursive networks can be found in the literature such as theorem proving [30], discourse representation theory [13], picture processing [18], document image classification [21], connectivity prediction for molecules [100], natural language parsing [92], protein structure prediction [73], and chemistry [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10031212,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "5220ea903fb9b90c035bf97595acceee0cd24c49",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the application of Cascade Correlation for structures to QSPR (quantitative structure-property relationships) and QSAR (quantitative structure-activity relationships) analysis. Cascade Correlation for structures is a neural network model recently proposed for the processing of structured data. This allows the direct treatment of chemical compounds as labeled trees, which constitutes a novel approach to QSPR/QSAR. We report the results obtained for QSPR on Alkanes (predicting the boiling point) and QSAR of a class of Benzodiazepines. Our approach compares favorably versus the traditional QSAR treatment based on equations and it is competitive with \u2018ad hoc\u2019 MLPs for the QSPR problem."
            },
            "slug": "Application-of-Cascade-Correlation-Networks-for-to-Bianucci-Micheli",
            "title": {
                "fragments": [],
                "text": "Application of Cascade Correlation Networks for Structures to Chemistry"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work reports the results obtained for QSPR on Alkanes (predicting the boiling point) and QSAR of a class of Benzodiazepines and it is competitive with \u2018ad hoc\u2019 MLPs for theQSPR problem."
            },
            "venue": {
                "fragments": [],
                "text": "Applied Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714772"
                        ],
                        "name": "Dale Schuurmans",
                        "slug": "Dale-Schuurmans",
                        "structuredName": {
                            "firstName": "Dale",
                            "lastName": "Schuurmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dale Schuurmans"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125105198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e003f0a280275de163269d32046950ad37aa37f0",
            "isKey": false,
            "numCitedBy": 221,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Introduction: Linear Methods using Kernel function, Applying Linear Methods to Structured Objects, Conditional Symmetric Independence Kernels, Pair Hidden Markov Models, Conditionally Symmetrically Independent PHMMs, Conclusion"
            },
            "slug": "Dynamic-Alignment-Kernels-Smola-Bartlett",
            "title": {
                "fragments": [],
                "text": "Dynamic Alignment Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter contains sections titled: Introduction: Linear Methods using Kernel function, Applying Linear Methods to Structured Objects, Conditional Symmetric Independence Kernels, Pair Hidden Markov Models, Conditionally Symmetrically Independent PHMMs, Conclusion."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34667013"
                        ],
                        "name": "Luana E. Gibbons",
                        "slug": "Luana-E.-Gibbons",
                        "structuredName": {
                            "firstName": "Luana",
                            "lastName": "Gibbons",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luana E. Gibbons"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3053584"
                        ],
                        "name": "D. Hearn",
                        "slug": "D.-Hearn",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Hearn",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hearn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759608"
                        ],
                        "name": "P. Pardalos",
                        "slug": "P.-Pardalos",
                        "structuredName": {
                            "firstName": "Panos",
                            "lastName": "Pardalos",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pardalos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27715055"
                        ],
                        "name": "M. Ramana",
                        "slug": "M.-Ramana",
                        "structuredName": {
                            "firstName": "Motakuri",
                            "lastName": "Ramana",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ramana"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 108
                            }
                        ],
                        "text": "It uses the Motzkin-Strauss formulation of the maximum clique problem [67] and its spurious-free extensions [12, 28, 70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13897706,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "664fd62e320785badd97c0f3d1880464386595f5",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a graph G whose adjacency matrix is A, the Motzkin-Strauss formulation of the Maximum-Clique Problem is the quadratic program max{xTAx \u2223 xTe = 1, x \u2265 0}. It is well known that the global optimum value of this QP is 1-1/\u03c9G, where \u03c9G is the clique number of G. Here, we characterize the following properties pertaining to the above QP: 1 first order optimality, 2 second order optimality, 3 local optimality, 4 strict local optimality. These characterizations reveal interesting underlying discrete structures, and are polynomial time verifiable. A parametrization of the Motzkin-Strauss QP is then introduced and its properties are investigated. Finally, an extension of the Motzkin-Strauss formulation is provided for the weighted clique number of a graph."
            },
            "slug": "Continuous-Characterizations-of-the-Maximum-Clique-Gibbons-Hearn",
            "title": {
                "fragments": [],
                "text": "Continuous Characterizations of the Maximum Clique Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The Motzkin-Strauss QP is characterized, revealing interesting underlying discrete structures, and its properties are investigated, which are polynomial time verifiable."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Oper. Res."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31577094"
                        ],
                        "name": "T. Motzkin",
                        "slug": "T.-Motzkin",
                        "structuredName": {
                            "firstName": "Theodore",
                            "lastName": "Motzkin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Motzkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34605579"
                        ],
                        "name": "E. Straus",
                        "slug": "E.-Straus",
                        "structuredName": {
                            "firstName": "Ernst",
                            "lastName": "Straus",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Straus"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "It uses the Motzkin-Strauss formulation of the maximum clique problem [67] and its spurious-free extensions [12, 28, 70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 121387797,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5dafd9a466729b7d01739f1b1db15bb95b25cef0",
            "isKey": false,
            "numCitedBy": 698,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Maximum of a square-free quadratic form on a simplex. The following question was suggested by a problem of J. E. MacDonald Jr. (1): Given a graph G with vertices 1, 2, . . . , n. Let S be the simplex in En given by xi \u2265 0, \u03a3xi = 1. What is"
            },
            "slug": "Maxima-for-Graphs-and-a-New-Proof-of-a-Theorem-of-Motzkin-Straus",
            "title": {
                "fragments": [],
                "text": "Maxima for Graphs and a New Proof of a Theorem of Tur\u00e1n"
            },
            "venue": {
                "fragments": [],
                "text": "Canadian Journal of Mathematics"
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707908"
                        ],
                        "name": "B. Jain",
                        "slug": "B.-Jain",
                        "structuredName": {
                            "firstName": "Brijnesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681964"
                        ],
                        "name": "F. Wysotzki",
                        "slug": "F.-Wysotzki",
                        "structuredName": {
                            "firstName": "Fritz",
                            "lastName": "Wysotzki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wysotzki"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 63
                            }
                        ],
                        "text": "Neural solutions which solely focus on the MCP can be found in [25, 43, 45, 101]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 407619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4123dbdf7ec290ccdff9edd4c3d3bb3cfae31bac",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an in-depth mathematical analysis of a winner-takes-all Network tailoredto the maximum clique problem, a well-known intractable combinatorial optimization problem which has practical applications in several real world domains. The analysis yields tight bounds for the parameter settings to ensure energy descent to feasible solutions. To verify the theoretical results we employ a fast annealing schedule to the WTA algorithm and show the effectiveness of the proposed approach for large scaled problems in extensive computer simulations."
            },
            "slug": "Fast-Winner-Takes-All-Networks-for-the-Maximum-Jain-Wysotzki",
            "title": {
                "fragments": [],
                "text": "Fast Winner-Takes-All Networks for the Maximum Clique Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "An in-depth mathematical analysis of a winner-takes-all Network tailored to the maximum clique problem, a well-known intractable combinatorial optimization problem which has practical applications in several real world domains is presented."
            },
            "venue": {
                "fragments": [],
                "text": "KI"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143760024"
                        ],
                        "name": "G. Levi",
                        "slug": "G.-Levi",
                        "structuredName": {
                            "firstName": "Giorgio",
                            "lastName": "Levi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Levi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "Ambler [1], Barrow and Burstall [6], and Levi [60] suggested to transform the graph matching problem to the maximum clique problem (MCP) in a so-called association graph, a product structure derived from the graphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123375336,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b74f42ea1c013f1edce969f628137ce36097ffb0",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this note the problem is considered of finding maximal common subgraphs of two given graphs. A technique is described by which this problem can be stated as a problem of deriving maximal compatibility classes. A known \u00abmaximal compatibility classes\u00bb algorithm can then be used to derive maximal common subgraphs.The same technique is shown to apply to the classical subgraph isomorphism problem."
            },
            "slug": "A-note-on-the-derivation-of-maximal-common-of-two-Levi",
            "title": {
                "fragments": [],
                "text": "A note on the derivation of maximal common subgraphs of two directed or undirected graphs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060242630"
                        ],
                        "name": "S. Bischoff",
                        "slug": "S.-Bischoff",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Bischoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bischoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073795953"
                        ],
                        "name": "D. Reuss",
                        "slug": "D.-Reuss",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Reuss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Reuss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681964"
                        ],
                        "name": "F. Wysotzki",
                        "slug": "F.-Wysotzki",
                        "structuredName": {
                            "firstName": "Fritz",
                            "lastName": "Wysotzki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wysotzki"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 51
                            }
                        ],
                        "text": "To meet the requirements of practical applications [9, 48, 83, 84, 95], weights are annotated to the vertices and edges of an association graph to express the similarities between pairs of items of both graphs being matched."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 187
                            }
                        ],
                        "text": "Since then this approach has been applied to learn structural prototypes of chemical compounds [83], to predict mutagenicity [84], and to similarity based recognition of segmented images [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 44451691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05d768df05fbef5570c2b1f7f26b887b5756926c",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Two similarity measures to compare whole and parts of images are proposed. These measures consider the color, shape and texture properties of image segments as well as their relative positions mutually."
            },
            "slug": "Applied-Connectionistic-Methods-in-Computer-Vision-Bischoff-Reuss",
            "title": {
                "fragments": [],
                "text": "Applied Connectionistic Methods in Computer Vision to Compare Segmented Images"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "Two similarity measures to compare whole and parts of images are proposed, which consider the color, shape and texture properties of image segments as well as their relative positions mutually."
            },
            "venue": {
                "fragments": [],
                "text": "KI"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2768912"
                        ],
                        "name": "J. Raymond",
                        "slug": "J.-Raymond",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Raymond",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Raymond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2384147"
                        ],
                        "name": "E. Gardiner",
                        "slug": "E.-Gardiner",
                        "structuredName": {
                            "firstName": "Eleanor",
                            "lastName": "Gardiner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gardiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144610645"
                        ],
                        "name": "P. Willett",
                        "slug": "P.-Willett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Willett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Willett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 82
                            }
                        ],
                        "text": "Association graph techniques have been applied to several graph matching problems [11, 71, 69, 77]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 34671580,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c3669cebc4f779fddbab0de970e312303078610",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently a method (RASCAL) for determining graph similarity using a maximum common edge subgraph algorithm has been proposed which has proven to be very efficient when used to calculate the relative similarity of chemical structures represented as graphs. This paper describes heuristics which simplify a RASCAL similarity calculation by taking advantage of certain properties specific to chemical graph representations of molecular structure. These heuristics are shown experimentally to increase the efficiency of the algorithm, especially at more distant values of chemical graph similarity."
            },
            "slug": "Heuristics-for-Similarity-Searching-of-Chemical-a-Raymond-Gardiner",
            "title": {
                "fragments": [],
                "text": "Heuristics for Similarity Searching of Chemical Graphs Using a Maximum Common Edge Subgraph Algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "J. Chem. Inf. Comput. Sci."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145257017"
                        ],
                        "name": "Anand Rangarajan",
                        "slug": "Anand-Rangarajan",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Rangarajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anand Rangarajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705072"
                        ],
                        "name": "E. Mjolsness",
                        "slug": "E.-Mjolsness",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Mjolsness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Mjolsness"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 12
                            }
                        ],
                        "text": "In the work [72, 76, 87, 93, 107] the graph matching problem is casted on the more principled statistical physics setting in terms of the mean-field theory and combined with self-amplification, softmax and penalty terms to improve solution quality and convergence properties."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8458636,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "409c855ed1bf7c984411300d77c924b5ba6e1dba",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a Lagrangian relaxation network for graph matching. The problem is find a permutation matrix M that minimizes a distance between the two graphs. The authors adopt a deterministic annealing approach which is similar to a Lagrangian decomposition approach in that the row and column constraints of the permutation matrix are satisfied separately and Lagrange multipliers are used to equate the two \"solutions\". A fixpoint preserving transformation is applied to the graph matching constraint. A symmetry-breaking term is added in order to obtain a permutation matrix and is reversed via another fixpoint preserving transformation. The resulting network performs minimization with respect to the Lagrange parameters and maximization with respect to the match matrix variables. Simulation results are shown on 100 node random graphs and for a wide range of connectivities.<<ETX>>"
            },
            "slug": "A-Lagrangian-relaxation-network-for-graph-matching-Rangarajan-Mjolsness",
            "title": {
                "fragments": [],
                "text": "A Lagrangian relaxation network for graph matching"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A Lagrangian relaxation network for graph matching is presented, with the application of a fixpoint preserving algebraic transformation to both the distance measure and self-amplification terms, and performs minimization and maximization on the permutation matrix variables."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144012376"
                        ],
                        "name": "J. Hofbauer",
                        "slug": "J.-Hofbauer",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Hofbauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hofbauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767754"
                        ],
                        "name": "K. Sigmund",
                        "slug": "K.-Sigmund",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Sigmund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sigmund"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "The Replicator dynamics is derived from evolutionary game theory [38]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 85023742,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "06e9fd76f501531560fc4d9d688c4d0f041891f2",
            "isKey": false,
            "numCitedBy": 4644,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "Every form of behavior is shaped by trial and error. Such stepwise adaptation can occur through individual learning or through natural selection, the basis of evolution. Since the work of Maynard Smith and others, it has been realized how game theory can model this process. Evolutionary game theory replaces the static solutions of classical game theory by a dynamical approach centered not on the concept of rational players but on the population dynamics of behavioral programs. In this book the authors investigate the nonlinear dynamics of the self-regulation of social and economic behavior, and of the closely related interactions among species in ecological communities. Replicator equations describe how successful strategies spread and thereby create new conditions that can alter the basis of their success, i.e., to enable us to understand the strategic and genetic foundations of the endless chronicle of invasions and extinctions that punctuate evolution. In short, evolutionary game theory describes when to escalate a conflict, how to elicit cooperation, why to expect a balance of the sexes, and how to understand natural selection in mathematical terms. \n \n Comprehensive treatment of ecological and game theoretic dynamics \n Invasion dynamics and permanence as key concepts \n Explanation in terms of games of things like competition between species"
            },
            "slug": "Evolutionary-Games-and-Population-Dynamics-Hofbauer-Sigmund",
            "title": {
                "fragments": [],
                "text": "Evolutionary Games and Population Dynamics"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "In this book the authors investigate the nonlinear dynamics of the self-regulation of social and economic behavior, and of the closely related interactions among species in ecological communities."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3379234"
                        ],
                        "name": "A. Fothergill",
                        "slug": "A.-Fothergill",
                        "structuredName": {
                            "firstName": "Ann",
                            "lastName": "Fothergill",
                            "middleNames": [
                                "Patricia"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fothergill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696931"
                        ],
                        "name": "H. Barrow",
                        "slug": "H.-Barrow",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Barrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Barrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48726084"
                        ],
                        "name": "Christopher M. Brown",
                        "slug": "Christopher-M.-Brown",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Brown",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher M. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730540"
                        ],
                        "name": "R. Burstall",
                        "slug": "R.-Burstall",
                        "structuredName": {
                            "firstName": "Rod",
                            "lastName": "Burstall",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Burstall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2507732"
                        ],
                        "name": "R. Popplestone",
                        "slug": "R.-Popplestone",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Popplestone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Popplestone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "Ambler [1], Barrow and Burstall [6], and Levi [60] suggested to transform the graph matching problem to the maximum clique problem (MCP) in a so-called association graph, a product structure derived from the graphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5478483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f46165aee5006d1cd19e44a2481fbfc889f845c0",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A versatile assembly system, using TV cameras and oomputer-controlled arm and moving table, is described. It makes almple assemblies such aa a peg and rings and a toy car. It separates parts from a heap, recognising them with an overhead camera, then assembles them by feel. It can be instructed to perform a new task with different parte by spending an hour showing it the parts and a day or two programming the assembly manipulations. A hierarchical description of parts, views, outlines etc. is used to construct models, and a structure matching algorithm is used in recognition."
            },
            "slug": "A-Versatile-Computer-Controlled-Assembly-System-Fothergill-Barrow",
            "title": {
                "fragments": [],
                "text": "A Versatile Computer-Controlled Assembly System"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A versatile assembly system, using TV cameras and oomputer-controlled arm and moving table, is described, which makes almple assemblies such aa a peg and rings and a toy car."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8111020"
                        ],
                        "name": "M. Pelillo",
                        "slug": "M.-Pelillo",
                        "structuredName": {
                            "firstName": "Marcello",
                            "lastName": "Pelillo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pelillo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34719181"
                        ],
                        "name": "A. Jagota",
                        "slug": "A.-Jagota",
                        "structuredName": {
                            "firstName": "Arun",
                            "lastName": "Jagota",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jagota"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 108
                            }
                        ],
                        "text": "It uses the Motzkin-Strauss formulation of the maximum clique problem [67] and its spurious-free extensions [12, 28, 70]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120514183,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ae79cf8e512f43fc7962f34bb50b9a0fb9c22721",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Feasible-and-infeasible-maxima-in-a-quadratic-for-Pelillo-Jagota",
            "title": {
                "fragments": [],
                "text": "Feasible and infeasible maxima in a quadratic program for maximum clique"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771100"
                        ],
                        "name": "N. Funabiki",
                        "slug": "N.-Funabiki",
                        "structuredName": {
                            "firstName": "Nobuo",
                            "lastName": "Funabiki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Funabiki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852999"
                        ],
                        "name": "Seishi Nishikawa",
                        "slug": "Seishi-Nishikawa",
                        "structuredName": {
                            "firstName": "Seishi",
                            "lastName": "Nishikawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seishi Nishikawa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 63
                            }
                        ],
                        "text": "Neural solutions which solely focus on the MCP can be found in [25, 43, 45, 101]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117095927,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a31ac9ca6f21e420af9d9a8e23f99269fe5c0bf4",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Comparisons-of-Energy-Descent-Optimization-for-Funabiki-Nishikawa",
            "title": {
                "fragments": [],
                "text": "Comparisons of Energy-Descent Optimization Algorithms for Maximum Clique Problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696931"
                        ],
                        "name": "H. Barrow",
                        "slug": "H.-Barrow",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Barrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Barrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730540"
                        ],
                        "name": "R. Burstall",
                        "slug": "R.-Burstall",
                        "structuredName": {
                            "firstName": "Rod",
                            "lastName": "Burstall",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Burstall"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "Ambler [1], Barrow and Burstall [6], and Levi [60] suggested to transform the graph matching problem to the maximum clique problem (MCP) in a so-called association graph, a product structure derived from the graphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1992172,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "94d5ca2790bbda25b891e79cbc0815d0d96fac0f",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Subgraph-Isomorphism,-Matching-Relational-and-Barrow-Burstall",
            "title": {
                "fragments": [],
                "text": "Subgraph Isomorphism, Matching Relational Structures and Maximal Cliques"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Lett."
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42372599,
            "fieldsOfStudy": [],
            "id": "b9e451a1975adfcdb20c07cf691c80594e2ea967",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Matching Hierarchical Structures Using Association Graphs"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2756664"
                        ],
                        "name": "K. Sch\u00e4dler",
                        "slug": "K.-Sch\u00e4dler",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Sch\u00e4dler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sch\u00e4dler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681964"
                        ],
                        "name": "F. Wysotzki",
                        "slug": "F.-Wysotzki",
                        "structuredName": {
                            "firstName": "Fritz",
                            "lastName": "Wysotzki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wysotzki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 51
                            }
                        ],
                        "text": "To meet the requirements of practical applications [9, 48, 83, 84, 95], weights are annotated to the vertices and edges of an association graph to express the similarities between pairs of items of both graphs being matched."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "Since then this approach has been applied to learn structural prototypes of chemical compounds [83], to predict mutagenicity [84], and to similarity based recognition of segmented images [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10896462,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b2cd1d3051babd6d2f2c2e5ba736cbe8e012bf8",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Application-of-a-neural-net-in-classification-and-Sch\u00e4dler-Wysotzki",
            "title": {
                "fragments": [],
                "text": "Application of a neural net in classification and knowledge discovery"
            },
            "venue": {
                "fragments": [],
                "text": "ESANN"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707908"
                        ],
                        "name": "B. Jain",
                        "slug": "B.-Jain",
                        "structuredName": {
                            "firstName": "Brijnesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681964"
                        ],
                        "name": "F. Wysotzki",
                        "slug": "F.-Wysotzki",
                        "structuredName": {
                            "firstName": "Fritz",
                            "lastName": "Wysotzki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wysotzki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1980218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "17064ae2c2de2cb4f224eebdae863afad5242a7f",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-maximum-weighted-clique-problem-and-Hopfield-Jain-Wysotzki",
            "title": {
                "fragments": [],
                "text": "The maximum weighted clique problem and Hopfield networks"
            },
            "venue": {
                "fragments": [],
                "text": "ESANN"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "The diffusion kernel has been applied to document processing whereby the generator is induced by co-occurrence information [50], and to bioinformatics data whereby the generator"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning semantic similarity. NIPS\u20192002"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information diffusion kernls"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS \u2019"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The maximum -clique problem and the Hopfield -clique model"
            },
            "venue": {
                "fragments": [],
                "text": "The maximum -clique problem and the Hopfield -clique model"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 9
                            }
                        ],
                        "text": "Wysotzki [105] applied a Hopfield-style network for approximately solving the MCP in an association graph."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Artifical intelligence and artifical neural nets"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Informatics,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "An alternative graph kernel is proposed in [51]: labels on randomly generated paths of infinite length are compared."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "Other alternatives to the Fisher kernel can be derived from the general model of marginalized kernels as described in [51]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Marginalized kernels between labeled graphs. ICML\u20192003"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The maximum \ufffdclique problem and the Hopfield \ufffdclique model"
            },
            "venue": {
                "fragments": [],
                "text": "Submitted to Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perspectives on learning withrecurrent networks"
            },
            "venue": {
                "fragments": [],
                "text": "ESANN \u2019"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "In the extended version [79], approximation completeness of the model and consistency for numerical integration and universal function approximators is proved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Functional mutli-layer perceptrons: a nonlinear tool for functional data analysis. CEREMADE preprint 0331"
            },
            "venue": {
                "fragments": [],
                "text": "Functional mutli-layer perceptrons: a nonlinear tool for functional data analysis. CEREMADE preprint 0331"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "To give an example, the approach [47] suggests a structural perceptron for adaptive processing of graphs within a supervised and unsupervised setting."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "In [29, 47] simple competitive learning algorithms for clustering weighted graphs are proposed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Structural perceptrons for attributed graphs. SSPR 2004"
            },
            "venue": {
                "fragments": [],
                "text": "Structural perceptrons for attributed graphs. SSPR 2004"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 199
                            }
                        ],
                        "text": "The more general data structure of directed acyclic graphs can be addressed in a similar way, counting the number of matching or partially matching subtrees of two given structures as proposed in [19, 94, 108] and also in (Micheli/Portera/Sperduti, this volume)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convolution kernels for natural languages"
            },
            "venue": {
                "fragments": [],
                "text": "Convolution kernels for natural languages"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 12
                            }
                        ],
                        "text": "In the work [72, 76, 87, 93, 107] the graph matching problem is casted on the more principled statistical physics setting in terms of the mean-field theory and combined with self-amplification, softmax and penalty terms to improve solution quality and convergence properties."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A new method for mapping optimisation problems"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Neural Systems,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 196
                            }
                        ],
                        "text": "The more general data structure of directed acyclic graphs can be addressed in a similar way, counting the number of matching or partially matching subtrees of two given structures as proposed in [19, 94, 108] and also in (Micheli/Portera/Sperduti, this volume)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kernel methods for relational extraction"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Machine Learning Research 3:1083-1106,"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 51
                            }
                        ],
                        "text": "To meet the requirements of practical applications [9, 48, 83, 84, 95], weights are annotated to the vertices and edges of an association graph to express the similarities between pairs of items of both graphs being matched."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Central clustering in the domain of graphs"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning: Special Issue on Theoretical Advances in Data Clustering,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "In the extended version [79], approximation completeness of the model and consistency for numerical integration and universal function approximators is proved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Functional mutli-layer perceptrons: a nonlinear tool for functional data analysis"
            },
            "venue": {
                "fragments": [],
                "text": "CEREMADE preprint 0331,"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[93] relaxed the two way constraints imposed on the permutation matrix to an one way constraint for retrieving several occurrences of a model in a scene in parallel."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 12
                            }
                        ],
                        "text": "In the work [72, 76, 87, 93, 107] the graph matching problem is casted on the more principled statistical physics setting in terms of the mean-field theory and combined with self-amplification, softmax and penalty terms to improve solution quality and convergence properties."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pattern recognition by graph matching using Potts MFT networks"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perspectives on learning with recurrent networks"
            },
            "venue": {
                "fragments": [],
                "text": "ESANN \u2019"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On median graphs : prope ties , algorithms , and applications"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perspectives on learning with recurrent networks"
            },
            "venue": {
                "fragments": [],
                "text": "Perspectives on learning with recurrent networks"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Disulfide Connectivity Prediction Using Recursive Neural Networks and Multiple Alignments"
            },
            "venue": {
                "fragments": [],
                "text": "Disulfide Connectivity Prediction Using Recursive Neural Networks and Multiple Alignments"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convolution kernels for natural languages"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS \u2019"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Disulfide Connectivity Prediction Using Recursive Neural Networks and Multiple Alignments"
            },
            "venue": {
                "fragments": [],
                "text": "To appear in Bioinformatics"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 100
                            }
                        ],
                        "text": "Efficient compression schemes using characteristics of only the winner neuron have been proposed in [32, 91] which achieve comparable results as the recursive SOM but which are computationally much more efficient."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural gas for sequences. WSOM\u20192003"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 152
                            }
                        ],
                        "text": "Thus, linear techniques such as principal component analysis or linear discriminants and non-parametric models have been transferred to functional data [15, 22, 42]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The functional nonparametric model and applications to chemometric data"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Statistics"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ESANN'2004 proceedings -European Symposium on Artificial Neural Networks Bruges (Belgium)"
            },
            "venue": {
                "fragments": [],
                "text": "ESANN'2004 proceedings -European Symposium on Artificial Neural Networks Bruges (Belgium)"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "Approaches which do not fall in these realms are, for example, the dynamic link architecture [57], extensions of associative memories for storing and retrieving graphs [55, 64], or selforganizing winner-takes-all classifiers for structures [46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distortion invariant object reognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 196
                            }
                        ],
                        "text": "The more general data structure of directed acyclic graphs can be addressed in a similar way, counting the number of matching or partially matching subtrees of two given structures as proposed in [19, 94, 108] and also in (Micheli/Portera/Sperduti, this volume)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convolution kernels for natural languages. NIPS\u20192001"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[58] extends the diffusion kernel introduced over discrete neighborhood structures to general Riemannian manifolds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information diffusion kernels. NIPS\u20192002"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 94
                            }
                        ],
                        "text": "Thus, they share most of the dynamic properties and difficulties of simple recurrent networks [33, 36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perspectives on learning with recurrent networks. ESANN\u20192002"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 58,
            "methodology": 38
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 130,
        "totalPages": 13
    },
    "page_url": "https://www.semanticscholar.org/paper/Neural-methods-for-non-standard-data-Hammer-Jain/b98587d738c1923d3f465ea5d0a0f9ad319220a4?sort=total-citations"
}