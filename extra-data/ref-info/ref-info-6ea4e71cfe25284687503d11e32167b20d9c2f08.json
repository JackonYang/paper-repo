{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107296751"
                        ],
                        "name": "D. Kumar",
                        "slug": "D.-Kumar",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145677714"
                        ],
                        "name": "A. Ramakrishnan",
                        "slug": "A.-Ramakrishnan",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ramakrishnan",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ramakrishnan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 4
                            }
                        ],
                        "text": "A G Ramakrishnan MILE Laboratory Dept. of EE Indian Institute \nof Science Bangalore, INDIA ramkiag@ee.iisc.ernet.in camera captured images into two parts, namely localization \n(or detection) and recognition."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Ku\u00admar and \nRamakrishnan [15] applied power-law transform to remove the a.ect of anti-aliasing."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 64
                            }
                        ],
                        "text": "[12] T. Kasar, D. Kumar, M. N. Anil Prasad, D. Girish and A. G. Ramakrishnan, \nMAST: Multi-script annotation for scene images toolkit , Proc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 43
                            }
                        ],
                        "text": "[17] D. Kumar, M. N. Anil Prasad and A. G. \nRamakrishnan, MAPS: Midline analysis and propagation of segmentation , Proc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 24
                            }
                        ],
                        "text": "[13] T. Kasar and A. G. Ramakrishnan, Multi-script and multi-oriented \ntext localization from scene images , Proc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "Kumar and Ramakrishnan [15] applied power-law transform to remove the affect of anti-aliasing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13876092,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7975b400d73a8b75f0745f9ce92cf46fff6d5ac",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we discuss the issues related to word recognition in born-digital word images. We introduce a novel method of power-law transformation on the word image for binarization. We show the improvement in image binarization and the consequent increase in the recognition performance of OCR engine on the word image. The optimal value of gamma for a word image is automatically chosen by our algorithm with fixed stroke width threshold. We have exhaustively experimented our algorithm by varying the gamma and stroke width threshold value. By varying the gamma value, we found that our algorithm performed better than the results reported in the literature. On the ICDAR Robust Reading Systems Challenge-1: Word Recognition Task on born digital dataset, as compared to the recognition rate of 61.5% achieved by TH-OCR after suitable pre-processing by Yang et. al. and 63.4% by ABBYY Fine Reader (used as baseline by the competition organizers without any preprocessing), we achieved 82.9% using Omnipage OCR applied on the images after being processed by our algorithm."
            },
            "slug": "Power-law-transformation-for-enhanced-recognition-Kumar-Ramakrishnan",
            "title": {
                "fragments": [],
                "text": "Power-law transformation for enhanced recognition of born-digital word images"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A novel method of power-law transformation on the word image for binarization is introduced and the improvement in image binarized and the consequent increase in the recognition performance of OCR engine on theword image."
            },
            "venue": {
                "fragments": [],
                "text": "2012 International Conference on Signal Processing and Communications (SPCOM)"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3200914"
                        ],
                        "name": "Asif Shahab",
                        "slug": "Asif-Shahab",
                        "structuredName": {
                            "firstName": "Asif",
                            "lastName": "Shahab",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Asif Shahab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 76
                            }
                        ],
                        "text": "These data sets are from ICDAR 2003 competition [4], ICDAR 2011 competition [10, 11], Street view [8], born-digital and Sign evaluation data sets [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "Figure 1: Sample camera captured word images from ICDAR 2011 dataset [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1468345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f4edbb12d346e873ca1faeff959aa7d4809495f",
            "isKey": false,
            "numCitedBy": 431,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Recognition of text in natural scene images is becoming a prominent research area due to the widespread availablity of imaging devices in low-cost consumer products like mobile phones. To evaluate the performance of recent algorithms in detecting and recognizing text from complex images, the ICDAR 2011 Robust Reading Competition was organized. Challenge 2 of the competition dealt specifically with detecting/recognizing text in natural scene images. This paper presents an overview of the approaches that the participants used, the evaluation measure, and the dataset used in the Challenge 2 of the contest. We also report the performance of all participating methods for text localization and word recognition tasks and compare their results using standard methods of area precision/recall and edit distance."
            },
            "slug": "ICDAR-2011-Robust-Reading-Competition-Challenge-2:-Shahab-Shafait",
            "title": {
                "fragments": [],
                "text": "ICDAR 2011 Robust Reading Competition Challenge 2: Reading Text in Scene Images"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An overview of the approaches that the participants used, the evaluation measure, and the dataset used in the ICDAR 2011 Robust Reading Competition for detecting/recognizing text in natural scene images is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1384553906"
                        ],
                        "name": "D. Kumar",
                        "slug": "D.-Kumar",
                        "structuredName": {
                            "firstName": "Deepak",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143825718"
                        ],
                        "name": "M. Prasad",
                        "slug": "M.-Prasad",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Prasad",
                            "middleNames": [
                                "N.",
                                "Anil"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Prasad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145677714"
                        ],
                        "name": "A. Ramakrishnan",
                        "slug": "A.-Ramakrishnan",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ramakrishnan",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ramakrishnan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "The reported benchmark results and those of MAPS algorithm [17] have been obtained using Nuance Omnipage OCR on the pixel level segmented word images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "The recognition rates of MAPS method [17], proposed by the authors, are comparable or better than the best in the literature, except for SVT 2010 data set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13303734,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3f82c4e95fd2be884e5ce045bd6b8a70f0a680a",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Scenic word images undergo degradations due to motion blur, uneven illumination, shadows and defocussing, which lead to difficulty in segmentation. As a result, the recognition results reported on the scenic word image datasets of ICDAR have been low. We introduce a novel technique, where we choose the middle row of the image as a sub-image and segment it first. Then, the labels from this segmented sub-image are used to propagate labels to other pixels in the image. This approach, which is unique and distinct from the existing methods, results in improved segmentation. Bayesian classification and Max-flow methods have been independently used for label propagation. This midline based approach limits the impact of degradations that happens to the image. The segmented text image is recognized using the trial version of Omnipage OCR. We have tested our method on ICDAR 2003 and ICDAR 2011 datasets. Our word recognition results of 64.5% and 71.6% are better than those of methods in the literature and also methods that competed in the Robust reading competition. Our method makes an implicit assumption that degradation is not present in the middle row."
            },
            "slug": "MAPS:-midline-analysis-and-propagation-of-Kumar-Prasad",
            "title": {
                "fragments": [],
                "text": "MAPS: midline analysis and propagation of segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel technique, where the middle row of the image is chosen as a sub-image and segmented first and the labels from this segmented sub- image are used to propagate labels to other pixels in the image, which results in improved segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "ICVGIP '12"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39719398"
                        ],
                        "name": "Anand Mishra",
                        "slug": "Anand-Mishra",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Mishra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anand Mishra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72492981"
                        ],
                        "name": "Alahari Karteek",
                        "slug": "Alahari-Karteek",
                        "structuredName": {
                            "firstName": "Alahari",
                            "lastName": "Karteek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alahari Karteek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694502"
                        ],
                        "name": "C. Jawahar",
                        "slug": "C.-Jawahar",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Jawahar",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jawahar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 63
                            }
                        ],
                        "text": "Small subsets have been annotated and utilized for experiments [9, 13, 14] from different data sets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "al [9] express the importance of binarization for word images and show 52% recognition on only the sample dataset, but not on the test set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "al [9] report an accuracy of 52%, this performance is only on images from the ICDAR 2003 sample dataset and the authors did not perform any experiments on the actual test set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1175264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f57f38a4cfb97bf242c0acc720e9335cd9e7d0e",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Inspired by the success of MRF models for solving object segmentation problems, we formulate the binarization problem in this framework. We represent the pixels in a document image as random variables in an MRF, and introduce a new energy (or cost) function on these variables. Each variable takes a foreground or background label, and the quality of the binarization (or labelling) is determined by the value of the energy function. We minimize the energy function, i.e. find the optimal binarization, using an iterative graph cut scheme. Our model is robust to variations in foreground and background colours as we use a Gaussian Mixture Model in the energy function. In addition, our algorithm is efficient to compute, and adapts to a variety of document images. We show results on word images from the challenging ICDAR 2003 dataset, and compare our performance with previously reported methods. Our approach shows significant improvement in pixel level accuracy as well as OCR accuracy."
            },
            "slug": "An-MRF-Model-for-Binarization-of-Natural-Scene-Text-Mishra-Karteek",
            "title": {
                "fragments": [],
                "text": "An MRF Model for Binarization of Natural Scene Text"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work represents the pixels in a document image as random variables in an MRF, and introduces a new energy function on these variables to find the optimal binarization, using an iterative graph cut scheme."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40019398"
                        ],
                        "name": "T. Kasar",
                        "slug": "T.-Kasar",
                        "structuredName": {
                            "firstName": "Thotreingam",
                            "lastName": "Kasar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kasar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145677714"
                        ],
                        "name": "A. Ramakrishnan",
                        "slug": "A.-Ramakrishnan",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ramakrishnan",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ramakrishnan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3396772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8e6a38bc682de750480d106d6795b31ef50faf6",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new method of color text localization from generic scene images containing text of different scripts and with arbitrary orientations. A representative set of colors is first identified using the edge information to initiate an unsupervised clustering algorithm. Text components are identified from each color layer using a combination of a support vector machine and a neural network classifier trained on a set of low-level features derived from the geometric, boundary, stroke and gradient information. Experiments on camera-captured images that contain variable fonts, size, color, irregular layout, non-uniform illumination and multiple scripts illustrate the robustness of the method. The proposed method yields precision and recall of 0.8 and 0.86 respectively on a database of 100 images. The method is also compared with others in the literature using the ICDAR 2003 robust reading competition dataset."
            },
            "slug": "Multi-script-and-Multi-oriented-Text-Localization-Kasar-Ramakrishnan",
            "title": {
                "fragments": [],
                "text": "Multi-script and Multi-oriented Text Localization from Scene Images"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A new method of color text localization from generic scene images containing text of different scripts and with arbitrary orientations is described, which yields precision and recall of 0.8 and 0.86 respectively on a database of 100 images."
            },
            "venue": {
                "fragments": [],
                "text": "CBDAR"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39719398"
                        ],
                        "name": "Anand Mishra",
                        "slug": "Anand-Mishra",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Mishra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anand Mishra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72492981"
                        ],
                        "name": "Alahari Karteek",
                        "slug": "Alahari-Karteek",
                        "structuredName": {
                            "firstName": "Alahari",
                            "lastName": "Karteek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alahari Karteek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694502"
                        ],
                        "name": "C. Jawahar",
                        "slug": "C.-Jawahar",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Jawahar",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jawahar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "One of the best reported results [7] uses a limited lexicon and two others [16] use a synthetic custom lexicon, both derived from the ground truths of the respective test sets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "al [16] is based on only 829 images, a subset of ICDAR 2003 test dataset."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5728901,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66b71064b99331f908b60cb6d138f2ebea5bdcca",
            "isKey": false,
            "numCitedBy": 306,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Scene text recognition has gained significant attention from the computer vision community in recent years. Recognizing such text is a challenging problem, even more so than the recognition of scanned documents. In this work, we focus on the problem of recognizing text extracted from street images. We present a framework that exploits both bottom-up and top-down cues. The bottom-up cues are derived from individual character detections from the image. We build a Conditional Random Field model on these detections to jointly model the strength of the detections and the interactions between them. We impose top-down cues obtained from a lexicon-based prior, i.e. language statistics, on the model. The optimal word represented by the text image is obtained by minimizing the energy function corresponding to the random field model. We show significant improvements in accuracies on two challenging public datasets, namely Street View Text (over 15%) and ICDAR 2003 (nearly 10%)."
            },
            "slug": "Top-down-and-bottom-up-cues-for-scene-text-Mishra-Karteek",
            "title": {
                "fragments": [],
                "text": "Top-down and bottom-up cues for scene text recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents a framework that exploits both bottom-up and top-down cues in the problem of recognizing text extracted from street images, and shows significant improvements in accuracies on two challenging public datasets, namely Street View Text and ICDAR 2003."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148896777"
                        ],
                        "name": "Kai Wang",
                        "slug": "Kai-Wang",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "Similarly, Wang and Belongie use synthetic, custom lexicons on Street view text (SVT) data set [8]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "Wang and Belongie introduced street view text (SVT) data set obtained as part of Google Street View project [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "These data sets are from ICDAR 2003 competition [4], ICDAR 2011 competition [10, 11], Street view [8], born-digital and Sign evaluation data sets [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14911813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d307221fa52e3939d46180cb5921ebbd92c8adb",
            "isKey": false,
            "numCitedBy": 425,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for spotting words in the wild, i.e., in real images taken in unconstrained environments. Text found in the wild has a surprising range of difficulty. At one end of the spectrum, Optical Character Recognition (OCR) applied to scanned pages of well formatted printed text is one of the most successful applications of computer vision to date. At the other extreme lie visual CAPTCHAs - text that is constructed explicitly to fool computer vision algorithms. Both tasks involve recognizing text, yet one is nearly solved while the other remains extremely challenging. In this work, we argue that the appearance of words in the wild spans this range of difficulties and propose a new word recognition approach based on state-of-the-art methods from generic object recognition, in which we consider object categories to be the words themselves. We compare performance of leading OCR engines - one open source and one proprietary - with our new approach on the ICDAR Robust Reading data set and a new word spotting data set we introduce in this paper: the Street View Text data set. We show improvements of up to 16% on the data sets, demonstrating the feasibility of a new approach to a seemingly old problem."
            },
            "slug": "Word-Spotting-in-the-Wild-Wang-Belongie",
            "title": {
                "fragments": [],
                "text": "Word Spotting in the Wild"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is argued that the appearance of words in the wild spans this range of difficulties and a new word recognition approach based on state-of-the-art methods from generic object recognition is proposed, in which object categories are considered to be the words themselves."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815031"
                        ],
                        "name": "S. Lucas",
                        "slug": "S.-Lucas",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lucas",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87531536"
                        ],
                        "name": "A. Panaretos",
                        "slug": "A.-Panaretos",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Panaretos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Panaretos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073684197"
                        ],
                        "name": "Luis Sosa",
                        "slug": "Luis-Sosa",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Sosa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luis Sosa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052189571"
                        ],
                        "name": "Anthony Tang",
                        "slug": "Anthony-Tang",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anthony Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108862960"
                        ],
                        "name": "Shirley Wong",
                        "slug": "Shirley-Wong",
                        "structuredName": {
                            "firstName": "Shirley",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shirley Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114080648"
                        ],
                        "name": "Robert Young",
                        "slug": "Robert-Young",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065499715"
                        ],
                        "name": "Kazuki Ashida",
                        "slug": "Kazuki-Ashida",
                        "structuredName": {
                            "firstName": "Kazuki",
                            "lastName": "Ashida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuki Ashida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055905787"
                        ],
                        "name": "Hiroki Nagai",
                        "slug": "Hiroki-Nagai",
                        "structuredName": {
                            "firstName": "Hiroki",
                            "lastName": "Nagai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hiroki Nagai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47471571"
                        ],
                        "name": "Masayuki Okamoto",
                        "slug": "Masayuki-Okamoto",
                        "structuredName": {
                            "firstName": "Masayuki",
                            "lastName": "Okamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masayuki Okamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152933693"
                        ],
                        "name": "Hiroaki Yamamoto",
                        "slug": "Hiroaki-Yamamoto",
                        "structuredName": {
                            "firstName": "Hiroaki",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hiroaki Yamamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34593830"
                        ],
                        "name": "H. Miyao",
                        "slug": "H.-Miyao",
                        "structuredName": {
                            "firstName": "Hidetoshi",
                            "lastName": "Miyao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Miyao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146280843"
                        ],
                        "name": "JunMin Zhu",
                        "slug": "JunMin-Zhu",
                        "structuredName": {
                            "firstName": "JunMin",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "JunMin Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2873679"
                        ],
                        "name": "WuWen Ou",
                        "slug": "WuWen-Ou",
                        "structuredName": {
                            "firstName": "WuWen",
                            "lastName": "Ou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "WuWen Ou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144899680"
                        ],
                        "name": "Christian Wolf",
                        "slug": "Christian-Wolf",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680935"
                        ],
                        "name": "J. Jolion",
                        "slug": "J.-Jolion",
                        "structuredName": {
                            "firstName": "Jean-Michel",
                            "lastName": "Jolion",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jolion"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1844464"
                        ],
                        "name": "L. Todoran",
                        "slug": "L.-Todoran",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Todoran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Todoran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717056"
                        ],
                        "name": "M. Worring",
                        "slug": "M.-Worring",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Worring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Worring"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46520089"
                        ],
                        "name": "Xiaofan Lin",
                        "slug": "Xiaofan-Lin",
                        "structuredName": {
                            "firstName": "Xiaofan",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofan Lin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2250003,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a01deac56a81646e8d84cb7bf2d905714ff00808",
            "isKey": false,
            "numCitedBy": 235,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.This paper describes the robust reading competitions for ICDAR 2003. With the rapid growth in research over the last few years on recognizing text in natural scenes, there is an urgent need to establish some common benchmark datasets and gain a clear understanding of the current state of the art. We use the term \u2018robust reading\u2019 to refer to text images that are beyond the capabilities of current commercial OCR packages. We chose to break down the robust reading problem into three subproblems and run competitions for each stage, and also a competition for the best overall system. The subproblems we chose were text locating, character recognition and word recognition. By breaking down the problem in this way, we hoped to gain a better understanding of the state of the art in each of the subproblems. Furthermore, our methodology involved storing detailed results of applying each algorithm to each image in the datasets, allowing researchers to study in depth the strengths and weaknesses of each algorithm. The text-locating contest was the only one to have any entries. We give a brief description of each entry and present the results of this contest, showing cases where the leading entries succeed and fail. We also describe an algorithm for combining the outputs of the individual text locators and show how the combination scheme improves on any of the individual systems."
            },
            "slug": "ICDAR-2003-robust-reading-competitions:-entries,-Lucas-Panaretos",
            "title": {
                "fragments": [],
                "text": "ICDAR 2003 robust reading competitions: entries, results, and future directions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper broke down the robust reading problem into three subproblems and run competitions for each stage, and also a competition for the best overall system, and described an algorithm for combining the outputs of the individual text locators and showed how the combination scheme improves on any of theindividual systems."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815031"
                        ],
                        "name": "S. Lucas",
                        "slug": "S.-Lucas",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lucas",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lucas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 110
                            }
                        ],
                        "text": "In the following ICDAR 2005 conference, text localization was the main theme and word recognition was skipped [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1842569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbf50fe5622253f401e892ed943a18033e18b7b9",
            "isKey": false,
            "numCitedBy": 318,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the results of the ICDAR 2005 competition for locating text in camera captured scenes. For this we used the same data as the ICDAR 2003 competition, which has been kept private until now. This allows a direct comparison with the 2003 entries. The main result is that the leading 2005 entry has improved significantly on the leading 2003 entry, with an increase in average f-score from 0.5 to 0.62, where the f-score is the same adapted information retrieval measure used for the 2003 competition. The paper also discusses the Web-based deployment and evaluation of text locating systems, and one of the leading entries has now been deployed in this way. This mode of usage could lead to more complete and more immediate knowledge of the strengths and weaknesses of each newly developed system."
            },
            "slug": "ICDAR-2005-text-locating-competition-results-Lucas",
            "title": {
                "fragments": [],
                "text": "ICDAR 2005 text locating competition results"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The main result is that the leading 2005 entry has improved significantly on the leading 2003 entry, with an increase in average f- score from 0.5 to 0.62, where the f-score is the same adapted information retrieval measure used for the 2003 competition."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109528136"
                        ],
                        "name": "Hailong Liu",
                        "slug": "Hailong-Liu",
                        "structuredName": {
                            "firstName": "Hailong",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hailong Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145507765"
                        ],
                        "name": "X. Ding",
                        "slug": "X.-Ding",
                        "structuredName": {
                            "firstName": "Xiaoqing",
                            "lastName": "Ding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Ding"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 28
                            }
                        ],
                        "text": "Since only TH-OCR algorithm [6] competed in the competition and could not beat the baseline method, it was mentioned as a honorary entry."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29932766,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a1b831f1d44ed3f59874320241135ba2ad1caf1",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In the research of statistical approach for handwritten character recognition, directional element feature (DEF) and modified quadratic discriminant function (MQDF) have been extremely successful and widely used in practical applications. In this paper, we apply several state-of-the-art techniques of handwritten character recognition on this baseline system to improve the recognition accuracy. In feature extraction stage, gradient feature is extracted to replace DEF, which provides higher resolution on both magnitude and angle of the directional strokes in character image. In classification stage, the performance of MQDF classifier is enhanced by multiple discrimination schemes, including minimum classification error (MCE) training on the classifier parameters and modified distance representation for similar characters discrimination. All these techniques we use lead to improvement on the character recognition rate. The performance of the improved recognition system has been evaluated by both handwritten digit recognition and handwritten Chinese character recognition experiments, in which very promising results are achieved."
            },
            "slug": "Handwritten-character-recognition-using-gradient-Liu-Ding",
            "title": {
                "fragments": [],
                "text": "Handwritten character recognition using gradient feature and quadratic classifier with multiple discrimination schemes"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Several state-of-the-art techniques of handwritten character recognition on this baseline system to improve the recognition accuracy are applied and lead to improvement on the character recognition rate."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862313"
                        ],
                        "name": "J. Weinman",
                        "slug": "J.-Weinman",
                        "structuredName": {
                            "firstName": "Jerod",
                            "lastName": "Weinman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weinman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389846455"
                        ],
                        "name": "E. Learned-Miller",
                        "slug": "E.-Learned-Miller",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Learned-Miller",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Learned-Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733922"
                        ],
                        "name": "A. Hanson",
                        "slug": "A.-Hanson",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Hanson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hanson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 146
                            }
                        ],
                        "text": "These data sets are from ICDAR 2003 competition [4], ICDAR 2011 competition [10, 11], Street view [8], born-digital and Sign evaluation data sets [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "One of the best reported results [7] uses a limited lexicon and two others [16] use a synthetic custom lexicon, both derived from the ground truths of the respective test sets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "al [7] showed that the recognition performance reduces with full lexicon."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5416971,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b2a523d48cee04c09c327e14fb8928c5feff03c",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Scene text recognition (STR) is the recognition of text anywhere in the environment, such as signs and storefronts. Relative to document recognition, it is challenging because of font variability, minimal language context, and uncontrolled conditions. Much information available to solve this problem is frequently ignored or used sequentially. Similarity between character images is often overlooked as useful information. Because of language priors, a recognizer may assign different labels to identical characters. Directly comparing characters to each other, rather than only a model, helps ensure that similar instances receive the same label. Lexicons improve recognition accuracy but are used post hoc. We introduce a probabilistic model for STR that integrates similarity, language properties, and lexical decision. Inference is accelerated with sparse belief propagation, a bottom-up method for shortening messages by reducing the dependency between weakly supported hypotheses. By fusing information sources in one model, we eliminate unrecoverable errors that result from sequential processing, improving accuracy. In experimental results recognizing text from images of signs in outdoor scenes, incorporating similarity reduces character recognition error by 19 percent, the lexicon reduces word recognition error by 35 percent, and sparse belief propagation reduces the lexicon words considered by 99.9 percent with a 12X speedup and no loss in accuracy."
            },
            "slug": "Scene-Text-Recognition-Using-Similarity-and-a-with-Weinman-Learned-Miller",
            "title": {
                "fragments": [],
                "text": "Scene Text Recognition Using Similarity and a Lexicon with Sparse Belief Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A probabilistic model for scene text recognition is introduced that integrates similarity, language properties, and lexical decision and is fusing information sources in one model to eliminate unrecoverable errors that result from sequential processing, improving accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40019398"
                        ],
                        "name": "T. Kasar",
                        "slug": "T.-Kasar",
                        "structuredName": {
                            "firstName": "Thotreingam",
                            "lastName": "Kasar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kasar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107296751"
                        ],
                        "name": "D. Kumar",
                        "slug": "D.-Kumar",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11126334"
                        ],
                        "name": "M. N. Anil Prasad",
                        "slug": "M.-N.-Anil-Prasad",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Anil Prasad",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. N. Anil Prasad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80941296"
                        ],
                        "name": "D. Girish",
                        "slug": "D.-Girish",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Girish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Girish"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145677714"
                        ],
                        "name": "A. Ramakrishnan",
                        "slug": "A.-Ramakrishnan",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ramakrishnan",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ramakrishnan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11269405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37e8634dbc8adcea71114936c215d0f70267c9fd",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a semi-automatic tool for annotation of multi-script text from natural scene images. To our knowledge, this is the maiden tool that deals with multi-script text or arbitrary orientation. The procedure involves manual seed selection followed by a region growing process to segment each word present in the image. The threshold for region growing can be varied by the user so as to ensure pixel-accurate character segmentation. The text present in the image is tagged word-by-word. A virtual keyboard interface has also been designed for entering the ground truth in ten Indic scripts, besides English. The keyboard interface can easily be generated for any script, thereby expanding the scope of the toolkit. Optionally, each segmented word can further be labeled into its constituent characters/symbols. Polygonal masks are used to split or merge the segmented words into valid characters/symbols. The ground truth is represented by a pixel-level segmented image and a '.txt' file that contains information about the number of words in the image, word bounding boxes, script and ground truth Unicode. The toolkit, developed using MATLAB, can be used to generate ground truth and annotation for any generic document image. Thus, it is useful for researchers in the document image processing community for evaluating the performance of document analysis and recognition techniques. The multi-script annotation toolokit (MAST) is available for free download."
            },
            "slug": "MAST:-multi-script-annotation-toolkit-for-scenic-Kasar-Kumar",
            "title": {
                "fragments": [],
                "text": "MAST: multi-script annotation toolkit for scenic text"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The multi-script annotation toolokit, developed using MATLAB, can be used to generate ground truth and annotation for any generic document image and is useful for researchers in the document image processing community for evaluating the performance of document analysis and recognition techniques."
            },
            "venue": {
                "fragments": [],
                "text": "MOCR_AND '11"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2729896"
                        ],
                        "name": "Sergi Robles Mestre",
                        "slug": "Sergi-Robles-Mestre",
                        "structuredName": {
                            "firstName": "Sergi",
                            "lastName": "Mestre",
                            "middleNames": [
                                "Robles"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergi Robles Mestre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40016884"
                        ],
                        "name": "J. M. Romeu",
                        "slug": "J.-M.-Romeu",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Romeu",
                            "middleNames": [
                                "Mas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. M. Romeu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38417650"
                        ],
                        "name": "F. Nourbakhsh",
                        "slug": "F.-Nourbakhsh",
                        "structuredName": {
                            "firstName": "Farshad",
                            "lastName": "Nourbakhsh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Nourbakhsh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40813600"
                        ],
                        "name": "P. Roy",
                        "slug": "P.-Roy",
                        "structuredName": {
                            "firstName": "Partha",
                            "lastName": "Roy",
                            "middleNames": [
                                "Pratim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Roy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "al initiated another robust reading challenge in ICDAR 2011 for born-digital images [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 76
                            }
                        ],
                        "text": "These data sets are from ICDAR 2003 competition [4], ICDAR 2011 competition [10, 11], Street view [8], born-digital and Sign evaluation data sets [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "al [10] initiated a new robust reading competition in 2011."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4377688,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c507148d502245c459df2ec883dc02fabc0ecad",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the results of the first Challenge of ICDAR 2011 Robust Reading Competition. Challenge 1 is focused on the extraction of text from born-digital images, specifically from images found in Web pages and emails. The challenge was organized in terms of three tasks that look at different stages of the process: text localization, text segmentation and word recognition. In this paper we present the results of the challenge for all three tasks, and make an open call for continuous participation outside the context of ICDAR 2011."
            },
            "slug": "ICDAR-2011-Robust-Reading-Competition-Challenge-1:-Karatzas-Mestre",
            "title": {
                "fragments": [],
                "text": "ICDAR 2011 Robust Reading Competition - Challenge 1: Reading Text in Born-Digital Images (Web and Email)"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This paper presents the results of the first Challenge of ICDAR 2011 Robust Reading Competition, focused on the extraction of text from born-digital images, specifically from images found in Web pages and emails."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145061328"
                        ],
                        "name": "R. Gonz\u00e1lez",
                        "slug": "R.-Gonz\u00e1lez",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Gonz\u00e1lez",
                            "middleNames": [
                                "Corsino"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gonz\u00e1lez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32377259"
                        ],
                        "name": "R. Woods",
                        "slug": "R.-Woods",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Woods",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Woods"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7472395,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72ce0faa2d0be574f5cb88cfe6353a3ba40a08ae",
            "isKey": false,
            "numCitedBy": 7123,
            "numCiting": 171,
            "paperAbstract": {
                "fragments": [],
                "text": "2. A sampled (but not quantized) image, whose brightness before quantization, in each spatial position, can take values in the range [0mV;250mV], has the linear histogram of its brightness represented (approximately) in Fig. 2.a). After the quantization, the histogram of the resulting digital image is the one in Fig. 2.b). Then, most likely, the quantizer that was used is: a) an 8 bit uniform quantizer; b) a 2 bit optimal quantizer; c) a 4 bit optimal quantizer; d) a 2 bit uniform quantizer."
            },
            "slug": "Digital-Image-Processing-Gonz\u00e1lez-Woods",
            "title": {
                "fragments": [],
                "text": "Digital Image Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "A sampled (but not quantized) image, whose brightness before quantization, in each spatial position, can take values in the range [0mV;250mV], has the linear histogram of its brightness represented (approximately) in Fig.2."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801638"
                        ],
                        "name": "J. Kittler",
                        "slug": "J.-Kittler",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Kittler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kittler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144275801"
                        ],
                        "name": "J. Illingworth",
                        "slug": "J.-Illingworth",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Illingworth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Illingworth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2604191"
                        ],
                        "name": "J. F\u00f6glein",
                        "slug": "J.-F\u00f6glein",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "F\u00f6glein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. F\u00f6glein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14389523,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "8737272b3d867ba7203570dafb12c4fe45307b43",
            "isKey": false,
            "numCitedBy": 286,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Threshold-selection-based-on-a-simple-image-Kittler-Illingworth",
            "title": {
                "fragments": [],
                "text": "Threshold selection based on a simple image statistic"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3200914"
                        ],
                        "name": "Asif Shahab",
                        "slug": "Asif-Shahab",
                        "structuredName": {
                            "firstName": "Asif",
                            "lastName": "Shahab",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Asif Shahab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809705"
                        ],
                        "name": "S. Uchida",
                        "slug": "S.-Uchida",
                        "structuredName": {
                            "firstName": "Seiichi",
                            "lastName": "Uchida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Uchida"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 63
                            }
                        ],
                        "text": "Small subsets have been annotated and utilized for experiments [9, 13, 14] from different data sets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 926374,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06388e33a797b32b5bfddf39c5db7ecf478a813f",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Computational models of visual attention use image features to identify salient locations in an image that are likely to attract human attention. Attention models have been quite effectively used for various object detection tasks. However, their use for scene text detection is under-investigated. As a general observation, scene text often conveys important information and is usually prominent or salient in the scene itself. In this paper, we evaluate four state-of-the-art attention models for their response to scene text. Initial results indicate that saliency maps produced by these attention models can be used for aiding scene text detection algorithms by suppressing non-text regions."
            },
            "slug": "How-Salient-is-Scene-Text-Shahab-Shafait",
            "title": {
                "fragments": [],
                "text": "How Salient is Scene Text?"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Initial results indicate that saliency maps produced by these attention models can be used for aiding scene text detection algorithms by suppressing non-text regions."
            },
            "venue": {
                "fragments": [],
                "text": "2012 10th IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809629"
                        ],
                        "name": "N. Otsu",
                        "slug": "N.-Otsu",
                        "structuredName": {
                            "firstName": "Nobuyuki",
                            "lastName": "Otsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Otsu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15326934,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "1d4816c612e38dac86f2149af667a5581686cdef",
            "isKey": false,
            "numCitedBy": 32882,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A nonparametric and unsupervised method ofautomatic threshold selection for picture segmentation is presented. An optimal threshold is selected by the discriminant criterion, namely, so as to maximize the separability of the resultant classes in gray levels. The procedure is very simple, utilizing only the zerothand the first-order cumulative moments of the gray-level histogram. It is straightforward to extend the method to multithreshold problems. Several experimental results are also presented to support the validity of the method."
            },
            "slug": "A-threshold-selection-method-from-gray-level-Otsu",
            "title": {
                "fragments": [],
                "text": "A threshold selection method from gray level histograms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861837498"
                        ],
                        "name": "G. G. Stokes",
                        "slug": "G.-G.-Stokes",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Stokes",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. G. Stokes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 110
                            }
                        ],
                        "text": "Finally, we apply Kittler\u2019s robust automatic threshold selection algorithm on the intensity image of the word [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 221060727,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "90006064cafcb0a9ad8a30cffeb56efe7e14129b",
            "isKey": false,
            "numCitedBy": 673075,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "however (for it was the literal soul of the life of the Redeemer, John xv. io), is the peculiar token of fellowship with the Redeemer. That love to God (what is meant here is not God\u2019s love to men) is described in such a case as a perfect love (love that has been perfected), involves no difficulty, for the simple reason that the proposition is purely hypothetical. We must, of course, also take the &dquo;keeping&dquo; in all its stringency. John knows right well that the case supposed here ncver becomes full reality. &dquo; Hereb)\u2019,&dquo; i.e. from the actual realization of love to God. &dquo; TIli7i 7e)e are ill Hinz &dquo;"
            },
            "slug": "\"J.\"-Stokes",
            "title": {
                "fragments": [],
                "text": "\"J.\""
            },
            "venue": {
                "fragments": [],
                "text": "The New Yale Book of Quotations"
            },
            "year": 2021
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809629"
                        ],
                        "name": "N. Otsu",
                        "slug": "N.-Otsu",
                        "structuredName": {
                            "firstName": "Nobuyuki",
                            "lastName": "Otsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Otsu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "Then, each of the images is split into the three individual planes and Otsu\u2019s threshold [1] is applied individually on the resulting nine planes, which are essentially gray level images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 123885967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0623b57025fdd723db3808eab90dce06e9ed294",
            "isKey": false,
            "numCitedBy": 1148,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "ATlreshold-Selection-Method-fromGray-Level-Otsu",
            "title": {
                "fragments": [],
                "text": "ATlreshold Selection Method fromGray-Level Histograms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "These data sets are from ICDAR 2003 competition [4], ICDAR 2011 competition [10, 11], Street view [8], born-digital and Sign evaluation data sets [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "Robust reading competition was first conducted in ICDAR 2003 [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "al [4] organized separate competitions for text localization on camera captured images and recognition from the word images cropped by placing a bounding box on the image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust reading competitions: entries, results and future directions"
            },
            "venue": {
                "fragments": [],
                "text": "\u201cICDAR"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adobe Reader. http://www.adobe.com/products/acrobatpro/scanningocr-to-pdf .html [20] GIMP. http://www.gimp.org/ [21] IAPR TC11 Reading Systems-Data sets List"
            },
            "venue": {
                "fragments": [],
                "text": "Adobe Reader. http://www.adobe.com/products/acrobatpro/scanningocr-to-pdf .html [20] GIMP. http://www.gimp.org/ [21] IAPR TC11 Reading Systems-Data sets List"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "A multi-script annotation toolkit for scene text (MAST) was developed by MILE lab in 2011 [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MAST: Multi-script annotation for scene images toolkit"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Joint workshop on MOCR and AND,"
            },
            "year": 2011
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 11
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 22,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Benchmarking-recognition-results-on-camera-captured-Kumar-Prasad/6ea4e71cfe25284687503d11e32167b20d9c2f08?sort=total-citations"
}