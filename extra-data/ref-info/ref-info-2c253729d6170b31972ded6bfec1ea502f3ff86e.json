{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2446509"
                        ],
                        "name": "P. D. Sahin",
                        "slug": "P.-D.-Sahin",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Sahin",
                            "middleNames": [
                                "Duygulu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Sahin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "First, we show that a very simple approach performs as well as state-of-the art methods [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "We recreated nine of the 10 datasets, with more than 98% intersection with [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 135
                            }
                        ],
                        "text": "Different subsets of the Corel image collection (60000 images annotated with 3 to 5 describing keywords) have been used in recent work [1, 7, 4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[1] presented a study of different auto-annotation methods on a subset of 80 Corel CDs, from which 10 different training and test sets were sampled."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "We use the normalized score measure [1],"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 53
                            }
                        ],
                        "text": ", the association of words to specific image regions [1, 3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 68
                            }
                        ],
                        "text": "More elaborate features could be added in a straightforward fashion [1, 4, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Furthermore, as in [1], the keyword vocabulary size was reduced from an average of 1876 to 149 keywords, by retaining only the keywords appearing more than 20 times in the training set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 102
                            }
                        ],
                        "text": "Furthermore, objectively assessing the quality of image autoannotation is in itself a complex problem [1, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 312,
                                "start": 309
                            }
                        ],
                        "text": "The second approach takes a differing viewpoint, and attempts to discover the statistical links between visual features and words on an unsupervised basis, by estimating the joint distribution of words and regional image features, and elegantly posing annotation as statistical inference in a graphical model [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 868535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a26268d2ba9d34e5b59ae6e5c11a83cdca1a85e",
            "isKey": true,
            "numCitedBy": 1760,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text. Learning the joint distribution of image regions and words has many applications. We consider in detail predicting words associated with whole images (auto-annotation) and corresponding to particular image regions (region naming). Auto-annotation might help organize and access large collections of images. Region naming is a model of object recognition as a process of translating image regions to words, much as one might translate from one language to another. Learning the relationships between image regions and semantic correlates (words) is an interesting example of multi-modal data mining, particularly because it is typically hard to apply data mining techniques to collections of images. We develop a number of models for the joint distribution of image regions and words, including several which explicitly learn the correspondence between regions and words. We study multi-modal and correspondence extensions to Hofmann's hierarchical clustering/aspect model, a translation model adapted from statistical machine translation (Brown et al.), and a multi-modal extension to mixture of latent Dirichlet allocation (MoM-LDA). All models are assessed using a large collection of annotated images of real scenes. We study in depth the difficult problem of measuring performance. For the annotation task, we look at prediction performance on held out data. We present three alternative measures, oriented toward different types of task. Measuring the performance of correspondence methods is harder, because one must determine whether a word has been placed on the right region of an image. We can use annotation performance as a proxy measure, but accurate measurement requires hand labeled data, and thus must occur on a smaller scale. We show results using both an annotation proxy, and manually labeled data."
            },
            "slug": "Matching-Words-and-Pictures-Barnard-Sahin",
            "title": {
                "fragments": [],
                "text": "Matching Words and Pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text, is presented, and a number of models for the joint distribution of image regions and words are developed, including several which explicitly learn the correspondence between regions and Words."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33794424"
                        ],
                        "name": "E. Chang",
                        "slug": "E.-Chang",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Chang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40603954"
                        ],
                        "name": "Kingshy Goh",
                        "slug": "Kingshy-Goh",
                        "structuredName": {
                            "firstName": "Kingshy",
                            "lastName": "Goh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kingshy Goh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2314761"
                        ],
                        "name": "Gerard Sychay",
                        "slug": "Gerard-Sychay",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Sychay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gerard Sychay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145394457"
                        ],
                        "name": "Gang Wu",
                        "slug": "Gang-Wu",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gang Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 135
                            }
                        ],
                        "text": "Different subsets of the Corel image collection (60000 images annotated with 3 to 5 describing keywords) have been used in recent work [1, 7, 4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 68
                            }
                        ],
                        "text": "More elaborate features could be added in a straightforward fashion [1, 4, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 158
                            }
                        ],
                        "text": "The first one defines annotation as a supervised learning problem, and associates words to images by first defining classes, each one corresponding to a word [4], or a set of words defining a concept [7], followed by training of each visual class model with manually labeled images, image classification into one or more classes, and finally annotating by propagating the corresponding class words."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12014229,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62f5bf45b2e702775fa2a36de45a7522bb9ff23f",
            "isKey": false,
            "numCitedBy": 497,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a content-based soft annotation (CBSA) procedure for providing images with semantical labels. The annotation procedure starts with labeling a small set of training images, each with one single semantical label (e.g., forest, animal, or sky). An ensemble of binary classifiers is then trained for predicting label membership for images. The trained ensemble is applied to each individual image to give the image multiple soft labels, and each label is associated with a label membership factor. To select a base binary-classifier for CBSA, we experiment with two learning methods, support vector machines (SVMs) and Bayes point machines (BPMs), and compare their class-prediction accuracy. Our empirical study on a 116-category 25K-image set shows that the BPM-based ensemble provides better annotation quality than the SVM-based ensemble for supporting multimodal image retrievals."
            },
            "slug": "CBSA:-content-based-soft-annotation-for-multimodal-Chang-Goh",
            "title": {
                "fragments": [],
                "text": "CBSA: content-based soft annotation for multimodal image retrieval using Bayes point machines"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work proposes a content-based soft annotation procedure for providing images with semantical labels, and experiments with two learning methods, support vector machines (SVMs) and Bayes point machines (BPMs), to select a base binary-classifier for CBSA."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Circuits Syst. Video Technol."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758740"
                        ],
                        "name": "T. Westerveld",
                        "slug": "T.-Westerveld",
                        "structuredName": {
                            "firstName": "Thijs",
                            "lastName": "Westerveld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Westerveld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 116
                            }
                        ],
                        "text": "LSA has been extensively used in text analysis, and more recently to improve retrieval of multimedia news documents [9, 10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 182
                            }
                        ],
                        "text": "Annotated images (multimedia documents) can naturally be embedded in such a vector-space representation in order to apply text analysis methods, via a quantized image representation [9, 10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1638901,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c41ff2177d56bc118ae55871061b340ac2741eb4",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we introduce a new approach to image retrieval. This new approach takes the best from two worlds, combines image features (content) and words from collateral text (context) into one semantic space. Our approach uses Latent Semantic Indexing, a method that uses co-occurrence statistics to uncover hidden semantics. This paper shows how this method, that has proven successful in both monolingual and cross lingual text retrieval, can be used for multi-modal and cross-modal information retrieval. Experiments with an on-line newspaper archive show that Latent Semantic Indexing can outperform both content based and context based approaches and that it is a promising approach for indexing visual and multi-modal data."
            },
            "slug": "Image-Retrieval:-Content-versus-Context-Westerveld",
            "title": {
                "fragments": [],
                "text": "Image Retrieval: Content versus Context"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experiments with an on-line newspaper archive show that Latent Semantic Indexing can outperform both content based and context based approaches and that it is a promising approach for indexing visual and multi-modal data."
            },
            "venue": {
                "fragments": [],
                "text": "RIAO"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 53
                            }
                        ],
                        "text": ", the association of words to specific image regions [1, 3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207561477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "473f4b7f8ae2b03dda2593f54b316ff7d55db26b",
            "isKey": false,
            "numCitedBy": 1214,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of modeling annotated data---data with multiple types where the instance of one type (such as a caption) serves as a description of the other type (such as an image). We describe three hierarchical probabilistic mixture models which aim to describe such data, culminating in correspondence latent Dirichlet allocation, a latent variable model that is effective at modeling the joint distribution of both types and the conditional distribution of the annotation given the primary type. We conduct experiments on the Corel database of images and captions, assessing performance in terms of held-out likelihood, automatic annotation, and text-based image retrieval."
            },
            "slug": "Modeling-annotated-data-Blei-Jordan",
            "title": {
                "fragments": [],
                "text": "Modeling annotated data"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Three hierarchical probabilistic mixture models which aim to describe annotated data with multiple types, culminating in correspondence latent Dirichlet allocation, a latent variable model that is effective at modeling the joint distribution of both types and the conditional distribution of the annotation given the primary type."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "PLSA [8] models each term in a document as arising from a mixture model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 163
                            }
                        ],
                        "text": "The large number of parameters in the model (M \u2217K for P (wj | zk) and K \u2217N for P (zk | di)) makes PLSA prone to overfitting, and requires a tempered version of EM [8]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "We apply and compare two wellknown latent space models for discrete data: LSA [6] and PLSA [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "This ability of PLSA to handle polysemy [8] could be penalized by the way of evaluating annotation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 201
                            }
                        ],
                        "text": "For annotation, the distributions P (wj | zk) are estimated once from the training set, while the P (zk | q) topic mixture for each unannotated image q is computed following the procedure described in [8] (1)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 109
                            }
                        ],
                        "text": "Several models for collections of discrete data have been proposed and successfully applied to text analysis [6, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "Latent Semantic Analysis (LSA) [6] and Probabilistic Latent Semantic Analysis (PLSA) [8] are two such algorithms, investigated here in the context of auto-annotation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 114
                            }
                        ],
                        "text": "The fact that the PLSA annotation score is lower than LSA is somewhat contradictory with the results presented in [8], where PLSA outerperforms LSA for retrieving text."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "Unfortunately, LSA lacks a clear probabilistic interpretation [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7605995,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6dd83b2aa34c806596fc619ff3fbccf5f9830ab",
            "isKey": true,
            "numCitedBy": 2499,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel statistical method for factor analysis of binary and count data which is closely related to a technique known as Latent Semantic Analysis. In contrast to the latter method which stems from linear algebra and performs a Singular Value Decomposition of co-occurrence tables, the proposed technique uses a generative latent class model to perform a probabilistic mixture decomposition. This results in a more principled approach with a solid foundation in statistical inference. More precisely, we propose to make use of a temperature controlled version of the Expectation Maximization algorithm for model fitting, which has shown excellent performance in practice. Probabilistic Latent Semantic Analysis has many applications, most prominently in information retrieval, natural language processing, machine learning from text, and in related areas. The paper presents perplexity results for different types of text and linguistic data collections and discusses an application in automated document indexing. The experiments indicate substantial and consistent improvements of the probabilistic method over standard Latent Semantic Analysis."
            },
            "slug": "Unsupervised-Learning-by-Probabilistic-Latent-Hofmann",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning by Probabilistic Latent Semantic Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes to make use of a temperature controlled version of the Expectation Maximization algorithm for model fitting, which has shown excellent performance in practice, and results in a more principled approach with a solid foundation in statistical inference."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48094094"
                        ],
                        "name": "James Ze Wang",
                        "slug": "James-Ze-Wang",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ze"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Ze Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 135
                            }
                        ],
                        "text": "Different subsets of the Corel image collection (60000 images annotated with 3 to 5 describing keywords) have been used in recent work [1, 7, 4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 102
                            }
                        ],
                        "text": "Furthermore, objectively assessing the quality of image autoannotation is in itself a complex problem [1, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 68
                            }
                        ],
                        "text": "More elaborate features could be added in a straightforward fashion [1, 4, 7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 200
                            }
                        ],
                        "text": "The first one defines annotation as a supervised learning problem, and associates words to images by first defining classes, each one corresponding to a word [4], or a set of words defining a concept [7], followed by training of each visual class model with manually labeled images, image classification into one or more classes, and finally annotating by propagating the corresponding class words."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3028284,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f39d3e88cce063ccd3ca01100efd44dcabc9d3b4",
            "isKey": true,
            "numCitedBy": 1187,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic linguistic indexing of pictures is an important but highly challenging problem for researchers in computer vision and content-based image retrieval. In this paper, we introduce a statistical modeling approach to this problem. Categorized images are used to train a dictionary of hundreds of statistical models each representing a concept. Images of any given concept are regarded as instances of a stochastic process that characterizes the concept. To measure the extent of association between an image and the textual description of a concept, the likelihood of the occurrence of the image based on the characterizing stochastic process is computed. A high likelihood indicates a strong association. In our experimental implementation, we focus on a particular group of stochastic processes, that is, the two-dimensional multiresolution hidden Markov models (2D MHMMs). We implemented and tested our ALIP (Automatic Linguistic Indexing of Pictures) system on a photographic image database of 600 different concepts, each with about 40 training images. The system is evaluated quantitatively using more than 4,600 images outside the training database and compared with a random annotation scheme. Experiments have demonstrated the good accuracy of the system and its high potential in linguistic indexing of photographic images."
            },
            "slug": "Automatic-Linguistic-Indexing-of-Pictures-by-a-Li-Wang",
            "title": {
                "fragments": [],
                "text": "Automatic Linguistic Indexing of Pictures by a Statistical Modeling Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper implemented and tested the ALIP (Automatic Linguistic Indexing of Pictures) system on a photographic image database of 600 different concepts, each with about 40 training images and demonstrated the good accuracy of the system and its high potential in linguistic indexing of photographic images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143761956"
                        ],
                        "name": "A. Benitez",
                        "slug": "A.-Benitez",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Benitez",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Benitez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15846908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b90d44b9ed546cdb96974c70af0189bdfc5e3f2",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents new methods for extracting semantic knowledge from collections of annotated images. The proposed methods include novel automatic techniques for extracting semantic concepts by disambiguating the senses of words in annotations using the lexical database WordNet, using both the images and their annotations, and for discovering semantic relations among the detected concepts based on WordNet. Another contribution of this paper is the evaluation of several techniques for visual feature descriptor extraction and data clustering in the extraction of semantic concepts. Experiments show the potential of integrating the analysis of both images and annotations for improving the performance of the word-sense disambiguation process. In particular, the accuracy improves 4-15% with respect to the baselines systems for nature images."
            },
            "slug": "Semantic-knowledge-construction-from-annotated-Benitez-Chang",
            "title": {
                "fragments": [],
                "text": "Semantic knowledge construction from annotated image collections"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experiments show the potential of integrating the analysis of both images and annotations for improving the performance of the word-sense disambiguation process, and the accuracy improves 4-15% with respect to the baselines systems for nature images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. IEEE International Conference on Multimedia and Expo"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121140068"
                        ],
                        "name": "R. Zhao",
                        "slug": "R.-Zhao",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160149"
                        ],
                        "name": "W. Grosky",
                        "slug": "W.-Grosky",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Grosky",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grosky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 116
                            }
                        ],
                        "text": "LSA has been extensively used in text analysis, and more recently to improve retrieval of multimedia news documents [9, 10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 182
                            }
                        ],
                        "text": "Annotated images (multimedia documents) can naturally be embedded in such a vector-space representation in order to apply text analysis methods, via a quantized image representation [9, 10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5719543,
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "id": "3c4cae972b9baa7bd4296b196c1d4a321069e825",
            "isKey": false,
            "numCitedBy": 272,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the results of our work that seek to negotiate the gap between low-level features and high-level concepts in the domain of web document retrieval. This work concerns a technique, called the latent semantic indexing (LSI), which has been used for textual information retrieval for many years. In this environment, LSI determines clusters of co-occurring keywords so that a query which uses a particular keyword can then retrieve documents perhaps not containing this keyword, but containing other keywords from the same cluster. In this paper, we examine the use of this technique for content-based web document retrieval, using both keywords and image features to represent the documents. Two different approaches to image feature representation, namely, color histograms and color anglograms, are adopted and evaluated. Experimental results show that LSI, together with both textual and visual features, is able to extract the underlying semantic structure of web documents, thus helping to improve the retrieval performance significantly, even when querying is done using only keywords."
            },
            "slug": "Narrowing-the-semantic-gap-improved-text-based-web-Zhao-Grosky",
            "title": {
                "fragments": [],
                "text": "Narrowing the semantic gap - improved text-based web document retrieval using visual features"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Experimental results show that LSI, together with both textual and visual features, is able to extract the underlying semantic structure of web documents, thus helping to improve the retrieval performance significantly, even when querying is done using only keywords."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Multim."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145632116"
                        ],
                        "name": "N. Coccaro",
                        "slug": "N.-Coccaro",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Coccaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Coccaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "An empirical method to derive probabilities from LSA is suggested in [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13185450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b888cae7e6e288b108f9d119fc23b84b4d447029",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a number of techniques designed to help integrate semantic knowledge with N-gram language models for automatic speech recognition. Our techniques allow us to integrate Latent Semantic Analysis (LSA), a word-similarity algorithm based on word co-occurrence information, with N-gram models. While LSA is good at predicting content words which are coherent with the rest of a text, it is a bad predictor of frequent words, has a low dynamic range, and is inaccurate when combined linearly with N-grams. We show that modifying the dynamic range, applying a per-word con \ufb01 dence metric, and using geometric rather than linear combinations with N-grams produces a more robust language model which has a lower perplexity on a Wall Street Journal test-set than a baseline N-gram model."
            },
            "slug": "Towards-better-integration-of-semantic-predictors-Coccaro-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Towards better integration of semantic predictors in statistical language modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that modifying the dynamic range, applying a per-word con \ufb01 dence metric, and using geometric rather than linear combinations with N-grams produces a more robust language model which has a lower perplexity on a Wall Street Journal test-set than a baseline N- gram model."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5,
            "methodology": 7,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 9,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/On-image-auto-annotation-with-latent-space-models-Monay-G\u00e1tica-P\u00e9rez/2c253729d6170b31972ded6bfec1ea502f3ff86e?sort=total-citations"
}