{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070476489"
                        ],
                        "name": "G. Barth",
                        "slug": "G.-Barth",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Barth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Barth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8050292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "594b85be162ba3c89df9da8c579c3c06a6ebf883",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The realization of the paper-free office seems to be difficult that expected. Therefore, good paper-computer interfaces are necessary to transform paper documents into an electronic form, which allows the use of a filing and retrieval system. An electronic document page is an optically scanned and digitized representation of a printed page. Document analysis is the problem of interpreting and labeling the constitutents of the document. Although there are very reliable optical character recognition (OCR) methods, the process could be very inefficient. To prune the search space and to become more efficient, some search supporting methods have to be developed. This article proposes an approach to identify the layout of a document page by dividing it recursively into nested rectangular areas. The procedure is used as a basis for a document layout model, which is able to control an automatic interpretation mechanism for deriving a high level representation of the contents of a document. We have implemented our method in Common Lisp on a Symbolies 3640 Workstation and have run it for a large population of office documents. The results obtained have been very encouraging and have convincingly confirmed the soundness of our approach."
            },
            "slug": "High-Level-Document-Analysis-Guided-by-Geometric-Dengel-Barth",
            "title": {
                "fragments": [],
                "text": "High Level Document Analysis Guided by Geometric Aspects"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This article proposes an approach to identify the layout of a document page by dividing it recursively into nested rectangular areas and uses it as a basis for a document layout model, which is able to control an automatic interpretation mechanism for deriving a high level representation of the contents of a documents."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409052480"
                        ],
                        "name": "S. C. Hinds",
                        "slug": "S.-C.-Hinds",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Hinds",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. C. Hinds"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2168553590"
                        ],
                        "name": "James L. Fisher",
                        "slug": "James-L.-Fisher",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Fisher",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James L. Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402307078"
                        ],
                        "name": "D. D'Amato",
                        "slug": "D.-D'Amato",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "D'Amato",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. D'Amato"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61919721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b27f45bebdec8e8d8503f7314533674c51de0e84",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "As part of the development of a document image analysis system, a method, based on the Hough transform, was devised for the detection of document skew and interline spacing-necessary parameters for the automatic segmentation of text from graphics. Because the Hough transform is computationally expensive, the amount of data within a document image is reduced through the computation of its horizontal and vertical black runlengths. Histograms of these runlengths are used to determine whether the document is in portrait or landscape orientation. A gray scale burst image is created from the black runlengths that are perpendicular to the text lines by placing the length of the run in the run's bottom-most pixel. By creating a burst image from the original document image, the processing time of the Hough transform can be reduced by a factor of as much as 7.4 for documents with gray-scale images. Because only small runlengths are input to the Hough transform and because the accumulator array is incremented by the runlength associated with a pixel rather than by a factor of 1, the negative effects of noise, black margins, and figures are avoided. Consequently, interline spacing can be determined more accurately.<<ETX>>"
            },
            "slug": "A-document-skew-detection-method-using-run-length-Hinds-Fisher",
            "title": {
                "fragments": [],
                "text": "A document skew detection method using run-length encoding and the Hough transform"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "By creating a burst image from the original document image, the processing time of the Hough transform can be reduced by a factor of as much as 7.4 for documents with gray-scale images and interline spacing can be determined more accurately."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings. 10th International Conference on Pattern Recognition"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47260288"
                        ],
                        "name": "L. Fletcher",
                        "slug": "L.-Fletcher",
                        "structuredName": {
                            "firstName": "Lloyd",
                            "lastName": "Fletcher",
                            "middleNames": [
                                "Alan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Fletcher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2685456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b08e547ba4edb60902d1708a5593d71f075aa7f1",
            "isKey": false,
            "numCitedBy": 655,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described. It is intended for use in an automated system for document analysis. The principal parts of the algorithm are the generation of connected components and the application of the Hough transform in order to group components into logical character strings that can then be separated from the graphics. The algorithm outputs two images, one containing text strings and the other graphics. These images can then be processed by suitable character recognition and graphics recognition systems. The performance of the algorithm, both in terms of its effectiveness and computational efficiency, was evaluated using several test images and showed superior performance compared to other techniques. >"
            },
            "slug": "A-Robust-Algorithm-for-Text-String-Separation-from-Fletcher-Kasturi",
            "title": {
                "fragments": [],
                "text": "A Robust Algorithm for Text String Separation from Mixed Text/Graphics Images"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described and showed superior performance compared to other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847486"
                        ],
                        "name": "R. Sinha",
                        "slug": "R.-Sinha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Sinha",
                            "middleNames": [
                                "Mahesh",
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sinha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511209"
                        ],
                        "name": "B. Prasada",
                        "slug": "B.-Prasada",
                        "structuredName": {
                            "firstName": "Birendra",
                            "lastName": "Prasada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Prasada"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10580238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f265964b78406766a519489cba77eca6a02b544",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Visual-text-recognition-through-contextual-Sinha-Prasada",
            "title": {
                "fragments": [],
                "text": "Visual text recognition through contextual processing"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102213388"
                        ],
                        "name": "K. Thompson",
                        "slug": "K.-Thompson",
                        "structuredName": {
                            "firstName": "Kendall",
                            "lastName": "Thompson",
                            "middleNames": [
                                "Milar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Thompson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26523155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5298e5b0a3c18f4ef4b3f09eb8bdc2f7e5f3e22f",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "By applying semantic analysis to images of extended passages of text, several volumes of a chess encyclopedia have been read with high accuracy. Although carefully proofread, the books were poorly printed and posed a severe challenge to conventional page-layout analysis and character-recognition methods. An experimental page-reader system performed strictly top-down layout analysis for identification of columns, lines, words, and characters. This proceeded rapidly and reliably thanks to a recently developed skew-estimation technique. Resegmentation of broken, touching, and dirty characters was handled in an efficient and integrated manner by a heuristic search operating on isolated words. By analyzing the syntax of game descriptions and applying the rules of chess, the error rate was reduced by a factor of 30 from what was achievable through shape analysis alone. Several computer vision systems integration issues suggested by this experience are discussed. >"
            },
            "slug": "Reading-Chess-Baird-Thompson",
            "title": {
                "fragments": [],
                "text": "Reading Chess"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "By applying semantic analysis to images of extended passages of text, several volumes of a chess encyclopedia have been read with high accuracy and the error rate was reduced by a factor of 30 from what was achievable through shape analysis alone."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20480391,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30035e057aff1ba6544e35d6ccf50ec902a08905",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Feature-identification-for-hybrid-pattern-Baird",
            "title": {
                "fragments": [],
                "text": "Feature identification for hybrid structural/statistical pattern classification"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2372168"
                        ],
                        "name": "D. Elliman",
                        "slug": "D.-Elliman",
                        "structuredName": {
                            "firstName": "Dave",
                            "lastName": "Elliman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Elliman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235118"
                        ],
                        "name": "I. Lancaster",
                        "slug": "I.-Lancaster",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Lancaster",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Lancaster"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2245098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72c4b0c2b3bf0ea9cae8eea122386fc9ded735d8",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-review-of-segmentation-and-contextual-analysis-Elliman-Lancaster",
            "title": {
                "fragments": [],
                "text": "A review of segmentation and contextual analysis techniques for text recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31338632"
                        ],
                        "name": "E. Riseman",
                        "slug": "E.-Riseman",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Riseman",
                            "middleNames": [
                                "M."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riseman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733922"
                        ],
                        "name": "A. Hanson",
                        "slug": "A.-Hanson",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Hanson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hanson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1402380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f6070891aa179e1342dfa9d69868ad2c691211e",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The effectiveness of various forms of contextual information in a postprocessing system for detection and correction of errors in words is examined. Various algorithms utilizing context are considered, from a dictionary algorithm which has available the maximum amount of information, to a set of contextual algorithms utilizing positional binary n-gram statistics. The latter information differs from the usual n-gram letter statistics in that the probabilities are position-dependent and each is quantized to 1 or 0, depending upon whether or not it is nonzero. This type of information is extremely compact and the computation for error correction is orders of magnitude less than that required by the dictionary algorithm."
            },
            "slug": "A-Contextual-Postprocessing-System-for-Error-Using-Riseman-Hanson",
            "title": {
                "fragments": [],
                "text": "A Contextual Postprocessing System for Error Correction Using Binary n-Grams"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Various algorithms utilizing context are considered, from a dictionary algorithm which has available the maximum amount of information, to a set of contextual algorithms utilizing positional binary n-gram statistics."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41312633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27",
            "isKey": false,
            "numCitedBy": 7830,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification."
            },
            "slug": "Backpropagation-Applied-to-Handwritten-Zip-Code-LeCun-Boser",
            "title": {
                "fragments": [],
                "text": "Backpropagation Applied to Handwritten Zip Code Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper demonstrates how constraints from the task domain can be integrated into a backpropagation network through the architecture of the network, successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2312891"
                        ],
                        "name": "A. Goshtasby",
                        "slug": "A.-Goshtasby",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Goshtasby",
                            "middleNames": [
                                "Ardeshir"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Goshtasby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143630353"
                        ],
                        "name": "R. Ehrich",
                        "slug": "R.-Ehrich",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Ehrich",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ehrich"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11479173,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf6cd667c7e209368d0dc24ac1230beb7e3c45bb",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Contextual-word-recognition-using-probabilistic-Goshtasby-Ehrich",
            "title": {
                "fragments": [],
                "text": "Contextual word recognition using probabilistic relaxation labeling"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398965769"
                        ],
                        "name": "Y. Abu-Mostafa",
                        "slug": "Y.-Abu-Mostafa",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Abu-Mostafa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Abu-Mostafa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17945746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f027c678076d7f2fd817f081079a334466449b1",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "When feasible, learning is a very attractive alternative to explicit programming. This is particularly true in areas where the problems do not lend themselves to systematic programming, such as pattern recognition in natural environments. The feasibility of learning an unknown function from examples depends on two questions: 1. Do the examples convey enough information to determine the function? 2. Is there a speedy way of constructing the function from the examples? These questions contrast the roles of information and complexity in learning. While the two roles share some ground, they are conceptually and technically different. In the common language of learning, the information question is that of generalization and the complexity question is that of scaling. The work of Vapnik and Chervonenkis (1971) provides the key tools for dealing with the information issue. In this review, we develop the main ideas of this framework and discuss how complexity fits in."
            },
            "slug": "The-Vapnik-Chervonenkis-Dimension:-Information-in-Abu-Mostafa",
            "title": {
                "fragments": [],
                "text": "The Vapnik-Chervonenkis Dimension: Information versus Complexity in Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The work of Vapnik and Chervonenkis (1971) provides the key tools for dealing with the information issue and the main ideas are developed and how complexity fits in are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8142232,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a36b028d024bf358c4af1a5e1dc3ca0aed23b553",
            "isKey": false,
            "numCitedBy": 3709,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter reproduces the English translation by B. Seckler of the paper by Vapnik and Chervonenkis in which they gave proofs for the innovative results they had obtained in a draft form in July 1966 and announced in 1968 in their note in Soviet Mathematics Doklady. The paper was first published in Russian as \u0412\u0430\u043f\u043d\u0438\u043a \u0412. \u041d. and \u0427\u0435\u0440\u0432\u043e\u043d\u0435\u043d\u043a\u0438\u0441 \u0410. \u042f. \u041e \u0440\u0430\u0432\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0419 \u0441\u0445\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438 \u0447\u0430\u0441\u0442\u043e\u0442 \u043f\u043e\u044f\u0432\u043b\u0435\u043d\u0438\u044f \u0441\u043e\u0431\u044b\u0442\u0438\u0419 \u043a \u0438\u0445 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044f\u043c. \u0422\u0435\u043e\u0440\u0438\u044f \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0435\u0419 \u0438 \u0435\u0435 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u044f 16(2), 264\u2013279 (1971)."
            },
            "slug": "Chervonenkis:-On-the-uniform-convergence-of-of-to-Vapnik",
            "title": {
                "fragments": [],
                "text": "Chervonenkis: On the uniform convergence of relative frequencies of events to their probabilities"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter reproduces the English translation by B. Seckler of the paper by Vapnik and Chervonenkis in which they gave proofs for the innovative results they had obtained in a draft form in July 1966 and announced in 1968 in their note in Soviet Mathematics Doklady."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1450924266"
                        ],
                        "name": "B. Moret",
                        "slug": "B.-Moret",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Moret",
                            "middleNames": [
                                "M.",
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moret"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14003269,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4285deefe2916557ede60b5f80102a017fca23e",
            "isKey": false,
            "numCitedBy": 341,
            "numCiting": 157,
            "paperAbstract": {
                "fragments": [],
                "text": "Decision trees and diagrams (also known as sequential evaluation procedures) have widespread applications in databases, dec~smn table programming, concrete complexity theory, switching theory, pattern recognmon, and taxonomy--in short, wherever discrete functions must be evaluated sequentially. In this tutorial survey a common framework of defimtmns and notation is established, the contributions from the main fields of apphcatmn are reviewed, recent results and extensions are presented, and areas of ongoing and future research are discussed."
            },
            "slug": "Decision-Trees-and-Diagrams-Moret",
            "title": {
                "fragments": [],
                "text": "Decision Trees and Diagrams"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "In this tutorial survey a common framework of defimtmns and notation is established, the contributions from the main fields of apphcatmn are reviewed, recent results and extensions are presented, and areas of ongoing and future research are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808760"
                        ],
                        "name": "S. Omohundro",
                        "slug": "S.-Omohundro",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Omohundro",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Omohundro"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44717168,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff80b7820fbc54926946c245e139c382266489ae",
            "isKey": false,
            "numCitedBy": 213,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Efficient-Algorithms-with-Neural-Network-Behavior-Omohundro",
            "title": {
                "fragments": [],
                "text": "Efficient Algorithms with Neural Network Behavior"
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46391416,
            "fieldsOfStudy": [],
            "id": "d6ddc3eec5641b882c3918a94beb9e6d0701a24a",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Block segmentation and text extraction in mixed text/image documents"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Image Process."
            },
            "year": 1982
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 15,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Omnidocument-technologies-Bokser/6c7e86cee5a41818b5307eefc1e31b71233c21b2?sort=total-citations"
}